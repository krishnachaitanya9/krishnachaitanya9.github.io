---
title: Latest Deep Learning Papers
date: 2020-10-07 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Infinite-Dimensional Fisher Markets: Equilibrium, Duality and Optimization. (arXiv:2010.03025v1 [cs.GT])</h2>
<h3>Yuan Gao, Christian Kroer</h3>
<p>This paper considers a linear Fisher market with $n$ buyers and a continuum
of items. In order to compute market equilibria, we introduce
(infinite-dimensional) convex programs over Banach spaces, thereby generalizing
the Eisenberg-Gale convex program and its dual. Regarding the new convex
programs, we establish existence of optimal solutions, the existence of
KKT-type conditions, as well as strong duality. All these properties are
established via non-standard arguments, which circumvent the limitations of
duality theory in optimization over infinite-dimensional vector spaces.
Furthermore, we show that there exists a pure equilibrium allocation, i.e., a
division of the item space. Similar to the finite-dimensional case, a market
equilibrium under the infinite-dimensional Fisher market is Pareto optimal,
envy-free and proportional. We also show how to obtain the (a.e. unique)
equilibrium price vector and a pure equilibrium allocation from the (unique)
$n$-dimensional equilibrium bang-per-buck vector. When the item space is the
unit interval $[0,1]$ and buyers have piecewise linear utilities, we show that
$\epsilon$-approximate equilibrium prices can be computed in time polynomial in
the market size and $\log \frac{1}{\epsilon}$. This is achieved by solving a
finite-dimensional convex program using the ellipsoid method. To this end, we
give nontrivial and efficient subgradient and separation oracles. For general
buyer valuations, we propose computing market equilibrium using stochastic dual
averaging, which finds an approximate equilibrium price vector with high
probability.
</p>
<a href="http://arxiv.org/abs/2010.03025" target="_blank">arXiv:2010.03025</a> [<a href="http://arxiv.org/pdf/2010.03025" target="_blank">pdf</a>]

<h2>Instance-Dependent Complexity of Contextual Bandits and Reinforcement Learning: A Disagreement-Based Perspective. (arXiv:2010.03104v1 [cs.LG])</h2>
<h3>Dylan J. Foster, Alexander Rakhlin, David Simchi-Levi, Yunzong Xu</h3>
<p>In the classical multi-armed bandit problem, instance-dependent algorithms
attain improved performance on "easy" problems with a gap between the best and
second-best arm. Are similar guarantees possible for contextual bandits? While
positive results are known for certain special cases, there is no general
theory characterizing when and how instance-dependent regret bounds for
contextual bandits can be achieved for rich, general classes of policies. We
introduce a family of complexity measures that are both sufficient and
necessary to obtain instance-dependent regret bounds. We then introduce new
oracle-efficient algorithms which adapt to the gap whenever possible, while
also attaining the minimax rate in the worst case. Finally, we provide
structural results that tie together a number of complexity measures previously
proposed throughout contextual bandits, reinforcement learning, and active
learning and elucidate their role in determining the optimal instance-dependent
regret. In a large-scale empirical evaluation, we find that our approach often
gives superior results for challenging exploration problems.

Turning our focus to reinforcement learning with function approximation, we
develop new oracle-efficient algorithms for reinforcement learning with rich
observations that obtain optimal gap-dependent sample complexity.
</p>
<a href="http://arxiv.org/abs/2010.03104" target="_blank">arXiv:2010.03104</a> [<a href="http://arxiv.org/pdf/2010.03104" target="_blank">pdf</a>]

<h2>SLCRF: Subspace Learning with Conditional Random Field for Hyperspectral Image Classification. (arXiv:2010.03115v1 [cs.CV])</h2>
<h3>Yun Cao, Jie Mei, Yuebin Wang, Liqiang Zhang, Junhuan Peng, Bing Zhang, Lihua Li, Yibo Zheng</h3>
<p>Subspace learning (SL) plays an important role in hyperspectral image (HSI)
classification, since it can provide an effective solution to reduce the
redundant information in the image pixels of HSIs. Previous works about SL aim
to improve the accuracy of HSI recognition. Using a large number of labeled
samples, related methods can train the parameters of the proposed solutions to
obtain better representations of HSI pixels. However, the data instances may
not be sufficient enough to learn a precise model for HSI classification in
real applications. Moreover, it is well-known that it takes much time, labor
and human expertise to label HSI images. To avoid the aforementioned problems,
a novel SL method that includes the probability assumption called subspace
learning with conditional random field (SLCRF) is developed. In SLCRF, first,
the 3D convolutional autoencoder (3DCAE) is introduced to remove the redundant
information in HSI pixels. In addition, the relationships are also constructed
using the spectral-spatial information among the adjacent pixels. Then, the
conditional random field (CRF) framework can be constructed and further
embedded into the HSI SL procedure with the semi-supervised approach. Through
the linearized alternating direction method termed LADMAP, the objective
function of SLCRF is optimized using a defined iterative algorithm. The
proposed method is comprehensively evaluated using the challenging public HSI
datasets. We can achieve stateof-the-art performance using these HSI sets.
</p>
<a href="http://arxiv.org/abs/2010.03115" target="_blank">arXiv:2010.03115</a> [<a href="http://arxiv.org/pdf/2010.03115" target="_blank">pdf</a>]

<h2>DML-GANR: Deep Metric Learning With Generative Adversarial Network Regularization for High Spatial Resolution Remote Sensing Image Retrieval. (arXiv:2010.03116v1 [cs.CV])</h2>
<h3>Yun Cao, Yuebin Wang, Junhuan Peng, Liqiang Zhang, Linlin Xu, Kai Yan, Lihua Li</h3>
<p>With a small number of labeled samples for training, it can save considerable
manpower and material resources, especially when the amount of high spatial
resolution remote sensing images (HSR-RSIs) increases considerably. However,
many deep models face the problem of overfitting when using a small number of
labeled samples. This might degrade HSRRSI retrieval accuracy. Aiming at
obtaining more accurate HSR-RSI retrieval performance with small training
samples, we develop a deep metric learning approach with generative adversarial
network regularization (DML-GANR) for HSR-RSI retrieval. The DML-GANR starts
from a high-level feature extraction (HFE) to extract high-level features,
which includes convolutional layers and fully connected (FC) layers. Each of
the FC layers is constructed by deep metric learning (DML) to maximize the
interclass variations and minimize the intraclass variations. The generative
adversarial network (GAN) is adopted to mitigate the overfitting problem and
validate the qualities of extracted high-level features. DML-GANR is optimized
through a customized approach, and the optimal parameters are obtained. The
experimental results on the three data sets demonstrate the superior
performance of DML-GANR over state-of-the-art techniques in HSR-RSI retrieval.
</p>
<a href="http://arxiv.org/abs/2010.03116" target="_blank">arXiv:2010.03116</a> [<a href="http://arxiv.org/pdf/2010.03116" target="_blank">pdf</a>]

<h2>Cognitive Learning-Aided Multi-Antenna Communications. (arXiv:2010.03131v1 [eess.SP])</h2>
<h3>Ahmet M. Elbir, Kumar Vijay Mishra</h3>
<p>Cognitive communications have emerged as a promising solution to enhance,
adapt, and invent new tools and capabilities that transcend conventional
wireless networks. Deep learning (DL) is critical in enabling essential
features of cognitive systems because of its fast prediction performance,
adaptive behavior, and model-free structure. These features are especially
significant for multi-antenna wireless communications systems, which generate
and handle massive data. Multiple antennas may provide multiplexing, diversity,
or antenna gains that, respectively, improve the capacity, bit error rate, or
the signal-to-interference-plus-noise ratio. In practice, multi-antenna
cognitive communications encounter challenges in terms of data complexity and
diversity, hardware complexity, and wireless channel dynamics. The DL-based
solutions tackle these problems at the various stages of communications
processing such as channel estimation, hybrid beamforming, user localization,
and sparse array design. There are research opportunities to address
significant design challenges arising from insufficient data coverage, learning
model complexity, and data transmission overheads. This article provides
synopses of various DL-based methods to impart cognitive behavior to
multi-antenna wireless communications.
</p>
<a href="http://arxiv.org/abs/2010.03131" target="_blank">arXiv:2010.03131</a> [<a href="http://arxiv.org/pdf/2010.03131" target="_blank">pdf</a>]

<h2>Optimal Gradient Compression for Distributed and Federated Learning. (arXiv:2010.03246v1 [cs.LG])</h2>
<h3>Alyazeed Albasyoni, Mher Safaryan, Laurent Condat, Peter Richt&#xe1;rik</h3>
<p>Communicating information, like gradient vectors, between computing nodes in
distributed and federated learning is typically an unavoidable burden,
resulting in scalability issues. Indeed, communication might be slow and
costly. Recent advances in communication-efficient training algorithms have
reduced this bottleneck by using compression techniques, in the form of
sparsification, quantization, or low-rank approximation. Since compression is a
lossy, or inexact, process, the iteration complexity is typically worsened; but
the total communication complexity can improve significantly, possibly leading
to large computation time savings. In this paper, we investigate the
fundamental trade-off between the number of bits needed to encode compressed
vectors and the compression error. We perform both worst-case and average-case
analysis, providing tight lower bounds. In the worst-case analysis, we
introduce an efficient compression operator, Sparse Dithering, which is very
close to the lower bound. In the average-case analysis, we design a simple
compression operator, Spherical Compression, which naturally achieves the lower
bound. Thus, our new compression schemes significantly outperform the state of
the art. We conduct numerical experiments to illustrate this improvement.
</p>
<a href="http://arxiv.org/abs/2010.03246" target="_blank">arXiv:2010.03246</a> [<a href="http://arxiv.org/pdf/2010.03246" target="_blank">pdf</a>]

<h2>Search-free DOA Estimation Method Based on Tensor Decomposition and Polynomial Rooting for Transmit Beamspace MIMO Radar. (arXiv:2010.03296v1 [cs.IT])</h2>
<h3>Feng Xu, Xiaopeng Yang, Tian Lan, Tapan K. Sarkar</h3>
<p>In order to improve the accuracy and resolution for transmit beamspace
multiple-input multiple-output (MIMO) radar, a search-free direction-of-arrival
(DOA) estimation method based on tensor decomposition and polynomial rooting is
proposed. In the proposed method, a 3-order tensor is firstly designed to model
the received signal of MIMO radar on the basis of the multi-linear property.
Then, the factor matrix with target DOA information is obtained by the tensor
decomposition via alternating least squares (ALS) algorithm, and subsequently
the DOA estimation is converted into independent minimization problem. In the
following, a polynomial function is constructed by exploiting the Vandermonde
structure of the transmit steering vector of MIMO radar. The factor matrix
contained in the polynomial can be regarded as a block matrix in the
generalized sidelobe canceller (GSC), which accordingly forms a unique deep
null in the direction of target in the transmit beampattern. The proposed
method can obtain the DOA estimation without the requirements of spectrum
searching or transmit beamspace matrix design, which is different from the
conventional DOA estimation techniques. The effectiveness and performance of
proposed method is verified by the simulations.
</p>
<a href="http://arxiv.org/abs/2010.03296" target="_blank">arXiv:2010.03296</a> [<a href="http://arxiv.org/pdf/2010.03296" target="_blank">pdf</a>]

<h2>Orthogonal Time-Frequency Space Modulation: A Full-Diversity Next Generation Waveform. (arXiv:2010.03344v1 [cs.IT])</h2>
<h3>Zhiqiang Wei, Weijie Yuan, Shuangyang Li, Jinhong Yuan, Ganesh Bharatula, Ronny Hadani, Lajos Hanzo</h3>
<p>The sixth-generation (6G) wireless networks are envisioned to provide a
global coverage for the intelligent digital society of the near future, ranging
from traditional terrestrial to non-terrestrial networks, where reliable
communications in high-mobility scenarios at high carrier frequencies would
play a vital role. In such scenarios, the conventional orthogonal frequency
division multiplexing (OFDM) modulation, that has been widely used in both the
fourth-generation (4G) and the emerging fifth-generation (5G) cellular systems
as well as in WiFi networks, is vulnerable to severe Doppler spread. In this
context, this article aims to introduce a recently proposed two-dimensional
modulation scheme referred to as orthogonal time-frequency space (OTFS)
modulation, which conveniently accommodates the channel dynamics via modulating
information in the delay-Doppler domain. This article provides an easy-reading
overview of OTFS, highlighting its underlying motivation and specific features.
The critical challenges of OTFS and our preliminary results are presented. We
also discuss a range of promising research opportunities and potential
applications of OTFS in 6G wireless networks.
</p>
<a href="http://arxiv.org/abs/2010.03344" target="_blank">arXiv:2010.03344</a> [<a href="http://arxiv.org/pdf/2010.03344" target="_blank">pdf</a>]

<h2>Teaching and learning in uncertainty. (arXiv:1901.07063v3 [cs.IT] UPDATED)</h2>
<h3>Varun Jog, Po-Ling Loh</h3>
<p>We investigate a simple model for social learning with two agents: a teacher
and a student. The teacher's goal is to teach the student the state of the
world; however, the teacher himself is not certain about the state of the world
and needs to simultaneously learn this parameter and teach it to the student.
We model the teacher's and student's uncertainties via noisy transmission
channels, and employ two simple decoding strategies for the student. We focus
on two teaching strategies: a "low-effort" strategy of simply forwarding
information, and a "high-effort" strategy of communicating the teacher's
current best estimate of the world at each time instant, based on his own
cumulative learning. Using tools from large deviation theory, we calculate the
exact learning rates for these strategies and demonstrate regimes where the
low-effort strategy outperforms the high-effort strategy. Finally, we present a
conjecture concerning the optimal learning rate for the student over all joint
strategies between the student and the teacher.
</p>
<a href="http://arxiv.org/abs/1901.07063" target="_blank">arXiv:1901.07063</a> [<a href="http://arxiv.org/pdf/1901.07063" target="_blank">pdf</a>]

<h2>Affine Rigidity Without Integration. (arXiv:1903.00889v3 [math.DG] UPDATED)</h2>
<h3>Zhangchi Chen (LM-Orsay), Joel Merker (LM-Orsay)</h3>
<p>Real analytic ($\mathcal{C}^\omega$) surfaces $S^2$ in $\mathbb{R}^3 \ni
(x,y,u)$ graphed as $\big\{ u = F(x,y) \big\}$ with $F_{xx} \neq 0$ whose
Gaussian curvature vanishes identically: \[ 0 \,\equiv\, F_{xx}\,F_{yy} -
F_{xy}^2, \] possess, under the action of the affine transformation group ${\sf
Aff}_3(\mathbb{R}) = {\sf GL}_3(\mathbb{R}) \ltimes \mathbb{R}^3$, a basic
invariant analogous to $2$-nondegeneracy for $\mathcal{C}^\omega$ real
hypersurfaces $M^5 \subset \mathbb{C}^3$: \[ S_{\sf aff} \,:=\,
\frac{F_{xx}\,F_{xxy}-F_{xy}\,F_{xxx}}{ F_{xx}^2}. \] It is known (or easily
recovered) that $S$ is affinely equivalent to $\big\{ u = x^2 \big\}$ if and
only if $S_{\sf aff} \equiv 0$.

Assuming that $S_{\sf aff} \neq 0$ everywhere, two deeper affine invariants
inspired from Pocchiola's Ph.D. are $W_{\sf aff}$ and $J_{\sf aff}$. Explicit
expressions are given in this article.

Theorem. $S$ is affinely equivalent to $\big\{ u = \frac{x^2}{1-y} \big\}$ if
and only if $W_{\sf aff} \equiv 0 \equiv J_{\sf aff}$.

As a direct corollary of the (brief) proof, affine rigidity of CR-flat
$2$-nondegenerate $\mathcal{C}^\omega$ Levi rank $1$ hypersurfaces $M^5 \subset
\mathbb{C}^3$ is deduced. The arguments rely on pure affine geometry, avoid any
tool from Analysis, and simplify A.V. Isaev, J. Differential Geom. 104 (2016),
111--141.

An independent article will show, in a more general context, how
$\mathcal{C}^\infty$ (even $\mathcal{C}^7$) $F(x,y)$ can be handled.
</p>
<a href="http://arxiv.org/abs/1903.00889" target="_blank">arXiv:1903.00889</a> [<a href="http://arxiv.org/pdf/1903.00889" target="_blank">pdf</a>]

<h2>Robust pricing and hedging of options on multiple assets and its numerics. (arXiv:1909.03870v2 [math.PR] UPDATED)</h2>
<h3>Stephan Eckstein, Gaoyue Guo, Tongseok Lim, Jan Obloj</h3>
<p>We consider robust pricing and hedging for options written on multiple assets
given market option prices for the individual assets. The resulting problem is
called the multi-marginal martingale optimal transport problem. We propose two
numerical methods to solve such problems: using discretisation and linear
programming applied to the primal side and using penalisation and deep neural
networks optimisation applied to the dual side. We prove convergence for our
methods and compare their numerical performance. We show how adding further
information about call option prices at additional maturities can be
incorporated and narrows down the no-arbitrage pricing bounds. Finally, we
obtain structural results for the case of the payoff given by a weighted sum of
covariances between the assets.
</p>
<a href="http://arxiv.org/abs/1909.03870" target="_blank">arXiv:1909.03870</a> [<a href="http://arxiv.org/pdf/1909.03870" target="_blank">pdf</a>]

<h2>Demon: Momentum Decay for Improved Neural Network Training. (arXiv:1910.04952v3 [cs.LG] UPDATED)</h2>
<h3>John Chen, Cameron Wolfe, Zhao Li, Anastasios Kyrillidis</h3>
<p>Momentum is a popular technique in deep learning for gradient-based
optimizers. We propose a decaying momentum (Demon) rule, motivated by decaying
the total contribution of a gradient to all future updates. Applying Demon to
Adam leads to significantly improved training, notably competitive to momentum
SGD with learning rate decay, even in settings in which adaptive methods are
typically non-competitive. Similarly, applying Demon to momentum SGD improves
over momentum SGD with learning rate decay in most cases. Notably, Demon
momentum SGD is observed to be significantly less sensitive to parameter tuning
than momentum SGD with learning rate decay schedule, critical to training
neural networks in practice. Results are demonstrated across a variety of
settings and architectures, including image classification, generative models,
and language models. Demon is easy to implement and tune, and incurs limited
extra computational overhead, compared to the vanilla counterparts. Code is
readily available.
</p>
<a href="http://arxiv.org/abs/1910.04952" target="_blank">arXiv:1910.04952</a> [<a href="http://arxiv.org/pdf/1910.04952" target="_blank">pdf</a>]

<h2>Optimal quantization of the mean measure and applications to statistical learning. (arXiv:2002.01216v3 [math.ST] UPDATED)</h2>
<h3>Fr&#xe9;d&#xe9;ric Chazal (DATASHAPE), Cl&#xe9;ment Levrard (DATASHAPE, LPSM (UMR\_8001)), Martin Royer (DATASHAPE)</h3>
<p>This paper addresses the case where data come as point sets, or more
generally as discrete measures. Our motivation is twofold: first we intend to
approximate with a compactly supported measure the mean of the measure
generating process, that coincides with the intensity measure in the point
process framework, or with the expected persistence diagram in the framework of
persistence-based topological data analysis. To this aim we provide two
algorithms that we prove almost minimax optimal. Second we build from the
estimator of the mean measure a vectorization map, that sends every measure
into a finite-dimensional Euclidean space, and investigate its properties
through a clustering-oriented lens. In a nutshell, we show that in a mixture of
measure generating process, our technique yields a representation in
$\mathbb{R}^k$, for $k \in \mathbb{N}^*$ that guarantees a good clustering of
the data points with high probability. Interestingly, our results apply in the
framework of persistence-based shape classification via the ATOL procedure
described in \cite{Royer19}.
</p>
<a href="http://arxiv.org/abs/2002.01216" target="_blank">arXiv:2002.01216</a> [<a href="http://arxiv.org/pdf/2002.01216" target="_blank">pdf</a>]

<h2>Federated Learning With Quantized Global Model Updates. (arXiv:2006.10672v2 [cs.IT] UPDATED)</h2>
<h3>Mohammad Mohammadi Amiri, Deniz Gunduz, Sanjeev R. Kulkarni, H. Vincent Poor</h3>
<p>We study federated learning (FL), which enables mobile devices to utilize
their local datasets to collaboratively train a global model with the help of a
central server, while keeping data localized. At each iteration, the server
broadcasts the current global model to the devices for local training, and
aggregates the local model updates from the devices to update the global model.
Previous work on the communication efficiency of FL has mainly focused on the
aggregation of model updates from the devices, assuming perfect broadcasting of
the global model. In this paper, we instead consider broadcasting a compressed
version of the global model. This is to further reduce the communication cost
of FL, which can be particularly limited when the global model is to be
transmitted over a wireless medium. We introduce a lossy FL (LFL) algorithm, in
which both the global model and the local model updates are quantized before
being transmitted. We analyze the convergence behavior of the proposed LFL
algorithm assuming the availability of accurate local model updates at the
server. Numerical experiments show that the proposed LFL scheme, which
quantizes the global model update (with respect to the global model estimate at
the devices) rather than the global model itself, significantly outperforms
other existing schemes studying quantization of the global model at the
PS-to-device direction. Also, the performance loss of the proposed scheme is
marginal compared to the fully lossless approach, where the PS and the devices
transmit their messages entirely without any quantization.
</p>
<a href="http://arxiv.org/abs/2006.10672" target="_blank">arXiv:2006.10672</a> [<a href="http://arxiv.org/pdf/2006.10672" target="_blank">pdf</a>]

<h2>Provably Efficient Reinforcement Learning for Discounted MDPs with Feature Mapping. (arXiv:2006.13165v3 [cs.LG] UPDATED)</h2>
<h3>Dongruo Zhou, Jiafan He, Quanquan Gu</h3>
<p>Modern tasks in reinforcement learning have large state and action spaces. To
deal with them efficiently, one often uses predefined feature mapping to
represent states and actions in a low dimensional space. In this paper, we
study reinforcement learning for discounted Markov Decision Processes (MDPs),
where the transition kernel can be parameterized as a linear function of
certain feature mapping. We propose a novel algorithm which makes use of the
feature mapping and obtains a $\tilde O(d\sqrt{T}/(1-\gamma)^2)$ regret, where
$d$ is the dimension of the feature space, $T$ is the time horizon and $\gamma$
is the discount factor of the MDP. To the best of our knowledge, this is the
first polynomial regret bound without accessing to a generative model or making
strong assumptions such as ergodicity of the MDP. By constructing a special
class of MDPs, we also show that for any algorithms, the regret is lower
bounded by $\Omega(d\sqrt{T}/(1-\gamma)^{1.5})$. Our upper and lower bound
results together suggest that the proposed reinforcement learning algorithm is
near-optimal up to a $(1-\gamma)^{-0.5}$ factor.
</p>
<a href="http://arxiv.org/abs/2006.13165" target="_blank">arXiv:2006.13165</a> [<a href="http://arxiv.org/pdf/2006.13165" target="_blank">pdf</a>]

<h2>On Additive Approximate Submodularity. (arXiv:2010.02912v2 [cs.DS] UPDATED)</h2>
<h3>Flavio Chierichetti, Anirban Dasgupta, Ravi Kumar</h3>
<p>A real-valued set function is (additively) approximately submodular if it
satisfies the submodularity conditions with an additive error. Approximate
submodularity arises in many settings, especially in machine learning, where
the function evaluation might not be exact. In this paper we study how close
such approximately submodular functions are to truly submodular functions.

We show that an approximately submodular function defined on a ground set of
$n$ elements is $O(n^2)$ pointwise-close to a submodular function. This result
also provides an algorithmic tool that can be used to adapt existing submodular
optimization algorithms to approximately submodular functions. To complement,
we show an $\Omega(\sqrt{n})$ lower bound on the distance to submodularity.

These results stand in contrast to the case of approximate modularity, where
the distance to modularity is a constant, and approximate convexity, where the
distance to convexity is logarithmic.
</p>
<a href="http://arxiv.org/abs/2010.02912" target="_blank">arXiv:2010.02912</a> [<a href="http://arxiv.org/pdf/2010.02912" target="_blank">pdf</a>]

<h2>Attention augmented differentiable forest for tabular data. (arXiv:2010.02921v1 [cs.LG])</h2>
<h3>Yingshi Chen</h3>
<p>Differentiable forest is an ensemble of decision trees with full
differentiability. Its simple tree structure is easy to use and explain. With
full differentiability, it would be trained in the end-to-end learning
framework with gradient-based optimization method. In this paper, we propose
tree attention block(TAB) in the framework of differentiable forest. TAB block
has two operations, squeeze and regulate. The squeeze operation would extract
the characteristic of each tree. The regulate operation would learn nonlinear
relations between these trees. So TAB block would learn the importance of each
tree and adjust its weight to improve accuracy. Our experiment on large tabular
dataset shows attention augmented differentiable forest would get comparable
accuracy with gradient boosted decision trees(GBDT), which is the
state-of-the-art algorithm for tabular datasets. And on some datasets, our
model has higher accuracy than best GBDT libs (LightGBM, Catboost, and
XGBoost). Differentiable forest model supports batch training and batch size is
much smaller than the size of training set. So on larger data sets, its memory
usage is much lower than GBDT model. The source codes are available at
https://github.com/closest-git/QuantumForest.
</p>
<a href="http://arxiv.org/abs/2010.02921" target="_blank">arXiv:2010.02921</a> [<a href="http://arxiv.org/pdf/2010.02921" target="_blank">pdf</a>]

<h2>Human-Level Performance in No-Press Diplomacy via Equilibrium Search. (arXiv:2010.02923v1 [cs.AI])</h2>
<h3>Jonathan Gray, Adam Lerer, Anton Bakhtin, Noam Brown</h3>
<p>Prior AI breakthroughs in complex games have focused on either the purely
adversarial or purely cooperative settings. In contrast, Diplomacy is a game of
shifting alliances that involves both cooperation and competition. For this
reason, Diplomacy has proven to be a formidable research challenge. In this
paper we describe an agent for the no-press variant of Diplomacy that combines
supervised learning on human data with one-step lookahead search via external
regret minimization. External regret minimization techniques have been behind
previous AI successes in adversarial games, most notably poker, but have not
previously been shown to be successful in large-scale games involving
cooperation. We show that our agent greatly exceeds the performance of past
no-press Diplomacy bots, is unexploitable by expert humans, and achieves a rank
of 23 out of 1,128 human players when playing anonymous games on a popular
Diplomacy website.
</p>
<a href="http://arxiv.org/abs/2010.02923" target="_blank">arXiv:2010.02923</a> [<a href="http://arxiv.org/pdf/2010.02923" target="_blank">pdf</a>]

<h2>Learning effective physical laws for generating cosmological hydrodynamics with Lagrangian Deep Learning. (arXiv:2010.02926v1 [astro-ph.CO])</h2>
<h3>Biwei Dai, Uros Seljak</h3>
<p>The goal of generative models is to learn the intricate relations between the
data to create new simulated data, but current approaches fail in very high
dimensions. When the true data generating process is based on physical
processes these impose symmetries and constraints, and the generative model can
be created by learning an effective description of the underlying physics,
which enables scaling of the generative model to very high dimensions. In this
work we propose Lagrangian Deep Learning (LDL) for this purpose, applying it to
learn outputs of cosmological hydrodynamical simulations. The model uses layers
of Lagrangian displacements of particles describing the observables to learn
the effective physical laws. The displacements are modeled as the gradient of
an effective potential, which explicitly satisfies the translational and
rotational invariance. The total number of learned parameters is only of order
10, and they can be viewed as effective theory parameters. We combine N-body
solver FastPM with LDL and apply them to a wide range of cosmological outputs,
from the dark matter to the stellar maps, gas density and temperature. The
computational cost of LDL is nearly four orders of magnitude lower than the
full hydrodynamical simulations, yet it outperforms it at the same resolution.
We achieve this with only of order 10 layers from the initial conditions to the
final output, in contrast to typical cosmological simulations with thousands of
time steps. This opens up the possibility of analyzing cosmological
observations entirely within this framework, without the need for large
dark-matter simulations.
</p>
<a href="http://arxiv.org/abs/2010.02926" target="_blank">arXiv:2010.02926</a> [<a href="http://arxiv.org/pdf/2010.02926" target="_blank">pdf</a>]

<h2>Learning to Represent Image and Text with Denotation Graph. (arXiv:2010.02949v1 [cs.CV])</h2>
<h3>Bowen Zhang, Hexiang Hu, Vihan Jain, Eugene Ie, Fei Sha</h3>
<p>Learning to fuse vision and language information and representing them is an
important research problem with many applications. Recent progresses have
leveraged the ideas of pre-training (from language modeling) and attention
layers in Transformers to learn representation from datasets containing images
aligned with linguistic expressions that describe the images. In this paper, we
propose learning representations from a set of implied, visually grounded
expressions between image and text, automatically mined from those datasets. In
particular, we use denotation graphs to represent how specific concepts (such
as sentences describing images) can be linked to abstract and generic concepts
(such as short phrases) that are also visually grounded. This type of
generic-to-specific relations can be discovered using linguistic analysis
tools. We propose methods to incorporate such relations into learning
representation. We show that state-of-the-art multimodal learning models can be
further improved by leveraging automatically harvested structural relations.
The representations lead to stronger empirical results on downstream tasks of
cross-modal image retrieval, referring expression, and compositional
attribute-object recognition. Both our codes and the extracted denotation
graphs on the Flickr30K and the COCO datasets are publically available on
https://sha-lab.github.io/DG.
</p>
<a href="http://arxiv.org/abs/2010.02949" target="_blank">arXiv:2010.02949</a> [<a href="http://arxiv.org/pdf/2010.02949" target="_blank">pdf</a>]

<h2>Using Sentences as Semantic Representations in Large Scale Zero-Shot Learning. (arXiv:2010.02959v1 [cs.CV])</h2>
<h3>Yannick Le Cacheux, Herv&#xe9; Le Borgne, Michel Crucianu</h3>
<p>Zero-shot learning aims to recognize instances of unseen classes, for which
no visual instance is available during training, by learning multimodal
relations between samples from seen classes and corresponding class semantic
representations. These class representations usually consist of either
attributes, which do not scale well to large datasets, or word embeddings,
which lead to poorer performance. A good trade-off could be to employ short
sentences in natural language as class descriptions. We explore different
solutions to use such short descriptions in a ZSL setting and show that while
simple methods cannot achieve very good results with sentences alone, a
combination of usual word embeddings and sentences can significantly outperform
current state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2010.02959" target="_blank">arXiv:2010.02959</a> [<a href="http://arxiv.org/pdf/2010.02959" target="_blank">pdf</a>]

<h2>Reinforcement Learning with Random Delays. (arXiv:2010.02966v1 [cs.LG])</h2>
<h3>Simon Ramstedt, Yann Bouteiller, Giovanni Beltrame, Christopher Pal, Jonathan Binas</h3>
<p>Action and observation delays commonly occur in many Reinforcement Learning
applications, such as remote control scenarios. We study the anatomy of
randomly delayed environments, and show that partially resampling trajectory
fragments in hindsight allows for off-policy multi-step value estimation. We
apply this principle to derive Delay-Correcting Actor-Critic (DCAC), an
algorithm based on Soft Actor-Critic with significantly better performance in
environments with delays. This is shown theoretically and also demonstrated
practically on a delay-augmented version of the MuJoCo continuous control
benchmark.
</p>
<a href="http://arxiv.org/abs/2010.02966" target="_blank">arXiv:2010.02966</a> [<a href="http://arxiv.org/pdf/2010.02966" target="_blank">pdf</a>]

<h2>UneVEn: Universal Value Exploration for Multi-Agent Reinforcement Learning. (arXiv:2010.02974v1 [cs.LG])</h2>
<h3>Tarun Gupta, Anuj Mahajan, Bei Peng, Wendelin B&#xf6;hmer, Shimon Whiteson</h3>
<p>This paper focuses on cooperative value-based multi-agent reinforcement
learning (MARL) in the paradigm of centralized training with decentralized
execution (CTDE). Current state-of-the-art value-based MARL methods leverage
CTDE to learn a centralized joint-action value function as a monotonic mixing
of each agent's utility function, which enables easy decentralization. However,
this monotonic restriction leads to inefficient exploration in tasks with
nonmonotonic returns due to suboptimal approximations of the values of joint
actions. To address this, we present a novel MARL approach called Universal
Value Exploration (UneVEn), which uses universal successor features (USFs) to
learn policies of tasks related to the target task, but with simpler reward
functions in a sample efficient manner. UneVEn uses novel action-selection
schemes between randomly sampled related tasks during exploration, which
enables the monotonic joint-action value function of the target task to place
more importance on useful joint actions. Empirical results on a challenging
cooperative predator-prey task requiring significant coordination amongst
agents show that UneVEn significantly outperforms state-of-the-art baselines.
</p>
<a href="http://arxiv.org/abs/2010.02974" target="_blank">arXiv:2010.02974</a> [<a href="http://arxiv.org/pdf/2010.02974" target="_blank">pdf</a>]

<h2>Supervised Seeded Iterated Learning for Interactive Language Learning. (arXiv:2010.02975v1 [cs.CL])</h2>
<h3>Yuchen Lu, Soumye Singhal, Florian Strub, Olivier Pietquin, Aaron Courville</h3>
<p>Language drift has been one of the major obstacles to train language models
through interaction. When word-based conversational agents are trained towards
completing a task, they tend to invent their language rather than leveraging
natural language. In recent literature, two general methods partially counter
this phenomenon: Supervised Selfplay (S2P) and Seeded Iterated Learning (SIL).
While S2P jointly trains interactive and supervised losses to counter the
drift, SIL changes the training dynamics to prevent language drift from
occurring. In this paper, we first highlight their respective weaknesses, i.e.,
late-stage training collapses and higher negative likelihood when evaluated on
human corpus. Given these observations, we introduce Supervised Seeded Iterated
Learning to combine both methods to minimize their respective weaknesses. We
then show the effectiveness of \algo in the language-drift translation game.
</p>
<a href="http://arxiv.org/abs/2010.02975" target="_blank">arXiv:2010.02975</a> [<a href="http://arxiv.org/pdf/2010.02975" target="_blank">pdf</a>]

<h2>Plug and Play Autoencoders for Conditional Text Generation. (arXiv:2010.02983v1 [cs.CL])</h2>
<h3>Florian Mai (1 and 2), Nikolaos Pappas (3), Ivan Montero (3), Noah A. Smith (3 and 4), James Henderson (1) ((1) Idiap Research Institute, (2) EPFL, (3) University of Washington, (4) Allen Institute for Artificial Intelligence)</h3>
<p>Text autoencoders are commonly used for conditional generation tasks such as
style transfer. We propose methods which are plug and play, where any
pretrained autoencoder can be used, and only require learning a mapping within
the autoencoder's embedding space, training embedding-to-embedding (Emb2Emb).
This reduces the need for labeled training data for the task and makes the
training procedure more efficient. Crucial to the success of this method is a
loss term for keeping the mapped embedding on the manifold of the autoencoder
and a mapping which is trained to navigate the manifold by learning offset
vectors. Evaluations on style transfer tasks both with and without
sequence-to-sequence supervision show that our method performs better than or
comparable to strong baselines while being up to four times faster.
</p>
<a href="http://arxiv.org/abs/2010.02983" target="_blank">arXiv:2010.02983</a> [<a href="http://arxiv.org/pdf/2010.02983" target="_blank">pdf</a>]

<h2>Optimizing Deep Neural Networks via Discretization of Finite-Time Convergent Flows. (arXiv:2010.02990v1 [cs.LG])</h2>
<h3>Mouhacine Benosman, Orlando Romero, Anoop Cherian</h3>
<p>In this paper, we investigate in the context of deep neural networks, the
performance of several discretization algorithms for two first-order
finite-time optimization flows. These flows are, namely, the rescaled-gradient
flow (RGF) and the signed-gradient flow (SGF), and consist of non-Lipscthiz or
discontinuous dynamical systems that converge locally in finite time to the
minima of gradient-dominated functions. We introduce three discretization
methods for these first-order finite-time flows, and provide convergence
guarantees. We then apply the proposed algorithms in training neural networks
and empirically test their performances on three standard datasets, namely,
CIFAR10, SVHN, and MNIST. Our results show that our schemes demonstrate faster
convergences against standard optimization alternatives, while achieving
equivalent or better accuracy.
</p>
<a href="http://arxiv.org/abs/2010.02990" target="_blank">arXiv:2010.02990</a> [<a href="http://arxiv.org/pdf/2010.02990" target="_blank">pdf</a>]

<h2>Fact Extraction and VERification -- The FEVER case: An Overview. (arXiv:2010.03001v1 [cs.CL])</h2>
<h3>Giannis Bekoulis, Christina Papagiannopoulou, Nikos Deligiannis</h3>
<p>Fact Extraction and VERification (FEVER) is a recently introduced task which
aims to identify the veracity of a given claim based on Wikipedia documents. A
lot of methods have been proposed to address this problem which consists of the
subtasks of (i) retrieving the relevant documents (and sentences) from
Wikipedia and (ii) validating whether the information in the documents supports
or refutes a given claim. This task is essential since it can be the building
block of applications that require a deep understanding of the language such as
fake news detection and medical claim verification. In this paper, we aim to
get a better understanding of the challenges in the task by presenting the
literature in a structured and comprehensive way. In addition, we describe the
proposed methods by analyzing the technical perspectives of the different
approaches and discussing the performance results on the FEVER dataset.
</p>
<a href="http://arxiv.org/abs/2010.03001" target="_blank">arXiv:2010.03001</a> [<a href="http://arxiv.org/pdf/2010.03001" target="_blank">pdf</a>]

<h2>Motion Prediction Using Temporal Inception Module. (arXiv:2010.03006v1 [cs.CV])</h2>
<h3>Tim Lebailly, Sena Kiciroglu, Mathieu Salzmann, Pascal Fua, Wei Wang</h3>
<p>Human motion prediction is a necessary component for many applications in
robotics and autonomous driving. Recent methods propose using
sequence-to-sequence deep learning models to tackle this problem. However, they
do not focus on exploiting different temporal scales for different length
inputs. We argue that the diverse temporal scales are important as they allow
us to look at the past frames with different receptive fields, which can lead
to better predictions. In this paper, we propose a Temporal Inception Module
(TIM) to encode human motion. Making use of TIM, our framework produces input
embeddings using convolutional layers, by using different kernel sizes for
different input lengths. The experimental results on standard motion prediction
benchmark datasets Human3.6M and CMU motion capture dataset show that our
approach consistently outperforms the state of the art methods.
</p>
<a href="http://arxiv.org/abs/2010.03006" target="_blank">arXiv:2010.03006</a> [<a href="http://arxiv.org/pdf/2010.03006" target="_blank">pdf</a>]

<h2>BAAAN: Backdoor Attacks Against Autoencoder and GAN-Based Machine Learning Models. (arXiv:2010.03007v1 [cs.CR])</h2>
<h3>Ahmed Salem, Yannick Sautter, Michael Backes, Mathias Humbert, Yang Zhang</h3>
<p>The tremendous progress of autoencoders and generative adversarial networks
(GANs) has led to their application to multiple critical tasks, such as fraud
detection and sanitized data generation. This increasing adoption has fostered
the study of security and privacy risks stemming from these models. However,
previous works have mainly focused on membership inference attacks. In this
work, we explore one of the most severe attacks against machine learning
models, namely the backdoor attack, against both autoencoders and GANs. The
backdoor attack is a training time attack where the adversary implements a
hidden backdoor in the target model that can only be activated by a secret
trigger. State-of-the-art backdoor attacks focus on classification-based tasks.
We extend the applicability of backdoor attacks to autoencoders and GAN-based
models. More concretely, we propose the first backdoor attack against
autoencoders and GANs where the adversary can control what the decoded or
generated images are when the backdoor is activated. Our results show that the
adversary can build a backdoored autoencoder that returns a target output for
all backdoored inputs, while behaving perfectly normal on clean inputs.
Similarly, for the GANs, our experiments show that the adversary can generate
data from a different distribution when the backdoor is activated, while
maintaining the same utility when the backdoor is not.
</p>
<a href="http://arxiv.org/abs/2010.03007" target="_blank">arXiv:2010.03007</a> [<a href="http://arxiv.org/pdf/2010.03007" target="_blank">pdf</a>]

<h2>Towards a Scalable and Distributed Infrastructure for Deep Learning Applications. (arXiv:2010.03012v1 [cs.DC])</h2>
<h3>Bita Hasheminezhad, Shahrzad Shirzad, Nanmiao Wu, Patrick Diehl, Hannes Schulz, Hartmut Kaiser</h3>
<p>Although recent scaling up approaches to train deep neural networks have
proven to be effective, the computational intensity of large and complex
models, as well as the availability of large-scale datasets require deep
learning frameworks to utilize scaling out techniques. Parallelization
approaches and distribution requirements are not considered in the primary
designs of most available distributed deep learning frameworks and most of them
still are not able to perform effective and efficient fine-grained inter-node
communication. We present Phylanx that has the potential to alleviate these
shortcomings. Phylanx presents a productivity-oriented frontend where user
Python code is translated to a futurized execution tree that can be executed
efficiently on multiple nodes using the C++ standard library for parallelism
and concurrency (HPX), leveraging fine-grained threading and an active
messaging task-based runtime system.
</p>
<a href="http://arxiv.org/abs/2010.03012" target="_blank">arXiv:2010.03012</a> [<a href="http://arxiv.org/pdf/2010.03012" target="_blank">pdf</a>]

<h2>On Negative Interference in Multilingual Models: Findings and A Meta-Learning Treatment. (arXiv:2010.03017v1 [cs.CL])</h2>
<h3>Zirui Wang, Zachary C. Lipton, Yulia Tsvetkov</h3>
<p>Modern multilingual models are trained on concatenated text from multiple
languages in hopes of conferring benefits to each (positive transfer), with the
most pronounced benefits accruing to low-resource languages. However, recent
work has shown that this approach can degrade performance on high-resource
languages, a phenomenon known as negative interference. In this paper, we
present the first systematic study of negative interference. We show that,
contrary to previous belief, negative interference also impacts low-resource
languages. While parameters are maximally shared to learn language-universal
structures, we demonstrate that language-specific parameters do exist in
multilingual models and they are a potential cause of negative interference.
Motivated by these observations, we also present a meta-learning algorithm that
obtains better cross-lingual transferability and alleviates negative
interference, by adding language-specific layers as meta-parameters and
training them in a manner that explicitly improves shared layers'
generalization on all languages. Overall, our results show that negative
interference is more common than previously known, suggesting new directions
for improving multilingual representations.
</p>
<a href="http://arxiv.org/abs/2010.03017" target="_blank">arXiv:2010.03017</a> [<a href="http://arxiv.org/pdf/2010.03017" target="_blank">pdf</a>]

<h2>Global Self-Attention Networks for Image Recognition. (arXiv:2010.03019v1 [cs.CV])</h2>
<h3>Zhuoran Shen, Irwan Bello, Raviteja Vemulapalli, Xuhui Jia, Ching-Hui Chen</h3>
<p>Recently, a series of works in computer vision have shown promising results
on various image and video understanding tasks using self-attention. However,
due to the quadratic computational and memory complexities of self-attention,
these works either apply attention only to low-resolution feature maps in later
stages of a deep network or restrict the receptive field of attention in each
layer to a small local region. To overcome these limitations, this work
introduces a new global self-attention module, referred to as the GSA module,
which is efficient enough to serve as the backbone component of a deep network.
This module consists of two parallel layers: a content attention layer that
attends to pixels based only on their content and a positional attention layer
that attends to pixels based on their spatial locations. The output of this
module is the sum of the outputs of the two layers. Based on the proposed GSA
module, we introduce new standalone global attention-based deep networks that
use GSA modules instead of convolutions to model pixel interactions. Due to the
global extent of the proposed GSA module, a GSA network has the ability to
model long-range pixel interactions throughout the network. Our experimental
results show that GSA networks outperform the corresponding convolution-based
networks significantly on the CIFAR-100 and ImageNet datasets while using less
parameters and computations. The proposed GSA networks also outperform various
existing attention-based networks on the ImageNet dataset.
</p>
<a href="http://arxiv.org/abs/2010.03019" target="_blank">arXiv:2010.03019</a> [<a href="http://arxiv.org/pdf/2010.03019" target="_blank">pdf</a>]

<h2>Real-Time Resource Allocation for Tracking Systems. (arXiv:2010.03024v1 [cs.CV])</h2>
<h3>Yash Satsangi, Shimon Whiteson, Frans A. Oliehoek, Henri Bouma</h3>
<p>Automated tracking is key to many computer vision applications. However, many
tracking systems struggle to perform in real-time due to the high computational
cost of detecting people, especially in ultra high resolution images. We
propose a new algorithm called \emph{PartiMax} that greatly reduces this cost
by applying the person detector only to the relevant parts of the image.
PartiMax exploits information in the particle filter to select $k$ of the $n$
candidate \emph{pixel boxes} in the image. We prove that PartiMax is guaranteed
to make a near-optimal selection with error bounds that are independent of the
problem size. Furthermore, empirical results on a real-life dataset show that
our system runs in real-time by processing only 10\% of the pixel boxes in the
image while still retaining 80\% of the original tracking performance achieved
when processing all pixel boxes.
</p>
<a href="http://arxiv.org/abs/2010.03024" target="_blank">arXiv:2010.03024</a> [<a href="http://arxiv.org/pdf/2010.03024" target="_blank">pdf</a>]

<h2>Predicting Hourly Demand in Station-free Bike-sharing Systems with Video-level Data. (arXiv:2010.03027v1 [cs.CV])</h2>
<h3>Xiao Yan, Gang Kou, Feng Xiao, Dapeng Zhang, Xianghua Gan</h3>
<p>Temporal and spatial features are both important for predicting the demands
in the bike-sharing systems. Many relevant experiments in the literature
support this. Meanwhile, it is observed that the data structure of spatial
features with vector form is weaker in space than the videos, which have
natural spatial structure. Therefore, to obtain more spatial features, this
study introduces city map to generate GPS demand videos while employing a novel
algorithm : eidetic 3D convolutional long short-term memory network named
E3D-LSTM to process the video-level data in bike-sharing system. The
spatio-temporal correlations and feature importance are experimented and
visualized to validate the significance of spatial and temporal features.
Despite the deep learning model is powerful in non-linear fitting ability,
statistic model has better interpretation. This study adopts ensemble learning,
which is a popular policy, to improve the performance and decrease variance. In
this paper, we propose a novel model stacked by deep learning and statistical
models, named the fusion multi-channel eidetic 3D convolutional long short-term
memory network(FM-E3DCL-Net), to better process temporal and spatial features
on the dataset about 100,000 transactions within one month in Shanghai of
Mobike company. Furthermore, other factors like weather, holiday and time
intervals are proved useful in addition to historical demand, since they
decrease the root mean squared error (RMSE) by 29.4%. On this basis, the
ensemble learning further decreases RMSE by 6.6%.
</p>
<a href="http://arxiv.org/abs/2010.03027" target="_blank">arXiv:2010.03027</a> [<a href="http://arxiv.org/pdf/2010.03027" target="_blank">pdf</a>]

<h2>A deep learning pipeline for identification of motor units in musculoskeletal ultrasound. (arXiv:2010.03028v1 [cs.CV])</h2>
<h3>Hazrat Ali, Johannes Umander, Robin Rohl&#xe9;n, Christer Gr&#xf6;nlund</h3>
<p>Ultrasound imaging provides information from a large part of the muscle. It
has recently been shown that ultrafast ultrasound imaging can be used to record
and analyze the mechanical response of individual MUs using blind source
separation. In this work, we present an alternative method - a deep learning
pipeline - to identify active MUs in ultrasound image sequences, including
segmentation of their territories and signal estimation of their mechanical
responses (twitch train). We train and evaluate the model using simulated data
mimicking the complex activation pattern of tens of activated MUs with
overlapping territories and partially synchronized activation patterns. Using a
slow fusion approach (based on 3D CNNs), we transform the spatiotemporal image
sequence data to 2D representations and apply a deep neural network
architecture for segmentation. Next, we employ a second deep neural network
architecture for signal estimation. The results show that the proposed pipeline
can effectively identify individual MUs, estimate their territories, and
estimate their twitch train signal at low contraction forces. The framework can
retain spatio-temporal consistencies and information of the mechanical response
of MU activity even when the ultrasound image sequences are transformed into a
2D representation for compatibility with more traditional computer vision and
image processing techniques. The proposed pipeline is potentially useful to
identify simultaneously active MUs in whole muscles in ultrasound image
sequences of voluntary skeletal muscle contractions at low force levels.
</p>
<a href="http://arxiv.org/abs/2010.03028" target="_blank">arXiv:2010.03028</a> [<a href="http://arxiv.org/pdf/2010.03028" target="_blank">pdf</a>]

<h2>Using Bayesian deep learning approaches for uncertainty-aware building energy surrogate models. (arXiv:2010.03029v1 [stat.ML])</h2>
<h3>Paul Westermann, Ralph Evins</h3>
<p>Fast machine learning-based surrogate models are trained to emulate slow,
high-fidelity engineering simulation models to accelerate engineering design
tasks. This introduces uncertainty as the surrogate is only an approximation of
the original model.

Bayesian methods can quantify that uncertainty, and deep learning models
exist that follow the Bayesian paradigm. These models, namely Bayesian neural
networks and Gaussian process models, enable us to give predictions together
with an estimate of the model's uncertainty. As a result we can derive
uncertainty-aware surrogate models that can automatically suspect unseen design
samples that cause large emulation errors. For these samples, the high-fidelity
model can be queried instead. This outlines how the Bayesian paradigm allows us
to hybridize fast, but approximate, and slow, but accurate models.

In this paper, we train two types of Bayesian models, dropout neural networks
and stochastic variational Gaussian Process models, to emulate a complex high
dimensional building energy performance simulation problem. The surrogate model
processes 35 building design parameters (inputs) to estimate 12 different
performance metrics (outputs). We benchmark both approaches, prove their
accuracy to be competitive, and show that errors can be reduced by up to 30%
when the 10% of samples with the highest uncertainty are transferred to the
high-fidelity model.
</p>
<a href="http://arxiv.org/abs/2010.03029" target="_blank">arXiv:2010.03029</a> [<a href="http://arxiv.org/pdf/2010.03029" target="_blank">pdf</a>]

<h2>A machine learning framework for LES closure terms. (arXiv:2010.03030v1 [physics.comp-ph])</h2>
<h3>Marius Kurz, Andrea Beck</h3>
<p>In the present work, we explore the capability of artificial neural networks
(ANN) to predict the closure terms for large eddy simulations (LES) solely from
coarse-scale data. To this end, we derive a consistent framework for LES
closure models, with special emphasis laid upon the incorporation of implicit
discretization-based filters and numerical approximation errors. We investigate
implicit filter types, which are inspired by the solution representation of
discontinuous Galerkin and finite volume schemes and mimic the behaviour of the
discretization operator, and a global Fourier cutoff filter as a representative
of a typical explicit LES filter. Within the perfect LES framework, we compute
the exact closure terms for the different LES filter functions from direct
numerical simulation results of decaying homogeneous isotropic turbulence.
Multiple ANN with a multilayer perceptron (MLP) or a gated recurrent unit (GRU)
architecture are trained to predict the computed closure terms solely from
coarse-scale input data. For the given application, the GRU architecture
clearly outperforms the MLP networks in terms of accuracy, whilst reaching up
to 99.9% cross-correlation between the networks' predictions and the exact
closure terms for all considered filter functions. The GRU networks are also
shown to generalize well across different LES filters and resolutions. The
present study can thus be seen as a starting point for the investigation of
data-based modeling approaches for LES, which not only include the physical
closure terms, but account for the discretization effects in implicitly
filtered LES as well.
</p>
<a href="http://arxiv.org/abs/2010.03030" target="_blank">arXiv:2010.03030</a> [<a href="http://arxiv.org/pdf/2010.03030" target="_blank">pdf</a>]

<h2>Why Skip If You Can Combine: A Simple Knowledge Distillation Technique for Intermediate Layers. (arXiv:2010.03034v1 [cs.CL])</h2>
<h3>Yimeng Wu, Peyman Passban, Mehdi Rezagholizade, Qun Liu</h3>
<p>With the growth of computing power neural machine translation (NMT) models
also grow accordingly and become better. However, they also become harder to
deploy on edge devices due to memory constraints. To cope with this problem, a
common practice is to distill knowledge from a large and accurately-trained
teacher network (T) into a compact student network (S). Although knowledge
distillation (KD) is useful in most cases, our study shows that existing KD
techniques might not be suitable enough for deep NMT engines, so we propose a
novel alternative. In our model, besides matching T and S predictions we have a
combinatorial mechanism to inject layer-level supervision from T to S. In this
paper, we target low-resource settings and evaluate our translation engines for
Portuguese--English, Turkish--English, and English--German directions. Students
trained using our technique have 50% fewer parameters and can still deliver
comparable results to those of 12-layer teachers.
</p>
<a href="http://arxiv.org/abs/2010.03034" target="_blank">arXiv:2010.03034</a> [<a href="http://arxiv.org/pdf/2010.03034" target="_blank">pdf</a>]

<h2>Move Fast and Meet Deadlines: Fine-grained Real-time Stream Processing with Cameo. (arXiv:2010.03035v1 [cs.DC])</h2>
<h3>Le Xu, Shivaram Venkataraman, Indranil Gupta, Luo Mai, Rahul Potharaju</h3>
<p>Resource provisioning in multi-tenant stream processing systems faces the
dual challenges of keeping resource utilization high (without
over-provisioning), and ensuring performance isolation. In our common
production use cases, where streaming workloads have to meet latency targets
and avoid breaching service-level agreements, existing solutions are incapable
of handling the wide variability of user needs. Our framework called Cameo uses
fine-grained stream processing (inspired by actor computation models), and is
able to provide high resource utilization while meeting latency targets. Cameo
dynamically calculates and propagates priorities of events based on user
latency targets and query semantics. Experiments on Microsoft Azure show that
compared to state-of-the-art, the Cameo framework: i) reduces query latency by
2.7X in single tenant settings, ii) reduces query latency by 4.6X in
multi-tenant scenarios, and iii) weathers transient spikes of workload.
</p>
<a href="http://arxiv.org/abs/2010.03035" target="_blank">arXiv:2010.03035</a> [<a href="http://arxiv.org/pdf/2010.03035" target="_blank">pdf</a>]

<h2>Empirical Frequentist Coverage of Deep Learning Uncertainty Quantification Procedures. (arXiv:2010.03039v1 [cs.LG])</h2>
<h3>Benjamin Kompa, Jasper Snoek, Andrew Beam</h3>
<p>Uncertainty quantification for complex deep learning models is increasingly
important as these techniques see growing use in high-stakes, real-world
settings. Currently, the quality of a model's uncertainty is evaluated using
point-prediction metrics such as negative log-likelihood or the Brier score on
heldout data. In this study, we provide the first large scale evaluation of the
empirical frequentist coverage properties of well known uncertainty
quantification techniques on a suite of regression and classification tasks. We
find that, in general, some methods do achieve desirable coverage properties on
in distribution samples, but that coverage is not maintained on
out-of-distribution data. Our results demonstrate the failings of current
uncertainty quantification techniques as dataset shift increases and establish
coverage as an important metric in developing models for real-world
applications.
</p>
<a href="http://arxiv.org/abs/2010.03039" target="_blank">arXiv:2010.03039</a> [<a href="http://arxiv.org/pdf/2010.03039" target="_blank">pdf</a>]

<h2>Rotate to Attend: Convolutional Triplet Attention Module. (arXiv:2010.03045v1 [cs.CV])</h2>
<h3>Diganta Misra, Trikay Nalamada, Ajay Uppili Arasanipalai, Qibin Hou</h3>
<p>Benefiting from the capability of building inter-dependencies among channels
or spatial locations, attention mechanisms have been extensively studied and
broadly used in a variety of computer vision tasks recently. In this paper, we
investigate light-weight but effective attention mechanisms and present triplet
attention, a novel method for computing attention weights by capturing
cross-dimension interaction using a three-branch structure. For an input
tensor, triplet attention builds inter-dimensional dependencies by the rotation
operation followed by residual transformations and encodes inter-channel and
spatial information with negligible computational overhead. Our method is
simple as well as efficient and can be easily plugged into classic backbone
networks as an add-on module. We demonstrate the effectiveness of our method on
various challenging tasks including image classification on ImageNet-1k and
object detection on MSCOCO and PASCAL VOC datasets. Furthermore, we provide
extensive in-sight into the performance of triplet attention by visually
inspecting the GradCAM and GradCAM++ results. The empirical evaluation of our
method supports our intuition on the importance of capturing dependencies
across dimensions when computing attention weights. Code for this paper can be
publicly accessed at https://github.com/LandskapeAI/triplet-attention
</p>
<a href="http://arxiv.org/abs/2010.03045" target="_blank">arXiv:2010.03045</a> [<a href="http://arxiv.org/pdf/2010.03045" target="_blank">pdf</a>]

<h2>Sequential Changepoint Detection in Neural Networks with Checkpoints. (arXiv:2010.03053v1 [cs.LG])</h2>
<h3>Michalis K. Titsias, Jakub Sygnowski, Yutian Chen</h3>
<p>We introduce a framework for online changepoint detection and simultaneous
model learning which is applicable to highly parametrized models, such as deep
neural networks. It is based on detecting changepoints across time by
sequentially performing generalized likelihood ratio tests that require only
evaluations of simple prediction score functions. This procedure makes use of
checkpoints, consisting of early versions of the actual model parameters, that
allow to detect distributional changes by performing predictions on future
data. We define an algorithm that bounds the Type I error in the sequential
testing procedure. We demonstrate the efficiency of our method in challenging
continual learning applications with unknown task changepoints, and show
improved performance compared to online Bayesian changepoint detection.
</p>
<a href="http://arxiv.org/abs/2010.03053" target="_blank">arXiv:2010.03053</a> [<a href="http://arxiv.org/pdf/2010.03053" target="_blank">pdf</a>]

<h2>Characterising Bias in Compressed Models. (arXiv:2010.03058v1 [cs.LG])</h2>
<h3>Sara Hooker, Nyalleng Moorosi, Gregory Clark, Samy Bengio, Emily Denton</h3>
<p>The popularity and widespread use of pruning and quantization is driven by
the severe resource constraints of deploying deep neural networks to
environments with strict latency, memory and energy requirements. These
techniques achieve high levels of compression with negligible impact on
top-line metrics (top-1 and top-5 accuracy). However, overall accuracy hides
disproportionately high errors on a small subset of examples; we call this
subset Compression Identified Exemplars (CIE). We further establish that for
CIE examples, compression amplifies existing algorithmic bias. Pruning
disproportionately impacts performance on underrepresented features, which
often coincides with considerations of fairness. Given that CIE is a relatively
small subset but a great contributor of error in the model, we propose its use
as a human-in-the-loop auditing tool to surface a tractable subset of the
dataset for further inspection or annotation by a domain expert. We provide
qualitative and quantitative support that CIE surfaces the most challenging
examples in the data distribution for human-in-the-loop auditing.
</p>
<a href="http://arxiv.org/abs/2010.03058" target="_blank">arXiv:2010.03058</a> [<a href="http://arxiv.org/pdf/2010.03058" target="_blank">pdf</a>]

<h2>Weakly-Supervised Feature Learning via Text and Image Matching. (arXiv:2010.03060v1 [cs.CV])</h2>
<h3>Gongbo Liang, Connor Greenwell, Yu Zhang, Xiaoqin Wang, Ramakanth Kavuluru, Nathan Jacobs</h3>
<p>When training deep neural networks for medical image classification,
obtaining a sufficient number of manually annotated images is often a
significant challenge. We propose to use textual findings, which are routinely
written by clinicians during manual image analysis, to help overcome this
problem. The key idea is to use a contrastive loss to train image and text
feature extractors to recognize if a given image-finding pair is a true match.
The learned image feature extractor is then fine-tuned, in a transfer learning
setting, for a supervised classification task. This approach makes it possible
to train using large datasets because pairs of images and textual findings are
widely available in medical records. We evaluate our method on three datasets
and find consistent performance improvements. The biggest gains are realized
when fewer manually labeled examples are available. In some cases, our method
achieves the same performance as the baseline even when using 70\%--98\% fewer
labeled examples.
</p>
<a href="http://arxiv.org/abs/2010.03060" target="_blank">arXiv:2010.03060</a> [<a href="http://arxiv.org/pdf/2010.03060" target="_blank">pdf</a>]

<h2>Anubhuti -- An annotated dataset for emotional analysis of Bengali short stories. (arXiv:2010.03065v1 [cs.CL])</h2>
<h3>Aditya Pal, Bhaskar Karn</h3>
<p>Thousands of short stories and articles are being written in many different
languages all around the world today. Bengali, or Bangla, is the second highest
spoken language in India after Hindi and is the national language of the
country of Bangladesh. This work reports in detail the creation of Anubhuti --
the first and largest text corpus for analyzing emotions expressed by writers
of Bengali short stories. We explain the data collection methods, the manual
annotation process and the resulting high inter-annotator agreement of the
dataset due to the linguistic expertise of the annotators and the clear
methodology of labelling followed. We also address some of the challenges faced
in the collection of raw data and annotation process of a low resource language
like Bengali. We have verified the performance of our dataset with baseline
Machine Learning as well as a Deep Learning model for emotion classification
and have found that these standard models have a high accuracy and relevant
feature selection on Anubhuti. In addition, we also explain how this dataset
can be of interest to linguists and data analysts to study the flow of emotions
as expressed by writers of Bengali literature.
</p>
<a href="http://arxiv.org/abs/2010.03065" target="_blank">arXiv:2010.03065</a> [<a href="http://arxiv.org/pdf/2010.03065" target="_blank">pdf</a>]

<h2>Domain Adaptive Transfer Learning on Visual Attention Aware Data Augmentation for Fine-grained Visual Categorization. (arXiv:2010.03071v1 [cs.CV])</h2>
<h3>Ashiq Imran, Vassilis Athitsos</h3>
<p>Fine-Grained Visual Categorization (FGVC) is a challenging topic in computer
vision. It is a problem characterized by large intra-class differences and
subtle inter-class differences. In this paper, we tackle this problem in a
weakly supervised manner, where neural network models are getting fed with
additional data using a data augmentation technique through a visual attention
mechanism. We perform domain adaptive knowledge transfer via fine-tuning on our
base network model. We perform our experiment on six challenging and commonly
used FGVC datasets, and we show competitive improvement on accuracies by using
attention-aware data augmentation techniques with features derived from deep
learning model InceptionV3, pre-trained on large scale datasets. Our method
outperforms competitor methods on multiple FGVC datasets and showed competitive
results on other datasets. Experimental studies show that transfer learning
from large scale datasets can be utilized effectively with visual attention
based data augmentation, which can obtain state-of-the-art results on several
FGVC datasets. We present a comprehensive analysis of our experiments. Our
method achieves state-of-the-art results in multiple fine-grained
classification datasets including challenging CUB200-2011 bird, Flowers-102,
and FGVC-Aircrafts datasets.
</p>
<a href="http://arxiv.org/abs/2010.03071" target="_blank">arXiv:2010.03071</a> [<a href="http://arxiv.org/pdf/2010.03071" target="_blank">pdf</a>]

<h2>Adversarial Patch Attacks on Monocular Depth Estimation Networks. (arXiv:2010.03072v1 [cs.CV])</h2>
<h3>Koichiro Yamanaka, Ryutaroh Matsumoto, Keita Takahashi, Toshiaki Fujii</h3>
<p>Thanks to the excellent learning capability of deep convolutional neural
networks (CNN), monocular depth estimation using CNNs has achieved great
success in recent years. However, depth estimation from a monocular image alone
is essentially an ill-posed problem, and thus, it seems that this approach
would have inherent vulnerabilities. To reveal this limitation, we propose a
method of adversarial patch attack on monocular depth estimation. More
specifically, we generate artificial patterns (adversarial patches) that can
fool the target methods into estimating an incorrect depth for the regions
where the patterns are placed. Our method can be implemented in the real world
by physically placing the printed patterns in real scenes. We also analyze the
behavior of monocular depth estimation under attacks by visualizing the
activation levels of the intermediate layers and the regions potentially
affected by the adversarial attack.
</p>
<a href="http://arxiv.org/abs/2010.03072" target="_blank">arXiv:2010.03072</a> [<a href="http://arxiv.org/pdf/2010.03072" target="_blank">pdf</a>]

<h2>Beyond [CLS] through Ranking by Generation. (arXiv:2010.03073v1 [cs.CL])</h2>
<h3>Cicero Nogueira dos Santos, Xiaofei Ma, Ramesh Nallapati, Zhiheng Huang, Bing Xiang</h3>
<p>Generative models for Information Retrieval, where ranking of documents is
viewed as the task of generating a query from a document's language model, were
very successful in various IR tasks in the past. However, with the advent of
modern deep neural networks, attention has shifted to discriminative ranking
functions that model the semantic similarity of documents and queries instead.
Recently, deep generative models such as GPT2 and BART have been shown to be
excellent text generators, but their effectiveness as rankers have not been
demonstrated yet. In this work, we revisit the generative framework for
information retrieval and show that our generative approaches are as effective
as state-of-the-art semantic similarity-based discriminative models for the
answer selection task. Additionally, we demonstrate the effectiveness of
unlikelihood losses for IR.
</p>
<a href="http://arxiv.org/abs/2010.03073" target="_blank">arXiv:2010.03073</a> [<a href="http://arxiv.org/pdf/2010.03073" target="_blank">pdf</a>]

<h2>On Simplifying Dependent Polyhedral Reductions. (arXiv:2010.03074v1 [cs.PL])</h2>
<h3>Sanjay Rajopadhye</h3>
<p>\emph{Reductions} combine collections of input values with an associative
(and usually also commutative) operator to produce either a single, or a
collection of outputs. They are ubiquitous in computing, especially with big
data and deep learning. When the \emph{same} input value contributes to
multiple output values, there is a tremendous opportunity for reducing (pun
intended) the computational effort. This is called \emph{simplification}.
\emph{Polyhedral reductions} are reductions where the input and output data
collections are (dense) multidimensional arrays (i.e., \emph{tensors}),
accessed with linear/affine functions of the indices. % \emph{generalized
tensor contractions} Gautam and Rajopadhye \cite{sanjay-popl06} showed how
polyhedral reductions could be simplified automatically (through compile time
analysis) and optimally (the resulting program had minimum asymptotic
complexity). Yang, Atkinson and Carbin \cite{yang2020simplifying} extended this
to the case when (some) input values depend on (some) outputs. Specifically,
they showed how the optimal simplification problem could be formulated as a
bilinear programming problem, and for the case when the reduction operator
admits an inverse, they gave a heuristic solution that retained optimality. In
this note, we show that simplification of dependent reductions can be
formulated as a simple extension of the Gautam-Rajopadhye backtracking search
algorithm.
</p>
<a href="http://arxiv.org/abs/2010.03074" target="_blank">arXiv:2010.03074</a> [<a href="http://arxiv.org/pdf/2010.03074" target="_blank">pdf</a>]

<h2>Correlated Differential Privacy: Feature Selection in Machine Learning. (arXiv:2010.03094v1 [cs.LG])</h2>
<h3>Tao Zhang, Tianqing Zhu, Ping Xiong, Huan Huo, Zahir Tari, Wanlei Zhou</h3>
<p>Privacy preserving in machine learning is a crucial issue in industry
informatics since data used for training in industries usually contain
sensitive information. Existing differentially private machine learning
algorithms have not considered the impact of data correlation, which may lead
to more privacy leakage than expected in industrial applications. For example,
data collected for traffic monitoring may contain some correlated records due
to temporal correlation or user correlation. To fill this gap, we propose a
correlation reduction scheme with differentially private feature selection
considering the issue of privacy loss when data have correlation in machine
learning tasks. %The key to the proposed scheme is to describe the data
correlation and select features which leads to less data correlation across the
whole dataset. The proposed scheme involves five steps with the goal of
managing the extent of data correlation, preserving the privacy, and supporting
accuracy in the prediction results. In this way, the impact of data correlation
is relieved with the proposed feature selection scheme, and moreover, the
privacy issue of data correlation in learning is guaranteed. The proposed
method can be widely used in machine learning algorithms which provide services
in industrial areas. Experiments show that the proposed scheme can produce
better prediction results with machine learning tasks and fewer mean square
errors for data queries compared to existing schemes.
</p>
<a href="http://arxiv.org/abs/2010.03094" target="_blank">arXiv:2010.03094</a> [<a href="http://arxiv.org/pdf/2010.03094" target="_blank">pdf</a>]

<h2>Gradient-based Causal Structure Learning with Normalizing Flow. (arXiv:2010.03095v1 [cs.LG])</h2>
<h3>Xiongren Chen</h3>
<p>In this paper, we propose a score-based normalizing flow method called DAG-NF
to learn dependencies of input observation data. Inspired by Grad-CAM in
computer vision, we use jacobian matrix of output on input as causal
relationships and this method can be generalized to any neural networks
especially for flow-based generative neural networks such as Masked
Autoregressive Flow(MAF) and Continuous Normalizing Flow(CNF) which compute the
log likelihood loss and divergence of distribution of input data and target
distribution. This method extends NOTEARS which enforces a important acylicity
constraint on continuous adjacency matrix of graph nodes and significantly
reduce the computational complexity of search space of graph.
</p>
<a href="http://arxiv.org/abs/2010.03095" target="_blank">arXiv:2010.03095</a> [<a href="http://arxiv.org/pdf/2010.03095" target="_blank">pdf</a>]

<h2>Channel Recurrent Attention Networks for Video Pedestrian Retrieval. (arXiv:2010.03108v1 [cs.CV])</h2>
<h3>Pengfei Fang, Pan Ji, Jieming Zhou, Lars Petersson, Mehrtash Harandi</h3>
<p>Full attention, which generates an attention value per element of the input
feature maps, has been successfully demonstrated to be beneficial in visual
tasks. In this work, we propose a fully attentional network, termed {\it
channel recurrent attention network}, for the task of video pedestrian
retrieval. The main attention unit, \textit{channel recurrent attention},
identifies attention maps at the frame level by jointly leveraging spatial and
channel patterns via a recurrent neural network. This channel recurrent
attention is designed to build a global receptive field by recurrently
receiving and learning the spatial vectors. Then, a \textit{set aggregation}
cell is employed to generate a compact video representation. Empirical
experimental results demonstrate the superior performance of the proposed deep
network, outperforming current state-of-the-art results across standard video
person retrieval benchmarks, and a thorough ablation study shows the
effectiveness of the proposed units.
</p>
<a href="http://arxiv.org/abs/2010.03108" target="_blank">arXiv:2010.03108</a> [<a href="http://arxiv.org/pdf/2010.03108" target="_blank">pdf</a>]

<h2>Causal Curiosity: RL Agents Discovering Self-supervised Experiments for Causal Representation Learning. (arXiv:2010.03110v1 [cs.LG])</h2>
<h3>Sumedh A. Sontakke, Arash Mehrjou, Laurent Itti, Bernhard Sch&#xf6;lkopf</h3>
<p>Humans show an innate ability to learn the regularities of the world through
interaction. By performing experiments in our environment, we are able to
discern the causal factors of variation and infer how they affect the dynamics
of our world. Analogously, here we attempt to equip reinforcement learning
agents with the ability to perform experiments that facilitate a categorization
of the rolled-out trajectories, and to subsequently infer the causal factors of
the environment in a hierarchical manner. We introduce a novel intrinsic
reward, called causal curiosity, and show that it allows our agents to learn
optimal sequences of actions, and to discover causal factors in the dynamics.
The learned behavior allows the agent to infer a binary quantized
representation for the ground-truth causal factors in every environment.
Additionally, we find that these experimental behaviors are semantically
meaningful (e.g., to differentiate between heavy and light blocks, our agents
learn to lift them), and are learnt in a self-supervised manner with
approximately 2.5 times less data than conventional supervised planners. We
show that these behaviors can be re-purposed and fine-tuned (e.g., from lifting
to pushing or other downstream tasks). Finally, we show that the knowledge of
causal factor representations aids zero-shot learning for more complex tasks.
</p>
<a href="http://arxiv.org/abs/2010.03110" target="_blank">arXiv:2010.03110</a> [<a href="http://arxiv.org/pdf/2010.03110" target="_blank">pdf</a>]

<h2>Modeling Human Driving Behavior in Highway Scenario using Inverse Reinforcement Learning. (arXiv:2010.03118v1 [cs.RO])</h2>
<h3>Zhiyu Huang, Chen Lv, Jingda Wu</h3>
<p>Human driving behavior modeling is of great importance for designing safe,
smart, smooth as well as personalized autonomous driving systems. In this
paper, an internal reward function-based driving model that emulates the
human's internal decision-making mechanism is proposed. Besides, a
sampling-based inverse reinforcement learning (IRL) algorithm that learns the
reward function from human naturalistic driving data is also developed. A
polynomial trajectory sampler is adopted to generate feasible trajectories and
approximate the partition function in the maximum entropy IRL framework, and a
dynamic and interactive environment is built upon the static driving dataset to
estimate the generated trajectories considering the mutual dependency of
agents' actions. The proposed method is applied to learn personalized reward
functions for individual human drivers from the NGSIM dataset. The qualitative
results demonstrate that the learned reward function is able to interpret their
decisions. The quantitative results also reveal that the personalized modeling
method significantly outperforms the general modeling approach, reducing the
errors in human likeness by 24%, and the proposed reward-function-based method
delivers better results compared to other baseline methods. Moreover, it is
found that estimating the response actions of surrounding vehicles plays an
integral role in estimating the trajectory accurately and achieving a better
generalization ability.
</p>
<a href="http://arxiv.org/abs/2010.03118" target="_blank">arXiv:2010.03118</a> [<a href="http://arxiv.org/pdf/2010.03118" target="_blank">pdf</a>]

<h2>A Fast and Effective Method of Macula Automatic Detection for Retina Images. (arXiv:2010.03122v1 [eess.IV])</h2>
<h3>Yukang Jiang, Jianying Pan, Yanhe Shen, Jin Zhu, Jiamin Huang, Huirui Xie, Xueqin Wang, Yan Luo</h3>
<p>Retina image processing is one of the crucial and popular topics of medical
image processing. The macula fovea is responsible for sharp central vision,
which is necessary for human behaviors where visual detail is of primary
importance, such as reading, writing, driving, etc. This paper proposes a novel
method to locate the macula through a series of morphological processing. On
the premise of maintaining high accuracy, our approach is simpler and faster
than others. Furthermore, for the hospital's real images, our method is also
able to detect the macula robustly.
</p>
<a href="http://arxiv.org/abs/2010.03122" target="_blank">arXiv:2010.03122</a> [<a href="http://arxiv.org/pdf/2010.03122" target="_blank">pdf</a>]

<h2>VCDM: Leveraging Variational Bi-encoding and Deep Contextualized Word Representations for Improved Definition Modeling. (arXiv:2010.03124v1 [cs.CL])</h2>
<h3>Machel Reid, Edison Marrese-Taylor, Yutaka Matsuo</h3>
<p>In this paper, we tackle the task of definition modeling, where the goal is
to learn to generate definitions of words and phrases. Existing approaches for
this task are discriminative, combining distributional and lexical semantics in
an implicit rather than direct way. To tackle this issue we propose a
generative model for the task, introducing a continuous latent variable to
explicitly model the underlying relationship between a phrase used within a
context and its definition. We rely on variational inference for estimation and
leverage contextualized word embeddings for improved performance. Our approach
is evaluated on four existing challenging benchmarks with the addition of two
new datasets, "Cambridge" and the first non-English corpus "Robert", which we
release to complement our empirical study. Our Variational Contextual
Definition Modeler (VCDM) achieves state-of-the-art performance in terms of
automatic and human evaluation metrics, demonstrating the effectiveness of our
approach.
</p>
<a href="http://arxiv.org/abs/2010.03124" target="_blank">arXiv:2010.03124</a> [<a href="http://arxiv.org/pdf/2010.03124" target="_blank">pdf</a>]

<h2>Computational analysis of pathological image enables interpretable prediction for microsatellite instability. (arXiv:2010.03130v1 [stat.ML])</h2>
<h3>Jin Zhu, Wangwei Wu, Yuting Zhang, Shiyun Lin, Yukang Jiang, Ruixian Liu, Xueqin Wang</h3>
<p>Microsatellite instability (MSI) is associated with several tumor types and
its status has become increasingly vital in guiding patient treatment
decisions. However, in clinical practice, distinguishing MSI from its
counterpart is challenging since the diagnosis of MSI requires additional
genetic or immunohistochemical tests. In this study, interpretable pathological
image analysis strategies are established to help medical experts to
automatically identify MSI. The strategies only require ubiquitous Haematoxylin
and eosin-stained whole-slide images and can achieve decent performance in the
three cohorts collected from The Cancer Genome Atlas. The strategies provide
interpretability in two aspects. On the one hand, the image-level
interpretability is achieved by generating localization heat maps of important
regions based on the deep learning network; on the other hand, the
feature-level interpretability is attained through feature importance and
pathological feature interaction analysis. More interestingly, both from the
image-level and feature-level interpretability, color features and texture
characteristics are shown to contribute the most to the MSI predictions.
Therefore, the classification models under the proposed strategies can not only
serve as an efficient tool for predicting the MSI status of patients, but also
provide more insights to pathologists with clinical understanding.
</p>
<a href="http://arxiv.org/abs/2010.03130" target="_blank">arXiv:2010.03130</a> [<a href="http://arxiv.org/pdf/2010.03130" target="_blank">pdf</a>]

<h2>Conditional Generative Modeling via Learning the Latent Space. (arXiv:2010.03132v1 [cs.LG])</h2>
<h3>Sameera Ramasinghe, Kanchana Ranasinghe, Salman Khan, Nick Barnes, Stephen Gould</h3>
<p>Although deep learning has achieved appealing results on several machine
learning tasks, most of the models are deterministic at inference, limiting
their application to single-modal settings. We propose a novel general-purpose
framework for conditional generation in multimodal spaces, that uses latent
variables to model generalizable learning patterns while minimizing a family of
regression cost functions. At inference, the latent variables are optimized to
find optimal solutions corresponding to multiple output modes. Compared to
existing generative solutions, in multimodal spaces, our approach demonstrates
faster and stable convergence, and can learn better representations for
downstream tasks. Importantly, it provides a simple generic model that can beat
highly engineered pipelines tailored using domain expertise on a variety of
tasks, while generating diverse outputs. Our codes will be released.
</p>
<a href="http://arxiv.org/abs/2010.03132" target="_blank">arXiv:2010.03132</a> [<a href="http://arxiv.org/pdf/2010.03132" target="_blank">pdf</a>]

<h2>Provable Hierarchical Imitation Learning via EM. (arXiv:2010.03133v1 [cs.LG])</h2>
<h3>Zhiyu Zhang, Ioannis Paschalidis</h3>
<p>Due to recent empirical successes, the options framework for hierarchical
reinforcement learning is gaining increasing popularity. Rather than learning
from rewards which suffers from the curse of dimensionality, we consider
learning an options-type hierarchical policy from expert demonstrations. Such a
problem is referred to as hierarchical imitation learning. Converting this
problem to parameter inference in a latent variable model, we theoretically
characterize the EM approach proposed by Daniel et al. (2016). The population
level algorithm is analyzed as an intermediate step, which is nontrivial due to
the samples being correlated. If the expert policy can be parameterized by a
variant of the options framework, then under regularity conditions, we prove
that the proposed algorithm converges with high probability to a norm ball
around the true parameter. To our knowledge, this is the first performance
guarantee for an hierarchical imitation learning algorithm that only observes
primitive state-action pairs.
</p>
<a href="http://arxiv.org/abs/2010.03133" target="_blank">arXiv:2010.03133</a> [<a href="http://arxiv.org/pdf/2010.03133" target="_blank">pdf</a>]

<h2>Representation Learning for Sequence Data with Deep Autoencoding Predictive Components. (arXiv:2010.03135v1 [cs.LG])</h2>
<h3>Junwen Bai, Weiran Wang, Yingbo Zhou, Caiming Xiong</h3>
<p>We propose Deep Autoencoding Predictive Components (DAPC) -- a
self-supervised representation learning method for sequence data, based on the
intuition that useful representations of sequence data should exhibit a simple
structure in the latent space. We encourage this latent structure by maximizing
an estimate of predictive information of latent feature sequences, which is the
mutual information between past and future windows at each time step. In
contrast to the mutual information lower bound commonly used by contrastive
learning, the estimate of predictive information we adopt is exact under a
Gaussian assumption. Additionally, it can be computed without negative
sampling. To reduce the degeneracy of the latent space extracted by powerful
encoders and keep useful information from the inputs, we regularize predictive
information learning with a challenging masked reconstruction loss. We
demonstrate that our method recovers the latent space of noisy dynamical
systems, extracts predictive features for forecasting tasks, and improves
automatic speech recognition when used to pretrain the encoder on large amounts
of unlabeled data.
</p>
<a href="http://arxiv.org/abs/2010.03135" target="_blank">arXiv:2010.03135</a> [<a href="http://arxiv.org/pdf/2010.03135" target="_blank">pdf</a>]

<h2>Finite Meta-Dynamic Neurons in Spiking Neural Networks for Spatio-temporal Learning. (arXiv:2010.03140v1 [cs.NE])</h2>
<h3>Xiang Cheng, Tielin Zhang, Shuncheng Jia, Bo Xu</h3>
<p>Spiking Neural Networks (SNNs) have incorporated more biologically-plausible
structures and learning principles, hence are playing critical roles in
bridging the gap between artificial and natural neural networks. The spikes are
the sparse signals describing the above-threshold event-based firing and
under-threshold dynamic computation of membrane potentials, which give us an
alternative uniformed and efficient way on both information representation and
computation. Inspired from the biological network, where a finite number of
meta neurons integrated together for various of cognitive functions, we
proposed and constructed Meta-Dynamic Neurons (MDN) to improve SNNs for a
better network generalization during spatio-temporal learning. The MDNs are
designed with basic neuronal dynamics containing 1st-order and 2nd-order
dynamics of membrane potentials, including the spatial and temporal meta types
supported by some hyper-parameters. The MDNs generated from a spatial (MNIST)
and a temporal (TIDigits) datasets first, and then extended to various other
different spatio-temporal tasks (including Fashion-MNIST, NETtalk, Cifar-10,
TIMIT and N-MNIST). The comparable accuracy was reached compared to other SOTA
SNN algorithms, and a better generalization was also achieved by SNNs using
MDNs than that without using MDNs.
</p>
<a href="http://arxiv.org/abs/2010.03140" target="_blank">arXiv:2010.03140</a> [<a href="http://arxiv.org/pdf/2010.03140" target="_blank">pdf</a>]

<h2>Projection-Based Constrained Policy Optimization. (arXiv:2010.03152v1 [cs.LG])</h2>
<h3>Tsung-Yen Yang, Justinian Rosca, Karthik Narasimhan, Peter J. Ramadge</h3>
<p>We consider the problem of learning control policies that optimize a reward
function while satisfying constraints due to considerations of safety,
fairness, or other costs. We propose a new algorithm, Projection-Based
Constrained Policy Optimization (PCPO). This is an iterative method for
optimizing policies in a two-step process: the first step performs a local
reward improvement update, while the second step reconciles any constraint
violation by projecting the policy back onto the constraint set. We
theoretically analyze PCPO and provide a lower bound on reward improvement, and
an upper bound on constraint violation, for each policy update. We further
characterize the convergence of PCPO based on two different metrics:
$\normltwo$ norm and Kullback-Leibler divergence. Our empirical results over
several control tasks demonstrate that PCPO achieves superior performance,
averaging more than 3.5 times less constraint violation and around 15\% higher
reward compared to state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.03152" target="_blank">arXiv:2010.03152</a> [<a href="http://arxiv.org/pdf/2010.03152" target="_blank">pdf</a>]

<h2>A Self-Refinement Strategy for Noise Reduction in Grammatical Error Correction. (arXiv:2010.03155v1 [cs.CL])</h2>
<h3>Masato Mita, Shun Kiyono, Masahiro Kaneko, Jun Suzuki, Kentaro Inui</h3>
<p>Existing approaches for grammatical error correction (GEC) largely rely on
supervised learning with manually created GEC datasets. However, there has been
little focus on verifying and ensuring the quality of the datasets, and on how
lower-quality data might affect GEC performance. We indeed found that there is
a non-negligible amount of "noise" where errors were inappropriately edited or
left uncorrected. To address this, we designed a self-refinement method where
the key idea is to denoise these datasets by leveraging the prediction
consistency of existing models, and outperformed strong denoising baseline
methods. We further applied task-specific techniques and achieved
state-of-the-art performance on the CoNLL-2014, JFLEG, and BEA-2019 benchmarks.
We then analyzed the effect of the proposed denoising method, and found that
our approach leads to improved coverage of corrections and facilitated fluency
edits which are reflected in higher recall and overall performance.
</p>
<a href="http://arxiv.org/abs/2010.03155" target="_blank">arXiv:2010.03155</a> [<a href="http://arxiv.org/pdf/2010.03155" target="_blank">pdf</a>]

<h2>Knowledge-enriched, Type-constrained and Grammar-guided Question Generation over Knowledge Bases. (arXiv:2010.03157v1 [cs.CL])</h2>
<h3>Sheng Bi, Xiya Cheng, Yuan-Fang Li, Yongzhen Wang, Guilin Qi</h3>
<p>Question generation over knowledge bases (KBQG) aims at generating
natural-language questions about a subgraph, i.e. a set of (connected) triples.
Two main challenges still face the current crop of encoder-decoder-based
methods, especially on small subgraphs: (1) low diversity and poor fluency due
to the limited information contained in the subgraphs, and (2) semantic drift
due to the decoder's oblivion of the semantics of the answer entity. We propose
an innovative knowledge-enriched, type-constrained and grammar-guided KBQG
model, named KTG, to addresses the above challenges. In our model, the encoder
is equipped with auxiliary information from the KB, and the decoder is
constrained with word types during QG. Specifically, entity domain and
description, as well as relation hierarchy information are considered to
construct question contexts, while a conditional copy mechanism is incorporated
to modulate question semantics according to current word types. Besides, a
novel reward function featuring grammatical similarity is designed to improve
both generative richness and syntactic correctness via reinforcement learning.
Extensive experiments show that our proposed model outperforms existing methods
by a significant margin on two widely-used benchmark datasets SimpleQuestion
and PathQuestion.
</p>
<a href="http://arxiv.org/abs/2010.03157" target="_blank">arXiv:2010.03157</a> [<a href="http://arxiv.org/pdf/2010.03157" target="_blank">pdf</a>]

<h2>Multilingual Knowledge Graph Completion via Ensemble Knowledge Transfer. (arXiv:2010.03158v1 [cs.CL])</h2>
<h3>Xuelu Chen, Muhao Chen, Changjun Fan, Ankith Uppunda, Yizhou Sun, Carlo Zaniolo</h3>
<p>Predicting missing facts in a knowledge graph (KG) is a crucial task in
knowledge base construction and reasoning, and it has been the subject of much
research in recent works using KG embeddings. While existing KG embedding
approaches mainly learn and predict facts within a single KG, a more plausible
solution would benefit from the knowledge in multiple language-specific KGs,
considering that different KGs have their own strengths and limitations on data
quality and coverage. This is quite challenging, since the transfer of
knowledge among multiple independently maintained KGs is often hindered by the
insufficiency of alignment information and the inconsistency of described
facts. In this paper, we propose KEnS, a novel framework for embedding learning
and ensemble knowledge transfer across a number of language-specific KGs. KEnS
embeds all KGs in a shared embedding space, where the association of entities
is captured based on self-learning. Then, KEnS performs ensemble inference to
combine prediction results from embeddings of multiple language-specific KGs,
for which multiple ensemble techniques are investigated. Experiments on five
real-world language-specific KGs show that KEnS consistently improves
state-of-the-art methods on KG completion, via effectively identifying and
leveraging complementary knowledge.
</p>
<a href="http://arxiv.org/abs/2010.03158" target="_blank">arXiv:2010.03158</a> [<a href="http://arxiv.org/pdf/2010.03158" target="_blank">pdf</a>]

<h2>Vision Skills Needed to Answer Visual Questions. (arXiv:2010.03160v1 [cs.HC])</h2>
<h3>Xiaoyu Zeng, Yanan Wang, Tai-Yin Chiu, Nilavra Bhattacharya, Danna Gurari</h3>
<p>The task of answering questions about images has garnered attention as a
practical service for assisting populations with visual impairments as well as
a visual Turing test for the artificial intelligence community. Our first aim
is to identify the common vision skills needed for both scenarios. To do so, we
analyze the need for four vision skills---object recognition, text recognition,
color recognition, and counting---on over 27,000 visual questions from two
datasets representing both scenarios. We next quantify the difficulty of these
skills for both humans and computers on both datasets. Finally, we propose a
novel task of predicting what vision skills are needed to answer a question
about an image. Our results reveal (mis)matches between aims of real users of
such services and the focus of the AI community. We conclude with a discussion
about future directions for addressing the visual question answering task.
</p>
<a href="http://arxiv.org/abs/2010.03160" target="_blank">arXiv:2010.03160</a> [<a href="http://arxiv.org/pdf/2010.03160" target="_blank">pdf</a>]

<h2>Near-Optimal Regret Bounds for Model-Free RL in Non-Stationary Episodic MDPs. (arXiv:2010.03161v1 [cs.LG])</h2>
<h3>Weichao Mao, Kaiqing Zhang, Ruihao Zhu, David Simchi-Levi, Tamer Ba&#x15f;ar</h3>
<p>We consider model-free reinforcement learning (RL) in non-stationary Markov
decision processes (MDPs). Both the reward functions and the state transition
distributions are allowed to vary over time, either gradually or abruptly, as
long as their cumulative variation magnitude does not exceed certain budgets.
We propose an algorithm, named Restarted Q-Learning with Upper Confidence
Bounds (RestartQ-UCB), for this setting, which adopts a simple restarting
strategy and an extra optimism term. Our algorithm outperforms the
state-of-the-art (model-based) solution in terms of dynamic regret.
Specifically, RestartQ-UCB with Freedman-type bonus terms achieves a dynamic
regret of $\widetilde{O}(S^{\frac{1}{3}} A^{\frac{1}{3}} \Delta^{\frac{1}{3}} H
T^{\frac{2}{3}})$, where $S$ and $A$ are the numbers of states and actions,
respectively, $\Delta&gt;0$ is the variation budget, $H$ is the number of steps
per episode, and $T$ is the total number of steps. We further show that our
algorithm is near-optimal by establishing an information-theoretical lower
bound of $\Omega(S^{\frac{1}{3}} A^{\frac{1}{3}} \Delta^{\frac{1}{3}}
H^{\frac{2}{3}} T^{\frac{2}{3}})$, which to the best of our knowledge is the
first impossibility result in non-stationary RL in general.
</p>
<a href="http://arxiv.org/abs/2010.03161" target="_blank">arXiv:2010.03161</a> [<a href="http://arxiv.org/pdf/2010.03161" target="_blank">pdf</a>]

<h2>Accurate, Efficient and Scalable Training of Graph Neural Networks. (arXiv:2010.03166v1 [cs.LG])</h2>
<h3>Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, Viktor Prasanna</h3>
<p>Graph Neural Networks (GNNs) are powerful deep learning models to generate
node embeddings on graphs. When applying deep GNNs on large graphs, it is still
challenging to perform training in an efficient and scalable way. We propose a
novel parallel training framework. Through sampling small subgraphs as
minibatches, we reduce training workload by orders of magnitude compared with
state-of-the-art minibatch methods. We then parallelize the key computation
steps on tightly-coupled shared memory systems. For graph sampling, we exploit
parallelism within and across sampler instances, and propose an efficient data
structure supporting concurrent accesses from samplers. The parallel sampler
theoretically achieves near-linear speedup with respect to number of processing
units. For feature propagation within subgraphs, we improve cache utilization
and reduce DRAM traffic by data partitioning. Our partitioning is a
2-approximation strategy for minimizing the communication cost compared to the
optimal. We further develop a runtime scheduler to reorder the training
operations and adjust the minibatch subgraphs to improve parallel performance.
Finally, we generalize the above parallelization strategies to support multiple
types of GNN models and graph samplers. The proposed training outperforms the
state-of-the-art in scalability, efficiency and accuracy simultaneously. On a
40-core Xeon platform, we achieve 60x speedup (with AVX) in the sampling step
and 20x speedup in the feature propagation step, compared to the serial
implementation. Our algorithm enables fast training of deeper GNNs, as
demonstrated by orders of magnitude speedup compared to the Tensorflow
implementation. We open-source our code at
https://github.com/GraphSAINT/GraphSAINT.
</p>
<a href="http://arxiv.org/abs/2010.03166" target="_blank">arXiv:2010.03166</a> [<a href="http://arxiv.org/pdf/2010.03166" target="_blank">pdf</a>]

<h2>A Study on Trees's Knots Prediction from their Bark Outer-Shape. (arXiv:2010.03173v1 [cs.CV])</h2>
<h3>Mejri Mohamed, Antoine Richard, Cedric Pradalier</h3>
<p>In the industry, the value of wood-logs strongly depends on their internal
structure and more specifically on the knots' distribution inside the trees. As
of today, CT-scanners are the prevalent tool to acquire accurate images of the
trees internal structure. However, CT-scanners are expensive, and slow, making
their use impractical for most industrial applications. Knowing where the knots
are within a tree could improve the efficiency of the overall tree industry by
reducing waste and improving the quality of wood-logs by-products. In this
paper we evaluate different deep-learning based architectures to predict the
internal knots distribution of a tree from its outer-shape, something that has
never been done before. Three types of techniques based on Convolutional Neural
Networks (CNN) will be studied.

The architectures are tested on both real and synthetic CT-scanned trees.
With these experiments, we demonstrate that CNNs can be used to predict
internal knots distribution based on the external surface of the trees. The
goal being to show that these inexpensive and fast methods could be used to
replace the CT-scanners.

Additionally, we look into the performance of several off-the-shelf
object-detectors to detect knots inside CT-scanned images. This method is used
to autonomously label part of our real CT-scanned trees alleviating the need to
manually segment the whole of the images.
</p>
<a href="http://arxiv.org/abs/2010.03173" target="_blank">arXiv:2010.03173</a> [<a href="http://arxiv.org/pdf/2010.03173" target="_blank">pdf</a>]

<h2>Transfer Learning and Distant Supervision for Multilingual Transformer Models: A Study on African Languages. (arXiv:2010.03179v1 [cs.CL])</h2>
<h3>Michael A. Hedderich, David Adelani, Dawei Zhu, Jesujoba Alabi, Udia Markus, Dietrich Klakow</h3>
<p>Multilingual transformer models like mBERT and XLM-RoBERTa have obtained
great improvements for many NLP tasks on a variety of languages. However,
recent works also showed that results from high-resource languages could not be
easily transferred to realistic, low-resource scenarios. In this work, we study
trends in performance for different amounts of available resources for the
three African languages Hausa, isiXhosa and Yor\`ub\'a on both NER and topic
classification. We show that in combination with transfer learning or distant
supervision, these models can achieve with as little as 10 or 100 labeled
sentences the same performance as baselines with much more supervised training
data. However, we also find settings where this does not hold. Our discussions
and additional experiments on assumptions such as time and hardware
restrictions highlight challenges and opportunities in low-resource learning.
</p>
<a href="http://arxiv.org/abs/2010.03179" target="_blank">arXiv:2010.03179</a> [<a href="http://arxiv.org/pdf/2010.03179" target="_blank">pdf</a>]

<h2>Not All Datasets Are Born Equal: On Heterogeneous Data and Adversarial Examples. (arXiv:2010.03180v1 [cs.LG])</h2>
<h3>Eden Levy, Yael Mathov, Ziv Katzir, Asaf Shabtai, Yuval Elovici</h3>
<p>Recent work on adversarial learning has focused mainly on neural networks and
domains where they excel, such as computer vision. The data in these domains is
homogeneous, whereas heterogeneous tabular data domains remain underexplored
despite their prevalence. Constructing an attack on models with heterogeneous
input spaces is challenging, as they are governed by complex domain-specific
validity rules and comprised of nominal, ordinal, and numerical features. We
argue that machine learning models trained on heterogeneous tabular data are as
susceptible to adversarial manipulations as those trained on continuous or
homogeneous data such as images. In this paper, we introduce an optimization
framework for identifying adversarial perturbations in heterogeneous input
spaces. We define distribution-aware constraints for preserving the consistency
of the adversarial examples and incorporate them by embedding the heterogeneous
input into a continuous latent space. Our approach focuses on an adversary who
aims to craft valid perturbations of minimal l_0-norms and apply them in real
life. We propose a neural network-based implementation of our approach and
demonstrate its effectiveness using three datasets from different content
domains. Our results suggest that despite the several constraints heterogeneity
imposes on the input space of a machine learning model, the susceptibility to
adversarial examples remains unimpaired.
</p>
<a href="http://arxiv.org/abs/2010.03180" target="_blank">arXiv:2010.03180</a> [<a href="http://arxiv.org/pdf/2010.03180" target="_blank">pdf</a>]

<h2>Generative Melody Composition with Human-in-the-Loop Bayesian Optimization. (arXiv:2010.03190v1 [cs.SD])</h2>
<h3>Yijun Zhou, Yuki Koyama, Masataka Goto, Takeo Igarashi</h3>
<p>Deep generative models allow even novice composers to generate various
melodies by sampling latent vectors. However, finding the desired melody is
challenging since the latent space is unintuitive and high-dimensional. In this
work, we present an interactive system that supports generative melody
composition with human-in-the-loop Bayesian optimization (BO). This system
takes a mixed-initiative approach; the system generates candidate melodies to
evaluate, and the user evaluates them and provides preferential feedback (i.e.,
picking the best melody among the candidates) to the system. This process is
iteratively performed based on BO techniques until the user finds the desired
melody. We conducted a pilot study using our prototype system, suggesting the
potential of this approach.
</p>
<a href="http://arxiv.org/abs/2010.03190" target="_blank">arXiv:2010.03190</a> [<a href="http://arxiv.org/pdf/2010.03190" target="_blank">pdf</a>]

<h2>Vision-Based Object Recognition in Indoor Environments Using Topologically Persistent Features. (arXiv:2010.03196v1 [cs.CV])</h2>
<h3>Ekta U. Samani, Xingjian Yang, Ashis G. Banerjee</h3>
<p>Object recognition in unseen indoor environments has been challenging for
most state-of-the-art object detectors. To address this challenge, we propose
the use of topologically persistent features for object recognition. We extract
two kinds of persistent features from binary segmentation maps, namely sparse
PI features and amplitude features, by applying persistent homology to
filtrations of the cubical complexes of segmentation maps generated using
height functions in multiple directions. The features are used for training a
fully connected network for recognition. For performance evaluation, in
addition to a widely used shape dataset, we collect new datasets comprising
scene images from two different environments, i.e., a living room and a
warehouse. Scene images in both environments consist of up to five different
objects with varying poses, chosen from a set of fourteen objects, taken in
varying illumination conditions from different distances and camera viewing
angles. The overall performance of our methods, trained using living room
images, remains relatively unaltered on the unseen warehouse images, without
retraining. In contrast, a state-of-the-art object detector's accuracy drops
considerably. Our methods also achieve higher overall recall and accuracy than
the state-of-the-art in the unseen warehouse environment. We also implement the
proposed framework on a real-world robot to demonstrate its usefulness.
</p>
<a href="http://arxiv.org/abs/2010.03196" target="_blank">arXiv:2010.03196</a> [<a href="http://arxiv.org/pdf/2010.03196" target="_blank">pdf</a>]

<h2>WDN: A Wide and Deep Network to Divide-and-Conquer Image Super-resolution. (arXiv:2010.03199v1 [eess.IV])</h2>
<h3>Vikram Singh (1), Anurag Mittal (1) ((1) Indian Institute of Technology - Madras)</h3>
<p>Divide and conquer is an established algorithm design paradigm that has
proven itself to solve a variety of problems efficiently. However, it is yet to
be fully explored in solving problems with a neural network, particularly the
problem of image super-resolution. In this work, we propose an approach to
divide the problem of image super-resolution into multiple sub-problems and
then solve/conquer them with the help of a neural network. Unlike a typical
deep neural network, we design an alternate network architecture that is much
wider (along with being deeper) than existing networks and is specially
designed to implement the divide-and-conquer design paradigm with a neural
network. Additionally, a technique to calibrate the intensities of feature map
pixels is being introduced. Extensive experimentation on five datasets reveals
that our approach towards the problem and the proposed architecture generate
better and sharper results than current state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.03199" target="_blank">arXiv:2010.03199</a> [<a href="http://arxiv.org/pdf/2010.03199" target="_blank">pdf</a>]

<h2>M3Lung-Sys: A Deep Learning System for Multi-Class Lung Pneumonia Screening from CT Imaging. (arXiv:2010.03201v1 [eess.IV])</h2>
<h3>Xuelin Qian, Huazhu Fu, Weiya Shi, Tao Chen, Yanwei Fu, Fei Shan, Xiangyang Xue</h3>
<p>To counter the outbreak of COVID-19, the accurate diagnosis of suspected
cases plays a crucial role in timely quarantine, medical treatment, and
preventing the spread of the pandemic. Considering the limited training cases
and resources (e.g, time and budget), we propose a Multi-task Multi-slice Deep
Learning System (M3Lung-Sys) for multi-class lung pneumonia screening from CT
imaging, which only consists of two 2D CNN networks, i.e., slice- and
patient-level classification networks. The former aims to seek the feature
representations from abundant CT slices instead of limited CT volumes, and for
the overall pneumonia screening, the latter one could recover the temporal
information by feature refinement and aggregation between different slices. In
addition to distinguish COVID-19 from Healthy, H1N1, and CAP cases, our M 3
Lung-Sys also be able to locate the areas of relevant lesions, without any
pixel-level annotation. To further demonstrate the effectiveness of our model,
we conduct extensive experiments on a chest CT imaging dataset with a total of
734 patients (251 healthy people, 245 COVID-19 patients, 105 H1N1 patients, and
133 CAP patients). The quantitative results with plenty of metrics indicate the
superiority of our proposed model on both slice- and patient-level
classification tasks. More importantly, the generated lesion location maps make
our system interpretable and more valuable to clinicians.
</p>
<a href="http://arxiv.org/abs/2010.03201" target="_blank">arXiv:2010.03201</a> [<a href="http://arxiv.org/pdf/2010.03201" target="_blank">pdf</a>]

<h2>RealSmileNet: A Deep End-To-End Network for Spontaneous and Posed Smile Recognition. (arXiv:2010.03203v1 [cs.CV])</h2>
<h3>Yan Yang, Md Zakir Hossain, Tom Gedeon, Shafin Rahman</h3>
<p>Smiles play a vital role in the understanding of social interactions within
different communities, and reveal the physical state of mind of people in both
real and deceptive ways. Several methods have been proposed to recognize
spontaneous and posed smiles. All follow a feature-engineering based pipeline
requiring costly pre-processing steps such as manual annotation of face
landmarks, tracking, segmentation of smile phases, and hand-crafted features.
The resulting computation is expensive, and strongly dependent on
pre-processing steps. We investigate an end-to-end deep learning model to
address these problems, the first end-to-end model for spontaneous and posed
smile recognition. Our fully automated model is fast and learns the feature
extraction processes by training a series of convolution and ConvLSTM layer
from scratch. Our experiments on four datasets demonstrate the robustness and
generalization of the proposed model by achieving state-of-the-art
performances.
</p>
<a href="http://arxiv.org/abs/2010.03203" target="_blank">arXiv:2010.03203</a> [<a href="http://arxiv.org/pdf/2010.03203" target="_blank">pdf</a>]

<h2>Like hiking? You probably enjoy nature: Persona-grounded Dialog with Commonsense Expansions. (arXiv:2010.03205v1 [cs.CL])</h2>
<h3>Bodhisattwa Prasad Majumder, Harsh Jhamtani, Taylor Berg-Kirkpatrick, Julian McAuley</h3>
<p>Existing persona-grounded dialog models often fail to capture simple
implications of given persona descriptions, something which humans are able to
do seamlessly. For example, state-of-the-art models cannot infer that interest
in hiking might imply love for nature or longing for a break. In this paper, we
propose to expand available persona sentences using existing commonsense
knowledge bases and paraphrasing resources to imbue dialog models with access
to an expanded and richer set of persona descriptions. Additionally, we
introduce fine-grained grounding on personas by encouraging the model to make a
discrete choice among persona sentences while synthesizing a dialog response.
Since such a choice is not observed in the data, we model it using a discrete
latent random variable and use variational learning to sample from hundreds of
persona expansions. Our model outperforms competitive baselines on the
PersonaChat dataset in terms of dialog quality and diversity while achieving
persona-consistent and controllable dialog generation.
</p>
<a href="http://arxiv.org/abs/2010.03205" target="_blank">arXiv:2010.03205</a> [<a href="http://arxiv.org/pdf/2010.03205" target="_blank">pdf</a>]

<h2>Physical System for Non Time Sequence Data. (arXiv:2010.03206v1 [cs.LG])</h2>
<h3>Xiongren Chen</h3>
<p>We propose a novelty approach to connect machine learning to causal structure
learning by jacobian matrix of neural network w.r.t. input variables. In this
paper, we extend the jacobian-based approach to physical system which is the
method human explore and reason the world and it is the highest level of
causality. By functions fitting with Neural ODE, we can read out causal
structure from functions. This method also enforces a important acylicity
constraint on continuous adjacency matrix of graph nodes and significantly
reduce the computational complexity of search space of graph.
</p>
<a href="http://arxiv.org/abs/2010.03206" target="_blank">arXiv:2010.03206</a> [<a href="http://arxiv.org/pdf/2010.03206" target="_blank">pdf</a>]

<h2>Deep learning models for predictive maintenance: a survey, comparison, challenges and prospect. (arXiv:2010.03207v1 [cs.LG])</h2>
<h3>Oscar Serradilla, Ekhi Zugasti, Urko Zurutuza</h3>
<p>Given the growing amount of industrial data spaces worldwide, deep learning
solutions have become popular for predictive maintenance, which monitor assets
to optimise maintenance tasks. Choosing the most suitable architecture for each
use-case is complex given the number of examples found in literature. This work
aims at facilitating this task by reviewing state-of-the-art deep learning
architectures, and how they integrate with predictive maintenance stages to
meet industrial companies' requirements (i.e. anomaly detection, root cause
analysis, remaining useful life estimation). They are categorised and compared
in industrial applications, explaining how to fill their gaps. Finally, open
challenges and future research paths are presented.
</p>
<a href="http://arxiv.org/abs/2010.03207" target="_blank">arXiv:2010.03207</a> [<a href="http://arxiv.org/pdf/2010.03207" target="_blank">pdf</a>]

<h2>Learning Arbitrary-Goal Fabric Folding with One Hour of Real Robot Experience. (arXiv:2010.03209v1 [cs.RO])</h2>
<h3>Robert Lee, Daniel Ward, Akansel Cosgun, Vibhavari Dasagi, Peter Corke, Jurgen Leitner</h3>
<p>Manipulating deformable objects, such as fabric, is a long standing problem
in robotics, with state estimation and control posing a significant challenge
for traditional methods. In this paper, we show that it is possible to learn
fabric folding skills in only an hour of self-supervised real robot experience,
without human supervision or simulation. Our approach relies on fully
convolutional networks and the manipulation of visual inputs to exploit learned
features, allowing us to create an expressive goal-conditioned pick and place
policy that can be trained efficiently with real world robot data only. Folding
skills are learned with only a sparse reward function and thus do not require
reward function engineering, merely an image of the goal configuration. We
demonstrate our method on a set of towel-folding tasks, and show that our
approach is able to discover sequential folding strategies, purely from
trial-and-error. We achieve state-of-the-art results without the need for
demonstrations or simulation, used in prior approaches. Videos available at:
https://sites.google.com/view/learningtofold
</p>
<a href="http://arxiv.org/abs/2010.03209" target="_blank">arXiv:2010.03209</a> [<a href="http://arxiv.org/pdf/2010.03209" target="_blank">pdf</a>]

<h2>Designing, Playing, and Performing with a Vision-based Mouth Interface. (arXiv:2010.03213v1 [cs.HC])</h2>
<h3>Michael J. Lyons, Michael Haehnel, Nobuji Tetsutani</h3>
<p>The role of the face and mouth in speech production as well asnon-verbal
communication suggests the use of facial action tocontrol musical sound. Here
we document work on theMouthesizer, a system which uses a headworn
miniaturecamera and computer vision algorithm to extract shapeparameters from
the mouth opening and output these as MIDIcontrol changes. We report our
experience with variousgesture-to-sound mappings and musical applications,
anddescribe a live performance which used the Mouthesizerinterface.
</p>
<a href="http://arxiv.org/abs/2010.03213" target="_blank">arXiv:2010.03213</a> [<a href="http://arxiv.org/pdf/2010.03213" target="_blank">pdf</a>]

<h2>Learning Half-Spaces and other Concept Classes in the Limit with Iterative Learners. (arXiv:2010.03227v1 [cs.LG])</h2>
<h3>Ardalan Khazraei, Timo K&#xf6;tzing, Karen Seidel</h3>
<p>In order to model an efficient learning paradigm, iterative learning
algorithms access data one by one, updating the current hypothesis without
regress to past data. Past research on iterative learning analyzed for example
many important additional requirements and their impact on iterative learners.
In this paper, our results are twofold. First, we analyze the relative learning
power of various settings of iterative learning, including learning from text
and from informant, as well as various further restrictions, for example we
show that strongly non-U-shaped learning is restrictive for iterative learning
from informant. Second, we investigate the learnability of the concept class of
half-spaces and provide a constructive iterative algorithm to learn the set of
half-spaces from informant.
</p>
<a href="http://arxiv.org/abs/2010.03227" target="_blank">arXiv:2010.03227</a> [<a href="http://arxiv.org/pdf/2010.03227" target="_blank">pdf</a>]

<h2>FairMixRep : Self-supervised Robust Representation Learning for Heterogeneous Data with Fairness constraints. (arXiv:2010.03228v1 [stat.ML])</h2>
<h3>Souradip Chakraborty, Ekansh Verma, Saswata Sahoo, Jyotishka Datta</h3>
<p>Representation Learning in a heterogeneous space with mixed variables of
numerical and categorical types has interesting challenges due to its complex
feature manifold. Moreover, feature learning in an unsupervised setup, without
class labels and a suitable learning loss function, add to the problem
complexity further. Further, the learned representation and subsequent
predictions should not reflect discriminatory behavior toward certain sensitive
groups or attributes. The proposed feature map should preserve maximum
variations present in the data and needs to be fair with respect to the
sensitive variables. We propose, in the first phase of our work, an efficient
encoder-decoder framework to capture the mixed-domain information. The second
phase of our work focuses on de-biasing the mixed space representations by
adding relevant fairness constraints. This ensures minimal information loss
between the representations before and after the fairness-preserving
projections. Both the information content and the fairness aspect of the final
representation learned has been validated through several metrics where it
shows excellent performance. Our work (FairMixRep) addresses the problem of
Mixed Space Fair Representation learning from an unsupervised perspective and
learns a Universal representation which is timely, unique and a novel research
contribution.
</p>
<a href="http://arxiv.org/abs/2010.03228" target="_blank">arXiv:2010.03228</a> [<a href="http://arxiv.org/pdf/2010.03228" target="_blank">pdf</a>]

<h2>Bias and Debias in Recommender System: A Survey and Future Directions. (arXiv:2010.03240v1 [cs.IR])</h2>
<h3>Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, Xiangnan He</h3>
<p>While recent years have witnessed a rapid growth of research papers on
recommender system (RS), most of the papers focus on inventing machine learning
models to better fit user behavior data. However, user behavior data is
observational rather than experimental. This makes various biases widely exist
in the data, including but not limited to selection bias, position bias,
exposure bias, and popularity bias. Blindly fitting the data without
considering the inherent biases will result in many serious issues, e.g., the
discrepancy between offline evaluation and online metrics, hurting user
satisfaction and trust on the recommendation service, etc. To transform the
large volume of research models into practical improvements, it is highly
urgent to explore the impacts of the biases and perform debiasing when
necessary. When reviewing the papers that consider biases in RS, we find that,
to our surprise, the studies are rather fragmented and lack a systematic
organization. The terminology "bias" is widely used in the literature, but its
definition is usually vague and even inconsistent across papers. This motivates
us to provide a systematic survey of existing work on RS biases. In this paper,
we first summarize seven types of biases in recommendation, along with their
definitions and characteristics. We then provide a taxonomy to position and
organize the existing work on recommendation debiasing. Finally, we identify
some open challenges and envision some future directions, with the hope of
inspiring more research work on this important yet less investigated topic.
</p>
<a href="http://arxiv.org/abs/2010.03240" target="_blank">arXiv:2010.03240</a> [<a href="http://arxiv.org/pdf/2010.03240" target="_blank">pdf</a>]

<h2>Equivariant Normalizing Flows for Point Processes and Sets. (arXiv:2010.03242v1 [cs.LG])</h2>
<h3>Marin Bilo&#x161;, Stephan G&#xfc;nnemann</h3>
<p>A point process describes how random sets of exchangeable points are
generated. The points usually influence the positions of each other via
attractive and repulsive forces. To model this behavior, it is enough to
transform the samples from the uniform process with a sufficiently complex
equivariant function. However, learning the parameters of the resulting process
is challenging since the likelihood is hard to estimate and often intractable.
This leads us to our proposed model - CONFET. Based on continuous normalizing
flows, it allows arbitrary interactions between points while having tractable
likelihood. Experiments on various real and synthetic datasets show the
improved performance of our new scalable approach.
</p>
<a href="http://arxiv.org/abs/2010.03242" target="_blank">arXiv:2010.03242</a> [<a href="http://arxiv.org/pdf/2010.03242" target="_blank">pdf</a>]

<h2>Deep Learning-Based Grading of Ductal Carcinoma In Situ in Breast Histopathology Images. (arXiv:2010.03244v1 [eess.IV])</h2>
<h3>Suzanne C. Wetstein, Nikolas Stathonikos, Josien P.W. Pluim, Yujing J. Heng, Natalie D. ter Hoeve, Celien P.H. Vreuls, Paul J. van Diest, Mitko Veta</h3>
<p>Ductal carcinoma in situ (DCIS) is a non-invasive breast cancer that can
progress into invasive ductal carcinoma (IDC). Studies suggest DCIS is often
overtreated since a considerable part of DCIS lesions may never progress into
IDC. Lower grade lesions have a lower progression speed and risk, possibly
allowing treatment de-escalation. However, studies show significant
inter-observer variation in DCIS grading. Automated image analysis may provide
an objective solution to address high subjectivity of DCIS grading by
pathologists.

In this study, we developed a deep learning-based DCIS grading system. It was
developed using the consensus DCIS grade of three expert observers on a dataset
of 1186 DCIS lesions from 59 patients. The inter-observer agreement, measured
by quadratic weighted Cohen's kappa, was used to evaluate the system and
compare its performance to that of expert observers. We present an analysis of
the lesion-level and patient-level inter-observer agreement on an independent
test set of 1001 lesions from 50 patients.

The deep learning system (dl) achieved on average slightly higher
inter-observer agreement to the observers (o1, o2 and o3)
($\kappa_{o1,dl}=0.81, \kappa_{o2,dl}=0.53, \kappa_{o3,dl}=0.40$) than the
observers amongst each other ($\kappa_{o1,o2}=0.58, \kappa_{o1,o3}=0.50,
\kappa_{o2,o3}=0.42$) at the lesion-level. At the patient-level, the deep
learning system achieved similar agreement to the observers
($\kappa_{o1,dl}=0.77, \kappa_{o2,dl}=0.75, \kappa_{o3,dl}=0.70$) as the
observers amongst each other ($\kappa_{o1,o2}=0.77, \kappa_{o1,o3}=0.75,
\kappa_{o2,o3}=0.72$).

In conclusion, we developed a deep learning-based DCIS grading system that
achieved a performance similar to expert observers. We believe this is the
first automated system that could assist pathologists by providing robust and
reproducible second opinions on DCIS grade.
</p>
<a href="http://arxiv.org/abs/2010.03244" target="_blank">arXiv:2010.03244</a> [<a href="http://arxiv.org/pdf/2010.03244" target="_blank">pdf</a>]

<h2>Learning Clusterable Visual Features for Zero-Shot Recognition. (arXiv:2010.03245v1 [cs.CV])</h2>
<h3>Jingyi Xu, Zhixin Shu, Dimitris Samaras</h3>
<p>In zero-shot learning (ZSL), conditional generators have been widely used to
generate additional training features. These features can then be used to train
the classifiers for testing data. However, some testing data are considered
"hard" as they lie close to the decision boundaries and are prone to
misclassification, leading to performance degradation for ZSL. In this paper,
we propose to learn clusterable features for ZSL problems. Using a Conditional
Variational Autoencoder (CVAE) as the feature generator, we project the
original features to a new feature space supervised by an auxiliary
classification loss. To further increase clusterability, we fine-tune the
features using Gaussian similarity loss. The clusterable visual features are
not only more suitable for CVAE reconstruction but are also more separable
which improves classification accuracy. Moreover, we introduce Gaussian noise
to enlarge the intra-class variance of the generated features, which helps to
improve the classifier's robustness. Our experiments on SUN,CUB, and AWA2
datasets show consistent improvement over previous state-of-the-art ZSL results
by a large margin. In addition to its effectiveness on zero-shot
classification, experiments show that our method to increase feature
clusterability benefits few-shot learning algorithms as well.
</p>
<a href="http://arxiv.org/abs/2010.03245" target="_blank">arXiv:2010.03245</a> [<a href="http://arxiv.org/pdf/2010.03245" target="_blank">pdf</a>]

<h2>Reconfigurable Intelligent Surfaces and Machine Learning for Wireless Fingerprinting Localization. (arXiv:2010.03251v1 [eess.SP])</h2>
<h3>Cam Ly Nguyen, Orestis Georgiou, Gabriele Gradoni</h3>
<p>Reconfigurable Intelligent Surfaces (RISs) promise improved, secure and more
efficient wireless communications. We propose and demonstrate how to exploit
the diversity offered by RISs to generate and select easily differentiable
radio maps for use in wireless fingerprinting localization applications.
Further, we apply machine learning feature selection methods to prune the large
state space of the RIS, thus reducing complexity and enhancing localization
accuracy and position acquisition time. We evaluate our proposed approach by
generation of radio maps with a novel radio propagation modelling and
simulations.
</p>
<a href="http://arxiv.org/abs/2010.03251" target="_blank">arXiv:2010.03251</a> [<a href="http://arxiv.org/pdf/2010.03251" target="_blank">pdf</a>]

<h2>Variational Transfer Learning for Fine-grained Few-shot Visual Recognition. (arXiv:2010.03255v1 [cs.CV])</h2>
<h3>Jingyi Xu, Mingzhen Huang, ShahRukh Athar, Dimitris Samaras</h3>
<p>Fine-grained few-shot recognition often suffers from the problem of training
data scarcity for novel categories.The network tends to overfit and does not
generalize well to unseen classes due to insufficient training data. Many
methods have been proposed to synthesize additional data to support the
training. In this paper, we focus one enlarging the intra-class variance of the
unseen class to improve few-shot classification performance. We assume that the
distribution of intra-class variance generalizes across the base class and the
novel class. Thus, the intra-class variance of the base set can be transferred
to the novel set for feature augmentation. Specifically, we first model the
distribution of intra-class variance on the base set via variational inference.
Then the learned distribution is transferred to the novel set to generate
additional features, which are used together with the original ones to train a
classifier. Experimental results show a significant boost over the
state-of-the-art methods on the challenging fine-grained few-shot image
classification benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.03255" target="_blank">arXiv:2010.03255</a> [<a href="http://arxiv.org/pdf/2010.03255" target="_blank">pdf</a>]

<h2>Learning Binary Semantic Embedding for Histology Image Classification and Retrieval. (arXiv:2010.03266v1 [cs.CV])</h2>
<h3>Xiao Kang, Xingbo Liu, Xiushan Nie, Yilong Yin</h3>
<p>With the development of medical imaging technology and machine learning,
computer-assisted diagnosis which can provide impressive reference to
pathologists, attracts extensive research interests. The exponential growth of
medical images and uninterpretability of traditional classification models have
hindered the applications of computer-assisted diagnosis. To address these
issues, we propose a novel method for Learning Binary Semantic Embedding
(LBSE). Based on the efficient and effective embedding, classification and
retrieval are performed to provide interpretable computer-assisted diagnosis
for histology images. Furthermore, double supervision, bit uncorrelation and
balance constraint, asymmetric strategy and discrete optimization are
seamlessly integrated in the proposed method for learning binary embedding.
Experiments conducted on three benchmark datasets validate the superiority of
LBSE under various scenarios.
</p>
<a href="http://arxiv.org/abs/2010.03266" target="_blank">arXiv:2010.03266</a> [<a href="http://arxiv.org/pdf/2010.03266" target="_blank">pdf</a>]

<h2>Low-Rank Robust Online Distance/Similarity Learning based on the Rescaled Hinge Loss. (arXiv:2010.03268v1 [cs.LG])</h2>
<h3>Davood Zabihzadeh, Ali Karami-Mollaee</h3>
<p>An important challenge in metric learning is scalability to both size and
dimension of input data. Online metric learning algorithms are proposed to
address this challenge. Existing methods are commonly based on (Passive
Aggressive) PA approach. Hence, they can rapidly process large volumes of data
with an adaptive learning rate. However, these algorithms are based on the
Hinge loss and so are not robust against outliers and label noise. Also,
existing online methods usually assume training triplets or pairwise
constraints are exist in advance. However, many datasets in real-world
applications are in the form of input data and their associated labels. We
address these challenges by formulating the online Distance-Similarity learning
problem with the robust Rescaled hinge loss function. The proposed model is
rather general and can be applied to any PA-based online Distance-Similarity
algorithm. Also, we develop an efficient robust one-pass triplet construction
algorithm. Finally, to provide scalability in high dimensional DML
environments, the low-rank version of the proposed methods is presented that
not only reduces the computational cost significantly but also keeps the
predictive performance of the learned metrics. Also, it provides a
straightforward extension of our methods for deep Distance-Similarity learning.
We conduct several experiments on datasets from various applications. The
results confirm that the proposed methods significantly outperform
state-of-the-art online DML methods in the presence of label noise and outliers
by a large margin.
</p>
<a href="http://arxiv.org/abs/2010.03268" target="_blank">arXiv:2010.03268</a> [<a href="http://arxiv.org/pdf/2010.03268" target="_blank">pdf</a>]

<h2>Attention Model Enhanced Network for Classification of Breast Cancer Image. (arXiv:2010.03271v1 [cs.CV])</h2>
<h3>Xiao Kang, Xingbo Liu, Xiushan Nie, Xiaoming Xi, Yilong Yin</h3>
<p>Breast cancer classification remains a challenging task due to inter-class
ambiguity and intra-class variability. Existing deep learning-based methods try
to confront this challenge by utilizing complex nonlinear projections. However,
these methods typically extract global features from entire images, neglecting
the fact that the subtle detail information can be crucial in extracting
discriminative features. In this study, we propose a novel method named
Attention Model Enhanced Network (AMEN), which is formulated in a multi-branch
fashion with pixel-wised attention model and classification submodular.
Specifically, the feature learning part in AMEN can generate pixel-wised
attention map, while the classification submodular are utilized to classify the
samples. To focus more on subtle detail information, the sample image is
enhanced by the pixel-wised attention map generated from former branch.
Furthermore, boosting strategy are adopted to fuse classification results from
different branches for better performance. Experiments conducted on three
benchmark datasets demonstrate the superiority of the proposed method under
various scenarios.
</p>
<a href="http://arxiv.org/abs/2010.03271" target="_blank">arXiv:2010.03271</a> [<a href="http://arxiv.org/pdf/2010.03271" target="_blank">pdf</a>]

<h2>Narrative Text Generation with a Latent Discrete Plan. (arXiv:2010.03272v1 [cs.CL])</h2>
<h3>Harsh Jhamtani, Taylor Berg-Kirkpatrick</h3>
<p>Past work on story generation has demonstrated the usefulness of conditioning
on a generation plan to generate coherent stories. However, these approaches
have used heuristics or off-the-shelf models to first tag training stories with
the desired type of plan, and then train generation models in a supervised
fashion. In this paper, we propose a deep latent variable model that first
samples a sequence of anchor words, one per sentence in the story, as part of
its generative process. During training, our model treats the sequence of
anchor words as a latent variable and attempts to induce anchoring sequences
that help guide generation in an unsupervised fashion. We conduct experiments
with several types of sentence decoder distributions: left-to-right and
non-monotonic, with different degrees of restriction. Further, since we use
amortized variational inference to train our model, we introduce two
corresponding types of inference network for predicting the posterior on anchor
words. We conduct human evaluations which demonstrate that the stories produced
by our model are rated better in comparison with baselines which do not
consider story plans, and are similar or better in quality relative to
baselines which use external supervision for plans. Additionally, the proposed
model gets favorable scores when evaluated on perplexity, diversity, and
control of story via discrete plan.
</p>
<a href="http://arxiv.org/abs/2010.03272" target="_blank">arXiv:2010.03272</a> [<a href="http://arxiv.org/pdf/2010.03272" target="_blank">pdf</a>]

<h2>Learning to Explain: Datasets and Models for Identifying Valid Reasoning Chains in Multihop Question-Answering. (arXiv:2010.03274v1 [cs.CL])</h2>
<h3>Harsh Jhamtani, Peter Clark</h3>
<p>Despite the rapid progress in multihop question-answering (QA), models still
have trouble explaining why an answer is correct, with limited explanation
training data available to learn from. To address this, we introduce three
explanation datasets in which explanations formed from corpus facts are
annotated. Our first dataset, eQASC, contains over 98K explanation annotations
for the multihop question answering dataset QASC, and is the first that
annotates multiple candidate explanations for each answer. The second dataset
eQASC-perturbed is constructed by crowd-sourcing perturbations (while
preserving their validity) of a subset of explanations in QASC, to test
consistency and generalization of explanation prediction models. The third
dataset eOBQA is constructed by adding explanation annotations to the OBQA
dataset to test generalization of models trained on eQASC. We show that this
data can be used to significantly improve explanation quality (+14% absolute F1
over a strong retrieval baseline) using a BERT-based classifier, but still
behind the upper bound, offering a new challenge for future research. We also
explore a delexicalized chain representation in which repeated noun phrases are
replaced by variables, thus turning them into generalized reasoning chains (for
example: "X is a Y" AND "Y has Z" IMPLIES "X has Z"). We find that generalized
chains maintain performance while also being more robust to certain
perturbations.
</p>
<a href="http://arxiv.org/abs/2010.03274" target="_blank">arXiv:2010.03274</a> [<a href="http://arxiv.org/pdf/2010.03274" target="_blank">pdf</a>]

<h2>ZEST: Zero-shot Learning from Text Descriptions using Textual Similarity and Visual Summarization. (arXiv:2010.03276v1 [cs.CL])</h2>
<h3>Tzuf Paz-Argaman, Yuval Atzmon, Gal Chechik, Reut Tsarfaty</h3>
<p>We study the problem of recognizing visual entities from the textual
descriptions of their classes. Specifically, given birds' images with free-text
descriptions of their species, we learn to classify images of previously-unseen
species based on specie descriptions. This setup has been studied in the vision
community under the name zero-shot learning from text, focusing on learning to
transfer knowledge about visual aspects of birds from seen classes to
previously-unseen ones. Here, we suggest focusing on the textual description
and distilling from the description the most relevant information to
effectively match visual features to the parts of the text that discuss them.
Specifically, (1) we propose to leverage the similarity between species,
reflected in the similarity between text descriptions of the species. (2) we
derive visual summaries of the texts, i.e., extractive summaries that focus on
the visual features that tend to be reflected in images. We propose a simple
attention-based model augmented with the similarity and visual summaries
components. Our empirical results consistently and significantly outperform the
state-of-the-art on the largest benchmarks for text-based zero-shot learning,
illustrating the critical importance of texts for zero-shot image-recognition.
</p>
<a href="http://arxiv.org/abs/2010.03276" target="_blank">arXiv:2010.03276</a> [<a href="http://arxiv.org/pdf/2010.03276" target="_blank">pdf</a>]

<h2>Variational Intrinsic Control Revisited. (arXiv:2010.03281v1 [cs.LG])</h2>
<h3>Taehwan Kwon</h3>
<p>In this paper, we revisit variational intrinsic control (VIC), an
unsupervised reinforcement learning method for finding the largest set of
intrinsic options available to an agent. In the original work by Gregor et al.
(2016), two VIC algorithms were proposed: one that represents the options
explicitly, and the other that does it implicitly. We show that the intrinsic
reward used in the latter is subject to bias in stochastic environments,
causing convergence to suboptimal solutions. To correct this behavior, we
propose two methods respectively based on the transitional probability model
and Gaussian Mixture Model. We substantiate our claims through rigorous
mathematical derivations and experimental analyses.
</p>
<a href="http://arxiv.org/abs/2010.03281" target="_blank">arXiv:2010.03281</a> [<a href="http://arxiv.org/pdf/2010.03281" target="_blank">pdf</a>]

<h2>Don't Trigger Me! A Triggerless Backdoor Attack Against Deep Neural Networks. (arXiv:2010.03282v1 [cs.CR])</h2>
<h3>Ahmed Salem, Michael Backes, Yang Zhang</h3>
<p>Backdoor attack against deep neural networks is currently being profoundly
investigated due to its severe security consequences. Current state-of-the-art
backdoor attacks require the adversary to modify the input, usually by adding a
trigger to it, for the target model to activate the backdoor. This added
trigger not only increases the difficulty of launching the backdoor attack in
the physical world, but also can be easily detected by multiple defense
mechanisms. In this paper, we present the first triggerless backdoor attack
against deep neural networks, where the adversary does not need to modify the
input for triggering the backdoor. Our attack is based on the dropout
technique. Concretely, we associate a set of target neurons that are dropped
out during model training with the target label. In the prediction phase, the
model will output the target label when the target neurons are dropped again,
i.e., the backdoor attack is launched. This triggerless feature of our attack
makes it practical in the physical world. Extensive experiments show that our
triggerless backdoor attack achieves a perfect attack success rate with a
negligible damage to the model's utility.
</p>
<a href="http://arxiv.org/abs/2010.03282" target="_blank">arXiv:2010.03282</a> [<a href="http://arxiv.org/pdf/2010.03282" target="_blank">pdf</a>]

<h2>Less is more: Faster and better music version identification with embedding distillation. (arXiv:2010.03284v1 [cs.SD])</h2>
<h3>Furkan Yesiler, Joan Serr&#xe0;, Emilia G&#xf3;mez</h3>
<p>Version identification systems aim to detect different renditions of the same
underlying musical composition (loosely called cover songs). By learning to
encode entire recordings into plain vector embeddings, recent systems have made
significant progress in bridging the gap between accuracy and scalability,
which has been a key challenge for nearly two decades. In this work, we propose
to further narrow this gap by employing a set of data distillation techniques
that reduce the embedding dimensionality of a pre-trained state-of-the-art
model. We compare a wide range of techniques and propose new ones, from
classical dimensionality reduction to more sophisticated distillation schemes.
With those, we obtain 99% smaller embeddings that, moreover, yield up to a 3%
accuracy increase. Such small embeddings can have an important impact in
retrieval time, up to the point of making a real-world system practical on a
standalone laptop.
</p>
<a href="http://arxiv.org/abs/2010.03284" target="_blank">arXiv:2010.03284</a> [<a href="http://arxiv.org/pdf/2010.03284" target="_blank">pdf</a>]

<h2>Double Targeted Universal Adversarial Perturbations. (arXiv:2010.03288v1 [cs.LG])</h2>
<h3>Philipp Benz, Chaoning Zhang, Tooba Imtiaz, In So Kweon</h3>
<p>Despite their impressive performance, deep neural networks (DNNs) are widely
known to be vulnerable to adversarial attacks, which makes it challenging for
them to be deployed in security-sensitive applications, such as autonomous
driving. Image-dependent perturbations can fool a network for one specific
image, while universal adversarial perturbations are capable of fooling a
network for samples from all classes without selection. We introduce a double
targeted universal adversarial perturbations (DT-UAPs) to bridge the gap
between the instance-discriminative image-dependent perturbations and the
generic universal perturbations. This universal perturbation attacks one
targeted source class to sink class, while having a limited adversarial effect
on other non-targeted source classes, for avoiding raising suspicions.
Targeting the source and sink class simultaneously, we term it double targeted
attack (DTA). This provides an attacker with the freedom to perform precise
attacks on a DNN model while raising little suspicion. We show the
effectiveness of the proposed DTA algorithm on a wide range of datasets and
also demonstrate its potential as a physical attack.
</p>
<a href="http://arxiv.org/abs/2010.03288" target="_blank">arXiv:2010.03288</a> [<a href="http://arxiv.org/pdf/2010.03288" target="_blank">pdf</a>]

<h2>QarSUMO: A Parallel, Congestion-optimized Traffic Simulator. (arXiv:2010.03289v1 [cs.DC])</h2>
<h3>Hao Chen, Ke Yang, Stefano Giovanni Rizzo, Giovanna Vantini, Phillip Taylor, Xiaosong Ma, Sanjay Chawla</h3>
<p>Traffic simulators are important tools for tasks such as urban planning and
transportation management. Microscopic simulators allow per-vehicle movement
simulation, but require longer simulation time. The simulation overhead is
exacerbated when there is traffic congestion and most vehicles move slowly.
This in particular hurts the productivity of emerging urban computing studies
based on reinforcement learning, where traffic simulations are heavily and
repeatedly used for designing policies to optimize traffic related tasks.

In this paper, we develop QarSUMO, a parallel, congestion-optimized version
of the popular SUMO open-source traffic simulator. QarSUMO performs high-level
parallelization on top of SUMO, to utilize powerful multi-core servers and
enables future extension to multi-node parallel simulation if necessary. The
proposed design, while partly sacrificing speedup, makes QarSUMO compatible
with future SUMO improvements. We further contribute such an improvement by
modifying the SUMO simulation engine for congestion scenarios where the update
computation of consecutive and slow-moving vehicles can be simplified.

We evaluate QarSUMO with both real-world and synthetic road network and
traffic data, and examine its execution time as well as simulation accuracy
relative to the original, sequential SUMO.
</p>
<a href="http://arxiv.org/abs/2010.03289" target="_blank">arXiv:2010.03289</a> [<a href="http://arxiv.org/pdf/2010.03289" target="_blank">pdf</a>]

<h2>Proximal Policy Optimization with Relative Pearson Divergence. (arXiv:2010.03290v1 [cs.LG])</h2>
<h3>Taisuke Kobayashi</h3>
<p>Deep reinforcement learning (DRL) is one of the promising approaches for
introducing robots into complicated environments. The recent remarkable
progress of DRL stands on regularization of policy. By constraining the update
of policy, DRL allows the policy to improve stably and efficiently. Among them,
a popular method, named proximal policy optimization (PPO), has been
introduced. PPO clips density ratio of the latest and baseline policies with a
threshold, while its minimization target is unclear. As another problem of PPO,
the symmetric threshold is given numerically while the density ratio itself is
in asymmetric domain, thereby causing unbalanced regularization of the policy.
This paper therefore proposes a new variant of PPO by considering a
regularization problem of relative Pearson (RPE) divergence, so-called PPO-RPE.
This regularization yields the clear minimization target, which constrains the
latest policy to the baseline one. Through its analysis, the intuitive
threshold-based design consistent with the asymmetry of the threshold and the
domain of density ratio can be derived. Four benchmark tasks were simulated to
compare PPO-RPE and the conventional methods. As a result, PPO-RPE outperformed
the conventional methods on all the tasks in terms of the task performance by
the learned policy.
</p>
<a href="http://arxiv.org/abs/2010.03290" target="_blank">arXiv:2010.03290</a> [<a href="http://arxiv.org/pdf/2010.03290" target="_blank">pdf</a>]

<h2>A Simple and Efficient Tensor Calculus for Machine Learning. (arXiv:2010.03313v1 [cs.LG])</h2>
<h3>S&#xf6;ren Laue, Matthias Mitterreiter, Joachim Giesen</h3>
<p>Computing derivatives of tensor expressions, also known as tensor calculus,
is a fundamental task in machine learning. A key concern is the efficiency of
evaluating the expressions and their derivatives that hinges on the
representation of these expressions. Recently, an algorithm for computing
higher order derivatives of tensor expressions like Jacobians or Hessians has
been introduced that is a few orders of magnitude faster than previous
state-of-the-art approaches. Unfortunately, the approach is based on Ricci
notation and hence cannot be incorporated into automatic differentiation
frameworks from deep learning like TensorFlow, PyTorch, autograd, or JAX that
use the simpler Einstein notation. This leaves two options, to either change
the underlying tensor representation in these frameworks or to develop a new,
provably correct algorithm based on Einstein notation. Obviously, the first
option is impractical. Hence, we pursue the second option. Here, we show that
using Ricci notation is not necessary for an efficient tensor calculus and
develop an equally efficient method for the simpler Einstein notation. It turns
out that turning to Einstein notation enables further improvements that lead to
even better efficiency.

The methods that are described in this paper have been implemented in the
online tool www.MatrixCalculus.org for computing derivatives of matrix and
tensor expressions.

An extended abstract of this paper appeared as "A Simple and Efficient Tensor
Calculus", AAAI 2020.
</p>
<a href="http://arxiv.org/abs/2010.03313" target="_blank">arXiv:2010.03313</a> [<a href="http://arxiv.org/pdf/2010.03313" target="_blank">pdf</a>]

<h2>Batch Normalization Increases Adversarial Vulnerability: Disentangling Usefulness and Robustness of Model Features. (arXiv:2010.03316v1 [cs.LG])</h2>
<h3>Philipp Benz, Chaoning Zhang, In So Kweon</h3>
<p>Batch normalization (BN) has been widely used in modern deep neural networks
(DNNs) due to fast convergence. BN is observed to increase the model accuracy
while at the cost of adversarial robustness. We conjecture that the increased
adversarial vulnerability is caused by BN shifting the model to rely more on
non-robust features (NRFs). Our exploration finds that other normalization
techniques also increase adversarial vulnerability and our conjecture is also
supported by analyzing the model corruption robustness and feature
transferability. With a classifier DNN defined as a feature set $F$ we propose
a framework for disentangling $F$ robust usefulness into $F$ usefulness and $F$
robustness. We adopt a local linearity based metric, termed LIGS, to define and
quantify $F$ robustness. Measuring the $F$ robustness with the LIGS provides
direct insight on the feature robustness shift independent of usefulness.
Moreover, the LIGS trend during the whole training stage sheds light on the
order of learned features, i.e. from RFs (robust features) to NRFs, or vice
versa. Our work analyzes how BN and other factors influence the DNN from the
feature perspective. Prior works mainly adopt accuracy to evaluate their
influence regarding $F$ usefulness, while we believe evaluating $F$ robustness
is equally important, for which our work fills the gap.
</p>
<a href="http://arxiv.org/abs/2010.03316" target="_blank">arXiv:2010.03316</a> [<a href="http://arxiv.org/pdf/2010.03316" target="_blank">pdf</a>]

<h2>Rotation-Invariant Local-to-Global Representation Learning for 3D Point Cloud. (arXiv:2010.03318v1 [cs.CV])</h2>
<h3>Seohyun Kim, Jaeyoo Park, Bohyung Han</h3>
<p>We propose a local-to-global representation learning algorithm for 3D point
cloud data, which is appropriate to handle various geometric transformations,
especially rotation, without explicit data augmentation with respect to the
transformations. Our model takes advantage of multi-level abstraction based on
graph convolutional neural networks, which constructs a descriptor hierarchy to
encode rotation-invariant shape information of an input object in a bottom-up
manner. The descriptors in each level are obtained from neural networks based
on graphs via stochastic sampling of 3D points, which is effective to make the
learned representations robust to the variations of input data. The proposed
algorithm presents the state-of-the-art performance on the rotation-augmented
3D object recognition benchmarks and we further analyze its characteristics
through comprehensive ablative experiments.
</p>
<a href="http://arxiv.org/abs/2010.03318" target="_blank">arXiv:2010.03318</a> [<a href="http://arxiv.org/pdf/2010.03318" target="_blank">pdf</a>]

<h2>YOdar: Uncertainty-based Sensor Fusion for Vehicle Detection with Camera and Radar Sensors. (arXiv:2010.03320v1 [cs.CV])</h2>
<h3>Kamil Kowol, Matthias Rottmann, Stefan Bracke, Hanno Gottschalk</h3>
<p>In this work, we present an uncertainty-based method for sensor fusion with
camera and radar data. The outputs of two neural networks, one processing
camera and the other one radar data, are combined in an uncertainty aware
manner. To this end, we gather the outputs and corresponding meta information
for both networks. For each predicted object, the gathered information is
post-processed by a gradient boosting method to produce a joint prediction of
both networks. In our experiments we combine the YOLOv3 object detection
network with a customized $1D$ radar segmentation network and evaluate our
method on the nuScenes dataset. In particular we focus on night scenes, where
the capability of object detection networks based on camera data is potentially
handicapped. Our experiments show, that this approach of uncertainty aware
fusion, which is also of very modular nature, significantly gains performance
compared to single sensor baselines and is in range of specifically tailored
deep learning based fusion approaches.
</p>
<a href="http://arxiv.org/abs/2010.03320" target="_blank">arXiv:2010.03320</a> [<a href="http://arxiv.org/pdf/2010.03320" target="_blank">pdf</a>]

<h2>Automated Human Activity Recognition by Colliding Bodies Optimization-based Optimal Feature Selection with Recurrent Neural Network. (arXiv:2010.03324v1 [cs.LG])</h2>
<h3>Pankaj Khatiwada, Matrika Subedi, Ayan Chatterjee, Martin Wulf Gerdes</h3>
<p>In smart healthcare, Human Activity Recognition (HAR) is considered to be an
efficient model in pervasive computation from sensor readings. The Ambient
Assisted Living (AAL) in the home or community helps the people in providing
independent care and enhanced living quality. However, many AAL models were
restricted using many factors that include computational cost and system
complexity. Moreover, the HAR concept has more relevance because of its
applications. Hence, this paper tempts to implement the HAR system using deep
learning with the data collected from smart sensors that are publicly available
in the UC Irvine Machine Learning Repository (UCI). The proposed model involves
three processes: (1) Data collection, (b) Optimal feature selection, (c)
Recognition. The data gathered from the benchmark repository is initially
subjected to optimal feature selection that helps to select the most
significant features. The proposed optimal feature selection is based on a new
meta-heuristic algorithm called Colliding Bodies Optimization (CBO). An
objective function derived by the recognition accuracy is used for
accomplishing the optimal feature selection. Here, the deep learning model
called Recurrent Neural Network (RNN) is used for activity recognition. The
proposed model on the concerned benchmark dataset outperforms existing learning
methods, providing high performance compared to the conventional models.
</p>
<a href="http://arxiv.org/abs/2010.03324" target="_blank">arXiv:2010.03324</a> [<a href="http://arxiv.org/pdf/2010.03324" target="_blank">pdf</a>]

<h2>Contour Primitive of Interest Extraction Network Based on One-shot Learning for Object-Agnostic Vision Measurement. (arXiv:2010.03325v1 [cs.CV])</h2>
<h3>Fangbo Qin, Jie Qin, Siyu Huang, De Xu</h3>
<p>Image contour based vision measurement is widely applied in robot
manipulation and industrial automation. It is appealing to realize
object-agnostic vision system, which can be conveniently reused for various
types of objects. We propose the contour primitive of interest extraction
network (CPieNet) based on the one-shot learning framework. First, CPieNet is
featured by that its contour primitive of interest (CPI) output, a designated
regular contour part lying on a specified object, provides the essential
geometric information for vision measurement. Second, CPieNet has the one-shot
learning ability, utilizing a support sample to assist the perception of the
novel object. To realize lower-cost training, we generate support-query sample
pairs from unpaired online public images, which cover a wide range of object
categories. To obtain single-pixel wide contour for precise measurement, the
Gabor-filters based non-maximum suppression is designed to thin the raw
contour. For the novel CPI extraction task, we built the Object Contour
Primitives dataset using online public images, and the Robotic Object Contour
Measurement dataset using a camera mounted on a robot. The effectiveness of the
proposed methods is validated by a series of experiments.
</p>
<a href="http://arxiv.org/abs/2010.03325" target="_blank">arXiv:2010.03325</a> [<a href="http://arxiv.org/pdf/2010.03325" target="_blank">pdf</a>]

<h2>Deep Learning in Diabetic Foot Ulcers Detection: A Comprehensive Evaluation. (arXiv:2010.03341v1 [cs.CV])</h2>
<h3>Moi Hoon Yap, Ryo Hachiuma, Azadeh Alavi, Raphael Brungel, Manu Goyal, Hongtao Zhu, Bill Cassidy, Johannes Ruckert, Moshe Olshansky, Xiao Huang, Hideo Saito, Saeed Hassanpour, Christoph M. Friedrich, David Ascher, Anping Song, Hiroki Kajita, David Gillespie, Neil D. Reeves, Joseph Pappachan, Claire O&#x27;Shea, Eibe Frank</h3>
<p>There has been a substantial amount of research on computer methods and
technology for the detection and recognition of diabetic foot ulcers (DFUs),
but there is a lack of systematic comparisons of state-of-the-art deep learning
object detection frameworks applied to this problem. With recent development
and data sharing performed as part of the DFU Challenge (DFUC2020) such a
comparison becomes possible: DFUC2020 provided participants with a
comprehensive dataset consisting of 2,000 images for training each method and
2,000 images for testing them. The following deep learning-based algorithms are
compared in this paper: Faster R-CNN; three variants of Faster R-CNN; an
ensemble consisting of four models obtained using Faster R-CNN approaches;
YOLOv3; YOLOv5; EfficientDet; and a new Cascade Attention Network. These deep
learning methods achieved the best top 5 results in DFUC2020. For each deep
learning method, this paper provides a detailed description of obtaining the
model, including pre-processing, data augmentation, architecture, training and
post-processing, and parameter settings. We provide a comprehensive evaluation
for each method. All the methods required a data augmentation stage to increase
the number of images available for training and a post-processing stage to
remove false positives. The best performance is obtained by Deformable
Convolution, a variant of Faster R-CNN, with a mAP of 0.6940 and an F1-Score of
0.7434. Our results show that state-of-the-art deep learning methods can detect
DFU with some accuracy, but there are many challenges ahead before they can be
implemented in real world settings.
</p>
<a href="http://arxiv.org/abs/2010.03341" target="_blank">arXiv:2010.03341</a> [<a href="http://arxiv.org/pdf/2010.03341" target="_blank">pdf</a>]

<h2>Slice-Aware Neural Ranking. (arXiv:2010.03343v1 [cs.IR])</h2>
<h3>Gustavo Penha, Claudia Hauff</h3>
<p>Understanding when and why neural ranking models fail for an IR task via
error analysis is an important part of the research cycle. Here we focus on the
challenges of (i) identifying categories of difficult instances (a pair of
question and response candidates) for which a neural ranker is ineffective and
(ii) improving neural ranking for such instances. To address both challenges we
resort to slice-based learning for which the goal is to improve effectiveness
of neural models for slices (subsets) of data. We address challenge (i) by
proposing different slicing functions (SFs) that select slices of the
dataset---based on prior work we heuristically capture different failures of
neural rankers. Then, for challenge (ii) we adapt a neural ranking model to
learn slice-aware representations, i.e. the adapted model learns to represent
the question and responses differently based on the model's prediction of which
slices they belong to. Our experimental results (the source code and data are
available at https://github.com/Guzpenha/slice_based_learning) across three
different ranking tasks and four corpora show that slice-based learning
improves the effectiveness by an average of 2% over a neural ranker that is not
slice-aware.
</p>
<a href="http://arxiv.org/abs/2010.03343" target="_blank">arXiv:2010.03343</a> [<a href="http://arxiv.org/pdf/2010.03343" target="_blank">pdf</a>]

<h2>Decentralize the feedback infrastructure!. (arXiv:2010.03356v1 [cs.CY])</h2>
<h3>Pedro Garcia Lopez</h3>
<p>The decentralized architecture of Internet sparkled techno-utopian visions of
a virtual freedom space for humanity. Peer-to-peer systems, collaborative
creation (wikipedia), open source software (Linux), universal shared knowledge,
and the hopes for disintermediation contributed to this major vision.

However, the reality is bleak: centralization is reigning in the cyberspace,
with huge technological corporations controlling our data, and
re-intermediation and control are stronger than ever in the so-called "sharing"
economy. The Internet is also fragmented by countries, with many states
imposing heavy controls to information and communication services.

The XXI century will witness the major clash between centralization and
decentralization in human history. And the major struggle will be around the
communication and feedback technologies that will intermediate and govern every
interaction in our lives.

Unlike previous approaches that propose to socialize the feedback
infrastructure or to use anti-monopoly laws to break Big Tech companies, in
this article we advocate for the decentralization of the information and
communication infrastructure. And the key to this decentralization is the
creation of standards enabling interoperability between data platforms. This
will in turn produce a true disintermediation from well established
technological players and open competition to small third parties. In this
article, we sketch such a decentralized open infrastructure including
communication, sharing, matchmaking, and reputation services that can be
constructed over open source technologies and standards.
</p>
<a href="http://arxiv.org/abs/2010.03356" target="_blank">arXiv:2010.03356</a> [<a href="http://arxiv.org/pdf/2010.03356" target="_blank">pdf</a>]

<h2>Interpreting Imagined Speech Waves with Machine Learning techniques. (arXiv:2010.03360v1 [eess.SP])</h2>
<h3>Abhiram Singh, Ashwin Gumaste</h3>
<p>This work explores the possibility of decoding Imagined Speech (IS) signals
which can be used to create a new design of Human-Computer Interface (HCI).
Since the underlying process generating EEG signals is unknown, various feature
extraction methods, along with different neural network (NN) models, are used
to approximate data distribution and classify IS signals. Based on the
experimental results, feed-forward NN model with ensemble and covariance matrix
transformed features showed the highest performance in comparison to other
existing methods. For comparison, three publicly available datasets were used.
We report a mean classification accuracy of 80% between rest and imagined
state, 96% and 80% for decoding long and short words on two datasets. These
results show that it is possible to differentiate brain signals (generated
during rest state) from the IS brain signals. Based on the experimental
results, we suggest that the word length and complexity can be used to decode
IS signals with high accuracy, and a BCI system can be designed with IS signals
for computer interaction. These ideas, and results give direction for the
development of a commercial level IS based BCI system, which can be used for
human-computer interaction in daily life.
</p>
<a href="http://arxiv.org/abs/2010.03360" target="_blank">arXiv:2010.03360</a> [<a href="http://arxiv.org/pdf/2010.03360" target="_blank">pdf</a>]

<h2>A study on using image based machine learning methods to develop the surrogate models of stamp forming simulations. (arXiv:2010.03370v1 [cs.CV])</h2>
<h3>Haosu Zhou, Qingfeng Xu, Nan Li</h3>
<p>In the design optimization of metal forming, it is increasingly significant
to use surrogate models to analyse the finite element analysis (FEA)
simulations. However, traditional surrogate models using scalar based machine
learning methods (SBMLMs) fall in short of accuracy and generalizability. This
is because SBMLMs fail to harness the location information of the simulations.
To overcome these shortcomings, image based machine learning methods (IBMLMs)
are leveraged in this paper. The underlying theory of location information,
which supports the advantages of IBMLM, is qualitatively interpreted. Based on
this theory, a Res-SE-U-Net IBMLM surrogate model is developed and compared
with a multi-layer perceptron (MLP) as a referencing SBMLM surrogate model. It
is demonstrated that the IBMLM model is advantageous over the MLP SBMLM model
in accuracy, generalizability, robustness, and informativeness. This paper
presents a promising methodology of leveraging IBMLMs in surrogate models to
make maximum use of info from FEA results. Future prospective studies that
inspired by this paper are also discussed.
</p>
<a href="http://arxiv.org/abs/2010.03370" target="_blank">arXiv:2010.03370</a> [<a href="http://arxiv.org/pdf/2010.03370" target="_blank">pdf</a>]

<h2>Why do you think that? Exploring Faithful Sentence-Level Rationales Without Supervision. (arXiv:2010.03384v1 [cs.CL])</h2>
<h3>Max Glockner, Ivan Habernal, Iryna Gurevych</h3>
<p>Evaluating the trustworthiness of a model's prediction is essential for
differentiating between `right for the right reasons' and `right for the wrong
reasons'. Identifying textual spans that determine the target label, known as
faithful rationales, usually relies on pipeline approaches or reinforcement
learning. However, such methods either require supervision and thus costly
annotation of the rationales or employ non-differentiable models. We propose a
differentiable training-framework to create models which output faithful
rationales on a sentence level, by solely applying supervision on the target
task. To achieve this, our model solves the task based on each rationale
individually and learns to assign high scores to those which solved the task
best. Our evaluation on three different datasets shows competitive results
compared to a standard BERT blackbox while exceeding a pipeline counterpart's
performance in two cases. We further exploit the transparent decision-making
process of these models to prefer selecting the correct rationales by applying
direct supervision, thereby boosting the performance on the rationale-level.
</p>
<a href="http://arxiv.org/abs/2010.03384" target="_blank">arXiv:2010.03384</a> [<a href="http://arxiv.org/pdf/2010.03384" target="_blank">pdf</a>]

<h2>Universal Weighting Metric Learning for Cross-Modal Matching. (arXiv:2010.03403v1 [cs.CV])</h2>
<h3>Jiwei Wei, Xing Xu, Yang Yang, Yanli Ji, Zheng Wang, Heng Tao Shen</h3>
<p>Cross-modal matching has been a highlighted research topic in both vision and
language areas. Learning appropriate mining strategy to sample and weight
informative pairs is crucial for the cross-modal matching performance. However,
most existing metric learning methods are developed for unimodal matching,
which is unsuitable for cross-modal matching on multimodal data with
heterogeneous features. To address this problem, we propose a simple and
interpretable universal weighting framework for cross-modal matching, which
provides a tool to analyze the interpretability of various loss functions.
Furthermore, we introduce a new polynomial loss under the universal weighting
framework, which defines a weight function for the positive and negative
informative pairs respectively. Experimental results on two image-text matching
benchmarks and two video-text matching benchmarks validate the efficacy of the
proposed method.
</p>
<a href="http://arxiv.org/abs/2010.03403" target="_blank">arXiv:2010.03403</a> [<a href="http://arxiv.org/pdf/2010.03403" target="_blank">pdf</a>]

<h2>Machine learning for recovery factor estimation of an oil reservoir: a tool for de-risking at a hydrocarbon asset evaluation. (arXiv:2010.03408v1 [stat.AP])</h2>
<h3>Ivan Makhotin, Denis Orlov, Dmitry Koroteev, Evgeny Burnaev, Aram Karapetyan, Dmitry Antonenko</h3>
<p>Well known oil recovery factor estimation techniques such as analogy,
volumetric calculations, material balance, decline curve analysis, hydrodynamic
simulations have certain limitations. Those techniques are time-consuming,
require specific data and expert knowledge. Besides, though uncertainty
estimation is highly desirable for this problem, the methods above do not
include this by default. In this work, we present a data-driven technique for
oil recovery factor of hydrocarbon reservoirs using parameters and various
representative statistics. We apply advanced machine learning methods using
extensive historical worldwide oilfields datasets (more than 2000 oil
reservoirs). The data-driven model might be used as a general tool for rapid
and completely objective estimation of the oil recovery factor. In addition, it
includes the ability to work with partial input data and to estimate the
prediction interval of the oil recovery factor. We perform the evaluation in
terms of accuracy and prediction intervals coverage for several tree-based
machine learning techniques in application to the following two cases: (1)
using parameters only related to geometry, geology, transport, storage and
fluid properties, (2) using an extended set of parameters including development
and production data. For both cases model proved itself to be robust and
reliable. We conclude that the proposed data-driven approach overcomes several
limitations of the traditional methods and is suitable for rapid, reliable and
objective estimation of oil recovery factor for hydrocarbon reservoir.
</p>
<a href="http://arxiv.org/abs/2010.03408" target="_blank">arXiv:2010.03408</a> [<a href="http://arxiv.org/pdf/2010.03408" target="_blank">pdf</a>]

<h2>Learning Mesh-Based Simulation with Graph Networks. (arXiv:2010.03409v1 [cs.LG])</h2>
<h3>Tobias Pfaff, Meire Fortunato, Alvaro Sanchez-Gonzalez, Peter W. Battaglia</h3>
<p>Mesh-based simulations are central to modeling complex physical systems in
many disciplines across science and engineering. Mesh representations support
powerful numerical integration methods and their resolution can be adapted to
strike favorable trade-offs between accuracy and efficiency. However,
high-dimensional scientific simulations are very expensive to run, and solvers
and parameters must often be tuned individually to each system studied. Here we
introduce MeshGraphNets, a framework for learning mesh-based simulations using
graph neural networks. Our model can be trained to pass messages on a mesh
graph and to adapt the mesh discretization during forward simulation. Our
results show it can accurately predict the dynamics of a wide range of physical
systems, including aerodynamics, structural mechanics, and cloth. The model's
adaptivity supports learning resolution-independent dynamics and can scale to
more complex state spaces at test time. Our method is also highly efficient,
running 1-2 orders of magnitude faster than the simulation on which it is
trained. Our approach broadens the range of problems on which neural network
simulators can operate and promises to improve the efficiency of complex,
scientific modeling tasks.
</p>
<a href="http://arxiv.org/abs/2010.03409" target="_blank">arXiv:2010.03409</a> [<a href="http://arxiv.org/pdf/2010.03409" target="_blank">pdf</a>]

<h2>Dual Reconstruction: a Unifying Objective for Semi-Supervised Neural Machine Translation. (arXiv:2010.03412v1 [cs.CL])</h2>
<h3>Weijia Xu, Xing Niu, Marine Carpuat</h3>
<p>While Iterative Back-Translation and Dual Learning effectively incorporate
monolingual training data in neural machine translation, they use different
objectives and heuristic gradient approximation strategies, and have not been
extensively compared. We introduce a novel dual reconstruction objective that
provides a unified view of Iterative Back-Translation and Dual Learning. It
motivates a theoretical analysis and controlled empirical study on
German-English and Turkish-English tasks, which both suggest that Iterative
Back-Translation is more effective than Dual Learning despite its relative
simplicity.
</p>
<a href="http://arxiv.org/abs/2010.03412" target="_blank">arXiv:2010.03412</a> [<a href="http://arxiv.org/pdf/2010.03412" target="_blank">pdf</a>]

<h2>Learning Nonlinear Dynamics and Chaos: A Universal Framework for Knowledge-Based System Identification and Prediction. (arXiv:2010.03415v1 [nlin.CD])</h2>
<h3>Tom Z. Jiahao, M. Ani Hsieh, Eric Forgoston</h3>
<p>We present a universal framework for learning the behavior of dynamical
systems from observations. We formulate the learning task as a constrained
optimization problem which can be efficiently solved with the adjoint
sensitivity method. Our scheme is flexible with regards to the choice of model,
and existing knowledge can be readily incorporated for hybrid learning. We
demonstrate the effectiveness of our scheme by learning a variety of systems
including a stiff Van der Pol oscillator, a chaotic Lorenz system, and the
Kuramoto-Sivashinsky equation. We also include examples of hybrid learning and
learning from noisy observations.
</p>
<a href="http://arxiv.org/abs/2010.03415" target="_blank">arXiv:2010.03415</a> [<a href="http://arxiv.org/pdf/2010.03415" target="_blank">pdf</a>]

<h2>Deep Neural Network: An Efficient and Optimized Machine Learning Paradigm for Reducing Genome Sequencing Error. (arXiv:2010.03420v1 [q-bio.GN])</h2>
<h3>Ferdinand Kartriku, Dr. Robert Sowah, Charles Saah</h3>
<p>Genomic data I used in many fields but, it has become known that most of the
platforms used in the sequencing process produce significant errors. This means
that the analysis and inferences generated from these data may have some errors
that need to be corrected. On the two main types of genome errors -
substitution and indels - our work is focused on correcting indels. A deep
learning approach was used to correct the errors in sequencing the chosen
dataset
</p>
<a href="http://arxiv.org/abs/2010.03420" target="_blank">arXiv:2010.03420</a> [<a href="http://arxiv.org/pdf/2010.03420" target="_blank">pdf</a>]

<h2>Cross-lingual Extended Named Entity Classification of Wikipedia Articles. (arXiv:2010.03424v1 [cs.CL])</h2>
<h3>The Viet Bui, Phuong Le-Hong</h3>
<p>The FPT.AI team participated in the SHINRA2020-ML subtask of the NTCIR-15
SHINRA task. This paper describes our method to solving the problem and
discusses the official results. Our method focuses on learning cross-lingual
representations, both on the word level and document level for page
classification. We propose a three-stage approach including multilingual model
pre-training, monolingual model fine-tuning and cross-lingual voting. Our
system is able to achieve the best scores for 25 out of 30 languages; and its
accuracy gaps to the best performing systems of the other five languages are
relatively small.
</p>
<a href="http://arxiv.org/abs/2010.03424" target="_blank">arXiv:2010.03424</a> [<a href="http://arxiv.org/pdf/2010.03424" target="_blank">pdf</a>]

<h2>Exploiting non-i.i.d. data towards more robust machine learning algorithms. (arXiv:2010.03429v1 [cs.LG])</h2>
<h3>Wim Casteels, Peter Hellinckx</h3>
<p>In the field of machine learning there is a growing interest towards more
robust and generalizable algorithms. This is for example important to bridge
the gap between the environment in which the training data was collected and
the environment where the algorithm is deployed. Machine learning algorithms
have increasingly been shown to excel in finding patterns and correlations from
data. Determining the consistency of these patterns and for example the
distinction between causal correlations and nonsensical spurious relations has
proven to be much more difficult. In this paper a regularization scheme is
introduced that prefers universal causal correlations. This approach is based
on 1) the robustness of causal correlations and 2) the data not being
independently and identically distribute (i.i.d.). The scheme is demonstrated
with a classification task by clustering the (non-i.i.d.) training set in
subpopulations. A non-i.i.d. regularization term is then introduced that
penalizes weights that are not invariant over these clusters. The resulting
algorithm favours correlations that are universal over the subpopulations and
indeed a better performance is obtained on an out-of-distribution test set with
respect to a more conventional l_2-regularization.
</p>
<a href="http://arxiv.org/abs/2010.03429" target="_blank">arXiv:2010.03429</a> [<a href="http://arxiv.org/pdf/2010.03429" target="_blank">pdf</a>]

<h2>"I'd rather just go to bed": Understanding Indirect Answers. (arXiv:2010.03450v1 [cs.CL])</h2>
<h3>Annie Louis, Dan Roth, Filip Radlinski</h3>
<p>We revisit a pragmatic inference problem in dialog: understanding indirect
responses to questions. Humans can interpret 'I'm starving.' in response to
'Hungry?', even without direct cue words such as 'yes' and 'no'. In dialog
systems, allowing natural responses rather than closed vocabularies would be
similarly beneficial. However, today's systems are only as sensitive to these
pragmatic moves as their language model allows. We create and release the first
large-scale English language corpus 'Circa' with 34,268 (polar question,
indirect answer) pairs to enable progress on this task. The data was collected
via elaborate crowdsourcing, and contains utterances with yes/no meaning, as
well as uncertain, middle-ground, and conditional responses. We also present
BERT-based neural models to predict such categories for a question-answer pair.
We find that while transfer learning from entailment works reasonably,
performance is not yet sufficient for robust dialog. Our models reach 82-88%
accuracy for a 4-class distinction, and 74-85% for 6 classes.
</p>
<a href="http://arxiv.org/abs/2010.03450" target="_blank">arXiv:2010.03450</a> [<a href="http://arxiv.org/pdf/2010.03450" target="_blank">pdf</a>]

<h2>Learning disentangled representations with the Wasserstein Autoencoder. (arXiv:2010.03459v1 [stat.ML])</h2>
<h3>Benoit Gaujac, Ilya Feige, David Barber</h3>
<p>Disentangled representation learning has undoubtedly benefited from objective
function surgery. However, a delicate balancing act of tuning is still required
in order to trade off reconstruction fidelity versus disentanglement. Building
on previous successes of penalizing the total correlation in the latent
variables, we propose TCWAE (Total Correlation Wasserstein Autoencoder).
Working in the WAE paradigm naturally enables the separation of the
total-correlation term, thus providing disentanglement control over the learned
representation, while offering more flexibility in the choice of reconstruction
cost. We propose two variants using different KL estimators and perform
extensive quantitative comparisons on data sets with known generative factors,
showing competitive results relative to state-of-the-art techniques. We further
study the trade off between disentanglement and reconstruction on
more-difficult data sets with unknown generative factors, where the flexibility
of the WAE paradigm in the reconstruction term improves reconstructions.
</p>
<a href="http://arxiv.org/abs/2010.03459" target="_blank">arXiv:2010.03459</a> [<a href="http://arxiv.org/pdf/2010.03459" target="_blank">pdf</a>]

<h2>Learning Deep-Latent Hierarchies by Stacking Wasserstein Autoencoders. (arXiv:2010.03467v1 [stat.ML])</h2>
<h3>Benoit Gaujac, Ilya Feige, David Barber</h3>
<p>Probabilistic models with hierarchical-latent-variable structures provide
state-of-the-art results amongst non-autoregressive, unsupervised density-based
models. However, the most common approach to training such models based on
Variational Autoencoders (VAEs) often fails to leverage deep-latent
hierarchies; successful approaches require complex inference and optimisation
schemes. Optimal Transport is an alternative, non-likelihood-based framework
for training generative models with appealing theoretical properties, in
principle allowing easier training convergence between distributions. In this
work we propose a novel approach to training models with deep-latent
hierarchies based on Optimal Transport, without the need for highly bespoke
models and inference networks. We show that our method enables the generative
model to fully leverage its deep-latent hierarchy, avoiding the well known
"latent variable collapse" issue of VAEs; therefore, providing qualitatively
better sample generations as well as more interpretable latent representation
than the original Wasserstein Autoencoder with Maximum Mean Discrepancy
divergence.
</p>
<a href="http://arxiv.org/abs/2010.03467" target="_blank">arXiv:2010.03467</a> [<a href="http://arxiv.org/pdf/2010.03467" target="_blank">pdf</a>]

<h2>Discriminative Cross-Modal Data Augmentation for Medical Imaging Applications. (arXiv:2010.03468v1 [eess.IV])</h2>
<h3>Yue Yang, Pengtao Xie</h3>
<p>While deep learning methods have shown great success in medical image
analysis, they require a number of medical images to train. Due to data privacy
concerns and unavailability of medical annotators, it is oftentimes very
difficult to obtain a lot of labeled medical images for model training. In this
paper, we study cross-modality data augmentation to mitigate the data
deficiency issue in the medical imaging domain. We propose a discriminative
unpaired image-to-image translation model which translates images in source
modality into images in target modality where the translation task is conducted
jointly with the downstream prediction task and the translation is guided by
the prediction. Experiments on two applications demonstrate the effectiveness
of our method.
</p>
<a href="http://arxiv.org/abs/2010.03468" target="_blank">arXiv:2010.03468</a> [<a href="http://arxiv.org/pdf/2010.03468" target="_blank">pdf</a>]

<h2>Learning a Cost-Effective Annotation Policy for Question Answering. (arXiv:2010.03476v1 [cs.CL])</h2>
<h3>Bernhard Kratzwald, Stefan Feuerriegel, Huan Sun</h3>
<p>State-of-the-art question answering (QA) relies upon large amounts of
training data for which labeling is time consuming and thus expensive. For this
reason, customizing QA systems is challenging. As a remedy, we propose a novel
framework for annotating QA datasets that entails learning a cost-effective
annotation policy and a semi-supervised annotation scheme. The latter reduces
the human effort: it leverages the underlying QA system to suggest potential
candidate annotations. Human annotators then simply provide binary feedback on
these candidates. Our system is designed such that past annotations
continuously improve the future performance and thus overall annotation cost.
To the best of our knowledge, this is the first paper to address the problem of
annotating questions with minimal annotation cost. We compare our framework
against traditional manual annotations in an extensive set of experiments. We
find that our approach can reduce up to 21.1% of the annotation cost.
</p>
<a href="http://arxiv.org/abs/2010.03476" target="_blank">arXiv:2010.03476</a> [<a href="http://arxiv.org/pdf/2010.03476" target="_blank">pdf</a>]

<h2>CATBERT: Context-Aware Tiny BERT for Detecting Social Engineering Emails. (arXiv:2010.03484v1 [cs.CR])</h2>
<h3>Younghoo Lee, Joshua Saxe, Richard Harang</h3>
<p>Targeted phishing emails are on the rise and facilitate the theft of billions
of dollars from organizations a year. While malicious signals from attached
files or malicious URLs in emails can be detected by conventional malware
signatures or machine learning technologies, it is challenging to identify
hand-crafted social engineering emails which don't contain any malicious code
and don't share word choices with known attacks. To tackle this problem, we
fine-tune a pre-trained BERT model by replacing the half of Transformer blocks
with simple adapters to efficiently learn sophisticated representations of the
syntax and semantics of the natural language. Our Context-Aware network also
learns the context representations between email's content and context features
from email headers. Our CatBERT(Context-Aware Tiny Bert) achieves a 87%
detection rate as compared to DistilBERT, LSTM, and logistic regression
baselines which achieve 83%, 79%, and 54% detection rates at false positive
rates of 1%, respectively. Our model is also faster than competing transformer
approaches and is resilient to adversarial attacks which deliberately replace
keywords with typos or synonyms.
</p>
<a href="http://arxiv.org/abs/2010.03484" target="_blank">arXiv:2010.03484</a> [<a href="http://arxiv.org/pdf/2010.03484" target="_blank">pdf</a>]

<h2>Inductive Entity Representations from Text via Link Prediction. (arXiv:2010.03496v1 [cs.CL])</h2>
<h3>Daniel Daza, Michael Cochez, Paul Groth</h3>
<p>We present a method for learning representations of entities, that uses a
Transformer-based architecture as an entity encoder, and link prediction
training on a knowledge graph with textual entity descriptions. We demonstrate
that our approach can be applied effectively for link prediction in different
inductive settings involving entities not seen during training, outperforming
related state-of-the-art methods (22% MRR improvement on average). We provide
evidence that the learned representations transfer to other tasks that do not
require fine-tuning the entity encoder. In an entity classification task we
obtain an average improvement of 16% accuracy compared with baselines that also
employ pre-trained models. For an information retrieval task, significant
improvements of up to 8.8% in NDCG@10 were obtained for natural language
queries.
</p>
<a href="http://arxiv.org/abs/2010.03496" target="_blank">arXiv:2010.03496</a> [<a href="http://arxiv.org/pdf/2010.03496" target="_blank">pdf</a>]

<h2>Reconfigurable Cyber-Physical System for Lifestyle Video-Monitoring via Deep Learning. (arXiv:2010.03497v1 [cs.CV])</h2>
<h3>Daniel Deniz, Francisco Barranco, Juan Isern, Eduardo Ros</h3>
<p>Indoor monitoring of people at their homes has become a popular application
in Smart Health. With the advances in Machine Learning and hardware for
embedded devices, new distributed approaches for Cyber-Physical Systems (CPSs)
are enabled. Also, changing environments and need for cost reduction motivate
novel reconfigurable CPS architectures. In this work, we propose an indoor
monitoring reconfigurable CPS that uses embedded local nodes (Nvidia Jetson
TX2). We embed Deep Learning architectures to address Human Action Recognition.
Local processing at these nodes let us tackle some common issues: reduction of
data bandwidth usage and preservation of privacy (no raw images are
transmitted). Also real-time processing is facilitated since optimized nodes
compute only its local video feed. Regarding the reconfiguration, a remote
platform monitors CPS qualities and a Quality and Resource Management (QRM)
tool sends commands to the CPS core to trigger its reconfiguration. Our
proposal is an energy-aware system that triggers reconfiguration based on
energy consumption for battery-powered nodes. Reconfiguration reduces up to 22%
the local nodes energy consumption extending the device operating time,
preserving similar accuracy with respect to the alternative with no
reconfiguration.
</p>
<a href="http://arxiv.org/abs/2010.03497" target="_blank">arXiv:2010.03497</a> [<a href="http://arxiv.org/pdf/2010.03497" target="_blank">pdf</a>]

<h2>Learning from demonstration using products of experts: applications to manipulation and task prioritization. (arXiv:2010.03505v1 [cs.RO])</h2>
<h3>Emmanuel Pignat, Jo&#xe3;o Silv&#xe9;rio, Sylvain Calinon</h3>
<p>Probability distributions are key components of many learning from
demonstration (LfD) approaches. While the configuration of a manipulator is
defined by its joint angles, poses are often best explained within several task
spaces. In many approaches, distributions within relevant task spaces are
learned independently and only combined at the control level. This
simplification implies several problems that are addressed in this work. We
show that the fusion of models in different task spaces can be expressed as a
product of experts (PoE), where the probabilities of the models are multiplied
and renormalized so that it becomes a proper distribution of joint angles.
Multiple experiments are presented to show that learning the different models
jointly in the PoE framework significantly improves the quality of the model.
The proposed approach particularly stands out when the robot has to learn
competitive or hierarchical objectives. Training the model jointly usually
relies on contrastive divergence, which requires costly approximations that can
affect performance. We propose an alternative strategy using variational
inference and mixture model approximations. In particular, we show that the
proposed approach can be extended to PoE with a nullspace structure (PoENS),
where the model is able to recover tasks that are masked by the resolution of
higher-level objectives.
</p>
<a href="http://arxiv.org/abs/2010.03505" target="_blank">arXiv:2010.03505</a> [<a href="http://arxiv.org/pdf/2010.03505" target="_blank">pdf</a>]

<h2>Learning Monocular 3D Vehicle Detection without 3D Bounding Box Labels. (arXiv:2010.03506v1 [cs.CV])</h2>
<h3>L. Koestler, N. Yang, R. Wang, D. Cremers</h3>
<p>The training of deep-learning-based 3D object detectors requires large
datasets with 3D bounding box labels for supervision that have to be generated
by hand-labeling. We propose a network architecture and training procedure for
learning monocular 3D object detection without 3D bounding box labels. By
representing the objects as triangular meshes and employing differentiable
shape rendering, we define loss functions based on depth maps, segmentation
masks, and ego- and object-motion, which are generated by pre-trained,
off-the-shelf networks. We evaluate the proposed algorithm on the real-world
KITTI dataset and achieve promising performance in comparison to
state-of-the-art methods requiring 3D bounding box labels for training and
superior performance to conventional baseline methods.
</p>
<a href="http://arxiv.org/abs/2010.03506" target="_blank">arXiv:2010.03506</a> [<a href="http://arxiv.org/pdf/2010.03506" target="_blank">pdf</a>]

<h2>Abductive Knowledge Induction From Raw Data. (arXiv:2010.03514v1 [cs.AI])</h2>
<h3>Wang-Zhou Dai, Stephen H. Muggleton</h3>
<p>For many reasoning-heavy tasks, it is challenging to find an appropriate
end-to-end differentiable approximation to domain-specific inference
mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into
neural perception and symbolic reasoning, which can directly exploit general
domain knowledge such as algorithms and logic rules. However, it suffers from
the exponential computational complexity caused by the interface between the
two components, where the neural model lacks direct supervision, and the
symbolic model lacks accurate input facts. As a result, they usually focus on
learning the neural model with a sound and complete symbolic knowledge base
while avoiding a crucial problem: where does the knowledge come from? In this
paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which
unites abduction and induction to learn perceptual neural network and
first-order logic theories simultaneously from raw data. Given the same amount
of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the
compared end-to-end models in predictive accuracy and data efficiency but also
induces logic programs that can be re-used as background knowledge in
subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the
first system that can jointly learn neural networks and recursive first-order
logic theories with predicate invention.
</p>
<a href="http://arxiv.org/abs/2010.03514" target="_blank">arXiv:2010.03514</a> [<a href="http://arxiv.org/pdf/2010.03514" target="_blank">pdf</a>]

<h2>Combination of digital signal processing and assembled predictive models facilitates the rational design of proteins. (arXiv:2010.03516v1 [cs.CE])</h2>
<h3>David Medina-Ortiz, Sebastian Contreras, Juan Amado-Hinojosa, Jorge Torres-Almonacid, Juan A. Asenjo, Marcelo Navarrete, &#xc1;lvaro Olivera-Nappa</h3>
<p>Predicting the effect of mutations in proteins is one of the most critical
challenges in protein engineering; by knowing the effect a substitution of one
(or several) residues in the protein's sequence has on its overall properties,
could design a variant with a desirable function. New strategies and
methodologies to create predictive models are continually being developed.
However, those that claim to be general often do not reach adequate
performance, and those that aim to a particular task improve their predictive
performance at the cost of the method's generality. Moreover, these approaches
typically require a particular decision to encode the amino acidic sequence,
without an explicit methodological agreement in such endeavor. To address these
issues, in this work, we applied clustering, embedding, and dimensionality
reduction techniques to the AAIndex database to select meaningful combinations
of physicochemical properties for the encoding stage. We then used the chosen
set of properties to obtain several encodings of the same sequence, to
subsequently apply the Fast Fourier Transform (FFT) on them. We perform an
exploratory stage of Machine-Learning models in the frequency space, using
different algorithms and hyperparameters. Finally, we select the best
performing predictive models in each set of properties and create an assembled
model. We extensively tested the proposed methodology on different datasets and
demonstrated that the generated assembled model achieved notably better
performance metrics than those models based on a single encoding and, in most
cases, better than those previously reported. The proposed method is available
as a Python library for non-commercial use under the GNU General Public License
(GPLv3) license.
</p>
<a href="http://arxiv.org/abs/2010.03516" target="_blank">arXiv:2010.03516</a> [<a href="http://arxiv.org/pdf/2010.03516" target="_blank">pdf</a>]

<h2>A Survey of Deep Meta-Learning. (arXiv:2010.03522v1 [cs.LG])</h2>
<h3>Mike Huisman, Jan N. van Rijn, Aske Plaat</h3>
<p>Deep neural networks can achieve great successes when presented with large
data sets and sufficient computational resources. However, their ability to
learn new concepts quickly is quite limited. Meta-learning is one approach to
address this issue, by enabling the network to learn how to learn. The exciting
field of Deep Meta-Learning advances at great speed, but lacks a unified,
insightful overview of current techniques. This work presents just that. After
providing the reader with a theoretical foundation, we investigate and
summarize key methods, which are categorized into i) metric-, ii) model-, and
iii) optimization-based techniques. In addition, we identify the main open
challenges, such as performance evaluations on heterogeneous benchmarks, and
reduction of the computational costs of meta-learning.
</p>
<a href="http://arxiv.org/abs/2010.03522" target="_blank">arXiv:2010.03522</a> [<a href="http://arxiv.org/pdf/2010.03522" target="_blank">pdf</a>]

<h2>BoMuDA: Boundless Multi-Source Domain Adaptive Segmentation in Unconstrained Environments. (arXiv:2010.03523v1 [cs.CV])</h2>
<h3>Divya Kothandaraman, Rohan Chandra, Dinesh Manocha</h3>
<p>We present an unsupervised multi-source domain adaptive semantic segmentation
approach in unstructured and unconstrained traffic environments. We propose a
novel training strategy that alternates between single-source domain adaptation
(DA) and multi-source distillation, and also between setting up an improvised
cost function and optimizing it. In each iteration, the single-source DA first
learns a neural network on a selected source, which is followed by a
multi-source fine-tuning step using the remaining sources. We call this
training routine the Alternating-Incremental ("Alt-Inc") algorithm.
Furthermore, our approach is also boundless i.e. it can explicitly classify
categories that do not belong to the training dataset (as opposed to labeling
such objects as "unknown"). We have conducted extensive experiments and
ablation studies using the Indian Driving Dataset, CityScapes, Berkeley
DeepDrive, GTA V, and the Synscapes datasets, and we show that our unsupervised
approach outperforms other unsupervised and semi-supervised SOTA benchmarks by
5.17% - 42.9% with a reduced model size by up to 5.2x.
</p>
<a href="http://arxiv.org/abs/2010.03523" target="_blank">arXiv:2010.03523</a> [<a href="http://arxiv.org/pdf/2010.03523" target="_blank">pdf</a>]

<h2>Episodic Reinforcement Learning in Finite MDPs: Minimax Lower Bounds Revisited. (arXiv:2010.03531v1 [cs.LG])</h2>
<h3>Omar Darwiche Domingues, Pierre M&#xe9;nard, Emilie Kaufmann, Michal Valko</h3>
<p>In this paper, we propose new problem-independent lower bounds on the sample
complexity and regret in episodic MDPs, with a particular focus on the
non-stationary case in which the transition kernel is allowed to change in each
stage of the episode. Our main contribution is a novel lower bound of
$\Omega((H^3SA/\epsilon^2)\log(1/\delta))$ on the sample complexity of an
$(\varepsilon,\delta)$-PAC algorithm for best policy identification in a
non-stationary MDP. This lower bound relies on a construction of "hard MDPs"
which is different from the ones previously used in the literature. Using this
same class of MDPs, we also provide a rigorous proof of the
$\Omega(\sqrt{H^3SAT})$ regret bound for non-stationary MDPs. Finally, we
discuss connections to PAC-MDP lower bounds.
</p>
<a href="http://arxiv.org/abs/2010.03531" target="_blank">arXiv:2010.03531</a> [<a href="http://arxiv.org/pdf/2010.03531" target="_blank">pdf</a>]

<h2>Gradient Flow in Sparse Neural Networks and How Lottery Tickets Win. (arXiv:2010.03533v1 [cs.LG])</h2>
<h3>Utku Evci, Yani A. Ioannou, Cem Keskin, Yann Dauphin</h3>
<p>Sparse Neural Networks (NNs) can match the generalization of dense NNs using
a fraction of the compute/storage for inference, and also have the potential to
enable efficient training. However, naively training unstructured sparse NNs
from random initialization results in significantly worse generalization, with
the notable exception of Lottery Tickets (LTs) and Dynamic Sparse Training
(DST). In this work, we attempt to answer: (1) why training unstructured sparse
networks from random initialization performs poorly and; (2) what makes LTs and
DST the exceptions? We show that sparse NNs have poor gradient flow at
initialization and propose a modified initialization for unstructured
connectivity. Furthermore, we find that DST methods significantly improve
gradient flow during training over traditional sparse training methods.
Finally, we show that LTs do not improve gradient flow, rather their success
lies in re-learning the pruning solution they are derived from - however, this
comes at the cost of learning novel solutions.
</p>
<a href="http://arxiv.org/abs/2010.03533" target="_blank">arXiv:2010.03533</a> [<a href="http://arxiv.org/pdf/2010.03533" target="_blank">pdf</a>]

<h2>Galileo at SemEval-2020 Task 12: Multi-lingual Learning for Offensive Language Identification using Pre-trained Language Models. (arXiv:2010.03542v1 [cs.CL])</h2>
<h3>Shuohuan Wang, Jiaxiang Liu, Xuan Ouyang, Yu Sun</h3>
<p>This paper describes Galileo's performance in SemEval-2020 Task 12 on
detecting and categorizing offensive language in social media. For Offensive
Language Identification, we proposed a multi-lingual method using Pre-trained
Language Models, ERNIE and XLM-R. For offensive language categorization, we
proposed a knowledge distillation method trained on soft labels generated by
several supervised models. Our team participated in all three sub-tasks. In
Sub-task A - Offensive Language Identification, we ranked first in terms of
average F1 scores in all languages. We are also the only team which ranked
among the top three across all languages. We also took the first place in
Sub-task B - Automatic Categorization of Offense Types and Sub-task C - Offence
Target Identification.
</p>
<a href="http://arxiv.org/abs/2010.03542" target="_blank">arXiv:2010.03542</a> [<a href="http://arxiv.org/pdf/2010.03542" target="_blank">pdf</a>]

<h2>A Self-supervised Approach for Semantic Indexing in the Context of COVID-19 Pandemic. (arXiv:2010.03544v1 [cs.IR])</h2>
<h3>Nima Ebadi, Peyman Najafirad</h3>
<p>The pandemic has accelerated the pace at which COVID-19 scientific papers are
published. In addition, the process of manually assigning semantic indexes to
these papers by experts is even more time-consuming and overwhelming in the
current health crisis. Therefore, there is an urgent need for automatic
semantic indexing models which can effectively scale-up to newly introduced
concepts and rapidly evolving distributions of the hyperfocused related
literature. In this research, we present a novel semantic indexing approach
based on the state-of-the-art self-supervised representation learning and
transformer encoding exclusively suitable for pandemic crises. We present a
case study on a novel dataset that is based on COVID-19 papers published and
manually indexed in PubMed. Our study shows that our self-supervised model
outperforms the best performing models of BioASQ Task 8a by micro-F1 score of
0.1 and LCA-F score of 0.08 on average. Our model also shows superior
performance on detecting the supplementary concepts which is quite important
when the focus of the literature has drastically shifted towards specific
concepts related to the pandemic. Our study sheds light on the main challenges
confronting semantic indexing models during a pandemic, namely new domains and
drastic changes of their distributions, and as a superior alternative for such
situations, propose a model founded on approaches which have shown auspicious
performance in improving generalization and data efficiency in various NLP
tasks. We also show the joint indexing of major Medical Subject Headings (MeSH)
and supplementary concepts improves the overall performance.
</p>
<a href="http://arxiv.org/abs/2010.03544" target="_blank">arXiv:2010.03544</a> [<a href="http://arxiv.org/pdf/2010.03544" target="_blank">pdf</a>]

<h2>Low-Resource Domain Adaptation for Compositional Task-Oriented Semantic Parsing. (arXiv:2010.03546v1 [cs.CL])</h2>
<h3>Xilun Chen, Asish Ghoshal, Yashar Mehdad, Luke Zettlemoyer, Sonal Gupta</h3>
<p>Task-oriented semantic parsing is a critical component of virtual assistants,
which is responsible for understanding the user's intents (set reminder, play
music, etc.). Recent advances in deep learning have enabled several approaches
to successfully parse more complex queries (Gupta et al., 2018; Rongali et
al.,2020), but these models require a large amount of annotated training data
to parse queries on new domains (e.g. reminder, music).

In this paper, we focus on adapting task-oriented semantic parsers to
low-resource domains, and propose a novel method that outperforms a supervised
neural model at a 10-fold data reduction. In particular, we identify two
fundamental factors for low-resource domain adaptation: better representation
learning and better training techniques. Our representation learning uses BART
(Lewis et al., 2019) to initialize our model which outperforms encoder-only
pre-trained representations used in previous work. Furthermore, we train with
optimization-based meta-learning (Finn et al., 2017) to improve generalization
to low-resource domains. This approach significantly outperforms all baseline
methods in the experiments on a newly collected multi-domain task-oriented
semantic parsing dataset (TOPv2), which we release to the public.
</p>
<a href="http://arxiv.org/abs/2010.03546" target="_blank">arXiv:2010.03546</a> [<a href="http://arxiv.org/pdf/2010.03546" target="_blank">pdf</a>]

<h2>Probabilistic Case-based Reasoning for Open-World Knowledge Graph Completion. (arXiv:2010.03548v1 [cs.CL])</h2>
<h3>Rajarshi Das, Ameya Godbole, Nicholas Monath, Manzil Zaheer, Andrew McCallum</h3>
<p>A case-based reasoning (CBR) system solves a new problem by retrieving
`cases' that are similar to the given problem. If such a system can achieve
high accuracy, it is appealing owing to its simplicity, interpretability, and
scalability. In this paper, we demonstrate that such a system is achievable for
reasoning in knowledge-bases (KBs). Our approach predicts attributes for an
entity by gathering reasoning paths from similar entities in the KB. Our
probabilistic model estimates the likelihood that a path is effective at
answering a query about the given entity. The parameters of our model can be
efficiently computed using simple path statistics and require no iterative
optimization. Our model is non-parametric, growing dynamically as new entities
and relations are added to the KB. On several benchmark datasets our approach
significantly outperforms other rule learning approaches and performs
comparably to state-of-the-art embedding-based approaches. Furthermore, we
demonstrate the effectiveness of our model in an "open-world" setting where new
entities arrive in an online fashion, significantly outperforming
state-of-the-art approaches and nearly matching the best offline method. Code
available at https://github.com/ameyagodbole/Prob-CBR
</p>
<a href="http://arxiv.org/abs/2010.03548" target="_blank">arXiv:2010.03548</a> [<a href="http://arxiv.org/pdf/2010.03548" target="_blank">pdf</a>]

<h2>On the Evaluation of Generative Adversarial Networks By Discriminative Models. (arXiv:2010.03549v1 [cs.CV])</h2>
<h3>Amirsina Torfi, Mohammadreza Beyki, Edward A. Fox</h3>
<p>Generative Adversarial Networks (GANs) can accurately model complex
multi-dimensional data and generate realistic samples. However, due to their
implicit estimation of data distributions, their evaluation is a challenging
task. The majority of research efforts associated with tackling this issue were
validated by qualitative visual evaluation. Such approaches do not generalize
well beyond the image domain. Since many of those evaluation metrics are
proposed and bound to the vision domain, they are difficult to apply to other
domains. Quantitative measures are necessary to better guide the training and
comparison of different GANs models. In this work, we leverage Siamese neural
networks to propose a domain-agnostic evaluation metric: (1) with a qualitative
evaluation that is consistent with human evaluation, (2) that is robust
relative to common GAN issues such as mode dropping and invention, and (3) does
not require any pretrained classifier. The empirical results in this paper
demonstrate the superiority of this method compared to the popular Inception
Score and are competitive with the FID score.
</p>
<a href="http://arxiv.org/abs/2010.03549" target="_blank">arXiv:2010.03549</a> [<a href="http://arxiv.org/pdf/2010.03549" target="_blank">pdf</a>]

<h2>High-Capacity Expert Binary Networks. (arXiv:2010.03558v1 [cs.CV])</h2>
<h3>Adrian Bulat, Brais Martinez, Georgios Tzimiropoulos</h3>
<p>Network binarization is a promising hardware-aware direction for creating
efficient deep models. Despite its memory and computational advantages,
reducing the accuracy gap between such models and their real-valued
counterparts remains an unsolved challenging research problem. To this end, we
make the following 3 contributions: (a) To increase model capacity, we propose
Expert Binary Convolution, which, for the first time, tailors conditional
computing to binary networks by learning to select one data-specific expert
binary filter at a time conditioned on input features. (b) To increase
representation capacity, we propose to address the inherent information
bottleneck in binary networks by introducing an efficient width expansion
mechanism which keeps the binary operations within the same budget. (c) To
improve network design, we propose a principled binary network growth mechanism
that unveils a set of network topologies of favorable properties. Overall, our
method improves upon prior work, with no increase in computational cost by ~6%,
reaching a groundbreaking ~71% on ImageNet classification.
</p>
<a href="http://arxiv.org/abs/2010.03558" target="_blank">arXiv:2010.03558</a> [<a href="http://arxiv.org/pdf/2010.03558" target="_blank">pdf</a>]

<h2>Deep Neural Networks for Czech Multi-label Document Classification. (arXiv:1701.03849v3 [cs.CL] UPDATED)</h2>
<h3>Ladislav Lenc, Pavel Kr&#xe1;l</h3>
<p>This paper is focused on automatic multi-label document classification of
Czech text documents. The current approaches usually use some pre-processing
which can have negative impact (loss of information, additional implementation
work, etc). Therefore, we would like to omit it and use deep neural networks
that learn from simple features. This choice was motivated by their successful
usage in many other machine learning fields. Two different networks are
compared: the first one is a standard multi-layer perceptron, while the second
one is a popular convolutional network. The experiments on a Czech newspaper
corpus show that both networks significantly outperform baseline method which
uses a rich set of features with maximum entropy classifier. We have also shown
that convolutional network gives the best results.
</p>
<a href="http://arxiv.org/abs/1701.03849" target="_blank">arXiv:1701.03849</a> [<a href="http://arxiv.org/pdf/1701.03849" target="_blank">pdf</a>]

<h2>Two-level preconditioning for Ridge Regression. (arXiv:1806.05826v2 [cs.NA] UPDATED)</h2>
<h3>Joris Tavernier, Jaak Simm, Karl Meerbergen, Yves Moreau</h3>
<p>Solving linear systems is often the computational bottleneck in real-life
problems. Iterative solvers are the only option due to the complexity of direct
algorithms or because the system matrix is not explicitly known. Here, we
develop a two-level preconditioner for regularized least squares linear systems
involving a feature or data matrix. Variants of this linear system may appear
in machine learning applications, such as ridge regression, logistic
regression, support vector machines and Bayesian regression. We use clustering
algorithms to create a coarser level that preserves the principal components of
the covariance or Gram matrix. This coarser level approximates the dominant
eigenvectors and is used to build a subspace preconditioner accelerating the
Conjugate Gradient method. We observed speed-ups for artificial and real-life
data.
</p>
<a href="http://arxiv.org/abs/1806.05826" target="_blank">arXiv:1806.05826</a> [<a href="http://arxiv.org/pdf/1806.05826" target="_blank">pdf</a>]

<h2>Tuning Fairness by Balancing Target Labels. (arXiv:1810.05598v4 [stat.ML] UPDATED)</h2>
<h3>Thomas Kehrenberg, Zexun Chen, Novi Quadrianto</h3>
<p>The issue of fairness in machine learning models has recently attracted a lot
of attention as ensuring it will ensure continued confidence of the general
public in the deployment of machine learning systems. We focus on mitigating
the harm incurred by a biased machine learning system that offers better
outputs (e.g. loans, job interviews) for certain groups than for others. We
show that bias in the output can naturally be controlled in probabilistic
models by introducing a latent target output. This formulation has several
advantages: first, it is a unified framework for several notions of group
fairness such as Demographic Parity and Equality of Opportunity; second, it is
expressed as a marginalisation instead of a constrained problem; and third, it
allows the encoding of our knowledge of what unbiased outputs should be.
Practically, the second allows us to avoid unstable constrained optimisation
procedures and to reuse off-the-shelf toolboxes. The latter translates to the
ability to control the level of fairness by directly varying fairness target
rates. In contrast, existing approaches rely on intermediate, arguably
unintuitive, control parameters such as covariance thresholds.
</p>
<a href="http://arxiv.org/abs/1810.05598" target="_blank">arXiv:1810.05598</a> [<a href="http://arxiv.org/pdf/1810.05598" target="_blank">pdf</a>]

<h2>ConvS2S-VC: Fully convolutional sequence-to-sequence voice conversion. (arXiv:1811.01609v3 [cs.SD] UPDATED)</h2>
<h3>Hirokazu Kameoka, Kou Tanaka, Damian Kwasny, Takuhiro Kaneko, Nobukatsu Hojo</h3>
<p>This paper proposes a voice conversion (VC) method using sequence-to-sequence
(seq2seq or S2S) learning, which flexibly converts not only the voice
characteristics but also the pitch contour and duration of input speech. The
proposed method, called ConvS2S-VC, has three key features. First, it uses a
model with a fully convolutional architecture. This is particularly
advantageous in that it is suitable for parallel computations using GPUs. It is
also beneficial since it enables effective normalization techniques such as
batch normalization to be used for all the hidden layers in the networks.
Second, it achieves many-to-many conversion by simultaneously learning mappings
among multiple speakers using only a single model instead of separately
learning mappings between each speaker pair using a different model. This
enables the model to fully utilize available training data collected from
multiple speakers by capturing common latent features that can be shared across
different speakers. Owing to this structure, our model works reasonably well
even without source speaker information, thus making it able to handle
any-to-many conversion tasks. Third, we introduce a mechanism, called the
conditional batch normalization that switches batch normalization layers in
accordance with the target speaker. This particular mechanism has been found to
be extremely effective for our many-to-many conversion model. We conducted
speaker identity conversion experiments and found that ConvS2S-VC obtained
higher sound quality and speaker similarity than baseline methods. We also
found from audio examples that it could perform well in various tasks including
emotional expression conversion, electrolaryngeal speech enhancement, and
English accent conversion.
</p>
<a href="http://arxiv.org/abs/1811.01609" target="_blank">arXiv:1811.01609</a> [<a href="http://arxiv.org/pdf/1811.01609" target="_blank">pdf</a>]

<h2>An Efficient Solution to Non-Minimal Case Essential Matrix Estimation. (arXiv:1903.09067v3 [cs.CV] UPDATED)</h2>
<h3>Ji Zhao</h3>
<p>Finding relative pose between two calibrated images is a fundamental task in
computer vision. Given five point correspondences, the classical five-point
methods can be used to calculate the essential matrix efficiently. For the case
of $N$ ($N &gt; 5$) inlier point correspondences, which is called $N$-point
problem, existing methods are either inefficient or prone to local minima. In
this paper, we propose a certifiably globally optimal and efficient solver for
the $N$-point problem. First we formulate the problem as a quadratically
constrained quadratic program (QCQP). Then a certifiably globally optimal
solution to this problem is obtained by semidefinite relaxation. This allows us
to obtain certifiably globally optimal solutions to the original non-convex
QCQPs in polynomial time. The theoretical guarantees of the semidefinite
relaxation are also provided, including tightness and local stability. To deal
with outliers, we propose a robust $N$-point method using M-estimators. Though
global optimality cannot be guaranteed for the overall robust framework, the
proposed robust $N$-point method can achieve good performance when the outlier
ratio is not high. Extensive experiments on synthetic and real-world datasets
demonstrated that our $N$-point method is $2\sim3$ orders of magnitude faster
than state-of-the-art methods. Moreover, our robust $N$-point method
outperforms state-of-the-art methods in terms of robustness and accuracy.
</p>
<a href="http://arxiv.org/abs/1903.09067" target="_blank">arXiv:1903.09067</a> [<a href="http://arxiv.org/pdf/1903.09067" target="_blank">pdf</a>]

<h2>Stochastically Dominant Distributional Reinforcement Learning. (arXiv:1905.07318v4 [cs.LG] UPDATED)</h2>
<h3>John D. Martin, Michal Lyskawinski, Xiaohu Li, Brendan Englot</h3>
<p>We describe a new approach for managing aleatoric uncertainty in the
Reinforcement Learning (RL) paradigm. Instead of selecting actions according to
a single statistic, we propose a distributional method based on the
second-order stochastic dominance (SSD) relation. This compares the inherent
dispersion of random returns induced by actions, producing a more comprehensive
and robust evaluation of the environment's uncertainty. The necessary
conditions for SSD require estimators to predict accurate second moments. To
accommodate this, we map the distributional RL problem to a Wasserstein
gradient flow, treating the distributional Bellman residual as a potential
energy functional. We propose a particle-based algorithm for which we prove
optimality and convergence. Our experiments characterize the algorithm
performance and demonstrate how uncertainty and performance are better balanced
using an \textsc{ssd} policy than with other risk measures.
</p>
<a href="http://arxiv.org/abs/1905.07318" target="_blank">arXiv:1905.07318</a> [<a href="http://arxiv.org/pdf/1905.07318" target="_blank">pdf</a>]

<h2>Parsing All: Syntax and Semantics, Dependencies and Spans. (arXiv:1908.11522v3 [cs.CL] UPDATED)</h2>
<h3>Junru Zhou, Zuchao Li, Hai Zhao</h3>
<p>Both syntactic and semantic structures are key linguistic contextual clues,
in which parsing the latter has been well shown beneficial from parsing the
former. However, few works ever made an attempt to let semantic parsing help
syntactic parsing. As linguistic representation formalisms, both syntax and
semantics may be represented in either span (constituent/phrase) or dependency,
on both of which joint learning was also seldom explored. In this paper, we
propose a novel joint model of syntactic and semantic parsing on both span and
dependency representations, which incorporates syntactic information
effectively in the encoder of neural network and benefits from two
representation formalisms in a uniform way. The experiments show that semantics
and syntax can benefit each other by optimizing joint objectives. Our single
model achieves new state-of-the-art or competitive results on both span and
dependency semantic parsing on Propbank benchmarks and both dependency and
constituent syntactic parsing on Penn Treebank.
</p>
<a href="http://arxiv.org/abs/1908.11522" target="_blank">arXiv:1908.11522</a> [<a href="http://arxiv.org/pdf/1908.11522" target="_blank">pdf</a>]

<h2>Estimating the potential for shared autonomous scooters. (arXiv:1909.03679v5 [cs.CY] UPDATED)</h2>
<h3>D&#xe1;niel Kondor, Xiaohu Zhang, Malika Meghjani, Paolo Santi, Jinhua Zhao, Carlo Ratti</h3>
<p>Recent technological developments have shown significant potential for
transforming urban mobility. Considering first- and last-mile travel and short
trips, the rapid adoption of dockless bike-share systems showed the possibility
of disruptive change, while simultaneously presenting new challenges, such as
fleet management or the use of public spaces. In this paper, we evaluate the
operational characteristics of a new class of shared vehicles that are being
actively developed in the industry: scooters with self-repositioning
capabilities. We do this by adapting the methodology of shareability networks
to a large-scale dataset of dockless bike-share usage, giving us estimates of
ideal fleet size under varying assumptions of fleet operations. We show that
the availability of self-repositioning capabilities can help achieve up to 10
times higher utilization of vehicles than possible in current bike-share
systems. We show that actual benefits will highly depend on the availability of
dedicated infrastructure, a key issue for scooter and bicycle use. Based on our
results, we envision that technological advances can present an opportunity to
rethink urban infrastructures and how transportation can be effectively
organized in cities.
</p>
<a href="http://arxiv.org/abs/1909.03679" target="_blank">arXiv:1909.03679</a> [<a href="http://arxiv.org/pdf/1909.03679" target="_blank">pdf</a>]

<h2>Minimal Learning Machine: Theoretical Results and Clustering-Based Reference Point Selection. (arXiv:1909.09978v2 [cs.LG] UPDATED)</h2>
<h3>Joonas H&#xe4;m&#xe4;l&#xe4;inen, Alisson S. C. Alencar, Tommi K&#xe4;rkk&#xe4;inen, C&#xe9;sar L. C. Mattos, Amauri H. Souza J&#xfa;nior, Jo&#xe3;o P. P. Gomes</h3>
<p>The Minimal Learning Machine (MLM) is a nonlinear supervised approach based
on learning a linear mapping between distance matrices computed in the input
and output data spaces, where distances are calculated using a subset of points
called reference points. Its simple formulation has attracted several recent
works on extensions and applications. In this paper, we aim to address some
open questions related to the MLM. First, we detail theoretical aspects that
assure the interpolation and universal approximation capabilities of the MLM,
which were previously only empirically verified. Second, we identify the task
of selecting reference points as having major importance for the MLM's
generalization capability. Several clustering-based methods for reference point
selection in regression scenarios are then proposed and analyzed. Based on an
extensive empirical evaluation, we conclude that the evaluated methods are both
scalable and useful. Specifically, for a small number of reference points, the
clustering-based methods outperformed the standard random selection of the
original MLM formulation.
</p>
<a href="http://arxiv.org/abs/1909.09978" target="_blank">arXiv:1909.09978</a> [<a href="http://arxiv.org/pdf/1909.09978" target="_blank">pdf</a>]

<h2>Imagine That! Leveraging Emergent Affordances for 3D Tool Synthesis. (arXiv:1909.13561v4 [cs.LG] UPDATED)</h2>
<h3>Yizhe Wu, Sudhanshu Kasewa, Oliver Groth, Sasha Salter, Li Sun, Oiwi Parker Jones, Ingmar Posner</h3>
<p>In this paper we explore the richness of information captured by the latent
space of a vision-based generative model. The model combines unsupervised
generative learning with a task-based performance predictor to learn and to
exploit task-relevant object affordances given visual observations from a
reaching task, involving a scenario and a stick-like tool. While the learned
embedding of the generative model captures factors of variation in 3D tool
geometry (e.g. length, width, and shape), the performance predictor identifies
sub-manifolds of the embedding that correlate with task success. Within a
variety of scenarios, we demonstrate that traversing the latent space via
backpropagation from the performance predictor allows us to imagine tools
appropriate for the task at hand. Our results indicate that affordances-like
the utility for reaching-are encoded along smooth trajectories in latent space.
Accessing these emergent affordances by considering only high-level performance
criteria (such as task success) enables an agent to manipulate tool geometries
in a targeted and deliberate way.
</p>
<a href="http://arxiv.org/abs/1909.13561" target="_blank">arXiv:1909.13561</a> [<a href="http://arxiv.org/pdf/1909.13561" target="_blank">pdf</a>]

<h2>FisheyeDistanceNet: Self-Supervised Scale-Aware Distance Estimation using Monocular Fisheye Camera for Autonomous Driving. (arXiv:1910.04076v4 [cs.CV] UPDATED)</h2>
<h3>Varun Ravi Kumar, Sandesh Athni Hiremath, Stefan Milz, Christian Witt, Clement Pinnard, Senthil Yogamani, Patrick Mader</h3>
<p>Fisheye cameras are commonly used in applications like autonomous driving and
surveillance to provide a large field of view ($&gt;180^{\circ}$). However, they
come at the cost of strong non-linear distortions which require more complex
algorithms. In this paper, we explore Euclidean distance estimation on fisheye
cameras for automotive scenes. Obtaining accurate and dense depth supervision
is difficult in practice, but self-supervised learning approaches show
promising results and could potentially overcome the problem. We present a
novel self-supervised scale-aware framework for learning Euclidean distance and
ego-motion from raw monocular fisheye videos without applying rectification.
While it is possible to perform piece-wise linear approximation of fisheye
projection surface and apply standard rectilinear models, it has its own set of
issues like re-sampling distortion and discontinuities in transition regions.
To encourage further research in this area, we will release our dataset as part
of the WoodScape project \cite{yogamani2019woodscape}. We further evaluated the
proposed algorithm on the KITTI dataset and obtained state-of-the-art results
comparable to other self-supervised monocular methods. Qualitative results on
an unseen fisheye video demonstrate impressive performance
https://youtu.be/Sgq1WzoOmXg.
</p>
<a href="http://arxiv.org/abs/1910.04076" target="_blank">arXiv:1910.04076</a> [<a href="http://arxiv.org/pdf/1910.04076" target="_blank">pdf</a>]

<h2>Minimax Weight and Q-Function Learning for Off-Policy Evaluation. (arXiv:1910.12809v4 [cs.LG] UPDATED)</h2>
<h3>Masatoshi Uehara, Jiawei Huang, Nan Jiang</h3>
<p>We provide theoretical investigations into off-policy evaluation in
reinforcement learning using function approximators for (marginalized)
importance weights and value functions. Our contributions include: (1) A new
estimator, MWL, that directly estimates importance ratios over the state-action
distributions, removing the reliance on knowledge of the behavior policy as in
prior work (Liu et al., 2018). (2) Another new estimator, MQL, obtained by
swapping the roles of importance weights and value-functions in MWL. MQL has an
intuitive interpretation of minimizing average Bellman errors and can be
combined with MWL in a doubly robust manner. (3) Several additional results
that offer further insights into these methods, including the sample complexity
analyses of MWL and MQL, their asymptotic optimality in the tabular setting,
how the learned importance weights depend the choice of the discriminator
class, and how our methods provide a unified view of some old and new
algorithms in RL.
</p>
<a href="http://arxiv.org/abs/1910.12809" target="_blank">arXiv:1910.12809</a> [<a href="http://arxiv.org/pdf/1910.12809" target="_blank">pdf</a>]

<h2>Interactive Refinement of Cross-Lingual Word Embeddings. (arXiv:1911.03070v3 [cs.CL] UPDATED)</h2>
<h3>Michelle Yuan, Mozhi Zhang, Benjamin Van Durme, Leah Findlater, Jordan Boyd-Graber</h3>
<p>Cross-lingual word embeddings transfer knowledge between languages: models
trained on high-resource languages can predict in low-resource languages. We
introduce CLIME, an interactive system to quickly refine cross-lingual word
embeddings for a given classification problem. First, CLIME ranks words by
their salience to the downstream task. Then, users mark similarity between
keywords and their nearest neighbors in the embedding space. Finally, CLIME
updates the embeddings using the annotations. We evaluate CLIME on identifying
health-related text in four low-resource languages: Ilocano, Sinhalese,
Tigrinya, and Uyghur. Embeddings refined by CLIME capture more nuanced word
semantics and have higher test accuracy than the original embeddings. CLIME
often improves accuracy faster than an active learning baseline and can be
easily combined with active learning to improve results.
</p>
<a href="http://arxiv.org/abs/1911.03070" target="_blank">arXiv:1911.03070</a> [<a href="http://arxiv.org/pdf/1911.03070" target="_blank">pdf</a>]

<h2>A Machine-learning based Probabilistic Perspective on Dynamic Security Assessment. (arXiv:1912.07477v2 [eess.SY] UPDATED)</h2>
<h3>Jochen L. Cremer, Goran Strbac</h3>
<p>Probabilistic security assessment and real-time dynamic security assessments
(DSA) are promising to better handle the risks of system operations. The
current methodologies of security assessments may require many time-domain
simulations for some stability phenomena that are unpractical in real-time.
Supervised machine learning is promising to predict DSA as their predictions
are immediately available. Classifiers are offline trained on operating
conditions and then used in real-time to identify operating conditions that are
insecure. However, the predictions of classifiers can be sometimes wrong and
hazardous if an alarm is missed for instance.

A probabilistic output of the classifier is explored in more detail and
proposed for probabilistic security assessment. An ensemble classifier is
trained and calibrated offline by using Platt scaling to provide accurate
probability estimates of the output. Imbalances in the training database and a
cost-skewness addressing strategy are proposed for considering that missed
alarms are significantly worse than false alarms. Subsequently, risk-minimised
predictions can be made in real-time operation by applying cost-sensitive
learning. Through case studies on a real data-set of the French transmission
grid and on the IEEE 6 bus system using static security metrics, it is
showcased how the proposed approach reduces inaccurate predictions and risks.
The sensitivity on the likelihood of contingency is studied as well as on
expected outage costs. Finally, the scalability to several contingencies and
operating conditions are showcased.
</p>
<a href="http://arxiv.org/abs/1912.07477" target="_blank">arXiv:1912.07477</a> [<a href="http://arxiv.org/pdf/1912.07477" target="_blank">pdf</a>]

<h2>Variational Hierarchical Dialog Autoencoder for Dialog State Tracking Data Augmentation. (arXiv:2001.08604v3 [cs.CL] UPDATED)</h2>
<h3>Kang Min Yoo, Hanbit Lee, Franck Dernoncourt, Trung Bui, Walter Chang, Sang-goo Lee</h3>
<p>Recent works have shown that generative data augmentation, where synthetic
samples generated from deep generative models complement the training dataset,
benefit NLP tasks. In this work, we extend this approach to the task of dialog
state tracking for goal-oriented dialogs. Due to the inherent hierarchical
structure of goal-oriented dialogs over utterances and related annotations, the
deep generative model must be capable of capturing the coherence among
different hierarchies and types of dialog features. We propose the Variational
Hierarchical Dialog Autoencoder (VHDA) for modeling the complete aspects of
goal-oriented dialogs, including linguistic features and underlying structured
annotations, namely speaker information, dialog acts, and goals. The proposed
architecture is designed to model each aspect of goal-oriented dialogs using
inter-connected latent variables and learns to generate coherent goal-oriented
dialogs from the latent spaces. To overcome training issues that arise from
training complex variational models, we propose appropriate training
strategies. Experiments on various dialog datasets show that our model improves
the downstream dialog trackers' robustness via generative data augmentation. We
also discover additional benefits of our unified approach to modeling
goal-oriented dialogs: dialog response generation and user simulation, where
our model outperforms previous strong baselines.
</p>
<a href="http://arxiv.org/abs/2001.08604" target="_blank">arXiv:2001.08604</a> [<a href="http://arxiv.org/pdf/2001.08604" target="_blank">pdf</a>]

<h2>Kalibre: Knowledge-based Neural Surrogate Model Calibration for Data Center Digital Twins. (arXiv:2001.10681v2 [eess.SY] UPDATED)</h2>
<h3>Ruihang Wang, Xin Zhou, Linsen Dong, Yonggang Wen, Rui Tan, Li Chen, Guan Wang, Feng Zeng</h3>
<p>Computational fluid dynamics (CFD) model has been widely used for prototyping
data centers. Evolving it to high-fidelity {\em digital twin} is desirable for
the management and operations of large-scale data centers. Manually calibrating
CFD model parameters to achieve twin-class fidelity by specially trained domain
expert is tedious and labor-intensive. To reduce manual efforts, existing
automatic calibration approaches developed for various computational models
apply heuristics to search model configurations within an empirically defined
parameter bound. However, in the context of CFD, each search step requires
long-lasting CFD model's iterated solving, rendering these approaches
impractical with increased model complexity. This paper presents Kalibre, a
knowledge-based neural surrogate approach that performs CFD model calibration
by iterating four key steps of i) training a neural surrogate model based on
CFD-generated data, ii) finding the optimal parameters at the moment through
neural surrogate retraining based on sensor-measured data, iii) configuring the
found parameters back to the CFD model, and iv) validating the CFD model using
sensor-measured data as the ground truth. Thus, the parameter search is
offloaded to the neural surrogate which is ultra-faster than CFD model's
iterated solving. To speed up the convergence of Kalibre, we integrate prior
knowledge of the twinned data center's thermophysics into the neural surrogate
design to improve its learning efficiency. With about five hours computation on
a 32-core processor, Kalibre achieves mean absolute errors (MAEs) of $0.81^o$C
and $0.75^o$C in calibrating two CFD models for two production data halls
hosting thousands of servers each while requires fewer CFD solving processes
than existing baseline approaches.
</p>
<a href="http://arxiv.org/abs/2001.10681" target="_blank">arXiv:2001.10681</a> [<a href="http://arxiv.org/pdf/2001.10681" target="_blank">pdf</a>]

<h2>Effective Diversity in Population Based Reinforcement Learning. (arXiv:2002.00632v3 [cs.LG] UPDATED)</h2>
<h3>Jack Parker-Holder, Aldo Pacchiano, Krzysztof Choromanski, Stephen Roberts</h3>
<p>Exploration is a key problem in reinforcement learning, since agents can only
learn from data they acquire in the environment. With that in mind, maintaining
a population of agents is an attractive method, as it allows data be collected
with a diverse set of behaviors. This behavioral diversity is often boosted via
multi-objective loss functions. However, those approaches typically leverage
mean field updates based on pairwise distances, which makes them susceptible to
cycling behaviors and increased redundancy. In addition, explicitly boosting
diversity often has a detrimental impact on optimizing already fruitful
behaviors for rewards. As such, the reward-diversity trade off typically relies
on heuristics. Finally, such methods require behavioral representations, often
handcrafted and domain specific. In this paper, we introduce an approach to
optimize all members of a population simultaneously. Rather than using pairwise
distance, we measure the volume of the entire population in a behavioral
manifold, defined by task-agnostic behavioral embeddings. In addition, our
algorithm Diversity via Determinants (DvD), adapts the degree of diversity
during training using online learning techniques. We introduce both
evolutionary and gradient-based instantiations of DvD and show they effectively
improve exploration without reducing performance when better exploration is not
required.
</p>
<a href="http://arxiv.org/abs/2002.00632" target="_blank">arXiv:2002.00632</a> [<a href="http://arxiv.org/pdf/2002.00632" target="_blank">pdf</a>]

<h2>Faster ILOD: Incremental Learning for Object Detectors based on Faster RCNN. (arXiv:2003.03901v2 [cs.CV] UPDATED)</h2>
<h3>Can Peng, Kun Zhao, Brian C. Lovell</h3>
<p>The human vision and perception system is inherently incremental where new
knowledge is continually learned over time whilst existing knowledge is
retained. On the other hand, deep learning networks are ill-equipped for
incremental learning. When a well-trained network is adapted to new categories,
its performance on the old categories will dramatically degrade. To address
this problem, incremental learning methods have been explored which preserve
the old knowledge of deep learning models. However, the state-of-the-art
incremental object detector employs an external fixed region proposal method
that increases overall computation time and reduces accuracy comparing to
Region Proposal Network (RPN) based object detectors such as Faster RCNN. The
purpose of this paper is to design an efficient end-to-end incremental object
detector using knowledge distillation. We first evaluate and analyze the
performance of the RPN-based detector with classic distillation on incremental
detection tasks. Then, we introduce multi-network adaptive distillation that
properly retains knowledge from the old categories when fine-tuning the model
for new task. Experiments on the benchmark datasets, PASCAL VOC and COCO,
demonstrate that the proposed incremental detector based on Faster RCNN is more
accurate as well as being 13 times faster than the baseline detector.
</p>
<a href="http://arxiv.org/abs/2003.03901" target="_blank">arXiv:2003.03901</a> [<a href="http://arxiv.org/pdf/2003.03901" target="_blank">pdf</a>]

<h2>Optimus: Organizing Sentences via Pre-trained Modeling of a Latent Space. (arXiv:2004.04092v3 [cs.CL] UPDATED)</h2>
<h3>Chunyuan Li, Xiang Gao, Yuan Li, Xiujun Li, Baolin Peng, Yizhe Zhang, Jianfeng Gao</h3>
<p>When trained effectively, the Variational Autoencoder (VAE) can be both a
powerful generative model and an effective representation learning framework
for natural language. In this paper, we propose the first large-scale language
VAE model, Optimus. A universal latent embedding space for sentences is first
pre-trained on large text corpus, and then fine-tuned for various language
generation and understanding tasks. Compared with GPT-2, Optimus enables guided
language generation from an abstract level using the latent vectors. Compared
with BERT, Optimus can generalize better on low-resource language understanding
tasks due to the smooth latent space structure. Extensive experimental results
on a wide range of language tasks demonstrate the effectiveness of Optimus. It
achieves new state-of-the-art on VAE language modeling benchmarks. We hope that
our first pre-trained big VAE language model itself and results can help the
NLP community renew the interests of deep generative models in the era of
large-scale pre-training, and make these principled methods more practical.
</p>
<a href="http://arxiv.org/abs/2004.04092" target="_blank">arXiv:2004.04092</a> [<a href="http://arxiv.org/pdf/2004.04092" target="_blank">pdf</a>]

<h2>Entities as Experts: Sparse Memory Access with Entity Supervision. (arXiv:2004.07202v2 [cs.CL] UPDATED)</h2>
<h3>Thibault F&#xe9;vry, Livio Baldini Soares, Nicholas FitzGerald, Eunsol Choi, Tom Kwiatkowski</h3>
<p>We focus on the problem of capturing declarative knowledge about entities in
the learned parameters of a language model. We introduce a new model - Entities
as Experts (EAE) - that can access distinct memories of the entities mentioned
in a piece of text. Unlike previous efforts to integrate entity knowledge into
sequence models, EAE's entity representations are learned directly from text.
We show that EAE's learned representations capture sufficient knowledge to
answer TriviaQA questions such as "Which Dr. Who villain has been played by
Roger Delgado, Anthony Ainley, Eric Roberts?", outperforming an
encoder-generator Transformer model with 10x the parameters. According to the
LAMA knowledge probes, EAE contains more factual knowledge than a similarly
sized BERT, as well as previous approaches that integrate external sources of
entity knowledge. Because EAE associates parameters with specific entities, it
only needs to access a fraction of its parameters at inference time, and we
show that the correct identification and representation of entities is
essential to EAE's performance.
</p>
<a href="http://arxiv.org/abs/2004.07202" target="_blank">arXiv:2004.07202</a> [<a href="http://arxiv.org/pdf/2004.07202" target="_blank">pdf</a>]

<h2>Adversarial Attacks and Defenses: An Interpretation Perspective. (arXiv:2004.11488v2 [cs.LG] UPDATED)</h2>
<h3>Ninghao Liu, Mengnan Du, Ruocheng Guo, Huan Liu, Xia Hu</h3>
<p>Despite the recent advances in a wide spectrum of applications, machine
learning models, especially deep neural networks, have been shown to be
vulnerable to adversarial attacks. Attackers add carefully-crafted
perturbations to input, where the perturbations are almost imperceptible to
humans, but can cause models to make wrong predictions. Techniques to protect
models against adversarial input are called adversarial defense methods.
Although many approaches have been proposed to study adversarial attacks and
defenses in different scenarios, an intriguing and crucial challenge remains
that how to really understand model vulnerability? Inspired by the saying that
"if you know yourself and your enemy, you need not fear the battles", we may
tackle the aforementioned challenge after interpreting machine learning models
to open the black-boxes. The goal of model interpretation, or interpretable
machine learning, is to extract human-understandable terms for the working
mechanism of models. Recently, some approaches start incorporating
interpretation into the exploration of adversarial attacks and defenses.
Meanwhile, we also observe that many existing methods of adversarial attacks
and defenses, although not explicitly claimed, can be understood from the
perspective of interpretation. In this paper, we review recent work on
adversarial attacks and defenses, particularly from the perspective of machine
learning interpretation. We categorize interpretation into two types,
feature-level interpretation and model-level interpretation. For each type of
interpretation, we elaborate on how it could be used for adversarial attacks
and defenses. We then briefly illustrate additional correlations between
interpretation and adversaries. Finally, we discuss the challenges and future
directions along tackling adversary issues with interpretation.
</p>
<a href="http://arxiv.org/abs/2004.11488" target="_blank">arXiv:2004.11488</a> [<a href="http://arxiv.org/pdf/2004.11488" target="_blank">pdf</a>]

<h2>Audio-Visual Instance Discrimination with Cross-Modal Agreement. (arXiv:2004.12943v2 [cs.CV] UPDATED)</h2>
<h3>Pedro Morgado, Nuno Vasconcelos, Ishan Misra</h3>
<p>We present a self-supervised learning approach to learn audio-visual
representations from video and audio. Our method uses contrastive learning for
cross-modal discrimination of video from audio and vice versa. We show that
optimizing for cross-modal discrimination, rather than within-modal
discrimination, is important to learn good representations from video and
audio. With this simple but powerful insight, our method achieves
state-of-the-art results when finetuned on action recognition tasks. While
recent work in contrastive learning defines positive and negative samples as
individual instances, we generalize this definition by exploring cross-modal
agreement. We group together multiple instances as positives by measuring their
similarity in both the video and the audio feature spaces. Cross-modal
agreement creates better positive and negative sets, and allows us to calibrate
visual similarities by seeking within-modal discrimination of positive
instances.
</p>
<a href="http://arxiv.org/abs/2004.12943" target="_blank">arXiv:2004.12943</a> [<a href="http://arxiv.org/pdf/2004.12943" target="_blank">pdf</a>]

<h2>A scalable and efficient convolutional neural network accelerator using HLS for a System on Chip design. (arXiv:2004.13075v2 [cs.CV] UPDATED)</h2>
<h3>Kim Bjerge, Jonathan Horsted Schougaard, Daniel Ejnar Larsen</h3>
<p>This paper presents a configurable Convolutional Neural Network Accelerator
(CNNA) for a System on Chip design (SoC). The goal was to accelerate inference
of different deep learning networks on an embedded SoC platform. The presented
CNNA has a scalable architecture which uses High Level Synthesis (HLS) and
SystemC for the hardware accelerator. It is able to accelerate any
Convolutional Neural Network (CNN) exported from Python and supports a
combination of convolutional, max-pooling, and fully connected layers. A
training method with fixed-point quantized weights is proposed and presented in
the paper. The CNNA is template-based, enabling it to scale for different
targets of the Xilinx Zynq platform. This approach enables design space
exploration, which makes it possible to explore several configurations of the
CNNA during C- and RTL-simulation, fitting it to the desired platform and
model. The CNN VGG16 was used to test the solution on a Xilinx Ultra96 board
using PYNQ. The result gave a high level of accuracy in training with an
auto-scaled fixed-point Q2.14 format compared to a similar floating-point
model. It was able to perform inference in 2.0 seconds, while having an average
power consumption of 2.63 W, which corresponds to a power efficiency of 6.0
GOPS/W.
</p>
<a href="http://arxiv.org/abs/2004.13075" target="_blank">arXiv:2004.13075</a> [<a href="http://arxiv.org/pdf/2004.13075" target="_blank">pdf</a>]

<h2>Multi-View Attention Network for Visual Dialog. (arXiv:2004.14025v3 [cs.AI] UPDATED)</h2>
<h3>Sungjin Park, Taesun Whang, Yeochan Yoon, Heuiseok Lim</h3>
<p>Visual dialog is a challenging vision-language task in which a series of
questions visually grounded by a given image are answered. To resolve the
visual dialog task, a high-level understanding of various multimodal inputs
(e.g., question, dialog history, and image) is required. Specifically, it is
necessary for an agent to 1) determine the semantic intent of question and 2)
align question-relevant textual and visual contents among heterogeneous
modality inputs. In this paper, we propose Multi-View Attention Network (MVAN),
which leverages multiple views about heterogeneous inputs based on attention
mechanisms. MVAN effectively captures the question-relevant information from
the dialog history with two complementary modules (i.e., Topic Aggregation and
Context Matching), and builds multimodal representations through sequential
alignment processes (i.e., Modality Alignment). Experimental results on VisDial
v1.0 dataset show the effectiveness of our proposed model, which outperforms
the previous state-of-the-art methods with respect to all evaluation metrics.
</p>
<a href="http://arxiv.org/abs/2004.14025" target="_blank">arXiv:2004.14025</a> [<a href="http://arxiv.org/pdf/2004.14025" target="_blank">pdf</a>]

<h2>GigaBERT: Zero-shot Transfer Learning from English to Arabic. (arXiv:2004.14519v3 [cs.CL] UPDATED)</h2>
<h3>Wuwei Lan, Yang Chen, Wei Xu, Alan Ritter</h3>
<p>Multilingual pre-trained Transformers, such as mBERT (Devlin et al., 2019)
and XLM-RoBERTa (Conneau et al., 2020a), have been shown to enable the
effective cross-lingual zero-shot transfer. However, their performance on
Arabic information extraction (IE) tasks is not very well studied. In this
paper, we pre-train a customized bilingual BERT, dubbed GigaBERT, that is
designed specifically for Arabic NLP and English-to-Arabic zero-shot transfer
learning. We study GigaBERT's effectiveness on zero-short transfer across four
IE tasks: named entity recognition, part-of-speech tagging, argument role
labeling, and relation extraction. Our best model significantly outperforms
mBERT, XLM-RoBERTa, and AraBERT (Antoun et al., 2020) in both the supervised
and zero-shot transfer settings. We have made our pre-trained models publicly
available at https://github.com/lanwuwei/GigaBERT.
</p>
<a href="http://arxiv.org/abs/2004.14519" target="_blank">arXiv:2004.14519</a> [<a href="http://arxiv.org/pdf/2004.14519" target="_blank">pdf</a>]

<h2>Interpretable Random Forests via Rule Extraction. (arXiv:2004.14841v3 [stat.ML] UPDATED)</h2>
<h3>Cl&#xe9;ment B&#xe9;nard (LPSM (UMR\_8001)), G&#xe9;rard Biau (LSTA), S&#xe9;bastien da Veiga, Erwan Scornet (CMAP)</h3>
<p>We introduce SIRUS (Stable and Interpretable RUle Set) for regression, a
stable rule learning algorithm which takes the form of a short and simple list
of rules. State-of-the-art learning algorithms are often referred to as "black
boxes" because of the high number of operations involved in their prediction
process. Despite their powerful predictivity, this lack of interpretability may
be highly restrictive for applications with critical decisions at stake. On the
other hand, algorithms with a simple structure-typically decision trees, rule
algorithms, or sparse linear models-are well known for their instability. This
undesirable feature makes the conclusions of the data analysis unreliable and
turns out to be a strong operational limitation. This motivates the design of
SIRUS, which combines a simple structure with a remarkable stable behavior when
data is perturbed. The algorithm is based on random forests, the predictive
accuracy of which is preserved. We demonstrate the efficiency of the method
both empirically (through experiments) and theoretically (with the proof of its
asymptotic stability). Our R/C++ software implementation sirus is available
from CRAN.
</p>
<a href="http://arxiv.org/abs/2004.14841" target="_blank">arXiv:2004.14841</a> [<a href="http://arxiv.org/pdf/2004.14841" target="_blank">pdf</a>]

<h2>Robust and Interpretable Grounding of Spatial References with Relation Networks. (arXiv:2005.00696v2 [cs.CL] UPDATED)</h2>
<h3>Tsung-Yen Yang, Andrew S. Lan, Karthik Narasimhan</h3>
<p>Learning representations of spatial references in natural language is a key
challenge in tasks like autonomous navigation and robotic manipulation. Recent
work has investigated various neural architectures for learning multi-modal
representations for spatial concepts. However, the lack of explicit reasoning
over entities makes such approaches vulnerable to noise in input text or state
observations. In this paper, we develop effective models for understanding
spatial references in text that are robust and interpretable, without
sacrificing performance. We design a text-conditioned \textit{relation network}
whose parameters are dynamically computed with a cross-modal attention module
to capture fine-grained spatial relations between entities. This design choice
provides interpretability of learned intermediate outputs. Experiments across
three tasks demonstrate that our model achieves superior performance, with a
17\% improvement in predicting goal locations and a 15\% improvement in
robustness compared to state-of-the-art systems.
</p>
<a href="http://arxiv.org/abs/2005.00696" target="_blank">arXiv:2005.00696</a> [<a href="http://arxiv.org/pdf/2005.00696" target="_blank">pdf</a>]

<h2>UnifiedQA: Crossing Format Boundaries With a Single QA System. (arXiv:2005.00700v3 [cs.CL] UPDATED)</h2>
<h3>Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, Hannaneh Hajishirzi</h3>
<p>Question answering (QA) tasks have been posed using a variety of formats,
such as extractive span selection, multiple choice, etc. This has led to
format-specialized models, and even to an implicit division in the QA
community. We argue that such boundaries are artificial and perhaps
unnecessary, given the reasoning abilities we seek to teach are not governed by
the format. As evidence, we use the latest advances in language modeling to
build a single pre-trained QA model, UnifiedQA, that performs surprisingly well
across 17 QA datasets spanning 4 diverse formats. UnifiedQA performs on par
with 9 different models that were trained on individual datasets themselves.
Even when faced with 12 unseen datasets of observed formats, UnifiedQA performs
surprisingly well, showing strong generalization from its out-of-format
training data. Finally, simply fine-tuning this pre-trained QA model into
specialized models results in a new state of the art on 6 datasets,
establishing UnifiedQA as a strong starting point for building QA systems.
</p>
<a href="http://arxiv.org/abs/2005.00700" target="_blank">arXiv:2005.00700</a> [<a href="http://arxiv.org/pdf/2005.00700" target="_blank">pdf</a>]

<h2>Exploring and Predicting Transferability across NLP Tasks. (arXiv:2005.00770v2 [cs.CL] UPDATED)</h2>
<h3>Tu Vu, Tong Wang, Tsendsuren Munkhdalai, Alessandro Sordoni, Adam Trischler, Andrew Mattarella-Micke, Subhransu Maji, Mohit Iyyer</h3>
<p>Recent advances in NLP demonstrate the effectiveness of training large-scale
language models and transferring them to downstream tasks. Can fine-tuning
these models on tasks other than language modeling further improve performance?
In this paper, we conduct an extensive study of the transferability between 33
NLP tasks across three broad classes of problems (text classification, question
answering, and sequence labeling). Our results show that transfer learning is
more beneficial than previously thought, especially when target task data is
scarce, and can improve performance even when the source task is small or
differs substantially from the target task (e.g., part-of-speech tagging
transfers well to the DROP QA dataset). We also develop task embeddings that
can be used to predict the most transferable source tasks for a given target
task, and we validate their effectiveness in experiments controlled for source
and target data size. Overall, our experiments reveal that factors such as
source data size, task and domain similarity, and task complexity all play a
role in determining transferability.
</p>
<a href="http://arxiv.org/abs/2005.00770" target="_blank">arXiv:2005.00770</a> [<a href="http://arxiv.org/pdf/2005.00770" target="_blank">pdf</a>]

<h2>Transforming task representations to perform novel tasks. (arXiv:2005.04318v3 [cs.LG] UPDATED)</h2>
<h3>Andrew K. Lampinen, James L. McClelland</h3>
<p>An important aspect of intelligence is the ability to adapt to a novel task
without any direct experience (zero-shot), based on its relationship to
previous tasks. Humans can exhibit this cognitive flexibility. By contrast,
models that achieve superhuman performance in specific tasks often fail to
adapt to even slight task alterations. To address this, we propose a general
computational framework for adapting to novel tasks based on their relationship
to prior tasks. We begin by learning vector representations of tasks. To adapt
to new tasks, we propose meta-mappings, higher-order tasks that transform basic
task representations. We demonstrate the effectiveness of this framework across
a wide variety of tasks and computational paradigms, ranging from regression to
image classification and reinforcement learning. We compare to both human
adaptability and language-based approaches to zero-shot learning. Across these
domains, meta-mapping is successful, often achieving 80-90% performance,
without any data, on a novel task, even when the new task directly contradicts
prior experience. We further show that meta-mapping can not only generalize to
new tasks via learned relationships, but can also generalize using novel
relationships unseen during training. Finally, using meta-mapping as a starting
point can dramatically accelerate later learning on a new task, and reduce
learning time and cumulative error substantially. Our results provide insight
into a possible computational basis of intelligent adaptability and offer a
possible framework for modeling cognitive flexibility and building more
flexible artificial intelligence systems.
</p>
<a href="http://arxiv.org/abs/2005.04318" target="_blank">arXiv:2005.04318</a> [<a href="http://arxiv.org/pdf/2005.04318" target="_blank">pdf</a>]

<h2>Investigation of learning abilities on linguistic features in sequence-to-sequence text-to-speech synthesis. (arXiv:2005.10390v2 [eess.AS] UPDATED)</h2>
<h3>Yusuke Yasuda, Xin Wang, Junichi Yamagishi</h3>
<p>Neural sequence-to-sequence text-to-speech synthesis (TTS) can produce
high-quality speech directly from text or simple linguistic features such as
phonemes. Unlike traditional pipeline TTS, the neural sequence-to-sequence TTS
does not require manually annotated and complicated linguistic features such as
part-of-speech tags and syntactic structures for system training. However, it
must be carefully designed and well optimized so that it can implicitly extract
useful linguistic features from the input features. In this paper we
investigate under what conditions the neural sequence-to-sequence TTS can work
well in Japanese and English along with comparisons with deep neural network
(DNN) based pipeline TTS systems. Unlike past comparative studies, the pipeline
systems also use autoregressive probabilistic modeling and a neural vocoder. We
investigated systems from three aspects: a) model architecture, b) model
parameter size, and c) language. For the model architecture aspect, we adopt
modified Tacotron systems that we previously proposed and their variants using
an encoder from Tacotron or Tacotron2. For the model parameter size aspect, we
investigate two model parameter sizes. For the language aspect, we conduct
listening tests in both Japanese and English to see if our findings can be
generalized across languages. Our experiments suggest that a) a neural
sequence-to-sequence TTS system should have a sufficient number of model
parameters to produce high quality speech, b) it should also use a powerful
encoder when it takes characters as inputs, and c) the encoder still has a room
for improvement and needs to have an improved architecture to learn
supra-segmental features more appropriately.
</p>
<a href="http://arxiv.org/abs/2005.10390" target="_blank">arXiv:2005.10390</a> [<a href="http://arxiv.org/pdf/2005.10390" target="_blank">pdf</a>]

<h2>NAUTILUS: a Versatile Voice Cloning System. (arXiv:2005.11004v2 [eess.AS] UPDATED)</h2>
<h3>Hieu-Thi Luong, Junichi Yamagishi</h3>
<p>We introduce a novel speech synthesis system, called NAUTILUS, that can
generate speech with a target voice either from a text input or a reference
utterance of an arbitrary source speaker. By using a multi-speaker speech
corpus to train all requisite encoders and decoders in the initial training
stage, our system can clone unseen voices using untranscribed speech of target
speakers on the basis of the backpropagation algorithm. Moreover, depending on
the data circumstance of the target speaker, the cloning strategy can be
adjusted to take advantage of additional data and modify the behaviors of
text-to-speech (TTS) and/or voice conversion (VC) systems to accommodate the
situation. We test the performance of the proposed framework by using deep
convolution layers to model the encoders, decoders and WaveNet vocoder.
Evaluations show that it achieves comparable quality with state-of-the-art TTS
and VC systems when cloning with just five minutes of untranscribed speech.
Moreover, it is demonstrated that the proposed framework has the ability to
switch between TTS and VC with high speaker consistency, which will be useful
for many applications.
</p>
<a href="http://arxiv.org/abs/2005.11004" target="_blank">arXiv:2005.11004</a> [<a href="http://arxiv.org/pdf/2005.11004" target="_blank">pdf</a>]

<h2>Graph Random Neural Network. (arXiv:2005.11079v2 [cs.LG] UPDATED)</h2>
<h3>Wenzheng Feng, Jie Zhang, Yuxiao Dong, Yu Han, Huanbo Luan, Qian Xu, Qiang Yang, Evgeny Kharlamov, Jie Tang</h3>
<p>Graph neural networks (GNNs) have generalized deep learning methods into
graph-structured data with promising performance on graph mining tasks.
However, existing GNNs often meet complex graph structures with scarce labeled
nodes and suffer from the limitations of non-robustness, over-smoothing, and
overfitting. To address these issues, we propose a simple yet effective GNN
framework---Graph Random Neural Network (Grand). Different from the
deterministic propagation in existing GNNs, Grand adopts a random propagation
strategy to enhance model robustness. This strategy also naturally enables
Grand to decouple the propagation from feature transformation, reducing the
risks of over-smoothing and overfitting. Moreover, random propagation acts as
an efficient method for graph data augmentation. Based on this, we propose the
consistency regularization for Grand by leveraging the distributional
consistency of unlabeled nodes in multiple augmentations, improving the
generalization capacity of the model. Extensive experiments on graph benchmark
datasets suggest that Grand significantly outperforms state-of-the-art GNN
baselines on semi-supervised graph learning tasks. Finally, we show that Grand
mitigates the issues of over-smoothing and overfitting, and its performance is
married with robustness.
</p>
<a href="http://arxiv.org/abs/2005.11079" target="_blank">arXiv:2005.11079</a> [<a href="http://arxiv.org/pdf/2005.11079" target="_blank">pdf</a>]

<h2>Long-Term Cloth-Changing Person Re-identification. (arXiv:2005.12633v3 [cs.CV] UPDATED)</h2>
<h3>Xuelin Qian, Wenxuan Wang, Li Zhang, Fangrui Zhu, Yanwei Fu, Tao Xiang, Yu-Gang Jiang, Xiangyang Xue</h3>
<p>Person re-identification (Re-ID) aims to match a target person across camera
views at different locations and times. Existing Re-ID studies focus on the
short-term cloth-consistent setting, under which a person re-appears in
different camera views with the same outfit. A discriminative feature
representation learned by existing deep Re-ID models is thus dominated by the
visual appearance of clothing. In this work, we focus on a much more difficult
yet practical setting where person matching is conducted over long-duration,
e.g., over days and months and therefore inevitably under the new challenge of
changing clothes. This problem, termed Long-Term Cloth-Changing (LTCC) Re-ID is
much understudied due to the lack of large scale datasets. The first
contribution of this work is a new LTCC dataset containing people captured over
a long period of time with frequent clothing changes. As a second contribution,
we propose a novel Re-ID method specifically designed to address the
cloth-changing challenge. Specifically, we consider that under cloth-changes,
soft-biometrics such as body shape would be more reliable. We, therefore,
introduce a shape embedding module as well as a cloth-elimination
shape-distillation module aiming to eliminate the now unreliable clothing
appearance features and focus on the body shape information. Extensive
experiments show that superior performance is achieved by the proposed model on
the new LTCC dataset. The code and dataset will be available at
https://naiq.github.io/LTCC_Perosn_ReID.html.
</p>
<a href="http://arxiv.org/abs/2005.12633" target="_blank">arXiv:2005.12633</a> [<a href="http://arxiv.org/pdf/2005.12633" target="_blank">pdf</a>]

<h2>Consistency Regularization for Certified Robustness of Smoothed Classifiers. (arXiv:2006.04062v2 [cs.LG] UPDATED)</h2>
<h3>Jongheon Jeong, Jinwoo Shin</h3>
<p>A recent technique of randomized smoothing has shown that the worst-case
(adversarial) $\ell_2$-robustness can be transformed into the average-case
Gaussian-robustness by "smoothing" a classifier, i.e., by considering the
averaged prediction over Gaussian noise. In this paradigm, one should rethink
the notion of adversarial robustness in terms of generalization ability of a
classifier under noisy observations. We found that the trade-off between
accuracy and certified robustness of smoothed classifiers can be greatly
controlled by simply regularizing the prediction consistency over noise. This
relationship allows us to design a robust training objective without
approximating a non-existing smoothed classifier, e.g., via soft smoothing. Our
experiments under various deep neural network architectures and datasets
demonstrate that the "certified" $\ell_2$-robustness can be dramatically
improved with the proposed regularization, even achieving better or comparable
results to the state-of-the-art approaches with significantly less training
costs and hyperparameters.
</p>
<a href="http://arxiv.org/abs/2006.04062" target="_blank">arXiv:2006.04062</a> [<a href="http://arxiv.org/pdf/2006.04062" target="_blank">pdf</a>]

<h2>Improving Inference for Neural Image Compression. (arXiv:2006.04240v3 [eess.IV] UPDATED)</h2>
<h3>Yibo Yang, Robert Bamler, Stephan Mandt</h3>
<p>We consider the problem of lossy image compression with deep latent variable
models. State-of-the-art methods build on hierarchical variational autoencoders
(VAEs) and learn inference networks to predict a compressible latent
representation of each data point. Drawing on the variational inference
perspective on compression, we identify three approximation gaps which limit
performance in the conventional approach: (i) an amortization gap, (ii) a
discretization gap, and (iii) a marginalization gap. We propose improvements to
each of these three shortcomings based on ideas related to iterative inference,
stochastic annealing for discrete optimization, and bits-back coding, resulting
in the first application of bits-back coding to lossy compression. In our
experiments, which include extensive baseline comparisons and ablation studies,
we achieve new state-of-the-art performance on lossy image compression using an
established VAE architecture, by changing only the inference method.
</p>
<a href="http://arxiv.org/abs/2006.04240" target="_blank">arXiv:2006.04240</a> [<a href="http://arxiv.org/pdf/2006.04240" target="_blank">pdf</a>]

<h2>Better Together: Resnet-50 accuracy with $13 \times$ fewer parameters and at $3\times$ speed. (arXiv:2006.05624v2 [cs.LG] UPDATED)</h2>
<h3>Utkarsh Nath, Shrinu Kushagra</h3>
<p>Recent research on compressing deep neural networks has focused on reducing
the number of parameters. Smaller networks are easier to export and deploy on
edge-devices. We introduce \textit{Adjoined networks} as a training approach
that can regularize and compress any CNN-based neural architecture. Our
one-shot learning paradigm trains both the original and the smaller networks
together. The parameters of the smaller network are shared across both the
architectures. We prove strong theoretical guarantees on the regularization
behavior of the adjoint training paradigm. We complement our theoretical
analysis by an extensive empirical evaluation of both the compression and
regularization behavior of adjoint networks. For resnet-50 trained adjointly on
Imagenet, we are able to achieve a $13.7x$ reduction in the number of
parameters (For size comparison, we ignore the parameters in the last linear
layer as it varies by dataset and are typically dropped during fine-tuning.
Else, the reductions are $11.5x$ and $95x$ for imagenet and cifar-100
respectively.) and a $3x$ improvement in inference time without any significant
drop in accuracy. For the same architecture on CIFAR-100, we are able to
achieve a $99.7x$ reduction in the number of parameters and a $5x$ improvement
in inference time. On both these datasets, the original network trained in the
adjoint fashion gains about $3\%$ in top-1 accuracy as compared to the same
network trained in the standard fashion.
</p>
<a href="http://arxiv.org/abs/2006.05624" target="_blank">arXiv:2006.05624</a> [<a href="http://arxiv.org/pdf/2006.05624" target="_blank">pdf</a>]

<h2>Self-Supervised Learning Aided Class-Incremental Lifelong Learning. (arXiv:2006.05882v4 [cs.LG] UPDATED)</h2>
<h3>Song Zhang, Gehui Shen, Jinsong Huang, Zhi-Hong Deng</h3>
<p>Lifelong or continual learning remains to be a challenge for artificial
neural network, as it is required to be both stable for preservation of old
knowledge and plastic for acquisition of new knowledge. It is common to see
previous experience get overwritten, which leads to the well-known issue of
catastrophic forgetting, especially in the scenario of class-incremental
learning (Class-IL). Recently, many lifelong learning methods have been
proposed to avoid catastrophic forgetting. However, models which learn without
replay of the input data, would encounter another problem which has been
ignored, and we refer to it as prior information loss (PIL). In training
procedure of Class-IL, as the model has no knowledge about following tasks, it
would only extract features necessary for tasks learned so far, whose
information is insufficient for joint classification. In this paper, our
empirical results on several image datasets show that PIL limits the
performance of current state-of-the-art method for Class-IL, the orthogonal
weights modification (OWM) algorithm. Furthermore, we propose to combine
self-supervised learning, which can provide effective representations without
requiring labels, with Class-IL to partly get around this problem. Experiments
show superiority of proposed method to OWM, as well as other strong baselines.
</p>
<a href="http://arxiv.org/abs/2006.05882" target="_blank">arXiv:2006.05882</a> [<a href="http://arxiv.org/pdf/2006.05882" target="_blank">pdf</a>]

<h2>Adaptive Reward-Free Exploration. (arXiv:2006.06294v2 [cs.LG] UPDATED)</h2>
<h3>Emilie Kaufmann, Pierre M&#xe9;nard, Omar Darwiche Domingues, Anders Jonsson, Edouard Leurent, Michal Valko</h3>
<p>Reward-free exploration is a reinforcement learning setting studied by Jin et
al. (2020), who address it by running several algorithms with regret guarantees
in parallel. In our work, we instead give a more natural adaptive approach for
reward-free exploration which directly reduces upper bounds on the maximum MDP
estimation error. We show that, interestingly, our reward-free UCRL algorithm
can be seen as a variant of an algorithm of Fiechter from 1994, originally
proposed for a different objective that we call best-policy identification. We
prove that RF-UCRL needs of order $({SAH^4}/{\varepsilon^2})(\log(1/\delta) +
S)$ episodes to output, with probability $1-\delta$, an
$\varepsilon$-approximation of the optimal policy for any reward function. This
bound improves over existing sample-complexity bounds in both the small
$\varepsilon$ and the small $\delta$ regimes. We further investigate the
relative complexities of reward-free exploration and best-policy
identification.
</p>
<a href="http://arxiv.org/abs/2006.06294" target="_blank">arXiv:2006.06294</a> [<a href="http://arxiv.org/pdf/2006.06294" target="_blank">pdf</a>]

<h2>Bayesian Additive Regression Trees with Model Trees. (arXiv:2006.07493v2 [stat.ML] UPDATED)</h2>
<h3>Estev&#xe3;o B. Prado, Rafael A. Moral, Andrew C. Parnell</h3>
<p>Bayesian Additive Regression Trees (BART) is a tree-based machine learning
method that has been successfully applied to regression and classification
problems. BART assumes regularisation priors on a set of trees that work as
weak learners and is very flexible for predicting in the presence of
non-linearity and high-order interactions. In this paper, we introduce an
extension of BART, called Model Trees BART (MOTR-BART), that considers
piecewise linear functions at node levels instead of piecewise constants. In
MOTR-BART, rather than having a unique value at node level for the prediction,
a linear predictor is estimated considering the covariates that have been used
as the split variables in the corresponding tree. In our approach, local
linearities are captured more efficiently and fewer trees are required to
achieve equal or better performance than BART. Via simulation studies and real
data applications, we compare MOTR-BART to its main competitors. R code for
MOTR-BART implementation is available at https://github.com/ebprado/MOTR-BART.
</p>
<a href="http://arxiv.org/abs/2006.07493" target="_blank">arXiv:2006.07493</a> [<a href="http://arxiv.org/pdf/2006.07493" target="_blank">pdf</a>]

<h2>Domain Generalization using Causal Matching. (arXiv:2006.07500v2 [cs.LG] UPDATED)</h2>
<h3>Divyat Mahajan, Shruti Tople, Amit Sharma</h3>
<p>Learning invariant representations has been proposed as a key technique for
addressing the domain generalization problem. However, the question of
identifying the right conditions for invariance remains unanswered. In this
work, we propose a causal interpretation of domain generalization that defines
domains as interventions under a data-generating process. Based on a general
causal model for data from multiple domains, we show that prior methods for
learning an invariant representation optimize for an incorrect objective. We
highlight an alternative condition: inputs across domains should have the same
representation if they are derived from the same base object. Inputs that share
the same base object may be available through data augmentation or in some
specific contexts, but base object information is not always available. Hence
we propose an iterative algorithm called MatchDG that approximates base object
similarity by using a contrastive loss formulation adapted for multiple
domains. We then match inputs that are similar under the resultant
representation to build an invariant classifier. We evaluate our matching-based
methods on rotated MNIST, Fashion-MNIST, PACS and Chest X-ray datasets and find
that they outperform prior work on out-of-domain accuracy. In particular,
top-10 matches from MatchDG have over 50% overlap with ground-truth matches in
MNIST and Fashion-MNIST. Code repository can be accessed here:
\textit{https://github.com/microsoft/robustdg}
</p>
<a href="http://arxiv.org/abs/2006.07500" target="_blank">arXiv:2006.07500</a> [<a href="http://arxiv.org/pdf/2006.07500" target="_blank">pdf</a>]

<h2>Entropic gradient descent algorithms and wide flat minima. (arXiv:2006.07897v2 [cs.LG] UPDATED)</h2>
<h3>Fabrizio Pittorino, Carlo Lucibello, Christoph Feinauer, Gabriele Perugini, Carlo Baldassi, Elizaveta Demyanenko, Riccardo Zecchina</h3>
<p>The properties of flat minima in the empirical risk landscape of neural
networks have been debated for some time. Increasing evidence suggests they
possess better generalization capabilities with respect to sharp ones. First,
we discuss Gaussian mixture classification models and show analytically that
there exist Bayes optimal pointwise estimators which correspond to minimizers
belonging to wide flat regions. These estimators can be found by applying
maximum flatness algorithms either directly on the classifier (which is norm
independent) or on the differentiable loss function used in learning. Next, we
extend the analysis to the deep learning scenario by extensive numerical
validations. Using two algorithms, Entropy-SGD and Replicated-SGD, that
explicitly include in the optimization objective a non-local flatness measure
known as local entropy, we consistently improve the generalization error for
common architectures (e.g. ResNet, EfficientNet). An easy to compute flatness
measure shows a clear correlation with test accuracy.
</p>
<a href="http://arxiv.org/abs/2006.07897" target="_blank">arXiv:2006.07897</a> [<a href="http://arxiv.org/pdf/2006.07897" target="_blank">pdf</a>]

<h2>Analytic Manifold Learning: Unifying and Evaluating Representations for Continuous Control. (arXiv:2006.08718v2 [cs.LG] UPDATED)</h2>
<h3>Rika Antonova, Maksim Maydanskiy, Danica Kragic, Sam Devlin, Katja Hofmann</h3>
<p>We address the problem of learning reusable state representations from
streaming high-dimensional observations. This is important for areas like
Reinforcement Learning (RL), which yields non-stationary data distributions
during training. We make two key contributions. First, we propose an evaluation
suite that measures alignment between latent and true low-dimensional states.
We benchmark several widely used unsupervised learning approaches. This
uncovers the strengths and limitations of existing approaches that impose
additional constraints/objectives on the latent space. Our second contribution
is a unifying mathematical formulation for learning latent relations. We learn
analytic relations on source domains, then use these relations to help
structure the latent space when learning on target domains. This formulation
enables a more general, flexible and principled way of shaping the latent
space. It formalizes the notion of learning independent relations, without
imposing restrictive simplifying assumptions or requiring domain-specific
information. We present mathematical properties, concrete algorithms for
implementation and experimental validation of successful learning and transfer
of latent relations.
</p>
<a href="http://arxiv.org/abs/2006.08718" target="_blank">arXiv:2006.08718</a> [<a href="http://arxiv.org/pdf/2006.08718" target="_blank">pdf</a>]

<h2>Go with the Flow: Adaptive Control for Neural ODEs. (arXiv:2006.09545v2 [cs.LG] UPDATED)</h2>
<h3>Mathieu Chalvidal, Matthew Ricci, Rufin VanRullen, Thomas Serre</h3>
<p>Despite their elegant formulation and lightweight memory cost, neural
ordinary differential equations (NODEs) suffer from known representational
limitations. In particular, the single flow learned by NODEs cannot express all
homeomorphisms from a given data space to itself, and their static weight
parametrization restricts the type of functions they can learn compared to
discrete architectures with layer-dependent weights. Here, we describe a new
module called neurally-controlled ODE (N-CODE) designed to improve the
expressivity of NODEs. The parameters of N-CODE modules are dynamic variables
governed by a trainable map from initial or current activation state, resulting
in forms of open-loop and closed-loop control, respectively. A single module is
sufficient for learning a distribution on non-autonomous flows that adaptively
drive neural representations. We provide theoretical and empirical evidence
that N-CODE circumvents limitations of previous models and show how increased
model expressivity manifests in several domains. In supervised learning, we
demonstrate that our framework achieves better performance than NODEs as
measured by both training speed and testing accuracy. In unsupervised learning,
we apply this control perspective to an image Autoencoder endowed with a latent
transformation flow, greatly improving representational power over a vanilla
model and leading to state-of-the-art image reconstruction on CIFAR-10.
</p>
<a href="http://arxiv.org/abs/2006.09545" target="_blank">arXiv:2006.09545</a> [<a href="http://arxiv.org/pdf/2006.09545" target="_blank">pdf</a>]

<h2>Unsupervised out-of-distribution detection using kernel density estimation. (arXiv:2006.10712v2 [cs.CV] UPDATED)</h2>
<h3>Ertunc Erdil, Krishna Chaitanya, Neerav Karani, Ender Konukoglu</h3>
<p>Deep neural networks (DNNs) achieve substantial advancement to the
state-of-the-art in many computer vision tasks. However, accuracy of DNNs may
drop drastically when test data come from a different distribution than
training data. Detecting out-of-distribution (OOD) samples before performing
downstream analysis on the predictions of a DNN thus arises as a crucial
problem for critical applications, such as medical diagnosis and autonomous
driving. The majority of the existing methods focus on OOD detection in the
classification problem. In this paper, we propose an unsupervised OOD detection
method using kernel density estimation (KDE), which is a non-parametric method
for estimating probability density functions (pdfs). Specifically, we estimate
the pdfs of features for each channel of the network, by performing KDE on the
in-distribution (InD) dataset. At test time, the pdfs are evaluated on the test
data to obtain a confidence score for each channel, which is expected to be
higher for InD and lower for OOD samples. These scores are combined into a
final score using logistic regression. Crucially, the proposed method does not
require class labels nor information on the output of a network. Thus, it can
be used for networks both for classification and non-classification problems.
Furthermore, the use of KDE eliminates the need for making a parametric
assumption (e.g. Gaussian) about feature densities. We performed experiments on
2 different classification networks trained on CIFAR-10 and CIFAR-100, and 2
different non-classification networks (segmentation and detection) trained on
COCO dataset. The proposed method achieved detection accuracy on-par with the
state-of-the-art for classification networks and substantially outperformed the
compared alternatives for segmentation and detection networks in all the tests,
thus exhibiting a larger scope of applications than existing methods.
</p>
<a href="http://arxiv.org/abs/2006.10712" target="_blank">arXiv:2006.10712</a> [<a href="http://arxiv.org/pdf/2006.10712" target="_blank">pdf</a>]

<h2>Contextual and Possibilistic Reasoning for Coalition Formation. (arXiv:2006.11097v2 [cs.AI] UPDATED)</h2>
<h3>Antonis Bikakis, Patrice Caire</h3>
<p>In multiagent systems, agents often have to rely on other agents to reach
their goals, for example when they lack a needed resource or do not have the
capability to perform a required action. Agents therefore need to cooperate.
Then, some of the questions raised are: Which agent(s) to cooperate with? What
are the potential coalitions in which agents can achieve their goals? As the
number of possibilities is potentially quite large, how to automate the
process? And then, how to select the most appropriate coalition, taking into
account the uncertainty in the agents' abilities to carry out certain tasks? In
this article, we address the question of how to find and evaluate coalitions
among agents in multiagent systems using MCS tools, while taking into
consideration the uncertainty around the agents' actions. Our methodology is
the following: We first compute the solution space for the formation of
coalitions using a contextual reasoning approach. Second, we model agents as
contexts in Multi-Context Systems (MCS), and dependence relations among agents
seeking to achieve their goals, as bridge rules. Third, we systematically
compute all potential coalitions using algorithms for MCS equilibria, and given
a set of functional and non-functional requirements, we propose ways to select
the best solutions. Finally, in order to handle the uncertainty in the agents'
actions, we extend our approach with features of possibilistic reasoning. We
illustrate our approach with an example from robotics.
</p>
<a href="http://arxiv.org/abs/2006.11097" target="_blank">arXiv:2006.11097</a> [<a href="http://arxiv.org/pdf/2006.11097" target="_blank">pdf</a>]

<h2>Accelerating Safe Reinforcement Learning with Constraint-mismatched Policies. (arXiv:2006.11645v2 [cs.LG] UPDATED)</h2>
<h3>Tsung-Yen Yang, Justinian Rosca, Karthik Narasimhan, Peter J. Ramadge</h3>
<p>We consider the problem of reinforcement learning when provided with (1) a
baseline control policy and (2) a set of constraints that the controlled system
must satisfy. The baseline policy can arise from a teacher agent, demonstration
data or even a heuristic while the constraints might encode safety, fairness or
other application-specific requirements. Importantly, the baseline policy may
be sub-optimal for the task at hand, and is not guaranteed to satisfy the
specified constraints. The key challenge therefore lies in effectively
leveraging the baseline policy for faster learning, while still ensuring that
the constraints are minimally violated. To reconcile these potentially
competing aspects, we propose an iterative policy optimization algorithm that
alternates between maximizing expected return on the task, minimizing distance
to the baseline policy, and projecting the policy onto the
constraint-satisfying set. We analyze the convergence of our algorithm
theoretically and provide a finite-sample guarantee. In our empirical
experiments on five different control tasks, our algorithm consistently
outperforms several state-of-the-art methods, achieving 10 times fewer
constraint violations and 40% higher reward on average.
</p>
<a href="http://arxiv.org/abs/2006.11645" target="_blank">arXiv:2006.11645</a> [<a href="http://arxiv.org/pdf/2006.11645" target="_blank">pdf</a>]

<h2>Learning for Video Compression with Recurrent Auto-Encoder and Recurrent Probability Model. (arXiv:2006.13560v3 [eess.IV] UPDATED)</h2>
<h3>Ren Yang, Fabian Mentzer, Luc Van Gool, Radu Timofte</h3>
<p>The past few years have witnessed increasing interests in applying deep
learning to video compression. However, the existing approaches compress a
video frame with only a few number of reference frames, which limits their
ability to fully exploit the temporal correlation among video frames. To
overcome this shortcoming, this paper proposes a Recurrent Learned Video
Compression (RLVC) approach with the Recurrent Auto-Encoder (RAE) and Recurrent
Probability Model (RPM). Specifically, the RAE employs recurrent cells in both
the encoder and decoder. As such, the temporal information in a large range of
frames can be used for generating latent representations and reconstructing
compressed outputs. Furthermore, the proposed RPM network recurrently estimates
the Probability Mass Function (PMF) of the latent representation, conditioned
on the distribution of previous latent representations. Due to the correlation
among consecutive frames, the conditional cross entropy can be lower than the
independent cross entropy, thus reducing the bit-rate. The experiments show
that our approach achieves the state-of-the-art learned video compression
performance in terms of both PSNR and MS-SSIM. Moreover, our approach
outperforms the default Low-Delay P (LDP) setting of x265 on PSNR, and also has
better performance on MS-SSIM than the SSIM-tuned x265 and the slowest setting
of x265.
</p>
<a href="http://arxiv.org/abs/2006.13560" target="_blank">arXiv:2006.13560</a> [<a href="http://arxiv.org/pdf/2006.13560" target="_blank">pdf</a>]

<h2>Transferability of Natural Language Inference to Biomedical Question Answering. (arXiv:2007.00217v3 [cs.CL] UPDATED)</h2>
<h3>Minbyul Jeong, Mujeen Sung, Gangwoo Kim, Donghyeon Kim, Wonjin Yoon, Jaehyo Yoo, Jaewoo Kang</h3>
<p>Biomedical question answering (QA) is a challenging task due to the scarcity
of data and the requirement of domain expertise. Pre-trained language models
have been used to address these issues. Recently, learning relationships
between sentence pairs has been proved to improve performance in general QA. In
this paper, we focus on applying BioBERT to transfer the knowledge of natural
language inference (NLI) to biomedical QA. We observe that BioBERT trained on
the NLI dataset obtains better performance on Yes/No (+5.59%), Factoid
(+0.53%), List type (+13.58%) questions compared to performance obtained in a
previous challenge (BioASQ 7B Phase B). We present a sequential transfer
learning method that significantly performed well in the 8th BioASQ Challenge
(Phase B). In sequential transfer learning, the order in which tasks are
fine-tuned is important. We measure an unanswerable rate of the extractive QA
setting when the formats of factoid and list type questions are converted to
the format of the Stanford Question Answering Dataset (SQuAD).
</p>
<a href="http://arxiv.org/abs/2007.00217" target="_blank">arXiv:2007.00217</a> [<a href="http://arxiv.org/pdf/2007.00217" target="_blank">pdf</a>]

<h2>Meta-Learning Symmetries by Reparameterization. (arXiv:2007.02933v2 [cs.LG] UPDATED)</h2>
<h3>Allan Zhou, Tom Knowles, Chelsea Finn</h3>
<p>Many successful deep learning architectures are equivariant to certain
transformations in order to conserve parameters and improve generalization:
most famously, convolution layers are equivariant to shifts of the input. This
approach only works when practitioners know the symmetries of the task and can
manually construct an architecture with the corresponding equivariances. Our
goal is an approach for learning equivariances from data, without needing to
design custom task-specific architectures. We present a method for learning and
encoding equivariances into networks by learning corresponding parameter
sharing patterns from data. Our method can provably represent
equivariance-inducing parameter sharing for any finite group of symmetry
transformations. Our experiments suggest that it can automatically learn to
encode equivariances to common transformations used in image processing tasks.
We provide our experiment code at
https://github.com/AllanYangZhou/metalearning-symmetries.
</p>
<a href="http://arxiv.org/abs/2007.02933" target="_blank">arXiv:2007.02933</a> [<a href="http://arxiv.org/pdf/2007.02933" target="_blank">pdf</a>]

<h2>UnRectDepthNet: Self-Supervised Monocular Depth Estimation using a Generic Framework for Handling Common Camera Distortion Models. (arXiv:2007.06676v3 [cs.CV] UPDATED)</h2>
<h3>Varun Ravi Kumar, Senthil Yogamani, Markus Bach, Christian Witt, Stefan Milz, Patrick Mader</h3>
<p>In classical computer vision, rectification is an integral part of multi-view
depth estimation. It typically includes epipolar rectification and lens
distortion correction. This process simplifies the depth estimation
significantly, and thus it has been adopted in CNN approaches. However,
rectification has several side effects, including a reduced field of view
(FOV), resampling distortion, and sensitivity to calibration errors. The
effects are particularly pronounced in case of significant distortion (e.g.,
wide-angle fisheye cameras). In this paper, we propose a generic scale-aware
self-supervised pipeline for estimating depth, euclidean distance, and visual
odometry from unrectified monocular videos. We demonstrate a similar level of
precision on the unrectified KITTI dataset with barrel distortion comparable to
the rectified KITTI dataset. The intuition being that the rectification step
can be implicitly absorbed within the CNN model, which learns the distortion
model without increasing complexity. Our approach does not suffer from a
reduced field of view and avoids computational costs for rectification at
inference time. To further illustrate the general applicability of the proposed
framework, we apply it to wide-angle fisheye cameras with 190$^\circ$
horizontal field of view. The training framework UnRectDepthNet takes in the
camera distortion model as an argument and adapts projection and unprojection
functions accordingly. The proposed algorithm is evaluated further on the KITTI
rectified dataset, and we achieve state-of-the-art results that improve upon
our previous work FisheyeDistanceNet. Qualitative results on a distorted test
scene video sequence indicate excellent performance
https://youtu.be/K6pbx3bU4Ss.
</p>
<a href="http://arxiv.org/abs/2007.06676" target="_blank">arXiv:2007.06676</a> [<a href="http://arxiv.org/pdf/2007.06676" target="_blank">pdf</a>]

<h2>AWS CORD-19 Search: A Neural Search Engine for COVID-19 Literature. (arXiv:2007.09186v3 [cs.IR] UPDATED)</h2>
<h3>Parminder Bhatia, Lan Liu, Kristjan Arumae, Nima Pourdamghani, Suyog Deshpande, Ben Snively, Mona Mona, Colby Wise, George Price, Shyam Ramaswamy, Xiaofei Ma, Ramesh Nallapati, Zhiheng Huang, Bing Xiang, Taha Kass-Hout</h3>
<p>Coronavirus disease (COVID-19) has been declared as a pandemic by WHO with
thousands of cases being reported each day. Numerous scientific articles are
being published on the disease raising the need for a service which can
organize, and query them in a reliable fashion. To support this cause we
present AWS CORD-19 Search (ACS), a public, COVID-19 specific, neural search
engine that is powered by several machine learning systems to support natural
language based searches. ACS with capabilities such as document ranking,
passage ranking, question answering and topic classification provides a
scalable solution to COVID-19 researchers and policy makers in their search and
discovery for answers to high priority scientific questions. We present a
quantitative evaluation and qualitative analysis of the system against other
leading COVID-19 search platforms. ACS is top performing across these systems
yielding quality results which we detail with relevant examples in this work.
</p>
<a href="http://arxiv.org/abs/2007.09186" target="_blank">arXiv:2007.09186</a> [<a href="http://arxiv.org/pdf/2007.09186" target="_blank">pdf</a>]

<h2>Self-Supervision with Superpixels: Training Few-shot Medical Image Segmentation without Annotation. (arXiv:2007.09886v2 [cs.CV] UPDATED)</h2>
<h3>Cheng Ouyang, Carlo Biffi, Chen Chen, Turkay Kart, Huaqi Qiu, Daniel Rueckert</h3>
<p>Few-shot semantic segmentation (FSS) has great potential for medical imaging
applications. Most of the existing FSS techniques require abundant annotated
semantic classes for training. However, these methods may not be applicable for
medical images due to the lack of annotations. To address this problem we make
several contributions: (1) A novel self-supervised FSS framework for medical
images in order to eliminate the requirement for annotations during training.
Additionally, superpixel-based pseudo-labels are generated to provide
supervision; (2) An adaptive local prototype pooling module plugged into
prototypical networks, to solve the common challenging foreground-background
imbalance problem in medical image segmentation; (3) We demonstrate the general
applicability of the proposed approach for medical images using three different
tasks: abdominal organ segmentation for CT and MRI, as well as cardiac
segmentation for MRI. Our results show that, for medical image segmentation,
the proposed method outperforms conventional FSS methods which require manual
annotations for training.
</p>
<a href="http://arxiv.org/abs/2007.09886" target="_blank">arXiv:2007.09886</a> [<a href="http://arxiv.org/pdf/2007.09886" target="_blank">pdf</a>]

<h2>A Research Agenda on Pediatric Chest X-Ray: Is Deep Learning Still in Childhood?. (arXiv:2007.11369v2 [cs.OH] UPDATED)</h2>
<h3>Afonso U. Fonseca, Gabriel S. Vieira, Fabr&#xed;zzio A. A. M. N. Soares, Renato F. Bulc&#xe3;o-Neto</h3>
<p>Several reasons explain the significant role that chest X-rays play on
supporting clinical analysis and early disease detection in pediatric patients,
such as low cost, high resolution, low radiation levels, and high availability.
In the last decade, Deep Learning (DL) has been given special attention from
the computer-aided diagnosis research community, outperforming the state of the
art of many techniques, including those applied to pediatric chest X-rays
(PCXR). Due to this increasing interest, much high-quality secondary research
has also arisen, overviewing machine learning and DL algorithms on medical
imaging and PCXR, in particular. However, these secondary studies follow
different guidelines, hampering their reproduction or improvement by
third-parties regarding the identified trends and gaps. This paper proposes a
"deep radiography" of primary research on DL techniques applied in PCXR images.
We elaborated on a Systematic Literature Mapping (SLM) protocol, including
automatic search on six sources for studies published from January 1, 2010, to
May 20, 2020, and selection criteria utilized on a hundred research papers. As
a result, this paper categorizes twenty-six relevant studies and provides a
research agenda highlighting limitations, gaps, and trends for further
investigations on DL usage in PCXR images. Besides the fact that there is no
systematic mapping study on this research topic, to the best of authors'
knowledge, this work organizes the process of finding and selecting relevant
studies and data gathering and synthesis in a reproducible way.
</p>
<a href="http://arxiv.org/abs/2007.11369" target="_blank">arXiv:2007.11369</a> [<a href="http://arxiv.org/pdf/2007.11369" target="_blank">pdf</a>]

<h2>PDE-Driven Spatiotemporal Disentanglement. (arXiv:2008.01352v2 [cs.LG] UPDATED)</h2>
<h3>J&#xe9;r&#xe9;mie Don&#xe0; (MLIA), Jean-Yves Franceschi (MLIA), Sylvain Lamprier (MLIA), Patrick Gallinari (MLIA)</h3>
<p>A recent line of work in the machine learning community addresses the problem
of predicting high-dimensional spatiotemporal phenomena by leveraging specific
tools from the differential equations theory. Following this direction, we
propose in this article a novel and general paradigm for this task based on a
resolution method for partial differential equations: the separation of
variables. This inspiration allows us to introduce a dynamical interpretation
of spatiotemporal disentanglement. It induces a principled model based on
learning disentangled spatial and temporal representations of a phenomenon to
accurately predict future observations. We experimentally demonstrate the
performance and broad applicability of our method against prior
state-of-the-art models on physical and synthetic video datasets.
</p>
<a href="http://arxiv.org/abs/2008.01352" target="_blank">arXiv:2008.01352</a> [<a href="http://arxiv.org/pdf/2008.01352" target="_blank">pdf</a>]

<h2>Learning to Set Waypoints for Audio-Visual Navigation. (arXiv:2008.09622v2 [cs.CV] UPDATED)</h2>
<h3>Changan Chen, Sagnik Majumder, Ziad Al-Halah, Ruohan Gao, Santhosh Kumar Ramakrishnan, Kristen Grauman</h3>
<p>In audio-visual navigation, an agent intelligently travels through a complex,
unmapped 3D environment using both sights and sounds to find a sound source
(e.g., a phone ringing in another room). Existing models learn to act at a
fixed granularity of agent motion and rely on simple recurrent aggregations of
the audio observations. We introduce a reinforcement learning approach to
audio-visual navigation with two key novel elements: 1) waypoints that are
dynamically set and learned end-to-end within the navigation policy, and 2) an
acoustic memory that provides a structured, spatially grounded record of what
the agent has heard as it moves. Both new ideas capitalize on the synergy of
audio and visual data for revealing the geometry of an unmapped space. We
demonstrate our approach on two challenging datasets of real-world 3D scenes,
Replica and Matterport3D. Our model improves the state of the art by a
substantial margin, and our experiments reveal that learning the links between
sights, sounds, and space is essential for audio-visual navigation.
</p>
<a href="http://arxiv.org/abs/2008.09622" target="_blank">arXiv:2008.09622</a> [<a href="http://arxiv.org/pdf/2008.09622" target="_blank">pdf</a>]

<h2>Uncovering Hidden Challenges in Query-Based Video Moment Retrieval. (arXiv:2009.00325v2 [cs.CV] UPDATED)</h2>
<h3>Mayu Otani, Yuta Nakashima, Esa Rahtu, Janne Heikkil&#xe4;</h3>
<p>The query-based moment retrieval is a problem of localising a specific clip
from an untrimmed video according a query sentence. This is a challenging task
that requires interpretation of both the natural language query and the video
content. Like in many other areas in computer vision and machine learning, the
progress in query-based moment retrieval is heavily driven by the benchmark
datasets and, therefore, their quality has significant impact on the field. In
this paper, we present a series of experiments assessing how well the benchmark
results reflect the true progress in solving the moment retrieval task. Our
results indicate substantial biases in the popular datasets and unexpected
behaviour of the state-of-the-art models. Moreover, we present new sanity check
experiments and approaches for visualising the results. Finally, we suggest
possible directions to improve the temporal sentence grounding in the future.
Our code for this paper is available at
https://mayu-ot.github.io/hidden-challenges-MR .
</p>
<a href="http://arxiv.org/abs/2009.00325" target="_blank">arXiv:2009.00325</a> [<a href="http://arxiv.org/pdf/2009.00325" target="_blank">pdf</a>]

<h2>FairXGBoost: Fairness-aware Classification in XGBoost. (arXiv:2009.01442v2 [cs.AI] UPDATED)</h2>
<h3>Srinivasan Ravichandran, Drona Khurana, Bharath Venkatesh, Narayanan Unny Edakunni</h3>
<p>Highly regulated domains such as finance have long favoured the use of
machine learning algorithms that are scalable, transparent, robust and yield
better performance. One of the most prominent examples of such an algorithm is
XGBoost. Meanwhile, there is also a growing interest in building fair and
unbiased models in these regulated domains and numerous bias-mitigation
algorithms have been proposed to this end. However, most of these
bias-mitigation methods are restricted to specific model families such as
logistic regression or support vector machine models, thus leaving modelers
with a difficult decision of choosing between fairness from the bias-mitigation
algorithms and scalability, transparency, performance from algorithms such as
XGBoost. We aim to leverage the best of both worlds by proposing a fair variant
of XGBoost that enjoys all the advantages of XGBoost, while also matching the
levels of fairness from the state-of-the-art bias-mitigation algorithms.
Furthermore, the proposed solution requires very little in terms of changes to
the original XGBoost library, thus making it easy for adoption. We provide an
empirical analysis of our proposed method on standard benchmark datasets used
in the fairness community.
</p>
<a href="http://arxiv.org/abs/2009.01442" target="_blank">arXiv:2009.01442</a> [<a href="http://arxiv.org/pdf/2009.01442" target="_blank">pdf</a>]

<h2>A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning. (arXiv:2009.08115v2 [cs.CL] UPDATED)</h2>
<h3>Yichi Zhang, Zhijian Ou, Huixin Wang, Junlan Feng</h3>
<p>Structured belief states are crucial for user goal tracking and database
query in task-oriented dialog systems. However, training belief trackers often
requires expensive turn-level annotations of every user utterance. In this
paper we aim at alleviating the reliance on belief state labels in building
end-to-end dialog systems, by leveraging unlabeled dialog data towards
semi-supervised learning. We propose a probabilistic dialog model, called the
LAtent BElief State (LABES) model, where belief states are represented as
discrete latent variables and jointly modeled with system responses given user
inputs. Such latent variable modeling enables us to develop semi-supervised
learning under the principled variational learning framework. Furthermore, we
introduce LABES-S2S, which is a copy-augmented Seq2Seq model instantiation of
LABES. In supervised experiments, LABES-S2S obtains strong results on three
benchmark datasets of different scales. In utilizing unlabeled dialog data,
semi-supervised LABES-S2S significantly outperforms both supervised-only and
semi-supervised baselines. Remarkably, we can reduce the annotation demands to
50% without performance loss on MultiWOZ.
</p>
<a href="http://arxiv.org/abs/2009.08115" target="_blank">arXiv:2009.08115</a> [<a href="http://arxiv.org/pdf/2009.08115" target="_blank">pdf</a>]

<h2>Intimate Partner Violence and Injury Prediction From Radiology Reports. (arXiv:2009.09084v2 [cs.CY] UPDATED)</h2>
<h3>Irene Y. Chen, Emily Alsentzer, Hyesun Park, Richard Thomas, Babina Gosangi, Rahul Gujrathi, Bharti Khurana</h3>
<p>Intimate partner violence (IPV) is an urgent, prevalent, and under-detected
public health issue. We present machine learning models to assess patients for
IPV and injury. We train the predictive algorithms on radiology reports with 1)
IPV labels based on entry to a violence prevention program and 2) injury labels
provided by emergency radiology fellowship-trained physicians. Our dataset
includes 34,642 radiology reports and 1479 patients of IPV victims and control
patients. Our best model predicts IPV a median of 3.08 years before violence
prevention program entry with a sensitivity of 64% and a specificity of 95%. We
conduct error analysis to determine for which patients our model has especially
high or low performance and discuss next steps for a deployed clinical risk
model.
</p>
<a href="http://arxiv.org/abs/2009.09084" target="_blank">arXiv:2009.09084</a> [<a href="http://arxiv.org/pdf/2009.09084" target="_blank">pdf</a>]

<h2>Structure Aware Negative Sampling in Knowledge Graphs. (arXiv:2009.11355v2 [cs.LG] UPDATED)</h2>
<h3>Kian Ahrabian, Aarash Feizi, Yasmin Salehi, William L. Hamilton, Avishek Joey Bose</h3>
<p>Learning low-dimensional representations for entities and relations in
knowledge graphs using contrastive estimation represents a scalable and
effective method for inferring connectivity patterns. A crucial aspect of
contrastive learning approaches is the choice of corruption distribution that
generates hard negative samples, which force the embedding model to learn
discriminative representations and find critical characteristics of observed
data. While earlier methods either employ too simple corruption distributions,
i.e. uniform, yielding easy uninformative negatives or sophisticated
adversarial distributions with challenging optimization schemes, they do not
explicitly incorporate known graph structure resulting in suboptimal negatives.
In this paper, we propose Structure Aware Negative Sampling (SANS), an
inexpensive negative sampling strategy that utilizes the rich graph structure
by selecting negative samples from a node's k-hop neighborhood. Empirically, we
demonstrate that SANS finds semantically meaningful negatives and is
competitive with SOTA approaches while requires no additional parameters nor
difficult adversarial optimization.
</p>
<a href="http://arxiv.org/abs/2009.11355" target="_blank">arXiv:2009.11355</a> [<a href="http://arxiv.org/pdf/2009.11355" target="_blank">pdf</a>]

<h2>Graph Adversarial Networks: Protecting Information against Adversarial Attacks. (arXiv:2009.13504v3 [cs.LG] UPDATED)</h2>
<h3>Peiyuan Liao, Han Zhao, Keyulu Xu, Tommi Jaakkola, Geoffrey Gordon, Stefanie Jegelka, Ruslan Salakhutdinov</h3>
<p>We study the problem of protecting information when learning with
graph-structured data. While the advent of Graph Neural Networks (GNNs) has
greatly improved node and graph representational learning in many applications,
the neighborhood aggregation paradigm exposes additional vulnerabilities to
attackers seeking to extract node-level information about sensitive attributes.
To counter this, we propose a minimax game between the desired GNN encoder and
the worst-case attacker. The resulting adversarial training creates a strong
defense against inference attacks, while only suffering a small loss in task
performance. We analyze the effectiveness of our framework against a worst-case
adversary, and characterize the trade-off between predictive accuracy and
adversarial defense. Experiments across multiple datasets from recommender
systems, knowledge graphs and quantum chemistry demonstrate that the proposed
approach provides a robust defense across various graph structures and tasks,
while producing competitive GNN encoders. Our code is available at
https://github.com/liaopeiyuan/GAL.
</p>
<a href="http://arxiv.org/abs/2009.13504" target="_blank">arXiv:2009.13504</a> [<a href="http://arxiv.org/pdf/2009.13504" target="_blank">pdf</a>]

<h2>Testing for Normality with Neural Networks. (arXiv:2009.13831v2 [stat.ML] UPDATED)</h2>
<h3>Milo&#x161; Simi&#x107;</h3>
<p>In this paper, we treat the problem of testing for normality as a binary
classification problem and construct a feedforward neural network that can
successfully detect normal distributions by inspecting small samples from them.
The numerical experiments conducted on small samples with no more than 100
elements indicated that the neural network which we trained was more accurate
and far more powerful than the most frequently used and most powerful standard
tests of normality: Shapiro-Wilk, Anderson-Darling, Lilliefors and
Jarque-Berra, as well as the kernel tests of goodness-of-fit. The neural
network had the AUROC score of almost 1, which corresponds to the perfect
binary classifier. Additionally, the network's accuracy was higher than 96% on
a set of larger samples with 250-1000 elements. Since the normality of data is
an assumption of numerous techniques for analysis and inference, the neural
network constructed in this study has a very high potential for use in everyday
practice of statistics, data analysis and machine learning in both science and
industry.
</p>
<a href="http://arxiv.org/abs/2009.13831" target="_blank">arXiv:2009.13831</a> [<a href="http://arxiv.org/pdf/2009.13831" target="_blank">pdf</a>]

<h2>Towards Effective Context for Meta-Reinforcement Learning: an Approach based on Contrastive Learning. (arXiv:2009.13891v2 [cs.LG] UPDATED)</h2>
<h3>Haotian Fu, Hongyao Tang, Jianye Hao, Chen Chen, Xidong Feng, Dong Li, Wulong Liu</h3>
<p>Context, the embedding of previous collected trajectories, is a powerful
construct for Meta-Reinforcement Learning (Meta-RL) algorithms. By conditioning
on an effective context, Meta-RL policies can easily generalize to new tasks
within a few adaptation steps. We argue that improving the quality of context
involves answering two questions: 1. How to train a compact and sufficient
encoder that can embed the task-specific information contained in prior
trajectories? 2. How to collect informative trajectories of which the
corresponding context reflects the specification of tasks? To this end, we
propose a novel Meta-RL framework called CCM (Contrastive learning augmented
Context-based Meta-RL). We first focus on the contrastive nature behind
different tasks and leverage it to train a compact and sufficient context
encoder. Further, we train a separate exploration policy and theoretically
derive a new information-gain-based objective which aims to collect informative
trajectories in a few steps. Empirically, we evaluate our approaches on common
benchmarks as well as several complex sparse-reward environments. The
experimental results show that CCM outperforms state-of-the-art algorithms by
addressing previously mentioned problems respectively.
</p>
<a href="http://arxiv.org/abs/2009.13891" target="_blank">arXiv:2009.13891</a> [<a href="http://arxiv.org/pdf/2009.13891" target="_blank">pdf</a>]

<h2>RG-Flow: A hierarchical and explainable flow model based on renormalization group and sparse prior. (arXiv:2010.00029v3 [cs.LG] UPDATED)</h2>
<h3>Hong-Ye Hu, Dian Wu, Yi-Zhuang You, Bruno Olshausen, Yubei Chen</h3>
<p>Flow-based generative models have become an important class of unsupervised
learning approaches. In this work, we incorporate the key idea of
renormalization group (RG) and sparse prior distribution to design a
hierarchical flow-based generative model, called RG-Flow, which can separate
different scale information of images with disentangle representations at each
scale. We demonstrate our method mainly on the CelebA dataset and show that the
disentangled representation at different scales enables semantic manipulation
and style mixing of the images. To visualize the latent representation, we
introduce the receptive fields for flow-based models and find receptive fields
learned by RG-Flow are similar to convolutional neural networks. In addition,
we replace the widely adopted Gaussian prior distribution by sparse prior
distributions to further enhance the disentanglement of representations. From a
theoretical perspective, the proposed method has $O(\log L)$ complexity for
image inpainting compared to previous flow-based models with $O(L^2)$
complexity.
</p>
<a href="http://arxiv.org/abs/2010.00029" target="_blank">arXiv:2010.00029</a> [<a href="http://arxiv.org/pdf/2010.00029" target="_blank">pdf</a>]

<h2>GCNNMatch: Graph Convolutional Neural Networks for Multi-Object Tracking via Sinkhorn Normalization. (arXiv:2010.00067v2 [cs.CV] UPDATED)</h2>
<h3>Ioannis Papakis, Abhijit Sarkar, Anuj Karpatne</h3>
<p>This paper proposes a novel method for online Multi-Object Tracking (MOT)
using Graph Convolutional Neural Network (GCNN) based feature extraction and
end-to-end feature matching for object association. The Graph based approach
incorporates both appearance and geometry of objects at past frames as well as
the current frame into the task of feature learning. This new paradigm enables
the network to leverage the "context" information of the geometry of objects
and allows us to model the interactions among the features of multiple objects.
Another central innovation of our proposed framework is the use of the Sinkhorn
algorithm for end-to-end learning of the associations among objects during
model training. The network is trained to predict object associations by taking
into account constraints specific to the MOT task. Experimental results
demonstrate the efficacy of the proposed approach in achieving top performance
on the MOT16 &amp; 17 Challenge problems among state-of-the-art online and
supervised approaches. The code is available at
https://github.com/IPapakis/GCNNMatch.
</p>
<a href="http://arxiv.org/abs/2010.00067" target="_blank">arXiv:2010.00067</a> [<a href="http://arxiv.org/pdf/2010.00067" target="_blank">pdf</a>]

<h2>A Deep Learning Framework for COVID Outbreak Prediction. (arXiv:2010.00382v2 [cs.LG] UPDATED)</h2>
<h3>Neeraj, Jimson Mathew, Ranjan Kumar Behera, Zenin Easa Panthakkalakath</h3>
<p>The outbreak of COVID-19 i.e. a variation of coronavirus, also known as novel
corona virus causing respiratory disease is a big concern worldwide since the
end of December 2019. As of September 12, 2020, it has turned into an epidemic
outbreak with more than 29 million confirmed cases and around 1 million
reported deaths worldwide. It has created an urgent need to monitor and
forecast COVID-19 spread behavior to better control this spread. Among all the
popular models for COVID-19 forecasting, statistical models are receiving much
attention in media. However, statistical models are showing less accuracy for
long term forecasting, as there is high level of uncertainty and required data
is also not sufficiently available. In this paper, we propose a comparative
analysis of deep learning models to forecast the COVID-19 outbreak as an
alternative to statistical models. We propose a new Attention-based
encoder-decoder model, named Attention-Long Short Term Memory (AttentionLSTM).
LSTM based neural network layer architecture incorporates the idea of
fine-grained attention mechanism i.e., attention on hidden state dimensions
instead of hidden state vector itself, which is capable of highlighting the
importance and contribution of each hidden state dimension. It helps in
detection on crucial temporal information, resulting in a highly interpretable
network. Additionally, we implement a learnable vector embedding for time. As,
time in a vector representation can be easily added with many architectures.
This vector representation is called Time2Vec. We have used COVID-19 data
repository by the Center for Systems Science and Engineering (CSSE) at Johns
Hopkins University to assess the proposed model's performance. The proposed
model give superior forecasting accuracy compared to other existing methods.
</p>
<a href="http://arxiv.org/abs/2010.00382" target="_blank">arXiv:2010.00382</a> [<a href="http://arxiv.org/pdf/2010.00382" target="_blank">pdf</a>]

<h2>COVID-19 Classification of X-ray Images Using Deep Neural Networks. (arXiv:2010.01362v2 [eess.IV] UPDATED)</h2>
<h3>Elisha Goldstein, Daphna Keidar, Daniel Yaron, Yair Shachar, Ayelet Blass, Leonid Charbinsky, Israel Aharony, Liza Lifshitz, Dimitri Lumelsky, Ziv Neeman, Matti Mizrachi, Majd Hajouj, Nethanel Eizenbach, Eyal Sela, Chedva S Weiss, Philip Levin, Ofer Benjaminov, Gil N Bachar, Shlomit Tamir, Yael Rapson, Dror Suhami, Amiel A Dror, Naama R Bogot, Ahuva Grubstein, Nogah Shabshin, Yishai M Elyada, Yonina C Eldar</h3>
<p>In the midst of the coronavirus disease 2019 (COVID-19) outbreak, chest X-ray
(CXR) imaging is playing an important role in the diagnosis and monitoring of
patients with COVID-19. Machine learning solutions have been shown to be useful
for X-ray analysis and classification in a range of medical contexts. The
purpose of this study is to create and evaluate a machine learning model for
diagnosis of COVID-19, and to provide a tool for searching for similar patients
according to their X-ray scans. In this retrospective study, a classifier was
built using a pre-trained deep learning model (ReNet50) and enhanced by data
augmentation and lung segmentation to detect COVID-19 in frontal CXR images
collected between January 2018 and July 2020 in four hospitals in Israel. A
nearest-neighbors algorithm was implemented based on the network results that
identifies the images most similar to a given image. The model was evaluated
using accuracy, sensitivity, area under the curve (AUC) of receiver operating
characteristic (ROC) curve and of the precision-recall (P-R) curve. The dataset
sourced for this study includes 2362 CXRs, balanced for positive and negative
COVID-19, from 1384 patients (63 +/- 18 years, 552 men). Our model achieved
89.7% (314/350) accuracy and 87.1% (156/179) sensitivity in classification of
COVID-19 on a test dataset comprising 15% (350 of 2326) of the original data,
with AUC of ROC 0.95 and AUC of the P-R curve 0.94. For each image we retrieve
images with the most similar DNN-based image embeddings; these can be used to
compare with previous cases.
</p>
<a href="http://arxiv.org/abs/2010.01362" target="_blank">arXiv:2010.01362</a> [<a href="http://arxiv.org/pdf/2010.01362" target="_blank">pdf</a>]

<h2>Efficient Inference For Neural Machine Translation. (arXiv:2010.02416v2 [cs.CL] UPDATED)</h2>
<h3>Yi-Te Hsu, Sarthak Garg, Yi-Hsiu Liao, Ilya Chatsviorkin</h3>
<p>Large Transformer models have achieved state-of-the-art results in neural
machine translation and have become standard in the field. In this work, we
look for the optimal combination of known techniques to optimize inference
speed without sacrificing translation quality. We conduct an empirical study
that stacks various approaches and demonstrates that combination of replacing
decoder self-attention with simplified recurrent units, adopting a deep encoder
and a shallow decoder architecture and multi-head attention pruning can achieve
up to 109% and 84% speedup on CPU and GPU respectively and reduce the number of
parameters by 25% while maintaining the same translation quality in terms of
BLEU.
</p>
<a href="http://arxiv.org/abs/2010.02416" target="_blank">arXiv:2010.02416</a> [<a href="http://arxiv.org/pdf/2010.02416" target="_blank">pdf</a>]

<h2>On the Role of Supervision in Unsupervised Constituency Parsing. (arXiv:2010.02423v2 [cs.CL] UPDATED)</h2>
<h3>Haoyue Shi, Karen Livescu, Kevin Gimpel</h3>
<p>We analyze several recent unsupervised constituency parsing models, which are
tuned with respect to the parsing $F_1$ score on the Wall Street Journal (WSJ)
development set (1,700 sentences). We introduce strong baselines for them, by
training an existing supervised parsing model (Kitaev and Klein, 2018) on the
same labeled examples they access. When training on the 1,700 examples, or even
when using only 50 examples for training and 5 for development, such a few-shot
parsing approach can outperform all the unsupervised parsing methods by a
significant margin. Few-shot parsing can be further improved by a simple data
augmentation method and self-training. This suggests that, in order to arrive
at fair conclusions, we should carefully consider the amount of labeled data
used for model development. We propose two protocols for future work on
unsupervised parsing: (i) use fully unsupervised criteria for hyperparameter
tuning and model selection; (ii) use as few labeled examples as possible for
model development, and compare to few-shot parsing trained on the same labeled
examples.
</p>
<a href="http://arxiv.org/abs/2010.02423" target="_blank">arXiv:2010.02423</a> [<a href="http://arxiv.org/pdf/2010.02423" target="_blank">pdf</a>]

<h2>Textual Supervision for Visually Grounded Spoken Language Understanding. (arXiv:2010.02806v2 [cs.CL] UPDATED)</h2>
<h3>Bertrand Higy, Desmond Elliott, Grzegorz Chrupa&#x142;a</h3>
<p>Visually-grounded models of spoken language understanding extract semantic
information directly from speech, without relying on transcriptions. This is
useful for low-resource languages, where transcriptions can be expensive or
impossible to obtain. Recent work showed that these models can be improved if
transcriptions are available at training time. However, it is not clear how an
end-to-end approach compares to a traditional pipeline-based approach when one
has access to transcriptions. Comparing different strategies, we find that the
pipeline approach works better when enough text is available. With low-resource
languages in mind, we also show that translations can be effectively used in
place of transcriptions but more data is needed to obtain similar results.
</p>
<a href="http://arxiv.org/abs/2010.02806" target="_blank">arXiv:2010.02806</a> [<a href="http://arxiv.org/pdf/2010.02806" target="_blank">pdf</a>]

<h2>Data Driven Density Functional Theory: A case for Physics Informed Learning. (arXiv:2010.03374v1 [cond-mat.stat-mech])</h2>
<h3>Peter Yatsyshin, Serafim Kalliadasis, Andrew B. Duncan</h3>
<p>We propose a novel data-driven approach to solving a classical statistical
mechanics problem: given data on collective motion of particles, characterise
the set of free energies associated with the system of particles. We
demonstrate empirically that the particle data contains all the information
necessary to infer a free energy. While traditional physical modelling seeks to
construct analytically tractable approximations, the proposed approach
leverages modern Bayesian computational capabilities to accomplish this in a
purely data-driven fashion. The Bayesian paradigm permits us to combine
underpinning physical principles with simulation data to obtain
uncertainty-quantified predictions of the free energy, in the form of a
probability distribution over the family of free energies consistent with the
observed particle data. In the present work we focus on classical statistical
mechanical systems with excluded volume interactions. Using standard
coarse-graining methods, our results can be made applicable to systems with
realistic attractive-repulsive interactions. We validate our method on a
paradigmatic and computationally cheap case of a one-dimensional fluid. With
the appropriate particle data, it is possible to learn canonical and
grand-canonical representations of the underlying physical system. Extensions
to higher-dimensional systems are conceptually straightforward.
</p>
<a href="http://arxiv.org/abs/2010.03374" target="_blank">arXiv:2010.03374</a> [<a href="http://arxiv.org/pdf/2010.03374" target="_blank">pdf</a>]

<h2>Better than the best? Answers via model ensemble in density-based clustering. (arXiv:1911.06726v2 [stat.ME] UPDATED)</h2>
<h3>Alessandro Casa, Luca Scrucca, Giovanna Menardi</h3>
<p>With the recent growth in data availability and complexity, and the
associated outburst of elaborate modelling approaches, model selection tools
have become a lifeline, providing objective criteria to deal with this
increasingly challenging landscape. In fact, basing predictions and inference
on a single model may be limiting if not harmful; ensemble approaches, which
combine different models, have been proposed to overcome the selection step,
and proven fruitful especially in the supervised learning framework.
Conversely, these approaches have been scantily explored in the unsupervised
setting. In this work we focus on the model-based clustering formulation, where
a plethora of mixture models, with different number of components and
parametrizations, is typically estimated. We propose an ensemble clustering
approach that circumvents the single best model paradigm, while improving
stability and robustness of the partitions. A new density estimator, being a
convex linear combination of the density estimates in the ensemble, is
introduced and exploited for group assignment. As opposed to the standard case,
where clusters are typically associated to the components of the selected
mixture model, we define partitions by borrowing the modal, or nonparametric,
formulation of the clustering problem, where groups are linked with
high-density regions. Staying in the density-based realm we thus show how
blending together parametric and nonparametric approaches may be beneficial
from a clustering perspective.
</p>
<a href="http://arxiv.org/abs/1911.06726" target="_blank">arXiv:1911.06726</a> [<a href="http://arxiv.org/pdf/1911.06726" target="_blank">pdf</a>]

<h2>Orbit: Probabilistic Forecast with Exponential Smoothing. (arXiv:2004.08492v3 [stat.CO] UPDATED)</h2>
<h3>Edwin Ng, Zhishi Wang, Huigang Chen, Steve Yang, Slawek Smyl</h3>
<p>Time series forecasting is an active research topic in academia as well as
industry. Although we see an increasing amount of adoptions of machine learning
methods in solving some of those forecasting challenges, statistical methods
remain powerful while dealing with low granularity data. This paper introduces
a refined Bayesian exponential smoothing model with the help of probabilistic
programming languages including Stan. Our model refinements include additional
global trend, transformation for multiplicative form, noise distribution and
choice of priors. A benchmark study is conducted on a rich set of time-series
data sets for our models along with other well-known time series models.
</p>
<a href="http://arxiv.org/abs/2004.08492" target="_blank">arXiv:2004.08492</a> [<a href="http://arxiv.org/pdf/2004.08492" target="_blank">pdf</a>]

