---
title: Latest Deep Learning Papers
date: 2020-10-19 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Hierarchical Reinforcement Learning for Optimal Control of Linear Multi-Agent Systems: the Homogeneous Case. (arXiv:2010.08615v1 [eess.SY])</h2>
<h3>Gangshan Jing, He Bai, Jemin George, Aranya Chakrabortty</h3>
<p>Individual agents in a multi-agent system (MAS) may have decoupled open-loop
dynamics, but a cooperative control objective usually results in coupled
closed-loop dynamics thereby making the control design computationally
expensive. The computation time becomes even higher when a learning strategy
such as reinforcement learning (RL) needs to be applied to deal with the
situation when the agents dynamics are not known. To resolve this problem, this
paper proposes a hierarchical RL scheme for a linear quadratic regulator (LQR)
design in a continuous-time linear MAS. The idea is to exploit the structural
properties of two graphs embedded in the $Q$ and $R$ weighting matrices in the
LQR objective to define an orthogonal transformation that can convert the
original LQR design to multiple decoupled smaller-sized LQR designs. We show
that if the MAS is homogeneous then this decomposition retains closed-loop
optimality. Conditions for decomposability, an algorithm for constructing the
transformation matrix, a hierarchical RL algorithm, and robustness analysis
when the design is applied to non-homogeneous MAS are presented. Simulations
show that the proposed approach can guarantee significant speed-up in learning
without any loss in the cumulative value of the LQR cost.
</p>
<a href="http://arxiv.org/abs/2010.08615" target="_blank">arXiv:2010.08615</a> [<a href="http://arxiv.org/pdf/2010.08615" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Efficient and Tuning-Free Link Adaptation. (arXiv:2010.08651v1 [eess.SP])</h2>
<h3>Vidit Saxena, Hugo Tullberg, Joakim Jald&#xe9;n</h3>
<p>Link adaptation (LA) optimizes the selection of modulation and coding schemes
(MCS) for a stochastic wireless channel. The classical outer loop LA (OLLA)
tracks the channel's signal-to-noise-and-interference ratio (SINR) based on the
observed transmission outcomes. On the other hand, recent Reinforcement
learning LA (RLLA) schemes sample the available MCSs to optimize the link
performance objective. However, both OLLA and RLLA rely on tuning parameters
that are challenging to configure. Further, OLLA optimizes for a target block
error rate (BLER) that only indirectly relates to the common
throughput-maximization objective, while RLLA does not fully exploit the
inter-dependence between the MCSs. In this paper, we propose latent Thompson
Sampling for LA (LTSLA), a RLLA scheme that does not require configuration
tuning, and which fully exploits MCS inter-dependence for efficient learning.
LTSLA models an SINR probability distribution for MCS selection, and refines
this distribution through Bayesian updates with the transmission outcomes.
LTSLA also automatically adapts to different channel fading profiles by
utilizing their respective Doppler estimates. We perform simulation studies of
LTSLA along with OLLA and RLLA schemes for frequency selective fading channels.
Numerical results demonstrate that LTSLA improves the instantaneous link
throughout by up to 50% compared to existing schemes.
</p>
<a href="http://arxiv.org/abs/2010.08651" target="_blank">arXiv:2010.08651</a> [<a href="http://arxiv.org/pdf/2010.08651" target="_blank">pdf</a>]

<h2>Generalized Intersection Algorithms with Fixpoints for Image Decomposition Learning. (arXiv:2010.08661v1 [cs.CV])</h2>
<h3>Robin Richter, Duy H. Thai, Stephan F. Huckemann</h3>
<p>In image processing, classical methods minimize a suitable functional that
balances between computational feasibility (convexity of the functional is
ideal) and suitable penalties reflecting the desired image decomposition. The
fact that algorithms derived from such minimization problems can be used to
construct (deep) learning architectures has spurred the development of
algorithms that can be trained for a specifically desired image decomposition,
e.g. into cartoon and texture. While many such methods are very successful,
theoretical guarantees are only scarcely available. To this end, in this
contribution, we formalize a general class of intersection point problems
encompassing a wide range of (learned) image decomposition models, and we give
an existence result for a large subclass of such problems, i.e. giving the
existence of a fixpoint of the corresponding algorithm. This class generalizes
classical model-based variational problems, such as the TV-l2 -model or the
more general TV-Hilbert model. To illustrate the potential for learned
algorithms, novel (non learned) choices within our class show comparable
results in denoising and texture removal.
</p>
<a href="http://arxiv.org/abs/2010.08661" target="_blank">arXiv:2010.08661</a> [<a href="http://arxiv.org/pdf/2010.08661" target="_blank">pdf</a>]

<h2>Constrained Motion Planning Networks X. (arXiv:2010.08707v1 [cs.RO])</h2>
<h3>Ahmed H. Qureshi, Jiangeng Dong, Asfiya Baig, Michael C. Yip</h3>
<p>Constrained motion planning is a challenging field of research, aiming for
computationally efficient methods that can find a collision-free path
connecting a given start and goal by transversing zero-volume constraint
manifolds for a given planning problem. These planning problems come up
surprisingly frequently, such as in robot manipulation for performing daily
life assistive tasks. However, few solutions to constrained motion planning are
available, and those that exist struggle with high computational time
complexity in finding a path solution on the manifolds. To address this
challenge, we present Constrained Motion Planning Networks X (CoMPNetX). It is
a neural planning approach, comprising a conditional deep neural generator and
discriminator with neural gradients-based fast projections to the constraint
manifolds. We also introduce neural task and scene representations conditioned
on which the CoMPNetX generates implicit manifold configurations to
turbo-charge any underlying classical planner such as Sampling-based Motion
Planning methods for quickly solving complex constrained planning tasks. We
show that our method, equipped with any constrained-adherence technique, finds
path solutions with high success rates and lower computation times than
state-of-the-art traditional path-finding tools on various challenging
scenarios.
</p>
<a href="http://arxiv.org/abs/2010.08707" target="_blank">arXiv:2010.08707</a> [<a href="http://arxiv.org/pdf/2010.08707" target="_blank">pdf</a>]

<h2>Tight Lower Complexity Bounds for Strongly Convex Finite-Sum Optimization. (arXiv:2010.08766v1 [cs.LG])</h2>
<h3>Min Zhang, Yao Shu, Kun He</h3>
<p>Finite-sum optimization plays an important role in the area of machine
learning, and hence has triggered a surge of interest in recent years. To
address this optimization problem, various randomized incremental gradient
methods have been proposed with guaranteed upper and lower complexity bounds
for their convergence. Nonetheless, these lower bounds rely on certain
conditions: deterministic optimization algorithm, or fixed probability
distribution for the selection of component functions. Meanwhile, some lower
bounds even do not match the upper bounds of the best known methods in certain
cases. To break these limitations, we derive tight lower complexity bounds of
randomized incremental gradient methods, including SAG, SAGA, SVRG, and SARAH,
for two typical cases of finite-sum optimization. Specifically, our results
tightly match the upper complexity of Katyusha when each component function is
strongly convex and smooth, and tightly match the upper complexity of SDCA
without duality and of KatyushaX when the finite-sum function is strongly
convex and the component functions are average smooth.
</p>
<a href="http://arxiv.org/abs/2010.08766" target="_blank">arXiv:2010.08766</a> [<a href="http://arxiv.org/pdf/2010.08766" target="_blank">pdf</a>]

<h2>Some new methods to build group equivariant non-expansive operators in TDA. (arXiv:2010.08823v1 [math.FA])</h2>
<h3>Nicola Quercioli</h3>
<p>Group equivariant operators are playing a more and more relevant role in
machine learning and topological data analysis. In this paper we present some
new results concerning the construction of $G$-equivariant non-expansive
operators (GENEOs) from a space $\varPhi$ of real-valued bounded continuous
functions on a topological space $X$ to $\varPhi$ itself. The space $\varPhi$
represents our set of data, while $G$ is a subgroup of the group of all
self-homeomorphisms of $X$, representing the invariance we are interested in.
</p>
<a href="http://arxiv.org/abs/2010.08823" target="_blank">arXiv:2010.08823</a> [<a href="http://arxiv.org/pdf/2010.08823" target="_blank">pdf</a>]

<h2>Approximate information state for approximate planning and reinforcement learning in partially observed systems. (arXiv:2010.08843v1 [cs.LG])</h2>
<h3>Jayakumar Subramanian, Amit Sinha, Raihan Seraj, Aditya Mahajan</h3>
<p>We propose a theoretical framework for approximate planning and learning in
partially observed systems. Our framework is based on the fundamental notion of
information state. We provide two equivalent definitions of information
state---i) a function of history which is sufficient to compute the expected
reward and predict its next value; ii) equivalently, a function of the history
which can be recursively updated and is sufficient to compute the expected
reward and predict the next observation. An information state always leads to a
dynamic programming decomposition. Our key result is to show that if a function
of the history (called approximate information state (AIS)) approximately
satisfies the properties of the information state, then there is a
corresponding approximate dynamic program. We show that the policy computed
using this is approximately optimal with bounded loss of optimality. We show
that several approximations in state, observation and action spaces in
literature can be viewed as instances of AIS. In some of these cases, we obtain
tighter bounds. A salient feature of AIS is that it can be learnt from data. We
present AIS based multi-time scale policy gradient algorithms. and detailed
numerical experiments with low, moderate and high dimensional environments.
</p>
<a href="http://arxiv.org/abs/2010.08843" target="_blank">arXiv:2010.08843</a> [<a href="http://arxiv.org/pdf/2010.08843" target="_blank">pdf</a>]

<h2>Fourier Neural Operator for Parametric Partial Differential Equations. (arXiv:2010.08895v1 [cs.LG])</h2>
<h3>Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, Anima Anandkumar</h3>
<p>The classical development of neural networks has primarily focused on
learning mappings between finite-dimensional Euclidean spaces. Recently, this
has been generalized to neural operators that learn mappings between function
spaces. For partial differential equations (PDEs), neural operators directly
learn the mapping from any functional parametric dependence to the solution.
Thus, they learn an entire family of PDEs, in contrast to classical methods
which solve one instance of the equation. In this work, we formulate a new
neural operator by parameterizing the integral kernel directly in Fourier
space, allowing for an expressive and efficient architecture. We perform
experiments on Burgers' equation, Darcy flow, and the Navier-Stokes equation
(including the turbulent regime). Our Fourier neural operator shows
state-of-the-art performance compared to existing neural network methodologies
and it is up to three orders of magnitude faster compared to traditional PDE
solvers.
</p>
<a href="http://arxiv.org/abs/2010.08895" target="_blank">arXiv:2010.08895</a> [<a href="http://arxiv.org/pdf/2010.08895" target="_blank">pdf</a>]

<h2>Max-Min Power Control in Downlink Massive MIMO with Distributed Antenna Arrays. (arXiv:2010.08966v1 [cs.IT])</h2>
<h3>Noman Akbar, Emil Bjornson, Nan Yang, Erik G. Larsson</h3>
<p>In this paper, we investigate optimal downlink power allocation in massive
multiple-input multiple-output (MIMO) networks with distributed antenna arrays
(DAAs) under correlated and uncorrelated channel fading. In DAA massive MIMO,
the base station (BS) consists of multiple antenna sub-arrays. Notably, the
antenna sub-arrays are deployed in arbitrary locations within a DAA massive
MIMO cell. Consequently, the distance-dependent large-scale propagation
coefficients are different from a user to these different antenna sub-arrays,
which makes power control a challenging problem. We assume that the network
operates in time-division duplex mode, where each BS obtains the channel
estimates via uplink pilots. Based on the channel estimates, the BSs perform
maximum-ratio transmission in the downlink. We then derive a closed-form
signal-to-interference-plus-noise ratio (SINR) expression, where the channels
are subject to correlated fading. Based on the SINR expression, we propose a
networkwide max-min power control algorithm to ensure that each user in the
network receives a uniform quality of service. Numerical results demonstrate
the performance advantages offered by DAA massive MIMO. For some specific
scenarios, DAA massive MIMO can improve the average per-user throughput up to
55%. Furthermore, we demonstrate that channel fading covariance is an important
factor in determining the performance of DAA massive MIMO.
</p>
<a href="http://arxiv.org/abs/2010.08966" target="_blank">arXiv:2010.08966</a> [<a href="http://arxiv.org/pdf/2010.08966" target="_blank">pdf</a>]

<h2>Sliding Differential Evolution Scheduling for Federated Learning in Bandwidth-Limited Networks. (arXiv:2010.08991v1 [cs.IT])</h2>
<h3>Yifan Luo, Jindan Xu, Wei Xu, Kezhi Wang</h3>
<p>Federated learning (FL) in a bandwidth-limited network with energy-limited
user equipments (UEs) is under-explored. In this paper, to jointly save energy
consumed by the battery-limited UEs and accelerate the convergence of the
global model in FL for the bandwidth-limited network, we propose the sliding
differential evolution-based scheduling (SDES) policy. To this end, we first
formulate an optimization that aims to minimize a weighted sum of energy
consumption and model training convergence. Then, we apply the SDES with
parallel differential evolution (DE) operations in several small-scale windows,
to address the above proposed problem effectively. Compared with existing
scheduling policies, the proposed SDES performs well in reducing energy
consumption and the model convergence with lower computational complexity.
</p>
<a href="http://arxiv.org/abs/2010.08991" target="_blank">arXiv:2010.08991</a> [<a href="http://arxiv.org/pdf/2010.08991" target="_blank">pdf</a>]

<h2>Visibility Optimization for Surveillance-Evasion Games. (arXiv:2010.09001v1 [cs.AI])</h2>
<h3>Louis Ly, Yen-Hsi Richard Tsai</h3>
<p>We consider surveillance-evasion differential games, where a pursuer must try
to constantly maintain visibility of a moving evader. The pursuer loses as soon
as the evader becomes occluded. Optimal controls for game can be formulated as
a Hamilton-Jacobi-Isaac equation. We use an upwind scheme to compute the
feedback value function, corresponding to the end-game time of the differential
game. Although the value function enables optimal controls, it is prohibitively
expensive to compute, even for a single pursuer and single evader on a small
grid. We consider a discrete variant of the surveillance-game. We propose two
locally optimal strategies based on the static value function for the
surveillance-evasion game with multiple pursuers and evaders. We show that
Monte Carlo tree search and self-play reinforcement learning can train a deep
neural network to generate reasonable strategies for on-line game play. Given
enough computational resources and offline training time, the proposed model
can continue to improve its policies and efficiently scale to higher
resolutions.
</p>
<a href="http://arxiv.org/abs/2010.09001" target="_blank">arXiv:2010.09001</a> [<a href="http://arxiv.org/pdf/2010.09001" target="_blank">pdf</a>]

<h2>On graded division rings. (arXiv:2010.09146v1 [math.RA])</h2>
<h3>Daniel E. N. Kawai, Javier S&#xe1;nchez</h3>
<p>We develop the theory of group graded division ring parallel to the one by P.
Cohn for (ungraded) division rings.
</p>
<a href="http://arxiv.org/abs/2010.09146" target="_blank">arXiv:2010.09146</a> [<a href="http://arxiv.org/pdf/2010.09146" target="_blank">pdf</a>]

<h2>Multi-Agent Deep Reinforcement Learning for Distributed Resource Management in Wirelessly Powered Communication Networks. (arXiv:2010.09171v1 [cs.IT])</h2>
<h3>Sangwon Hwang, Hanjin Kim, Hoon Lee, Inkyu Lee</h3>
<p>This paper studies multi-agent deep reinforcement learning (MADRL) based
resource allocation methods for multi-cell wireless powered communication
networks (WPCNs) where multiple hybrid access points (H-APs) wirelessly charge
energy-limited users to collect data from them. We design a distributed
reinforcement learning strategy where H-APs individually determine time and
power allocation variables. Unlike traditional centralized optimization
algorithms which require global information collected at a central unit, the
proposed MADRL technique models an H-AP as an agent producing its action based
only on its own locally observable states. Numerical results verify that the
proposed approach can achieve comparable performance of the centralized
algorithms.
</p>
<a href="http://arxiv.org/abs/2010.09171" target="_blank">arXiv:2010.09171</a> [<a href="http://arxiv.org/pdf/2010.09171" target="_blank">pdf</a>]

<h2>Safe and active parameter exploration for event-triggered control. (arXiv:2010.09174v1 [math.OC])</h2>
<h3>Kazumune Hashimoto</h3>
<p>This paper presents a framework of learning parameter space for
event-triggered control. In particular, our goal is to find a set of parameters
for the event-triggered condition, such that certain specifications on safety
and convergence properties are satisfied. The exploration strategy is based on
the Gaussian process-based active learning, in which, for each iteration, the
parameter with having the largest variance is evaluated. Moreover, we provide a
theoretical analysis, so that the derived parameter space satisfies both
convergence and safety. Finally, a numerical simulation is given to illustrate
the effectiveness of the approach.
</p>
<a href="http://arxiv.org/abs/2010.09174" target="_blank">arXiv:2010.09174</a> [<a href="http://arxiv.org/pdf/2010.09174" target="_blank">pdf</a>]

<h2>Extraction of Discrete Spectra Modes from Video Data Using a Deep Convolutional Koopman Network. (arXiv:2010.09245v1 [cs.CV])</h2>
<h3>Scott Leask, Vincent McDonell</h3>
<p>Recent deep learning extensions in Koopman theory have enabled compact,
interpretable representations of nonlinear dynamical systems which are amenable
to linear analysis. Deep Koopman networks attempt to learn the Koopman
eigenfunctions which capture the coordinate transformation to globally
linearize system dynamics. These eigenfunctions can be linked to underlying
system modes which govern the dynamical behavior of the system. While many
related techniques have demonstrated their efficacy on canonical systems and
their associated state variables, in this work the system dynamics are observed
optically (i.e. in video format). We demonstrate the ability of a deep
convolutional Koopman network (CKN) in automatically identifying independent
modes for dynamical systems with discrete spectra. Practically, this affords
flexibility in system data collection as the data are easily obtainable
observable variables. The learned models are able to successfully and robustly
identify the underlying modes governing the system, even with a redundantly
large embedding space. Modal disaggregation is encouraged using a simple
masking procedure. All of the systems analyzed in this work use an identical
network architecture.
</p>
<a href="http://arxiv.org/abs/2010.09245" target="_blank">arXiv:2010.09245</a> [<a href="http://arxiv.org/pdf/2010.09245" target="_blank">pdf</a>]

<h2>Frequency-Hopping MIMO Radar-Based Communications: An Overview. (arXiv:2010.09257v1 [eess.SP])</h2>
<h3>Kai Wu, J. Andrew Zhang, Xiaojing Huang, Y. Jay Guo</h3>
<p>Enabled by the advancement in radio frequency technologies, the convergence
of radar and communication systems becomes increasingly promising and is
envisioned as a key feature of future 6G networks. Recently, the
frequency-hopping (FH) MIMO radar is introduced to underlay dual-function
radar-communication (DFRC) systems. Superior to many previous radar-centric
DFRC designs, the symbol rate of FH-MIMO radar-based DFRC (FH-MIMO DFRC) can
exceed the radar pulse repetition frequency. However, many practical issues,
particularly those regarding effective data communications, are
unexplored/unsolved. To promote the awareness and general understanding of the
novel DFRC, this article is devoted to providing a timely introduction of
FH-MIMO DFRC. We comprehensively review many essential aspects of the novel
DFRC: channel/signal models, signaling strategies, modulation/demodulation
processing and channel estimation methods, to name a few. We also highlight
major remaining issues in FH-MIMO DFRC and suggest potential solutions to shed
light on future research works.
</p>
<a href="http://arxiv.org/abs/2010.09257" target="_blank">arXiv:2010.09257</a> [<a href="http://arxiv.org/pdf/2010.09257" target="_blank">pdf</a>]

<h2>Learning Exponential Family Graphical Models with Latent Variables using Regularized Conditional Likelihood. (arXiv:2010.09386v1 [stat.ML])</h2>
<h3>Armeen Taeb, Parikshit Shah, Venkat Chandrasekaran</h3>
<p>Fitting a graphical model to a collection of random variables given sample
observations is a challenging task if the observed variables are influenced by
latent variables, which can induce significant confounding statistical
dependencies among the observed variables. We present a new convex relaxation
framework based on regularized conditional likelihood for latent-variable
graphical modeling in which the conditional distribution of the observed
variables conditioned on the latent variables is given by an exponential family
graphical model. In comparison to previously proposed tractable methods that
proceed by characterizing the marginal distribution of the observed variables,
our approach is applicable in a broader range of settings as it does not
require knowledge about the specific form of distribution of the latent
variables and it can be specialized to yield tractable approaches to problems
in which the observed data are not well-modeled as Gaussian. We demonstrate the
utility and flexibility of our framework via a series of numerical experiments
on synthetic as well as real data.
</p>
<a href="http://arxiv.org/abs/2010.09386" target="_blank">arXiv:2010.09386</a> [<a href="http://arxiv.org/pdf/2010.09386" target="_blank">pdf</a>]

<h2>Multi-Armed Bandits with Dependent Arms. (arXiv:2010.09478v1 [cs.LG])</h2>
<h3>Rahul Singh, Fang Liu, Yin Sun, Ness Shroff</h3>
<p>We study a variant of the classical multi-armed bandit problem (MABP) which
we call as Multi-Armed Bandits with dependent arms.~More specifically, multiple
arms are grouped together to form a cluster, and the reward distributions of
arms belonging to the same cluster are known functions of an unknown parameter
that is a characteristic of the cluster. Thus, pulling an arm $i$ not only
reveals information about its own reward distribution, but also about all those
arms that share the same cluster with arm $i$. This "correlation" amongst the
arms complicates the exploration-exploitation trade-off that is encountered in
the MABP because the observation dependencies allow us to test simultaneously
multiple hypotheses regarding the optimality of an arm. We develop learning
algorithms based on the UCB principle which utilize these additional side
observations appropriately while performing exploration-exploitation trade-off.
We show that the regret of our algorithms grows as $O(K\log T)$, where $K$ is
the number of clusters. In contrast, for an algorithm such as the vanilla UCB
that is optimal for the classical MABP and does not utilize these dependencies,
the regret scales as $O(M\log T)$ where $M$ is the number of arms.
</p>
<a href="http://arxiv.org/abs/2010.09478" target="_blank">arXiv:2010.09478</a> [<a href="http://arxiv.org/pdf/2010.09478" target="_blank">pdf</a>]

<h2>Information-Theoretic Bounds on Transfer Generalization Gap Based on Jensen-Shannon Divergence. (arXiv:2010.09484v1 [cs.LG])</h2>
<h3>Sharu Theresa Jose, Osvaldo Simeone</h3>
<p>In transfer learning, training and testing data sets are drawn from different
data distributions. The transfer generalization gap is the difference between
the population loss on the target data distribution and the training loss. The
training data set generally includes data drawn from both source and target
distributions. This work presents novel information-theoretic upper bounds on
the average transfer generalization gap that capture (i) the domain shift
between the target data distribution $P'_Z$ and and the source distribution
$P_Z$ through Nielsen's family of $\alpha$-Jensen-Shannon (JS) divergences
$D_{JS}^{\alpha}(P'_Z || P_Z)$; and (ii) the sensitivity of the transfer
learner output $W$ to each individual sample of the data set $Z_i$ via the
mutual information $I(W;Z_i)$. The $\alpha$-JS divergence is bounded even when
the support of $P_Z$ is not included in that of $P'_Z$ . This contrasts the
Kullback- Leibler (KL) divergence $D_{KL}(P_Z||P'_Z)$-based bounds of Wu et al.
[1], which are vacuous under this assumption. Moreover, the obtained bounds
hold for unbounded loss functions with bounded cumulant generating functions,
unlike the $\phi$-divergence based bound of Wu et al. We also obtain new upper
bounds on the average transfer excess risk in terms of the $\alpha$-JS
divergence for empirical weighted risk minimization (EWRM), which minimizes the
weighted average training losses over source and target data sets. Finally, we
provide a numerical example to illustrate the merits of the introduced bounds.
</p>
<a href="http://arxiv.org/abs/2010.09484" target="_blank">arXiv:2010.09484</a> [<a href="http://arxiv.org/pdf/2010.09484" target="_blank">pdf</a>]

<h2>No-regreet learning and mixed Nash equilibria: They do not mix. (arXiv:2010.09514v1 [cs.GT])</h2>
<h3>Lampros Flokas, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Thanasis Lianeas, Panayotis Mertikopoulos, Georgios Piliouras</h3>
<p>Understanding the behavior of no-regret dynamics in general $N$-player games
is a fundamental question in online learning and game theory. A folk result in
the field states that, in finite games, the empirical frequency of play under
no-regret learning converges to the game's set of coarse correlated equilibria.
By contrast, our understanding of how the day-to-day behavior of the dynamics
correlates to the game's Nash equilibria is much more limited, and only partial
results are known for certain classes of games (such as zero-sum or congestion
games). In this paper, we study the dynamics of "follow-the-regularized-leader"
(FTRL), arguably the most well-studied class of no-regret dynamics, and we
establish a sweeping negative result showing that the notion of mixed Nash
equilibrium is antithetical to no-regret learning. Specifically, we show that
any Nash equilibrium which is not strict (in that every player has a unique
best response) cannot be stable and attracting under the dynamics of FTRL. This
result has significant implications for predicting the outcome of a learning
process as it shows unequivocally that only strict (and hence, pure) Nash
equilibria can emerge as stable limit points thereof.
</p>
<a href="http://arxiv.org/abs/2010.09514" target="_blank">arXiv:2010.09514</a> [<a href="http://arxiv.org/pdf/2010.09514" target="_blank">pdf</a>]

<h2>Learning to solve TV regularized problems with unrolled algorithms. (arXiv:2010.09545v1 [math.OC])</h2>
<h3>Hamza Cherkaoui, Jeremias Sulam, Thomas Moreau</h3>
<p>Total Variation (TV) is a popular regularization strategy that promotes
piece-wise constant signals by constraining the $\ell_1$-norm of the first
order derivative of the estimated signal. The resulting optimization problem is
usually solved using iterative algorithms such as proximal gradient descent,
primal-dual algorithms or ADMM. However, such methods can require a very large
number of iterations to converge to a suitable solution. In this paper, we
accelerate such iterative algorithms by unfolding proximal gradient descent
solvers in order to learn their parameters for 1D TV regularized problems.
While this could be done using the synthesis formulation, we demonstrate that
this leads to slower performances. The main difficulty in applying such methods
in the analysis formulation lies in proposing a way to compute the derivatives
through the proximal operator. As our main contribution, we develop and
characterize two approaches to do so, describe their benefits and limitations,
and discuss the regime where they can actually improve over iterative
procedures. We validate those findings with experiments on synthetic and real
data.
</p>
<a href="http://arxiv.org/abs/2010.09545" target="_blank">arXiv:2010.09545</a> [<a href="http://arxiv.org/pdf/2010.09545" target="_blank">pdf</a>]

<h2>Stability of 2-Parameter Persistent Homology. (arXiv:2010.09628v1 [math.AT])</h2>
<h3>Andrew J. Blumberg, Michael Lesnick</h3>
<p>The \v{C}ech and Rips constructions of persistent homology are stable with
respect to perturbations of the input data. However, neither is robust to
outliers, and both can be insensitive to topological structure of high-density
regions of the data. A natural solution is to consider 2-parameter persistence.
This paper studies the stability of 2-parameter persistent homology: We show
that several related density-sensitive constructions of bifiltrations from data
satisfy stability properties accommodating the addition and removal of
outliers. Specifically, we consider the multicover bifiltration, Sheehy's
subdivision bifiltrations, and the degree bifiltrations. For the multicover and
subdivision bifiltrations, we get 1-Lipschitz stability results closely
analogous to the standard stability results for 1-parameter persistent
homology. For the degree bifiltrations, only weaker results are possible.
</p>
<a href="http://arxiv.org/abs/2010.09628" target="_blank">arXiv:2010.09628</a> [<a href="http://arxiv.org/pdf/2010.09628" target="_blank">pdf</a>]

<h2>Probabilistic Linear Solvers for Machine Learning. (arXiv:2010.09691v1 [cs.LG])</h2>
<h3>Jonathan Wenger, Philipp Hennig</h3>
<p>Linear systems are the bedrock of virtually all numerical computation.
Machine learning poses specific challenges for the solution of such systems due
to their scale, characteristic structure, stochasticity and the central role of
uncertainty in the field. Unifying earlier work we propose a class of
probabilistic linear solvers which jointly infer the matrix, its inverse and
the solution from matrix-vector product observations. This class emerges from a
fundamental set of desiderata which constrains the space of possible algorithms
and recovers the method of conjugate gradients under certain conditions. We
demonstrate how to incorporate prior spectral information in order to calibrate
uncertainty and experimentally showcase the potential of such solvers for
machine learning.
</p>
<a href="http://arxiv.org/abs/2010.09691" target="_blank">arXiv:2010.09691</a> [<a href="http://arxiv.org/pdf/2010.09691" target="_blank">pdf</a>]

<h2>Planar Kinematics: Cyclic Fixed Points, Mirror Superpotential, k-Dimensional Catalan Numbers, and Root Polytopes. (arXiv:2010.09708v1 [math.CO])</h2>
<h3>Freddy Cachazo, Nick Early</h3>
<p>In this paper we prove that points in the space $X(k,n)$ of configurations of
$n$ points in $\mathbb{CP}^{k-1}$ which are fixed under a certain cyclic action
are the solutions to the generalized scattering equations on planar kinematics
(PK). In the first part, we give a constructive upper bound: we show that these
solutions inject into certain aperiodic k-element subsets of $\{1,\ldots, n\}$,
and consequently that their number is bounded above by the number of Lyndon
words with k one's and n-k zeros. The proof uses a somewhat surprising
connection between the superpotential of the mirror of $G(n-k,n)$ and the
generalized CHY potential on $X(k,n)$. We also check the recent conjecture that
generalized biadjoint amplitudes evaluate to $k$-dimensional Catalan numbers on
PK for several examples including $k=3$ and $n\leq 40$ and $(k,n)=(6,13)$. We
then reformulate the CEGM generalized biadjoint scalar amplitude directly as a
Laplace transform-type integral over ${\rm Trop}^+ G(k,n)$ and we use it to
evaluate the amplitude on PK with the purpose of exhibiting how GFD's glue
together.

We initiate the study of two minimal lattice polytopal neighborhoods of the
planar kinematics point. One of these, the rank-graded root polytope
$\mathcal{R}_{k,n}$, in the case $k=2$, is a projection of the standard type A
root polytope. The other, denoted $\Pi_{k,n}$, in the case $k=2$, is a
degeneration of the associahedron. We check up to and including
$\mathcal{R}_{3,9}$ and $\mathcal{R}_{4,9}$ that the relative volume of
$\mathcal{R}_{k,n}$ is the multi-dimensional Catalan number $C^{(k)}_{n-k}$,
hinting towards the possibility of deeper geometric and combinatorial
interpretations of $m^{(k)}(\mathbb{I}_n,\mathbb{I}_n)$ near the PK point.
</p>
<a href="http://arxiv.org/abs/2010.09708" target="_blank">arXiv:2010.09708</a> [<a href="http://arxiv.org/pdf/2010.09708" target="_blank">pdf</a>]

<h2>Regularized Orthogonal Machine Learning for Nonlinear Semiparametric Models. (arXiv:1806.04823v6 [math.ST] UPDATED)</h2>
<h3>Denis Nekipelov, Vira Semenova, Vasilis Syrgkanis</h3>
<p>This paper contributes to the literature on high-dimensional sparse
M-estimation by allowing the loss function to depend on a functional nuisance
parameter, which we estimate by modern machine learning tools. For a class of
single-index conditional moment restrictions (CMRs), we explicitly derive the
loss function. We first adjust the moment function so that the gradient of the
future M-estimator loss is insensitive (formally, Neyman-orthogonal) with
respect to the first-stage regularization bias. We then take the loss function
to be an indefinite integral of the adjusted moment function with respect to
the single-index. The proposed l1-regularized M-estimator achieves the oracle
convergence rate, where the oracle knows the nuisance parameter and solves only
the parametric problem. Our framework nests a novel approach to modeling
heterogeneous treatment effects with a binary dependent variable. In addition,
we apply our results to conditional moment models with missing data and static
games of incomplete information. Finally, we generalize our results to generic
extremum estimation with a nuisance component.
</p>
<a href="http://arxiv.org/abs/1806.04823" target="_blank">arXiv:1806.04823</a> [<a href="http://arxiv.org/pdf/1806.04823" target="_blank">pdf</a>]

<h2>On the Convergence of Adaptive Gradient Methods for Nonconvex Optimization. (arXiv:1808.05671v3 [cs.LG] UPDATED)</h2>
<h3>Dongruo Zhou, Jinghui Chen, Yuan Cao, Yiqi Tang, Ziyan Yang, Quanquan Gu</h3>
<p>Adaptive gradient methods are workhorses in deep learning. However, the
convergence guarantees of adaptive gradient methods for nonconvex optimization
have not been thoroughly studied. In this paper, we provide a fine-grained
convergence analysis for a general class of adaptive gradient methods including
AMSGrad, RMSProp and AdaGrad. For smooth nonconvex functions, we prove that
adaptive gradient methods in expectation converge to a first-order stationary
point. Our convergence rate is better than existing results for adaptive
gradient methods in terms of dimension, and is strictly faster than stochastic
gradient decent (SGD) when the stochastic gradients are sparse. To the best of
our knowledge, this is the first result showing the advantage of adaptive
gradient methods over SGD in nonconvex setting. In addition, we also prove high
probability bounds on the convergence rates of AMSGrad, RMSProp as well as
AdaGrad, which have not been established before. Our analyses shed light on
better understanding the mechanism behind adaptive gradient methods in
optimizing nonconvex objectives.
</p>
<a href="http://arxiv.org/abs/1808.05671" target="_blank">arXiv:1808.05671</a> [<a href="http://arxiv.org/pdf/1808.05671" target="_blank">pdf</a>]

<h2>Posterior Distribution for the Number of Clusters in Dirichlet Process Mixture Models. (arXiv:1905.09959v2 [stat.ML] UPDATED)</h2>
<h3>Chiao-Yu Yang, Eric Xia, Nhat Ho, Michael I. Jordan</h3>
<p>Dirichlet process mixture models (DPMM) play a central role in Bayesian
nonparametrics, with applications throughout statistics and machine learning.
DPMMs are generally used in clustering problems where the number of clusters is
not known in advance, and the posterior distribution is treated as providing
inference for this number. Recently, however, it has been shown that the DPMM
is inconsistent in inferring the true number of components in certain cases.
This is an asymptotic result, and it would be desirable to understand whether
it holds with finite samples, and to more fully understand the full posterior.
In this work, we provide a rigorous study for the posterior distribution of the
number of clusters in DPMM under different prior distributions on the
parameters and constraints on the distributions of the data. We provide novel
lower bounds on the ratios of probabilities between $s+1$ clusters and $s$
clusters when the prior distributions on parameters are chosen to be Gaussian
or uniform distributions.
</p>
<a href="http://arxiv.org/abs/1905.09959" target="_blank">arXiv:1905.09959</a> [<a href="http://arxiv.org/pdf/1905.09959" target="_blank">pdf</a>]

<h2>Graph MBO as a semi-discrete implicit Euler scheme for graph Allen-Cahn flow. (arXiv:1907.10774v2 [math.AP] UPDATED)</h2>
<h3>Jeremy Budd, Yves van Gennip</h3>
<p>In recent years there has been an emerging interest in PDE-like flows defined
on finite graphs, with applications in clustering and image segmentation. In
particular for image segmentation and semi-supervised learning Bertozzi and
Flenner (2012) developed an algorithm based on the Allen-Cahn gradient flow of
a graph Ginzburg-Landau functional, and Merkurjev, Kosti\'c and Bertozzi (2013)
devised a variant algorithm based instead on graph Merriman-Bence-Osher (MBO)
dynamics. This work offers rigorous justification for this use of the MBO
scheme in place of Allen-Cahn flow. First, we choose the double-obstacle
potential for the Ginzburg-Landau functional, and derive well-posedness and
regularity results for the resulting graph Allen-Cahn flow. Next, we exhibit a
"semi-discrete" time-discretisation scheme for Allen-Cahn flow of which the MBO
scheme is a special case. We investigate the long-time behaviour of this
scheme, and prove its convergence to the Allen-Cahn trajectory as the time-step
vanishes. Finally, following a question raised by Van Gennip, Guillen, Osting
and Bertozzi (2014), we exhibit results towards proving a link between
double-obstacle Allen-Cahn flow and mean curvature flow on graphs. We show some
promising $\Gamma$-convergence results, and translate to the graph setting two
comparison principles used by Chen and Elliott (1994) to prove the analogous
link in the continuum.
</p>
<a href="http://arxiv.org/abs/1907.10774" target="_blank">arXiv:1907.10774</a> [<a href="http://arxiv.org/pdf/1907.10774" target="_blank">pdf</a>]

<h2>Eight-dimensional Octonion-like but Associative Normed Division Algebra. (arXiv:1908.06172v6 [math.GM] UPDATED)</h2>
<h3>Joy Christian (Oxford)</h3>
<p>We present an eight-dimensional even sub-algebra of the 2^4 = 16-dimensional
associative Clifford algebra Cl(4,0) and show that its eight-dimensional
elements denoted as X and Y respect the norm relation ||XY|| = ||X|| ||Y||,
thus forming an octonion-like but associative normed division algebra, provided
the norms are calculated using fundamental geometric product instead of the
usual scalar product. The corresponding 7-sphere has a topology that differs
from that of octonionic 7-sphere.
</p>
<a href="http://arxiv.org/abs/1908.06172" target="_blank">arXiv:1908.06172</a> [<a href="http://arxiv.org/pdf/1908.06172" target="_blank">pdf</a>]

<h2>Ground Metric Learning on Graphs. (arXiv:1911.03117v2 [stat.ML] UPDATED)</h2>
<h3>Matthieu Heitz, Nicolas Bonneel, David Coeurjolly, Marco Cuturi, Gabriel Peyr&#xe9;</h3>
<p>Optimal transport (OT) distances between probability distributions are
parameterized by the ground metric they use between observations. Their
relevance for real-life applications strongly hinges on whether that ground
metric parameter is suitably chosen. Selecting it adaptively and
algorithmically from prior knowledge, the so-called ground metric learning GML)
problem, has therefore appeared in various settings. We consider it in this
paper when the learned metric is constrained to be a geodesic distance on a
graph that supports the measures of interest. This imposes a rich structure for
candidate metrics, but also enables far more efficient learning procedures when
compared to a direct optimization over the space of all metric matrices. We use
this setting to tackle an inverse problem stemming from the observation of a
density evolving with time: we seek a graph ground metric such that the OT
interpolation between the starting and ending densities that result from that
ground metric agrees with the observed evolution. This OT dynamic framework is
relevant to model natural phenomena exhibiting displacements of mass, such as
for instance the evolution of the color palette induced by the modification of
lighting and materials.
</p>
<a href="http://arxiv.org/abs/1911.03117" target="_blank">arXiv:1911.03117</a> [<a href="http://arxiv.org/pdf/1911.03117" target="_blank">pdf</a>]

<h2>Implicit Regularization and Convergence for Weight Normalization. (arXiv:1911.07956v3 [cs.LG] UPDATED)</h2>
<h3>Xiaoxia Wu, Edgar Dobriban, Tongzheng Ren, Shanshan Wu, Zhiyuan Li, Suriya Gunasekar, Rachel Ward, Qiang Liu</h3>
<p>Normalization methods such as batch [Ioffe and Szegedy, 2015], weight
[Salimansand Kingma, 2016], instance [Ulyanov et al., 2016], and layer
normalization [Baet al., 2016] have been widely used in modern machine
learning. Here, we study the weight normalization (WN) method [Salimans and
Kingma, 2016] and a variant called reparametrized projected gradient descent
(rPGD) for overparametrized least-squares regression. WN and rPGD reparametrize
the weights with a scale g and a unit vector w and thus the objective function
becomes non-convex. We show that this non-convex formulation has beneficial
regularization effects compared to gradient descent on the original objective.
These methods adaptively regularize the weights and converge close to the
minimum l2 norm solution, even for initializations far from zero. For certain
stepsizes of g and w , we show that they can converge close to the minimum norm
solution. This is different from the behavior of gradient descent, which
converges to the minimum norm solution only when started at a point in the
range space of the feature matrix, and is thus more sensitive to
initialization.
</p>
<a href="http://arxiv.org/abs/1911.07956" target="_blank">arXiv:1911.07956</a> [<a href="http://arxiv.org/pdf/1911.07956" target="_blank">pdf</a>]

<h2>Explicit Sequential Equilibria in LQ Deep Structured Games and Weighted Mean-Field Games. (arXiv:1912.03931v4 [math.OC] UPDATED)</h2>
<h3>Jalal Arabneydi, Amir G. Aghdam, Roland P. Malham&#xe9;</h3>
<p>In this paper, we investigate a class of nonzero-sum dynamic stochastic
games, where players have linear dynamics and quadratic cost functions. The
players are coupled in both dynamics and cost through a linear regression
(weighted average) as well as a quadratic regression (weighted covariance
matrix) of the states and actions, where the linear regression of states is
called deep state. We study collaborative and non-collaborative games under
three information structures: perfect sharing, deep state sharing, and no
sharing for three different types of weights: positive, homogeneous and
asymptotically vanishing weights. For perfect and deep state sharing
information structures, we propose a transformation-based technique to solve
for the best-response equations of players and identify a few sufficient
conditions under which a unique subgame perfect Nash equilibrium exists. The
equilibrium is linear in the local state and deep state, and the corresponding
gains are obtained by solving a novel non-standard Riccati equation (whose
dimension is independent of the number of players, thus making the solution
scalable). When the information structure is no-sharing and the number of
players is asymptotically large, one approximate population-size-dependent
equilibrium and one approximate population-size-independent equilibrium (also
called sequential weighted mean-field equilibrium) are proposed, and their
convergence to the infinite-population limits are established. In addition, the
main results are extended to infinite-horizon cost function, and generalized to
multiple orthogonal linear regressions and heterogeneous sub-populations. A
numerical example is provided to demonstrate the difference between the two
proposed approximate equilibria.
</p>
<a href="http://arxiv.org/abs/1912.03931" target="_blank">arXiv:1912.03931</a> [<a href="http://arxiv.org/pdf/1912.03931" target="_blank">pdf</a>]

<h2>A first-order optimization algorithm for statistical learning with hierarchical sparsity structure. (arXiv:2001.03322v3 [math.OC] UPDATED)</h2>
<h3>Dewei Zhang, Yin Liu, Sam Davanloo Tajbakhsh</h3>
<p>In many statistical learning problems, it is desired that the optimal
solution conforms to an a priori known sparsity structure represented by a
directed acyclic graph. Inducing such structures by means of convex
regularizers requires nonsmooth penalty functions that exploit group
overlapping. Our study focuses on evaluating the proximal operator of the
Latent Overlapping Group lasso developed by Jacob et al. (2009). We implemented
an Alternating Direction Method of Multiplier with a sharing scheme to solve
large-scale instances of the underlying optimization problem efficiently. In
the absence of strong convexity, global linear convergence of the algorithm is
established using the error bound theory. More specifically, the paper
contributes to establishing primal and dual error bounds when the nonsmooth
component in the objective function does not have a polyhedral epigraph. We
also investigate the effect of the graph structure on the speed of convergence
of the algorithm. Detailed numerical simulation studies over different graph
structures supporting the proposed algorithm and two applications in learning
are provided.
</p>
<a href="http://arxiv.org/abs/2001.03322" target="_blank">arXiv:2001.03322</a> [<a href="http://arxiv.org/pdf/2001.03322" target="_blank">pdf</a>]

<h2>Estimating the reach of a manifold via its convexity defect function. (arXiv:2001.08006v3 [math.ST] UPDATED)</h2>
<h3>Cl&#xe9;ment Berenfeld, John Harvey, Marc Hoffmann, Krishnan Shankar</h3>
<p>The reach of a submanifold is a crucial regularity parameter for manifold
learning and geometric inference from point clouds. This paper relates the
reach of a submanifold to its convexity defect function. Using the stability
properties of convexity defect functions, along with some new bounds and the
recent submanifold estimator of Aamari and Levrard [Ann. Statist. 47 177-204
(2019)], an estimator for the reach is given. A uniform expected loss bound
over a C^k model is found. Lower bounds for the minimax rate for estimating the
reach over these models are also provided. The estimator almost achieves these
rates in the C^3 and C^4 cases, with a gap given by a logarithmic factor.
</p>
<a href="http://arxiv.org/abs/2001.08006" target="_blank">arXiv:2001.08006</a> [<a href="http://arxiv.org/pdf/2001.08006" target="_blank">pdf</a>]

<h2>Convergence Rates of Accelerated Markov Gradient Descent with Applications in Reinforcement Learning. (arXiv:2002.02873v3 [math.OC] UPDATED)</h2>
<h3>Thinh T. Doan, Lam M. Nguyen, Nhan H. Pham, Justin Romberg</h3>
<p>Motivated by broad applications in machine learning, we study the popular
accelerated stochastic gradient descent (ASGD) algorithm for solving (possibly
nonconvex) optimization problems. We characterize the finite-time performance
of this method when the gradients are sampled from Markov processes, and hence
biased and dependent from time step to time step; in contrast, the analysis in
existing work relies heavily on the stochastic gradients being independent and
sometimes unbiased. Our main contributions show that under certain (standard)
assumptions on the underlying Markov chain generating the gradients, ASGD
converges at the nearly the same rate with Markovian gradient samples as with
independent gradient samples. The only difference is a logarithmic factor that
accounts for the mixing time of the Markov chain. One of the key motivations
for this study are complicated control problems that can be modeled by a Markov
decision process and solved using reinforcement learning. We apply the
accelerated method to several challenging problems in the OpenAI Gym and
Mujoco, and show that acceleration can significantly improve the performance of
the classic temporal difference learning and REINFORCE algorithms.
</p>
<a href="http://arxiv.org/abs/2002.02873" target="_blank">arXiv:2002.02873</a> [<a href="http://arxiv.org/pdf/2002.02873" target="_blank">pdf</a>]

<h2>Hard Shape-Constrained Kernel Machines. (arXiv:2005.12636v2 [stat.ML] UPDATED)</h2>
<h3>Pierre-Cyril Aubin-Frankowski, Zoltan Szabo</h3>
<p>Shape constraints (such as non-negativity, monotonicity, convexity) play a
central role in a large number of applications, as they usually improve
performance for small sample size and help interpretability. However enforcing
these shape requirements in a hard fashion is an extremely challenging problem.
Classically, this task is tackled (i) in a soft way (without out-of-sample
guarantees), (ii) by specialized transformation of the variables on a
case-by-case basis, or (iii) by using highly restricted function classes, such
as polynomials or polynomial splines. In this paper, we prove that hard affine
shape constraints on function derivatives can be encoded in kernel machines
which represent one of the most flexible and powerful tools in machine learning
and statistics. Particularly, we present a tightened second-order cone
constrained reformulation, that can be readily implemented in convex solvers.
We prove performance guarantees on the solution, and demonstrate the efficiency
of the approach in joint quantile regression with applications to economics and
to the analysis of aircraft trajectories, among others.
</p>
<a href="http://arxiv.org/abs/2005.12636" target="_blank">arXiv:2005.12636</a> [<a href="http://arxiv.org/pdf/2005.12636" target="_blank">pdf</a>]

<h2>Learning Restricted Boltzmann Machines with Sparse Latent Variables. (arXiv:2006.04166v2 [cs.LG] UPDATED)</h2>
<h3>Guy Bresler, Rares-Darius Buhai</h3>
<p>Restricted Boltzmann Machines (RBMs) are a common family of undirected
graphical models with latent variables. An RBM is described by a bipartite
graph, with all observed variables in one layer and all latent variables in the
other. We consider the task of learning an RBM given samples generated
according to it. The best algorithms for this task currently have time
complexity $\tilde{O}(n^2)$ for ferromagnetic RBMs (i.e., with attractive
potentials) but $\tilde{O}(n^d)$ for general RBMs, where $n$ is the number of
observed variables and $d$ is the maximum degree of a latent variable. Let the
MRF neighborhood of an observed variable be its neighborhood in the Markov
Random Field of the marginal distribution of the observed variables. In this
paper, we give an algorithm for learning general RBMs with time complexity
$\tilde{O}(n^{2^s+1})$, where $s$ is the maximum number of latent variables
connected to the MRF neighborhood of an observed variable. This is an
improvement when $s &lt; \log_2 (d-1)$, which corresponds to RBMs with sparse
latent variables. Furthermore, we give a version of this learning algorithm
that recovers a model with small prediction error and whose sample complexity
is independent of the minimum potential in the Markov Random Field of the
observed variables. This is of interest because the sample complexity of
current algorithms scales with the inverse of the minimum potential, which
cannot be controlled in terms of natural properties of the RBM.
</p>
<a href="http://arxiv.org/abs/2006.04166" target="_blank">arXiv:2006.04166</a> [<a href="http://arxiv.org/pdf/2006.04166" target="_blank">pdf</a>]

<h2>Fast Optimization with Zeroth-Order Feedback in Distributed, Multi-User MIMO Systems. (arXiv:2006.05445v2 [cs.IT] UPDATED)</h2>
<h3>Olivier Bilenne, Panayotis Mertikopoulos, E. Veronica Belmega</h3>
<p>In this paper, we develop a gradient-free optimization methodology for
efficient resource allocation in Gaussian MIMO multiple access channels. Our
approach combines two main ingredients: (i) an entropic semidefinite
optimization based on matrix exponential learning (MXL); and (ii) a one-shot
gradient estimator which achieves low variance through the reuse of past
information. This novel algorithm, which we call gradient-free MXL algorithm
with callbacks (MXL0$^{+}$), retains the convergence speed of gradient-based
methods while requiring minimal feedback per iteration$-$a single scalar. In
more detail, in a MIMO multiple access channel with $K$ users and $M$ transmit
antennas per user, the MXL0$^{+}$ algorithm achieves $\epsilon$-optimality
within $\text{poly}(K,M)/\epsilon^2$ iterations (on average and with high
probability), even when implemented in a fully distributed, asynchronous
manner. For cross-validation, we also perform a series of numerical experiments
in medium- to large-scale MIMO networks under realistic channel conditions.
Throughout our experiments, the performance of MXL0$^{+}$ matches$-$and
sometimes exceeds$-$that of gradient-based MXL methods, all the while operating
with a vastly reduced communication overhead. In view of these findings, the
MXL0$^{+}$ algorithm appears to be uniquely suited for distributed massive MIMO
systems where gradient calculations can become prohibitively expensive.
</p>
<a href="http://arxiv.org/abs/2006.05445" target="_blank">arXiv:2006.05445</a> [<a href="http://arxiv.org/pdf/2006.05445" target="_blank">pdf</a>]

<h2>Graphs isomorphisms under edge-replacements and the family of amoebas. (arXiv:2007.11769v2 [math.CO] UPDATED)</h2>
<h3>Yair Caro, Adriana Hansberg, Amanda Montejano</h3>
<p>Let $G$ be a graph of order $n$ and let $e\in E(G)$ and $e'\in
E(\overline{G}) \cup \{e\}$. If the graph $G-e+e'$ is isomorphic to $G$, we say
that $e\to e'$ is a \emph{feasible edge-replacement}. We call $G$ a \emph{local
amoeba} if, for any two copies $G_1$, $G_2$ of $G$ that are embedded in $K_n$,
$G_1$ can be transformed into $G_2$ by a chain of feasible edge-replacements.
On the other hand, $G$ is called \emph{global amoeba} if there is an integer $T
\ge 1$ such that $G \cup tK_1$ is a local amoeba for all $t \ge T$. We study
global and local amoebas under an underlying algebraic theoretical setting. In
this way, a deeper understanding of their structure and their intrinsic
properties as well as how these two families relate with each other comes into
light. Moreover, it is shown that any connected graph can be a connected
component of an amoeba, and a construction of a family of amoeba trees with a
Fibonacci-like structure and with arbitrary large maximum degree is presented.
</p>
<a href="http://arxiv.org/abs/2007.11769" target="_blank">arXiv:2007.11769</a> [<a href="http://arxiv.org/pdf/2007.11769" target="_blank">pdf</a>]

<h2>PowerGossip: Practical Low-Rank Communication Compression in Decentralized Deep Learning. (arXiv:2008.01425v2 [cs.LG] UPDATED)</h2>
<h3>Thijs Vogels, Sai Praneeth Karimireddy, Martin Jaggi</h3>
<p>Lossy gradient compression has become a practical tool to overcome the
communication bottleneck in centrally coordinated distributed training of
machine learning models. However, algorithms for decentralized training with
compressed communication over arbitrary connected networks have been more
complicated, requiring additional memory and hyperparameters. We introduce a
simple algorithm that directly compresses the model differences between
neighboring workers using low-rank linear compressors applied on model
differences. Inspired by the PowerSGD algorithm for centralized deep learning,
this algorithm uses power iteration steps to maximize the information
transferred per bit. We prove that our method requires no additional
hyperparameters, converges faster than prior methods, and is asymptotically
independent of both the network and the compression. Out of the box, these
compressors perform on par with state-of-the-art tuned compression algorithms
in a series of deep learning benchmarks.
</p>
<a href="http://arxiv.org/abs/2008.01425" target="_blank">arXiv:2008.01425</a> [<a href="http://arxiv.org/pdf/2008.01425" target="_blank">pdf</a>]

<h2>A Topological Framework for Deep Learning. (arXiv:2008.13697v9 [cs.LG] UPDATED)</h2>
<h3>Mustafa Hajij, Kyle Istvan</h3>
<p>We utilize classical facts from topology to show that the classification
problem in machine learning is always solvable under very mild conditions.
Furthermore, we show that a softmax classification network acts on an input
topological space by a finite sequence of topological moves to achieve the
classification task. Moreover, given a training dataset, we show how
topological formalism can be used to suggest the appropriate architectural
choices for neural networks designed to be trained as classifiers on the data.
Finally, we show how the architecture of a neural network cannot be chosen
independently from the shape of the underlying data. To demonstrate these
results, we provide example datasets and show how they are acted upon by neural
nets from this topological perspective.
</p>
<a href="http://arxiv.org/abs/2008.13697" target="_blank">arXiv:2008.13697</a> [<a href="http://arxiv.org/pdf/2008.13697" target="_blank">pdf</a>]

<h2>Low-Rank and Sparse Enhanced Tucker Decomposition for Tensor Completion. (arXiv:2010.00359v2 [cs.LG] UPDATED)</h2>
<h3>Chenjian Pan, Chen Ling, Hongjin He, Liqun Qi, Yanwei Xu</h3>
<p>Tensor completion refers to the task of estimating the missing data from an
incomplete measurement or observation, which is a core problem frequently
arising from the areas of big data analysis, computer vision, and network
engineering. Due to the multidimensional nature of high-order tensors, the
matrix approaches, e.g., matrix factorization and direct matricization of
tensors, are often not ideal for tensor completion and recovery. Exploiting the
potential periodicity and inherent correlation properties appeared in
real-world tensor data, in this paper, we shall incorporate the low-rank and
sparse regularization technique to enhance Tucker decomposition for tensor
completion. A series of computational experiments on real-world datasets,
including internet traffic data, color images, and face recognition, show that
our model performs better than many existing state-of-the-art matricization and
tensorization approaches in terms of achieving higher recovery accuracy.
</p>
<a href="http://arxiv.org/abs/2010.00359" target="_blank">arXiv:2010.00359</a> [<a href="http://arxiv.org/pdf/2010.00359" target="_blank">pdf</a>]

<h2>Learning to Decode: Reinforcement Learning for Decoding of Sparse Graph-Based Channel Codes. (arXiv:2010.05637v2 [cs.IT] UPDATED)</h2>
<h3>Salman Habib, Allison Beemer, Joerg Kliewer</h3>
<p>We show in this work that reinforcement learning can be successfully applied
to decoding short to moderate length sparse graph-based channel codes.
Specifically, we focus on low-density parity check (LDPC) codes, which for
example have been standardized in the context of 5G cellular communication
systems due to their excellent error correcting performance. These codes are
typically decoded via belief propagation iterative decoding on the
corresponding bipartite (Tanner) graph of the code via flooding, i.e., all
check and variable nodes in the Tanner graph are updated at once. In contrast,
in this paper we utilize a sequential update policy which selects the optimum
check node (CN) scheduling in order to improve decoding performance. In
particular, we model the CN update process as a multi-armed bandit process with
dependent arms and employ a Q-learning scheme for optimizing the CN scheduling
policy. In order to reduce the learning complexity, we propose a novel
graph-induced CN clustering approach to partition the state space in such a way
that dependencies between clusters are minimized. Our results show that
compared to other decoding approaches from the literature, the proposed
reinforcement learning scheme not only significantly improves the decoding
performance, but also reduces the decoding complexity dramatically once the
scheduling policy is learned.
</p>
<a href="http://arxiv.org/abs/2010.05637" target="_blank">arXiv:2010.05637</a> [<a href="http://arxiv.org/pdf/2010.05637" target="_blank">pdf</a>]

<h2>Regret Guarantees for Online Receding Horizon Control. (arXiv:2010.07269v2 [math.OC] UPDATED)</h2>
<h3>Deepan Muthirayan, Jianjun Yuan, Pramod P. Khargonekar</h3>
<p>In this paper we provide provable regret guarantees for an online receding
horizon type control policy in a setting where the system to be controlled is
an unknown linear dynamical system, the cost for the controller is a general
additive function over a finite period $T$, and there exist control input
constraints that when violated incur an additional cost. We show that the
learning based receding horizon control policy achieves the regret of
$O(T^{3/4})$ for both the controller's cost and cumulative constraint violation
w.r.t the baseline receding horizon control policy that has full knowledge of
the system.
</p>
<a href="http://arxiv.org/abs/2010.07269" target="_blank">arXiv:2010.07269</a> [<a href="http://arxiv.org/pdf/2010.07269" target="_blank">pdf</a>]

<h2>Consistency of archetypal analysis. (arXiv:2010.08148v2 [math.ST] UPDATED)</h2>
<h3>Braxton Osting, Dong Wang, Yiming Xu, Dominique Zosso</h3>
<p>Archetypal analysis is an unsupervised learning method that uses a convex
polytope to summarize multivariate data. For fixed $k$, the method finds a
convex polytope with $k$ vertices, called archetype points, such that the
polytope is contained in the convex hull of the data and the mean squared
distance between the data and the polytope is minimal. In this paper, we prove
a consistency result that shows if the data is independently sampled from a
probability measure with bounded support, then the archetype points converge to
a solution of the continuum version of the problem, of which we identify and
establish several properties. We also obtain the convergence rate of the
optimal objective values under appropriate assumptions on the distribution. If
the data is independently sampled from a distribution with unbounded support,
we also prove a consistency result for a modified method that penalizes the
dispersion of the archetype points. Our analysis is supported by detailed
computational experiments of the archetype points for data sampled from the
uniform distribution in a disk, the normal distribution, an annular
distribution, and a Gaussian mixture model.
</p>
<a href="http://arxiv.org/abs/2010.08148" target="_blank">arXiv:2010.08148</a> [<a href="http://arxiv.org/pdf/2010.08148" target="_blank">pdf</a>]

<h2>A bio-inspired geometric model for sound reconstruction. (arXiv:2004.02450v2 [eess.AS] CROSS LISTED)</h2>
<h3>Ugo Boscain (LJLL (UMR\_7598), CNRS, CaGE ), Dario Prandi (CNRS, L2S), Ludovic Sacchelli (LAGEPP), Giuseppina Turco (CNRS, LLF UMR7110)</h3>
<p>The reconstruction mechanisms built by the human auditory system during sound
reconstruction are still a matter of debate. The purpose of this study is to
propose a mathematical model of sound reconstruction based on the functional
architecture of the auditory cortex (A1). The model is inspired by the
geometrical modelling of vision, which has undergone a great development in the
last ten years. There are however fundamental dissimilarities, due to the
different role played by the time and the different group of symmetries. The
algorithm transforms the degraded sound in an 'image' in the time-frequency
domain via a short-time Fourier transform. Such an image is then lifted in the
Heisenberg group and it is reconstructed via a Wilson-Cowan differo-integral
equation. Preliminary numerical experiments are provided, showing the good
reconstruction properties of the algorithm on synthetic sounds concentrated
around two frequencies.
</p>
<a href="http://arxiv.org/abs/2004.02450" target="_blank">arXiv:2004.02450</a> [<a href="http://arxiv.org/pdf/2004.02450" target="_blank">pdf</a>]

<h2>ByzShield: An Efficient and Robust System for Distributed Training. (arXiv:2010.04902v1 [cs.LG] CROSS LISTED)</h2>
<h3>Konstantinos Konstantinidis, Aditya Ramamoorthy</h3>
<p>Training of large scale models on distributed clusters is a critical
component of the machine learning pipeline. However, this training can easily
be made to fail if some workers behave in an adversarial (Byzantine) fashion
whereby they return arbitrary results to the parameter server (PS). A plethora
of existing papers consider a variety of attack models and propose robust
aggregation and/or computational redundancy to alleviate the effects of these
attacks. In this work we consider an omniscient attack model where the
adversary has full knowledge about the gradient computation assignments of the
workers and can choose to attack (up to) any q out of n worker nodes to induce
maximal damage. Our redundancy-based method ByzShield leverages the properties
of bipartite expander graphs for the assignment of tasks to workers; this helps
to effectively mitigate the effect of the Byzantine behavior. Specifically, we
demonstrate an upper bound on the worst case fraction of corrupted gradients
based on the eigenvalues of our constructions which are based on mutually
orthogonal Latin squares and Ramanujan graphs. Our numerical experiments
indicate over a 36% reduction on average in the fraction of corrupted gradients
compared to the state of the art. Likewise, our experiments on training
followed by image classification on the CIFAR-10 dataset show that ByzShield
has on average a 20% advantage in accuracy under the most sophisticated
attacks. ByzShield also tolerates a much larger fraction of adversarial nodes
compared to prior work.
</p>
<a href="http://arxiv.org/abs/2010.04902" target="_blank">arXiv:2010.04902</a> [<a href="http://arxiv.org/pdf/2010.04902" target="_blank">pdf</a>]

<h2>A Generative Model based Adversarial Security of Deep Learning and Linear Classifier Models. (arXiv:2010.08546v1 [cs.LG])</h2>
<h3>erhat Ozgur Catak, Samed Sivaslioglu, Kevser Sahinbas</h3>
<p>In recent years, machine learning algorithms have been applied widely in
various fields such as health, transportation, and the autonomous car. With the
rapid developments of deep learning techniques, it is critical to take the
security concern into account for the application of the algorithms. While
machine learning offers significant advantages in terms of the application of
algorithms, the issue of security is ignored. Since it has many applications in
the real world, security is a vital part of the algorithms. In this paper, we
have proposed a mitigation method for adversarial attacks against machine
learning models with an autoencoder model that is one of the generative ones.
The main idea behind adversarial attacks against machine learning models is to
produce erroneous results by manipulating trained models. We have also
presented the performance of autoencoder models to various attack methods from
deep neural networks to traditional algorithms by using different methods such
as non-targeted and targeted attacks to multi-class logistic regression, a fast
gradient sign method, a targeted fast gradient sign method and a basic
iterative method attack to neural networks for the MNIST dataset.
</p>
<a href="http://arxiv.org/abs/2010.08546" target="_blank">arXiv:2010.08546</a> [<a href="http://arxiv.org/pdf/2010.08546" target="_blank">pdf</a>]

<h2>Characterizing the Latent Space of Molecular Deep Generative Models with Persistent Homology Metrics. (arXiv:2010.08548v1 [q-bio.BM])</h2>
<h3>Yair Schiff, Vijil Chenthamarakshan, Karthikeyan Natesan Ramamurthy, Payel Das</h3>
<p>Deep generative models are increasingly becoming integral parts of the in
silico molecule design pipeline and have dual goals of learning the chemical
and structural features that render candidate molecules viable while also being
flexible enough to generate novel designs. Specifically, Variational Auto
Encoders (VAEs) are generative models in which encoder-decoder network pairs
are trained to reconstruct training data distributions in such a way that the
latent space of the encoder network is smooth. Therefore, novel candidates can
be found by sampling from this latent space. However, the scope of
architectures and hyperparameters is vast and choosing the best combination for
in silico discovery has important implications for downstream success.
Therefore, it is important to develop a principled methodology for
distinguishing how well a given generative model is able to learn salient
molecular features. In this work, we propose a method for measuring how well
the latent space of deep generative models is able to encode structural and
chemical features of molecular datasets by correlating latent space metrics
with metrics from the field of topological data analysis (TDA). We apply our
evaluation methodology to a VAE trained on SMILES strings and show that 3D
topology information is consistently encoded throughout the latent space of the
model.
</p>
<a href="http://arxiv.org/abs/2010.08548" target="_blank">arXiv:2010.08548</a> [<a href="http://arxiv.org/pdf/2010.08548" target="_blank">pdf</a>]

<h2>Reflective Decoding: Unsupervised Paraphrasing and Abductive Reasoning. (arXiv:2010.08566v1 [cs.CL])</h2>
<h3>Peter West, Ximing Lu, Ari Holtzman, Chandra Bhagavatula, Jena Hwang, Yejin Choi</h3>
<p>Pretrained Language Models (LMs) generate text with remarkable quality,
novelty,and coherence. Yet applying LMs to the problems of paraphrasing and
infilling currently requires direct supervision, since these tasks break the
left-to-right generation setup of pretrained LMs. We present Reflective
Decoding, a novel unsupervised approach to apply the capabilities of pretrained
LMs to non-sequential tasks. Our approach is general and applicable to two
distant tasks - paraphrasing and abductive reasoning. It requires no
supervision or parallel corpora, only two pretrained language models: forward
and backward. Reflective Decoding operates in two intuitive steps. In the
contextualization step, we use LMs to generate many left and right contexts
which collectively capture the meaning of the input sentence. Then, in the
reflection step we decode in the semantic neighborhood of the input,
conditioning on an ensemble of generated contexts with the reverse direction
LM. We reflect through the generated contexts, effectively using them as an
intermediate meaning representation to generate conditional output. Empirical
results demonstrate that Reflective Decoding outperforms strong unsupervised
baselines on both paraphrasing and abductive text infilling, significantly
narrowing the gap between unsupervised and supervised methods.Reflective
Decoding introduces the concept of using generated contexts to represent
meaning, opening up new possibilities for unsupervised conditional text
generation.
</p>
<a href="http://arxiv.org/abs/2010.08566" target="_blank">arXiv:2010.08566</a> [<a href="http://arxiv.org/pdf/2010.08566" target="_blank">pdf</a>]

<h2>Generalizable Machine Learning in Neuroscience using Graph Neural Networks. (arXiv:2010.08569v1 [cs.LG])</h2>
<h3>Paul Y. Wang, Sandalika Sapra, Vivek Kurien George, Gabriel A. Silva</h3>
<p>Although a number of studies have explored deep learning in neuroscience, the
application of these algorithms to neural systems on a microscopic scale, i.e.
parameters relevant to lower scales of organization, remains relatively novel.
Motivated by advances in whole-brain imaging, we examined the performance of
deep learning models on microscopic neural dynamics and resulting emergent
behaviors using calcium imaging data from the nematode C. elegans. We show that
neural networks perform remarkably well on both neuron-level dynamics
prediction, and behavioral state classification. In addition, we compared the
performance of structure agnostic neural networks and graph neural networks to
investigate if graph structure can be exploited as a favorable inductive bias.
To perform this experiment, we designed a graph neural network which explicitly
infers relations between neurons from neural activity and leverages the
inferred graph structure during computations. In our experiments, we found that
graph neural networks generally outperformed structure agnostic models and
excel in generalization on unseen organisms, implying a potential path to
generalizable machine learning in neuroscience.
</p>
<a href="http://arxiv.org/abs/2010.08569" target="_blank">arXiv:2010.08569</a> [<a href="http://arxiv.org/pdf/2010.08569" target="_blank">pdf</a>]

<h2>Improving significance of binary black hole mergers in Advanced LIGO data using deep learning : Confirmation of GW151216. (arXiv:2010.08584v1 [gr-qc])</h2>
<h3>Shreejit Jadhav, Nikhil Mukund, Bhooshan Gadre, Sanjit Mitra, Sheelu Abraham</h3>
<p>We present a novel Machine Learning (ML) based strategy to search for compact
binary coalescences (CBCs) in data from ground-based gravitational wave (GW)
observatories. This is the first ML-based search that not only recovers all the
binary black hole mergers in the first GW transients calalog (GWTC-1), but also
makes a clean detection of GW151216, which was not significant enough to be
included in the catalogue. Moreover, we achieve this by only adding a new
coincident ranking statistic (MLStat) to a standard analysis that was used for
GWTC-1. In CBC searches, reducing contamination by terrestrial and instrumental
transients, which create a loud noise background by triggering numerous false
alarms, is crucial to improving the sensitivity for detecting true events. The
sheer volume of data and and large number of expected detections also prompts
the use of ML techniques. We perform transfer learning to train "InceptionV3",
a pre-trained deep neural network, along with curriculum learning to
distinguish GW signals from noisy events by analysing their continuous wavelet
transform (CWT) maps. MLStat incorporates information from this ML classifier
into the standard coincident search likelihood used by the conventional search.
This leads to at least an order of magnitude improvement in the inverse
false-alarm-rate (IFAR) for the previously "low significance" events GW151012,
GW170729 and GW151216. The confidence in detection of GW151216 is further
strengthened by performing its parameter estimation using \waveform.
Considering the impressive ability of the statistic to distinguish signals from
glitches, the list of marginal events from MLStat could be quite reliable for
astrophysical population studies and further follow-up. This work demonstrates
the immense potential and readiness of MLStat for finding new sources in
current data and possibility of its adaptation in similar searches.
</p>
<a href="http://arxiv.org/abs/2010.08584" target="_blank">arXiv:2010.08584</a> [<a href="http://arxiv.org/pdf/2010.08584" target="_blank">pdf</a>]

<h2>Learning Dexterous Manipulation from Suboptimal Experts. (arXiv:2010.08587v1 [cs.RO])</h2>
<h3>Rae Jeong, Jost Tobias Springenberg, Jackie Kay, Daniel Zheng, Yuxiang Zhou, Alexandre Galashov, Nicolas Heess, Francesco Nori</h3>
<p>Learning dexterous manipulation in high-dimensional state-action spaces is an
important open challenge with exploration presenting a major bottleneck.
Although in many cases the learning process could be guided by demonstrations
or other suboptimal experts, current RL algorithms for continuous action spaces
often fail to effectively utilize combinations of highly off-policy expert data
and on-policy exploration data. As a solution, we introduce Relative Entropy
Q-Learning (REQ), a simple policy iteration algorithm that combines ideas from
successful offline and conventional RL algorithms. It represents the optimal
policy via importance sampling from a learned prior and is well-suited to take
advantage of mixed data distributions. We demonstrate experimentally that REQ
outperforms several strong baselines on robotic manipulation tasks for which
suboptimal experts are available. We show how suboptimal experts can be
constructed effectively by composing simple waypoint tracking controllers, and
we also show how learned primitives can be combined with waypoint controllers
to obtain reference behaviors to bootstrap a complex manipulation task on a
simulated bimanual robot with human-like hands. Finally, we show that REQ is
also effective for general off-policy RL, offline RL, and RL from
demonstrations. Videos and further materials are available at
sites.google.com/view/rlfse.
</p>
<a href="http://arxiv.org/abs/2010.08587" target="_blank">arXiv:2010.08587</a> [<a href="http://arxiv.org/pdf/2010.08587" target="_blank">pdf</a>]

<h2>Deep Submodular Networks for Extractive Data Summarization. (arXiv:2010.08593v1 [cs.LG])</h2>
<h3>Suraj Kothawade, Jiten Girdhar, Chandrashekhar Lavania, Rishabh Iyer</h3>
<p>Deep Models are increasingly becoming prevalent in summarization problems
(e.g. document, video and images) due to their ability to learn complex feature
interactions and representations. However, they do not model characteristics
such as diversity, representation, and coverage, which are also very important
for summarization tasks. On the other hand, submodular functions naturally
model these characteristics because of their diminishing returns property. Most
approaches for modelling and learning submodular functions rely on very simple
models, such as weighted mixtures of submodular functions. Unfortunately, these
models only learn the relative importance of the different submodular functions
(such as diversity, representation or importance), but cannot learn more
complex feature representations, which are often required for state-of-the-art
performance. We propose Deep Submodular Networks (DSN), an end-to-end learning
framework that facilitates the learning of more complex features and richer
functions, crafted for better modelling of all aspects of summarization. The
DSN framework can be used to learn features appropriate for summarization from
scratch. We demonstrate the utility of DSNs on both generic and query focused
image-collection summarization, and show significant improvement over the
state-of-the-art. In particular, we show that DSNs outperform simple mixture
models using off the shelf features. Secondly, we also show that just using
four submodular functions in a DSN with end-to-end learning performs comparably
to the state-of-the-art mixture model with a hand-crafted set of 594 components
and outperforms other methods for image collection summarization.
</p>
<a href="http://arxiv.org/abs/2010.08593" target="_blank">arXiv:2010.08593</a> [<a href="http://arxiv.org/pdf/2010.08593" target="_blank">pdf</a>]

<h2>Flow-FL: Data-Driven Federated Learning for Spatio-Temporal Predictions in Multi-Robot Systems. (arXiv:2010.08595v1 [cs.RO])</h2>
<h3>Nathalie Majcherczyk, Nishan Srishankar, Carlo Pinciroli</h3>
<p>In this paper, we show how the Federated Learning (FL) framework enables
learning collectively from distributed data in connected robot teams. This
framework typically works with clients collecting data locally, updating neural
network weights of their model, and sending updates to a server for aggregation
into a global model. We explore the design space of FL by comparing two
variants of this concept. The first variant follows the traditional FL approach
in which a server aggregates the local models. In the second variant, that we
call Flow-FL, the aggregation process is serverless thanks to the use of a
gossip-based shared data structure. In both variants, we use a data-driven
mechanism to synchronize the learning process in which robots contribute model
updates when they collect sufficient data. We validate our approach with an
agent trajectory forecasting problem in a multi-agent setting. Using a
centralized implementation as a baseline, we study the effects of staggered
online data collection, and variations in data flow, number of participating
robots, and time delays introduced by the decentralization of the framework in
a multi-robot setting.
</p>
<a href="http://arxiv.org/abs/2010.08595" target="_blank">arXiv:2010.08595</a> [<a href="http://arxiv.org/pdf/2010.08595" target="_blank">pdf</a>]

<h2>Efficient Robotic Object Search via HIEM: Hierarchical Policy Learning with Intrinsic-Extrinsic Modeling. (arXiv:2010.08596v1 [cs.RO])</h2>
<h3>Xin Ye, Yezhou Yang</h3>
<p>Despite the significant success at enabling robots with autonomous behaviors
makes deep reinforcement learning a promising approach for robotic object
search task, the deep reinforcement learning approach severely suffers from the
nature sparse reward setting of the task. To tackle this challenge, we present
a novel policy learning paradigm for the object search task, based on
hierarchical and interpretable modeling with an intrinsic-extrinsic reward
setting. More specifically, we explore the environment efficiently through a
proxy low-level policy which is driven by the intrinsic rewarding sub-goals. We
further learn our hierarchical policy from the efficient exploration experience
where we optimize both of our high-level and low-level policies towards the
extrinsic rewarding goal to perform the object search task well. Experiments
conducted on the House3D environment validate and show that the robot, trained
with our model, can perform the object search task in a more optimal and
interpretable way.
</p>
<a href="http://arxiv.org/abs/2010.08596" target="_blank">arXiv:2010.08596</a> [<a href="http://arxiv.org/pdf/2010.08596" target="_blank">pdf</a>]

<h2>Robot Navigation in Constrained Pedestrian Environments using Reinforcement Learning. (arXiv:2010.08600v1 [cs.RO])</h2>
<h3>Claudia P&#xe9;rez-D&#x27;Arpino, Can Liu, Patrick Goebel, Roberto Mart&#xed;n-Mart&#xed;n, Silvio Savarese</h3>
<p>Navigating fluently around pedestrians is a necessary capability for mobile
robots deployed in human environments, such as office buildings and homes.
While related literature has addressed the co-navigation problem focused on the
scalability with the number of pedestrians in open spaces, typical indoor
environments present the additional challenge of constrained spaces such as
corridors, doorways and crosswalks that limit maneuverability and influence
patterns of pedestrian interaction. We present an approach based on
reinforcement learning to learn policies capable of dynamic adaptation to the
presence of moving pedestrians while navigating between desired locations in
constrained environments. The policy network receives guidance from a motion
planner that provides waypoints to follow a globally planned trajectory,
whereas the reinforcement component handles the local interactions. We explore
a compositional principle for multi-layout training and find that policies
trained in a small set of geometrically simple layouts successfully generalize
to unseen and more complex layouts that exhibit composition of the simple
structural elements available during training. Going beyond wall-world like
domains, we show transfer of the learned policy to unseen 3D reconstructions of
two real environments (market, home). These results support the applicability
of the compositional principle to real-world environments and indicate
promising usage of agent simulation within reconstructed environments for tasks
that involve interaction.
</p>
<a href="http://arxiv.org/abs/2010.08600" target="_blank">arXiv:2010.08600</a> [<a href="http://arxiv.org/pdf/2010.08600" target="_blank">pdf</a>]

<h2>DeepIntent: ImplicitIntent based Android IDS with E2E Deep Learning architecture. (arXiv:2010.08607v1 [cs.CR])</h2>
<h3>Mohit Sewak, Sanjay K. Sahay, Hemant Rathore</h3>
<p>The Intent in Android plays an important role in inter-process and
intra-process communications. The implicit Intent that an application could
accept are declared in its manifest and are amongst the easiest feature to
extract from an apk. Implicit Intents could even be extracted online and in
real-time. So far neither the feasibility of developing an Intrusion Detection
System solely on implicit Intent has been explored, nor are any benchmarks
available of a malware classifier that is based on implicit Intent alone. We
demonstrate that despite Intent is implicit and well declared, it can provide
very intuitive insights to distinguish malicious from non-malicious
applications. We conducted exhaustive experiments with over 40 different
end-to-end Deep Learning configurations of Auto-Encoders and
Multi-Layer-Perceptron to create a benchmark for a malware classifier that
works exclusively on implicit Intent. Using the results from the experiments we
create an intrusion detection system using only the implicit Intents and
end-to-end Deep Learning architecture. We obtained an area-under-curve
statistic of 0.81, and accuracy of 77.2% along with false-positive-rate of 0.11
on Drebin dataset.
</p>
<a href="http://arxiv.org/abs/2010.08607" target="_blank">arXiv:2010.08607</a> [<a href="http://arxiv.org/pdf/2010.08607" target="_blank">pdf</a>]

<h2>DOOM: A Novel Adversarial-DRL-Based Op-Code Level Metamorphic Malware Obfuscator for the Enhancement of IDS. (arXiv:2010.08608v1 [cs.CR])</h2>
<h3>Mohit Sewak, Sanjay K. Sahay, Hemant Rathore</h3>
<p>We designed and developed DOOM (Adversarial-DRL based Opcode level Obfuscator
to generate Metamorphic malware), a novel system that uses adversarial deep
reinforcement learning to obfuscate malware at the op-code level for the
enhancement of IDS. The ultimate goal of DOOM is not to give a potent weapon in
the hands of cyber-attackers, but to create defensive-mechanisms against
advanced zero-day attacks. Experimental results indicate that the obfuscated
malware created by DOOM could effectively mimic multiple-simultaneous zero-day
attacks. To the best of our knowledge, DOOM is the first system that could
generate obfuscated malware detailed to individual op-code level. DOOM is also
the first-ever system to use efficient continuous action control based deep
reinforcement learning in the area of malware generation and defense.
Experimental results indicate that over 67% of the metamorphic malware
generated by DOOM could easily evade detection from even the most potent IDS.
This achievement gains significance, as with this, even IDS augment with
advanced routing sub-system can be easily evaded by the malware generated by
DOOM.
</p>
<a href="http://arxiv.org/abs/2010.08608" target="_blank">arXiv:2010.08608</a> [<a href="http://arxiv.org/pdf/2010.08608" target="_blank">pdf</a>]

<h2>Universal guarantees for decision tree induction via a higher-order splitting criterion. (arXiv:2010.08633v1 [cs.LG])</h2>
<h3>Guy Blanc, Neha Gupta, Jane Lange, Li-Yang Tan</h3>
<p>We propose a simple extension of top-down decision tree learning heuristics
such as ID3, C4.5, and CART. Our algorithm achieves provable guarantees for all
target functions $f: \{-1,1\}^n \to \{-1,1\}$ with respect to the uniform
distribution, circumventing impossibility results showing that existing
heuristics fare poorly even for simple target functions. The crux of our
extension is a new splitting criterion that takes into account the correlations
between $f$ and small subsets of its attributes. The splitting criteria of
existing heuristics (e.g. Gini impurity and information gain), in contrast, are
based solely on the correlations between $f$ and its individual attributes.

Our algorithm satisfies the following guarantee: for all target functions $f
: \{-1,1\}^n \to \{-1,1\}$, sizes $s\in \mathbb{N}$, and error parameters
$\epsilon$, it constructs a decision tree of size $s^{\tilde{O}((\log
s)^2/\epsilon^2)}$ that achieves error $\le O(\mathsf{opt}_s) + \epsilon$,
where $\mathsf{opt}_s$ denotes the error of the optimal size $s$ decision tree.
A key technical notion that drives our analysis is the noise stability of $f$,
a well-studied smoothness measure.
</p>
<a href="http://arxiv.org/abs/2010.08633" target="_blank">arXiv:2010.08633</a> [<a href="http://arxiv.org/pdf/2010.08633" target="_blank">pdf</a>]

<h2>A general approach to compute the relevance of middle-level input features. (arXiv:2010.08639v1 [cs.LG])</h2>
<h3>Andrea Apicella, Salvatore Giugliano, Francesco Isgr&#xf2;, Roberto Prevete</h3>
<p>This work proposes a novel general framework, in the context of eXplainable
Artificial Intelligence (XAI), to construct explanations for the behaviour of
Machine Learning (ML) models in terms of middle-level features. One can isolate
two different ways to provide explanations in the context of XAI: low and
middle-level explanations. Middle-level explanations have been introduced for
alleviating some deficiencies of low-level explanations such as, in the context
of image classification, the fact that human users are left with a significant
interpretive burden: starting from low-level explanations, one has to identify
properties of the overall input that are perceptually salient for the human
visual system. However, a general approach to correctly evaluate the elements
of middle-level explanations with respect ML model responses has never been
proposed in the literature.
</p>
<a href="http://arxiv.org/abs/2010.08639" target="_blank">arXiv:2010.08639</a> [<a href="http://arxiv.org/pdf/2010.08639" target="_blank">pdf</a>]

<h2>Zoom-CAM: Generating Fine-grained Pixel Annotations from Image Labels. (arXiv:2010.08644v1 [cs.CV])</h2>
<h3>Xiangwei Shi, Seyran Khademi, Yunqiang Li, Jan van Gemert</h3>
<p>Current weakly supervised object localization and segmentation rely on
class-discriminative visualization techniques to generate pseudo-labels for
pixel-level training. Such visualization methods, including class activation
mapping (CAM) and Grad-CAM, use only the deepest, lowest resolution
convolutional layer, missing all information in intermediate layers. We propose
Zoom-CAM: going beyond the last lowest resolution layer by integrating the
importance maps over all activations in intermediate layers. Zoom-CAM captures
fine-grained small-scale objects for various discriminative class instances,
which are commonly missed by the baseline visualization methods. We focus on
generating pixel-level pseudo-labels from class labels. The quality of our
pseudo-labels evaluated on the ImageNet localization task exhibits more than
2.8% improvement on top-1 error. For weakly supervised semantic segmentation
our generated pseudo-labels improve a state of the art model by 1.1%.
</p>
<a href="http://arxiv.org/abs/2010.08644" target="_blank">arXiv:2010.08644</a> [<a href="http://arxiv.org/pdf/2010.08644" target="_blank">pdf</a>]

<h2>Cross-Lingual Relation Extraction with Transformers. (arXiv:2010.08652v1 [cs.CL])</h2>
<h3>Jian Ni, Taesun Moon, Parul Awasthy, Radu Florian</h3>
<p>Relation extraction (RE) is one of the most important tasks in information
extraction, as it provides essential information for many NLP applications. In
this paper, we propose a cross-lingual RE approach that does not require any
human annotation in a target language or any cross-lingual resources. Building
upon unsupervised cross-lingual representation learning frameworks, we develop
several deep Transformer based RE models with a novel encoding scheme that can
effectively encode both entity location and entity type information. Our RE
models, when trained with English data, outperform several deep neural network
based English RE models. More importantly, our models can be applied to perform
zero-shot cross-lingual RE, achieving the state-of-the-art cross-lingual RE
performance on two datasets (68-89% of the accuracy of the supervised
target-language RE model). The high cross-lingual transfer efficiency without
requiring additional training data or cross-lingual resources shows that our RE
models are especially useful for low-resource languages.
</p>
<a href="http://arxiv.org/abs/2010.08652" target="_blank">arXiv:2010.08652</a> [<a href="http://arxiv.org/pdf/2010.08652" target="_blank">pdf</a>]

<h2>Adaptive Dense-to-Sparse Paradigm for Pruning Online Recommendation System with Non-Stationary Data. (arXiv:2010.08655v1 [cs.LG])</h2>
<h3>Mao Ye, Dhruv Choudhary, Jiecao Yu, Ellie Wen, Zeliang Chen, Jiyan Yang, Jongsoo Park, Qiang Liu, Arun Kejariwal</h3>
<p>Large scale deep learning provides a tremendous opportunity to improve the
quality of content recommendation systems by employing both wider and deeper
models, but this comes at great infrastructural cost and carbon footprint in
modern data centers. Pruning is an effective technique that reduces both memory
and compute demand for model inference. However, pruning for online
recommendation systems is challenging due to the continuous data distribution
shift (a.k.a non-stationary data). Although incremental training on the full
model is able to adapt to the non-stationary data, directly applying it on the
pruned model leads to accuracy loss. This is because the sparsity pattern after
pruning requires adjustment to learn new patterns. To the best of our
knowledge, this is the first work to provide in-depth analysis and discussion
of applying pruning to online recommendation systems with non-stationary data
distribution. Overall, this work makes the following contributions: 1) We
present an adaptive dense to sparse paradigm equipped with a novel pruning
algorithm for pruning a large scale recommendation system with non-stationary
data distribution; 2) We design the pruning algorithm to automatically learn
the sparsity across layers to avoid repeating hand-tuning, which is critical
for pruning the heterogeneous architectures of recommendation systems trained
with non-stationary data.
</p>
<a href="http://arxiv.org/abs/2010.08655" target="_blank">arXiv:2010.08655</a> [<a href="http://arxiv.org/pdf/2010.08655" target="_blank">pdf</a>]

<h2>Class-incremental Learning with Pre-allocated Fixed Classifiers. (arXiv:2010.08657v1 [cs.LG])</h2>
<h3>Federico Pernici, Matteo Bruni, Claudio Baecchi, Francesco Turchini, Alberto Del Bimbo</h3>
<p>In class-incremental learning, a learning agent faces a stream of data with
the goal of learning new classes while not forgetting previous ones. Neural
networks are known to suffer under this setting, as they forget previously
acquired knowledge. To address this problem, effective methods exploit past
data stored in an episodic memory while expanding the final classifier nodes to
accommodate the new classes.

In this work, we substitute the expanding classifier with a novel fixed
classifier in which a number of pre-allocated output nodes are subject to the
classification loss right from the beginning of the learning phase. Contrarily
to the standard expanding classifier, this allows: (a) the output nodes of
future unseen classes to firstly see negative samples since the beginning of
learning together with the positive samples that incrementally arrive; (b) to
learn features that do not change their geometric configuration as novel
classes are incorporated in the learning model.

Experiments with public datasets show that the proposed approach is as
effective as the expanding classifier while exhibiting novel intriguing
properties of the internal feature representation that are otherwise
not-existent. Our ablation study on pre-allocating a large number of classes
further validates the approach.
</p>
<a href="http://arxiv.org/abs/2010.08657" target="_blank">arXiv:2010.08657</a> [<a href="http://arxiv.org/pdf/2010.08657" target="_blank">pdf</a>]

<h2>Wireless Localisation in WiFi using Novel Deep Architectures. (arXiv:2010.08658v1 [cs.LG])</h2>
<h3>Peizheng Li, Han Cui, Aftab Khan, Usman Raza, Robert Piechocki, Angela Doufexi, Tim Farnham</h3>
<p>This paper studies the indoor localisation of WiFi devices based on a
commodity chipset and standard channel sounding. First, we present a novel
shallow neural network (SNN) in which features are extracted from the channel
state information (CSI) corresponding to WiFi subcarriers received on different
antennas and used to train the model. The single-layer architecture of this
localisation neural network makes it lightweight and easy-to-deploy on devices
with stringent constraints on computational resources. We further investigate
for localisation the use of deep learning models and design novel architectures
for convolutional neural network (CNN) and long-short term memory (LSTM). We
extensively evaluate these localisation algorithms for continuous tracking in
indoor environments. Experimental results prove that even an SNN model, after a
careful handcrafted feature extraction, can achieve accurate localisation.
Meanwhile, using a well-organised architecture, the neural network models can
be trained directly with raw data from the CSI and localisation features can be
automatically extracted to achieve accurate position estimates. We also found
that the performance of neural network-based methods are directly affected by
the number of anchor access points (APs) regardless of their structure. With
three APs, all neural network models proposed in this paper can obtain
localisation accuracy of around 0.5 metres. In addition the proposed deep NN
architecture reduces the data pre-processing time by 6.5 hours compared with a
shallow NN using the data collected in our testbed. In the deployment phase,
the inference time is also significantly reduced to 0.1 ms per sample. We also
demonstrate the generalisation capability of the proposed method by evaluating
models using different target movement characteristics to the ones in which
they were trained.
</p>
<a href="http://arxiv.org/abs/2010.08658" target="_blank">arXiv:2010.08658</a> [<a href="http://arxiv.org/pdf/2010.08658" target="_blank">pdf</a>]

<h2>Semantics of the Black-Box: Can knowledge graphs help make deep learning systems more interpretable and explainable?. (arXiv:2010.08660v1 [cs.AI])</h2>
<h3>Manas Gaur, Keyur Faldu, Amit Sheth</h3>
<p>The recent series of innovations in deep learning (DL) have shown enormous
potential to impact individuals and society, both positively and negatively.
The DL models utilizing massive computing power and enormous datasets have
significantly outperformed prior historical benchmarks on increasingly
difficult, well-defined research tasks across technology domains such as
computer vision, natural language processing, signal processing, and
human-computer interactions. However, the Black-Box nature of DL models and
their over-reliance on massive amounts of data condensed into labels and dense
representations poses challenges for interpretability and explainability of the
system. Furthermore, DLs have not yet been proven in their ability to
effectively utilize relevant domain knowledge and experience critical to human
understanding. This aspect is missing in early data-focused approaches and
necessitated knowledge-infused learning and other strategies to incorporate
computational knowledge. This article demonstrates how knowledge, provided as a
knowledge graph, is incorporated into DL methods using knowledge-infused
learning, which is one of the strategies. We then discuss how this makes a
fundamental difference in the interpretability and explainability of current
approaches, and illustrate it with examples from natural language processing
for healthcare and education applications.
</p>
<a href="http://arxiv.org/abs/2010.08660" target="_blank">arXiv:2010.08660</a> [<a href="http://arxiv.org/pdf/2010.08660" target="_blank">pdf</a>]

<h2>Just-in-Time Learning for Bottom-Up Enumerative Synthesis. (arXiv:2010.08663v1 [cs.PL])</h2>
<h3>Shraddha Barke, Hila Peleg, Nadia Polikarpova</h3>
<p>A key challenge in program synthesis is the astronomical size of the search
space the synthesizer has to explore. In response to this challenge, recent
work proposed to guide synthesis using learned probabilistic models. Obtaining
such a model, however, might be infeasible for a problem domain where no
high-quality training data is available. In this work we introduce an
alternative approach to guided program synthesis: instead of training a model
ahead of time we show how to bootstrap one just in time, during synthesis, by
learning from partial solutions encountered along the way. To make the best use
of the model, we also propose a new program enumeration algorithm we dub guided
bottom-up search, which extends the efficient bottom-up search with guidance
from probabilistic models.

We implement this approach in a tool called Probe, which targets problems in
the popular syntax-guided synthesis (SyGuS) format. We evaluate Probe on
benchmarks from the literature and show that it achieves significant
performance gains both over unguided bottom-up search and over a
state-of-the-art probability-guided synthesizer, which had been trained on a
corpus of existing solutions. Moreover, we show that these performance gains do
not come at the cost of solution quality: programs generated by Probe are only
slightly more verbose than the shortest solutions and perform no unnecessary
case-splitting.
</p>
<a href="http://arxiv.org/abs/2010.08663" target="_blank">arXiv:2010.08663</a> [<a href="http://arxiv.org/pdf/2010.08663" target="_blank">pdf</a>]

<h2>Active Domain Adaptation via Clustering Uncertainty-weighted Embeddings. (arXiv:2010.08666v1 [cs.CV])</h2>
<h3>Viraj Prabhu, Arjun Chandrasekaran, Kate Saenko, Judy Hoffman</h3>
<p>Generalizing deep neural networks to new target domains is critical to their
real-world utility. In practice, it may be feasible to get some target data
labeled, but to be cost-effective it is desirable to select a
maximally-informative subset via active learning (AL). We study this problem of
AL under a domain shift. We empirically demonstrate how existing AL approaches
based solely on model uncertainty or representative sampling are suboptimal for
active domain adaptation. Our algorithm, Active Domain Adaptation via
CLustering Uncertainty-weighted Embeddings (ADA-CLUE), i) identifies diverse
datapoints for labeling that are both uncertain under the model and
representative of unlabeled target data, and ii) leverages the available source
and target data for adaptation by optimizing a semi-supervised adversarial
entropy loss that is complementary to our active sampling objective. On
standard image classification benchmarks for domain adaptation, ADA-CLUE
consistently performs as well or better than competing active adaptation,
active learning, and domain adaptation methods across shift severities, model
initializations, and labeling budgets.
</p>
<a href="http://arxiv.org/abs/2010.08666" target="_blank">arXiv:2010.08666</a> [<a href="http://arxiv.org/pdf/2010.08666" target="_blank">pdf</a>]

<h2>Robot Learning with Crash Constraints. (arXiv:2010.08669v1 [cs.RO])</h2>
<h3>Alonso Marco, Dominik Baumann, Majid Khadiv, Philipp Hennig, Ludovic Righetti, Sebastian Trimpe</h3>
<p>In the past decade, numerous machine learning algorithms have been shown to
successfully learn optimal policies to control real robotic systems. However,
it is not rare to encounter failing behaviors as the learning loop progresses.
Specifically, in robot applications where failing is undesired but not
catastrophic, many algorithms struggle with leveraging data obtained from
failures. This is usually caused by (i) the failed experiment ending
prematurely, or (ii) the acquired data being scarce or corrupted. Both
complicate the design of proper reward functions to penalize failures. In this
paper, we propose a framework that addresses those issues. We consider failing
behaviors as those that violate a constraint and address the problem of
"learning with crash constraints", where no data is obtained upon constraint
violation. The no-data case is addressed by a novel GP model (GPCR) for the
constraint that combines discrete events (failure/success) with continuous
observations (only obtained upon success). We demonstrate the effectiveness of
our framework on simulated benchmarks and on a real jumping quadruped, where
the constraint boundary is unknown a priori. Experimental data is collected, by
means of constrained Bayesian optimization, directly on the real robot. Our
results outperform manual tuning and GPCR proves useful on estimating the
constraint boundary.
</p>
<a href="http://arxiv.org/abs/2010.08669" target="_blank">arXiv:2010.08669</a> [<a href="http://arxiv.org/pdf/2010.08669" target="_blank">pdf</a>]

<h2>Long-Term Face Tracking for Crowded Video-Surveillance Scenarios. (arXiv:2010.08675v1 [cs.CV])</h2>
<h3>Germ&#xe1;n Barquero, Carles Fern&#xe1;ndez, Isabelle Hupont</h3>
<p>Most current multi-object trackers focus on short-term tracking, and are
based on deep and complex systems that do not operate in real-time, often
making them impractical for video-surveillance. In this paper, we present a
long-term multi-face tracking architecture conceived for working in crowded
contexts, particularly unconstrained in terms of movement and occlusions, and
where the face is often the only visible part of the person. Our system
benefits from advances in the fields of face detection and face recognition to
achieve long-term tracking. It follows a tracking-by-detection approach,
combining a fast short-term visual tracker with a novel online tracklet
reconnection strategy grounded on face verification. Additionally, a correction
module is included to correct past track assignments with no extra
computational cost. We present a series of experiments introducing novel,
specialized metrics for the evaluation of long-term tracking capabilities and a
video dataset that we publicly release. Findings demonstrate that, in this
context, our approach allows to obtain up to 50% longer tracks than
state-of-the-art deep learning trackers.
</p>
<a href="http://arxiv.org/abs/2010.08675" target="_blank">arXiv:2010.08675</a> [<a href="http://arxiv.org/pdf/2010.08675" target="_blank">pdf</a>]

<h2>TensorFlow Lite Micro: Embedded Machine Learning on TinyML Systems. (arXiv:2010.08678v1 [cs.LG])</h2>
<h3>Robert David, Jared Duke, Advait Jain, Vijay Janapa Reddi, Nat Jeffries, Jian Li, Nick Kreeger, Ian Nappier, Meghna Natraj, Shlomi Regev, Rocky Rhodes, Tiezhen Wang, Pete Warden</h3>
<p>Deep learning inference on embedded devices is a burgeoning field with myriad
applications because tiny embedded devices are omnipresent. But we must
overcome major challenges before we can benefit from this opportunity. Embedded
processors are severely resource constrained. Their nearest mobile counterparts
exhibit at least a 100---1,000x difference in compute capability, memory
availability, and power consumption. As a result, the machine-learning (ML)
models and associated ML inference framework must not only execute efficiently
but also operate in a few kilobytes of memory. Also, the embedded devices'
ecosystem is heavily fragmented. To maximize efficiency, system vendors often
omit many features that commonly appear in mainstream systems, including
dynamic memory allocation and virtual memory, that allow for cross-platform
interoperability. The hardware comes in many flavors (e.g., instruction-set
architecture and FPU support, or lack thereof). We introduce TensorFlow Lite
Micro (TF Micro), an open-source ML inference framework for running
deep-learning models on embedded systems. TF Micro tackles the efficiency
requirements imposed by embedded-system resource constraints and the
fragmentation challenges that make cross-platform interoperability nearly
impossible. The framework adopts a unique interpreter-based approach that
provides flexibility while overcoming these challenges. This paper explains the
design decisions behind TF Micro and describes its implementation details.
Also, we present an evaluation to demonstrate its low resource requirement and
minimal run-time performance overhead.
</p>
<a href="http://arxiv.org/abs/2010.08678" target="_blank">arXiv:2010.08678</a> [<a href="http://arxiv.org/pdf/2010.08678" target="_blank">pdf</a>]

<h2>MeshMVS: Multi-View Stereo Guided Mesh Reconstruction. (arXiv:2010.08682v1 [cs.CV])</h2>
<h3>Rakesh Shrestha, Zhiwen Fan, Siyu Zhu, Zuozhuo Dai, Qingkun Su, Ping Tan</h3>
<p>Deep learning based 3D shape generation methods generally utilize latent
features extracted from color images to encode the objects' semantics and guide
the shape generation process. These color image semantics only implicitly
encode 3D information, potentially limiting the accuracy of the generated
shapes. In this paper we propose a multi-view mesh generation method which
incorporates geometry information in the color images explicitly by using the
features from intermediate 2.5D depth representations of the input images and
regularizing the 3D shapes against these depth images. Our system first
predicts a coarse 3D volume from the color images by probabilistically merging
voxel occupancy grids from individual views. Depth images corresponding to the
multi-view color images are predicted which along with the rendered depth
images of the coarse shape are used as a contrastive input whose features guide
the refinement of the coarse shape through a series of graph convolution
networks. Attention-based multi-view feature pooling is proposed to fuse the
contrastive depth features from different viewpoints which are fed to the graph
convolution networks.

We validate the proposed multi-view mesh generation method on ShapeNet, where
we obtain a significant improvement with 34% decrease in chamfer distance to
ground truth and 14% increase in the F1-score compared with the
state-of-the-art multi-view shape generation method.
</p>
<a href="http://arxiv.org/abs/2010.08682" target="_blank">arXiv:2010.08682</a> [<a href="http://arxiv.org/pdf/2010.08682" target="_blank">pdf</a>]

<h2>Learning a Continuous Representation of 3D Molecular Structures with Deep Generative Models. (arXiv:2010.08687v1 [q-bio.QM])</h2>
<h3>Matthew Ragoza, Tomohide Masuda, David Ryan Koes</h3>
<p>Machine learning methods in drug discovery have primarily focused on virtual
screening of molecular libraries using discriminative models. Generative models
are an entirely different approach to drug discovery that learn to represent
and optimize molecules in a continuous latent space. These methods have already
been applied with increasing success to the generation of two dimensional
molecules as SMILES strings and molecular graphs. In this work, we describe
deep generative models for three dimensional molecular structures using atomic
density grids and a novel fitting algorithm that converts continuous grids to
discrete molecular structures. Our models jointly represent drug-like molecules
and their conformations in a latent space that can be explored through
interpolation. We are able to sample diverse sets of molecules based on a given
input compound and increase the probability of creating a valid, drug-like
molecule.
</p>
<a href="http://arxiv.org/abs/2010.08687" target="_blank">arXiv:2010.08687</a> [<a href="http://arxiv.org/pdf/2010.08687" target="_blank">pdf</a>]

<h2>Automatic Tree Ring Detection using Jacobi Sets. (arXiv:2010.08691v1 [cs.CV])</h2>
<h3>Kayla Makela, Tim Ophelders, Michelle Quigley, Elizabeth Munch, Daniel Chitwood, Asia Dowtin</h3>
<p>Tree ring widths are an important source of climatic and historical data, but
measuring these widths typically requires extensive manual work. Computer
vision techniques provide promising directions towards the automation of tree
ring detection, but most automated methods still require a substantial amount
of user interaction to obtain high accuracy. We perform analysis on 3D X-ray CT
images of a cross-section of a tree trunk, known as a tree disk. We present
novel automated methods for locating the pith (center) of a tree disk, and ring
boundaries. Our methods use a combination of standard image processing
techniques and tools from topological data analysis. We evaluate the efficacy
of our method for two different CT scans by comparing its results to manually
located rings and centers and show that it is better than current automatic
methods in terms of correctly counting each ring and its location. Our methods
have several parameters, which we optimize experimentally by minimizing edit
distances to the manually obtained locations.
</p>
<a href="http://arxiv.org/abs/2010.08691" target="_blank">arXiv:2010.08691</a> [<a href="http://arxiv.org/pdf/2010.08691" target="_blank">pdf</a>]

<h2>A Systematic Approach to Computing the Manipulator Jacobian and Hessian using the Elementary Transform Sequence. (arXiv:2010.08696v1 [cs.RO])</h2>
<h3>Jesse Haviland, Peter Corke</h3>
<p>The elementary transform sequence (ETS) provides a universal method of
describing the kinematics of any serial-link manipulator. The ETS notation is
intuitive and easy to understand, while avoiding the complexity and limitations
of Denvit-Hartenberg frame assignment. In this paper, we describe a systematic
method for computing the manipulator Jacobian and Hessian (differential
kinematics) using the ETS notation. Differential kinematics have many
applications including numerical inverse kinematics, resolved-rate motion
control and manipulability motion control. Furthermore, we provide an
open-source Python library which implements our algorithm and can be interfaced
with any serial-link manipulator (available at
github.com/petercorke/robotics-toolbox-python).
</p>
<a href="http://arxiv.org/abs/2010.08696" target="_blank">arXiv:2010.08696</a> [<a href="http://arxiv.org/pdf/2010.08696" target="_blank">pdf</a>]

<h2>Is Image Encoding Beneficial for Deep Learning in Finance? An Analysis of Image Encoding Methods for the Application of Convolutional Neural Networks in Finance. (arXiv:2010.08698v1 [q-fin.ST])</h2>
<h3>Dan Wang, Tianrui Wang, Ionu&#x163; Florescu</h3>
<p>In 2012, SEC mandated all corporate filings for any company doing business in
US be entered into the Electronic Data Gathering, Analysis, and Retrieval
(EDGAR) system. In this work we are investigating ways to analyze the data
available through EDGAR database. This may serve portfolio managers (pension
funds, mutual funds, insurance, hedge funds) to get automated insights into
companies they invest in, to better manage their portfolios. The analysis is
based on Artificial Neural Networks applied to the data.} In particular, one of
the most popular machine learning methods, the Convolutional Neural Network
(CNN) architecture, originally developed to interpret and classify images, is
now being used to interpret financial data. This work investigates the best way
to input data collected from the SEC filings into a CNN architecture. We
incorporate accounting principles and mathematical methods into the design of
three image encoding methods. Specifically, two methods are derived from
accounting principles (Sequential Arrangement, Category Chunk Arrangement) and
one is using a purely mathematical technique (Hilbert Vector Arrangement). In
this work we analyze fundamental financial data as well as financial ratio data
and study companies from the financial, healthcare and IT sectors in the United
States. We find that using imaging techniques to input data for CNN works
better for financial ratio data but is not significantly better than simply
using the 1D input directly for fundamental data. We do not find the Hilbert
Vector Arrangement technique to be significantly better than other imaging
techniques.
</p>
<a href="http://arxiv.org/abs/2010.08698" target="_blank">arXiv:2010.08698</a> [<a href="http://arxiv.org/pdf/2010.08698" target="_blank">pdf</a>]

<h2>DEAL: Difficulty-aware Active Learning for Semantic Segmentation. (arXiv:2010.08705v1 [cs.CV])</h2>
<h3>Shuai Xie, Zunlei Feng, Ying Chen, Songtao Sun, Chao Ma, Mingli Song</h3>
<p>Active learning aims to address the paucity of labeled data by finding the
most informative samples. However, when applying to semantic segmentation,
existing methods ignore the segmentation difficulty of different semantic
areas, which leads to poor performance on those hard semantic areas such as
tiny or slender objects. To deal with this problem, we propose a semantic
Difficulty-awarE Active Learning (DEAL) network composed of two branches: the
common segmentation branch and the semantic difficulty branch. For the latter
branch, with the supervision of segmentation error between the segmentation
result and GT, a pixel-wise probability attention module is introduced to learn
the semantic difficulty scores for different semantic areas. Finally, two
acquisition functions are devised to select the most valuable samples with
semantic difficulty. Competitive results on semantic segmentation benchmarks
demonstrate that DEAL achieves state-of-the-art active learning performance and
improves the performance of the hard semantic areas in particular.
</p>
<a href="http://arxiv.org/abs/2010.08705" target="_blank">arXiv:2010.08705</a> [<a href="http://arxiv.org/pdf/2010.08705" target="_blank">pdf</a>]

<h2>Causal Transfer Random Forest: Combining Logged Data and Randomized Experiments for Robust Prediction. (arXiv:2010.08710v1 [cs.LG])</h2>
<h3>Shuxi Zeng, Murat Ali Bayir, Joel Pfeiffer, Denis Charles, Emre Kiciman</h3>
<p>It is often critical for prediction models to be robust to distributional
shifts between training and testing data. Viewed from a causal perspective, the
challenge is to distinguish the stable causal relationships from the unstable
spurious correlations across shifts. We describe a causal transfer random
forest (CTRF) that combines existing training data with a small amount of data
from a randomized experiment to train a model which is robust to the feature
shifts and therefore transfers to a new targeting distribution. Theoretically,
we justify the robustness of the approach against feature shifts with the
knowledge from causal learning. Empirically, we evaluate the CTRF using both
synthetic data experiments and real-world experiments in the Bing Ads platform,
including a click prediction task and in the context of an end-to-end
counterfactual optimization system. The proposed CTRF produces robust
predictions and outperforms most baseline methods compared in the presence of
feature shifts.
</p>
<a href="http://arxiv.org/abs/2010.08710" target="_blank">arXiv:2010.08710</a> [<a href="http://arxiv.org/pdf/2010.08710" target="_blank">pdf</a>]

<h2>Understanding Information Processing in Human Brain by Interpreting Machine Learning Models. (arXiv:2010.08715v1 [q-bio.NC])</h2>
<h3>Ilya Kuzovkin</h3>
<p>The thesis explores the role machine learning methods play in creating
intuitive computational models of neural processing. Combined with
interpretability techniques, machine learning could replace human modeler and
shift the focus of human effort to extracting the knowledge from the ready-made
models and articulating that knowledge into intuitive descroptions of reality.
This perspective makes the case in favor of the larger role that exploratory
and data-driven approach to computational neuroscience could play while
coexisting alongside the traditional hypothesis-driven approach.

We exemplify the proposed approach in the context of the knowledge
representation taxonomy with three research projects that employ
interpretability techniques on top of machine learning methods at three
different levels of neural organization. The first study (Chapter 3) explores
feature importance analysis of a random forest decoder trained on intracerebral
recordings from 100 human subjects to identify spectrotemporal signatures that
characterize local neural activity during the task of visual categorization.
The second study (Chapter 4) employs representation similarity analysis to
compare the neural responses of the areas along the ventral stream with the
activations of the layers of a deep convolutional neural network. The third
study (Chapter 5) proposes a method that allows test subjects to visually
explore the state representation of their neural signal in real time. This is
achieved by using a topology-preserving dimensionality reduction technique that
allows to transform the neural data from the multidimensional representation
used by the computer into a two-dimensional representation a human can grasp.

The approach, the taxonomy, and the examples, present a strong case for the
applicability of machine learning methods to automatic knowledge discovery in
neuroscience.
</p>
<a href="http://arxiv.org/abs/2010.08715" target="_blank">arXiv:2010.08715</a> [<a href="http://arxiv.org/pdf/2010.08715" target="_blank">pdf</a>]

<h2>Picture-to-Amount (PITA): Predicting Relative Ingredient Amounts from Food Images. (arXiv:2010.08727v1 [cs.CV])</h2>
<h3>Jiatong Li, Fangda Han, Ricardo Guerrero, Vladimir Pavlovic</h3>
<p>Increased awareness of the impact of food consumption on health and lifestyle
today has given rise to novel data-driven food analysis systems. Although these
systems may recognize the ingredients, a detailed analysis of their amounts in
the meal, which is paramount for estimating the correct nutrition, is usually
ignored. In this paper, we study the novel and challenging problem of
predicting the relative amount of each ingredient from a food image. We propose
PITA, the Picture-to-Amount deep learning architecture to solve the problem.
More specifically, we predict the ingredient amounts using a domain-driven
Wasserstein loss from image-to-recipe cross-modal embeddings learned to align
the two views of food data. Experiments on a dataset of recipes collected from
the Internet show the model generates promising results and improves the
baselines on this challenging task. A demo of our system and our data is
availableat: foodai.cs.rutgers.edu.
</p>
<a href="http://arxiv.org/abs/2010.08727" target="_blank">arXiv:2010.08727</a> [<a href="http://arxiv.org/pdf/2010.08727" target="_blank">pdf</a>]

<h2>Secure Weighted Aggregation in Federated Learning. (arXiv:2010.08730v1 [cs.CR])</h2>
<h3>Jiale Guo, Ziyao Liu, Kwok-Yan Lam, Jun Zhao, Yiqiang Chen, Chaoping Xing</h3>
<p>Federated learning (FL) schemes enable multiple clients to jointly solve a
machine learning problem using their local data to train a local model, then
aggregating these models under the coordination of a central server. To achieve
such a practical FL system, we need to consider (i) how to deal with the
disparity across clients' datasets, and (ii) how to further protect the privacy
of clients' locally trained models, which may leak information. The first
concern can be addressed using a weighted aggregation scheme where the weights
of clients are determined based on their data size and quality. Approaches in
previous works result in a good performance but do not provide any privacy
guarantee. For the second concern, privacy-preserving aggregation schemes can
provide privacy guarantees that can be mathematically analyzed. However, the
security issue still exists that both the central server and clients may send
fraudulent messages to each other for their own benefits, especially if there
is an incentive mechanism where the reward provided by the server is
distributed according to clients' weights. To address the issues mentioned
above, we propose a secure weighted aggregation scheme. Precisely, relying on
the homomorphic encryption (HE) crypto-system, each client's weight is
calculated in a privacy-preserving manner. Furthermore, we adopt a
zero-knowledge proof (ZKP) based verification scheme to prevent the central
server and clients from receiving fraudulent messages from each other. To the
best of our knowledge, this work proposes the first aggregation scheme to deal
with data disparity and fraudulent messages in the FL system from both privacy
and security perspective.
</p>
<a href="http://arxiv.org/abs/2010.08730" target="_blank">arXiv:2010.08730</a> [<a href="http://arxiv.org/pdf/2010.08730" target="_blank">pdf</a>]

<h2>Audio-based Near-Duplicate Video Retrieval with Audio Similarity Learning. (arXiv:2010.08737v1 [cs.MM])</h2>
<h3>Pavlos Avgoustinakis, Giorgos Kordopatis-Zilos, Symeon Papadopoulos, Andreas L. Symeonidis, Ioannis Kompatsiaris</h3>
<p>In this work, we address the problem of audio-based near-duplicate video
retrieval. We propose the Audio Similarity Learning (AuSiL) approach that
effectively captures temporal patterns of audio similarity between video pairs.
For the robust similarity calculation between two videos, we first extract
representative audio-based video descriptors by leveraging transfer learning
based on a Convolutional Neural Network (CNN) trained on a large scale dataset
of audio events, and then we calculate the similarity matrix derived from the
pairwise similarity of these descriptors. The similarity matrix is subsequently
fed to a CNN network that captures the temporal structures existing within its
content. We train our network following a triplet generation process and
optimizing the triplet loss function. To evaluate the effectiveness of the
proposed approach, we have manually annotated two publicly available video
datasets based on the audio duplicity between their videos. The proposed
approach achieves very competitive results compared to three state-of-the-art
methods. Also, unlike the competing methods, it is very robust to the retrieval
of audio duplicates generated with speed transformations.
</p>
<a href="http://arxiv.org/abs/2010.08737" target="_blank">arXiv:2010.08737</a> [<a href="http://arxiv.org/pdf/2010.08737" target="_blank">pdf</a>]

<h2>Self-Selective Context for Interaction Recognition. (arXiv:2010.08750v1 [cs.CV])</h2>
<h3>Mert Kilickaya, Noureldien Hussein, Efstratios Gavves, Arnold Smeulders</h3>
<p>Human-object interaction recognition aims for identifying the relationship
between a human subject and an object. Researchers incorporate global scene
context into the early layers of deep Convolutional Neural Networks as a
solution. They report a significant increase in the performance since generally
interactions are correlated with the scene (\ie riding bicycle on the city
street). However, this approach leads to the following problems. It increases
the network size in the early layers, therefore not efficient. It leads to
noisy filter responses when the scene is irrelevant, therefore not accurate. It
only leverages scene context whereas human-object interactions offer a
multitude of contexts, therefore incomplete. To circumvent these issues, in
this work, we propose Self-Selective Context (SSC). SSC operates on the joint
appearance of human-objects and context to bring the most discriminative
context(s) into play for recognition. We devise novel contextual features that
model the locality of human-object interactions and show that SSC can
seamlessly integrate with the State-of-the-art interaction recognition models.
Our experiments show that SSC leads to an important increase in interaction
recognition performance, while using much fewer parameters.
</p>
<a href="http://arxiv.org/abs/2010.08750" target="_blank">arXiv:2010.08750</a> [<a href="http://arxiv.org/pdf/2010.08750" target="_blank">pdf</a>]

<h2>Gradient Aware Cascade Network for Multi-Focus Image Fusion. (arXiv:2010.08751v1 [cs.CV])</h2>
<h3>Boyuan Ma, Xiang Yin, Di Wu, Xiaojuan Ban, Haiyou Huang</h3>
<p>The general aim of multi-focus image fusion is to gather focused regions of
different images to generate a unique all-in-focus fused image. Deep learning
based methods become the mainstream of image fusion by virtue of its powerful
feature representation ability. However, most of the existing deep learning
structures failed to balance fusion quality and end-to-end implementation
convenience. End-to-end decoder design often leads to poor performance because
of its non-linear mapping mechanism. On the other hand, generating an
intermediate decision map achieves better quality for the fused image, but
relies on the rectification with empirical post-processing parameter choices.
In this work, to handle the requirements of both output image quality and
comprehensive simplicity of structure implementation, we propose a cascade
network to simultaneously generate decision map and fused result with an
end-to-end training procedure. It avoids the dependence on empirical
post-processing methods in the inference stage. To improve the fusion quality,
we introduce a gradient aware loss function to preserve gradient information in
output fused image. In addition, we design a decision calibration strategy to
decrease the time consumption in the application of multiple image fusion.
Extensive experiments are conducted to compare with 16 different
state-of-the-art multi-focus image fusion structures with 6 assessment metrics.
The results prove that our designed structure can generally ameliorate the
output fused image quality, while implementation efficiency increases over 30\%
for multiple image fusion.
</p>
<a href="http://arxiv.org/abs/2010.08751" target="_blank">arXiv:2010.08751</a> [<a href="http://arxiv.org/pdf/2010.08751" target="_blank">pdf</a>]

<h2>Variational Dynamic for Self-Supervised Exploration in Deep Reinforcement Learning. (arXiv:2010.08755v1 [cs.LG])</h2>
<h3>Chenjia Bai, Peng Liu, Zhaoran Wang, Kaiyu Liu, Lingxiao Wang, Yingnan Zhao</h3>
<p>Efficient exploration remains a challenging problem in reinforcement
learning, especially for tasks where extrinsic rewards from environments are
sparse or even totally disregarded. Significant advances based on intrinsic
motivation show promising results in simple environments but often get stuck in
environments with multimodal and stochastic dynamics. In this work, we propose
a variational dynamic model based on the conditional variational inference to
model the multimodality and stochasticity. We consider the environmental
state-action transition as a conditional generative process by generating the
next-state prediction under the condition of the current state, action, and
latent variable. We derive an upper bound of the negative log-likelihood of the
environmental transition and use such an upper bound as the intrinsic reward
for exploration, which allows the agent to learn skills by self-supervised
exploration without observing extrinsic rewards. We evaluate the proposed
method on several image-based simulation tasks and a real robotic manipulating
task. Our method outperforms several state-of-the-art environment model-based
exploration approaches.
</p>
<a href="http://arxiv.org/abs/2010.08755" target="_blank">arXiv:2010.08755</a> [<a href="http://arxiv.org/pdf/2010.08755" target="_blank">pdf</a>]

<h2>Squashing activation functions in benchmark tests: towards eXplainable Artificial Intelligence using continuous-valued logic. (arXiv:2010.08760v1 [cs.LG])</h2>
<h3>Daniel Zeltner, Benedikt Schmid, Gabor Csiszar, Orsolya Csiszar</h3>
<p>Over the past few years, deep neural networks have shown excellent results in
multiple tasks, however, there is still an increasing need to address the
problem of interpretability to improve model transparency, performance, and
safety. Achieving eXplainable Artificial Intelligence (XAI) by combining neural
networks with continuous logic and multi-criteria decision-making tools is one
of the most promising ways to approach this problem: by this combination, the
black-box nature of neural models can be reduced. The continuous logic-based
neural model uses so-called Squashing activation functions, a parametric family
of functions that satisfy natural invariance requirements and contain rectified
linear units as a particular case. This work demonstrates the first benchmark
tests that measure the performance of Squashing functions in neural networks.
Three experiments were carried out to examine their usability and a comparison
with the most popular activation functions was made for five different network
types. The performance was determined by measuring the accuracy, loss, and time
per epoch. These experiments and the conducted benchmarks have proven that the
use of Squashing functions is possible and similar in performance to
conventional activation functions. Moreover, a further experiment was conducted
by implementing nilpotent logical gates to demonstrate how simple
classification tasks can be solved successfully and with high performance. The
results indicate that due to the embedded nilpotent logical operators and the
differentiability of the Squashing function, it is possible to solve
classification problems, where other commonly used activation functions fail.
</p>
<a href="http://arxiv.org/abs/2010.08760" target="_blank">arXiv:2010.08760</a> [<a href="http://arxiv.org/pdf/2010.08760" target="_blank">pdf</a>]

<h2>Layer-wise Characterization of Latent Information Leakage in Federated Learning. (arXiv:2010.08762v1 [cs.CR])</h2>
<h3>Fan Mo, Anastasia Borovykh, Mohammad Malekzadeh, Hamed Haddadi, Soteris Demetriou</h3>
<p>Training a deep neural network (DNN) via federated learning allows
participants to share model updates (gradients), instead of the data itself.
However, recent studies show that unintended latent information (e.g. gender or
race) carried by the gradients can be discovered by attackers, compromising the
promised privacy guarantee of federated learning. Existing privacy-preserving
techniques (e.g. differential privacy) either have limited defensive capacity
against the potential attacks, or suffer from considerable model utility loss.
Moreover, characterizing the latent information carried by the gradients and
the consequent privacy leakage has been a major theoretical and practical
challenge. In this paper, we propose two new metrics to address these
challenges: the empirical $\mathcal{V}$-information, a theoretically grounded
notion of information which measures the amount of gradient information that is
usable for an attacker, and the sensitivity analysis that utilizes the Jacobian
matrix to measure the amount of changes in the gradients with respect to latent
information which further quantifies private risk. We show that these metrics
can localize the private information in each layer of a DNN and quantify the
leakage depending on how sensitive the gradients are with respect to the latent
information. As a practical application, we design LatenTZ: a federated
learning framework that lets the most sensitive layers to run in the clients'
Trusted Execution Environments (TEE). The implementation evaluation of LatenTZ
shows that TEE-based approaches are promising for defending against powerful
property inference attacks without a significant overhead in the clients'
computing resources nor trading off the model's utility.
</p>
<a href="http://arxiv.org/abs/2010.08762" target="_blank">arXiv:2010.08762</a> [<a href="http://arxiv.org/pdf/2010.08762" target="_blank">pdf</a>]

<h2>DE-GAN: A Conditional Generative Adversarial Network for Document Enhancement. (arXiv:2010.08764v1 [cs.CV])</h2>
<h3>Mohamed Ali Souibgui, Yousri Kessentini</h3>
<p>Documents often exhibit various forms of degradation, which make it hard to
be read and substantially deteriorate the performance of an OCR system. In this
paper, we propose an effective end-to-end framework named Document Enhancement
Generative Adversarial Networks (DE-GAN) that uses the conditional GANs (cGANs)
to restore severely degraded document images. To the best of our knowledge,
this practice has not been studied within the context of generative adversarial
deep networks. We demonstrate that, in different tasks (document clean up,
binarization, deblurring and watermark removal), DE-GAN can produce an enhanced
version of the degraded document with a high quality. In addition, our approach
provides consistent improvements compared to state-of-the-art methods over the
widely used DIBCO 2013, DIBCO 2017 and H-DIBCO 2018 datasets, proving its
ability to restore a degraded document image to its ideal condition. The
obtained results on a wide variety of degradation reveal the flexibility of the
proposed model to be exploited in other document enhancement problems.
</p>
<a href="http://arxiv.org/abs/2010.08764" target="_blank">arXiv:2010.08764</a> [<a href="http://arxiv.org/pdf/2010.08764" target="_blank">pdf</a>]

<h2>DeHiDe: Deep Learning-based Hybrid Model to Detect Fake News using Blockchain. (arXiv:2010.08765v1 [cs.LG])</h2>
<h3>Prashansa Agrawal, Parwat Singh Anjana, Sathya Peri</h3>
<p>The surge in the spread of misleading information, lies, propaganda, and
false facts, frequently known as fake news, raised questions concerning social
media's influence in today's fast-moving democratic society. The widespread and
rapid dissemination of fake news cost us in many ways. For example, individual
or societal costs by hampering elections integrity, significant economic losses
by impacting stock markets, or increases the risk to national security. It is
challenging to overcome the spreading of fake news problems in traditional
centralized systems. However, Blockchain-- a distributed decentralized
technology that ensures data provenance, authenticity, and traceability by
providing a transparent, immutable, and verifiable transaction records can help
in detecting and contending fake news. This paper proposes a novel hybrid model
DeHiDe: Deep Learning-based Hybrid Model to Detect Fake News using Blockchain.
The DeHiDe is a blockchain-based framework for legitimate news sharing by
filtering out the fake news. It combines the benefit of blockchain with an
intelligent deep learning model to reinforce robustness and accuracy in
combating fake news's hurdle. It also compares the proposed method to existing
state-of-the-art methods. The DeHiDe is expected to outperform state-of-the-art
approaches in terms of services, features, and performance.
</p>
<a href="http://arxiv.org/abs/2010.08765" target="_blank">arXiv:2010.08765</a> [<a href="http://arxiv.org/pdf/2010.08765" target="_blank">pdf</a>]

<h2>Studying the Similarity of COVID-19 Sounds based on Correlation Analysis of MFCC. (arXiv:2010.08770v1 [cs.SD])</h2>
<h3>Mohamed Bader, Ismail Shahin, Abdelfatah Hassan</h3>
<p>Recently there has been a formidable work which has been put up from the
people who are working in the frontlines such as hospitals, clinics, and labs
alongside researchers and scientists who are also putting tremendous efforts in
the fight against COVID-19 pandemic. Due to the preposterous spread of the
virus, the integration of the artificial intelligence has taken a considerable
part in the health sector, by implementing the fundamentals of Automatic Speech
Recognition (ASR) and deep learning algorithms. In this paper, we illustrate
the importance of speech signal processing in the extraction of the
Mel-Frequency Cepstral Coefficients (MFCCs) of the COVID-19 and non-COVID-19
samples and find their relationship using Pearson correlation coefficients. Our
results show high similarity in MFCCs between different COVID-19 cough and
breathing sounds, while MFCC of voice is more robust between COVID-19 and
non-COVID-19 samples. Moreover, our results are preliminary, and there is a
possibility to exclude the voices of COVID-19 patients from further processing
in diagnosing the disease.
</p>
<a href="http://arxiv.org/abs/2010.08770" target="_blank">arXiv:2010.08770</a> [<a href="http://arxiv.org/pdf/2010.08770" target="_blank">pdf</a>]

<h2>Using machine learning to reduce ensembles of geological models for oil and gas exploration. (arXiv:2010.08775v1 [cs.LG])</h2>
<h3>Anna Roub&#xed;ckov&#xe1;, Lucy MacGregor, Nick Brown, Oliver Thomson Brown, Mike Stewart</h3>
<p>Exploration using borehole drilling is a key activity in determining the most
appropriate locations for the petroleum industry to develop oil fields.
However, estimating the amount of Oil In Place (OIP) relies on computing with a
very significant number of geological models, which, due to the ever increasing
capability to capture and refine data, is becoming infeasible. As such, data
reduction techniques are required to reduce this set down to a smaller, yet
still fully representative ensemble. In this paper we explore different
approaches to identifying the key grouping of models, based on their most
important features, and then using this information select a reduced set which
we can be confident fully represent the overall model space. The result of this
work is an approach which enables us to describe the entire state space using
only 0.5\% of the models, along with a series of lessons learnt. The techniques
that we describe are not only applicable to oil and gas exploration, but also
more generally to the HPC community as we are forced to work with reduced
data-sets due to the rapid increase in data collection capability.
</p>
<a href="http://arxiv.org/abs/2010.08775" target="_blank">arXiv:2010.08775</a> [<a href="http://arxiv.org/pdf/2010.08775" target="_blank">pdf</a>]

<h2>The NVIDIA PilotNet Experiments. (arXiv:2010.08776v1 [cs.CV])</h2>
<h3>Mariusz Bojarski, Chenyi Chen, Joyjit Daw, Alperen De&#x11f;irmenci, Joya Deri, Bernhard Firner, Beat Flepp, Sachin Gogri, Jesse Hong, Lawrence Jackel, Zhenhua Jia, BJ Lee, Bo Liu, Fei Liu, Urs Muller, Samuel Payne, Nischal Kota Nagendra Prasad, Artem Provodin, John Roach, Timur Rvachov, Neha Tadimeti, Jesper van Engelen, Haiguang Wen, Eric Yang, Zongyi Yang</h3>
<p>Four years ago, an experimental system known as PilotNet became the first
NVIDIA system to steer an autonomous car along a roadway. This system
represents a departure from the classical approach for self-driving in which
the process is manually decomposed into a series of modules, each performing a
different task. In PilotNet, on the other hand, a single deep neural network
(DNN) takes pixels as input and produces a desired vehicle trajectory as
output; there are no distinct internal modules connected by human-designed
interfaces. We believe that handcrafted interfaces ultimately limit performance
by restricting information flow through the system and that a learned approach,
in combination with other artificial intelligence systems that add redundancy,
will lead to better overall performing systems. We continue to conduct research
toward that goal.

This document describes the PilotNet lane-keeping effort, carried out over
the past five years by our NVIDIA PilotNet group in Holmdel, New Jersey. Here
we present a snapshot of system status in mid-2020 and highlight some of the
work done by the PilotNet group.
</p>
<a href="http://arxiv.org/abs/2010.08776" target="_blank">arXiv:2010.08776</a> [<a href="http://arxiv.org/pdf/2010.08776" target="_blank">pdf</a>]

<h2>Active Testing: An Unbiased Evaluation Method for Distantly Supervised Relation Extraction. (arXiv:2010.08777v1 [cs.CL])</h2>
<h3>Pengshuai Li, Xinsong Zhang, Weijia Jia, Wei Zhao</h3>
<p>Distant supervision has been a widely used method for neural relation
extraction for its convenience of automatically labeling datasets. However,
existing works on distantly supervised relation extraction suffer from the low
quality of test set, which leads to considerable biased performance evaluation.
These biases not only result in unfair evaluations but also mislead the
optimization of neural relation extraction. To mitigate this problem, we
propose a novel evaluation method named active testing through utilizing both
the noisy test set and a few manual annotations. Experiments on a widely used
benchmark show that our proposed approach can yield approximately unbiased
evaluations for distantly supervised relation extractors.
</p>
<a href="http://arxiv.org/abs/2010.08777" target="_blank">arXiv:2010.08777</a> [<a href="http://arxiv.org/pdf/2010.08777" target="_blank">pdf</a>]

<h2>DIFER: Differentiable Automated Feature Engineering. (arXiv:2010.08784v1 [cs.LG])</h2>
<h3>Guanghui Zhu, Zhuoer Xu, Xu Guo, Chunfeng Yuan, Yihua Huang</h3>
<p>Feature engineering, a crucial step of machine learning, aims to extract
useful features from raw data to improve data quality. In recent years, great
efforts have been devoted to Automated Feature Engineering (AutoFE) to replace
expensive human labor. However, existing methods are computationally demanding
due to treating AutoFE as a coarse-grained black-box optimization problem over
a discrete space. In this work, we propose an efficient gradient-based method
called DIFER to perform differentiable automated feature engineering in a
continuous vector space. DIFER selects potential features based on evolutionary
algorithm and leverages an encoder-predictor-decoder controller to optimize
existing features. We map features into the continuous vector space via the
encoder, optimize the embedding along the gradient direction induced by the
predicted score, and recover better features from the optimized embedding by
the decoder. Extensive experiments on classification and regression datasets
demonstrate that DIFER can significantly improve the performance of various
machine learning algorithms and outperform current state-of-the-art AutoFE
methods in terms of both efficiency and performance.
</p>
<a href="http://arxiv.org/abs/2010.08784" target="_blank">arXiv:2010.08784</a> [<a href="http://arxiv.org/pdf/2010.08784" target="_blank">pdf</a>]

<h2>Discovering Pattern Structure Using Differentiable Compositing. (arXiv:2010.08788v1 [cs.CV])</h2>
<h3>Pradyumna Reddy, Paul Guerrero, Matt Fisher, Wilmot Li, Miloy J.Mitra</h3>
<p>Patterns, which are collections of elements arranged in regular or
near-regular arrangements, are an important graphic art form and widely used
due to their elegant simplicity and aesthetic appeal. When a pattern is encoded
as a flat image without the underlying structure, manually editing the pattern
is tedious and challenging as one has to both preserve the individual element
shapes and their original relative arrangements. State-of-the-art deep learning
frameworks that operate at the pixel level are unsuitable for manipulating such
patterns. Specifically, these methods can easily disturb the shapes of the
individual elements or their arrangement, and thus fail to preserve the latent
structures of the input patterns. We present a novel differentiable compositing
operator using pattern elements and use it to discover structures, in the form
of a layered representation of graphical objects, directly from raw pattern
images. This operator allows us to adapt current deep learning based image
methods to effectively handle patterns. We evaluate our method on a range of
patterns and demonstrate superiority in the context of pattern manipulations
when compared against state-of-the-art
</p>
<a href="http://arxiv.org/abs/2010.08788" target="_blank">arXiv:2010.08788</a> [<a href="http://arxiv.org/pdf/2010.08788" target="_blank">pdf</a>]

<h2>Threats and Corrective Measures for IoT Security with Observance to Cybercrime. (arXiv:2010.08793v1 [cs.NI])</h2>
<h3>Sita Rani, Aman Kataria, Smarajit Ghosh, Vinod Karar, Takshi Gupta, Kyungroul Lee, Chang Choi</h3>
<p>Internet of Things (IoT) is the utmost assuring framework to facilitate human
life with quality and comfort. IoT has contributed significantly in numerous
application areas. The stormy expansion of smart devices and their credence for
data transfer on wireless mechanics boosts their susceptibility to
cyber-attacks. Consequently, the rate of cybercrimes is increasing day by day.
Hence, the study of IoT security threats and possible corrective measures can
benefit the researchers to identify appropriate solutions to deal with various
challenges in cybercrime investigation. IoT forensics plays a vital role in
cybercrime investigation. This review paper presents an overview of the IoT
framework consisting of IoT architecture, protocols, and technologies. Various
security issues at each layer and corrective measures are also discussed in
detail. This paper also presents the role of IoT forensics in cybercrime
investigation in various domains like smart homes, smart cities, automated
vehicles, healthcare, etc. Along with the role of advanced technologies like
Artificial Intelligence, Machine Learning, Cloud computing, Edge computing, Fog
computing, and Blockchain technology in cybercrime investigation are also
discussed. At last, the various open research challenges in the area of IoT to
assist cybercrime investigation are explained, which provide a new direction to
the researchers to work further.
</p>
<a href="http://arxiv.org/abs/2010.08793" target="_blank">arXiv:2010.08793</a> [<a href="http://arxiv.org/pdf/2010.08793" target="_blank">pdf</a>]

<h2>Directed Variational Cross-encoder Network for Few-shot Multi-image Co-segmentation. (arXiv:2010.08800v1 [cs.CV])</h2>
<h3>Sayan Banerjee, S Divakar Bhat, Subhasis Chaudhuri, Rajbabu Velmurugan</h3>
<p>In this paper, we propose a novel framework for multi-image co-segmentation
using class agnostic meta-learning strategy by generalizing to new classes
given only a small number of training samples for each new class. We have
developed a novel encoder-decoder network termed as DVICE (Directed Variational
Inference Cross Encoder), which learns a continuous embedding space to ensure
better similarity learning. We employ a combination of the proposed DVICE
network and a novel few-shot learning approach to tackle the small sample size
problem encountered in co-segmentation with small datasets like iCoseg and
MSRC. Furthermore, the proposed framework does not use any semantic class
labels and is entirely class agnostic. Through exhaustive experimentation over
multiple datasets using only a small volume of training data, we have
demonstrated that our approach outperforms all existing state-of-the-art
techniques.
</p>
<a href="http://arxiv.org/abs/2010.08800" target="_blank">arXiv:2010.08800</a> [<a href="http://arxiv.org/pdf/2010.08800" target="_blank">pdf</a>]

<h2>Assessment of Reward Functions in Reinforcement Learning for Multi-Modal Urban Traffic Control under Real-World limitations. (arXiv:2010.08819v1 [cs.LG])</h2>
<h3>Alvaro Cabrejas-Egea, Colm Connaughton</h3>
<p>Reinforcement Learning is proving a successful tool that can manage urban
intersections with a fraction of the effort required to curate traditional
traffic controllers. However, literature on the introduction and control of
pedestrians to such intersections is scarce. Furthermore, it is unclear what
traffic state variables should be used as reward to obtain the best agent
performance. This paper robustly evaluates 30 different Reinforcement Learning
reward functions for controlling intersections serving pedestrians and vehicles
covering the main traffic state variables available via modern vision-based
sensors. Some rewards proposed in previous literature solely for vehicular
traffic are extended to pedestrians while new ones are introduced. We use a
calibrated model in terms of demand, sensors, green times and other operational
constraints of a real intersection in Greater Manchester, UK. The assessed
rewards can be classified in 5 groups depending on the magnitudes used: queues,
waiting time, delay, average speed and throughput in the junction. The
performance of different agents, in terms of waiting time, is compared across
different demand levels, from normal operation to saturation of traditional
adaptive controllers. We find that those rewards maximising the speed of the
network obtain the lowest waiting time for vehicles and pedestrians
simultaneously, closely followed by queue minimisation, demonstrating better
performance than other previously proposed methods.
</p>
<a href="http://arxiv.org/abs/2010.08819" target="_blank">arXiv:2010.08819</a> [<a href="http://arxiv.org/pdf/2010.08819" target="_blank">pdf</a>]

<h2>Consistency and Coherency Enhanced Story Generation. (arXiv:2010.08822v1 [cs.CL])</h2>
<h3>Wei Wang, Piji Li, Hai-Tao Zheng</h3>
<p>Story generation is a challenging task, which demands to maintain consistency
of the plots and characters throughout the story. Previous works have shown
that GPT2, a large-scale language model, has achieved good performance on story
generation. However, we observe that several serious issues still exist in the
stories generated by GPT2 which can be categorized into two folds: consistency
and coherency. In terms of consistency, on one hand, GPT2 cannot guarantee the
consistency of the plots explicitly. On the other hand, the generated stories
usually contain coreference errors. In terms of coherency, GPT2 does not take
account of the discourse relations between sentences of stories directly. To
enhance the consistency and coherency of the generated stories, we propose a
two-stage generation framework, where the first stage is to organize the story
outline which depicts the story plots and events, and the second stage is to
expand the outline into a complete story. Therefore the plots consistency can
be controlled and guaranteed explicitly. In addition, coreference supervision
signals are incorporated to reduce coreference errors and improve the
coreference consistency. Moreover, we design an auxiliary task of discourse
relation modeling to improve the coherency of the generated stories.
Experimental results on a story dataset show that our model outperforms the
baseline approaches in terms of both automatic metrics and human evaluation.
</p>
<a href="http://arxiv.org/abs/2010.08822" target="_blank">arXiv:2010.08822</a> [<a href="http://arxiv.org/pdf/2010.08822" target="_blank">pdf</a>]

<h2>MESA: Boost Ensemble Imbalanced Learning with MEta-SAmpler. (arXiv:2010.08830v1 [cs.LG])</h2>
<h3>Zhining Liu, Pengfei Wei, Jing Jiang, Wei Cao, Jiang Bian, Yi Chang</h3>
<p>Imbalanced learning (IL), i.e., learning unbiased models from
class-imbalanced data, is a challenging problem. Typical IL methods including
resampling and reweighting were designed based on some heuristic assumptions.
They often suffer from unstable performance, poor applicability, and high
computational cost in complex tasks where their assumptions do not hold. In
this paper, we introduce a novel ensemble IL framework named MESA. It
adaptively resamples the training set in iterations to get multiple classifiers
and forms a cascade ensemble model. MESA directly learns the sampling strategy
from data to optimize the final metric beyond following random heuristics.
Moreover, unlike prevailing meta-learning-based IL solutions, we decouple the
model-training and meta-training in MESA by independently train the
meta-sampler over task-agnostic meta-data. This makes MESA generally applicable
to most of the existing learning models and the meta-sampler can be efficiently
applied to new tasks. Extensive experiments on both synthetic and real-world
tasks demonstrate the effectiveness, robustness, and transferability of MESA.
Our code is available at https://github.com/ZhiningLiu1998/mesa.
</p>
<a href="http://arxiv.org/abs/2010.08830" target="_blank">arXiv:2010.08830</a> [<a href="http://arxiv.org/pdf/2010.08830" target="_blank">pdf</a>]

<h2>A Grid-based Representation for Human Action Recognition. (arXiv:2010.08841v1 [cs.CV])</h2>
<h3>Soufiane Lamghari, Guillaume-Alexandre Bilodeau, Nicolas Saunier</h3>
<p>Human action recognition (HAR) in videos is a fundamental research topic in
computer vision. It consists mainly in understanding actions performed by
humans based on a sequence of visual observations. In recent years, HAR have
witnessed significant progress, especially with the emergence of deep learning
models. However, most of existing approaches for action recognition rely on
information that is not always relevant for the task, and are limited in the
way they fuse temporal information. In this paper, we propose a novel method
for human action recognition that encodes efficiently the most discriminative
appearance information of an action with explicit attention on representative
pose features, into a new compact grid representation. Our GRAR (Grid-based
Representation for Action Recognition) method is tested on several benchmark
datasets that demonstrate that our model can accurately recognize human
actions, despite intra-class appearance variations and occlusion challenges.
</p>
<a href="http://arxiv.org/abs/2010.08841" target="_blank">arXiv:2010.08841</a> [<a href="http://arxiv.org/pdf/2010.08841" target="_blank">pdf</a>]

<h2>Finding Physical Adversarial Examples for Autonomous Driving with Fast and Differentiable Image Compositing. (arXiv:2010.08844v1 [cs.CV])</h2>
<h3>Jinghan Yang, Adith Boloor, Ayan Chakrabarti, Xuan Zhang, Yevgeniy Vorobeychik</h3>
<p>There is considerable evidence that deep neural networks are vulnerable to
adversarial perturbations applied directly to their digital inputs. However, it
remains an open question whether this translates to vulnerabilities in
real-world systems. Specifically, in the context of image inputs to autonomous
driving systems, an attack can be achieved only by modifying the physical
environment, so as to ensure that the resulting stream of video inputs to the
car's controller leads to incorrect driving decisions. Inducing this effect on
the video inputs indirectly through the environment requires accounting for
system dynamics and tracking viewpoint changes. We propose a scalable and
efficient approach for finding adversarial physical modifications, using a
differentiable approximation for the mapping from environmental
modifications-namely, rectangles drawn on the road-to the corresponding video
inputs to the controller network. Given the color, location, position, and
orientation parameters of the rectangles, our mapping composites them onto
pre-recorded video streams of the original environment. Our mapping accounts
for geometric and color variations, is differentiable with respect to rectangle
parameters, and uses multiple original video streams obtained by varying the
driving trajectory. When combined with a neural network-based controller, our
approach allows the design of adversarial modifications through end-to-end
gradient-based optimization. We evaluate our approach using the Carla
autonomous driving simulator, and show that it is significantly more scalable
and far more effective at generating attacks than a prior black-box approach
based on Bayesian Optimization.
</p>
<a href="http://arxiv.org/abs/2010.08844" target="_blank">arXiv:2010.08844</a> [<a href="http://arxiv.org/pdf/2010.08844" target="_blank">pdf</a>]

<h2>Discriminability of Single-Layer Graph Neural Networks. (arXiv:2010.08847v1 [eess.SP])</h2>
<h3>Samuel Pfrommer, Fernando Gama, Alejandro Ribeiro</h3>
<p>Network data can be conveniently modeled as a graph signal, where data values
are assigned to nodes of a graph that describes the underlying network
topology. Successful learning from network data is built upon methods that
effectively exploit this graph structure. Graph neural networks (GNNs) are one
such method that has exhibited promising performance. Understanding why GNNs
work so well is of paramount importance, particularly in applications involving
physical networks. We focus on the property of discriminability and establish
conditions under which the inclusion of pointwise nonlinearities to a stable
graph filter bank can potentially lead to an increased discriminability of
high-eigenvalue content. We define a notion of discriminability tied to the
stability of the architecture, show that GNNs are at least as discriminable as
linear graph filter banks, and characterize the signals that cannot be
discriminated by either.
</p>
<a href="http://arxiv.org/abs/2010.08847" target="_blank">arXiv:2010.08847</a> [<a href="http://arxiv.org/pdf/2010.08847" target="_blank">pdf</a>]

<h2>Against Scale: Provocations and Resistances to Scale Thinking. (arXiv:2010.08850v1 [cs.CY])</h2>
<h3>Alex Hanna, Tina M. Park</h3>
<p>At the heart of what drives the bulk of innovation and activity in Silicon
Valley and elsewhere is scalability. This unwavering commitment to scalability
-- to identify strategies for efficient growth -- is at the heart of what we
refer to as "scale thinking." Whether people are aware of it or not, scale
thinking is all-encompassing. It is not just an attribute of one's product,
service, or company, but frames how one thinks about the world (what
constitutes it and how it can be observed and measured), its problems (what is
a problem worth solving versus not), and the possible technological fixes for
those problems. This paper examines different facets of scale thinking and its
implication on how we view technology and collaborative work. We argue that
technological solutions grounded in scale thinking are unlikely to be as
liberatory or effective at deep, systemic change as their purveyors imagine.
Rather, solutions which resist scale thinking are necessary to undo the social
structures which lie at the heart of social inequality. We draw on recent work
on mutual aid networks and propose questions to ask of collaborative work
systems as a means to evaluate technological solutions and guide designers in
identifying sites of resistance to scale thinking.
</p>
<a href="http://arxiv.org/abs/2010.08850" target="_blank">arXiv:2010.08850</a> [<a href="http://arxiv.org/pdf/2010.08850" target="_blank">pdf</a>]

<h2>A Stochastic Neural Network for Attack-Agnostic Adversarial Robustness. (arXiv:2010.08852v1 [cs.LG])</h2>
<h3>Panagiotis Eustratiadis, Henry Gouk, Da Li, Timothy Hospedales</h3>
<p>Stochastic Neural Networks (SNNs) that inject noise into their hidden layers
have recently been shown to achieve strong robustness against adversarial
attacks. However, existing SNNs are usually heuristically motivated, and
further rely on adversarial training, which is computationally costly and
biases models' defense towards a specific attack. We propose a new SNN that
achieves state-of-the-art performance without relying on adversarial training,
and enjoys solid theoretical justification. Specifically, while existing SNNs
inject learned or hand-tuned isotropic noise, our SNN learns an anisotropic
noise distribution to optimize a learning-theoretic bound on adversarial
robustness. We evaluate our method on three benchmarks (CIFAR-10, SVHN,
F-MNIST), show that it can be applied to different architectures (ResNet-18,
LeNet++), and that it provides robustness to a variety of white-box and
black-box attacks, while being simple and fast to train compared to existing
alternatives. The source code is openly available on GitHub:
https://github.com/peustr/A2SNN.
</p>
<a href="http://arxiv.org/abs/2010.08852" target="_blank">arXiv:2010.08852</a> [<a href="http://arxiv.org/pdf/2010.08852" target="_blank">pdf</a>]

<h2>On Size Generalization in Graph Neural Networks. (arXiv:2010.08853v1 [cs.LG])</h2>
<h3>Gilad Yehudai, Ethan Fetaya, Eli Meirom, Gal Chechik, Haggai Maron</h3>
<p>Graph neural networks (GNNs) can process graphs of different sizes but their
capacity to generalize across sizes is still not well understood. Size
generalization is key to numerous GNN applications, from solving combinatorial
optimization problems to learning in molecular biology. In such problems,
obtaining labels and training on large graphs can be prohibitively expensive,
but training on smaller graphs is possible.

This paper puts forward the size-generalization question and characterizes
important aspects of that problem theoretically and empirically. We show that
even for very simple tasks, GNNs do not naturally generalize to graphs of
larger size. Instead, their generalization performance is closely related to
the distribution of patterns of connectivity and features and how that
distribution changes from small to large graphs. Specifically, we show that in
many cases, there are GNNs that can perfectly solve a task on small graphs but
generalize poorly to large graphs and that these GNNs are encountered in
practice. We then formalize size generalization as a domain-adaption problem
and describe two learning setups where size generalization can be improved.
First, as a self-supervised learning problem (SSL) over the target domain of
large graphs. Second, as a semi-supervised learning problem when few samples
are available in the target domain. We demonstrate the efficacy of these
solutions on a diverse set of benchmark graph datasets.
</p>
<a href="http://arxiv.org/abs/2010.08853" target="_blank">arXiv:2010.08853</a> [<a href="http://arxiv.org/pdf/2010.08853" target="_blank">pdf</a>]

<h2>GOAT: GPU Outsourcing of Deep Learning Training With Asynchronous Probabilistic Integrity Verification Inside Trusted Execution Environment. (arXiv:2010.08855v1 [cs.CR])</h2>
<h3>Aref Asvadishirehjini (1), Murat Kantarcioglu (1), Bradley Malin (2) ((1) University of Texas at Dallas, (2) Vanderbilt University)</h3>
<p>Machine learning models based on Deep Neural Networks (DNNs) are increasingly
deployed in a wide range of applications ranging from self-driving cars to
COVID-19 treatment discovery. To support the computational power necessary to
learn a DNN, cloud environments with dedicated hardware support have emerged as
critical infrastructure. However, there are many integrity challenges
associated with outsourcing computation. Various approaches have been developed
to address these challenges, building on trusted execution environments (TEE).
Yet, no existing approach scales up to support realistic integrity-preserving
DNN model training for heavy workloads (deep architectures and millions of
training examples) without sustaining a significant performance hit. To
mitigate the time gap between pure TEE (full integrity) and pure GPU (no
integrity), we combine random verification of selected computation steps with
systematic adjustments of DNN hyper-parameters (e.g., a narrow gradient
clipping range), hence limiting the attacker's ability to shift the model
parameters significantly provided that the step is not selected for
verification during its training phase. Experimental results show the new
approach achieves 2X to 20X performance improvement over pure TEE based
solution while guaranteeing a very high probability of integrity (e.g., 0.999)
with respect to state-of-the-art DNN backdoor attacks.
</p>
<a href="http://arxiv.org/abs/2010.08855" target="_blank">arXiv:2010.08855</a> [<a href="http://arxiv.org/pdf/2010.08855" target="_blank">pdf</a>]

<h2>An Algorithm to Satisfy the QoS Requirements in a Heterogeneous LoRaWAN Network. (arXiv:2010.08860v1 [cs.NI])</h2>
<h3>Dmitry Bankov, Evgeny Khorov, Andrey Lyakhov</h3>
<p>LoRaWAN is a popular low power wide area network technology widely used in
many scenarios, such as environmental monitoring and smart cities. Different
applications demand various quality of service (QoS), and their service within
a single network requires special solutions for QoS provision. We consider the
problem of QoS provision in heterogeneous LoRaWAN networks that consist of
several groups of devices that require different packet loss rate (PLR). To
solve this problem, we develop a mathematical model that can find the PLR
distribution in a LoRaWAN network. With the model, we show that the PLR can
vary significantly, and it is wrong to consider only the average PLR for the
QoS provision. Finally, we develop an algorithm for assigning modulation and
coding schemes to end-devices that provides PLRs below the required thresholds.
</p>
<a href="http://arxiv.org/abs/2010.08860" target="_blank">arXiv:2010.08860</a> [<a href="http://arxiv.org/pdf/2010.08860" target="_blank">pdf</a>]

<h2>Deep Learning in the Era of Edge Computing: Challenges and Opportunities. (arXiv:2010.08861v1 [cs.LG])</h2>
<h3>Mi Zhang, Faen Zhang, Nicholas D. Lane, Yuanchao Shu, Xiao Zeng, Biyi Fang, Shen Yan, Hui Xu</h3>
<p>The era of edge computing has arrived. Although the Internet is the backbone
of edge computing, its true value lies at the intersection of gathering data
from sensors and extracting meaningful information from the sensor data. We
envision that in the near future, majority of edge devices will be equipped
with machine intelligence powered by deep learning. However, deep
learning-based approaches require a large volume of high-quality data to train
and are very expensive in terms of computation, memory, and power consumption.
In this chapter, we describe eight research challenges and promising
opportunities at the intersection of computer systems, networking, and machine
learning. Solving those challenges will enable resource-limited edge devices to
leverage the amazing capability of deep learning. We hope this chapter could
inspire new research that will eventually lead to the realization of the vision
of intelligent edge.
</p>
<a href="http://arxiv.org/abs/2010.08861" target="_blank">arXiv:2010.08861</a> [<a href="http://arxiv.org/pdf/2010.08861" target="_blank">pdf</a>]

<h2>HABERTOR: An Efficient and Effective Deep Hatespeech Detector. (arXiv:2010.08865v1 [cs.CL])</h2>
<h3>Thanh Tran, Yifan Hu, Changwei Hu, Kevin Yen, Fei Tan, Kyumin Lee, Serim Park</h3>
<p>We present our HABERTOR model for detecting hatespeech in large scale
user-generated content. Inspired by the recent success of the BERT model, we
propose several modifications to BERT to enhance the performance on the
downstream hatespeech classification task. HABERTOR inherits BERT's
architecture, but is different in four aspects: (i) it generates its own
vocabularies and is pre-trained from the scratch using the largest scale
hatespeech dataset; (ii) it consists of Quaternion-based factorized components,
resulting in a much smaller number of parameters, faster training and
inferencing, as well as less memory usage; (iii) it uses our proposed
multi-source ensemble heads with a pooling layer for separate input sources, to
further enhance its effectiveness; and (iv) it uses a regularized adversarial
training with our proposed fine-grained and adaptive noise magnitude to enhance
its robustness. Through experiments on the large-scale real-world hatespeech
dataset with 1.4M annotated comments, we show that HABERTOR works better than
15 state-of-the-art hatespeech detection methods, including fine-tuning
Language Models. In particular, comparing with BERT, our HABERTOR is 4~5 times
faster in the training/inferencing phase, uses less than 1/3 of the memory, and
has better performance, even though we pre-train it by using less than 1% of
the number of words. Our generalizability analysis shows that HABERTOR
transfers well to other unseen hatespeech datasets and is a more efficient and
effective alternative to BERT for the hatespeech classification.
</p>
<a href="http://arxiv.org/abs/2010.08865" target="_blank">arXiv:2010.08865</a> [<a href="http://arxiv.org/pdf/2010.08865" target="_blank">pdf</a>]

<h2>MyWear: A Smart Wear for Continuous Body Vital Monitoring and Emergency Alert. (arXiv:2010.08866v1 [eess.SP])</h2>
<h3>Sibi C. Sethuraman, Pranav Kompally, Saraju P. Mohanty, Uma Choppali</h3>
<p>Smart healthcare which is built as healthcare Cyber-Physical System (H-CPS)
from Internet-of-Medical-Things (IoMT) is becoming more important than before.
Medical devices and their connectivity through Internet with alongwith the
electronics health record (EHR) and AI analytics making H-CPS possible.
IoMT-end devices like wearables and implantables are key for H-CPS based smart
healthcare. Smart garment is a specific wearable which can be used for smart
healthcare. There are various smart garments that help users to monitor their
body vitals in real-time. Many commercially available garments collect the
vital data and transmit it to the mobile application for visualization.
However, these don't perform real-time analysis for the user to comprehend
their health conditions. Also, such garments are not included with an alert
system to alert users and contacts in case of emergency. In MyWear, we propose
a wearable body vital monitoring garment that captures physiological data and
automatically analyses such heart rate, stress level, muscle activity to detect
abnormalities. A copy of the physiological data is transmitted to the cloud for
detecting any abnormalities in heart beats and predict any potential heart
failure in future. We also propose a deep neural network (DNN) model that
automatically classifies abnormal heart beat and potential heart failure. For
immediate assistance in such a situation, we propose an alert system that sends
an alert message to nearby medical officials. The proposed MyWear has an
average accuracy of 96.9% and precision of 97.3% for detection of the
abnormalities.
</p>
<a href="http://arxiv.org/abs/2010.08866" target="_blank">arXiv:2010.08866</a> [<a href="http://arxiv.org/pdf/2010.08866" target="_blank">pdf</a>]

<h2>Sensitivity and Specificity Evaluation of Deep Learning Models for Detection of Pneumoperitoneum on Chest Radiographs. (arXiv:2010.08872v1 [cs.CV])</h2>
<h3>Manu Goyal, Judith Austin-Strohbehn, Sean J. Sun, Karen Rodriguez, Jessica M. Sin, Yvonne Y. Cheung, Saeed Hassanpour</h3>
<p>Background: Deep learning has great potential to assist with detecting and
triaging critical findings such as pneumoperitoneum on medical images. To be
clinically useful, the performance of this technology still needs to be
validated for generalizability across different types of imaging systems.
Materials and Methods: This retrospective study included 1,287 chest X-ray
images of patients who underwent initial chest radiography at 13 different
hospitals between 2011 and 2019. The chest X-ray images were labelled
independently by four radiologist experts as positive or negative for
pneumoperitoneum. State-of-the-art deep learning models (ResNet101,
InceptionV3, DenseNet161, and ResNeXt101) were trained on a subset of this
dataset, and the automated classification performance was evaluated on the rest
of the dataset by measuring the AUC, sensitivity, and specificity for each
model. Furthermore, the generalizability of these deep learning models was
assessed by stratifying the test dataset according to the type of the utilized
imaging systems. Results: All deep learning models performed well for
identifying radiographs with pneumoperitoneum, while DenseNet161 achieved the
highest AUC of 95.7%, Specificity of 89.9%, and Sensitivity of 91.6%.
DenseNet161 model was able to accurately classify radiographs from different
imaging systems (Accuracy: 90.8%), while it was trained on images captured from
a specific imaging system from a single institution. This result suggests the
generalizability of our model for learning salient features in chest X-ray
images to detect pneumoperitoneum, independent of the imaging system.
</p>
<a href="http://arxiv.org/abs/2010.08872" target="_blank">arXiv:2010.08872</a> [<a href="http://arxiv.org/pdf/2010.08872" target="_blank">pdf</a>]

<h2>i-Mix: A Strategy for Regularizing Contrastive Representation Learning. (arXiv:2010.08887v1 [cs.LG])</h2>
<h3>Kibok Lee, Yian Zhu, Kihyuk Sohn, Chun-Liang Li, Jinwoo Shin, Honglak Lee</h3>
<p>Contrastive representation learning has shown to be an effective way of
learning representations from unlabeled data. However, much progress has been
made in vision domains relying on data augmentations carefully designed using
domain knowledge. In this work, we propose i-Mix, a simple yet effective
regularization strategy for improving contrastive representation learning in
both vision and non-vision domains. We cast contrastive learning as training a
non-parametric classifier by assigning a unique virtual class to each data in a
batch. Then, data instances are mixed in both the input and virtual label
spaces, providing more augmented data during training. In experiments, we
demonstrate that i-Mix consistently improves the quality of self-supervised
representations across domains, resulting in significant performance gains on
downstream tasks. Furthermore, we confirm its regularization effect via
extensive ablation studies across model and dataset sizes.
</p>
<a href="http://arxiv.org/abs/2010.08887" target="_blank">arXiv:2010.08887</a> [<a href="http://arxiv.org/pdf/2010.08887" target="_blank">pdf</a>]

<h2>Light Stage Super-Resolution: Continuous High-Frequency Relighting. (arXiv:2010.08888v1 [cs.GR])</h2>
<h3>Tiancheng Sun, Zexiang Xu, Xiuming Zhang, Sean Fanello, Christoph Rhemann, Paul Debevec, Yun-Ta Tsai, Jonathan T. Barron, Ravi Ramamoorthi</h3>
<p>The light stage has been widely used in computer graphics for the past two
decades, primarily to enable the relighting of human faces. By capturing the
appearance of the human subject under different light sources, one obtains the
light transport matrix of that subject, which enables image-based relighting in
novel environments. However, due to the finite number of lights in the stage,
the light transport matrix only represents a sparse sampling on the entire
sphere. As a consequence, relighting the subject with a point light or a
directional source that does not coincide exactly with one of the lights in the
stage requires interpolation and resampling the images corresponding to nearby
lights, and this leads to ghosting shadows, aliased specularities, and other
artifacts. To ameliorate these artifacts and produce better results under
arbitrary high-frequency lighting, this paper proposes a learning-based
solution for the "super-resolution" of scans of human faces taken from a light
stage. Given an arbitrary "query" light direction, our method aggregates the
captured images corresponding to neighboring lights in the stage, and uses a
neural network to synthesize a rendering of the face that appears to be
illuminated by a "virtual" light source at the query location. This neural
network must circumvent the inherent aliasing and regularity of the light stage
data that was used for training, which we accomplish through the use of
regularized traditional interpolation methods within our network. Our learned
model is able to produce renderings for arbitrary light directions that exhibit
realistic shadows and specular highlights, and is able to generalize across a
wide variety of subjects.
</p>
<a href="http://arxiv.org/abs/2010.08888" target="_blank">arXiv:2010.08888</a> [<a href="http://arxiv.org/pdf/2010.08888" target="_blank">pdf</a>]

<h2>DeepAveragers: Offline Reinforcement Learning by Solving Derived Non-Parametric MDPs. (arXiv:2010.08891v1 [cs.LG])</h2>
<h3>Aayam Shrestha, Stefan Lee, Prasad Tadepalli, Alan Fern</h3>
<p>We study an approach to offline reinforcement learning (RL) based on
optimally solving finitely-represented MDPs derived from a static dataset of
experience. This approach can be applied on top of any learned representation
and has the potential to easily support multiple solution objectives as well as
zero-shot adjustment to changing environments and goals. Our main contribution
is to introduce the Deep Averagers with Costs MDP (DAC-MDP) and to investigate
its solutions for offline RL. DAC-MDPs are a non-parametric model that can
leverage deep representations and account for limited data by introducing costs
for exploiting under-represented parts of the model. In theory, we show
conditions that allow for lower-bounding the performance of DAC-MDP solutions.
We also investigate the empirical behavior in a number of environments,
including those with image-based observations. Overall, the experiments
demonstrate that the framework can work in practice and scale to large complex
offline RL problems.
</p>
<a href="http://arxiv.org/abs/2010.08891" target="_blank">arXiv:2010.08891</a> [<a href="http://arxiv.org/pdf/2010.08891" target="_blank">pdf</a>]

<h2>Fast Distributed Training of Deep Neural Networks: Dynamic Communication Thresholding for Model and Data Parallelism. (arXiv:2010.08899v1 [cs.LG])</h2>
<h3>Vipul Gupta, Dhruv Choudhary, Ping Tak Peter Tang, Xiaohan Wei, Xing Wang, Yuzhen Huang, Arun Kejariwal, Kannan Ramchandran, Michael W. Mahoney</h3>
<p>Data Parallelism (DP) and Model Parallelism (MP) are two common paradigms to
enable large-scale distributed training of neural networks. Recent trends, such
as the improved model performance of deeper and wider neural networks when
trained with billions of data points, have prompted the use of hybrid
parallelism---a paradigm that employs both DP and MP to scale further
parallelization for machine learning. Hybrid training allows compute power to
increase, but it runs up against the key bottleneck of communication overhead
that hinders scalability.

In this paper, we propose a compression framework called Dynamic
Communication Thresholding (DCT) for communication-efficient hybrid training.
DCT filters the entities to be communicated across the network through a simple
hard-thresholding function, allowing only the most relevant information to pass
through. For communication efficient DP, DCT compresses the parameter gradients
sent to the parameter server during model synchronization, while compensating
for the introduced errors with known techniques. For communication efficient
MP, DCT incorporates a novel technique to compress the activations and
gradients sent across the network during the forward and backward propagation,
respectively. This is done by identifying and updating only the most relevant
neurons of the neural network for each training sample in the data. Under
modest assumptions, we show that the convergence of training is maintained with
DCT. We evaluate DCT on natural language processing and recommender system
models. DCT reduces overall communication by 20x, improving end-to-end training
time on industry scale models by 37%. Moreover, we observe an improvement in
the trained model performance, as the induced sparsity is possibly acting as an
implicit sparsity based regularization.
</p>
<a href="http://arxiv.org/abs/2010.08899" target="_blank">arXiv:2010.08899</a> [<a href="http://arxiv.org/pdf/2010.08899" target="_blank">pdf</a>]

<h2>Boosting High-Level Vision with Joint Compression Artifacts Reduction and Super-Resolution. (arXiv:2010.08919v1 [cs.CV])</h2>
<h3>Xiaoyu Xiang, Qian Lin, Jan P. Allebach</h3>
<p>Due to the limits of bandwidth and storage space, digital images are usually
down-scaled and compressed when transmitted over networks, resulting in loss of
details and jarring artifacts that can lower the performance of high-level
visual tasks. In this paper, we aim to generate an artifact-free
high-resolution image from a low-resolution one compressed with an arbitrary
quality factor by exploring joint compression artifacts reduction (CAR) and
super-resolution (SR) tasks. First, we propose a context-aware joint CAR and SR
neural network (CAJNN) that integrates both local and non-local features to
solve CAR and SR in one-stage. Finally, a deep reconstruction network is
adopted to predict high quality and high-resolution images. Evaluation on CAR
and SR benchmark datasets shows that our CAJNN model outperforms previous
methods and also takes 26.2% shorter runtime. Based on this model, we explore
addressing two critical challenges in high-level computer vision: optical
character recognition of low-resolution texts, and extremely tiny face
detection. We demonstrate that CAJNN can serve as an effective image
preprocessing method and improve the accuracy for real-scene text recognition
(from 85.30% to 85.75%) and the average precision for tiny face detection (from
0.317 to 0.611).
</p>
<a href="http://arxiv.org/abs/2010.08919" target="_blank">arXiv:2010.08919</a> [<a href="http://arxiv.org/pdf/2010.08919" target="_blank">pdf</a>]

<h2>Average-reward model-free reinforcement learning: a systematic review and literature mapping. (arXiv:2010.08920v1 [cs.LG])</h2>
<h3>Vektor Dewanto, George Dunn, Ali Eshragh, Marcus Gallagher, Fred Roosta</h3>
<p>Model-free reinforcement learning (RL) has been an active area of research
and provides a fundamental framework for agent-based learning and
decision-making in artificial intelligence. In this paper, we review a specific
subset of this literature, namely work that utilizes optimization criteria
based on average rewards, in the infinite horizon setting. Average reward RL
has the advantage of being the most selective criterion in recurrent (ergodic)
Markov decision processes. In comparison to widely-used discounted reward
criterion, it also requires no discount factor, which is a critical
hyperparameter, and properly aligns the optimization and performance metrics.
Motivated by the solo survey by Mahadevan (1996a), we provide an updated review
of work in this area and extend it to cover policy-iteration and function
approximation methods (in addition to the value-iteration and tabular
counterparts). We also identify and discuss opportunities for future work.
</p>
<a href="http://arxiv.org/abs/2010.08920" target="_blank">arXiv:2010.08920</a> [<a href="http://arxiv.org/pdf/2010.08920" target="_blank">pdf</a>]

<h2>Meta-path Free Semi-supervised Learning for Heterogeneous Networks. (arXiv:2010.08924v1 [cs.LG])</h2>
<h3>Shin-woo Park, Byung Jun Bae, Jinyoung Yeo, Seung-won Hwang</h3>
<p>Graph neural networks (GNNs) have been widely used in representation learning
on graphs and achieved superior performance in tasks such as node
classification. However, analyzing heterogeneous graph of different types of
nodes and links still brings great challenges for injecting the heterogeneity
into a graph neural network. A general remedy is to manually or automatically
design meta-paths to transform a heterogeneous graph into a homogeneous graph,
but this is suboptimal since the features from the first-order neighbors are
not fully leveraged for training and inference. In this paper, we propose
simple and effective graph neural networks for heterogeneous graph, excluding
the use of meta-paths. Specifically, our models focus on relaxing the
heterogeneity stress for model parameters by expanding model capacity of
general GNNs in an effective way. Extensive experimental results on six
real-world graphs not only show the superior performance of our proposed models
over the state-of-the-arts, but also demonstrate the potentially good balance
between reducing the heterogeneity stress and increasing the parameter size.
Our code is freely available for reproducing our results.
</p>
<a href="http://arxiv.org/abs/2010.08924" target="_blank">arXiv:2010.08924</a> [<a href="http://arxiv.org/pdf/2010.08924" target="_blank">pdf</a>]

<h2>Dynamic Ensemble Learning for Credit Scoring: A Comparative Study. (arXiv:2010.08930v1 [cs.LG])</h2>
<h3>Mahsan Abdoli, Mohammad Akbari, Jamal Shahrabi</h3>
<p>Automatic credit scoring, which assesses the probability of default by loan
applicants, plays a vital role in peer-to-peer lending platforms to reduce the
risk of lenders. Although it has been demonstrated that dynamic selection
techniques are effective for classification tasks, the performance of these
techniques for credit scoring has not yet been determined. This study attempts
to benchmark different dynamic selection approaches systematically for ensemble
learning models to accurately estimate the credit scoring task on a large and
high-dimensional real-life credit scoring data set. The results of this study
indicate that dynamic selection techniques are able to boost the performance of
ensemble models, especially in imbalanced training environments.
</p>
<a href="http://arxiv.org/abs/2010.08930" target="_blank">arXiv:2010.08930</a> [<a href="http://arxiv.org/pdf/2010.08930" target="_blank">pdf</a>]

<h2>Distortion-aware Monocular Depth Estimation for Omnidirectional Images. (arXiv:2010.08942v1 [cs.CV])</h2>
<h3>Hong-Xiang Chen, Kunhong Li, Yulan Guo, Zhiheng Fu, Mengyi Liu</h3>
<p>A main challenge for tasks on panorama lies in the distortion of objects
among images. In this work, we propose a Distortion-Aware Monocular
Omnidirectional (DAMO) dense depth estimation network to address this challenge
on indoor panoramas with two steps. First, we introduce a distortion-aware
module to extract calibrated semantic features from omnidirectional images.
Specifically, we exploit deformable convolution to adjust its sampling grids to
geometric variations of distorted objects on panoramas and then utilize a strip
pooling module to sample against horizontal distortion introduced by inverse
gnomonic projection. Second, we further introduce a plug-and-play
spherical-aware weight matrix for our objective function to handle the uneven
distribution of areas projected from a sphere. Experiments on the 360D dataset
show that the proposed method can effectively extract semantic features from
distorted panoramas and alleviate the supervision bias caused by distortion. It
achieves state-of-the-art performance on the 360D dataset with high efficiency.
</p>
<a href="http://arxiv.org/abs/2010.08942" target="_blank">arXiv:2010.08942</a> [<a href="http://arxiv.org/pdf/2010.08942" target="_blank">pdf</a>]

<h2>Temporal Binary Representation for Event-Based Action Recognition. (arXiv:2010.08946v1 [cs.CV])</h2>
<h3>Simone Undri Innocenti, Federico Becattini, Federico Pernici, Alberto Del Bimbo</h3>
<p>In this paper we present an event aggregation strategy to convert the output
of an event camera into frames processable by traditional Computer Vision
algorithms. The proposed method first generates sequences of intermediate
binary representations, which are then losslessly transformed into a compact
format by simply applying a binary-to-decimal conversion. This strategy allows
us to encode temporal information directly into pixel values, which are then
interpreted by deep learning models. We apply our strategy, called Temporal
Binary Representation, to the task of Gesture Recognition, obtaining state of
the art results on the popular DVS128 Gesture Dataset. To underline the
effectiveness of the proposed method compared to existing ones, we also collect
an extension of the dataset under more challenging conditions on which to
perform experiments.
</p>
<a href="http://arxiv.org/abs/2010.08946" target="_blank">arXiv:2010.08946</a> [<a href="http://arxiv.org/pdf/2010.08946" target="_blank">pdf</a>]

<h2>Unexpected Information Leakage of Differential Privacy Due to Linear Property of Queries. (arXiv:2010.08958v1 [cs.CR])</h2>
<h3>Wen Huang, Shijie Zhou, Yongjian Liao</h3>
<p>The differential privacy is a widely accepted conception of privacy
preservation and the Laplace mechanism is a famous instance of differential
privacy mechanisms to deal with numerical data. In this paper, we find that the
differential privacy does not take liner property of queries into account,
resulting in unexpected information leakage. In specific, the linear property
makes it possible to divide one query into two queries such as
$q(D)=q(D_1)+q(D_2)$ if $D=D_1\cup D_2$ and $D_1\cap D_2=\emptyset$. If
attackers try to obtain an answer of $q(D)$, they not only can issue the query
$q(D)$, but also can issue the $q(D_1)$ and calculate the $q(D_2)$ by
themselves as long as they know $D_2$. By different divisions of one query,
attackers can obtain multiple different answers for the query from differential
privacy mechanisms. However, from attackers' perspective and from differential
privacy mechanisms' perspective, the totally consumed privacy budget is
different if divisions are delicately designed. The difference leads to
unexpected information leakage because the privacy budget is the key parameter
to control the amount of legally released information from differential privacy
mechanisms. In order to demonstrate the unexpected information leakage, we
present a membership inference attacks against the Laplace mechanism.
</p>
<a href="http://arxiv.org/abs/2010.08958" target="_blank">arXiv:2010.08958</a> [<a href="http://arxiv.org/pdf/2010.08958" target="_blank">pdf</a>]

<h2>Feature Importance Ranking for Deep Learning. (arXiv:2010.08973v1 [cs.LG])</h2>
<h3>Maksymilian Wojtas, Ke Chen</h3>
<p>Feature importance ranking has become a powerful tool for explainable AI.
However, its nature of combinatorial optimization poses a great challenge for
deep learning. In this paper, we propose a novel dual-net architecture
consisting of operator and selector for discovery of an optimal feature subset
of a fixed size and ranking the importance of those features in the optimal
subset simultaneously. During learning, the operator is trained for a
supervised learning task via optimal feature subset candidates generated by the
selector that learns predicting the learning performance of the operator
working on different optimal subset candidates. We develop an alternate
learning algorithm that trains two nets jointly and incorporates a stochastic
local search procedure into learning to address the combinatorial optimization
challenge. In deployment, the selector generates an optimal feature subset and
ranks feature importance, while the operator makes predictions based on the
optimal subset for test data. A thorough evaluation on synthetic, benchmark and
real data sets suggests that our approach outperforms several state-of-the-art
feature importance ranking and supervised feature selection methods. (Our
source code is available: https://github.com/maksym33/FeatureImportanceDL)
</p>
<a href="http://arxiv.org/abs/2010.08973" target="_blank">arXiv:2010.08973</a> [<a href="http://arxiv.org/pdf/2010.08973" target="_blank">pdf</a>]

<h2>Federated Unsupervised Representation Learning. (arXiv:2010.08982v1 [cs.LG])</h2>
<h3>Fengda Zhang, Kun Kuang, Zhaoyang You, Tao Shen, Jun Xiao, Yin Zhang, Chao Wu, Yueting Zhuang, Xiaolin Li</h3>
<p>To leverage enormous unlabeled data on distributed edge devices, we formulate
a new problem in federated learning called Federated Unsupervised
Representation Learning (FURL) to learn a common representation model without
supervision while preserving data privacy. FURL poses two new challenges: (1)
data distribution shift (Non-IID distribution) among clients would make local
models focus on different categories, leading to the inconsistency of
representation spaces. (2) without the unified information among clients in
FURL, the representations across clients would be misaligned. To address these
challenges, we propose Federated Constrastive Averaging with dictionary and
alignment (FedCA) algorithm. FedCA is composed of two key modules: (1)
dictionary module to aggregate the representations of samples from each client
and share with all clients for consistency of representation space and (2)
alignment module to align the representation of each client on a base model
trained on a public data. We adopt the contrastive loss for local model
training. Through extensive experiments with three evaluation protocols in IID
and Non-IID settings, we demonstrate that FedCA outperforms all baselines with
significant margins.
</p>
<a href="http://arxiv.org/abs/2010.08982" target="_blank">arXiv:2010.08982</a> [<a href="http://arxiv.org/pdf/2010.08982" target="_blank">pdf</a>]

<h2>Construction and Application of Teaching System Based on Crowdsourcing Knowledge Graph. (arXiv:2010.08995v1 [cs.DB])</h2>
<h3>Jinta Weng, Ying Gao, Jing Qiu, Guozhu Ding, Huanqin Zheng</h3>
<p>Through the combination of crowdsourcing knowledge graph and teaching system,
research methods to generate knowledge graph and its applications. Using two
crowdsourcing approaches, crowdsourcing task distribution and reverse captcha
generation, to construct knowledge graph in the field of teaching system.
Generating a complete hierarchical knowledge graph of the teaching domain by
nodes of school, student, teacher, course, knowledge point and exercise type.
The knowledge graph constructed in a crowdsourcing manner requires many users
to participate collaboratively with fully consideration of teachers' guidance
and users' mobilization issues. Based on the three subgraphs of knowledge
graph, prominent teacher, student learning situation and suitable learning
route could be visualized. Personalized exercises recommendation model is used
to formulate the personalized exercise by algorithm based on the knowledge
graph. Collaborative creation model is developed to realize the crowdsourcing
construction mechanism. Though unfamiliarity with the learning mode of
knowledge graph and learners' less attention to the knowledge structure, system
based on Crowdsourcing Knowledge Graph can still get high acceptance around
students and teachers
</p>
<a href="http://arxiv.org/abs/2010.08995" target="_blank">arXiv:2010.08995</a> [<a href="http://arxiv.org/pdf/2010.08995" target="_blank">pdf</a>]

<h2>Image-based Automated Species Identification: Can Virtual Data Augmentation Overcome Problems of Insufficient Sampling?. (arXiv:2010.09009v1 [cs.CV])</h2>
<h3>Morris Klasen, Dirk Ahrens, Jonas Eberle, Volker Steinhage</h3>
<p>Automated species identification and delimitation is challenging,
particularly in rare and thus often scarcely sampled species, which do not
allow sufficient discrimination of infraspecific versus interspecific
variation. Typical problems arising from either low or exaggerated
interspecific morphological differentiation are best met by automated methods
of machine learning that learn efficient and effective species identification
from training samples. However, limited infraspecific sampling remains a key
challenge also in machine learning. 1In this study, we assessed whether a
two-level data augmentation approach may help to overcome the problem of scarce
training data in automated visual species identification. The first level of
visual data augmentation applies classic approaches of data augmentation and
generation of faked images using a GAN approach. Descriptive feature vectors
are derived from bottleneck features of a VGG-16 convolutional neural network
(CNN) that are then stepwise reduced in dimensionality using Global Average
Pooling and PCA to prevent overfitting. The second level of data augmentation
employs synthetic additional sampling in feature space by an oversampling
algorithm in vector space (SMOTE). Applied on two challenging datasets of
scarab beetles (Coleoptera), our augmentation approach outperformed a
non-augmented deep learning baseline approach as well as a traditional 2D
morphometric approach (Procrustes analysis).
</p>
<a href="http://arxiv.org/abs/2010.09009" target="_blank">arXiv:2010.09009</a> [<a href="http://arxiv.org/pdf/2010.09009" target="_blank">pdf</a>]

<h2>FGAGT: Flow-Guided Adaptive Graph Tracking. (arXiv:2010.09015v1 [cs.CV])</h2>
<h3>Chaobing Shan, Chunbo Wei, Bing Deng, Jianqiang Huang, Xian-Sheng Hua, Xiaoliang Cheng, Kewei Liang</h3>
<p>Multi-object tracking (MOT) has always been a very important research
direction in computer vision and has great applications in autonomous driving,
video object behavior prediction, traffic management, and accident prevention.
Recently, some methods have made great progress on MOT, such as CenterTrack,
which predicts the trajectory position based on optical flow then tracks it,
and FairMOT, which uses higher resolution feature maps to extract Re-id
features. In this article, we propose the FGAGT tracker. Different from
FairMOT, we use Pyramid Lucas Kanade optical flow method to predict the
position of the historical objects in the current frame, and use ROI
Pooling\cite{He2015} and fully connected layers to extract the historical
objects' appearance feature vectors on the feature maps of the current frame.
Next, input them and new objects' feature vectors into the adaptive graph
neural network to update the feature vectors. The adaptive graph network can
update the feature vectors of the objects by combining historical global
position and appearance information. Because the historical information is
preserved, it can also re-identify the occluded objects. In the training phase,
we propose the Balanced MSE LOSS to balance the sample distribution. In the
Inference phase, we use the Hungarian algorithm for data association. Our
method reaches the level of state-of-the-art, where the MOTA index exceeds
FairMOT by 2.5 points, and CenterTrack by 8.4 points on the MOT17 dataset,
exceeds FairMOT by 7.2 points on the MOT16 dataset.
</p>
<a href="http://arxiv.org/abs/2010.09015" target="_blank">arXiv:2010.09015</a> [<a href="http://arxiv.org/pdf/2010.09015" target="_blank">pdf</a>]

<h2>JSRT: James-Stein Regression Tree. (arXiv:2010.09022v1 [cs.LG])</h2>
<h3>Xingchun Xiang, Qingtao Tang, Huaixuan Zhang, Tao Dai, Shu-Tao Xia</h3>
<p>Regression tree (RT) has been widely used in machine learning and data mining
community. Given a target data for prediction, a regression tree is first
constructed based on a training dataset before making prediction for each leaf
node. In practice, the performance of RT relies heavily on the local mean of
samples from an individual node during the tree construction/prediction stage,
while neglecting the global information from different nodes, which also plays
an important role. To address this issue, we propose a novel regression tree,
named James-Stein Regression Tree (JSRT) by considering global information from
different nodes. Specifically, we incorporate the global mean information based
on James-Stein estimator from different nodes during the construction/predicton
stage. Besides, we analyze the generalization error of our method under the
mean square error (MSE) metric. Extensive experiments on public benchmark
datasets verify the effectiveness and efficiency of our method, and demonstrate
the superiority of our method over other RT prediction methods.
</p>
<a href="http://arxiv.org/abs/2010.09022" target="_blank">arXiv:2010.09022</a> [<a href="http://arxiv.org/pdf/2010.09022" target="_blank">pdf</a>]

<h2>Characterizing and Taming Model Instability Across Edge Devices. (arXiv:2010.09028v1 [cs.LG])</h2>
<h3>Eyal Cidon, Evgenya Pergament, Zain Asgar, Asaf Cidon, Sachin Katti</h3>
<p>The same machine learning model running on different edge devices may produce
highly-divergent outputs on a nearly-identical input. Possible reasons for the
divergence include differences in the device sensors, the device's signal
processing hardware and software, and its operating system and processors. This
paper presents the first methodical characterization of the variations in model
prediction across real-world mobile devices. We demonstrate that accuracy is
not a useful metric to characterize prediction divergence, and introduce a new
metric, instability, which captures this variation. We characterize different
sources for instability, and show that differences in compression formats and
image signal processing account for significant instability in object
classification models. Notably, in our experiments, 14-17% of images produced
divergent classifications across one or more phone models. We evaluate three
different techniques for reducing instability. In particular, we adapt prior
work on making models robust to noise in order to fine-tune models to be robust
to variations across edge devices. We demonstrate our fine-tuning techniques
reduce instability by 75%.
</p>
<a href="http://arxiv.org/abs/2010.09028" target="_blank">arXiv:2010.09028</a> [<a href="http://arxiv.org/pdf/2010.09028" target="_blank">pdf</a>]

<h2>Living in the Physics and Machine Learning Interplay for Earth Observation. (arXiv:2010.09031v1 [cs.LG])</h2>
<h3>Gustau Camps-Valls, Daniel H. Svendsen, Jordi Cort&#xe9;s-Andr&#xe9;s, &#xc1;lvaro Moreno-Mart&#xed;nez, Adri&#xe1;n P&#xe9;rez-Suay, Jose Adsuara, Irene Mart&#xed;n, Maria Piles, Jordi Mu&#xf1;oz-Mar&#xed;, Luca Martino</h3>
<p>Most problems in Earth sciences aim to do inferences about the system, where
accurate predictions are just a tiny part of the whole problem. Inferences mean
understanding variables relations, deriving models that are physically
interpretable, that are simple parsimonious, and mathematically tractable.
Machine learning models alone are excellent approximators, but very often do
not respect the most elementary laws of physics, like mass or energy
conservation, so consistency and confidence are compromised. In this paper, we
describe the main challenges ahead in the field, and introduce several ways to
live in the Physics and machine learning interplay: to encode differential
equations from data, constrain data-driven models with physics-priors and
dependence constraints, improve parameterizations, emulate physical models, and
blend data-driven and process-based models. This is a collective long-term AI
agenda towards developing and applying algorithms capable of discovering
knowledge in the Earth system.
</p>
<a href="http://arxiv.org/abs/2010.09031" target="_blank">arXiv:2010.09031</a> [<a href="http://arxiv.org/pdf/2010.09031" target="_blank">pdf</a>]

<h2>Model-Based Inverse Reinforcement Learning from Visual Demonstrations. (arXiv:2010.09034v1 [cs.RO])</h2>
<h3>Neha Das, Sarah Bechtle, Todor Davchev, Dinesh Jayaraman, Akshara Rai, Franziska Meier</h3>
<p>Scaling model-based inverse reinforcement learning (IRL) to real robotic
manipulation tasks with unknown dynamics remains an open problem. The key
challenges lie in learning good dynamics models, developing algorithms that
scale to high-dimensional state-spaces and being able to learn from both visual
and proprioceptive demonstrations. In this work, we present a gradient-based
inverse reinforcement learning framework that utilizes a pre-trained visual
dynamics model to learn cost functions when given only visual human
demonstrations. The learned cost functions are then used to reproduce the
demonstrated behavior via visual model predictive control. We evaluate our
framework on hardware on two basic object manipulation tasks.
</p>
<a href="http://arxiv.org/abs/2010.09034" target="_blank">arXiv:2010.09034</a> [<a href="http://arxiv.org/pdf/2010.09034" target="_blank">pdf</a>]

<h2>Deep Structured Prediction for Facial Landmark Detection. (arXiv:2010.09035v1 [cs.CV])</h2>
<h3>Lisha Chen, Hui Su, Qiang Ji</h3>
<p>Existing deep learning based facial landmark detection methods have achieved
excellent performance. These methods, however, do not explicitly embed the
structural dependencies among landmark points. They hence cannot preserve the
geometric relationships between landmark points or generalize well to
challenging conditions or unseen data. This paper proposes a method for deep
structured facial landmark detection based on combining a deep Convolutional
Network with a Conditional Random Field. We demonstrate its superior
performance to existing state-of-the-art techniques in facial landmark
detection, especially a better generalization ability on challenging datasets
that include large pose and occlusion.
</p>
<a href="http://arxiv.org/abs/2010.09035" target="_blank">arXiv:2010.09035</a> [<a href="http://arxiv.org/pdf/2010.09035" target="_blank">pdf</a>]

<h2>Evaluation of a Vision-to-Audition Substitution System that Provides 2D WHERE Information and Fast User Learning. (arXiv:2010.09041v1 [cs.HC])</h2>
<h3>Louis Comm&#xe8;re, Sean U.N. Wood, Jean Rouat</h3>
<p>Vision to audition substitution devices are designed to convey visual
information through auditory input. The acceptance of such systems depends
heavily on their ease of use, training time, reliability and on the amount of
coverage of online auditory perception of current auditory scenes. Existing
devices typically require extensive training time or complex and
computationally demanding technology. The purpose of this work is to
investigate the learning curve for a vision to audition substitution system
that provides simple location features. Forty-two blindfolded users
participated in experiments involving location and navigation tasks.
Participants had no prior experience with the system. For the location task,
participants had to locate 3 objects on a table after a short familiarisation
period (10 minutes). Then once they understood the manipulation of the device,
they proceeded to the navigation task: participants had to walk through a large
corridor without colliding with obstacles randomly placed on the floor.
Participants were asked to repeat the task 5 times. In the end of the
experiment, each participant had to fill out a questionnaire to provide
feedback. They were able to perform localisation and navigation effectively
after a short training time with an average of 10 minutes. Their navigation
skills greatly improved across the trials.
</p>
<a href="http://arxiv.org/abs/2010.09041" target="_blank">arXiv:2010.09041</a> [<a href="http://arxiv.org/pdf/2010.09041" target="_blank">pdf</a>]

<h2>Addressing Variance Shrinkage in Variational Autoencoders using Quantile Regression. (arXiv:2010.09042v1 [cs.LG])</h2>
<h3>Haleh Akrami, Anand A. Joshi, Sergul Aydore, Richard M. Leahy</h3>
<p>Estimation of uncertainty in deep learning models is of vital importance,
especially in medical imaging, where reliance on inference without taking into
account uncertainty could lead to misdiagnosis. Recently, the probabilistic
Variational AutoEncoder (VAE) has become a popular model for anomaly detection
in applications such as lesion detection in medical images. The VAE is a
generative graphical model that is used to learn the data distribution from
samples and then generate new samples from this distribution. By training on
normal samples, the VAE can be used to detect inputs that deviate from this
learned distribution. The VAE models the output as a conditionally independent
Gaussian characterized by means and variances for each output dimension. VAEs
can therefore use reconstruction probability instead of reconstruction error
for anomaly detection. Unfortunately, joint optimization of both mean and
variance in the VAE leads to the well-known problem of shrinkage or
underestimation of variance. We describe an alternative approach that avoids
this variance shrinkage problem by using quantile regression. Using estimated
quantiles to compute mean and variance under the Gaussian assumption, we
compute reconstruction probability as a principled approach to outlier or
anomaly detection. Results on simulated and Fashion MNIST data demonstrate the
effectiveness of our approach. We also show how our approach can be used for
principled heterogeneous thresholding for lesion detection in brain images.
</p>
<a href="http://arxiv.org/abs/2010.09042" target="_blank">arXiv:2010.09042</a> [<a href="http://arxiv.org/pdf/2010.09042" target="_blank">pdf</a>]

<h2>Meta-Learning for Low-Resource Unsupervised Neural MachineTranslation. (arXiv:2010.09046v1 [cs.CL])</h2>
<h3>Yunwon Tae, Cheonbok Park, Taehee Kim, Soyoung Yang, Mohammad Azam Khan, Eunjeong Park, Tao Qin, Jaegul Choo</h3>
<p>Unsupervised machine translation, which utilizes unpaired monolingual corpora
as training data, has achieved comparable performance against supervised
machine translation. However, it still suffers from data-scarce domains. To
address this issue, this paper presents a meta-learning algorithm for
unsupervised neural machine translation (UNMT) that trains the model to adapt
to another domain by utilizing only a small amount of training data. We assume
that domain-general knowledge is a significant factor in handling data-scarce
domains. Hence, we extend the meta-learning algorithm, which utilizes knowledge
learned from high-resource domains to boost the performance of low-resource
UNMT. Our model surpasses a transfer learning-based approach by up to 2-4 BLEU
scores. Extensive experimental results show that our proposed algorithm is
pertinent for fast adaptation and consistently outperforms other baseline
models.
</p>
<a href="http://arxiv.org/abs/2010.09046" target="_blank">arXiv:2010.09046</a> [<a href="http://arxiv.org/pdf/2010.09046" target="_blank">pdf</a>]

<h2>Model-free conventions in multi-agent reinforcement learning with heterogeneous preferences. (arXiv:2010.09054v1 [cs.MA])</h2>
<h3>Raphael K&#xf6;ster, Kevin R. McKee, Richard Everett, Laura Weidinger, William S. Isaac, Edward Hughes, Edgar A. Du&#xe9;&#xf1;ez-Guzm&#xe1;n, Thore Graepel, Matthew Botvinick, Joel Z. Leibo</h3>
<p>Game theoretic views of convention generally rest on notions of common
knowledge and hyper-rational models of individual behavior. However, decades of
work in behavioral economics have questioned the validity of both foundations.
Meanwhile, computational neuroscience has contributed a modernized 'dual
process' account of decision-making where model-free (MF) reinforcement
learning trades off with model-based (MB) reinforcement learning. The former
captures habitual and procedural learning while the latter captures choices
taken via explicit planning and deduction. Some conventions (e.g. international
treaties) are likely supported by cognition that resonates with the game
theoretic and MB accounts. However, convention formation may also occur via MF
mechanisms like habit learning; though this possibility has been understudied.
Here, we demonstrate that complex, large-scale conventions can emerge from MF
learning mechanisms. This suggests that some conventions may be supported by
habit-like cognition rather than explicit reasoning. We apply MF multi-agent
reinforcement learning to a temporo-spatially extended game with incomplete
information. In this game, large parts of the state space are reachable only by
collective action. However, heterogeneity of tastes makes such coordinated
action difficult: multiple equilibria are desirable for all players, but
subgroups prefer a particular equilibrium over all others. This creates a
coordination problem that can be solved by establishing a convention. We
investigate start-up and free rider subproblems as well as the effects of group
size, intensity of intrinsic preference, and salience on the emergence dynamics
of coordination conventions. Results of our simulations show agents establish
and switch between conventions, even working against their own preferred
outcome when doing so is necessary for effective coordination.
</p>
<a href="http://arxiv.org/abs/2010.09054" target="_blank">arXiv:2010.09054</a> [<a href="http://arxiv.org/pdf/2010.09054" target="_blank">pdf</a>]

<h2>Social-VRNN: One-Shot Multi-modal Trajectory Prediction for Interacting Pedestrians. (arXiv:2010.09056v1 [cs.RO])</h2>
<h3>Bruno Brito, Hai Zhu, Wei Pan, Javier Alonso-Mora</h3>
<p>Prediction of human motions is key for safe navigation of autonomous robots
among humans. In cluttered environments, several motion hypotheses may exist
for a pedestrian, due to its interactions with the environment and other
pedestrians.

Previous works for estimating multiple motion hypotheses require a large
number of samples which limits their applicability in real-time motion
planning. In this paper, we present a variational learning approach for
interaction-aware and multi-modal trajectory prediction based on deep
generative neural networks.

Our approach can achieve faster convergence and requires significantly fewer
samples comparing to state-of-the-art methods. Experimental results on real and
simulation data show that our model can effectively learn to infer different
trajectories. We compare our method with three baseline approaches and present
performance results demonstrating that our generative model can achieve higher
accuracy for trajectory prediction by producing diverse trajectories.
</p>
<a href="http://arxiv.org/abs/2010.09056" target="_blank">arXiv:2010.09056</a> [<a href="http://arxiv.org/pdf/2010.09056" target="_blank">pdf</a>]

<h2>Enabling Fast Differentially Private SGD via Just-in-Time Compilation and Vectorization. (arXiv:2010.09063v1 [cs.LG])</h2>
<h3>Pranav Subramani, Nicholas Vadivelu, Gautam Kamath</h3>
<p>A common pain point in differentially private machine learning is the
significant runtime overhead incurred when executing Differentially Private
Stochastic Gradient Descent (DPSGD), which may be as large as two orders of
magnitude. We thoroughly demonstrate that by exploiting powerful language
primitives, including vectorization, just-in-time compilation, and static graph
optimization, one can dramatically reduce these overheads, in many cases nearly
matching the best non-private running times. These gains are realized in two
frameworks: JAX and TensorFlow. JAX provides rich support for these primitives
as core features of the language through the XLA compiler. We also rebuild core
parts of TensorFlow Privacy, integrating features from TensorFlow 2 as well as
XLA compilation, granting significant memory and runtime improvements over the
current release version. These approaches allow us to achieve up to 50x
speedups in comparison to the best alternatives. Our code is available at
https://github.com/TheSalon/fast-dpsgd.
</p>
<a href="http://arxiv.org/abs/2010.09063" target="_blank">arXiv:2010.09063</a> [<a href="http://arxiv.org/pdf/2010.09063" target="_blank">pdf</a>]

<h2>Exploiting Context for Robustness to Label Noise in Active Learning. (arXiv:2010.09066v1 [cs.CV])</h2>
<h3>Sudipta Paul, Shivkumar Chandrasekaran, B.S. Manjunath, Amit K. Roy-Chowdhury</h3>
<p>Several works in computer vision have demonstrated the effectiveness of
active learning for adapting the recognition model when new unlabeled data
becomes available. Most of these works consider that labels obtained from the
annotator are correct. However, in a practical scenario, as the quality of the
labels depends on the annotator, some of the labels might be wrong, which
results in degraded recognition performance. In this paper, we address the
problems of i) how a system can identify which of the queried labels are wrong
and ii) how a multi-class active learning system can be adapted to minimize the
negative impact of label noise. Towards solving the problems, we propose a
noisy label filtering based learning approach where the inter-relationship
(context) that is quite common in natural data is utilized to detect the wrong
labels. We construct a graphical representation of the unlabeled data to encode
these relationships and obtain new beliefs on the graph when noisy labels are
available. Comparing the new beliefs with the prior relational information, we
generate a dissimilarity score to detect the incorrect labels and update the
recognition model with correct labels which result in better recognition
performance. This is demonstrated in three different applications: scene
classification, activity classification, and document classification.
</p>
<a href="http://arxiv.org/abs/2010.09066" target="_blank">arXiv:2010.09066</a> [<a href="http://arxiv.org/pdf/2010.09066" target="_blank">pdf</a>]

<h2>RADIATE: A Radar Dataset for Automotive Perception. (arXiv:2010.09076v1 [cs.CV])</h2>
<h3>Marcel Sheeny, Emanuele De Pellegrin, Saptarshi Mukherjee, Alireza Ahrabian, Sen Wang, Andrew Wallace</h3>
<p>Datasets for autonomous cars are essential for the development and
benchmarking of perception systems. However, most existing datasets are
captured with camera and LiDAR sensors in good weather conditions. In this
paper, we present the RAdar Dataset In Adverse weaThEr (RADIATE), aiming to
facilitate research on object detection, tracking and scene understanding using
radar sensing for safe autonomous driving. RADIATE includes 3 hours of
annotated radar images with more than 200K labelled road actors in total, on
average about 4.6 instances per radar image. It covers 8 different categories
of actors in a variety of weather conditions (e.g., sun, night, rain, fog and
snow) and driving scenarios (e.g., parked, urban, motorway and suburban),
representing different levels of challenge. To the best of our knowledge, this
is the first public radar dataset which provides high-resolution radar images
on public roads with a large amount of road actors labelled. The data collected
in adverse weather, e.g., fog and snowfall, is unique. Some baseline results of
radar based object detection and recognition are given to show that the use of
radar data is promising for automotive applications in bad weather, where
vision and LiDAR can fail. RADIATE also has stereo images, 32-channel LiDAR and
GPS data, directed at other applications such as sensor fusion, localisation
and mapping. The public dataset can be accessed at
this http URL
</p>
<a href="http://arxiv.org/abs/2010.09076" target="_blank">arXiv:2010.09076</a> [<a href="http://arxiv.org/pdf/2010.09076" target="_blank">pdf</a>]

<h2>A Spatial-Temporal Graph Based Hybrid Infectious Disease Model with Application to COVID-19. (arXiv:2010.09077v1 [cs.LG])</h2>
<h3>Yunling Zheng, Zhijian Li, Jack Xin, Guofa Zhou</h3>
<p>As the COVID-19 pandemic evolves, reliable prediction plays an important role
for policy making. The classical infectious disease model SEIR
(susceptible-exposed-infectious-recovered) is a compact yet simplistic temporal
model. The data-driven machine learning models such as RNN (recurrent neural
networks) can suffer in case of limited time series data such as COVID-19. In
this paper, we combine SEIR and RNN on a graph structure to develop a hybrid
spatio-temporal model to achieve both accuracy and efficiency in training and
forecasting. We introduce two features on the graph structure: node feature
(local temporal infection trend) and edge feature (geographic neighbor effect).
For node feature, we derive a discrete recursion (called I-equation) from SEIR
so that gradient descend method applies readily to its optimization. For edge
feature, we design an RNN model to capture the neighboring effect and
regularize the landscape of loss function so that local minima are effective
and robust for prediction. The resulting hybrid model (called IeRNN) improves
the prediction accuracy on state-level COVID-19 new case data from the US,
out-performing standard temporal models (RNN, SEIR, and ARIMA) in 1-day and
7-day ahead forecasting. Our model accommodates various degrees of reopening
and provides potential outcomes for policymakers.
</p>
<a href="http://arxiv.org/abs/2010.09077" target="_blank">arXiv:2010.09077</a> [<a href="http://arxiv.org/pdf/2010.09077" target="_blank">pdf</a>]

<h2>Graphite: GRAPH-Induced feaTure Extraction for Point Cloud Registration. (arXiv:2010.09079v1 [cs.CV])</h2>
<h3>Mahdi Saleh, Shervin Dehghani, Benjamin Busam, Nassir Navab, Federico Tombari</h3>
<p>3D Point clouds are a rich source of information that enjoy growing
popularity in the vision community. However, due to the sparsity of their
representation, learning models based on large point clouds is still a
challenge. In this work, we introduce Graphite, a GRAPH-Induced feaTure
Extraction pipeline, a simple yet powerful feature transform and keypoint
detector. Graphite enables intensive down-sampling of point clouds with
keypoint detection accompanied by a descriptor. We construct a generic
graph-based learning scheme to describe point cloud regions and extract salient
points. To this end, we take advantage of 6D pose information and metric
learning to learn robust descriptions and keypoints across different scans. We
Reformulate the 3D keypoint pipeline with graph neural networks which allow
efficient processing of the point set while boosting its descriptive power
which ultimately results in more accurate 3D registrations. We demonstrate our
lightweight descriptor on common 3D descriptor matching and point cloud
registration benchmarks and achieve comparable results with the state of the
art. Describing 100 patches of a point cloud and detecting their keypoints
takes only ~0.018 seconds with our proposed network.
</p>
<a href="http://arxiv.org/abs/2010.09079" target="_blank">arXiv:2010.09079</a> [<a href="http://arxiv.org/pdf/2010.09079" target="_blank">pdf</a>]

<h2>Gait Recognition using Multi-Scale Partial Representation Transformation with Capsules. (arXiv:2010.09084v1 [cs.CV])</h2>
<h3>Alireza Sepas-Moghaddam, Saeed Ghorbani, Nikolaus F. Troje, Ali Etemad</h3>
<p>Gait recognition, referring to the identification of individuals based on the
manner in which they walk, can be very challenging due to the variations in the
viewpoint of the camera and the appearance of individuals. Current methods for
gait recognition have been dominated by deep learning models, notably those
based on partial feature representations. In this context, we propose a novel
deep network, learning to transfer multi-scale partial gait representations
using capsules to obtain more discriminative gait features. Our network first
obtains multi-scale partial representations using a state-of-the-art deep
partial feature extractor. It then recurrently learns the correlations and
co-occurrences of the patterns among the partial features in forward and
backward directions using Bi-directional Gated Recurrent Units (BGRU). Finally,
a capsule network is adopted to learn deeper part-whole relationships and
assigns more weights to the more relevant features while ignoring the spurious
dimensions. That way, we obtain final features that are more robust to both
viewing and appearance changes. The performance of our method has been
extensively tested on two gait recognition datasets, CASIA-B and OU-MVLP, using
four challenging test protocols. The results of our method have been compared
to the state-of-the-art gait recognition solutions, showing the superiority of
our model, notably when facing challenging viewing and carrying conditions.
</p>
<a href="http://arxiv.org/abs/2010.09084" target="_blank">arXiv:2010.09084</a> [<a href="http://arxiv.org/pdf/2010.09084" target="_blank">pdf</a>]

<h2>Wireless Control for Smart Manufacturing: Recent Approaches and Open Challenges. (arXiv:2010.09087v1 [eess.SY])</h2>
<h3>Dominik Baumann, Fabian Mager, Ulf Wetzker, Lothar Thiele, Marco Zimmerling, Sebastian Trimpe</h3>
<p>Smart manufacturing aims to overcome the limitations of today's rigid
assembly lines by making the material flow and manufacturing process more
flexible, versatile, and scalable. The main economic drivers are higher
resource and cost efficiency as the manufacturers can more quickly adapt to
changing market needs and also increase the lifespan of their production sites.
The ability to close feedback loops fast and reliably over long distances among
mobile robots, remote sensors, and human operators is a key enabler for smart
manufacturing. Thus, this article provides a perspective on control and
coordination over wireless networks. Based on an analysis of real-world use
cases, we identify the main technical challenges that need to be solved to
close the large gap between the current state of the art in industry and the
vision of smart manufacturing. We discuss to what extent existing
control-over-wireless solutions in the literature address those challenges,
including our own approach toward a tight integration of control and wireless
communication. In addition to a theoretical analysis of closed-loop stability,
practical experiments on a cyber-physical testbed demonstrate that our approach
supports relevant smart manufacturing scenarios. The article concludes with a
discussion of open challenges and future research directions.
</p>
<a href="http://arxiv.org/abs/2010.09087" target="_blank">arXiv:2010.09087</a> [<a href="http://arxiv.org/pdf/2010.09087" target="_blank">pdf</a>]

<h2>Training Stronger Baselines for Learning to Optimize. (arXiv:2010.09089v1 [cs.LG])</h2>
<h3>Tianlong Chen, Weiyi Zhang, Jingyang Zhou, Shiyu Chang, Sijia Liu, Lisa Amini, Zhangyang Wang</h3>
<p>Learning to optimize (L2O) has gained increasing attention since classical
optimizers require laborious problem-specific design and hyperparameter tuning.
However, there is a gap between the practical demand and the achievable
performance of existing L2O models. Specifically, those learned optimizers are
applicable to only a limited class of problems, and often exhibit instability.
With many efforts devoted to designing more sophisticated L2O models, we argue
for another orthogonal, under-explored theme: the training techniques for those
L2O models. We show that even the simplest L2O model could have been trained
much better. We first present a progressive training scheme to gradually
increase the optimizer unroll length, to mitigate a well-known L2O dilemma of
truncation bias (shorter unrolling) versus gradient explosion (longer
unrolling). We further leverage off-policy imitation learning to guide the L2O
learning, by taking reference to the behavior of analytical optimizers. Our
improved training techniques are plugged into a variety of state-of-the-art L2O
models, and immediately boost their performance, without making any change to
their model structures. Especially, by our proposed techniques, an earliest and
simplest L2O model can be trained to outperform the latest complicated L2O
models on a number of tasks. Our results demonstrate a greater potential of L2O
yet to be unleashed, and urge to rethink the recent progress. Our codes are
publicly available at: https://github.com/VITA-Group/L2O-Training-Techniques.
</p>
<a href="http://arxiv.org/abs/2010.09089" target="_blank">arXiv:2010.09089</a> [<a href="http://arxiv.org/pdf/2010.09089" target="_blank">pdf</a>]

<h2>View-Invariant Gait Recognition with Attentive Recurrent Learning of Partial Representations. (arXiv:2010.09092v1 [cs.CV])</h2>
<h3>Alireza Sepas-Moghaddam, Ali Etemad</h3>
<p>Gait recognition refers to the identification of individuals based on
features acquired from their body movement during walking. Despite the recent
advances in gait recognition with deep learning, variations in data acquisition
and appearance, namely camera angles, subject pose, occlusions, and clothing,
are challenging factors that need to be considered for achieving accurate gait
recognition systems. In this paper, we propose a network that first learns to
extract gait convolutional energy maps (GCEM) from frame-level convolutional
features. It then adopts a bidirectional recurrent neural network to learn from
split bins of the GCEM, thus exploiting the relations between learned partial
spatiotemporal representations. We then use an attention mechanism to
selectively focus on important recurrently learned partial representations as
identity information in different scenarios may lie in different GCEM bins. Our
proposed model has been extensively tested on two large-scale CASIA-B and
OU-MVLP gait datasets using four different test protocols and has been compared
to a number of state-of-the-art and baseline solutions. Additionally, a
comprehensive experiment has been performed to study the robustness of our
model in the presence of six different synthesized occlusions. The experimental
results show the superiority of our proposed method, outperforming the
state-of-the-art, especially in scenarios where different clothing and carrying
conditions are encountered. The results also revealed that our model is more
robust against different occlusions as compared to the state-of-the-art
methods.
</p>
<a href="http://arxiv.org/abs/2010.09092" target="_blank">arXiv:2010.09092</a> [<a href="http://arxiv.org/pdf/2010.09092" target="_blank">pdf</a>]

<h2>Multi-Agent Reinforcement Learning in NOMA-aided UAV Networks for Cellular Offloading. (arXiv:2010.09094v1 [cs.LG])</h2>
<h3>Ruikang Zhong, Xiao Liu, Yuanwei Liu, Yue Chen</h3>
<p>A novel framework is proposed for cellular offloading with the aid of
multiple unmanned aerial vehicles (UAVs), while the non-orthogonal multiple
access (NOMA) technique is employed at each UAV to further improve the spectrum
efficiency of the wireless network. The optimization problem of joint
three-dimensional (3D) trajectory design and power allocation is formulated for
maximizing the throughput. Since ground mobile users are considered as roaming
continuously, the UAVs need to be re-deployed timely based on the movement of
users. In an effort to solve this pertinent dynamic problem, a K-means based
clustering algorithm is first adopted for periodically partitioning users.
Afterward, a mutual deep Q-network (MDQN) algorithm is proposed to jointly
determine the optimal 3D trajectory and power allocation of UAVs. In contrast
to the conventional DQN algorithm, the MDQN algorithm enables the experience of
multi-agent to be input into a shared neural network to shorten the training
time with the assistance of state abstraction. Numerical results demonstrate
that: 1) the proposed MDQN algorithm is capable of converging under minor
constraints and has a faster convergence rate than the conventional DQN
algorithm in the multi-agent case; 2) The achievable sum rate of the NOMA
enhanced UAV network is 23% superior to the case of orthogonal multiple access
(OMA); 3) By designing the optimal 3D trajectory of UAVs with the aid of the
MDON algorithm, the sum rate of the network enjoys 142% and 56% gains than that
of invoking the circular trajectory and the 2D trajectory, respectively.
</p>
<a href="http://arxiv.org/abs/2010.09094" target="_blank">arXiv:2010.09094</a> [<a href="http://arxiv.org/pdf/2010.09094" target="_blank">pdf</a>]

<h2>Real-time Quadrotor Navigation Through Planning in Depth Space in Unstructured Environments. (arXiv:2010.09098v1 [cs.RO])</h2>
<h3>Shakeeb Ahmad, Rafael Fierro</h3>
<p>This paper addresses the problem of real-time vision-based autonomous
obstacle avoidance in unstructured environments for quadrotor UAVs. We assume
that our UAV is equipped with a forward facing stereo camera as the only sensor
to perceive the world around it. Moreover, all the computations are performed
onboard. Feasible trajectory generation in this kind of problems requires rapid
collision checks along with efficient planning algorithms. We propose a
trajectory generation approach in the depth image space, which refers to the
environment information as depicted by the depth images. In order to predict
the collision in a look ahead robot trajectory, we create depth images from the
sequence of robot poses along the path. We compare these images with the depth
images of the actual world sensed through the forward facing stereo camera. We
aim at generating fuel optimal trajectories inside the depth image space. In
case of a predicted collision, a switching strategy is used to aggressively
deviate the quadrotor away from the obstacle. For this purpose we use two
closed loop motion primitives based on Linear Quadratic Regulator (LQR)
objective functions. The proposed approach is validated through simulation and
hardware experiments.
</p>
<a href="http://arxiv.org/abs/2010.09098" target="_blank">arXiv:2010.09098</a> [<a href="http://arxiv.org/pdf/2010.09098" target="_blank">pdf</a>]

<h2>Variational Capsule Encoder. (arXiv:2010.09102v1 [cs.CV])</h2>
<h3>Harish RaviPrakash, Syed Muhammad Anwar, Ulas Bagci</h3>
<p>We propose a novel capsule network based variational encoder architecture,
called Bayesian capsules (B-Caps), to modulate the mean and standard deviation
of the sampling distribution in the latent space. We hypothesized that this
approach can learn a better representation of features in the latent space than
traditional approaches. Our hypothesis was tested by using the learned latent
variables for image reconstruction task, where for MNIST and Fashion-MNIST
datasets, different classes were separated successfully in the latent space
using our proposed model. Our experimental results have shown improved
reconstruction and classification performances for both datasets adding
credence to our hypothesis. We also showed that by increasing the latent space
dimension, the proposed B-Caps was able to learn a better representation when
compared to the traditional variational auto-encoders (VAE). Hence our results
indicate the strength of capsule networks in representation learning which has
never been examined under the VAE settings before.
</p>
<a href="http://arxiv.org/abs/2010.09102" target="_blank">arXiv:2010.09102</a> [<a href="http://arxiv.org/pdf/2010.09102" target="_blank">pdf</a>]

<h2>Unsupervised Foveal Vision Neural Networks with Top-Down Attention. (arXiv:2010.09103v1 [cs.LG])</h2>
<h3>Ryan Burt, Nina N. Thigpen, Andreas Keil, Jose C. Principe</h3>
<p>Deep learning architectures are an extremely powerful tool for recognizing
and classifying images. However, they require supervised learning and normally
work on vectors the size of image pixels and produce the best results when
trained on millions of object images. To help mitigate these issues, we propose
the fusion of bottom-up saliency and top-down attention employing only
unsupervised learning techniques, which helps the object recognition module to
focus on relevant data and learn important features that can later be
fine-tuned for a specific task. In addition, by utilizing only relevant
portions of the data, the training speed can be greatly improved. We test the
performance of the proposed Gamma saliency technique on the Toronto and CAT2000
databases, and the foveated vision in the Street View House Numbers (SVHN)
database. The results in foveated vision show that Gamma saliency is comparable
to the best and computationally faster. The results in SVHN show that our
unsupervised cognitive architecture is comparable to fully supervised methods
and that the Gamma saliency also improves CNN performance if desired. We also
develop a topdown attention mechanism based on the Gamma saliency applied to
the top layer of CNNs to improve scene understanding in multi-object images or
images with strong background clutter. When we compare the results with human
observers in an image dataset of animals occluded in natural scenes, we show
that topdown attention is capable of disambiguating object from background and
improves system performance beyond the level of human observers.
</p>
<a href="http://arxiv.org/abs/2010.09103" target="_blank">arXiv:2010.09103</a> [<a href="http://arxiv.org/pdf/2010.09103" target="_blank">pdf</a>]

<h2>Movement-induced Priors for Deep Stereo. (arXiv:2010.09105v1 [cs.CV])</h2>
<h3>Yuxin Hou, Muhammad Kamran Janjua, Juho Kannala, Arno Solin</h3>
<p>We propose a method for fusing stereo disparity estimation with
movement-induced prior information. Instead of independent inference
frame-by-frame, we formulate the problem as a non-parametric learning task in
terms of a temporal Gaussian process prior with a movement-driven kernel for
inter-frame reasoning. We present a hierarchy of three Gaussian process kernels
depending on the availability of motion information, where our main focus is on
a new gyroscope-driven kernel for handheld devices with low-quality MEMS
sensors, thus also relaxing the requirement of having full 6D camera poses
available. We show how our method can be combined with two state-of-the-art
deep stereo methods. The method either work in a plug-and-play fashion with
pre-trained deep stereo networks, or further improved by jointly training the
kernels together with encoder-decoder architectures, leading to consistent
improvement.
</p>
<a href="http://arxiv.org/abs/2010.09105" target="_blank">arXiv:2010.09105</a> [<a href="http://arxiv.org/pdf/2010.09105" target="_blank">pdf</a>]

<h2>Robust Learning under Strong Noise via SQs. (arXiv:2010.09106v1 [stat.ML])</h2>
<h3>Ioannis Anagnostides, Themis Gouleakis, Ali Marashian</h3>
<p>This work provides several new insights on the robustness of Kearns'
statistical query framework against challenging label-noise models. First, we
build on a recent result by \cite{DBLP:journals/corr/abs-2006-04787} that
showed noise tolerance of distribution-independently evolvable concept classes
under Massart noise. Specifically, we extend their characterization to more
general noise models, including the Tsybakov model which considerably
generalizes the Massart condition by allowing the flipping probability to be
arbitrarily close to $\frac{1}{2}$ for a subset of the domain. As a corollary,
we employ an evolutionary algorithm by \cite{DBLP:conf/colt/KanadeVV10} to
obtain the first polynomial time algorithm with arbitrarily small excess error
for learning linear threshold functions over any spherically symmetric
distribution in the presence of spherically symmetric Tsybakov noise. Moreover,
we posit access to a stronger oracle, in which for every labeled example we
additionally obtain its flipping probability. In this model, we show that every
SQ learnable class admits an efficient learning algorithm with OPT + $\epsilon$
misclassification error for a broad class of noise models. This setting
substantially generalizes the widely-studied problem of classification under
RCN with known noise rate, and corresponds to a non-convex optimization problem
even when the noise function -- i.e. the flipping probabilities of all points
-- is known in advance.
</p>
<a href="http://arxiv.org/abs/2010.09106" target="_blank">arXiv:2010.09106</a> [<a href="http://arxiv.org/pdf/2010.09106" target="_blank">pdf</a>]

<h2>Bridging the gap between Markowitz planning and deep reinforcement learning. (arXiv:2010.09108v1 [cs.LG])</h2>
<h3>Eric Benhamou, David Saltiel, Sandrine Ungari, Abhishek Mukhopadhyay</h3>
<p>While researchers in the asset management industry have mostly focused on
techniques based on financial and risk planning techniques like Markowitz
efficient frontier, minimum variance, maximum diversification or equal risk
parity, in parallel, another community in machine learning has started working
on reinforcement learning and more particularly deep reinforcement learning to
solve other decision making problems for challenging task like autonomous
driving, robot learning, and on a more conceptual side games solving like Go.
This paper aims to bridge the gap between these two approaches by showing Deep
Reinforcement Learning (DRL) techniques can shed new lights on portfolio
allocation thanks to a more general optimization setting that casts portfolio
allocation as an optimal control problem that is not just a one-step
optimization, but rather a continuous control optimization with a delayed
reward. The advantages are numerous: (i) DRL maps directly market conditions to
actions by design and hence should adapt to changing environment, (ii) DRL does
not rely on any traditional financial risk assumptions like that risk is
represented by variance, (iii) DRL can incorporate additional data and be a
multi inputs method as opposed to more traditional optimization methods. We
present on an experiment some encouraging results using convolution networks.
</p>
<a href="http://arxiv.org/abs/2010.09108" target="_blank">arXiv:2010.09108</a> [<a href="http://arxiv.org/pdf/2010.09108" target="_blank">pdf</a>]

<h2>Fair Division Under Cardinality Constraints. (arXiv:1804.09521v3 [cs.GT] UPDATED)</h2>
<h3>Siddharth Barman, Arpita Biswas</h3>
<p>We consider the problem of fairly allocating indivisible goods, among agents,
under cardinality constraints and additive valuations. In this setting, we are
given a partition of the entire set of goods---i.e., the goods are
categorized---and a limit is specified on the number of goods that can be
allocated from each category to any agent. The objective here is to find a fair
allocation in which the subset of goods assigned to any agent satisfies the
given cardinality constraints. This problem naturally captures a number of
resource-allocation applications, and is a generalization of the well-studied
(unconstrained) fair division problem.

The two central notions of fairness, in the context of fair division of
indivisible goods, are envy freeness up to one good (EF1) and the (approximate)
maximin share guarantee (MMS). We show that the existence and algorithmic
guarantees established for these solution concepts in the unconstrained setting
can essentially be achieved under cardinality constraints. Specifically, we
develop efficient algorithms which compute EF1 and approximately MMS
allocations in the constrained setting.

Furthermore, focusing on the case wherein all the agents have the same
additive valuation, we establish that EF1 allocations exist and can be computed
efficiently even under laminar matroid constraints.
</p>
<a href="http://arxiv.org/abs/1804.09521" target="_blank">arXiv:1804.09521</a> [<a href="http://arxiv.org/pdf/1804.09521" target="_blank">pdf</a>]

<h2>Deep Nets: What have they ever done for Vision?. (arXiv:1805.04025v3 [cs.CV] UPDATED)</h2>
<h3>Alan L. Yuille, Chenxi Liu</h3>
<p>This is an opinion paper about the strengths and weaknesses of Deep Nets for
vision. They are at the heart of the enormous recent progress in artificial
intelligence and are of growing importance in cognitive science and
neuroscience. They have had many successes but also have several limitations
and there is limited understanding of their inner workings. At present Deep
Nets perform very well on specific visual tasks with benchmark datasets but
they are much less general purpose, flexible, and adaptive than the human
visual system. We argue that Deep Nets in their current form are unlikely to be
able to overcome the fundamental problem of computer vision, namely how to deal
with the combinatorial explosion, caused by the enormous complexity of natural
images, and obtain the rich understanding of visual scenes that the human
visual achieves. We argue that this combinatorial explosion takes us into a
regime where "big data is not enough" and where we need to rethink our methods
for benchmarking performance and evaluating vision algorithms. We stress that,
as vision algorithms are increasingly used in real world applications, that
performance evaluation is not merely an academic exercise but has important
consequences in the real world. It is impractical to review the entire Deep Net
literature so we restrict ourselves to a limited range of topics and references
which are intended as entry points into the literature. The views expressed in
this paper are our own and do not necessarily represent those of anybody else
in the computer vision community.
</p>
<a href="http://arxiv.org/abs/1805.04025" target="_blank">arXiv:1805.04025</a> [<a href="http://arxiv.org/pdf/1805.04025" target="_blank">pdf</a>]

<h2>Autonomous Exploration, Reconstruction, and Surveillance of 3D Environments Aided by Deep Learning. (arXiv:1809.06025v3 [cs.LG] UPDATED)</h2>
<h3>Louis Ly, Yen-Hsi Richard Tsai</h3>
<p>We consider the exploration problem: an agent equipped with a depth sensor
must map out a previously unknown environment using as few sensor measurements
as possible. We propose an approach based on supervised learning of a greedy
algorithm. We provide a bound on the optimality of the greedy algorithm using
submodularity theory. Using a level set representation, we train a
convolutional neural network to determine vantage points that maximize
visibility. We show that this method drastically reduces the on-line
computational cost and determines a small set of vantage points that solve the
problem. This enables us to efficiently produce highly-resolved and
topologically accurate maps of complex 3D environments. Unlike traditional
next-best-view and frontier-based strategies, the proposed method accounts for
geometric priors while evaluating potential vantage points. While existing deep
learning approaches focus on obstacle avoidance and local navigation, our
method aims at finding near-optimal solutions to the more global exploration
problem. We present realistic simulations on 2D and 3D urban environments.
</p>
<a href="http://arxiv.org/abs/1809.06025" target="_blank">arXiv:1809.06025</a> [<a href="http://arxiv.org/pdf/1809.06025" target="_blank">pdf</a>]

<h2>Deep Learning Methods for Reynolds-Averaged Navier-Stokes Simulations of Airfoil Flows. (arXiv:1810.08217v3 [cs.LG] UPDATED)</h2>
<h3>Nils Thuerey, Konstantin Weissenow, Lukas Prantl, Xiangyu Hu</h3>
<p>With this study we investigate the accuracy of deep learning models for the
inference of Reynolds-Averaged Navier-Stokes solutions. We focus on a
modernized U-net architecture, and evaluate a large number of trained neural
networks with respect to their accuracy for the calculation of pressure and
velocity distributions. In particular, we illustrate how training data size and
the number of weights influence the accuracy of the solutions. With our best
models we arrive at a mean relative pressure and velocity error of less than 3%
across a range of previously unseen airfoil shapes. In addition all source code
is publicly available in order to ensure reproducibility and to provide a
starting point for researchers interested in deep learning methods for physics
problems. While this work focuses on RANS solutions, the neural network
architecture and learning setup are very generic, and applicable to a wide
range of PDE boundary value problems on Cartesian grids.
</p>
<a href="http://arxiv.org/abs/1810.08217" target="_blank">arXiv:1810.08217</a> [<a href="http://arxiv.org/pdf/1810.08217" target="_blank">pdf</a>]

<h2>Boundary loss for highly unbalanced segmentation. (arXiv:1812.07032v4 [eess.IV] UPDATED)</h2>
<h3>Hoel Kervadec, Jihene Bouchtiba, Christian Desrosiers, Eric Granger, Jose Dolz, Ismail Ben Ayed</h3>
<p>Widely used loss functions for CNN segmentation, e.g., Dice or cross-entropy,
are based on integrals over the segmentation regions. Unfortunately, for highly
unbalanced segmentations, such regional summations have values that differ by
several orders of magnitude across classes, which affects training performance
and stability. We propose a boundary loss, which takes the form of a distance
metric on the space of contours, not regions. This can mitigate the
difficulties of highly unbalanced problems because it uses integrals over the
interface between regions instead of unbalanced integrals over the regions.
Furthermore, a boundary loss complements regional information. Inspired by
graph-based optimization techniques for computing active-contour flows, we
express a non-symmetric $L_2$ distance on the space of contours as a regional
integral, which avoids completely local differential computations involving
contour points. This yields a boundary loss expressed with the regional softmax
probability outputs of the network, which can be easily combined with standard
regional losses and implemented with any existing deep network architecture for
N-D segmentation. We report comprehensive evaluations and comparisons on
different unbalanced problems, showing that our boundary loss can yield
significant increases in performances while improving training stability. Our
code is publicly available: https://github.com/LIVIAETS/surface-loss .
</p>
<a href="http://arxiv.org/abs/1812.07032" target="_blank">arXiv:1812.07032</a> [<a href="http://arxiv.org/pdf/1812.07032" target="_blank">pdf</a>]

<h2>JECL: Joint Embedding and Cluster Learning for Image-Text Pairs. (arXiv:1901.01860v3 [cs.LG] UPDATED)</h2>
<h3>Sean T. Yang, Kuan-Hao Huang, Bill Howe</h3>
<p>We propose JECL, a method for clustering image-caption pairs by training
parallel encoders with regularized clustering and alignment objectives,
simultaneously learning both representations and cluster assignments. These
image-caption pairs arise frequently in high-value applications where
structured training data is expensive to produce, but free-text descriptions
are common. JECL trains by minimizing the Kullback-Leibler divergence between
the distribution of the images and text to that of a combined joint target
distribution and optimizing the Jensen-Shannon divergence between the soft
cluster assignments of the images and text. Regularizers are also applied to
JECL to prevent trivial solutions. Experiments show that JECL outperforms both
single-view and multi-view methods on large benchmark image-caption datasets,
and is remarkably robust to missing captions and varying data sizes.
</p>
<a href="http://arxiv.org/abs/1901.01860" target="_blank">arXiv:1901.01860</a> [<a href="http://arxiv.org/pdf/1901.01860" target="_blank">pdf</a>]

<h2>A Model-Driven Stack-Based Fully Convolutional Network for Pancreas Segmentation. (arXiv:1903.00832v3 [cs.CV] UPDATED)</h2>
<h3>Hao Li, Jun Li, Xiaozhu Lin, Xiaohua Qian</h3>
<p>The irregular geometry and high inter-slice variability in computerized
tomography (CT) scans of the human pancreas make an accurate segmentation of
this crucial organ a challenging task for existing data-driven deep learning
methods. To address this problem, we present a novel model-driven stack-based
fully convolutional network with a sliding window fusion algorithm for pancreas
segmentation, termed MDS-Net. The MDS-Net's cost function includes a data
approximation term and a prior knowledge regularization term combined with a
stack scheme for capturing and fusing the two-dimensional (2D) and local
three-dimensional (3D) context information. Specifically, 3D CT scans are
divided into multiple stacks to capture the local spatial context feature. To
highlight the importance of single slices, the inter-slice relationships in the
stack data are also incorporated in the MDS-Net framework. For implementing
this proposed model-driven method, we create a stack-based U-Net architecture
and successfully derive its back-propagation procedure for end-to-end training.
Furthermore, a sliding window fusion algorithm is utilized to improve the
consistency of adjacent CT slices and intra-stack. Finally, extensive
quantitative assessments on the NIH Pancreas-CT dataset demonstrated higher
pancreatic segmentation accuracy and reliability of MDS-Net compared to other
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/1903.00832" target="_blank">arXiv:1903.00832</a> [<a href="http://arxiv.org/pdf/1903.00832" target="_blank">pdf</a>]

<h2>Weisfeiler and Leman go sparse: Towards scalable higher-order graph embeddings. (arXiv:1904.01543v3 [cs.DS] UPDATED)</h2>
<h3>Christopher Morris, Gaurav Rattan, Petra Mutzel</h3>
<p>Graph kernels based on the $1$-dimensional Weisfeiler-Leman algorithm and
corresponding neural architectures recently emerged as powerful tools for
(supervised) learning with graphs. However, due to the purely local nature of
the algorithms, they might miss essential patterns in the given data and can
only handle binary relations. The $k$-dimensional Weisfeiler-Leman algorithm
addresses this by considering $k$-tuples, defined over the set of vertices, and
defines a suitable notion of adjacency between these vertex tuples. Hence, it
accounts for the higher-order interactions between vertices. However, it does
not scale and may suffer from overfitting when used in a machine learning
setting. Hence, it remains an important open problem to design WL-based graph
learning methods that are simultaneously expressive, scalable, and
non-overfitting. Here, we propose local variants and corresponding neural
architectures, which consider a subset of the original neighborhood, making
them more scalable, and less prone to overfitting. The expressive power of (one
of) our algorithms is strictly higher than the original algorithm, in terms of
ability to distinguish non-isomorphic graphs. Our experimental study confirms
that the local algorithms, both kernel and neural architectures, lead to vastly
reduced computation times, and prevent overfitting. The kernel version
establishes a new state-of-the-art for graph classification on a wide range of
benchmark datasets, while the neural version shows promising performance on
large-scale molecular regression tasks.
</p>
<a href="http://arxiv.org/abs/1904.01543" target="_blank">arXiv:1904.01543</a> [<a href="http://arxiv.org/pdf/1904.01543" target="_blank">pdf</a>]

<h2>Deep Residual Autoencoders for Expectation Maximization-inspired Dictionary Learning. (arXiv:1904.08827v3 [cs.LG] UPDATED)</h2>
<h3>Bahareh Tolooshams, Sourav Dey, Demba Ba</h3>
<p>We introduce a neural-network architecture, termed the constrained recurrent
sparse autoencoder (CRsAE), that solves convolutional dictionary learning
problems, thus establishing a link between dictionary learning and neural
networks. Specifically, we leverage the interpretation of the
alternating-minimization algorithm for dictionary learning as an approximate
Expectation-Maximization algorithm to develop autoencoders that enable the
simultaneous training of the dictionary and regularization parameter (ReLU
bias). The forward pass of the encoder approximates the sufficient statistics
of the E-step as the solution to a sparse coding problem, using an iterative
proximal gradient algorithm called FISTA. The encoder can be interpreted either
as a recurrent neural network or as a deep residual network, with two-sided
ReLU non-linearities in both cases. The M-step is implemented via a two-stage
back-propagation. The first stage relies on a linear decoder applied to the
encoder and a norm-squared loss. It parallels the dictionary update step in
dictionary learning. The second stage updates the regularization parameter by
applying a loss function to the encoder that includes a prior on the parameter
motivated by Bayesian statistics. We demonstrate in an image-denoising task
that CRsAE learns Gabor-like filters, and that the EM-inspired approach for
learning biases is superior to the conventional approach. In an application to
recordings of electrical activity from the brain, we demonstrate that CRsAE
learns realistic spike templates and speeds up the process of identifying spike
times by 900x compared to algorithms based on convex optimization.
</p>
<a href="http://arxiv.org/abs/1904.08827" target="_blank">arXiv:1904.08827</a> [<a href="http://arxiv.org/pdf/1904.08827" target="_blank">pdf</a>]

<h2>Adversarial Balancing-based Representation Learning for Causal Effect Inference with Observational Data. (arXiv:1904.13335v3 [cs.LG] UPDATED)</h2>
<h3>Xin Du, Lei Sun, Wouter Duivesteijn, Alexander Nikolaev, Mykola Pechenizkiy</h3>
<p>Learning causal effects from observational data greatly benefits a variety of
domains such as health care, education and sociology. For instance, one could
estimate the impact of a new drug on specific individuals to assist the clinic
plan and improve the survival rate. In this paper, we focus on studying the
problem of estimating Conditional Average Treatment Effect (CATE) from
observational data. The challenges for this problem are two-fold: on the one
hand, we have to derive a causal estimator to estimate the causal quantity from
observational data, where there exists confounding bias; on the other hand, we
have to deal with the identification of CATE when the distribution of
covariates in treatment and control groups are imbalanced. To overcome these
challenges, we propose a neural network framework called Adversarial
Balancing-based representation learning for Causal Effect Inference (ABCEI),
based on the recent advances in representation learning. To ensure the
identification of CATE, ABCEI uses adversarial learning to balance the
distributions of covariates in treatment and control groups in the latent
representation space, without any assumption on the form of the treatment
selection/assignment function. In addition, during the representation learning
and balancing process, highly predictive information from the original
covariate space might be lost. ABCEI can tackle this information loss problem
by preserving useful information for predicting causal effects under the
regularization of a mutual information estimator. The experimental results show
that ABCEI is robust against treatment selection bias, and matches/outperforms
the state-of-the-art approaches. Our experiments show promising results on
several datasets, representing different health care domains among others.
</p>
<a href="http://arxiv.org/abs/1904.13335" target="_blank">arXiv:1904.13335</a> [<a href="http://arxiv.org/pdf/1904.13335" target="_blank">pdf</a>]

<h2>Lesion Segmentation in Ultrasound Using Semi-pixel-wise Cycle Generative Adversarial Nets. (arXiv:1905.01902v4 [cs.CV] UPDATED)</h2>
<h3>Jie Xing, Zheren Li, Biyuan Wang, Yuji Qi, Bingbin Yu, Farhad G. Zanjani, Aiwen Zheng, Remco Duits, Tao Tan</h3>
<p>Breast cancer is the most common invasive cancer with the highest cancer
occurrence in females. Handheld ultrasound is one of the most efficient ways to
identify and diagnose the breast cancer. The area and the shape information of
a lesion is very helpful for clinicians to make diagnostic decisions. In this
study we propose a new deep-learning scheme, semi-pixel-wise cycle generative
adversarial net (SPCGAN) for segmenting the lesion in 2D ultrasound. The method
takes the advantage of a fully convolutional neural network (FCN) and a
generative adversarial net to segment a lesion by using prior knowledge. We
compared the proposed method to a fully connected neural network and the level
set segmentation method on a test dataset consisting of 32 malignant lesions
and 109 benign lesions. Our proposed method achieved a Dice similarity
coefficient (DSC) of 0.92 while FCN and the level set achieved 0.90 and 0.79
respectively. Particularly, for malignant lesions, our method increases the DSC
(0.90) of the fully connected neural network to 0.93 significantly (p$&lt;$0.001).
The results show that our SPCGAN can obtain robust segmentation results. The
framework of SPCGAN is particularly effective when sufficient training samples
are not available compared to FCN. Our proposed method may be used to relieve
the radiologists' burden for annotation.
</p>
<a href="http://arxiv.org/abs/1905.01902" target="_blank">arXiv:1905.01902</a> [<a href="http://arxiv.org/pdf/1905.01902" target="_blank">pdf</a>]

<h2>Empirical Likelihood for Contextual Bandits. (arXiv:1906.03323v4 [cs.LG] UPDATED)</h2>
<h3>Nikos Karampatziakis, John Langford, Paul Mineiro</h3>
<p>We propose an estimator and confidence interval for computing the value of a
policy from off-policy data in the contextual bandit setting. To this end we
apply empirical likelihood techniques to formulate our estimator and confidence
interval as simple convex optimization problems. Using the lower bound of our
confidence interval, we then propose an off-policy policy optimization
algorithm that searches for policies with large reward lower bound. We
empirically find that both our estimator and confidence interval improve over
previous proposals in finite sample regimes. Finally, the policy optimization
algorithm we propose outperforms a strong baseline system for learning from
off-policy data.
</p>
<a href="http://arxiv.org/abs/1906.03323" target="_blank">arXiv:1906.03323</a> [<a href="http://arxiv.org/pdf/1906.03323" target="_blank">pdf</a>]

<h2>Value Functions for Depth-Limited Solving in Imperfect-Information Games. (arXiv:1906.06412v3 [cs.AI] UPDATED)</h2>
<h3>Vojt&#x11b;ch Kova&#x159;&#xed;k, Dominik Seitz, Viliam Lis&#xfd;, Jan Rudolf, Shuo Sun, Karel Ha</h3>
<p>We provide a formal definition of depth-limited games together with an
accessible and rigorous explanation of the underlying concepts, both of which
were previously missing in imperfect-information games. The definition works
for an arbitrary extensive-form game and is not tied to any specific
game-solving algorithm. Moreover, this framework unifies and significantly
extends three approaches to depth-limited solving that previously existed in
extensive-form games and multiagent reinforcement learning but were not known
to be compatible. A key ingredient of these depth-limited games are value
functions. Focusing on two-player zero-sum imperfect-information games, we show
how to obtain optimal value functions and prove that public information
provides both necessary and sufficient context for computing them. We provide a
domain-independent encoding of the domain which allows for approximating value
functions even by simple feed-forward neural networks. We use the resulting
value network to implement a depth-limited version of counterfactual regret
minimization. In three distinct domains, we show that the algorithm produces a
low-exploitability strategy if and only if it is paired with a near-optimal
value network. We show that the value network is capable of generalizing to
unseen game situations and that the resulting algorithm performs on par with
CFR-D despite being trained on randomly-generated game situations.
</p>
<a href="http://arxiv.org/abs/1906.06412" target="_blank">arXiv:1906.06412</a> [<a href="http://arxiv.org/pdf/1906.06412" target="_blank">pdf</a>]

<h2>Motion Sensor-based Privacy Attack on Smartphones. (arXiv:1907.05972v3 [cs.CR] UPDATED)</h2>
<h3>S Abhishek Anand, Chen Wang, Jian Liu, Nitesh Saxena, Yingying Chen</h3>
<p>In this paper, we build a speech privacy attack that exploits speech
reverberations generated from a smartphone's in-built loudspeaker captured via
a zero-permission motion sensor (accelerometer). We design our attack
Spearphone2, and demonstrate that speech reverberations from inbuilt
loudspeakers, at an appropriate loudness, can impact the accelerometer, leaking
sensitive information about the speech. In particular, we show that by
exploiting the affected accelerometer readings and carefully selecting feature
sets along with off-the-shelf machine learning techniques, Spearphone can
successfully perform gender classification (accuracy over 90%) and speaker
identification (accuracy over 80%) for any audio/video playback on the
smartphone. Our results with testing the attack on a voice call and voice
assistant response were also encouraging, showcasing the impact of the proposed
attack. In addition, we perform speech recognition and speech reconstruction to
extract more information about the eavesdropped speech to an extent. Our work
brings to light a fundamental design vulnerability in many currently-deployed
smartphones, which may put people's speech privacy at risk while using the
smartphone in the loudspeaker mode during phone calls, media playback or voice
assistant interactions.
</p>
<a href="http://arxiv.org/abs/1907.05972" target="_blank">arXiv:1907.05972</a> [<a href="http://arxiv.org/pdf/1907.05972" target="_blank">pdf</a>]

<h2>DeepNC: Deep Generative Network Completion. (arXiv:1907.07381v4 [cs.SI] UPDATED)</h2>
<h3>Cong Tran, Won-Yong Shin, Andreas Spitz, Michael Gertz</h3>
<p>Most network data are collected from partially observable networks with both
missing nodes and missing edges, for example, due to limited resources and
privacy settings specified by users on social media. Thus, it stands to reason
that inferring the missing parts of the networks by performing network
completion should precede downstream applications. However, despite this need,
the recovery of missing nodes and edges in such incomplete networks is an
insufficiently explored problem due to the modeling difficulty, which is much
more challenging than link prediction that only infers missing edges. In this
paper, we present DeepNC, a novel method for inferring the missing parts of a
network based on a deep generative model of graphs. Specifically, our method
first learns a likelihood over edges via an autoregressive generative model,
and then identifies the graph that maximizes the learned likelihood conditioned
on the observable graph topology. Moreover, we propose a computationally
efficient DeepNC algorithm that consecutively finds individual nodes that
maximize the probability in each node generation step, as well as an enhanced
version using the expectation-maximization algorithm. The runtime complexities
of both algorithms are shown to be almost linear in the number of nodes in the
network. We empirically demonstrate the superiority of DeepNC over
state-of-the-art network completion approaches.
</p>
<a href="http://arxiv.org/abs/1907.07381" target="_blank">arXiv:1907.07381</a> [<a href="http://arxiv.org/pdf/1907.07381" target="_blank">pdf</a>]

<h2>Evolutionary Algorithms and Efficient Data Analytics for Image Processing. (arXiv:1907.12914v3 [cs.CV] UPDATED)</h2>
<h3>Farid Ghareh Mohammadi, Farzan Shenavarmasouleh, M. Hadi Amini, Hamid R. Arabnia</h3>
<p>Steganography algorithms facilitate communication between a source and a
destination in a secret manner. This is done by embedding messages/text/data
into images without impacting the appearance of the resultant images/videos.
Steganalysis is the science of determining if an image has secret messages
embedded/hidden in it. Because there are numerous steganography algorithms, and
since each one of them requires a different type of steganalysis, the
steganalysis process is extremely challenging. Thus, researchers aim to develop
one universal steganalysis to detect all known and unknown steganography
algorithms, ideally in real-time. Universal steganalysis extracts a large
number of features to distinguish stego images from cover images. However, the
increase in features leads to the problem of the curse of dimensionality (CoD),
which is considered to be an NP-hard problem. This COD problem additionally
makes real-time steganalysis hard. A large number of features generates large
datasets for which machine learning cannot generate an optimal model.
Generating a machine learning based model also takes a long time which makes
real-time processing appear impossible in any optimization for time-intensive
fields such as visual computing. Possible solutions for CoD are deep learning
and evolutionary algorithms that overcome the machine learning limitations. In
this study, we investigate previously developed evolutionary algorithms for
boosting real-time image processing and argue that they provide the most
promising solutions for the CoD problem.
</p>
<a href="http://arxiv.org/abs/1907.12914" target="_blank">arXiv:1907.12914</a> [<a href="http://arxiv.org/pdf/1907.12914" target="_blank">pdf</a>]

<h2>Unsupervised Recalibration. (arXiv:1908.09157v3 [stat.ML] UPDATED)</h2>
<h3>Albert Ziegler, Pawe&#x142; Czy&#x17c;</h3>
<p>Unsupervised recalibration (URC) is a general way to improve the accuracy of
an already trained probabilistic classification or regression model upon
encountering new data while deployed in the field. URC does not require any
ground truth associated with the new field data. URC merely observes the
model's predictions and recognizes when the training set is not representative
of field data, and then corrects to remove any introduced bias.

URC can be particularly useful when applied separately to different
subpopulations observed in the field that were not considered as features when
training the machine learning model. This makes it possible to exploit
subpopulation information without retraining the model or even having ground
truth for some or all subpopulations available.

Additionally, if these subpopulations are the object of study, URC serves to
determine the correct ground truth distributions for them, where naive
aggregation methods, like averaging the model's predictions, systematically
underestimate their differences.
</p>
<a href="http://arxiv.org/abs/1908.09157" target="_blank">arXiv:1908.09157</a> [<a href="http://arxiv.org/pdf/1908.09157" target="_blank">pdf</a>]

<h2>Self-paced Ensemble for Highly Imbalanced Massive Data Classification. (arXiv:1909.03500v3 [cs.LG] UPDATED)</h2>
<h3>Zhining Liu, Wei Cao, Zhifeng Gao, Jiang Bian, Hechang Chen, Yi Chang, Tie-Yan Liu</h3>
<p>Many real-world applications reveal difficulties in learning classifiers from
imbalanced data. The rising big data era has been witnessing more
classification tasks with large-scale but extremely imbalance and low-quality
datasets. Most of existing learning methods suffer from poor performance or low
computation efficiency under such a scenario. To tackle this problem, we
conduct deep investigations into the nature of class imbalance, which reveals
that not only the disproportion between classes, but also other difficulties
embedded in the nature of data, especially, noises and class overlapping,
prevent us from learning effective classifiers. Taking those factors into
consideration, we propose a novel framework for imbalance classification that
aims to generate a strong ensemble by self-paced harmonizing data hardness via
under-sampling. Extensive experiments have shown that this new framework, while
being very computationally efficient, can lead to robust performance even under
highly overlapping classes and extremely skewed distribution. Note that, our
methods can be easily adapted to most of existing learning methods (e.g., C4.5,
SVM, GBDT and Neural Network) to boost their performance on imbalanced data.
</p>
<a href="http://arxiv.org/abs/1909.03500" target="_blank">arXiv:1909.03500</a> [<a href="http://arxiv.org/pdf/1909.03500" target="_blank">pdf</a>]

<h2>BAFFLE : Blockchain Based Aggregator Free Federated Learning. (arXiv:1909.07452v3 [cs.LG] UPDATED)</h2>
<h3>Paritosh Ramanan, Kiyoshi Nakayama</h3>
<p>A key aspect of Federated Learning (FL) is the requirement of a centralized
aggregator to maintain and update the global model. However, in many cases
orchestrating a centralized aggregator might be infeasible due to numerous
operational constraints. In this paper, we introduce BAFFLE, an aggregator
free, blockchain driven, FL environment that is inherently decentralized.
BAFFLE leverages Smart Contracts (SC) to coordinate the round delineation,
model aggregation and update tasks in FL. BAFFLE boosts computational
performance by decomposing the global parameter space into distinct chunks
followed by a score and bid strategy. In order to characterize the performance
of BAFFLE, we conduct experiments on a private Ethereum network and use the
centralized and aggregator driven methods as our benchmark. We show that BAFFLE
significantly reduces the gas costs for FL on the blockchain as compared to a
direct adaptation of the aggregator based method. Our results also show that
BAFFLE achieves high scalability and computational efficiency while delivering
similar accuracy as the benchmark methods.
</p>
<a href="http://arxiv.org/abs/1909.07452" target="_blank">arXiv:1909.07452</a> [<a href="http://arxiv.org/pdf/1909.07452" target="_blank">pdf</a>]

<h2>Gamma-Nets: Generalizing Value Estimation over Timescale. (arXiv:1911.07794v5 [cs.LG] UPDATED)</h2>
<h3>Craig Sherstan, Shibhansh Dohare, James MacGlashan, Johannes G&#xfc;nther, Patrick M. Pilarski</h3>
<p>We present $\Gamma$-nets, a method for generalizing value function estimation
over timescale. By using the timescale as one of the estimator's inputs we can
estimate value for arbitrary timescales. As a result, the prediction target for
any timescale is available and we are free to train on multiple timescales at
each timestep. Here we empirically evaluate $\Gamma$-nets in the policy
evaluation setting. We first demonstrate the approach on a square wave and then
on a robot arm using linear function approximation. Next, we consider the deep
reinforcement learning setting using several Atari video games. Our results
show that $\Gamma$-nets can be effective for predicting arbitrary timescales,
with only a small cost in accuracy as compared to learning estimators for fixed
timescales. $\Gamma$-nets provide a method for compactly making predictions at
many timescales without requiring a priori knowledge of the task, making it a
valuable contribution to ongoing work on model-based planning, representation
learning, and lifelong learning algorithms.
</p>
<a href="http://arxiv.org/abs/1911.07794" target="_blank">arXiv:1911.07794</a> [<a href="http://arxiv.org/pdf/1911.07794" target="_blank">pdf</a>]

<h2>Multi-Modal Deep Clustering: Unsupervised Partitioning of Images. (arXiv:1912.02678v2 [cs.CV] UPDATED)</h2>
<h3>Guy Shiran, Daphna Weinshall</h3>
<p>The clustering of unlabeled raw images is a daunting task, which has recently
been approached with some success by deep learning methods. Here we propose an
unsupervised clustering framework, which learns a deep neural network in an
end-to-end fashion, providing direct cluster assignments of images without
additional processing. Multi-Modal Deep Clustering (MMDC), trains a deep
network to align its image embeddings with target points sampled from a
Gaussian Mixture Model distribution. The cluster assignments are then
determined by mixture component association of image embeddings.
Simultaneously, the same deep network is trained to solve an additional
self-supervised task of predicting image rotations. This pushes the network to
learn more meaningful image representations that facilitate a better
clustering. Experimental results show that MMDC achieves or exceeds
state-of-the-art performance on six challenging benchmarks. On natural image
datasets we improve on previous results with significant margins of up to 20%
absolute accuracy points, yielding an accuracy of 82% on CIFAR-10, 45% on
CIFAR-100 and 69% on STL-10.
</p>
<a href="http://arxiv.org/abs/1912.02678" target="_blank">arXiv:1912.02678</a> [<a href="http://arxiv.org/pdf/1912.02678" target="_blank">pdf</a>]

<h2>Solving Bayesian Inverse Problems via Variational Autoencoders. (arXiv:1912.04212v4 [stat.ML] UPDATED)</h2>
<h3>Hwan Goh, Sheroze Sheriffdeen, Jonathan Wittmer, Tan Bui-Thanh</h3>
<p>In recent years, the field of machine learning has made phenomenal progress
in the pursuit of simulating real-world data generation processes. One notable
example of such success is the variational autoencoder (VAE). In this work,
with a small shift in perspective, we leverage and adapt VAEs for a different
purpose: uncertainty quantification in scientific inverse problems. We
introduce UQ-VAE: a flexible, adaptive, hybrid data/model-informed framework
for training neural networks capable of rapid modelling of the posterior
distribution representing the unknown parameter of interest. Specifically, from
divergence-based variational inference, our framework is derived such that all
the information usually present in scientific inverse problems is fully
utilized in the training procedure. Additionally, this framework includes an
adjustable hyperparameter that allows selection of the notion of distance
between the posterior model and the target distribution. This introduces more
flexibility in controlling how optimization directs the learning of the
posterior model. Further, this framework possesses an inherent adaptive
optimization property that emerges through the learning of the posterior
uncertainty.
</p>
<a href="http://arxiv.org/abs/1912.04212" target="_blank">arXiv:1912.04212</a> [<a href="http://arxiv.org/pdf/1912.04212" target="_blank">pdf</a>]

<h2>CLOSURE: Assessing Systematic Generalization of CLEVR Models. (arXiv:1912.05783v2 [cs.AI] UPDATED)</h2>
<h3>Dzmitry Bahdanau, Harm de Vries, Timothy J. O&#x27;Donnell, Shikhar Murty, Philippe Beaudoin, Yoshua Bengio, Aaron Courville</h3>
<p>The CLEVR dataset of natural-looking questions about 3D-rendered scenes has
recently received much attention from the research community. A number of
models have been proposed for this task, many of which achieved very high
accuracies of around 97-99%. In this work, we study how systematic the
generalization of such models is, that is to which extent they are capable of
handling novel combinations of known linguistic constructs. To this end, we
test models' understanding of referring expressions based on matching object
properties (such as e.g. "another cube that is the same size as the brown
cube") in novel contexts. Our experiments on the thereby constructed CLOSURE
benchmark show that state-of-the-art models often do not exhibit systematicity
after being trained on CLEVR. Surprisingly, we find that an explicitly
compositional Neural Module Network model also generalizes badly on CLOSURE,
even when it has access to the ground-truth programs at test time. We improve
the NMN's systematic generalization by developing a novel Vector-NMN module
architecture with vector-valued inputs and outputs. Lastly, we investigate how
much few-shot transfer learning can help models that are pretrained on CLEVR to
adapt to CLOSURE. Our few-shot learning experiments contrast the adaptation
behavior of the models with intermediate discrete programs with that of the
end-to-end continuous models.
</p>
<a href="http://arxiv.org/abs/1912.05783" target="_blank">arXiv:1912.05783</a> [<a href="http://arxiv.org/pdf/1912.05783" target="_blank">pdf</a>]

<h2>A Comprehensive Analysis of Weakly-Supervised Semantic Segmentation in Different Image Domains. (arXiv:1912.11186v3 [cs.CV] UPDATED)</h2>
<h3>Lyndon Chan, Mahdi S. Hosseini, Konstantinos N. Plataniotis</h3>
<p>Recently proposed methods for weakly-supervised semantic segmentation have
achieved impressive performance in predicting pixel classes despite being
trained with only image labels which lack positional information. Because image
annotations are cheaper and quicker to generate, weak supervision is more
practical than full supervision for training segmentation algorithms. These
methods have been predominantly developed to solve the background separation
and partial segmentation problems presented by natural scene images and it is
unclear whether they can be simply transferred to other domains with different
characteristics, such as histopathology and satellite images, and still perform
well. This paper evaluates state-of-the-art weakly-supervised semantic
segmentation methods on natural scene, histopathology, and satellite image
datasets and analyzes how to determine which method is most suitable for a
given dataset. Our experiments indicate that histopathology and satellite
images present a different set of problems for weakly-supervised semantic
segmentation than natural scene images, such as ambiguous boundaries and class
co-occurrence. Methods perform well for datasets they were developed on, but
tend to perform poorly on other datasets. We present some practical techniques
for these methods on unseen datasets and argue that more work is needed for a
generalizable approach to weakly-supervised semantic segmentation. Our full
code implementation is available on GitHub:
https://github.com/lyndonchan/wsss-analysis.
</p>
<a href="http://arxiv.org/abs/1912.11186" target="_blank">arXiv:1912.11186</a> [<a href="http://arxiv.org/pdf/1912.11186" target="_blank">pdf</a>]

<h2>Visual-Semantic-Pose Graph Mixture Networks for Human-Object Interaction Detection. (arXiv:2001.02302v5 [cs.LG] UPDATED)</h2>
<h3>Zhijun Liang, Juan Rojas, Junfa Liu, Yisheng Guan</h3>
<p>Human-Object Interaction (HOI) Detection infers the action predicate on a
&lt;subject, predicate, object&gt; triplet. Whilst contextual information has been
found critical in this task, even with the advent of deep learning, researchers
still grapple to understand how to best leverage contextual cues for inference.
What is the best way to integrate visual, spatial, semantic, and pose
information? Many works have used a subset of cues or limited their analysis to
single subject-object pair for inference. Few works have studied the
disambiguating contribution of subsidiary relations made available via graph
networks. In this work, we contribute a two-stream (multi-branched) network
that effectively aggregates a series of contextual cues. In a first study, we
propose a dual graph attention network to dynamically aggregate the visual,
instance spatial, and semantic cues from primary subject-object relations as
well as subsidiary ones to enhance inference. Subsequently, we incorporate
human pose features and propose a second network stream that runs a pose-based
modular network. The latter is composed of dual branches that run a graph
convolutional network and multi-layer perceptrons to improve detection in
crowded scenes. The result is a graph mixture network that processes a wide set
of contextual cues effectively. We call our model: Visual-Semantic-Pose Graph
Mixture Networks (VSP-GMNs). Our final model outperforms state-of-the-art on
the challenging HICO-DET dataset by significant margins of almost 10%,
especially in long-tail cases that are harder to interpret. We also achieve a
competitive performance on the smaller V-COCO dataset. Code, video, and
supplementary material information are available at www.juanrojas.net/VSPGMN.
</p>
<a href="http://arxiv.org/abs/2001.02302" target="_blank">arXiv:2001.02302</a> [<a href="http://arxiv.org/pdf/2001.02302" target="_blank">pdf</a>]

<h2>Concept Whitening for Interpretable Image Recognition. (arXiv:2002.01650v4 [cs.LG] UPDATED)</h2>
<h3>Zhi Chen, Yijie Bei, Cynthia Rudin</h3>
<p>What does a neural network encode about a concept as we traverse through the
layers? Interpretability in machine learning is undoubtedly important, but the
calculations of neural networks are very challenging to understand. Attempts to
see inside their hidden layers can either be misleading, unusable, or rely on
the latent space to possess properties that it may not have. In this work,
rather than attempting to analyze a neural network posthoc, we introduce a
mechanism, called concept whitening (CW), to alter a given layer of the network
to allow us to better understand the computation leading up to that layer. When
a concept whitening module is added to a CNN, the axes of the latent space are
aligned with known concepts of interest. By experiment, we show that CW can
provide us a much clearer understanding for how the network gradually learns
concepts over layers. CW is an alternative to a batch normalization layer in
that it normalizes, and also decorrelates (whitens) the latent space. CW can be
used in any layer of the network without hurting predictive performance.
</p>
<a href="http://arxiv.org/abs/2002.01650" target="_blank">arXiv:2002.01650</a> [<a href="http://arxiv.org/pdf/2002.01650" target="_blank">pdf</a>]

<h2>Correlation-aware Deep Generative Model for Unsupervised Anomaly Detection. (arXiv:2002.07349v3 [cs.LG] UPDATED)</h2>
<h3>Haoyi Fan, Fengbin Zhang, Ruidong Wang, Liang Xi, Zuoyong Li</h3>
<p>Unsupervised anomaly detection aims to identify anomalous samples from highly
complex and unstructured data, which is pervasive in both fundamental research
and industrial applications. However, most existing methods neglect the complex
correlation among data samples, which is important for capturing normal
patterns from which the abnormal ones deviate. In this paper, we propose a
method of Correlation aware unsupervised Anomaly detection via Deep Gaussian
Mixture Model (CADGMM), which captures the complex correlation among data
points for high-quality low-dimensional representation learning. Specifically,
the relations among data samples are correlated firstly in forms of a graph
structure, in which, the node denotes the sample and the edge denotes the
correlation between two samples from the feature space. Then, a dual-encoder
that consists of a graph encoder and a feature encoder, is employed to encode
both the feature and correlation information of samples into the
low-dimensional latent space jointly, followed by a decoder for data
reconstruction. Finally, a separate estimation network as a Gaussian Mixture
Model is utilized to estimate the density of the learned latent vector, and the
anomalies can be detected by measuring the energy of the samples. Extensive
experiments on real-world datasets demonstrate the effectiveness of the
proposed method.
</p>
<a href="http://arxiv.org/abs/2002.07349" target="_blank">arXiv:2002.07349</a> [<a href="http://arxiv.org/pdf/2002.07349" target="_blank">pdf</a>]

<h2>Variational Encoder-based Reliable Classification. (arXiv:2002.08289v2 [cs.LG] UPDATED)</h2>
<h3>Chitresh Bhushan, Zhaoyuan Yang, Nurali Virani, Naresh Iyer</h3>
<p>Machine learning models provide statistically impressive results which might
be individually unreliable. To provide reliability, we propose an Epistemic
Classifier (EC) that can provide justification of its belief using support from
the training dataset as well as quality of reconstruction. Our approach is
based on modified variational auto-encoders that can identify a semantically
meaningful low-dimensional space where perceptually similar instances are close
in $\ell_2$-distance too. Our results demonstrate improved reliability of
predictions and robust identification of samples with adversarial attacks as
compared to baseline of softmax-based thresholding.
</p>
<a href="http://arxiv.org/abs/2002.08289" target="_blank">arXiv:2002.08289</a> [<a href="http://arxiv.org/pdf/2002.08289" target="_blank">pdf</a>]

<h2>Structured Prediction for Conditional Meta-Learning. (arXiv:2002.08799v2 [cs.LG] UPDATED)</h2>
<h3>Ruohan Wang, Yiannis Demiris, Carlo Ciliberto</h3>
<p>The goal of optimization-based meta-learning is to find a single
initialization shared across a distribution of tasks to speed up the process of
learning new tasks. Conditional meta-learning seeks task-specific
initialization to better capture complex task distributions and improve
performance. However, many existing conditional methods are difficult to
generalize and lack theoretical guarantees. In this work, we propose a new
perspective on conditional meta-learning via structured prediction. We derive
task-adaptive structured meta-learning (TASML), a principled framework that
yields task-specific objective functions by weighing meta-training data on
target tasks. Our non-parametric approach is model-agnostic and can be combined
with existing meta-learning methods to achieve conditioning. Empirically, we
show that TASML improves the performance of existing meta-learning models, and
outperforms the state-of-the-art on benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2002.08799" target="_blank">arXiv:2002.08799</a> [<a href="http://arxiv.org/pdf/2002.08799" target="_blank">pdf</a>]

<h2>Petrophysically and geologically guided multi-physics inversion using a dynamic Gaussian mixture model. (arXiv:2002.09515v3 [physics.geo-ph] UPDATED)</h2>
<h3>Thibaut Astic, Lindsey J. Heagy, Douglas W. Oldenburg</h3>
<p>In a previous paper, we introduced a framework for carrying out
petrophysically and geologically guided geophysical inversions. In that
framework, petrophysical and geological information is modelled with a Gaussian
Mixture Model (GMM). In the inversion, the GMM serves as a prior for the
geophysical model. The formulation was confined to problems in which a single
physical property model was sought, with a single geophysical dataset. In this
paper, we extend that framework to jointly invert multiple geophysical datasets
that depend on multiple physical properties. The petrophysical and geological
information is used to couple geophysical surveys that, otherwise, rely on
independent physics. This requires advancements in two areas. First, an
extension from a univariate to a multivariate analysis of the petrophysical
data, and their inclusion within the inverse problem, is necessary. Second, we
address the practical issues of simultaneously inverting data from multiple
surveys and finding a solution that acceptably reproduces each one, along with
the petrophysical and geological information. To illustrate the efficacy of our
approach and the advantages of carrying out multi-physics inversions, we invert
synthetic gravity and magnetic data associated with a kimberlite deposit. The
kimberlite pipe contains two distinct facies embedded in a host rock. Inverting
the datasets individually leads to a binary geological model: background or
kimberlite. A multi-physics inversion, with petrophysical information,
differentiates between the two main kimberlite facies of the pipe. Through this
example, we also highlight the capabilities of our framework to work with
interpretive geologic assumptions when minimal quantitative information is
available. In those cases, the dynamic updates of the Gaussian Mixture Model
allow us to perform multi-physics inversions by learning a petrophysical model.
</p>
<a href="http://arxiv.org/abs/2002.09515" target="_blank">arXiv:2002.09515</a> [<a href="http://arxiv.org/pdf/2002.09515" target="_blank">pdf</a>]

<h2>Identifying Self-Admitted Technical Debts with Jitterbug: A Two-step Approach. (arXiv:2002.11049v3 [cs.SE] UPDATED)</h2>
<h3>Zhe Yu, Fahmid Morshed Fahid, Huy Tu, Tim Menzies</h3>
<p>Keeping track of and managing Self-Admitted Technical Debts (SATDs) are
important to maintaining a healthy software project. This requires much time
and effort from human experts to identify the SATDs manually. The current
automated solutions do not have satisfactory precision and recall in
identifying SATDs to fully automate the process. To solve the above problems,
we propose a two-step framework called Jitterbug for identifying SATDs.
Jitterbug first identifies the "easy to find" SATDs automatically with close to
100% precision using a novel pattern recognition technique. Subsequently,
machine learning techniques are applied to assist human experts in manually
identifying the remaining "hard to find" SATDs with reduced human effort. Our
simulation studies on ten software projects show that Jitterbug can identify
SATDs more efficiently (with less human effort) than the prior state-of-the-art
methods.
</p>
<a href="http://arxiv.org/abs/2002.11049" target="_blank">arXiv:2002.11049</a> [<a href="http://arxiv.org/pdf/2002.11049" target="_blank">pdf</a>]

<h2>Gradient Boosted Normalizing Flows. (arXiv:2002.11896v4 [cs.LG] UPDATED)</h2>
<h3>Robert Giaquinto, Arindam Banerjee</h3>
<p>By chaining a sequence of differentiable invertible transformations,
normalizing flows (NF) provide an expressive method of posterior approximation,
exact density evaluation, and sampling. The trend in normalizing flow
literature has been to devise deeper, more complex transformations to achieve
greater flexibility. We propose an alternative: Gradient Boosted Normalizing
Flows (GBNF) model a density by successively adding new NF components with
gradient boosting. Under the boosting framework, each new NF component
optimizes a sample weighted likelihood objective, resulting in new components
that are fit to the residuals of the previously trained components. The GBNF
formulation results in a mixture model structure, whose flexibility increases
as more components are added. Moreover, GBNFs offer a wider, as opposed to
strictly deeper, approach that improves existing NFs at the cost of additional
training---not more complex transformations. We demonstrate the effectiveness
of this technique for density estimation and, by coupling GBNF with a
variational autoencoder, generative modeling of images. Our results show that
GBNFs outperform their non-boosted analog, and, in some cases, produce better
results with smaller, simpler flows.
</p>
<a href="http://arxiv.org/abs/2002.11896" target="_blank">arXiv:2002.11896</a> [<a href="http://arxiv.org/pdf/2002.11896" target="_blank">pdf</a>]

<h2>Two-Level Attention-based Fusion Learning for RGB-D Face Recognition. (arXiv:2003.00168v3 [cs.CV] UPDATED)</h2>
<h3>Hardik Uppal, Alireza Sepas-Moghaddam, Michael Greenspan, Ali Etemad</h3>
<p>With recent advances in RGB-D sensing technologies as well as improvements in
machine learning and fusion techniques, RGB-D facial recognition has become an
active area of research. A novel attention aware method is proposed to fuse two
image modalities, RGB and depth, for enhanced RGB-D facial recognition. The
proposed method first extracts features from both modalities using a
convolutional feature extractor. These features are then fused using a
two-layer attention mechanism. The first layer focuses on the fused feature
maps generated by the feature extractor, exploiting the relationship between
feature maps using LSTM recurrent learning. The second layer focuses on the
spatial features of those maps using convolution. The training database is
preprocessed and augmented through a set of geometric transformations, and the
learning process is further aided using transfer learning from a pure 2D RGB
image training process. Comparative evaluations demonstrate that the proposed
method outperforms other state-of-the-art approaches, including both
traditional and deep neural network-based methods, on the challenging
CurtinFaces and IIIT-D RGB-D benchmark databases, achieving classification
accuracies over 98.2% and 99.3% respectively. The proposed attention mechanism
is also compared with other attention mechanisms, demonstrating more accurate
results.
</p>
<a href="http://arxiv.org/abs/2003.00168" target="_blank">arXiv:2003.00168</a> [<a href="http://arxiv.org/pdf/2003.00168" target="_blank">pdf</a>]

<h2>Volumetric landmark detection with a multi-scale shift equivariant neural network. (arXiv:2003.01639v2 [cs.CV] UPDATED)</h2>
<h3>Tianyu Ma, Ajay Gupta, Mert R. Sabuncu</h3>
<p>Deep neural networks yield promising results in a wide range of computer
vision applications, including landmark detection. A major challenge for
accurate anatomical landmark detection in volumetric images such as clinical CT
scans is that large-scale data often constrain the capacity of the employed
neural network architecture due to GPU memory limitations, which in turn can
limit the precision of the output. We propose a multi-scale, end-to-end deep
learning method that achieves fast and memory-efficient landmark detection in
3D images. Our architecture consists of blocks of shift-equivariant networks,
each of which performs landmark detection at a different spatial scale. These
blocks are connected from coarse to fine-scale, with differentiable resampling
layers, so that all levels can be trained together. We also present a noise
injection strategy that increases the robustness of the model and allows us to
quantify uncertainty at test time. We evaluate our method for carotid artery
bifurcations detection on 263 CT volumes and achieve a better than
state-of-the-art accuracy with mean Euclidean distance error of 2.81mm.
</p>
<a href="http://arxiv.org/abs/2003.01639" target="_blank">arXiv:2003.01639</a> [<a href="http://arxiv.org/pdf/2003.01639" target="_blank">pdf</a>]

<h2>Good Subnetworks Provably Exist: Pruning via Greedy Forward Selection. (arXiv:2003.01794v3 [cs.LG] UPDATED)</h2>
<h3>Mao Ye, Chengyue Gong, Lizhen Nie, Denny Zhou, Adam Klivans, Qiang Liu</h3>
<p>Recent empirical works show that large deep neural networks are often highly
redundant and one can find much smaller subnetworks without a significant drop
of accuracy. However, most existing methods of network pruning are empirical
and heuristic, leaving it open whether good subnetworks provably exist, how to
find them efficiently, and if network pruning can be provably better than
direct training using gradient descent. We answer these problems positively by
proposing a simple greedy selection approach for finding good subnetworks,
which starts from an empty network and greedily adds important neurons from the
large network. This differs from the existing methods based on backward
elimination, which remove redundant neurons from the large network.
Theoretically, applying the greedy selection strategy on sufficiently large
{pre-trained} networks guarantees to find small subnetworks with lower loss
than networks directly trained with gradient descent. Our results also apply to
pruning randomly weighted networks. Practically, we improve prior arts of
network pruning on learning compact neural architectures on ImageNet, including
ResNet, MobilenetV2/V3, and ProxylessNet. Our theory and empirical results on
MobileNet suggest that we should fine-tune the pruned subnetworks to leverage
the information from the large model, instead of re-training from new random
initialization as suggested in \citet{liu2018rethinking}.
</p>
<a href="http://arxiv.org/abs/2003.01794" target="_blank">arXiv:2003.01794</a> [<a href="http://arxiv.org/pdf/2003.01794" target="_blank">pdf</a>]

<h2>PLOP: Probabilistic poLynomial Objects trajectory Planning for autonomous driving. (arXiv:2003.08744v2 [cs.CV] UPDATED)</h2>
<h3>Thibault Buhet, Emilie Wirbel, Xavier Perrotton</h3>
<p>To navigate safely in an urban environment, an autonomous vehicle (ego
vehicle) needs to understand and anticipate its surroundings, in particular the
behavior of other road users (neighbors). However, multiple choices are often
acceptable (e.g. turn right or left, or different ways of avoiding an
obstacle). We focus here on predicting multiple feasible future trajectories
both for the ego vehicle and neighbors through a probabilistic framework. We
use a conditional imitation learning algorithm, conditioned by a navigation
command for the ego vehicle (e.g. "turn right"). It takes as input the ego car
front camera image, a Lidar point cloud in a bird-eye view grid and present and
past objects detections to output ego vehicle and neighbors possible
trajectories but also semantic segmentation as an auxiliary loss. We evaluate
our method on the publicly available dataset nuScenes, showing state-of-the-art
performance and investigating the impact of our architecture choices.
</p>
<a href="http://arxiv.org/abs/2003.08744" target="_blank">arXiv:2003.08744</a> [<a href="http://arxiv.org/pdf/2003.08744" target="_blank">pdf</a>]

<h2>Domain Adaptation by Class Centroid Matching and Local Manifold Self-Learning. (arXiv:2003.09391v3 [cs.CV] UPDATED)</h2>
<h3>Lei Tian, Yongqiang Tang, Liangchen Hu, Zhida Ren, Wensheng Zhang</h3>
<p>Domain adaptation has been a fundamental technology for transferring
knowledge from a source domain to a target domain. The key issue of domain
adaptation is how to reduce the distribution discrepancy between two domains in
a proper way such that they can be treated indifferently for learning. In this
paper, we propose a novel domain adaptation approach, which can thoroughly
explore the data distribution structure of target domain.Specifically, we
regard the samples within the same cluster in target domain as a whole rather
than individuals and assigns pseudo-labels to the target cluster by class
centroid matching. Besides, to exploit the manifold structure information of
target data more thoroughly, we further introduce a local manifold
self-learning strategy into our proposal to adaptively capture the inherent
local connectivity of target samples. An efficient iterative optimization
algorithm is designed to solve the objective function of our proposal with
theoretical convergence guarantee. In addition to unsupervised domain
adaptation, we further extend our method to the semi-supervised scenario
including both homogeneous and heterogeneous settings in a direct but elegant
way. Extensive experiments on seven benchmark datasets validate the significant
superiority of our proposal in both unsupervised and semi-supervised manners.
</p>
<a href="http://arxiv.org/abs/2003.09391" target="_blank">arXiv:2003.09391</a> [<a href="http://arxiv.org/pdf/2003.09391" target="_blank">pdf</a>]

<h2>Unsupervised Anomaly Detection with Adversarial Mirrored AutoEncoders. (arXiv:2003.10713v2 [cs.LG] UPDATED)</h2>
<h3>G. Somepalli, Y. Wu, Y. Balaji, B. Vinzamuri, S. Feizi</h3>
<p>Deep neural networks have great predictive power when they are applied to the
in-distribution test data, but they tend to predict incorrect outputs, highly
confidently, for out-of-distribution (OOD) samples. Hence, it is of utmost
importance to detect anomalous samples before deploying deep systems in the
real world. The use of deep generative models for anomaly detection has shown
great promise owing to their ability to learn proper representations of complex
input data distributions. However, earlier studies have shown that generative
models assign higher likelihoods to OOD samples compared to the data
distribution they have been trained on. In this work, we propose Adversarial
Mirrored AutoEncoder (AMA), a simple modification to Adversarial Autoencoder
where we use a Mirrored Wasserstein loss in the Discriminator to enforce better
semantic-level reconstruction. We also propose a new metric for anomaly
quantification instead of a regular reconstruction-based metric which has been
used in most of the recent generative model-based anomaly detection methods. We
show that in an unsupervised setting, our model outperforms or matches recent
anomaly detectors based on generative models over CIFAR-10 and MNIST on both
in-distribution and OOD anomalies.
</p>
<a href="http://arxiv.org/abs/2003.10713" target="_blank">arXiv:2003.10713</a> [<a href="http://arxiv.org/pdf/2003.10713" target="_blank">pdf</a>]

<h2>Noisy Text Data: Achilles' Heel of BERT. (arXiv:2003.12932v3 [cs.CL] UPDATED)</h2>
<h3>Ankit Kumar, Piyush Makhija, Anuj Gupta</h3>
<p>Owing to the phenomenal success of BERT on various NLP tasks and benchmark
datasets, industry practitioners are actively experimenting with fine-tuning
BERT to build NLP applications for solving industry use cases. For most
datasets that are used by practitioners to build industrial NLP applications,
it is hard to guarantee absence of any noise in the data. While BERT has
performed exceedingly well for transferring the learnings from one use case to
another, it remains unclear how BERT performs when fine-tuned on noisy text. In
this work, we explore the sensitivity of BERT to noise in the data. We work
with most commonly occurring noise (spelling mistakes, typos) and show that
this results in significant degradation in the performance of BERT. We present
experimental results to show that BERT's performance on fundamental NLP tasks
like sentiment analysis and textual similarity drops significantly in the
presence of (simulated) noise on benchmark datasets viz. IMDB Movie Review,
STS-B, SST-2. Further, we identify shortcomings in the existing BERT pipeline
that are responsible for this drop in performance. Our findings suggest that
practitioners need to be vary of presence of noise in their datasets while
fine-tuning BERT to solve industry use cases.
</p>
<a href="http://arxiv.org/abs/2003.12932" target="_blank">arXiv:2003.12932</a> [<a href="http://arxiv.org/pdf/2003.12932" target="_blank">pdf</a>]

<h2>Leverage the Average: an Analysis of KL Regularization in RL. (arXiv:2003.14089v4 [cs.LG] UPDATED)</h2>
<h3>Nino Vieillard, Tadashi Kozuno, Bruno Scherrer, Olivier Pietquin, R&#xe9;mi Munos, Matthieu Geist</h3>
<p>Recent Reinforcement Learning (RL) algorithms making use of Kullback-Leibler
(KL) regularization as a core component have shown outstanding performance.
Yet, only little is understood theoretically about why KL regularization helps,
so far. We study KL regularization within an approximate value iteration scheme
and show that it implicitly averages q-values. Leveraging this insight, we
provide a very strong performance bound, the very first to combine two
desirable aspects: a linear dependency to the horizon (instead of quadratic)
and an error propagation term involving an averaging effect of the estimation
errors (instead of an accumulation effect). We also study the more general case
of an additional entropy regularizer. The resulting abstract scheme encompasses
many existing RL algorithms. Some of our assumptions do not hold with neural
networks, so we complement this theoretical analysis with an extensive
empirical study.
</p>
<a href="http://arxiv.org/abs/2003.14089" target="_blank">arXiv:2003.14089</a> [<a href="http://arxiv.org/pdf/2003.14089" target="_blank">pdf</a>]

<h2>A Graph Attention Spatio-temporal Convolutional Networks for 3D Human Pose Estimation in Video. (arXiv:2003.14179v3 [cs.CV] UPDATED)</h2>
<h3>Junfa Liu, Juan Rojas, Zhijun Liang, Yihui Li, Yisheng Guan</h3>
<p>Spatio-temporal information is key to resolve occlusion and depth ambiguity
in 3D pose estimation. Previous methods have focused on either temporal
contexts or local-to-global architectures that embed fixed-length
spatio-temporal information. To date, there have not been effective proposals
to simultaneously and flexibly capture varying spatio-temporal sequences and
effectively achieves real-time 3D pose estimation. In this work, we improve the
learning of kinematic constraints in the human skeleton: posture, local
kinematic connections, and symmetry by modeling local and global spatial
information via attention mechanisms. To adapt to single- and multi-frame
estimation, the dilated temporal model is employed to process varying skeleton
sequences. Also, importantly, we carefully design the interleaving of spatial
semantics with temporal dependencies to achieve a synergistic effect. To this
end, we propose a simple yet effective graph attention spatio-temporal
convolutional network (GAST-Net) that comprises of interleaved temporal
convolutional and graph attention blocks. Experiments on two challenging
benchmark datasets (Human3.6M and HumanEva-I) and YouTube videos demonstrate
that our approach effectively mitigates depth ambiguity and self-occlusion,
generalizes to half upper body estimation, and achieves competitive performance
on 2D-to-3D video pose estimation.
</p>
<a href="http://arxiv.org/abs/2003.14179" target="_blank">arXiv:2003.14179</a> [<a href="http://arxiv.org/pdf/2003.14179" target="_blank">pdf</a>]

<h2>Generative Latent Implicit Conditional Optimization when Learning from Small Sample. (arXiv:2003.14297v4 [cs.LG] UPDATED)</h2>
<h3>Idan Azuri, Daphna Weinshall</h3>
<p>We revisit the long-standing problem of learning from small sample, to which
end we propose a novel method called GLICO (Generative Latent Implicit
Conditional Optimization). GLICO learns a mapping from the training examples to
a latent space, and a generator that generates images from vectors in the
latent space. Unlike most recent works, which rely on access to large amounts
of unlabeled data, GLICO does not require access to any additional data other
than the small set of labeled points. In fact, GLICO learns to synthesize
completely new samples for every class using as little as 5 or 10 examples per
class, with as few as 10 such classes without imposing any prior. GLICO is then
used to augment the small training set while training a classifier on the small
sample. To this end, our proposed method samples the learned latent space using
spherical interpolation, and generates new examples using the trained
generator. Empirical results show that the new sampled set is diverse enough,
leading to improvement in image classification in comparison with the state of
the art, when trained on small samples obtained from CIFAR-10, CIFAR-100, and
CUB-200.
</p>
<a href="http://arxiv.org/abs/2003.14297" target="_blank">arXiv:2003.14297</a> [<a href="http://arxiv.org/pdf/2003.14297" target="_blank">pdf</a>]

<h2>Long-Tailed Recognition Using Class-Balanced Experts. (arXiv:2004.03706v2 [cs.CV] UPDATED)</h2>
<h3>Saurabh Sharma, Ning Yu, Mario Fritz, Bernt Schiele</h3>
<p>Deep learning enables impressive performance in image recognition using
large-scale artificially-balanced datasets. However, real-world datasets
exhibit highly class-imbalanced distributions, yielding two main challenges:
relative imbalance amongst the classes and data scarcity for mediumshot or
fewshot classes. In this work, we address the problem of long-tailed
recognition wherein the training set is highly imbalanced and the test set is
kept balanced. Differently from existing paradigms relying on data-resampling,
cost-sensitive learning, online hard example mining, loss objective reshaping,
and/or memory-based modeling, we propose an ensemble of class-balanced experts
that combines the strength of diverse classifiers. Our ensemble of
class-balanced experts reaches results close to state-of-the-art and an
extended ensemble establishes a new state-of-the-art on two benchmarks for
long-tailed recognition. We conduct extensive experiments to analyse the
performance of the ensembles, and discover that in modern large-scale datasets,
relative imbalance is a harder problem than data scarcity. The training and
evaluation code is available at
https://github.com/ssfootball04/class-balanced-experts.
</p>
<a href="http://arxiv.org/abs/2004.03706" target="_blank">arXiv:2004.03706</a> [<a href="http://arxiv.org/pdf/2004.03706" target="_blank">pdf</a>]

<h2>Deep Learning based Frameworks for Handling Imbalance in DGA, Email, and URL Data Analysis. (arXiv:2004.04812v2 [cs.LG] UPDATED)</h2>
<h3>Simran K, Prathiksha Balakrishna, Vinayakumar Ravi, Soman KP</h3>
<p>Deep learning is a state of the art method for a lot of applications. The
main issue is that most of the real-time data is highly imbalanced in nature.
In order to avoid bias in training, cost-sensitive approach can be used. In
this paper, we propose cost-sensitive deep learning based frameworks and the
performance of the frameworks is evaluated on three different Cyber Security
use cases which are Domain Generation Algorithm (DGA), Electronic mail (Email),
and Uniform Resource Locator (URL). Various experiments were performed using
cost-insensitive as well as cost-sensitive methods and parameters for both of
these methods are set based on hyperparameter tuning. In all experiments, the
cost-sensitive deep learning methods performed better than the cost-insensitive
approaches. This is mainly due to the reason that cost-sensitive approach gives
importance to the classes which have a very less number of samples during
training and this helps to learn all the classes in a more efficient manner.
</p>
<a href="http://arxiv.org/abs/2004.04812" target="_blank">arXiv:2004.04812</a> [<a href="http://arxiv.org/pdf/2004.04812" target="_blank">pdf</a>]

<h2>Order Matters: Generating Progressive Explanations for Planning Tasks in Human-Robot Teaming. (arXiv:2004.07822v2 [cs.AI] UPDATED)</h2>
<h3>Mehrdad Zakershahrak, Shashank Rao Marpally, Akshay Sharma, Ze Gong, Yu Zhang</h3>
<p>Prior work on generating explanations in a planning and decision-making
context has focused on providing the rationale behind an AI agent's decision
making. While these methods provide the right explanations from the explainer's
perspective, they fail to heed the cognitive requirement of understanding an
explanation from the explainee's (the human's) perspective. In this work, we
set out to address this issue by first considering the influence of information
order in an explanation, or the progressiveness of explanations. Intuitively,
progression builds later concepts on previous ones and is known to contribute
to better learning. In this work, we aim to investigate similar effects during
explanation generation when an explanation is broken into multiple parts that
are communicated sequentially. The challenge here lies in modeling the humans'
preferences for information order in receiving such explanations to assist
understanding. Given this sequential process, a formulation based on goal-based
MDP for generating progressive explanations is presented. The reward function
of this MDP is learned via inverse reinforcement learning based on explanations
that are retrieved via human subject studies. We first evaluated our approach
on a scavenger-hunt domain to demonstrate its effectively in capturing the
humans' preferences. Upon analyzing the results, it revealed something more
fundamental: the preferences arise strongly from both domain dependent and
independence features. The correlation with domain independent features pushed
us to verify this result further in an escape room domain. Results confirmed
our hypothesis that the process of understanding an explanation was a dynamic
process. The human preference that reflected this aspect corresponded exactly
to the progression for knowledge assimilation hidden deeper in our cognitive
process.
</p>
<a href="http://arxiv.org/abs/2004.07822" target="_blank">arXiv:2004.07822</a> [<a href="http://arxiv.org/pdf/2004.07822" target="_blank">pdf</a>]

<h2>Natural Disaster Classification using Aerial Photography Explainable for Typhoon Damaged Feature. (arXiv:2004.10130v3 [cs.CV] UPDATED)</h2>
<h3>Takato Yasuno, Masazumi Amakata, Masahiro Okano</h3>
<p>Recent years, typhoon damages has become social problem owing to climate
change. Especially, 9 September 2019, Typhoon Faxai passed on the Chiba
prefecture in Japan, whose damages included with electric provision stop
because of strong wind recorded on the maximum 45 meter per second. A large
amount of tree fell down, and the neighbor electric poles also fell down at the
same time. These disaster features have caused that it took 18 days for
recovery longer than past ones. Immediate responses are important for faster
recovery. As long as we can, aerial survey for global screening of devastated
region would be required for decision support to respond where to recover
ahead. This paper proposes a practical method to visualize the damaged areas
focused on the typhoon disaster features using aerial photography. This method
can classify eight classes which contains land covers without damages and areas
with disaster, where an aerial photograph is partitioned into 4,096 grids that
is 64 by 64, with each unit image of 48 meter square. Using target feature
class probabilities, we can visualize disaster features map to scale the color
range from blue to yellow. Furthermore, we can realize disaster feature mapping
on each unit grid images to compute the convolutional activation map using
Grad-CAM based on deep neural network layers for classification. We demonstrate
case studies applied to aerial photographs recorded at the Chiba prefecture
after typhoon disaster. (233 words)
</p>
<a href="http://arxiv.org/abs/2004.10130" target="_blank">arXiv:2004.10130</a> [<a href="http://arxiv.org/pdf/2004.10130" target="_blank">pdf</a>]

<h2>OF-VO: Reliable Navigation among Pedestrians Using Commodity Sensors. (arXiv:2004.10976v2 [cs.RO] UPDATED)</h2>
<h3>Jing Liang, Yi-Ling Qiao, Tianrui Guan, Dinesh Manocha</h3>
<p>We present a novel algorithm for safe navigation of a mobile robot in
uncertain environment among pedestrians. Our approach uses commodity visual
sensors, including mono-camera and a 2D lidar, for explicitly predicting the
velocities and positions of surrounding obstacles through optical flow
estimation, object detection and sensor fusion. Given these probabilistic
partial observations of the environment, we present a modified
velocity-obstacle (VO) algorithm to compute velocities to navigate robot as it
approaches to target. A key aspect of our work is coupling the perception (OF:
optical flow) and planning (VO) components for reliable navigation. Overall,
our OF-VO algorithm is a hybrid combination of learning-based and model-based
methods and offers better performance than prior algorithms in terms of
navigation time and success rate of collision avoidance. We highlight the
realtime performance of OF-VO in simulated and real-world dynamic scenes on a
Turtlebot robot navigating among pedestrians with commodity sensors. A demo
video is available at https://www.youtube.com/watch?v=5sYhZrGwsxM
</p>
<a href="http://arxiv.org/abs/2004.10976" target="_blank">arXiv:2004.10976</a> [<a href="http://arxiv.org/pdf/2004.10976" target="_blank">pdf</a>]

<h2>SL-DML: Signal Level Deep Metric Learning for Multimodal One-Shot Action Recognition. (arXiv:2004.11085v4 [cs.CV] UPDATED)</h2>
<h3>Raphael Memmesheimer, Nick Theisen, Dietrich Paulus</h3>
<p>Recognizing an activity with a single reference sample using metric learning
approaches is a promising research field. The majority of few-shot methods
focus on object recognition or face-identification. We propose a metric
learning approach to reduce the action recognition problem to a nearest
neighbor search in embedding space. We encode signals into images and extract
features using a deep residual CNN. Using triplet loss, we learn a feature
embedding. The resulting encoder transforms features into an embedding space in
which closer distances encode similar actions while higher distances encode
different actions. Our approach is based on a signal level formulation and
remains flexible across a variety of modalities. It further outperforms the
baseline on the large scale NTU RGB+D 120 dataset for the One-Shot action
recognition protocol by 5.6%. With just 60% of the training data, our approach
still outperforms the baseline approach by 3.7%. With 40% of the training data,
our approach performs comparably well to the second follow up. Further, we show
that our approach generalizes well in experiments on the UTD-MHAD dataset for
inertial, skeleton and fused data and the Simitate dataset for motion capturing
data. Furthermore, our inter-joint and inter-sensor experiments suggest good
capabilities on previously unseen setups.
</p>
<a href="http://arxiv.org/abs/2004.11085" target="_blank">arXiv:2004.11085</a> [<a href="http://arxiv.org/pdf/2004.11085" target="_blank">pdf</a>]

<h2>Molecular Design in Synthetically Accessible Chemical Space via Deep Reinforcement Learning. (arXiv:2004.14308v2 [physics.chem-ph] UPDATED)</h2>
<h3>Julien Horwood, Emmanuel Noutahi</h3>
<p>The fundamental goal of generative drug design is to propose optimized
molecules that meet predefined activity, selectivity, and pharmacokinetic
criteria. Despite recent progress, we argue that existing generative methods
are limited in their ability to favourably shift the distributions of molecular
properties during optimization. We instead propose a novel Reinforcement
Learning framework for molecular design in which an agent learns to directly
optimize through a space of synthetically-accessible drug-like molecules. This
becomes possible by defining transitions in our Markov Decision Process as
chemical reactions, and allows us to leverage synthetic routes as an inductive
bias. We validate our method by demonstrating that it outperforms existing
state-of the art approaches in the optimization of pharmacologically-relevant
objectives, while results on multi-objective optimization tasks suggest
increased scalability to realistic pharmaceutical design problems.
</p>
<a href="http://arxiv.org/abs/2004.14308" target="_blank">arXiv:2004.14308</a> [<a href="http://arxiv.org/pdf/2004.14308" target="_blank">pdf</a>]

<h2>Deep Latent Variable Model for Learning Longitudinal Multi-view Data. (arXiv:2005.05210v2 [stat.ML] UPDATED)</h2>
<h3>Lin Qiu, Vernon M. Chinchilli, Lin Lin</h3>
<p>In many scientific problems such as video surveillance, modern genomic
analysis, and clinical studies, data are often collected from diverse domains
across time that exhibit time-dependent heterogeneous properties. It is
important to not only integrate data from multiple sources (called multiview
data), but also to incorporate time dependency for deep understanding of the
underlying system. Latent factor models are popular tools for exploring
multi-view data. However, it is frequently observed that these models do not
perform well for complex systems and they are not applicable to time-series
data. Therefore, we propose a generative model based on variational autoencoder
and recurrent neural network to infer the latent dynamic factors for
multivariate timeseries data. This approach allows us to identify the
disentangled latent embeddings across multiple modalities while accounting for
the time factor. We invoke our proposed model for analyzing three datasets on
which we demonstrate the effectiveness and the interpretability of the model.
</p>
<a href="http://arxiv.org/abs/2005.05210" target="_blank">arXiv:2005.05210</a> [<a href="http://arxiv.org/pdf/2005.05210" target="_blank">pdf</a>]

<h2>Aortic Pressure Forecasting with Deep Sequence Learning. (arXiv:2005.05502v3 [cs.LG] UPDATED)</h2>
<h3>Eliza Huang, Rui Wang, Uma Chandrasekaran, Rose Yu</h3>
<p>Mean aortic pressure (MAP) is a major determinant of perfusion in all organs
systems. The ability to forecast MAP would enhance the ability of physicians to
estimate prognosis of the patient and assist in early detection of hemodynamic
instability. However, forecasting MAP is challenging because the blood pressure
(BP) time series is noisy and can be highly non-stationary. The aim of this
study was to forecast the mean aortic pressure five minutes in advance, using
the 25 Hz time series data of previous five minutes as input. We provide a
benchmark study of different deep learning models for BP forecasting. We
investigate a left ventricular dwelling transvalvular micro-axial device, the
Impella, in patients undergoing high-risk percutaneous intervention. The
Impella provides hemodynamic support, thus aiding in native heart function
recovery. It is also equipped with pressure sensors to capture high frequency
MAP measurements at origin, instead of peripherally. Our dataset and the
clinical application is novel in the BP forecasting field. We performed a
comprehensive study on time series with increasing, decreasing, and stationary
trends. The experiments show that recurrent neural networks with Legendre
Memory Unit achieve the best performance with an overall forecasting error of
1.8 mmHg.
</p>
<a href="http://arxiv.org/abs/2005.05502" target="_blank">arXiv:2005.05502</a> [<a href="http://arxiv.org/pdf/2005.05502" target="_blank">pdf</a>]

<h2>Implicit Regularization in Deep Learning May Not Be Explainable by Norms. (arXiv:2005.06398v2 [cs.LG] UPDATED)</h2>
<h3>Noam Razin, Nadav Cohen</h3>
<p>Mathematically characterizing the implicit regularization induced by
gradient-based optimization is a longstanding pursuit in the theory of deep
learning. A widespread hope is that a characterization based on minimization of
norms may apply, and a standard test-bed for studying this prospect is matrix
factorization (matrix completion via linear neural networks). It is an open
question whether norms can explain the implicit regularization in matrix
factorization. The current paper resolves this open question in the negative,
by proving that there exist natural matrix factorization problems on which the
implicit regularization drives all norms (and quasi-norms) towards infinity.
Our results suggest that, rather than perceiving the implicit regularization
via norms, a potentially more useful interpretation is minimization of rank. We
demonstrate empirically that this interpretation extends to a certain class of
non-linear neural networks, and hypothesize that it may be key to explaining
generalization in deep learning.
</p>
<a href="http://arxiv.org/abs/2005.06398" target="_blank">arXiv:2005.06398</a> [<a href="http://arxiv.org/pdf/2005.06398" target="_blank">pdf</a>]

<h2>Face Identity Disentanglement via Latent Space Mapping. (arXiv:2005.07728v3 [cs.CV] UPDATED)</h2>
<h3>Yotam Nitzan, Amit Bermano, Yangyan Li, Daniel Cohen-Or</h3>
<p>Learning disentangled representations of data is a fundamental problem in
artificial intelligence. Specifically, disentangled latent representations
allow generative models to control and compose the disentangled factors in the
synthesis process. Current methods, however, require extensive supervision and
training, or instead, noticeably compromise quality. In this paper, we present
a method that learns how to represent data in a disentangled way, with minimal
supervision, manifested solely using available pre-trained networks. Our key
insight is to decouple the processes of disentanglement and synthesis, by
employing a leading pre-trained unconditional image generator, such as
StyleGAN. By learning to map into its latent space, we leverage both its
state-of-the-art quality, and its rich and expressive latent space, without the
burden of training it. We demonstrate our approach on the complex and high
dimensional domain of human heads. We evaluate our method qualitatively and
quantitatively, and exhibit its success with de-identification operations and
with temporal identity coherency in image sequences. Through extensive
experimentation, we show that our method successfully disentangles identity
from other facial attributes, surpassing existing methods, even though they
require more training and supervision.
</p>
<a href="http://arxiv.org/abs/2005.07728" target="_blank">arXiv:2005.07728</a> [<a href="http://arxiv.org/pdf/2005.07728" target="_blank">pdf</a>]

<h2>PatchGuard: A Provably Robust Defense against Adversarial Patches via Small Receptive Fields and Masking. (arXiv:2005.10884v4 [cs.CV] UPDATED)</h2>
<h3>Chong Xiang, Arjun Nitin Bhagoji, Vikash Sehwag, Prateek Mittal</h3>
<p>Localized adversarial patches aim to induce misclassification in machine
learning models by arbitrarily modifying pixels within a restricted region of
an image. Such attacks can be realized in the physical world by attaching the
adversarial patch to the object to be misclassified, and defending against such
attacks is an unsolved/open problem. In this paper, we propose a general
defense framework called PatchGuard that can achieve high provable robustness
while maintaining high clean accuracy against localized adversarial patches.
The cornerstone of PatchGuard involves the use of CNNs with small receptive
fields to impose a bound on the number of features corrupted by an adversarial
patch. Given a bounded number of corrupted features, the problem of designing
an adversarial patch defense reduces to that of designing a secure feature
aggregation mechanism. Towards this end, we present our robust masking defense
that robustly detects and masks corrupted features to recover the correct
prediction. Our extensive evaluation on ImageNet, ImageNette (a 10-class subset
of ImageNet), and CIFAR-10 datasets demonstrates that our defense achieves
state-of-the-art performance in terms of both provable robust accuracy and
clean accuracy.
</p>
<a href="http://arxiv.org/abs/2005.10884" target="_blank">arXiv:2005.10884</a> [<a href="http://arxiv.org/pdf/2005.10884" target="_blank">pdf</a>]

<h2>Multiple Access in Aerial Networks: From Orthogonal and Non-Orthogonal to Rate-Splitting. (arXiv:2005.13122v4 [eess.SP] UPDATED)</h2>
<h3>Wael Jaafar, Shimaa Naser, Sami Muhaidat, Paschalis C. Sofotasios, Halim Yanikomeroglu</h3>
<p>Recently, interest on the utilization of unmanned aerial vehicles (UAVs) has
aroused. Specifically, UAVs can be used in cellular networks as aerial users
for delivery, surveillance, rescue search, or as an aerial base station (aBS)
for communication with ground users in remote uncovered areas or in dense
environments requiring prompt high capacity. Aiming to satisfy the high
requirements of wireless aerial networks, several multiple access techniques
have been investigated. In particular, space-division multiple access(SDMA) and
power-domain non-orthogonal multiple access (NOMA) present promising
multiplexing gains for aerial downlink and uplink. Nevertheless, these gains
are limited as they depend on the conditions of the environment. Hence, a
generalized scheme has been recently proposed, called rate-splitting multiple
access (RSMA), which is capable of achieving better spectral efficiency gains
compared to SDMA and NOMA. In this paper, we present a comprehensive survey of
key multiple access technologies adopted for aerial networks, where aBSs are
deployed to serve ground users. Since there have been only sporadic results
reported on the use of RSMA in aerial systems, we aim to extend the discussion
on this topic by modelling and analyzing the weighted sum-rate performance of a
two-user downlink network served by an RSMA-based aBS. Finally, related open
issues and future research directions are exposed.
</p>
<a href="http://arxiv.org/abs/2005.13122" target="_blank">arXiv:2005.13122</a> [<a href="http://arxiv.org/pdf/2005.13122" target="_blank">pdf</a>]

<h2>The INTERSPEECH 2020 Deep Noise Suppression Challenge: Datasets, Subjective Testing Framework, and Challenge Results. (arXiv:2005.13981v3 [eess.AS] UPDATED)</h2>
<h3>Chandan K. A. Reddy, Vishak Gopal, Ross Cutler, Ebrahim Beyrami, Roger Cheng, Harishchandra Dubey, Sergiy Matusevych, Robert Aichner, Ashkan Aazami, Sebastian Braun, Puneet Rana, Sriram Srinivasan, Johannes Gehrke</h3>
<p>The INTERSPEECH 2020 Deep Noise Suppression (DNS) Challenge is intended to
promote collaborative research in real-time single-channel Speech Enhancement
aimed to maximize the subjective (perceptual) quality of the enhanced speech. A
typical approach to evaluate the noise suppression methods is to use objective
metrics on the test set obtained by splitting the original dataset. While the
performance is good on the synthetic test set, often the model performance
degrades significantly on real recordings. Also, most of the conventional
objective metrics do not correlate well with subjective tests and lab
subjective tests are not scalable for a large test set. In this challenge, we
open-sourced a large clean speech and noise corpus for training the noise
suppression models and a representative test set to real-world scenarios
consisting of both synthetic and real recordings. We also open-sourced an
online subjective test framework based on ITU-T P.808 for researchers to
reliably test their developments. We evaluated the results using P.808 on a
blind test set. The results and the key learnings from the challenge are
discussed. The datasets and scripts can be found here for quick access
https://github.com/microsoft/DNS-Challenge.
</p>
<a href="http://arxiv.org/abs/2005.13981" target="_blank">arXiv:2005.13981</a> [<a href="http://arxiv.org/pdf/2005.13981" target="_blank">pdf</a>]

<h2>Semi-supervised Embedding Learning for High-dimensional Bayesian Optimization. (arXiv:2005.14601v3 [cs.LG] UPDATED)</h2>
<h3>Jingfan Chen, Guanghui Zhu, Chunfeng Yuan, Yihua Huang</h3>
<p>Bayesian optimization is a broadly applied methodology to optimize the
expensive black-box function. Despite its success, it still faces the challenge
from the high-dimensional search space. To alleviate this problem, we propose a
novel Bayesian optimization framework (termed SILBO), which finds a
low-dimensional space to perform Bayesian optimization iteratively through
semi-supervised dimension reduction. SILBO incorporates both labeled points and
unlabeled points acquired from the acquisition function to guide the embedding
space learning. To accelerate the learning procedure, we present a randomized
method for generating the projection matrix. Furthermore, to map from the
low-dimensional space to the high-dimensional original space, we propose two
mapping strategies: $\text{SILBO}_{FZ}$ and $\text{SILBO}_{FX}$ according to
the evaluation overhead of the objective function. Experimental results on both
synthetic function and hyperparameter optimization tasks demonstrate that SILBO
outperforms the existing state-of-the-art high-dimensional Bayesian
optimization methods.
</p>
<a href="http://arxiv.org/abs/2005.14601" target="_blank">arXiv:2005.14601</a> [<a href="http://arxiv.org/pdf/2005.14601" target="_blank">pdf</a>]

<h2>True{\AE}dapt: Learning Smooth Online Trajectory Adaptation with Bounded Jerk, Acceleration and Velocity in Joint Space. (arXiv:2006.00375v2 [cs.RO] UPDATED)</h2>
<h3>Jonas C. Kiemel, Robin Weitemeyer, Pascal Mei&#xdf;ner, Torsten Kr&#xf6;ger</h3>
<p>We present True{\AE}dapt, a model-free method to learn online adaptations of
robot trajectories based on their effects on the environment. Given sensory
feedback and future waypoints of the original trajectory, a neural network is
trained to predict joint accelerations at regular intervals. The adapted
trajectory is generated by linear interpolation of the predicted accelerations,
leading to continuously differentiable joint velocities and positions. Bounded
jerks, accelerations and velocities are guaranteed by calculating the range of
valid accelerations at each decision step and clipping the network's output
accordingly. A deviation penalty during the training process causes the adapted
trajectory to follow the original one. Smooth movements are encouraged by
penalizing high accelerations and jerks. We evaluate our approach by training a
simulated KUKA iiwa robot to balance a ball on a plate while moving and
demonstrate that the balancing policy can be directly transferred to a real
robot.
</p>
<a href="http://arxiv.org/abs/2006.00375" target="_blank">arXiv:2006.00375</a> [<a href="http://arxiv.org/pdf/2006.00375" target="_blank">pdf</a>]

<h2>High-Fidelity Audio Generation and Representation Learning with Guided Adversarial Autoencoder. (arXiv:2006.00877v2 [eess.AS] UPDATED)</h2>
<h3>Kazi Nazmul Haque, Rajib Rana, Bj&#xf6;rn W Schuller</h3>
<p>Unsupervised disentangled representation learning from the unlabelled audio
data, and high fidelity audio generation have become two linchpins in the
machine learning research fields. However, the representation learned from an
unsupervised setting does not guarantee its' usability for any downstream task
at hand, which can be a wastage of the resources, if the training was conducted
for that particular posterior job. Also, during the representation learning, if
the model is highly biased towards the downstream task, it losses its
generalisation capability which directly benefits the downstream job but the
ability to scale it to other related task is lost. Therefore, to fill this gap,
we propose a new autoencoder based model named "Guided Adversarial Autoencoder
(GAAE)", which can learn both post-task-specific representations and the
general representation capturing the factors of variation in the training data
leveraging a small percentage of labelled samples; thus, makes it suitable for
future related tasks. Furthermore, our proposed model can generate audio with
superior quality, which is indistinguishable from the real audio samples.
Hence, with the extensive experimental results, we have demonstrated that by
harnessing the power of the high-fidelity audio generation, the proposed GAAE
model can learn powerful representation from unlabelled dataset leveraging a
fewer percentage of labelled data as supervision/guidance.
</p>
<a href="http://arxiv.org/abs/2006.00877" target="_blank">arXiv:2006.00877</a> [<a href="http://arxiv.org/pdf/2006.00877" target="_blank">pdf</a>]

<h2>Neural Power Units. (arXiv:2006.01681v3 [cs.LG] UPDATED)</h2>
<h3>Niklas Heim, Tom&#xe1;&#x161; Pevn&#xfd;, V&#xe1;clav &#x160;m&#xed;dl</h3>
<p>Conventional Neural Networks can approximate simple arithmetic operations,
but fail to generalize beyond the range of numbers that were seen during
training. Neural Arithmetic Units aim to overcome this difficulty, but current
arithmetic units are either limited to operate on positive numbers or can only
represent a subset of arithmetic operations. We introduce the Neural Power Unit
(NPU) that operates on the full domain of real numbers and is capable of
learning arbitrary power functions in a single layer. The NPU thus fixes the
shortcomings of existing arithmetic units and extends their expressivity. We
achieve this by using complex arithmetic without requiring a conversion of the
network to complex numbers. A simplification of the unit to the RealNPU yields
a highly transparent model. We show that the NPUs outperform their competitors
in terms of accuracy and sparsity on artificial arithmetic datasets, and that
the RealNPU can discover the governing equations of a dynamical system only
from data.
</p>
<a href="http://arxiv.org/abs/2006.01681" target="_blank">arXiv:2006.01681</a> [<a href="http://arxiv.org/pdf/2006.01681" target="_blank">pdf</a>]

<h2>Learning Kernel Tests Without Data Splitting. (arXiv:2006.02286v3 [cs.LG] UPDATED)</h2>
<h3>Jonas M. K&#xfc;bler, Wittawat Jitkrittum, Bernhard Sch&#xf6;lkopf, Krikamol Muandet</h3>
<p>Modern large-scale kernel-based tests such as maximum mean discrepancy (MMD)
and kernelized Stein discrepancy (KSD) optimize kernel hyperparameters on a
held-out sample via data splitting to obtain the most powerful test statistics.
While data splitting results in a tractable null distribution, it suffers from
a reduction in test power due to smaller test sample size. Inspired by the
selective inference framework, we propose an approach that enables learning the
hyperparameters and testing on the full sample without data splitting. Our
approach can correctly calibrate the test in the presence of such dependency,
and yield a test threshold in closed form. At the same significance level, our
approach's test power is empirically larger than that of the data-splitting
approach, regardless of its split proportion.
</p>
<a href="http://arxiv.org/abs/2006.02286" target="_blank">arXiv:2006.02286</a> [<a href="http://arxiv.org/pdf/2006.02286" target="_blank">pdf</a>]

<h2>Distributionally Robust $k$-Nearest Neighbors for Few-Shot Learning. (arXiv:2006.04004v2 [stat.ML] UPDATED)</h2>
<h3>Shixiang Zhu, Liyan Xie, Minghe Zhang, Rui Gao, Yao Xie</h3>
<p>Learning a robust classifier from a few samples remains a key challenge in
machine learning. A major thrust of research in classification with few
training samples has been based on metric learning to capture similarities
between samples and then perform the $k$-nearest neighbor algorithm. To make
such an algorithm more robust, in this paper, we propose a distributionally
robust $k$-nearest neighbor algorithm Dr.k-NN, which features assigning minimax
optimal weights to training samples when performing classification. We also
couple it with neural-network-based feature embedding. We demonstrate the
competitive performance of our algorithm comparing to the state-of-the-art in
the few-training-sample setting with various real-data experiments.
</p>
<a href="http://arxiv.org/abs/2006.04004" target="_blank">arXiv:2006.04004</a> [<a href="http://arxiv.org/pdf/2006.04004" target="_blank">pdf</a>]

<h2>Ethical Considerations and Statistical Analysis of Industry Involvement in Machine Learning Research. (arXiv:2006.04541v2 [cs.CY] UPDATED)</h2>
<h3>Thilo Hagendorff, Kristof Meding</h3>
<p>Industry involvement in the machine learning (ML) community seems to be
increasing. However, the quantitative scale and ethical implications of this
influence are rather unknown. For this purpose, we have not only carried out an
informed ethical analysis of the field, but have inspected all papers of the
main ML conferences NeurIPS, CVPR, and ICML of the last 5 years - almost 11,000
papers in total. Our statistical approach focuses on conflicts of interest,
innovation and gender equality. We have obtained four main findings: (1)
Academic-corporate collaborations are growing in numbers. At the same time, we
found that conflicts of interest are rarely disclosed. (2) Industry publishes
papers about trending ML topics on average two years earlier than academia
does. (3) Industry papers are not lagging behind academic papers in regard to
social impact considerations. (4) Finally, we demonstrate that industrial
papers fall short of their academic counterparts with respect to the ratio of
gender diversity. We believe that this work is a starting point for an informed
debate within and outside of the ML community.
</p>
<a href="http://arxiv.org/abs/2006.04541" target="_blank">arXiv:2006.04541</a> [<a href="http://arxiv.org/pdf/2006.04541" target="_blank">pdf</a>]

<h2>Secure Byzantine-Robust Machine Learning. (arXiv:2006.04747v2 [cs.LG] UPDATED)</h2>
<h3>Lie He, Sai Praneeth Karimireddy, Martin Jaggi</h3>
<p>Increasingly machine learning systems are being deployed to edge servers and
devices (e.g. mobile phones) and trained in a collaborative manner. Such
distributed/federated/decentralized training raises a number of concerns about
the robustness, privacy, and security of the procedure. While extensive work
has been done in tackling with robustness, privacy, or security individually,
their combination has rarely been studied. In this paper, we propose a secure
two-server protocol that offers both input privacy and Byzantine-robustness. In
addition, this protocol is communication-efficient, fault-tolerant and enjoys
local differential privacy.
</p>
<a href="http://arxiv.org/abs/2006.04747" target="_blank">arXiv:2006.04747</a> [<a href="http://arxiv.org/pdf/2006.04747" target="_blank">pdf</a>]

<h2>Pointer Graph Networks. (arXiv:2006.06380v2 [stat.ML] UPDATED)</h2>
<h3>Petar Veli&#x10d;kovi&#x107;, Lars Buesing, Matthew C. Overlan, Razvan Pascanu, Oriol Vinyals, Charles Blundell</h3>
<p>Graph neural networks (GNNs) are typically applied to static graphs that are
assumed to be known upfront. This static input structure is often informed
purely by insight of the machine learning practitioner, and might not be
optimal for the actual task the GNN is solving. In absence of reliable domain
expertise, one might resort to inferring the latent graph structure, which is
often difficult due to the vast search space of possible graphs. Here we
introduce Pointer Graph Networks (PGNs) which augment sets or graphs with
additional inferred edges for improved model generalisation ability. PGNs allow
each node to dynamically point to another node, followed by message passing
over these pointers. The sparsity of this adaptable graph structure makes
learning tractable while still being sufficiently expressive to simulate
complex algorithms. Critically, the pointing mechanism is directly supervised
to model long-term sequences of operations on classical data structures,
incorporating useful structural inductive biases from theoretical computer
science. Qualitatively, we demonstrate that PGNs can learn parallelisable
variants of pointer-based data structures, namely disjoint set unions and
link/cut trees. PGNs generalise out-of-distribution to 5x larger test inputs on
dynamic graph connectivity tasks, outperforming unrestricted GNNs and Deep
Sets.
</p>
<a href="http://arxiv.org/abs/2006.06380" target="_blank">arXiv:2006.06380</a> [<a href="http://arxiv.org/pdf/2006.06380" target="_blank">pdf</a>]

<h2>Investigating the Impact of Pre-processing and Prediction Aggregation on the DeepFake Detection Task. (arXiv:2006.07084v3 [cs.CV] UPDATED)</h2>
<h3>Polychronis Charitidis, Giorgos Kordopatis-Zilos, Symeon Papadopoulos, Ioannis Kompatsiaris</h3>
<p>Recent advances in content generation technologies (widely known as
DeepFakes) along with the online proliferation of manipulated media content
render the detection of such manipulations a task of increasing importance.
Even though there are many DeepFake detection methods, only a few focus on the
impact of dataset preprocessing and the aggregation of frame-level to
video-level prediction on model performance. In this paper, we propose a
pre-processing step to improve the training data quality and examine its effect
on the performance of DeepFake detection. We also propose and evaluate the
effect of video-level prediction aggregation approaches. Experimental results
show that the proposed pre-processing approach leads to considerable
improvements in the performance of detection models, and the proposed
prediction aggregation scheme further boosts the detection efficiency in cases
where there are multiple faces in a video.
</p>
<a href="http://arxiv.org/abs/2006.07084" target="_blank">arXiv:2006.07084</a> [<a href="http://arxiv.org/pdf/2006.07084" target="_blank">pdf</a>]

<h2>The OARF Benchmark Suite: Characterization and Implications for Federated Learning Systems. (arXiv:2006.07856v2 [cs.LG] UPDATED)</h2>
<h3>Sixu Hu, Yuan Li, Xu Liu, Qinbin Li, Zhaomin Wu, Bingsheng He</h3>
<p>This paper presents and characterizes an Open Application Repository for
Federated Learning (OARF), a benchmark suite for federated machine learning
systems. Previously available benchmarks for federated learning have focused
mainly on synthetic datasets and use a very limited number of applications.
OARF includes different data partitioning methods (horizontal, vertical and
hybrid) as well as emerging applications in image, text and structured data,
which represent different scenarios in federated learning. Our characterization
shows that the benchmark suite is diverse in data size, distribution, feature
distribution and learning task complexity. We have developed reference
implementations, and evaluated the important aspects of federated learning,
including model accuracy, communication cost, differential privacy, secure
multiparty computation and vertical federated learning.
</p>
<a href="http://arxiv.org/abs/2006.07856" target="_blank">arXiv:2006.07856</a> [<a href="http://arxiv.org/pdf/2006.07856" target="_blank">pdf</a>]

<h2>ChestX-Det10: Chest X-ray Dataset on Detection of Thoracic Abnormalities. (arXiv:2006.10550v3 [eess.IV] UPDATED)</h2>
<h3>Jingyu Liu, Jie Lian, Yizhou Yu</h3>
<p>Instance level detection of thoracic diseases or abnormalities are crucial
for automatic diagnosis in chest X-ray images. Most existing works on chest
X-rays focus on disease classification and weakly supervised localization. In
order to push forward the research on disease classification and localization
on chest X-rays. We provide a new benchmark called ChestX-Det10, including
box-level annotations of 10 categories of disease/abnormality of $\sim$ 3,500
images. The annotations are located at
https://github.com/Deepwise-AILab/ChestX-Det10-Dataset.
</p>
<a href="http://arxiv.org/abs/2006.10550" target="_blank">arXiv:2006.10550</a> [<a href="http://arxiv.org/pdf/2006.10550" target="_blank">pdf</a>]

<h2>Adaptive Learning Rates with Maximum Variation Averaging. (arXiv:2006.11918v2 [cs.LG] UPDATED)</h2>
<h3>Chen Zhu, Yu Cheng, Zhe Gan, Furong Huang, Jingjing Liu, Tom Goldstein</h3>
<p>Adaptive gradient methods such as RMSProp and Adam use exponential moving
estimate of the squared gradient to compute coordinate-wise adaptive step
sizes, achieving better convergence than SGD in face of noisy objectives.
However, Adam can have undesirable convergence behavior due to unstable or
extreme adaptive learning rates. Methods such as AMSGrad and AdaBound have been
proposed to stabilize the adaptive learning rates of Adam in the later stage of
training, but they do not outperform Adam in some practical tasks such as
training Transformers. In this paper, we propose an adaptive learning rate
principle, in which the running mean of squared gradient is replaced by a
weighted mean, with weights chosen to maximize the estimated variance of each
coordinate. This gives a worst-case estimate for the local gradient variance,
taking smaller steps when large curvatures or noisy gradients are present,
which leads to more desirable convergence behavior than Adam. We prove the
proposed algorithm converges under mild assumptions for nonconvex stochastic
optimization problems, and demonstrate the improved efficacy of our adaptive
averaging approach on image classification, machine translation and natural
language understanding tasks. Moreover, our method overcomes the
non-convergence issue of Adam in BERT pretraining at large batch sizes, while
achieving better test performance than LAMB in the same setting. The code is
available at https://github.com/zhuchen03/MaxVA.
</p>
<a href="http://arxiv.org/abs/2006.11918" target="_blank">arXiv:2006.11918</a> [<a href="http://arxiv.org/pdf/2006.11918" target="_blank">pdf</a>]

<h2>Bidirectional Self-Normalizing Neural Networks. (arXiv:2006.12169v2 [cs.LG] UPDATED)</h2>
<h3>Yao Lu, Stephen Gould, Thalaiyasingam Ajanthan</h3>
<p>The problem of vanishing and exploding gradients has been a long-standing
obstacle that hinders the effective training of neural networks. Despite
various tricks and techniques that have been employed to alleviate the problem
in practice, there still lacks satisfactory theories or provable solutions. In
this paper, we address the problem from the perspective of high-dimensional
probability theory. We provide a rigorous result that shows, under mild
conditions, how the vanishing/exploding gradients problem disappears with high
probability if the neural networks have sufficient width. Our main idea is to
constrain both forward and backward signal propagation in a nonlinear neural
network through a new class of activation functions, namely Gaussian-Poincar\'e
normalized functions, and orthogonal weight matrices. Experiments on both
synthetic and real-world data validate our theory and confirm its effectiveness
on very deep neural networks when applied in practice.
</p>
<a href="http://arxiv.org/abs/2006.12169" target="_blank">arXiv:2006.12169</a> [<a href="http://arxiv.org/pdf/2006.12169" target="_blank">pdf</a>]

<h2>Distribution-Based Invariant Deep Networks for Learning Meta-Features. (arXiv:2006.13708v2 [stat.ML] UPDATED)</h2>
<h3>Gwendoline De Bie, Herilalaina Rakotoarison, Gabriel Peyr&#xe9;, Mich&#xe8;le Sebag</h3>
<p>Recent advances in deep learning from probability distributions successfully
achieve classification or regression from distribution samples, thus invariant
under permutation of the samples. The first contribution of the paper is to
extend these neural architectures to achieve invariance under permutation of
the features, too. The proposed architecture, called Dida, inherits the NN
properties of universal approximation, and its robustness w.r.t.
Lipschitz-bounded transformations of the input distribution is established. The
second contribution is to empirically and comparatively demonstrate the merits
of the approach on two tasks defined at the dataset level. On both tasks, Dida
learns meta-features supporting the characterization of a (labelled) dataset.
The first task consists of predicting whether two dataset patches are extracted
from the same initial dataset. The second task consists of predicting whether
the learning performance achieved by a hyper-parameter configuration under a
fixed algorithm (ranging in k-NN, SVM, logistic regression and linear
classifier with SGD) dominates that of another configuration, for a dataset
extracted from the OpenML benchmarking suite. On both tasks, Dida outperforms
the state of the art: DSS (Maron et al., 2020) and Dataset2Vec (Jomaa et al.,
2019) architectures, as well as the models based on the hand-crafted
meta-features of the literature.
</p>
<a href="http://arxiv.org/abs/2006.13708" target="_blank">arXiv:2006.13708</a> [<a href="http://arxiv.org/pdf/2006.13708" target="_blank">pdf</a>]

<h2>Subpopulation Data Poisoning Attacks. (arXiv:2006.14026v2 [cs.LG] UPDATED)</h2>
<h3>Matthew Jagielski, Giorgio Severi, Niklas Pousette Harger, Alina Oprea</h3>
<p>Machine learning systems are deployed in critical settings, but they might
fail in unexpected ways, impacting the accuracy of their predictions. Poisoning
attacks against machine learning induce adversarial modification of data used
by a machine learning algorithm to selectively change its output when it is
deployed. In this work, we introduce a novel data poisoning attack called a
\emph{subpopulation attack}, which is particularly relevant when datasets are
large and diverse. We design a modular framework for subpopulation attacks,
instantiate it with different building blocks, and show that the attacks are
effective for a variety of datasets and machine learning models. We further
optimize the attacks in continuous domains using influence functions and
gradient optimization methods. Compared to existing backdoor poisoning attacks,
subpopulation attacks have the advantage of inducing misclassification in
naturally distributed data points at inference time, making the attacks
extremely stealthy. Our impossibility result for defending against
subpopulation attacks and the limitations of existing defenses highlight the
difficulty of protecting machine learning against this new threat vector.
</p>
<a href="http://arxiv.org/abs/2006.14026" target="_blank">arXiv:2006.14026</a> [<a href="http://arxiv.org/pdf/2006.14026" target="_blank">pdf</a>]

<h2>Efficient computation and analysis of distributional Shapley values. (arXiv:2007.01357v2 [stat.ML] UPDATED)</h2>
<h3>Yongchan Kwon, Manuel A. Rivas, James Zou</h3>
<p>Distributional data Shapley value (DShapley) has recently been proposed as a
principled framework to quantify the contribution of individual datum in
machine learning. DShapley develops the foundational game theory concept of
Shapley values into a statistical framework and can be applied to identify data
points that are useful (or harmful) to a learning algorithm. Estimating
DShapley is computationally expensive, however, and this can be a major
challenge to using it in practice. Moreover, there has been little mathematical
analyses of how this value depends on data characteristics. In this paper, we
derive the first analytic expressions for DShapley for the canonical problems
of linear regression, binary classification, and non-parametric density
estimation. These analytic forms provide new algorithms to estimate DShapley
that are several orders of magnitude faster than previous state-of-the-art
methods. Furthermore, our formulas are directly interpretable and provide
quantitative insights into how the value varies for different types of data. We
demonstrate the practical efficacy of our approach on multiple real and
synthetic datasets.
</p>
<a href="http://arxiv.org/abs/2007.01357" target="_blank">arXiv:2007.01357</a> [<a href="http://arxiv.org/pdf/2007.01357" target="_blank">pdf</a>]

<h2>Automated and Formal Synthesis of Neural Barrier Certificates for Dynamical Models. (arXiv:2007.03251v2 [eess.SY] UPDATED)</h2>
<h3>Andrea Peruffo, Daniele Ahmed, Alessandro Abate</h3>
<p>We introduce an automated, formal, counterexample-based approach to
synthesise Barrier Certificates (BC) for the safety verification of continuous
and hybrid dynamical models. The approach is underpinned by an inductive
framework: this is structured as a sequential loop between a learner, which
manipulates a candidate BC structured as a neural network, and a sound
verifier, which either certifies the candidate's validity or generates
counter-examples to further guide the learner. We compare the approach against
state-of-the-art techniques, over polynomial and non-polynomial dynamical
models: the outcomes show that we can synthesise sound BCs up to two orders of
magnitude faster, with in particular a stark speedup on the verification engine
(up to five orders less), whilst needing a far smaller data set (up to three
orders less) for the learning part. Beyond improvements over the state of the
art, we further challenge the new approach on a hybrid dynamical model and on
larger-dimensional models, and showcase the numerical robustness of our
algorithms and codebase.
</p>
<a href="http://arxiv.org/abs/2007.03251" target="_blank">arXiv:2007.03251</a> [<a href="http://arxiv.org/pdf/2007.03251" target="_blank">pdf</a>]

<h2>NVAE: A Deep Hierarchical Variational Autoencoder. (arXiv:2007.03898v2 [stat.ML] UPDATED)</h2>
<h3>Arash Vahdat, Jan Kautz</h3>
<p>Normalizing flows, autoregressive models, variational autoencoders (VAEs),
and deep energy-based models are among competing likelihood-based frameworks
for deep generative learning. Among them, VAEs have the advantage of fast and
tractable sampling and easy-to-access encoding networks. However, they are
currently outperformed by other models such as normalizing flows and
autoregressive models. While the majority of the research in VAEs is focused on
the statistical challenges, we explore the orthogonal direction of carefully
designing neural architectures for hierarchical VAEs. We propose Nouveau VAE
(NVAE), a deep hierarchical VAE built for image generation using depth-wise
separable convolutions and batch normalization. NVAE is equipped with a
residual parameterization of Normal distributions and its training is
stabilized by spectral regularization. We show that NVAE achieves
state-of-the-art results among non-autoregressive likelihood-based models on
the MNIST, CIFAR-10, CelebA 64, and CelebA HQ datasets and it provides a strong
baseline on FFHQ. For example, on CIFAR-10, NVAE pushes the state-of-the-art
from 2.98 to 2.91 bits per dimension, and it produces high-quality images on
CelebA HQ. To the best of our knowledge, NVAE is the first successful VAE
applied to natural images as large as 256$\times$256 pixels. The source code is
available at https://github.com/NVlabs/NVAE .
</p>
<a href="http://arxiv.org/abs/2007.03898" target="_blank">arXiv:2007.03898</a> [<a href="http://arxiv.org/pdf/2007.03898" target="_blank">pdf</a>]

<h2>Learning Retrospective Knowledge with Reverse Reinforcement Learning. (arXiv:2007.06703v2 [cs.LG] UPDATED)</h2>
<h3>Shangtong Zhang, Vivek Veeriah, Shimon Whiteson</h3>
<p>We present a Reverse Reinforcement Learning (Reverse RL) approach for
representing retrospective knowledge. General Value Functions (GVFs) have
enjoyed great success in representing predictive knowledge, i.e., answering
questions about possible future outcomes such as "how much fuel will be
consumed in expectation if we drive from A to B?". GVFs, however, cannot answer
questions like "how much fuel do we expect a car to have given it is at B at
time $t$?". To answer this question, we need to know when that car had a full
tank and how that car came to B. Since such questions emphasize the influence
of possible past events on the present, we refer to their answers as
retrospective knowledge. In this paper, we show how to represent retrospective
knowledge with Reverse GVFs, which are trained via Reverse RL. We demonstrate
empirically the utility of Reverse GVFs in both representation learning and
anomaly detection.
</p>
<a href="http://arxiv.org/abs/2007.06703" target="_blank">arXiv:2007.06703</a> [<a href="http://arxiv.org/pdf/2007.06703" target="_blank">pdf</a>]

<h2>Deep Learning modeling of Limit Order Book: a comparative perspective. (arXiv:2007.07319v3 [q-fin.TR] UPDATED)</h2>
<h3>Antonio Briola, Jeremy Turiel, Tomaso Aste</h3>
<p>The present work addresses theoretical and practical questions in the domain
of Deep Learning for High Frequency Trading. State-of-the-art models such as
Random models, Logistic Regressions, LSTMs, LSTMs equipped with an Attention
mask, CNN-LSTMs and MLPs are reviewed and compared on the same tasks, feature
space and dataset, and then clustered according to pairwise similarity and
performance metrics. The underlying dimensions of the modeling techniques are
hence investigated to understand whether these are intrinsic to the Limit Order
Book's dynamics. We observe that the Multilayer Perceptron performs comparably
to or better than state-of-the-art CNN-LSTM architectures indicating that
dynamic spatial and temporal dimensions are a good approximation of the LOB's
dynamics, but not necessarily the true underlying dimensions.
</p>
<a href="http://arxiv.org/abs/2007.07319" target="_blank">arXiv:2007.07319</a> [<a href="http://arxiv.org/pdf/2007.07319" target="_blank">pdf</a>]

<h2>Adversarial Immunization for Improving Certifiable Robustness on Graphs. (arXiv:2007.09647v2 [cs.LG] UPDATED)</h2>
<h3>Shuchang Tao, Huawei Shen, Qi Cao, Liang Hou, Xueqi Cheng</h3>
<p>Despite achieving strong performance in the semi-supervised node
classification task, graph neural networks (GNNs) are vulnerable to adversarial
attacks, similar to other deep learning models. Existing research works either
focus on developing defense models or explore certifiable robustness under GNNs
against adversarial attacks. However, little research attention is paid to the
potential and practice of immunization to adversarial attacks on graphs. In
this paper, we formulate the problem of graph adversarial immunization} as a
bilevel optimization problem, i.e., vaccinating a fraction of node pairs,
connected or unconnected, to improve the certifiable robustness of graph
against any admissible adversarial attack. We further propose an efficient
algorithm with meta-gradient in a discrete way to circumvent the
computationally expensive combinatorial optimization when solving the
adversarial immunization problem. Experiments are conducted on two citation
networks and one social network. Experimental results demonstrate that the
proposed adversarial immunization method remarkably improves the fraction of
robust nodes by 14%-50%, with an affordable immune budget of only 3.2% edges.
</p>
<a href="http://arxiv.org/abs/2007.09647" target="_blank">arXiv:2007.09647</a> [<a href="http://arxiv.org/pdf/2007.09647" target="_blank">pdf</a>]

<h2>Quantifying Model Uncertainty in Inverse Problems via Bayesian Deep Gradient Descent. (arXiv:2007.09971v2 [cs.CV] UPDATED)</h2>
<h3>Riccardo Barbano, Chen Zhang, Simon Arridge, Bangti Jin</h3>
<p>Recent advances in reconstruction methods for inverse problems leverage
powerful data-driven models, e.g., deep neural networks. These techniques have
demonstrated state-of-the-art performances for several imaging tasks, but they
often do not provide uncertainty on the obtained reconstruction. In this work,
we develop a scalable, data-driven, knowledge-aided computational framework to
quantify the model uncertainty via Bayesian neural networks. The approach
builds on, and extends deep gradient descent, a recently developed greedy
iterative training scheme, and recasts it within a probabilistic framework.
Scalability is achieved by being hybrid in the architecture: only the last
layer of each block is Bayesian, while the others remain deterministic, and by
being greedy in training. The framework is showcased on one representative
medical imaging modality, viz. computed tomography with either sparse view or
limited view data, and exhibits competitive performance with respect to
state-of-the-art benchmarks, e.g., total variation, deep gradient descent and
learned primal-dual.
</p>
<a href="http://arxiv.org/abs/2007.09971" target="_blank">arXiv:2007.09971</a> [<a href="http://arxiv.org/pdf/2007.09971" target="_blank">pdf</a>]

<h2>The Lottery Ticket Hypothesis for Pre-trained BERT Networks. (arXiv:2007.12223v2 [cs.LG] UPDATED)</h2>
<h3>Tianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia Liu, Yang Zhang, Zhangyang Wang, Michael Carbin</h3>
<p>In natural language processing (NLP), enormous pre-trained models like BERT
have become the standard starting point for training on a range of downstream
tasks, and similar trends are emerging in other areas of deep learning. In
parallel, work on the lottery ticket hypothesis has shown that models for NLP
and computer vision contain smaller matching subnetworks capable of training in
isolation to full accuracy and transferring to other tasks. In this work, we
combine these observations to assess whether such trainable, transferrable
subnetworks exist in pre-trained BERT models. For a range of downstream tasks,
we indeed find matching subnetworks at 40% to 90% sparsity. We find these
subnetworks at (pre-trained) initialization, a deviation from prior NLP
research where they emerge only after some amount of training. Subnetworks
found on the masked language modeling task (the same task used to pre-train the
model) transfer universally; those found on other tasks transfer in a limited
fashion if at all. As large-scale pre-training becomes an increasingly central
paradigm in deep learning, our results demonstrate that the main lottery ticket
observations remain relevant in this context. Codes available at
https://github.com/VITA-Group/BERT-Tickets.
</p>
<a href="http://arxiv.org/abs/2007.12223" target="_blank">arXiv:2007.12223</a> [<a href="http://arxiv.org/pdf/2007.12223" target="_blank">pdf</a>]

<h2>CAMPs: Learning Context-Specific Abstractions for Efficient Planning in Factored MDPs. (arXiv:2007.13202v2 [cs.LG] UPDATED)</h2>
<h3>Rohan Chitnis, Tom Silver, Beomjoon Kim, Leslie Pack Kaelbling, Tomas Lozano-Perez</h3>
<p>Meta-planning, or learning to guide planning from experience, is a promising
approach to improving the computational cost of planning. A general
meta-planning strategy is to learn to impose constraints on the states
considered and actions taken by the agent. We observe that (1) imposing a
constraint can induce context-specific independences that render some aspects
of the domain irrelevant, and (2) an agent can take advantage of this fact by
imposing constraints on its own behavior. These observations lead us to propose
the context-specific abstract Markov decision process (CAMP), an abstraction of
a factored MDP that affords efficient planning. We then describe how to learn
constraints to impose so the CAMP optimizes a trade-off between rewards and
computational cost. Our experiments consider five planners across four domains,
including robotic navigation among movable obstacles (NAMO), robotic task and
motion planning for sequential manipulation, and classical planning. We find
planning with learned CAMPs to consistently outperform baselines, including
Stilman's NAMO-specific algorithm. Video: https://youtu.be/wTXt6djcAd4 Code:
https://git.io/JTnf6
</p>
<a href="http://arxiv.org/abs/2007.13202" target="_blank">arXiv:2007.13202</a> [<a href="http://arxiv.org/pdf/2007.13202" target="_blank">pdf</a>]

<h2>Neural Compression and Filtering for Edge-assisted Real-time Object Detection in Challenged Networks. (arXiv:2007.15818v2 [cs.CV] UPDATED)</h2>
<h3>Yoshitomo Matsubara, Marco Levorato</h3>
<p>The edge computing paradigm places compute-capable devices - edge servers -
at the network edge to assist mobile devices in executing data analysis tasks.
Intuitively, offloading compute-intense tasks to edge servers can reduce their
execution time. However, poor conditions of the wireless channel connecting the
mobile devices to the edge servers may degrade the overall capture-to-output
delay achieved by edge offloading. Herein, we focus on edge computing
supporting remote object detection by means of Deep Neural Networks (DNNs), and
develop a framework to reduce the amount of data transmitted over the wireless
link. The core idea we propose builds on recent approaches splitting DNNs into
sections - namely head and tail models - executed by the mobile device and edge
server, respectively. The wireless link, then, is used to transport the output
of the last layer of the head model to the edge server, instead of the DNN
input. Most prior work focuses on classification tasks and leaves the DNN
structure unaltered. Herein, our focus is on DNNs for three different object
detection tasks, which present a much more convoluted structure, and modify the
architecture of the network to: (i) achieve in-network compression by
introducing a bottleneck layer in the early layers on the head model, and (ii)
prefilter pictures that do not contain objects of interest using a
convolutional neural network. Results show that the proposed technique
represents an effective intermediate option between local and edge computing in
a parameter region where these extreme point solutions fail to provide
satisfactory performance. The code and trained models are available at
https://github.com/yoshitomo-matsubara/hnd-ghnd-object-detectors .
</p>
<a href="http://arxiv.org/abs/2007.15818" target="_blank">arXiv:2007.15818</a> [<a href="http://arxiv.org/pdf/2007.15818" target="_blank">pdf</a>]

<h2>Learning to Rank for Active Learning: A Listwise Approach. (arXiv:2008.00078v2 [cs.CV] UPDATED)</h2>
<h3>Minghan Li, Xialei Liu, Joost van de Weijer, Bogdan Raducanu</h3>
<p>Active learning emerged as an alternative to alleviate the effort to label
huge amount of data for data hungry applications (such as image/video indexing
and retrieval, autonomous driving, etc.). The goal of active learning is to
automatically select a number of unlabeled samples for annotation (according to
a budget), based on an acquisition function, which indicates how valuable a
sample is for training the model. The learning loss method is a task-agnostic
approach which attaches a module to learn to predict the target loss of
unlabeled data, and select data with the highest loss for labeling. In this
work, we follow this strategy but we define the acquisition function as a
learning to rank problem and rethink the structure of the loss prediction
module, using a simple but effective listwise approach. Experimental results on
four datasets demonstrate that our method outperforms recent state-of-the-art
active learning approaches for both image classification and regression tasks.
</p>
<a href="http://arxiv.org/abs/2008.00078" target="_blank">arXiv:2008.00078</a> [<a href="http://arxiv.org/pdf/2008.00078" target="_blank">pdf</a>]

<h2>Self-supervised Learning of Point Clouds via Orientation Estimation. (arXiv:2008.00305v2 [cs.CV] UPDATED)</h2>
<h3>Omid Poursaeed, Tianxing Jiang, Han Qiao, Nayun Xu, Vladimir G. Kim</h3>
<p>Point clouds provide a compact and efficient representation of 3D shapes.
While deep neural networks have achieved impressive results on point cloud
learning tasks, they require massive amounts of manually labeled data, which
can be costly and time-consuming to collect. In this paper, we leverage 3D
self-supervision for learning downstream tasks on point clouds with fewer
labels. A point cloud can be rotated in infinitely many ways, which provides a
rich label-free source for self-supervision. We consider the auxiliary task of
predicting rotations that in turn leads to useful features for other tasks such
as shape classification and 3D keypoint prediction. Using experiments on
ShapeNet and ModelNet, we demonstrate that our approach outperforms the
state-of-the-art. Moreover, features learned by our model are complementary to
other self-supervised methods and combining them leads to further performance
improvement.
</p>
<a href="http://arxiv.org/abs/2008.00305" target="_blank">arXiv:2008.00305</a> [<a href="http://arxiv.org/pdf/2008.00305" target="_blank">pdf</a>]

<h2>AUTSL: A Large Scale Multi-modal Turkish Sign Language Dataset and Baseline Methods. (arXiv:2008.00932v2 [cs.CV] UPDATED)</h2>
<h3>Ozge Mercanoglu Sincan, Hacer Yalim Keles</h3>
<p>Sign language recognition is a challenging problem where signs are identified
by simultaneous local and global articulations of multiple sources, i.e. hand
shape and orientation, hand movements, body posture, and facial expressions.
Solving this problem computationally for a large vocabulary of signs in real
life settings is still a challenge, even with the state-of-the-art models. In
this study, we present a new largescale multi-modal Turkish Sign Language
dataset (AUTSL) with a benchmark and provide baseline models for performance
evaluations. Our dataset consists of 226 signs performed by 43 different
signers and 38,336 isolated sign video samples in total. Samples contain a wide
variety of backgrounds recorded in indoor and outdoor environments. Moreover,
spatial positions and the postures of signers also vary in the recordings. Each
sample is recorded with Microsoft Kinect v2 and contains RGB, depth, and
skeleton modalities. We prepared benchmark training and test sets for user
independent assessments of the models. We trained several deep learning based
models and provide empirical evaluations using the benchmark; we used CNNs to
extract features, unidirectional and bidirectional LSTM models to characterize
temporal information. We also incorporated feature pooling modules and temporal
attention to our models to improve the performances. We evaluated our baseline
models on AUTSL and Montalbano datasets. Our models achieved competitive
results with the state-of-the-art methods on Montalbano dataset, i.e. 96.11%
accuracy. In AUTSL random train-test splits, our models performed up to 95.95%
accuracy. In the proposed user-independent benchmark dataset our best baseline
model achieved 62.02% accuracy. The gaps in the performances of the same
baseline models show the challenges inherent in our benchmark dataset. AUTSL
benchmark dataset is publicly available at https://cvml.ankara.edu.tr.
</p>
<a href="http://arxiv.org/abs/2008.00932" target="_blank">arXiv:2008.00932</a> [<a href="http://arxiv.org/pdf/2008.00932" target="_blank">pdf</a>]

<h2>GloDyNE: Global Topology Preserving Dynamic Network Embedding. (arXiv:2008.01935v2 [cs.SI] UPDATED)</h2>
<h3>Chengbin Hou, Han Zhang, Shan He, Ke Tang</h3>
<p>Learning low-dimensional topological representation of a network in dynamic
environments is attracting much attention due to the time-evolving nature of
many real-world networks. The main and common objective of Dynamic Network
Embedding (DNE) is to efficiently update node embeddings while preserving
network topology at each time step. The idea of most existing DNE methods is to
capture the topological changes at or around the most affected nodes (instead
of all nodes) and accordingly update node embeddings. Unfortunately, this kind
of approximation, although can improve efficiency, cannot effectively preserve
the global topology of a dynamic network at each time step, due to not
considering the inactive sub-networks that receive accumulated topological
changes propagated via the high-order proximity. To tackle this challenge, we
propose a novel node selecting strategy to diversely select the representative
nodes over a network, which is coordinated with a new incremental learning
paradigm of Skip-Gram based embedding approach. The extensive experiments show
GloDyNE, with a small fraction of nodes being selected, can already achieve the
superior or comparable performance w.r.t. the state-of-the-art DNE methods in
three typical downstream tasks. Particularly, GloDyNE significantly outperforms
other methods in the graph reconstruction task, which demonstrates its ability
of global topology preservation. The source code is available at
https://github.com/houchengbin/GloDyNE
</p>
<a href="http://arxiv.org/abs/2008.01935" target="_blank">arXiv:2008.01935</a> [<a href="http://arxiv.org/pdf/2008.01935" target="_blank">pdf</a>]

<h2>Offline Meta Learning of Exploration. (arXiv:2008.02598v2 [cs.LG] UPDATED)</h2>
<h3>Ron Dorfman, Aviv Tamar</h3>
<p>Consider the following problem: given the complete training histories of $N$
conventional RL agents, trained on $N$ different tasks, design a meta-agent
that can quickly maximize reward in a new, unseen task from the same task
distribution. In particular, while each conventional RL agent explored and
exploited its own different task, the meta-agent must identify regularities in
the data that lead to effective exploration/exploitation in the unseen task.
This meta-learning problem is an instance of a setting we term Offline Meta
Reinforcement Learning (OMRL). To solve our challenge, we take a Bayesian RL
(BRL) view, and seek to learn a Bayes-optimal policy from the offline data. We
extend the recently proposed VariBAD BRL algorithm to the off-policy setting,
and demonstrate learning of approximately Bayes-optimal exploration strategies
from offline data using deep neural networks. For the particular problem
described above, our method learns effective exploration behavior that is
qualitatively different from the exploration used by any RL agent in the data.
Furthermore, we find that when applied to the online meta-RL setting (agent
simultaneously collects data and improves its meta-RL policy), our method is
significantly more sample efficient than the state-of-the-art VariBAD.
</p>
<a href="http://arxiv.org/abs/2008.02598" target="_blank">arXiv:2008.02598</a> [<a href="http://arxiv.org/pdf/2008.02598" target="_blank">pdf</a>]

<h2>Nighttime Dehazing with a Synthetic Benchmark. (arXiv:2008.03864v3 [cs.CV] UPDATED)</h2>
<h3>Jing Zhang, Yang Cao, Zheng-Jun Zha, Dacheng Tao</h3>
<p>Increasing the visibility of nighttime hazy images is challenging because of
uneven illumination from active artificial light sources and haze
absorbing/scattering. The absence of large-scale benchmark datasets hampers
progress in this area. To address this issue, we propose a novel synthetic
method called 3R to simulate nighttime hazy images from daytime clear images,
which first reconstructs the scene geometry, then simulates the light rays and
object reflectance, and finally renders the haze effects. Based on it, we
generate realistic nighttime hazy images by sampling real-world light colors
from a prior empirical distribution. Experiments on the synthetic benchmark
show that the degrading factors jointly reduce the image quality. To address
this issue, we propose an optimal-scale maximum reflectance prior to
disentangle the color correction from haze removal and address them
sequentially. Besides, we also devise a simple but effective learning-based
baseline which has an encoder-decoder structure based on the MobileNet-v2
backbone. Experiment results demonstrate their superiority over
state-of-the-art methods in terms of both image quality and runtime. Both the
dataset and source code will be available at https://github.com/chaimi2013/3R.
</p>
<a href="http://arxiv.org/abs/2008.03864" target="_blank">arXiv:2008.03864</a> [<a href="http://arxiv.org/pdf/2008.03864" target="_blank">pdf</a>]

<h2>ARCADe: A Rapid Continual Anomaly Detector. (arXiv:2008.04042v2 [cs.LG] UPDATED)</h2>
<h3>Ahmed Frikha, Denis Krompa&#xdf;, Volker Tresp</h3>
<p>Although continual learning and anomaly detection have separately been
well-studied in previous works, their intersection remains rather unexplored.
The present work addresses a learning scenario where a model has to
incrementally learn a sequence of anomaly detection tasks, i.e. tasks from
which only examples from the normal (majority) class are available for
training. We define this novel learning problem of continual anomaly detection
(CAD) and formulate it as a meta-learning problem. Moreover, we propose A Rapid
Continual Anomaly Detector (ARCADe), an approach to train neural networks to be
robust against the major challenges of this new learning problem, namely
catastrophic forgetting and overfitting to the majority class. The results of
our experiments on three datasets show that, in the CAD problem setting, ARCADe
substantially outperforms baselines from the continual learning and anomaly
detection literature. Finally, we provide deeper insights into the learning
strategy yielded by the proposed meta-learning algorithm.
</p>
<a href="http://arxiv.org/abs/2008.04042" target="_blank">arXiv:2008.04042</a> [<a href="http://arxiv.org/pdf/2008.04042" target="_blank">pdf</a>]

<h2>PLACE: Proximity Learning of Articulation and Contact in 3D Environments. (arXiv:2008.05570v2 [cs.CV] UPDATED)</h2>
<h3>Siwei Zhang, Yan Zhang, Qianli Ma, Michael J. Black, Siyu Tang</h3>
<p>High fidelity digital 3D environments have been proposed in recent years,
however, it remains extremely challenging to automatically equip such
environment with realistic human bodies. Existing work utilizes images, depth
or semantic maps to represent the scene, and parametric human models to
represent 3D bodies. While being straightforward, their generated human-scene
interactions are often lack of naturalness and physical plausibility. Our key
observation is that humans interact with the world through body-scene contact.
To synthesize realistic human-scene interactions, it is essential to
effectively represent the physical contact and proximity between the body and
the world. To that end, we propose a novel interaction generation method, named
PLACE (Proximity Learning of Articulation and Contact in 3D Environments),
which explicitly models the proximity between the human body and the 3D scene
around it. Specifically, given a set of basis points on a scene mesh, we
leverage a conditional variational autoencoder to synthesize the minimum
distances from the basis points to the human body surface. The generated
proximal relationship exhibits which region of the scene is in contact with the
person. Furthermore, based on such synthesized proximity, we are able to
effectively obtain expressive 3D human bodies that interact with the 3D scene
naturally. Our perceptual study shows that PLACE significantly improves the
state-of-the-art method, approaching the realism of real human-scene
interaction. We believe our method makes an important step towards the fully
automatic synthesis of realistic 3D human bodies in 3D scenes. The code and
model are available for research at
https://sanweiliti.github.io/PLACE/PLACE.html.
</p>
<a href="http://arxiv.org/abs/2008.05570" target="_blank">arXiv:2008.05570</a> [<a href="http://arxiv.org/pdf/2008.05570" target="_blank">pdf</a>]

<h2>OR-Gym: A Reinforcement Learning Library for Operations Research Problems. (arXiv:2008.06319v2 [cs.AI] UPDATED)</h2>
<h3>Christian D. Hubbs, Hector D. Perez, Owais Sarwar, Nikolaos V. Sahinidis, Ignacio E. Grossmann, John M. Wassick</h3>
<p>Reinforcement learning (RL) has been widely applied to game-playing and
surpassed the best human-level performance in many domains, yet there are few
use-cases in industrial or commercial settings. We introduce OR-Gym, an
open-source library for developing reinforcement learning algorithms to address
operations research problems. In this paper, we apply reinforcement learning to
the knapsack, multi-dimensional bin packing, multi-echelon supply chain, and
multi-period asset allocation model problems, as well as benchmark the RL
solutions against MILP and heuristic models. These problems are used in
logistics, finance, engineering, and are common in many business operation
settings. We develop environments based on prototypical models in the
literature and implement various optimization and heuristic models in order to
benchmark the RL results. By re-framing a series of classic optimization
problems as RL tasks, we seek to provide a new tool for the operations research
community, while also opening those in the RL community to many of the problems
and challenges in the OR field.
</p>
<a href="http://arxiv.org/abs/2008.06319" target="_blank">arXiv:2008.06319</a> [<a href="http://arxiv.org/pdf/2008.06319" target="_blank">pdf</a>]

<h2>Learning Affordance Landscapes for Interaction Exploration in 3D Environments. (arXiv:2008.09241v2 [cs.CV] UPDATED)</h2>
<h3>Tushar Nagarajan, Kristen Grauman</h3>
<p>Embodied agents operating in human spaces must be able to master how their
environment works: what objects can the agent use, and how can it use them? We
introduce a reinforcement learning approach for exploration for interaction,
whereby an embodied agent autonomously discovers the affordance landscape of a
new unmapped 3D environment (such as an unfamiliar kitchen). Given an
egocentric RGB-D camera and a high-level action space, the agent is rewarded
for maximizing successful interactions while simultaneously training an
image-based affordance segmentation model. The former yields a policy for
acting efficiently in new environments to prepare for downstream interaction
tasks, while the latter yields a convolutional neural network that maps image
regions to the likelihood they permit each action, densifying the rewards for
exploration. We demonstrate our idea with AI2-iTHOR. The results show agents
can learn how to use new home environments intelligently and that it prepares
them to rapidly address various downstream tasks like "find a knife and put it
in the drawer." Project page:
this http URL
</p>
<a href="http://arxiv.org/abs/2008.09241" target="_blank">arXiv:2008.09241</a> [<a href="http://arxiv.org/pdf/2008.09241" target="_blank">pdf</a>]

<h2>NAS-Bench-301 and the Case for Surrogate Benchmarks for Neural Architecture Search. (arXiv:2008.09777v2 [cs.LG] UPDATED)</h2>
<h3>Julien Siems, Lucas Zimmer, Arber Zela, Jovita Lukasik, Margret Keuper, Frank Hutter</h3>
<p>The most significant barrier to the advancement of Neural Architecture Search
(NAS) is its demand for large computational resources, which hinders
scientifically sound empirical evaluations. As a remedy, several tabular NAS
benchmarks were proposed to simulate runs of NAS methods in seconds. However,
all existing tabular NAS benchmarks are limited to extremely small
architectural spaces since they rely on exhaustive evaluations of the space.
This leads to unrealistic results that do not transfer to larger search spaces.
To overcome this fundamental limitation, we propose NAS-Bench-301, the first
surrogate NAS benchmark, using a search space containing $10^{18}$
architectures, many orders of magnitude larger than any previous tabular NAS
benchmark. After motivating the benefits of a surrogate benchmark over a
tabular one, we fit various regression models on our dataset, which consists of
$\sim$60k architecture evaluations, and build surrogates via deep ensembles to
also model uncertainty. We benchmark a wide range of NAS algorithms using
NAS-Bench-301 and obtain comparable results to the true benchmark at a fraction
of the real cost. Finally, we show how NAS-Bench-301 can be used to generate
new scientific insights.
</p>
<a href="http://arxiv.org/abs/2008.09777" target="_blank">arXiv:2008.09777</a> [<a href="http://arxiv.org/pdf/2008.09777" target="_blank">pdf</a>]

<h2>A Framework for Quantifying Controversy of Social Network Debates Using Attributed Networks: Biased Random Walk (BRW). (arXiv:2008.11453v4 [cs.SI] UPDATED)</h2>
<h3>Hanif Emamgholizadeh, Milad Nourizade, Mir Saman Tajbakhsh, Mahdieh Hashminezhad, Farzaneh Nasr Esfahani</h3>
<p>All societies have been much more bipolar over the past few years,
particularly after the emergence of online social networks and media. In fact,
the gap between the two ends of social spectrum is going to be even deeper
after the spread of new media. In this circumstance, social polarization has
been a growing concern among socialists and computer science experts because of
the detrimental impact which online social networks can have on societies by
adding fuel to the fire of extremism. Several types of research were conducted
for proposing measures to calculate the controversy level in social networks,
afterward, to reduce controversy among contradicting viewpoints, for example,
by exposing opinions of one side to other side's members. Most of the attempts
for quantifying social networks' controversy have considered the networks in
their most primary forms, without any attributes. Although these kinds of
researches provide platform-free algorithms to be used in different social
networks, they are not able to take into account a great deal of useful
information provided by users (node attributes).To surmount this shortcoming,
we propose a framework to be utilized in different networks with different
attributes. We propelled some Biased Random Walks (BRW) to find their path from
start point to an initially unknown endpoint with respect to initial energy of
start node and energy loss of nodes on the path. We extracted structural
attribute of networks, using node2vec, and compared it with state-of-the-art
algorithms, and showed its accuracy. Then, we extracted some content attributes
of user and analyze their effects on the results of our algorithm. BRW is
compared with another state-of-the-art controversy measuring algorithm. Then,
its changes in different level of controversy in Persian Twitter is considered
to show how it works in different circumstance.
</p>
<a href="http://arxiv.org/abs/2008.11453" target="_blank">arXiv:2008.11453</a> [<a href="http://arxiv.org/pdf/2008.11453" target="_blank">pdf</a>]

<h2>Planning in Learned Latent Action Spaces for Generalizable Legged Locomotion. (arXiv:2008.11867v3 [cs.RO] UPDATED)</h2>
<h3>Tianyu Li, Roberto Calandra, Deepak Pathak, Yuandong Tian, Franziska Meier, Akshara Rai</h3>
<p>Hierarchical learning has been successful at learning generalizable
locomotion skills on walking robots in a sample-efficient manner. However, the
low-dimensional "latent" action used to communicate between the two layers of
the hierarchy is typically user-designed. In this work, we present a
fully-learned hierarchical framework, that is capable of jointly learning the
low-level controller and the high-level latent action space. Once this latent
space is learned, we plan over continuous latent actions in a model-predictive
control fashion, using a learned high-level dynamics model. This framework
generalizes to multiple robots, and we present results on a Daisy hexapod
simulation, A1 quadruped simulation, and Daisy robot hardware. We compare a
range of learned hierarchical approaches from literature, and show that our
framework outperforms baselines on multiple tasks and two simulations. In
addition to learning approaches, we also compare to inverse-kinematics (IK)
acting on planned footsteps, and show that our fully-learned framework
outperforms IK in adverse settings on both A1 and Daisy simulations. On
hardware, we show the Daisy hexapod achieving multiple locomotion tasks, such
as goal reaching, trajectory and velocity tracking in an unstructured outdoor
setting, with only 2000 hardware samples, reinforcing the robustness and
sample-efficiency of our approach.
</p>
<a href="http://arxiv.org/abs/2008.11867" target="_blank">arXiv:2008.11867</a> [<a href="http://arxiv.org/pdf/2008.11867" target="_blank">pdf</a>]

<h2>Generalization on the Enhancement of Layerwise Relevance Interpretability of Deep Neural Network. (arXiv:2009.02516v2 [cs.CV] UPDATED)</h2>
<h3>Erico Tjoa, Guan Cuntai</h3>
<p>The practical application of deep neural networks are still limited by their
lack of transparency. One of the efforts to provide explanation for decisions
made by artificial intelligence (AI) is the use of saliency or heat maps
highlighting relevant regions that contribute significantly to its prediction.
A layer-wise amplitude filtering method was previously introduced to improve
the quality of heatmaps, performing error corrections by noise-spike
suppression. In this study, we generalize the layerwise error correction by
considering any identifiable error and assuming there exists a groundtruth
interpretable information. The forms of errors propagated through layerwise
relevance methods are studied and we propose a filtering technique for
interpretability signal rectification taylored to the trend of signal amplitude
of the particular neural network used. Finally, we put forth arguments for the
use of groundtruth interpretable information.
</p>
<a href="http://arxiv.org/abs/2009.02516" target="_blank">arXiv:2009.02516</a> [<a href="http://arxiv.org/pdf/2009.02516" target="_blank">pdf</a>]

<h2>Information Theoretic Counterfactual Learning from Missing-Not-At-Random Feedback. (arXiv:2009.02623v2 [cs.LG] UPDATED)</h2>
<h3>Zifeng Wang, Xi Chen, Rui Wen, Shao-Lun Huang, Ercan E. Kuruoglu, Yefeng Zheng</h3>
<p>Counterfactual learning for dealing with missing-not-at-random data (MNAR) is
an intriguing topic in the recommendation literature since MNAR data are
ubiquitous in modern recommender systems. Missing-at-random (MAR) data, namely
randomized controlled trials (RCTs), are usually required by most previous
counterfactual learning methods for debiasing learning. However, the execution
of RCTs is extraordinarily expensive in practice. To circumvent the use of
RCTs, we build an information-theoretic counterfactual variational information
bottleneck (CVIB), as an alternative for debiasing learning without RCTs. By
separating the task-aware mutual information term in the original information
bottleneck Lagrangian into factual and counterfactual parts, we derive a
contrastive information loss and an additional output confidence penalty, which
facilitates balanced learning between the factual and counterfactual domains.
Empirical evaluation on real-world datasets shows that our CVIB significantly
enhances both shallow and deep models, which sheds light on counterfactual
learning in recommendation that goes beyond RCTs.
</p>
<a href="http://arxiv.org/abs/2009.02623" target="_blank">arXiv:2009.02623</a> [<a href="http://arxiv.org/pdf/2009.02623" target="_blank">pdf</a>]

<h2>Blockchain-based Federated Learning for Device Failure Detection in Industrial IoT. (arXiv:2009.02643v2 [cs.DC] UPDATED)</h2>
<h3>Weishan Zhang, Qinghua Lu, Qiuyu Yu, Zhaotong Li, Yue Liu, Sin Kit Lo, Shiping Chen, Xiwei Xu, Liming Zhu</h3>
<p>Device failure detection is one of most essential problems in industrial
internet of things (IIoT). However, in conventional IIoT device failure
detection, client devices need to upload raw data to the central server for
model training, which might lead to disclosure of sensitive business data.
Therefore, in this paper, to ensure client data privacy, we propose a
blockchain-based federated learning approach for device failure detection in
IIoT. First, we present a platform architecture of blockchain-based federated
learning systems for failure detection in IIoT, which enables verifiable
integrity of client data. In the architecture, each client periodically creates
a Merkle tree in which each leaf node represents a client data record, and
stores the tree root on a blockchain. Further, to address the data
heterogeneity issue in IIoT failure detection, we propose a novel centroid
distance weighted federated averaging (CDW\_FedAvg) algorithm taking into
account the distance between positive class and negative class of each client
dataset. In addition, to motivate clients to participate in federated learning,
a smart contact based incentive mechanism is designed depending on the size and
the centroid distance of client data used in local model training. A prototype
of the proposed architecture is implemented with our industry partner, and
evaluated in terms of feasibility, accuracy and performance. The results show
that the approach is feasible, and has satisfactory accuracy and performance.
</p>
<a href="http://arxiv.org/abs/2009.02643" target="_blank">arXiv:2009.02643</a> [<a href="http://arxiv.org/pdf/2009.02643" target="_blank">pdf</a>]

<h2>Themes Informed Audio-visual Correspondence Learning. (arXiv:2009.06573v2 [cs.AI] UPDATED)</h2>
<h3>Runze Su, Fei Tao, Xudong Liu, Haoran Wei, Xiaorong Mei, Zhiyao Duan, Lei Yuan, Ji Liu, Yuying Xie</h3>
<p>The applications of short-term user-generated video (UGV), such as Snapchat,
and Youtube short-term videos, booms recently, raising lots of multimodal
machine learning tasks. Among them, learning the correspondence between audio
and visual information from videos is a challenging one. Most previous work of
the audio-visual correspondence(AVC) learning only investigated constrained
videos or simple settings, which may not fit the application of UGV. In this
paper, we proposed new principles for AVC and introduced a new framework to set
sight of videos' themes to facilitate AVC learning. We also released the
KWAI-AD-AudVis corpus which contained 85432 short advertisement videos (around
913 hours) made by users. We evaluated our proposed approach on this corpus,
and it was able to outperform the baseline by 23.15% absolute difference.
</p>
<a href="http://arxiv.org/abs/2009.06573" target="_blank">arXiv:2009.06573</a> [<a href="http://arxiv.org/pdf/2009.06573" target="_blank">pdf</a>]

<h2>Multi-Referenced Training for Dialogue Response Generation. (arXiv:2009.07117v2 [cs.CL] UPDATED)</h2>
<h3>Tianyu Zhao, Tatsuya Kawahara</h3>
<p>In open-domain dialogue response generation, a dialogue context can be
continued with diverse responses, and the dialogue models should capture such
one-to-many relations. In this work, we first analyze the training objective of
dialogue models from the view of Kullback-Leibler divergence (KLD) and show
that the gap between the real world probability distribution and the
single-referenced data's probability distribution prevents the model from
learning the one-to-many relations efficiently. Then we explore approaches to
multi-referenced training in two aspects. Data-wise, we generate diverse pseudo
references from a powerful pretrained model to build multi-referenced data that
provides a better approximation of the real-world distribution. Model-wise, we
propose to equip variational models with an expressive prior, named linear
Gaussian model (LGM). Experimental results of automated evaluation and human
evaluation show that the methods yield significant improvements over baselines.
We will release our code and data in
https://github.com/ZHAOTING/dialog-processing.
</p>
<a href="http://arxiv.org/abs/2009.07117" target="_blank">arXiv:2009.07117</a> [<a href="http://arxiv.org/pdf/2009.07117" target="_blank">pdf</a>]

<h2>MSP: An FPGA-Specific Mixed-Scheme, Multi-Precision Deep Neural Network Quantization Framework. (arXiv:2009.07460v2 [cs.LG] UPDATED)</h2>
<h3>Sung-En Chang, Yanyu Li, Mengshu Sun, Weiwen Jiang, Runbin Shi, Xue Lin, Yanzhi Wang</h3>
<p>With the tremendous success of deep learning, there exists imminent need to
deploy deep learning models onto edge devices. To tackle the limited computing
and storage resources in edge devices, model compression techniques have been
widely used to trim deep neural network (DNN) models for on-device inference
execution. This paper targets the commonly used FPGA (field programmable gate
array) devices as the hardware platforms for DNN edge computing. We focus on
the DNN quantization as the main model compression technique, since DNN
quantization has been of great importance for the implementations of DNN models
on the hardware platforms. The novelty of this work comes in twofold: (i) We
propose a mixed-scheme DNN quantization method that incorporates both the
linear and non-linear number systems for quantization, with the aim to boost
the utilization of the heterogeneous computing resources, i.e., LUTs (look up
tables) and DSPs (digital signal processors) on an FPGA. Note that all the
existing (single-scheme) quantization methods can only utilize one type of
resources (either LUTs or DSPs for the MAC (multiply-accumulate) operations in
deep learning computations. (ii) We use a quantization method that supports
multiple precisions along the intra-layer dimension, while the existing
quantization methods apply multi-precision quantization along the inter-layer
dimension. The intra-layer multi-precision method can uniform the hardware
configurations for different layers to reduce computation overhead and at the
same time preserve the model accuracy as the inter-layer approach.
</p>
<a href="http://arxiv.org/abs/2009.07460" target="_blank">arXiv:2009.07460</a> [<a href="http://arxiv.org/pdf/2009.07460" target="_blank">pdf</a>]

<h2>Recurrent Graph Tensor Networks. (arXiv:2009.08727v3 [cs.LG] UPDATED)</h2>
<h3>Yao Lei Xu, Danilo P. Mandic</h3>
<p>Recurrent Neural Networks (RNNs) are among the most successful machine
learning models for sequence modelling. In this paper, we show that the
modelling of hidden states in RNNs can be approximated through a multi-linear
graph filter, which describes the directional flow of temporal information. The
so derived multi-linear graph filter is then generalized to a tensor network
form to improve its modelling power, resulting in a novel Recurrent Graph
Tensor Network (RGTN). To validate the expressive power of the derived network,
several variants of RGTN models were proposed and employed for the task of
time-series forecasting, demonstrating superior properties in terms of
convergence, performance, and complexity. By leveraging the multi-modal nature
of tensor networks, RGTN models were shown to out-perform a standard RNN by 23%
in terms of mean-squared-error while using up to 86% less parameters.
Therefore, by combining the expressive power of tensor networks with a suitable
graph filter, we show that the proposed RGTN models can out-perform a classical
RNN at a drastically lower parameter complexity, especially in the multi-modal
setting.
</p>
<a href="http://arxiv.org/abs/2009.08727" target="_blank">arXiv:2009.08727</a> [<a href="http://arxiv.org/pdf/2009.08727" target="_blank">pdf</a>]

<h2>Self-Supervised Learning of Non-Rigid Residual Flow and Ego-Motion. (arXiv:2009.10467v2 [cs.CV] UPDATED)</h2>
<h3>Ivan Tishchenko, Sandro Lombardi, Martin R. Oswald, Marc Pollefeys</h3>
<p>Most of the current scene flow methods choose to model scene flow as a per
point translation vector without differentiating between static and dynamic
components of 3D motion. In this work we present an alternative method for
end-to-end scene flow learning by joint estimation of non-rigid residual flow
and ego-motion flow for dynamic 3D scenes. We propose to learn the relative
rigid transformation from a pair of point clouds followed by an iterative
refinement. We then learn the non-rigid flow from transformed inputs with the
deducted rigid part of the flow. Furthermore, we extend the supervised
framework with self-supervisory signals based on the temporal consistency
property of a point cloud sequence. Our solution allows both training in a
supervised mode complemented by self-supervisory loss terms as well as training
in a fully self-supervised mode. We demonstrate that decomposition of scene
flow into non-rigid flow and ego-motion flow along with an introduction of the
self-supervisory signals allowed us to outperform the current state-of-the-art
supervised methods.
</p>
<a href="http://arxiv.org/abs/2009.10467" target="_blank">arXiv:2009.10467</a> [<a href="http://arxiv.org/pdf/2009.10467" target="_blank">pdf</a>]

<h2>Learning in a Small/Big World. (arXiv:2009.11917v5 [econ.TH] UPDATED)</h2>
<h3>Benson Tsz Kin Leung</h3>
<p>Savage (1972) lays down the foundation of Bayesian decision theory, but
asserts that it is not applicable in big worlds where the environment is
complex. Using the theory of finite automaton to model belief formation, this
paper studies the characteristics of optimal learning behavior in small and big
worlds, where the complexity of the environment is low and high, respectively,
relative to the cognitive ability of the decision maker. Confirming Savage's
claim, optimal learning behavior is closed to Bayesian in small worlds but
significantly different in big worlds. In addition, I show that in big worlds,
the optimal learning behavior could exhibit a wide range of well-documented
non-Bayesian learning behavior, including the use of heuristic, correlation
neglect, persistent over-confidence, inattentive learning, and other behaviors
of model simplification or misspecification. These results establish a clear
and testable relationship between the prominence of non-Bayesian learning
behavior, complexity and cognitive ability.
</p>
<a href="http://arxiv.org/abs/2009.11917" target="_blank">arXiv:2009.11917</a> [<a href="http://arxiv.org/pdf/2009.11917" target="_blank">pdf</a>]

<h2>Learning to Stop: A Simple yet Effective Approach to Urban Vision-Language Navigation. (arXiv:2009.13112v3 [cs.CV] UPDATED)</h2>
<h3>Jiannan Xiang, Xin Eric Wang, William Yang Wang</h3>
<p>Vision-and-Language Navigation (VLN) is a natural language grounding task
where an agent learns to follow language instructions and navigate to specified
destinations in real-world environments. A key challenge is to recognize and
stop at the correct location, especially for complicated outdoor environments.
Existing methods treat the STOP action equally as other actions, which results
in undesirable behaviors that the agent often fails to stop at the destination
even though it might be on the right path. Therefore, we propose Learning to
Stop (L2Stop), a simple yet effective policy module that differentiates STOP
and other actions. Our approach achieves the new state of the art on a
challenging urban VLN dataset Touchdown, outperforming the baseline by 6.89%
(absolute improvement) on Success weighted by Edit Distance (SED).
</p>
<a href="http://arxiv.org/abs/2009.13112" target="_blank">arXiv:2009.13112</a> [<a href="http://arxiv.org/pdf/2009.13112" target="_blank">pdf</a>]

<h2>Toward Privacy and Utility Preserving Image Representation. (arXiv:2009.14376v2 [cs.CV] UPDATED)</h2>
<h3>Ahmadreza Mosallanezhad, Yasin N. Silva, Michelle V. Mancenido, Huan Liu</h3>
<p>Face images are rich data items that are useful and can easily be collected
in many applications, such as in 1-to-1 face verification tasks in the domain
of security and surveillance systems. Multiple methods have been proposed to
protect an individual's privacy by perturbing the images to remove traces of
identifiable information, such as gender or race. However, significantly less
attention has been given to the problem of protecting images while maintaining
optimal task utility. In this paper, we study the novel problem of creating
privacy-preserving image representations with respect to a given utility task
by proposing a principled framework called the Adversarial Image Anonymizer
(AIA). AIA first creates an image representation using a generative model, then
enhances the learned image representations using adversarial learning to
preserve privacy and utility for a given task. Experiments were conducted on a
publicly available data set to demonstrate the effectiveness of AIA as a
privacy-preserving mechanism for face images.
</p>
<a href="http://arxiv.org/abs/2009.14376" target="_blank">arXiv:2009.14376</a> [<a href="http://arxiv.org/pdf/2009.14376" target="_blank">pdf</a>]

<h2>Training Data Augmentation for Deep Learning RF Systems. (arXiv:2010.00178v2 [cs.LG] UPDATED)</h2>
<h3>William H. Clark IV, Steven Hauser, William C. Headley, Alan J. Michaels</h3>
<p>Applications of machine learning are subject to three major components that
contribute to the final performance metrics. Within the specifics of neural
networks, and deep learning specifically, the first two are the architecture
for the model being trained and the training approach used. This work focuses
on the third component, the data being used during training. The questions that
arise are then "what is in the data" and "what within the data matters?"
Looking into the Radio Frequency Machine Learning (RFML) field of Modulation
Classification, the use of synthetic, captured, and augmented data are examined
and compared to provide insights about the quantity and quality of the
available data presented. In general, all three data types have useful
contributions to a final application, but captured data germane to the intended
use case will always provide more significant information and enable the
greatest performance. Despite the benefit of captured data, the difficulties
that arise from collection often make the quantity of data needed to achieve
peak performance impractical. This paper helps quantify the balance between
real and synthetic data, offering concrete examples where training data is
parametrically varied in size and source.
</p>
<a href="http://arxiv.org/abs/2010.00178" target="_blank">arXiv:2010.00178</a> [<a href="http://arxiv.org/pdf/2010.00178" target="_blank">pdf</a>]

<h2>Model-sharing Games: Analyzing Federated Learning Under Voluntary Participation. (arXiv:2010.00753v2 [cs.GT] UPDATED)</h2>
<h3>Kate Donahue, Jon Kleinberg</h3>
<p>Federated learning is a setting where agents, each with access to their own
data source, combine models learned from local data to create a global model.
If agents are drawing their data from different distributions, though,
federated learning might produce a biased global model that is not optimal for
each agent. This means that agents face a fundamental question: should they
join the global model or stay with their local model? In this work, we show how
this situation can be naturally analyzed through the framework of coalitional
game theory.

Motivated by these considerations, we propose the following game: there are
heterogeneous players with different model parameters governing their data
distribution and different amounts of data they have noisily drawn from their
own distribution. Each player's goal is to obtain a model with minimal expected
mean squared error (MSE) on their own distribution. They have a choice of
fitting a model based solely on their own data, or combining their learned
parameters with those of some subset of the other players. Combining models
reduces the variance component of their error through access to more data, but
increases the bias because of the heterogeneity of distributions. In this work,
we derive exact expected MSE values for problems in linear regression and mean
estimation. We use these values to analyze the resulting game in the framework
of hedonic game theory; we study how players might divide into coalitions,
where each set of players within a coalition jointly constructs a single model.
In a case with arbitrarily many players that each have either a "small" or
"large" amount of data, we constructively show that there always exists a
stable partition of players into coalitions.
</p>
<a href="http://arxiv.org/abs/2010.00753" target="_blank">arXiv:2010.00753</a> [<a href="http://arxiv.org/pdf/2010.00753" target="_blank">pdf</a>]

<h2>Machine learning approach to force reconstruction in photoelastic materials. (arXiv:2010.01163v2 [cs.CV] UPDATED)</h2>
<h3>Renat Sergazinov, Miroslav Kramar</h3>
<p>Photoelastic techniques have a long tradition in both qualitative and
quantitative analysis of the stresses in granular materials. Over the last two
decades, computational methods for reconstructing forces between particles from
their photoelastic response have been developed by many different experimental
teams. Unfortunately, all of these methods are computationally expensive. This
limits their use for processing extensive data sets that capture the time
evolution of granular ensembles consisting of a large number of particles. In
this paper, we present a novel approach to this problem which leverages the
power of convolutional neural networks to recognize complex spatial patterns.
The main drawback of using neural networks is that training them usually
requires a large labeled data set which is hard to obtain experimentally. We
show that this problem can be successfully circumvented by pretraining the
networks on a large synthetic data set and then fine-tuning them on much
smaller experimental data sets. Due to our current lack of experimental data,
we demonstrate the potential of our method by changing the size of the
considered particles which alters the exhibited photoelastic patterns more than
typical experimental errors.
</p>
<a href="http://arxiv.org/abs/2010.01163" target="_blank">arXiv:2010.01163</a> [<a href="http://arxiv.org/pdf/2010.01163" target="_blank">pdf</a>]

<h2>When in Doubt, Ask: Generating Answerable and Unanswerable Questions, Unsupervised. (arXiv:2010.01611v2 [cs.CL] UPDATED)</h2>
<h3>Liubov Nikolenko, Pouya Rezazadeh Kalehbasti</h3>
<p>Question Answering (QA) is key for making possible a robust communication
between human and machine. Modern language models used for QA have surpassed
the human-performance in several essential tasks; however, these models require
large amounts of human-generated training data which are costly and
time-consuming to create. This paper studies augmenting human-made datasets
with synthetic data as a way of surmounting this problem. A state-of-the-art
model based on deep transformers is used to inspect the impact of using
synthetic answerable and unanswerable questions to complement a well-known
human-made dataset. The results indicate a tangible improvement in the
performance of the language model (measured in terms of F1 and EM scores)
trained on the mixed dataset. Specifically, unanswerable question-answers prove
more effective in boosting the model: the F1 score gain from adding to the
original dataset the answerable, unanswerable, and combined question-answers
were 1.3%, 5.0%, and 6.7%, respectively. [Link to the Github repository:
https://github.com/lnikolenko/EQA]
</p>
<a href="http://arxiv.org/abs/2010.01611" target="_blank">arXiv:2010.01611</a> [<a href="http://arxiv.org/pdf/2010.01611" target="_blank">pdf</a>]

<h2>Towards Generalized and Distributed Privacy-Preserving Representation Learning. (arXiv:2010.01792v2 [cs.LG] UPDATED)</h2>
<h3>Sheikh Shams Azam, Taejin Kim, Seyyedali Hosseinalipour, Christopher Brinton, Carlee Joe-Wong, Saurabh Bagchi</h3>
<p>We study the problem of learning data representations that are private yet
informative, i.e., providing information about intended "ally" targets while
obfuscating sensitive "adversary" attributes. We propose a novel framework,
Exclusion-Inclusion Generative Adversarial Network (EIGAN), that generalizes
existing adversarial privacy-preserving representation learning (PPRL)
approaches to generate data encodings that account for multiple possibly
overlapping ally and adversary targets. Preserving privacy is even more
difficult when the data is collected across multiple distributed nodes, which
for privacy reasons may not wish to share their data even for PPRL training.
Thus, learning such data representations at each node in a distributed manner
(i.e., without transmitting source data) is of particular importance. This
motivates us to develop D-EIGAN, the first distributed PPRL method, based on
federated learning with fractional parameter sharing to account for
communication resource limitations. We theoretically analyze the behavior of
adversaries under the optimal EIGAN and D-EIGAN encoders and consider the
impact of dependencies among ally and adversary tasks on the encoder
performance. Our experiments on real-world and synthetic datasets demonstrate
the advantages of EIGAN encodings in terms of accuracy, robustness, and
scalability; in particular, we show that EIGAN outperforms the previous
state-of-the-art by a significant accuracy margin (47% improvement). The
experiments further reveal that D-EIGAN's performance is consistent with EIGAN
under different node data distributions and is resilient to communication
constraints.
</p>
<a href="http://arxiv.org/abs/2010.01792" target="_blank">arXiv:2010.01792</a> [<a href="http://arxiv.org/pdf/2010.01792" target="_blank">pdf</a>]

<h2>Graph Cross Networks with Vertex Infomax Pooling. (arXiv:2010.01804v2 [cs.LG] UPDATED)</h2>
<h3>Maosen Li, Siheng Chen, Ya Zhang, Ivor W. Tsang</h3>
<p>We propose a novel graph cross network (GXN) to achieve comprehensive feature
learning from multiple scales of a graph. Based on trainable hierarchical
representations of a graph, GXN enables the interchange of intermediate
features across scales to promote information flow. Two key ingredients of GXN
include a novel vertex infomax pooling (VIPool), which creates multiscale
graphs in a trainable manner, and a novel feature-crossing layer, enabling
feature interchange across scales. The proposed VIPool selects the most
informative subset of vertices based on the neural estimation of mutual
information between vertex features and neighborhood features. The intuition
behind is that a vertex is informative when it can maximally reflect its
neighboring information. The proposed feature-crossing layer fuses intermediate
features between two scales for mutual enhancement by improving information
flow and enriching multiscale features at hidden layers. The cross shape of the
feature-crossing layer distinguishes GXN from many other multiscale
architectures. Experimental results show that the proposed GXN improves the
classification accuracy by 2.12% and 1.15% on average for graph classification
and vertex classification, respectively. Based on the same network, the
proposed VIPool consistently outperforms other graph-pooling methods.
</p>
<a href="http://arxiv.org/abs/2010.01804" target="_blank">arXiv:2010.01804</a> [<a href="http://arxiv.org/pdf/2010.01804" target="_blank">pdf</a>]

<h2>Interpretable Machine Learning for COVID-19: An Empirical Study on Severity Prediction Task. (arXiv:2010.02006v2 [cs.LG] UPDATED)</h2>
<h3>Han Wu, Wenjie Ruan, Jiangtao Wang, Dingchang Zheng, Shaolin Li, Jian Chen, Kunwei Li, Xiangfei Chai, Sumi Helal</h3>
<p>Black-box nature hinders the deployment of many high-accuracy models in
medical diagnosis. It is risky to put one's life in the hands of models that
medical researchers do not trust. However, to understand the mechanism of a new
virus, such as COVID-19, machine learning models may catch important symptoms
that medical practitioners do not notice due to the surge of infected patients
during a pandemic.

In this work, the interpretation of machine learning models reveals that a
high C-reactive protein (CRP) corresponds to severe infection, and severe
patients usually go through a cardiac injury, which is consistent with
well-established medical knowledge. Additionally, through the interpretation of
machine learning models, we find phlegm and diarrhea are two important
symptoms, without which indicate a high risk of turning severe. These two
symptoms are not recognized at the early stage of the outbreak, whereas our
findings are corroborated by later autopsies of COVID-19 patients. We find
patients with a high N-terminal pro B-type natriuretic peptide (NTproBNP) have
a significantly increased risk of death which does not receive much attention
initially but proves true by the following-up study. Thus, we suggest
interpreting machine learning models can offer help to diagnosis at the early
stage of an outbreak.
</p>
<a href="http://arxiv.org/abs/2010.02006" target="_blank">arXiv:2010.02006</a> [<a href="http://arxiv.org/pdf/2010.02006" target="_blank">pdf</a>]

<h2>We Don't Speak the Same Language: Interpreting Polarization through Machine Translation. (arXiv:2010.02339v2 [cs.CL] UPDATED)</h2>
<h3>Ashiqur R. KhudaBukhsh, Rupak Sarkar, Mark S. Kamlet, Tom M. Mitchell</h3>
<p>Polarization among US political parties, media and elites is a widely studied
topic. Prominent lines of prior research across multiple disciplines have
observed and analyzed growing polarization in social media. In this paper, we
present a new methodology that offers a fresh perspective on interpreting
polarization through the lens of machine translation. With a novel proposition
that two sub-communities are speaking in two different \emph{languages}, we
demonstrate that modern machine translation methods can provide a simple yet
powerful and interpretable framework to understand the differences between two
(or more) large-scale social media discussion data sets at the granularity of
words. Via a substantial corpus of 86.6 million comments by 6.5 million users
on over 200,000 news videos hosted by YouTube channels of four prominent US
news networks, we demonstrate that simple word-level and phrase-level
translation pairs can reveal deep insights into the current political divide --
what is \emph{black lives matter} to one can be \emph{all lives matter} to the
other.
</p>
<a href="http://arxiv.org/abs/2010.02339" target="_blank">arXiv:2010.02339</a> [<a href="http://arxiv.org/pdf/2010.02339" target="_blank">pdf</a>]

<h2>Vision-Based Object Recognition in Indoor Environments Using Topologically Persistent Features. (arXiv:2010.03196v2 [cs.CV] UPDATED)</h2>
<h3>Ekta U. Samani, Xingjian Yang, Ashis G. Banerjee</h3>
<p>Object recognition in unseen indoor environments remains a challenging
problem for visual perception of mobile robots. In this letter, we propose the
use of topologically persistent features, which rely on the shape information
of the objects, to address this challenge. In particular, we extract two kinds
of features, namely, sparse persistence image (PI) and amplitude, by applying
persistent homology to multi-directional height function-based filtrations of
the cubical complexes representing the object segmentation maps. The features
are then used to train a fully connected network for recognition. For
performance evaluation, in addition to a widely-used shape dataset, we collect
a new dataset comprising scene images from two different environments, namely,
a living room and a mock warehouse. The scenes in both the environments include
up to five different objects that are chosen from a given set of fourteen
objects. The objects have varying poses and arrangements, and are imaged under
different illumination conditions and camera poses. The recognition performance
of our methods, which are trained using the living room images, remains
relatively unaffected on the unseen warehouse images. In contrast, the
performance of the state-of-the-art Faster R-CNN method decreases
significantly. In fact, the use of sparse PI features yields higher overall
recall and accuracy; and, better F1 scores on many of the individual object
classes. We also implement the proposed method on a real-world robot to
demonstrate its usefulness.
</p>
<a href="http://arxiv.org/abs/2010.03196" target="_blank">arXiv:2010.03196</a> [<a href="http://arxiv.org/pdf/2010.03196" target="_blank">pdf</a>]

<h2>Cross-lingual Extended Named Entity Classification of Wikipedia Articles. (arXiv:2010.03424v2 [cs.CL] UPDATED)</h2>
<h3>The Viet Bui, Phuong Le-Hong</h3>
<p>The FPT.AI team participated in the SHINRA2020-ML subtask of the NTCIR-15
SHINRA task. This paper describes our method to solving the problem and
discusses the official results. Our method focuses on learning cross-lingual
representations, both on the word level and document level for page
classification. We propose a three-stage approach including multilingual model
pre-training, monolingual model fine-tuning and cross-lingual voting. Our
system is able to achieve the best scores for 25 out of 30 languages; and its
accuracy gaps to the best performing systems of the other five languages are
relatively small.
</p>
<a href="http://arxiv.org/abs/2010.03424" target="_blank">arXiv:2010.03424</a> [<a href="http://arxiv.org/pdf/2010.03424" target="_blank">pdf</a>]

<h2>Are Adaptive Face Recognition Systems still Necessary? Experiments on the APE Dataset. (arXiv:2010.04072v2 [cs.CV] UPDATED)</h2>
<h3>Giulia Orr&#xf9;, Marco Micheletto, Julian Fierrez, Gian Luca Marcialis</h3>
<p>In the last five years, deep learning methods, in particular CNN, have
attracted considerable attention in the field of face-based recognition,
achieving impressive results. Despite this progress, it is not yet clear
precisely to what extent deep features are able to follow all the intra-class
variations that the face can present over time. In this paper we investigate
the performance the performance improvement of face recognition systems by
adopting self updating strategies of the face templates. For that purpose, we
evaluate the performance of a well-known deep-learning face representation,
namely, FaceNet, on a dataset that we generated explicitly conceived to embed
intra-class variations of users on a large time span of captures: the
APhotoEveryday (APE) dataset. Moreover, we compare these deep features with
handcrafted features extracted using the BSIF algorithm. In both cases, we
evaluate various template update strategies, in order to detect the most useful
for such kind of features. Experimental results show the effectiveness of
"optimized" self-update methods with respect to systems without update or
random selection of templates.
</p>
<a href="http://arxiv.org/abs/2010.04072" target="_blank">arXiv:2010.04072</a> [<a href="http://arxiv.org/pdf/2010.04072" target="_blank">pdf</a>]

<h2>comp-syn: Perceptually Grounded Word Embeddings with Color. (arXiv:2010.04292v2 [cs.CL] UPDATED)</h2>
<h3>Bhargav Srinivasa Desikan, Tasker Hull, Ethan O. Nadler, Douglas Guilbeault, Aabir Abubaker Kar, Mark Chu, Donald Ruggiero Lo Sardo</h3>
<p>Popular approaches to natural language processing create word embeddings
based on textual co-occurrence patterns, but often ignore embodied, sensory
aspects of language. Here, we introduce the Python package comp-syn, which
provides grounded word embeddings based on the perceptually uniform color
distributions of Google Image search results. We demonstrate that comp-syn
significantly enriches models of distributional semantics. In particular, we
show that (1) comp-syn predicts human judgments of word concreteness with
greater accuracy and in a more interpretable fashion than word2vec using
low-dimensional word-color embeddings, and (2) comp-syn performs comparably to
word2vec on a metaphorical vs. literal word-pair classification task. comp-syn
is open-source on PyPi and is compatible with mainstream machine-learning
Python packages. Our package release includes word-color embeddings for over
40,000 English words, each associated with crowd-sourced word concreteness
judgments.
</p>
<a href="http://arxiv.org/abs/2010.04292" target="_blank">arXiv:2010.04292</a> [<a href="http://arxiv.org/pdf/2010.04292" target="_blank">pdf</a>]

<h2>A Tensor Compiler for Unified Machine Learning Prediction Serving. (arXiv:2010.04804v3 [cs.LG] UPDATED)</h2>
<h3>Supun Nakandala, Karla Saur, Gyeong-In Yu, Konstantinos Karanasos, Carlo Curino, Markus Weimer, Matteo Interlandi</h3>
<p>Machine Learning (ML) adoption in the enterprise requires simpler and more
efficient software infrastructure---the bespoke solutions typical in large web
companies are simply untenable. Model scoring, the process of obtaining
predictions from a trained model over new data, is a primary contributor to
infrastructure complexity and cost as models are trained once but used many
times. In this paper we propose HUMMINGBIRD, a novel approach to model scoring,
which compiles featurization operators and traditional ML models (e.g.,
decision trees) into a small set of tensor operations. This approach inherently
reduces infrastructure complexity and directly leverages existing investments
in Neural Network compilers and runtimes to generate efficient computations for
both CPU and hardware accelerators. Our performance results are intriguing:
despite replacing imperative computations (e.g., tree traversals) with tensor
computation abstractions, HUMMINGBIRD is competitive and often outperforms
hand-crafted kernels on micro-benchmarks on both CPU and GPU, while enabling
seamless end-to-end acceleration of ML pipelines. We have released HUMMINGBIRD
as open source.
</p>
<a href="http://arxiv.org/abs/2010.04804" target="_blank">arXiv:2010.04804</a> [<a href="http://arxiv.org/pdf/2010.04804" target="_blank">pdf</a>]

<h2>Human-Supervised Semi-Autonomous Mobile Manipulators for Safely and Efficiently Executing Machine Tending Tasks. (arXiv:2010.04899v2 [cs.RO] UPDATED)</h2>
<h3>Sarah Al-Hussaini, Shantanu Thakar, Hyojeong Kim, Pradeep Rajendran, Brual C. Shah, Jeremy A. Marvel, Satyandra K. Gupta</h3>
<p>Mobile manipulators can be used for machine tending and material handling
tasks in small volume manufacturing applications. These applications usually
have semi-structured work environment. The use of a fully autonomous mobile
manipulator for such applications can be risky, as an inaccurate model of the
workspace may result in damage to expensive equipment. On the other hand, the
use of a fully teleoperated mobile manipulator may require a significant amount
of operator time. In this paper, a semi-autonomous mobile manipulator is
developed for safely and efficiently carrying out machine tending tasks under
human supervision. The robot is capable of generating motion plans from the
high-level task description and presenting simulation results to the human for
approval. The human operator can authorize the robot to execute the
automatically generated plan or provide additional input to the planner to
refine the plan. If the level of uncertainty in some parts of the workspace
model is high, then the human can decide to perform teleoperation to safely
execute the task. Our preliminary user trials show that non-expert operators
can quickly learn to use the system and perform machine tending tasks.
</p>
<a href="http://arxiv.org/abs/2010.04899" target="_blank">arXiv:2010.04899</a> [<a href="http://arxiv.org/pdf/2010.04899" target="_blank">pdf</a>]

<h2>Light Field Salient Object Detection: A Review and Benchmark. (arXiv:2010.04968v2 [cs.CV] UPDATED)</h2>
<h3>Yao Jiang, Tao Zhou, Ge-Peng Ji, Keren Fu, Qijun Zhao, Deng-Ping Fan</h3>
<p>Salient object detection (SOD) is a long-standing research topic in computer
vision and has drawn an increasing amount of research interest in the past
decade. This paper provides the first comprehensive review and benchmark for
SOD on light field, which has long been lacking in the saliency community.
Firstly, we introduce preliminary knowledge on lights, including theory and
data forms, and then review existing studies on light field SOD, covering ten
traditional models, seven deep learning-based models, one comparative study,
and one brief review. Existing datasets for light field SOD are also summarized
with detailed information and statistical analyses. Secondly, we benchmark
seven representative light field SOD models together with several cutting-edge
RGB-D SOD models on four widely used light field datasets, from which
insightful discussions and analyses, including a comparison between light field
SOD and RGB-D SOD models, are achieved. Besides, due to the inconsistency of
datasets in their current forms, we further generate complete data and
supplement focal stacks, depth maps and multi-view images for the inconsistent
datasets, making them consistent and unified. Our supplemental data makes a
universal benchmark possible. Lastly, because light field SOD is quite a
special problem attributed to its diverse data representations and high
dependency on acquisition hardware, making it differ greatly from other
saliency detection tasks, we provide nine hints into the challenges and future
directions, and outline several open issues. We hope our review and
benchmarking could serve as a catalyst to advance research in this field. All
the materials including collected models, datasets, benchmarking results, and
supplemented light field datasets will be publicly available on our project
site https://github.com/kerenfu/LFSOD-Survey.
</p>
<a href="http://arxiv.org/abs/2010.04968" target="_blank">arXiv:2010.04968</a> [<a href="http://arxiv.org/pdf/2010.04968" target="_blank">pdf</a>]

<h2>Software Sustainability & High Energy Physics. (arXiv:2010.05102v2 [hep-ex] UPDATED)</h2>
<h3>Daniel S. Katz, Sudhir Malik, Mark S. Neubauer, Graeme A. Stewart, K&#xe9;t&#xe9;vi A. Assamagan, Erin A. Becker, Neil P. Chue Hong, Ian A. Cosden, Samuel Meehan, Edward J. W. Moyse, Adrian M. Price-Whelan, Elizabeth Sexton-Kennedy, Meirin Oan Evans, Matthew Feickert, Clemens Lange, Kilian Lieret, Rob Quick, Arturo S&#xe1;nchez Pineda, Christopher Tunnell</h3>
<p>New facilities of the 2020s, such as the High Luminosity Large Hadron
Collider (HL-LHC), will be relevant through at least the 2030s. This means that
their software efforts and those that are used to analyze their data need to
consider sustainability to enable their adaptability to new challenges,
longevity, and efficiency, over at least this period. This will help ensure
that this software will be easier to develop and maintain, that it remains
available in the future on new platforms, that it meets new needs, and that it
is as reusable as possible. This report discusses a virtual half-day workshop
on "Software Sustainability and High Energy Physics" that aimed 1) to bring
together experts from HEP as well as those from outside to share their
experiences and practices, and 2) to articulate a vision that helps the
Institute for Research and Innovation in Software for High Energy Physics
(IRIS-HEP) to create a work plan to implement elements of software
sustainability. Software sustainability practices could lead to new
collaborations, including elements of HEP software being directly used outside
the field, and, as has happened more frequently in recent years, to HEP
developers contributing to software developed outside the field rather than
reinventing it. A focus on and skills related to sustainable software will give
HEP software developers an important skill that is essential to careers in the
realm of software, inside or outside HEP. The report closes with
recommendations to improve software sustainability in HEP, aimed at the HEP
community via IRIS-HEP and the HEP Software Foundation (HSF).
</p>
<a href="http://arxiv.org/abs/2010.05102" target="_blank">arXiv:2010.05102</a> [<a href="http://arxiv.org/pdf/2010.05102" target="_blank">pdf</a>]

<h2>Robust Fairness under Covariate Shift. (arXiv:2010.05166v2 [cs.LG] UPDATED)</h2>
<h3>Ashkan Rezaei, Anqi Liu, Omid Memarrast, Brian Ziebart</h3>
<p>Making predictions that are fair with regard to protected group membership
(race, gender, age, etc.) has become an important requirement for
classification algorithms. Existing techniques derive a fair model from sampled
labeled data relying on the assumption that training and testing data are
identically and independently drawn (iid) from the same distribution.In
practice, distribution shift can and does occur between training and testing
datasets as the characteristics of individuals interacting with the machine
learning system -- and which individuals interact with the system -- change. We
investigate fairness under covariate shift, a relaxation of the iid assumption
in which the inputs or covariates change while the conditional label
distribution remains the same. We seek fair decisions under these assumptions
on target data with unknown labels.We propose an approach that obtains the
predictor that is robust to the worst-case in terms of target performance while
satisfying target fairness requirements and matching statistical properties of
the source data. We demonstrate the benefits of our approach on benchmark
prediction tasks.
</p>
<a href="http://arxiv.org/abs/2010.05166" target="_blank">arXiv:2010.05166</a> [<a href="http://arxiv.org/pdf/2010.05166" target="_blank">pdf</a>]

<h2>DistDGL: Distributed Graph Neural Network Training for Billion-Scale Graphs. (arXiv:2010.05337v2 [cs.LG] UPDATED)</h2>
<h3>Da Zheng, Chao Ma, Minjie Wang, Jinjing Zhou, Qidong Su, Xiang Song, Quan Gan, Zheng Zhang, George Karypis</h3>
<p>Graph neural networks (GNN) have shown great success in learning from
graph-structured data. They are widely used in various applications, such as
recommendation, fraud detection, and search. In these domains, the graphs are
typically large, containing hundreds of millions of nodes and several billions
of edges. To tackle this challenge, we develop DistDGL, a system for training
GNNs in a mini-batch fashion on a cluster of machines. DistDGL is based on the
Deep Graph Library (DGL), a popular GNN development framework. DistDGL
distributes the graph and its associated data (initial features and embeddings)
across the machines and uses this distribution to derive a computational
decomposition by following an owner-compute rule. DistDGL follows a synchronous
training approach and allows ego-networks forming the mini-batches to include
non-local nodes. To minimize the overheads associated with distributed
computations, DistDGL uses a high-quality and light-weight min-cut graph
partitioning algorithm along with multiple balancing constraints. This allows
it to reduce communication overheads and statically balance the computations.
It further reduces the communication by replicating halo nodes and by using
sparse embedding updates. The combination of these design choices allows
DistDGL to train high-quality models while achieving high parallel efficiency
and memory scalability. We demonstrate our optimizations on both inductive and
transductive GNN models. Our results show that DistDGL achieves linear speedup
without compromising model accuracy and requires only 13 seconds to complete a
training epoch for a graph with 100 million nodes and 3 billion edges on a
cluster with 16 machines.
</p>
<a href="http://arxiv.org/abs/2010.05337" target="_blank">arXiv:2010.05337</a> [<a href="http://arxiv.org/pdf/2010.05337" target="_blank">pdf</a>]

<h2>Is Plug-in Solver Sample-Efficient for Feature-based Reinforcement Learning?. (arXiv:2010.05673v2 [cs.LG] UPDATED)</h2>
<h3>Qiwen Cui, Lin F. Yang</h3>
<p>It is believed that a model-based approach for reinforcement learning (RL) is
the key to reduce sample complexity. However, the understanding of the sample
optimality of model-based RL is still largely missing, even for the linear
case. This work considers sample complexity of finding an $\epsilon$-optimal
policy in a Markov decision process (MDP) that admits a linear additive feature
representation, given only access to a generative model. We solve this problem
via a plug-in solver approach, which builds an empirical model and plans in
this empirical model via an arbitrary plug-in solver. We prove that under the
anchor-state assumption, which implies implicit non-negativity in the feature
space, the minimax sample complexity of finding an $\epsilon$-optimal policy in
a $\gamma$-discounted MDP is $O(K/(1-\gamma)^3\epsilon^2)$, which only depends
on the dimensionality $K$ of the feature space and has no dependence on the
state or action space. We further extend our results to a relaxed setting where
anchor-states may not exist and show that a plug-in approach can be sample
efficient as well, providing a flexible approach to design model-based
algorithms for RL.
</p>
<a href="http://arxiv.org/abs/2010.05673" target="_blank">arXiv:2010.05673</a> [<a href="http://arxiv.org/pdf/2010.05673" target="_blank">pdf</a>]

<h2>How does Weight Correlation Affect the Generalisation Ability of Deep Neural Networks. (arXiv:2010.05983v3 [cs.LG] UPDATED)</h2>
<h3>Gaojie Jin, Xinping Yi, Liang Zhang, Lijun Zhang, Sven Schewe, Xiaowei Huang</h3>
<p>This paper studies the novel concept of weight correlation in deep neural
networks and discusses its impact on the networks' generalisation ability. For
fully-connected layers, the weight correlation is defined as the average cosine
similarity between weight vectors of neurons, and for convolutional layers, the
weight correlation is defined as the cosine similarity between filter matrices.
Theoretically, we show that, weight correlation can, and should, be
incorporated into the PAC Bayesian framework for the generalisation of neural
networks, and the resulting generalisation bound is monotonic with respect to
the weight correlation. We formulate a new complexity measure, which lifts the
PAC Bayes measure with weight correlation, and experimentally confirm that it
is able to rank the generalisation errors of a set of networks more precisely
than existing measures. More importantly, we develop a new regulariser for
training, and provide extensive experiments that show that the generalisation
error can be greatly reduced with our novel approach.
</p>
<a href="http://arxiv.org/abs/2010.05983" target="_blank">arXiv:2010.05983</a> [<a href="http://arxiv.org/pdf/2010.05983" target="_blank">pdf</a>]

<h2>Mitigating Gender Bias in Machine Translation with Target Gender Annotations. (arXiv:2010.06203v2 [cs.CL] UPDATED)</h2>
<h3>Art&#x16b;rs Stafanovi&#x10d;s, Toms Bergmanis, M&#x101;rcis Pinnis</h3>
<p>When translating "The secretary asked for details." to a language with
grammatical gender, it might be necessary to determine the gender of the
subject "secretary". If the sentence does not contain the necessary
information, it is not always possible to disambiguate. In such cases, machine
translation systems select the most common translation option, which often
corresponds to the stereotypical translations, thus potentially exacerbating
prejudice and marginalisation of certain groups and people. We argue that the
information necessary for an adequate translation can not always be deduced
from the sentence being translated or even might depend on external knowledge.
Therefore, in this work, we propose to decouple the task of acquiring the
necessary information from the task of learning to translate correctly when
such information is available. To that end, we present a method for training
machine translation systems to use word-level annotations containing
information about subject's gender. To prepare training data, we annotate
regular source language words with grammatical gender information of the
corresponding target language words. Using such data to train machine
translation systems reduces their reliance on gender stereotypes when
information about the subject's gender is available. Our experiments on five
language pairs show that this allows improving accuracy on the WinoMT test set
by up to 25.8 percentage points.
</p>
<a href="http://arxiv.org/abs/2010.06203" target="_blank">arXiv:2010.06203</a> [<a href="http://arxiv.org/pdf/2010.06203" target="_blank">pdf</a>]

<h2>A review of 3D human pose estimation algorithms for markerless motion capture. (arXiv:2010.06449v2 [cs.CV] UPDATED)</h2>
<h3>Yann Desmarais, Denis Mottet, Pierre Slangen, Philippe Montesinos</h3>
<p>Human pose estimation (HPE) in 3D is an active research field that have many
applications in entertainment, health and sport science, robotics. In the last
five years markerless motion captures techniques have seen their average error
decrease from more than 10cm to less than 2cm today. This evolution is mainly
driven by the improvements in 2D pose estimation task that benefited from the
use of convolutional networks. However with the multiplication of different
approaches it can be difficult to identify what is more adapted to the
specifics of any applications. We suggest to classify existing methods with a
taxonomy based on the performance criteria of accuracy, speed and robustness.
We review more than twenty methods from the last three years. Additionally we
analyze the metrics, benchmarks and structure of the different pose estimation
systems and propose several direction for future research. We hope to offer a
good introduction to 3D markerless pose estimation as well as discussing the
leading contemporary algorithms.
</p>
<a href="http://arxiv.org/abs/2010.06449" target="_blank">arXiv:2010.06449</a> [<a href="http://arxiv.org/pdf/2010.06449" target="_blank">pdf</a>]

<h2>Motif Learning in Knowledge Graphs Using Trajectories Of Differential Equations. (arXiv:2010.06684v2 [cs.LG] UPDATED)</h2>
<h3>Mojtaba Nayyeri, Chengjin Xu, Jens Lehmann, Sahar Vahdati</h3>
<p>Knowledge Graph Embeddings (KGEs) have shown promising performance on link
prediction tasks by mapping the entities and relations from a knowledge graph
into a geometric space (usually a vector space). Ultimately, the plausibility
of the predicted links is measured by using a scoring function over the learned
embeddings (vectors). Therefore, the capability in preserving graph
characteristics including structural aspects and semantics highly depends on
the design of the KGE, as well as the inherited abilities from the underlying
geometry. Many KGEs use the flat geometry which renders them incapable of
preserving complex structures and consequently causes wrong inferences by the
models. To address this problem, we propose a neuro differential KGE that
embeds nodes of a KG on the trajectories of Ordinary Differential Equations
(ODEs). To this end, we represent each relation (edge) in a KG as a vector
field on a smooth Riemannian manifold. We specifically parameterize ODEs by a
neural network to represent various complex shape manifolds and more
importantly complex shape vector fields on the manifold. Therefore, the
underlying embedding space is capable of getting various geometric forms to
encode complexity in subgraph structures with different motifs. Experiments on
synthetic and benchmark dataset as well as social network KGs justify the ODE
trajectories as a means to structure preservation and consequently avoiding
wrong inferences over state-of-the-art KGE models.
</p>
<a href="http://arxiv.org/abs/2010.06684" target="_blank">arXiv:2010.06684</a> [<a href="http://arxiv.org/pdf/2010.06684" target="_blank">pdf</a>]

<h2>Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised Approach. (arXiv:2010.06792v2 [cs.CL] UPDATED)</h2>
<h3>Bowen Tan, Lianhui Qin, Eric P. Xing, Zhiting Hu</h3>
<p>Given a document and a target aspect (e.g., a topic of interest),
aspect-based abstractive summarization attempts to generate a summary with
respect to the aspect. Previous studies usually assume a small pre-defined set
of aspects and fall short of summarizing on other diverse topics. In this work,
we study summarizing on arbitrary aspects relevant to the document, which
significantly expands the application of the task in practice. Due to the lack
of supervision data, we develop a new weak supervision construction method and
an aspect modeling scheme, both of which integrate rich external knowledge
sources such as ConceptNet and Wikipedia. Experiments show our approach
achieves performance boosts on summarizing both real and synthetic documents
given pre-defined or arbitrary aspects.
</p>
<a href="http://arxiv.org/abs/2010.06792" target="_blank">arXiv:2010.06792</a> [<a href="http://arxiv.org/pdf/2010.06792" target="_blank">pdf</a>]

<h2>Transfer2Attack: Text Adversarial Attacks via Cross-Domain Interpretability. (arXiv:2010.06812v2 [cs.LG] UPDATED)</h2>
<h3>Mahmoud Hossam, Trung Le, He Zhao, Dinh Phung</h3>
<p>Training robust deep learning models for down-stream tasks is a critical
challenge. Research has shown that down-stream models can be easily fooled with
adversarial inputs that look like the training data, but slightly perturbed, in
a way imperceptible to humans. Understanding the behavior of natural language
models under these attacks is crucial to better defend these models against
such attacks. In the lack-box attack setting, where no access to model
parameters is available, the attacker can only query the output information
from the targeted model to craft a successful attack. Current black-box
state-of-the-art models are costly in both computational complexity and number
of queries needed to craft successful adversarial examples. For real world
scenarios, the number of queries is critical, where less queries are desired to
avoid suspicion towards an attacking agent. In this paper, we propose
Transfer2Attack, a black-box adversarial attack on text classification task.
Instead of searching for important words to be perturbed by querying the target
model, Transfer2Attack employs an interpretable substitute model from a similar
domain to learn word importance scores. We show that our framework either
achieves or out-performs attack rates of the state-of-the-art models, yet with
lower queries cost and higher efficiency.
</p>
<a href="http://arxiv.org/abs/2010.06812" target="_blank">arXiv:2010.06812</a> [<a href="http://arxiv.org/pdf/2010.06812" target="_blank">pdf</a>]

<h2>Multi-Scale Networks for 3D Human Pose Estimation with Inference Stage Optimization. (arXiv:2010.06844v2 [cs.CV] UPDATED)</h2>
<h3>Cheng Yu, Bo Wang, Bo Yang, Robby T. Tan</h3>
<p>Estimating 3D human poses from a monocular video is still a challenging task.
Many existing methods' performance drops when the target person is occluded by
other objects, or the motion is too fast/slow relative to the scale and speed
of the training data. Moreover, many of these methods are not designed or
trained under severe occlusion explicitly, making their performance on handling
occlusion compromised. Addressing these problems, we introduce a
spatio-temporal network for robust 3D human pose estimation. As humans in
videos may appear in different scales and have various motion speeds, we apply
multi-scale spatial features for 2D joints or keypoints prediction in each
individual frame, and multi-stride temporal convolutional networks (TCNs) to
estimate 3D joints or keypoints. Furthermore, we design a spatio-temporal
discriminator based on body structures as well as limb motions to assess
whether the predicted pose forms a valid pose and a valid movement. During
training, we explicitly mask out some keypoints to simulate various occlusion
cases, from minor to severe occlusion, so that our network can learn better and
becomes robust to various degrees of occlusion. As there are limited 3D
ground-truth data, we further utilize 2D video data to inject a semi-supervised
learning capability to our network. Moreover, we observe that there is a
discrepancy between 3D pose prediction and 2D pose estimation due to different
pose variations between video and image training datasets. We, therefore
propose a confidence-based inference stage optimization to adaptively enforce
3D pose projection to match 2D pose estimation to further improve final pose
prediction accuracy. Experiments on public datasets validate the effectiveness
of our method, and our ablation studies show the strengths of our network's
individual submodules.
</p>
<a href="http://arxiv.org/abs/2010.06844" target="_blank">arXiv:2010.06844</a> [<a href="http://arxiv.org/pdf/2010.06844" target="_blank">pdf</a>]

<h2>Deep Ensembles for Low-Data Transfer Learning. (arXiv:2010.06866v2 [cs.LG] UPDATED)</h2>
<h3>Basil Mustafa, Carlos Riquelme, Joan Puigcerver, Andr&#xe9; Susano Pinto, Daniel Keysers, Neil Houlsby</h3>
<p>In the low-data regime, it is difficult to train good supervised models from
scratch. Instead practitioners turn to pre-trained models, leveraging transfer
learning. Ensembling is an empirically and theoretically appealing way to
construct powerful predictive models, but the predominant approach of training
multiple deep networks with different random initialisations collides with the
need for transfer via pre-trained weights. In this work, we study different
ways of creating ensembles from pre-trained models. We show that the nature of
pre-training itself is a performant source of diversity, and propose a
practical algorithm that efficiently identifies a subset of pre-trained models
for any downstream dataset. The approach is simple: Use nearest-neighbour
accuracy to rank pre-trained models, fine-tune the best ones with a small
hyperparameter sweep, and greedily construct an ensemble to minimise validation
cross-entropy. When evaluated together with strong baselines on 19 different
downstream tasks (the Visual Task Adaptation Benchmark), this achieves
state-of-the-art performance at a much lower inference budget, even when
selecting from over 2,000 pre-trained models. We also assess our ensembles on
ImageNet variants and show improved robustness to distribution shift.
</p>
<a href="http://arxiv.org/abs/2010.06866" target="_blank">arXiv:2010.06866</a> [<a href="http://arxiv.org/pdf/2010.06866" target="_blank">pdf</a>]

<h2>Fairness in Streaming Submodular Maximization: Algorithms and Hardness. (arXiv:2010.07431v2 [cs.LG] UPDATED)</h2>
<h3>Marwa El Halabi, Slobodan Mitrovi&#x107;, Ashkan Norouzi-Fard, Jakab Tardos, Jakub Tarnawski</h3>
<p>Submodular maximization has become established as the method of choice for
the task of selecting representative and diverse summaries of data. However, if
datapoints have sensitive attributes such as gender or age, such machine
learning algorithms, left unchecked, are known to exhibit bias: under- or
over-representation of particular groups. This has made the design of fair
machine learning algorithms increasingly important. In this work we address the
question: Is it possible to create fair summaries for massive datasets? To this
end, we develop the first streaming approximation algorithms for submodular
maximization under fairness constraints, for both monotone and non-monotone
functions. We validate our findings empirically on exemplar-based clustering,
movie recommendation, DPP-based summarization, and maximum coverage in social
networks, showing that fairness constraints do not significantly impact
utility.
</p>
<a href="http://arxiv.org/abs/2010.07431" target="_blank">arXiv:2010.07431</a> [<a href="http://arxiv.org/pdf/2010.07431" target="_blank">pdf</a>]

<h2>CS2-Net: Deep Learning Segmentation of Curvilinear Structures in Medical Imaging. (arXiv:2010.07486v2 [eess.IV] UPDATED)</h2>
<h3>Lei Mou, Yitian Zhao, Huazhu Fu, Yonghuai Liu, Jun Cheng, Yalin Zheng, Pan Su, Jianlong Yang, Li Chen, Alejandro F Frang, Masahiro Akiba, Jiang Liu</h3>
<p>Automated detection of curvilinear structures, e.g., blood vessels or nerve
fibres, from medical and biomedical images is a crucial early step in automatic
image interpretation associated to the management of many diseases. Precise
measurement of the morphological changes of these curvilinear organ structures
informs clinicians for understanding the mechanism, diagnosis, and treatment of
e.g. cardiovascular, kidney, eye, lung, and neurological conditions. In this
work, we propose a generic and unified convolution neural network for the
segmentation of curvilinear structures and illustrate in several 2D/3D medical
imaging modalities. We introduce a new curvilinear structure segmentation
network (CS2-Net), which includes a self-attention mechanism in the encoder and
decoder to learn rich hierarchical representations of curvilinear structures.
Two types of attention modules - spatial attention and channel attention - are
utilized to enhance the inter-class discrimination and intra-class
responsiveness, to further integrate local features with their global
dependencies and normalization, adaptively. Furthermore, to facilitate the
segmentation of curvilinear structures in medical images, we employ a 1x3 and a
3x1 convolutional kernel to capture boundary features. ...
</p>
<a href="http://arxiv.org/abs/2010.07486" target="_blank">arXiv:2010.07486</a> [<a href="http://arxiv.org/pdf/2010.07486" target="_blank">pdf</a>]

<h2>Wasserstein Distance Regularized Sequence Representation for Text Matching in Asymmetrical Domains. (arXiv:2010.07717v2 [cs.CL] UPDATED)</h2>
<h3>Weijie Yu, Chen Xu, Jun Xu, Liang Pang, Xiaopeng Gao, Xiaozhao Wang, Ji-Rong Wen</h3>
<p>One approach to matching texts from asymmetrical domains is projecting the
input sequences into a common semantic space as feature vectors upon which the
matching function can be readily defined and learned. In real-world matching
practices, it is often observed that with the training goes on, the feature
vectors projected from different domains tend to be indistinguishable. The
phenomenon, however, is often overlooked in existing matching models. As a
result, the feature vectors are constructed without any regularization, which
inevitably increases the difficulty of learning the downstream matching
functions. In this paper, we propose a novel match method tailored for text
matching in asymmetrical domains, called WD-Match. In WD-Match, a Wasserstein
distance-based regularizer is defined to regularize the features vectors
projected from different domains. As a result, the method enforces the feature
projection function to generate vectors such that those correspond to different
domains cannot be easily discriminated. The training process of WD-Match
amounts to a game that minimizes the matching loss regularized by the
Wasserstein distance. WD-Match can be used to improve different text matching
methods, by using the method as its underlying matching model. Four popular
text matching methods have been exploited in the paper. Experimental results
based on four publicly available benchmarks showed that WD-Match consistently
outperformed the underlying methods and the baselines.
</p>
<a href="http://arxiv.org/abs/2010.07717" target="_blank">arXiv:2010.07717</a> [<a href="http://arxiv.org/pdf/2010.07717" target="_blank">pdf</a>]

<h2>A Transformer Based Pitch Sequence Autoencoder with MIDI Augmentation. (arXiv:2010.07758v2 [cs.SD] UPDATED)</h2>
<h3>Mingshuo Ding, Yinghao Ma</h3>
<p>Algorithms based on deep learning have been widely put forward for automatic
music generated. However, few objective approaches have been proposed to assess
whether a melody was created by automatons or Homo sapiens. Conference of Sound
and Music Technology (2020) provides us a great opportunity to cope with the
problem. In this paper, a masked language model based on ALBERT trained with
AI-composed single-track MIDI is demonstrated for composers classification
tasks. Besides, music tune transposition and MIDI sequence truncation is
applied for data augments. To prevent from over-fitting, a refined loss
function is proposed and the amount of parameters is reduced. This work
provides a new approach to tackle the problem on obtaining features from tiny
dataset which is common in music signal analysis and deserve more attention.
</p>
<a href="http://arxiv.org/abs/2010.07758" target="_blank">arXiv:2010.07758</a> [<a href="http://arxiv.org/pdf/2010.07758" target="_blank">pdf</a>]

<h2>alurity, a toolbox for robot cybersecurity. (arXiv:2010.07759v2 [cs.RO] UPDATED)</h2>
<h3>V&#xed;ctor Mayoral-Vilches, Irati Abad-Fern&#xe1;ndez, Martin Pinzger, Stefan Rass, Bernhard Dieber, Alcino Cunha, Francisco J. Rodr&#xed;guez-Lera, Giovanni Lacava, Angelica Marotta, Fabio Martinelli, Endika Gil-Uriarte</h3>
<p>The reuse of technologies and inherent complexity of most robotic systems is
increasingly leading to robots with wide attack surfaces and a variety of
potential vulnerabilities. Given their growing presence in public environments,
security research is increasingly becoming more important than in any other
area, specially due to the safety implications that robot vulnerabilities could
cause on humans. We argue that security triage in robotics is still immature
and that new tools must be developed to accelerate the
testing-triage-exploitation cycle, necessary for prioritizing and accelerating
the mitigation of flaws.

The present work tackles the current lack of offensive cybersecurity research
in robotics by presenting a toolbox and the results obtained with it through
several use cases conducted over a year period. We propose a modular and
composable toolbox for robot cybersecurity: alurity. By ensuring that both
roboticists and security researchers working on a project have a common,
consistent and easily reproducible development environment, alurity aims to
facilitate the cybersecurity research and the collaboration across teams.
</p>
<a href="http://arxiv.org/abs/2010.07759" target="_blank">arXiv:2010.07759</a> [<a href="http://arxiv.org/pdf/2010.07759" target="_blank">pdf</a>]

<h2>Double Robust Representation Learning for Counterfactual Prediction. (arXiv:2010.07866v2 [stat.ML] UPDATED)</h2>
<h3>Shuxi Zeng, Serge Assaad, Chenyang Tao, Shounak Datta, Lawrence Carin, Fan Li</h3>
<p>Causal inference, or counterfactual prediction, is central to decision making
in healthcare, policy and social sciences. To de-bias causal estimators with
high-dimensional data in observational studies, recent advances suggest the
importance of combining machine learning models for both the propensity score
and the outcome function. We propose a novel scalable method to learn
double-robust representations for counterfactual predictions, leading to
consistent causal estimation if the model for either the propensity score or
the outcome, but not necessarily both, is correctly specified. Specifically, we
use the entropy balancing method to learn the weights that minimize the
Jensen-Shannon divergence of the representation between the treated and control
groups, based on which we make robust and efficient counterfactual predictions
for both individual and average treatment effects. We provide theoretical
justifications for the proposed method. The algorithm shows competitive
performance with the state-of-the-art on real world and synthetic data.
</p>
<a href="http://arxiv.org/abs/2010.07866" target="_blank">arXiv:2010.07866</a> [<a href="http://arxiv.org/pdf/2010.07866" target="_blank">pdf</a>]

<h2>Deep Generative Modeling in Network Science with Applications to Public Policy Research. (arXiv:2010.07870v2 [cs.LG] UPDATED)</h2>
<h3>Gavin S. Hartnett, Raffaele Vardavas, Lawrence Baker, Michael Chaykowsky, C. Ben Gibson, Federico Girosi, David P. Kennedy, Osonde A. Osoba</h3>
<p>Network data is increasingly being used in quantitative, data-driven public
policy research. These are typically very rich datasets that contain complex
correlations and inter-dependencies. This richness both promises to be quite
useful for policy research, while at the same time posing a challenge for the
useful extraction of information from these datasets - a challenge which calls
for new data analysis methods. In this report, we formulate a research agenda
of key methodological problems whose solutions would enable new advances across
many areas of policy research. We then review recent advances in applying deep
learning to network data, and show how these methods may be used to address
many of the methodological problems we identified. We particularly emphasize
deep generative methods, which can be used to generate realistic synthetic
networks useful for microsimulation and agent-based models capable of informing
key public policy questions. We extend these recent advances by developing a
new generative framework which applies to large social contact networks
commonly used in epidemiological modeling. For context, we also compare and
contrast these recent neural network-based approaches with the more traditional
Exponential Random Graph Models. Lastly, we discuss some open problems where
more progress is needed.
</p>
<a href="http://arxiv.org/abs/2010.07870" target="_blank">arXiv:2010.07870</a> [<a href="http://arxiv.org/pdf/2010.07870" target="_blank">pdf</a>]

<h2>Multi-Agent Trust Region Policy Optimization. (arXiv:2010.07916v2 [cs.AI] UPDATED)</h2>
<h3>Hepeng Li, Haibo He</h3>
<p>We extend trust region policy optimization (TRPO) to multi-agent
reinforcement learning (MARL) problems. We show that the policy update of TRPO
can be transformed into a distributed consensus optimization problem for
multi-agent cases. By making a series of approximations to the consensus
optimization model, we propose a decentralized MARL algorithm, which we call
multi-agent TRPO (MATRPO). This algorithm can optimize distributed policies
based on local observations and private rewards. The agents do not need to know
observations, rewards, policies or value/action-value functions of other
agents. The agents only share a likelihood ratio with their neighbors during
the training process. The algorithm is fully decentralized and
privacy-preserving. Our experiments on two cooperative games demonstrate its
robust performance on complicated MARL tasks.
</p>
<a href="http://arxiv.org/abs/2010.07916" target="_blank">arXiv:2010.07916</a> [<a href="http://arxiv.org/pdf/2010.07916" target="_blank">pdf</a>]

<h2>Hyperparameter Auto-tuning in Self-Supervised Robotic Learning. (arXiv:2010.08252v2 [cs.RO] UPDATED)</h2>
<h3>Jiancong Huang, Juan Rojas, Matthieu Zimmer, Hongmin Wu, Yisheng Guan, Paul Weng</h3>
<p>Policy optimization in reinforcement learning requires the selection of
numerous hyperparameters across different environments. Fixing them incorrectly
may negatively impact optimization performance leading notably to insufficient
or redundant learning. Insufficient learning (due to convergence to local
optima) results in under-performing policies whilst redundant learning wastes
time and resources. The effects are further exacerbated when using single
policies to solve multi-task learning problems. In this paper, we study how the
Evidence Lower Bound (ELBO) used in Variational Auto-Encoders (VAEs) is
affected by the diversity of image samples. Different tasks or setups in visual
reinforcement learning incur varying diversity. We exploit the ELBO to create
an auto-tuning technique in self-supervised reinforcement learning. Our
approach can auto-tune three hyperparameters: the replay buffer size, the
number of policy gradient updates during each epoch, and the number of
exploration steps during each epoch. We use the state-of-the-art
self-supervised robotic learning framework (Reinforcement Learning with
Imagined Goals (RIG) using Soft Actor-Critic) as baseline for experimental
verification. Experiments show that our method can auto-tune online and yields
the best performance at a fraction of the time and computational resources.
Code, video, and appendix for simulated and real-robot experiments can be found
at this http URL
</p>
<a href="http://arxiv.org/abs/2010.08252" target="_blank">arXiv:2010.08252</a> [<a href="http://arxiv.org/pdf/2010.08252" target="_blank">pdf</a>]

<h2>Position paper: A systematic framework for categorising IoT device fingerprinting mechanisms. (arXiv:2010.08466v2 [cs.NI] UPDATED)</h2>
<h3>Poonam Yadav, Angelo Feraudo, Budi Arief, Siamak F. Shahandashti, Vassilios G. Vassilakis</h3>
<p>The popularity of the Internet of Things (IoT) devices makes it increasingly
important to be able to fingerprint them, for example in order to detect if
there are misbehaving or even malicious IoT devices in one's network. The aim
of this paper is to provide a systematic categorisation of machine learning
augmented techniques that can be used for fingerprinting IoT devices. This can
serve as a baseline for comparing various IoT fingerprinting mechanisms, so
that network administrators can choose one or more mechanisms that are
appropriate for monitoring and maintaining their network. We carried out an
extensive literature review of existing papers on fingerprinting IoT devices --
paying close attention to those with machine learning features. This is
followed by an extraction of important and comparable features among the
mechanisms outlined in those papers. As a result, we came up with a key set of
terminologies that are relevant both in the fingerprinting context and in the
IoT domain. This enabled us to construct a framework called IDWork, which can
be used for categorising existing IoT fingerprinting mechanisms in a way that
will facilitate a coherent and fair comparison of these mechanisms. We found
that the majority of the IoT fingerprinting mechanisms take a passive approach
-- mainly through network sniffing -- instead of being intrusive and
interactive with the device of interest. Additionally, a significant number of
the surveyed mechanisms employ both static and dynamic approaches, in order to
benefit from complementary features that can be more robust against certain
attacks such as spoofing and replay attacks.
</p>
<a href="http://arxiv.org/abs/2010.08466" target="_blank">arXiv:2010.08466</a> [<a href="http://arxiv.org/pdf/2010.08466" target="_blank">pdf</a>]

<h2>Learnability and Robustness of Shallow Neural Networks Learned With a Performance-Driven BP and a Variant PSO For Edge Decision-Making. (arXiv:2008.06135v1 [cs.NE] CROSS LISTED)</h2>
<h3>Hongmei He, Mengyuan Chen, Gang Xu, Zhilong Zhu, Zhenhuan Zhu</h3>
<p>In many cases, the computing resources are limited without the benefit from
GPU, especially in the edge devices of IoT enabled systems. It may not be easy
to implement complex AI models in edge devices. The Universal Approximation
Theorem states that a shallow neural network (SNN) can represent any nonlinear
function. However, how fat is an SNN enough to solve a nonlinear
decision-making problem in edge devices? In this paper, we focus on the
learnability and robustness of SNNs, obtained by a greedy tight force heuristic
algorithm (performance driven BP) and a loose force meta-heuristic algorithm (a
variant of PSO). Two groups of experiments are conducted to examine the
learnability and the robustness of SNNs with Sigmoid activation,
learned/optimised by KPI-PDBPs and KPI-VPSOs, where, KPIs (key performance
indicators: error (ERR), accuracy (ACC) and $F_1$ score) are the objectives,
driving the searching process. An incremental approach is applied to examine
the impact of hidden neuron numbers on the performance of SNNs,
learned/optimised by KPI-PDBPs and KPI-VPSOs. From the engineering prospective,
all sensors are well justified for a specific task. Hence, all sensor readings
should be strongly correlated to the target. Therefore, the structure of an SNN
should depend on the dimensions of a problem space. The experimental results
show that the number of hidden neurons up to the dimension number of a problem
space is enough; the learnability of SNNs, produced by KPI-PDBP, is better than
that of SNNs, optimized by KPI-VPSO, regarding the performance and learning
time on the training data sets; the robustness of SNNs learned by KPI-PDBPs and
KPI-VPSOs depends on the data sets; and comparing with other classic machine
learning models, ACC-PDBPs win for almost all tested data sets.
</p>
<a href="http://arxiv.org/abs/2008.06135" target="_blank">arXiv:2008.06135</a> [<a href="http://arxiv.org/pdf/2008.06135" target="_blank">pdf</a>]

<h2>Markov Neighborhood Regression for High-Dimensional Inference. (arXiv:2010.08864v1 [stat.ME])</h2>
<h3>Faming Liang, Jingnan Xue, Bochao Jia</h3>
<p>This paper proposes an innovative method for constructing confidence
intervals and assessing p-values in statistical inference for high-dimensional
linear models. The proposed method has successfully broken the high-dimensional
inference problem into a series of low-dimensional inference problems: For each
regression coefficient $\beta_i$, the confidence interval and $p$-value are
computed by regressing on a subset of variables selected according to the
conditional independence relations between the corresponding variable $X_i$ and
other variables. Since the subset of variables forms a Markov neighborhood of
$X_i$ in the Markov network formed by all the variables $X_1,X_2,\ldots,X_p$,
the proposed method is coined as Markov neighborhood regression. The proposed
method is tested on high-dimensional linear, logistic and Cox regression. The
numerical results indicate that the proposed method significantly outperforms
the existing ones. Based on the Markov neighborhood regression, a method of
learning causal structures for high-dimensional linear models is proposed and
applied to identification of drug sensitive genes and cancer driver genes. The
idea of using conditional independence relations for dimension reduction is
general and potentially can be extended to other high-dimensional or big data
problems as well.
</p>
<a href="http://arxiv.org/abs/2010.08864" target="_blank">arXiv:2010.08864</a> [<a href="http://arxiv.org/pdf/2010.08864" target="_blank">pdf</a>]

<h2>DAGs with No Fears: A Closer Look at Continuous Optimization for Learning Bayesian Networks. (arXiv:2010.09133v1 [cs.LG])</h2>
<h3>Dennis Wei, Tian Gao, Yue Yu</h3>
<p>This paper re-examines a continuous optimization framework dubbed NOTEARS for
learning Bayesian networks. We first generalize existing algebraic
characterizations of acyclicity to a class of matrix polynomials. Next,
focusing on a one-parameter-per-edge setting, it is shown that the
Karush-Kuhn-Tucker (KKT) optimality conditions for the NOTEARS formulation
cannot be satisfied except in a trivial case, which explains a behavior of the
associated algorithm. We then derive the KKT conditions for an equivalent
reformulation, show that they are indeed necessary, and relate them to explicit
constraints that certain edges be absent from the graph. If the score function
is convex, these KKT conditions are also sufficient for local minimality
despite the non-convexity of the constraint. Informed by the KKT conditions, a
local search post-processing algorithm is proposed and shown to substantially
and universally improve the structural Hamming distance of all tested
algorithms, typically by a factor of 2 or more. Some combinations with local
search are both more accurate and more efficient than the original NOTEARS.
</p>
<a href="http://arxiv.org/abs/2010.09133" target="_blank">arXiv:2010.09133</a> [<a href="http://arxiv.org/pdf/2010.09133" target="_blank">pdf</a>]

<h2>Factorization Machines with Regularization for Sparse Feature Interactions. (arXiv:2010.09225v1 [stat.ML])</h2>
<h3>Kyohei Atarashi, Satoshi Oyama, Masahito Kurihara</h3>
<p>Factorization machines (FMs) are machine learning predictive models based on
second-order feature interactions and FMs with sparse regularization are called
sparse FMs. Such regularizations enable feature selection, which selects the
most relevant features for accurate prediction, and therefore they can
contribute to the improvement of the model accuracy and interpretability.
However, because FMs use second-order feature interactions, the selection of
features often cause the loss of many relevant feature interactions in the
resultant models. In such cases, FMs with regularization specially designed for
feature interaction selection trying to achieve interaction-level sparsity may
be preferred instead of those just for feature selection trying to achieve
feature-level sparsity. In this paper, we present a new regularization scheme
for feature interaction selection in FMs. The proposed regularizer is an upper
bound of the $\ell_1$ regularizer for the feature interaction matrix, which is
computed from the parameter matrix of FMs. For feature interaction selection,
our proposed regularizer makes the feature interaction matrix sparse without a
restriction on sparsity patterns imposed by the existing methods. We also
describe efficient proximal algorithms for the proposed FMs and present
theoretical analyses of both existing and the new regularize. In addition, we
will discuss how our ideas can be applied or extended to more accurate feature
selection and other related models such as higher-order FMs and the all-subsets
model. The analysis and experimental results on synthetic and real-world
datasets show the effectiveness of the proposed methods.
</p>
<a href="http://arxiv.org/abs/2010.09225" target="_blank">arXiv:2010.09225</a> [<a href="http://arxiv.org/pdf/2010.09225" target="_blank">pdf</a>]

<h2>Estimating Stochastic Linear Combination of Non-linear Regressions Efficiently and Scalably. (arXiv:2010.09265v1 [cs.LG])</h2>
<h3>Di Wang, Xiangyu Guo, Chaowen Guan, Shi Li, Jinhui Xu</h3>
<p>Recently, many machine learning and statistical models such as non-linear
regressions, the Single Index, Multi-index, Varying Coefficient Index Models
and Two-layer Neural Networks can be reduced to or be seen as a special case of
a new model which is called the \textit{Stochastic Linear Combination of
Non-linear Regressions} model. However, due to the high non-convexity of the
problem, there is no previous work study how to estimate the model. In this
paper, we provide the first study on how to estimate the model efficiently and
scalably. Specifically, we first show that with some mild assumptions, if the
variate vector $x$ is multivariate Gaussian, then there is an algorithm whose
output vectors have $\ell_2$-norm estimation errors of $O(\sqrt{\frac{p}{n}})$
with high probability, where $p$ is the dimension of $x$ and $n$ is the number
of samples. The key idea of the proof is based on an observation motived by the
Stein's lemma. Then we extend our result to the case where $x$ is bounded and
sub-Gaussian using the zero-bias transformation, which could be seen as a
generalization of the classic Stein's lemma. We also show that with some
additional assumptions there is an algorithm whose output vectors have
$\ell_\infty$-norm estimation errors of
$O(\frac{1}{\sqrt{p}}+\sqrt{\frac{p}{n}})$ with high probability. We also
provide a concrete example to show that there exists some link function which
satisfies the previous assumptions. Finally, for both Gaussian and sub-Gaussian
cases we propose a faster sub-sampling based algorithm and show that when the
sub-sample sizes are large enough then the estimation errors will not be
sacrificed by too much. Experiments for both cases support our theoretical
results.

To the best of our knowledge, this is the first work that studies and
provides theoretical guarantees for the stochastic linear combination of
non-linear regressions model.
</p>
<a href="http://arxiv.org/abs/2010.09265" target="_blank">arXiv:2010.09265</a> [<a href="http://arxiv.org/pdf/2010.09265" target="_blank">pdf</a>]

<h2>Neuralizing Efficient Higher-order Belief Propagation. (arXiv:2010.09283v1 [cs.LG])</h2>
<h3>Mohammed Haroon Dupty, Wee Sun Lee</h3>
<p>Graph neural network models have been extensively used to learn node
representations for graph structured data in an end-to-end setting. These
models often rely on localized first order approximations of spectral graph
convolutions and hence are unable to capture higher-order relational
information between nodes. Probabilistic Graphical Models form another class of
models that provide rich flexibility in incorporating such relational
information but are limited by inefficient approximate inference algorithms at
higher order. In this paper, we propose to combine these approaches to learn
better node and graph representations. First, we derive an efficient
approximate sum-product loopy belief propagation inference algorithm for
higher-order PGMs. We then embed the message passing updates into a neural
network to provide the inductive bias of the inference algorithm in end-to-end
learning. This gives us a model that is flexible enough to accommodate domain
knowledge while maintaining the computational advantage. We further propose
methods for constructing higher-order factors that are conditioned on node and
edge features and share parameters wherever necessary. Our experimental
evaluation shows that our model indeed captures higher-order information,
substantially outperforming state-of-the-art $k$-order graph neural networks in
molecular datasets.
</p>
<a href="http://arxiv.org/abs/2010.09283" target="_blank">arXiv:2010.09283</a> [<a href="http://arxiv.org/pdf/2010.09283" target="_blank">pdf</a>]

<h2>Privacy-preserving Data Sharing on Vertically Partitioned Data. (arXiv:2010.09293v1 [cs.LG])</h2>
<h3>Razane Tajeddine, Joonas J&#xe4;lk&#xf6;, Samuel Kaski, Antti Honkela</h3>
<p>In this work, we present a method for differentially private data sharing by
training a mixture model on vertically partitioned data, where each party holds
different features for the same set of individuals. We use secure multi-party
computation (MPC) to combine the contribution of the data from the parties to
train the model. We apply the differentially private variational inference
(DPVI) for learning the model. Assuming the mixture components contain no
dependencies across different parties, the objective function can be factorized
into a sum of products of individual components of each party. Therefore, each
party can calculate its shares on its own without the use of MPC. Then MPC is
only needed to get the product between the different shares and add the noise.
Applying the method to demographic data from the US Census, we obtain
comparable accuracy to the non-partitioned case with approximately 20-fold
increase in computing time.
</p>
<a href="http://arxiv.org/abs/2010.09293" target="_blank">arXiv:2010.09293</a> [<a href="http://arxiv.org/pdf/2010.09293" target="_blank">pdf</a>]

<h2>Characterizing Deep Gaussian Processes via Nonlinear Recurrence Systems. (arXiv:2010.09301v1 [cs.LG])</h2>
<h3>Anh Tong, Jaesik Choi</h3>
<p>Recent advances in Deep Gaussian Processes (DGPs) show the potential to have
more expressive representation than that of traditional Gaussian Processes
(GPs). However, there exists a pathology of deep Gaussian processes that their
learning capacities reduce significantly when the number of layers increases.
In this paper, we present a new analysis in DGPs by studying its corresponding
nonlinear dynamic systems to explain the issue. Existing work reports the
pathology for the squared exponential kernel function. We extend our
investigation to four types of common stationary kernel functions. The
recurrence relations between layers are analytically derived, providing a
tighter bound and the rate of convergence of the dynamic systems. We
demonstrate our finding with a number of experimental results.
</p>
<a href="http://arxiv.org/abs/2010.09301" target="_blank">arXiv:2010.09301</a> [<a href="http://arxiv.org/pdf/2010.09301" target="_blank">pdf</a>]

<h2>Bayesian Inference for Optimal Transport with Stochastic Cost. (arXiv:2010.09327v1 [cs.LG])</h2>
<h3>Anton Mallasto, Markus Heinonen, Samuel Kaski</h3>
<p>In machine learning and computer vision, optimal transport has had
significant success in learning generative models and defining metric distances
between structured and stochastic data objects, that can be cast as probability
measures. The key element of optimal transport is the so called lifting of an
\emph{exact} cost (distance) function, defined on the sample space, to a cost
(distance) between probability measures over the sample space. However, in many
real life applications the cost is \emph{stochastic}: e.g., the unpredictable
traffic flow affects the cost of transportation between a factory and an
outlet. To take this stochasticity into account, we introduce a Bayesian
framework for inferring the optimal transport plan distribution induced by the
stochastic cost, allowing for a principled way to include prior information and
to model the induced stochasticity on the transport plans. Additionally, we
tailor an HMC method to sample from the resulting transport plan posterior
distribution.
</p>
<a href="http://arxiv.org/abs/2010.09327" target="_blank">arXiv:2010.09327</a> [<a href="http://arxiv.org/pdf/2010.09327" target="_blank">pdf</a>]

<h2>Interpretable Machine Learning -- A Brief History, State-of-the-Art and Challenges. (arXiv:2010.09337v1 [stat.ML])</h2>
<h3>Christoph Molnar, Giuseppe Casalicchio, Bernd Bischl</h3>
<p>We present a brief history of the field of interpretable machine learning
(IML), give an overview of state-of-the-art interpretation methods, and discuss
challenges. Research in IML has boomed in recent years. As young as the field
is, it has over 200 years old roots in regression modeling and rule-based
machine learning, starting in the 1960s. Recently, many new IML methods have
been proposed, many of them model-agnostic, but also interpretation techniques
specific to deep learning and tree-based ensembles. IML methods either directly
analyze model components, study sensitivity to input perturbations, or analyze
local or global surrogate approximations of the ML model. The field approaches
a state of readiness and stability, with many methods not only proposed in
research, but also implemented in open-source software. But many important
challenges remain for IML, such as dealing with dependent features, causal
interpretation, and uncertainty estimation, which need to be resolved for its
successful application to scientific problems. A further challenge is a missing
rigorous definition of interpretability, which is accepted by the community. To
address the challenges and advance the field, we urge to recall our roots of
interpretable, data-driven modeling in statistics and (rule-based) ML, but also
to consider other areas such as sensitivity analysis, causal inference, and the
social sciences.
</p>
<a href="http://arxiv.org/abs/2010.09337" target="_blank">arXiv:2010.09337</a> [<a href="http://arxiv.org/pdf/2010.09337" target="_blank">pdf</a>]

<h2>A Framework to Learn with Interpretation. (arXiv:2010.09345v1 [cs.LG])</h2>
<h3>Jayneel Parekh, Pavlo Mozharovskyi, Florence d&#x27;Alche-Buc</h3>
<p>With increasingly widespread use of deep neural networks in critical
decision-making applications, interpretability of these models is becoming
imperative. We consider the problem of jointly learning a predictive model and
its associated interpretation model. The task of the interpreter is to provide
both local and global interpretability about the predictive model in terms of
human-understandable high level attribute functions, without any loss of
accuracy. This is achieved by a dedicated architecture and well chosen
regularization penalties. We seek for a small-size dictionary of attribute
functions that take as inputs the outputs of selected hidden layers and whose
outputs feed a linear classifier. We impose a high level of conciseness by
constraining the activation of a very few attributes for a given input with a
real-entropy-based criterion while enforcing fidelity to both inputs and
outputs of the predictive model. A major advantage of simultaneous learning is
that the predictive neural network benefits from the interpretability
constraint as well. We also develop a more detailed pipeline based on some
common and novel simple tools to develop understanding about the learnt
features. We show on two datasets, MNIST and QuickDraw, their relevance for
both global and local interpretability.
</p>
<a href="http://arxiv.org/abs/2010.09345" target="_blank">arXiv:2010.09345</a> [<a href="http://arxiv.org/pdf/2010.09345" target="_blank">pdf</a>]

<h2>Learning Optimal Conditional Priors For Disentangled Representations. (arXiv:2010.09360v1 [cs.LG])</h2>
<h3>Graziano Mita, Maurizio Filippone, Pietro Michiardi</h3>
<p>A large part of the literature on learning disentangled representations
focuses on variational autoencoders (VAEs). Recent developments demonstrate
that disentanglement cannot be obtained in a fully unsupervised setting without
inductive biases on models and data. As such, Khemakhem et al., AISTATS 2020,
suggest employing a factorized prior distribution over the latent variables
that is conditionally dependent on auxiliary observed variables complementing
input observations. While this is a remarkable advancement toward model
identifiability, the learned conditional prior only focuses on sufficiency,
giving no guarantees on a minimal representation. Motivated by information
theoretic principles, we propose a novel VAE-based generative model with
theoretical guarantees on disentanglement. Our proposed model learns a
sufficient and compact - thus optimal - conditional prior, which serves as
regularization for the latent space. Experimental results indicate superior
performance with respect to state-of-the-art methods, according to several
established metrics proposed in the literature on disentanglement.
</p>
<a href="http://arxiv.org/abs/2010.09360" target="_blank">arXiv:2010.09360</a> [<a href="http://arxiv.org/pdf/2010.09360" target="_blank">pdf</a>]

<h2>Probabilistic selection of inducing points for sparse Gaussian processes. (arXiv:2010.09370v1 [cs.LG])</h2>
<h3>Anders Kirk Uhrenholt, Valentin Charvet, Bj&#xf8;rn Sand Jensen</h3>
<p>Sparse Gaussian processes and various extensions thereof are enabled through
inducing points, that simultaneously bottleneck the predictive capacity and act
as the main contributor towards model complexity. However, the number of
inducing points is generally not associated with uncertainty which prevents us
from applying the apparatus of Bayesian reasoning in identifying an appropriate
trade-off. In this work we place a point process prior on the inducing points
and approximate the associated posterior through stochastic variational
inference. By letting the prior encourage a moderate number of inducing points,
we enable the model to learn which and how many points to utilise. We
experimentally show that fewer inducing points are preferred by the model as
the points become less informative, and further demonstrate how the method can
be applied in deep Gaussian processes and latent variable modelling.
</p>
<a href="http://arxiv.org/abs/2010.09370" target="_blank">arXiv:2010.09370</a> [<a href="http://arxiv.org/pdf/2010.09370" target="_blank">pdf</a>]

<h2>Learning Parameter Distributions to Detect Concept Drift in Data Streams. (arXiv:2010.09388v1 [cs.LG])</h2>
<h3>Johannes Haug, Gjergji Kasneci</h3>
<p>Data distributions in streaming environments are usually not stationary. In
order to maintain a high predictive quality at all times, online learning
models need to adapt to distributional changes, which are known as concept
drift. The timely and robust identification of concept drift can be difficult,
as we never have access to the true distribution of streaming data. In this
work, we propose a novel framework for the detection of real concept drift,
called ERICS. By treating the parameters of a predictive model as random
variables, we show that concept drift corresponds to a change in the
distribution of optimal parameters. To this end, we adopt common measures from
information theory. The proposed framework is completely model-agnostic. By
choosing an appropriate base model, ERICS is also capable to detect concept
drift at the input level, which is a significant advantage over existing
approaches. An evaluation on several synthetic and real-world data sets
suggests that the proposed framework identifies concept drift more effectively
and precisely than various existing works.
</p>
<a href="http://arxiv.org/abs/2010.09388" target="_blank">arXiv:2010.09388</a> [<a href="http://arxiv.org/pdf/2010.09388" target="_blank">pdf</a>]

<h2>Efficient Estimation and Evaluation of Prediction Rules in Semi-Supervised Settings under Stratified Sampling. (arXiv:2010.09443v1 [stat.ML])</h2>
<h3>Jessica Gronsbell, Molei Liu, Lu Tian, Tianxi Cai</h3>
<p>In many contemporary applications, large amounts of unlabeled data are
readily available while labeled examples are limited. There has been
substantial interest in semi-supervised learning (SSL) which aims to leverage
unlabeled data to improve estimation or prediction. However, current SSL
literature focuses primarily on settings where labeled data is selected
randomly from the population of interest. Non-random sampling, while posing
additional analytical challenges, is highly applicable to many real world
problems. Moreover, no SSL methods currently exist for estimating the
prediction performance of a fitted model under non-random sampling. In this
paper, we propose a two-step SSL procedure for evaluating a prediction rule
derived from a working binary regression model based on the Brier score and
overall misclassification rate under stratified sampling. In step I, we impute
the missing labels via weighted regression with nonlinear basis functions to
account for nonrandom sampling and to improve efficiency. In step II, we
augment the initial imputations to ensure the consistency of the resulting
estimators regardless of the specification of the prediction model or the
imputation model. The final estimator is then obtained with the augmented
imputations. We provide asymptotic theory and numerical studies illustrating
that our proposals outperform their supervised counterparts in terms of
efficiency gain. Our methods are motivated by electronic health records (EHR)
research and validated with a real data analysis of an EHR-based study of
diabetic neuropathy.
</p>
<a href="http://arxiv.org/abs/2010.09443" target="_blank">arXiv:2010.09443</a> [<a href="http://arxiv.org/pdf/2010.09443" target="_blank">pdf</a>]

<h2>Improving Transformation Invariance in Contrastive Representation Learning. (arXiv:2010.09515v1 [cs.LG])</h2>
<h3>Adam Foster, Rattana Pukdee, Tom Rainforth</h3>
<p>We propose methods to strengthen the invariance properties of representations
obtained by contrastive learning. While existing approaches implicitly induce a
degree of invariance as representations are learned, we look to more directly
enforce invariance in the encoding process. To this end, we first introduce a
training objective for contrastive learning that uses a novel regularizer to
control how the representation changes under transformation. We show that
representations trained with this objective perform better on downstream tasks
and are more robust to the introduction of nuisance transformations at test
time. Second, we propose a change to how test time representations are
generated by introducing a feature averaging approach that combines encodings
from multiple transformations of the original input, finding that this leads to
across the board performance gains. Finally, we introduce the novel Spirograph
dataset to explore our ideas in the context of a differentiable generative
process with multiple downstream tasks, showing that our techniques for
learning invariance are highly beneficial.
</p>
<a href="http://arxiv.org/abs/2010.09515" target="_blank">arXiv:2010.09515</a> [<a href="http://arxiv.org/pdf/2010.09515" target="_blank">pdf</a>]

<h2>Model-based Policy Optimization with Unsupervised Model Adaptation. (arXiv:2010.09546v1 [cs.LG])</h2>
<h3>Jian Shen, Han Zhao, Weinan Zhang, Yong Yu</h3>
<p>Model-based reinforcement learning methods learn a dynamics model with real
data sampled from the environment and leverage it to generate simulated data to
derive an agent. However, due to the potential distribution mismatch between
simulated data and real data, this could lead to degraded performance. Despite
much effort being devoted to reducing this distribution mismatch, existing
methods fail to solve it explicitly. In this paper, we investigate how to
bridge the gap between real and simulated data due to inaccurate model
estimation for better policy optimization. To begin with, we first derive a
lower bound of the expected return, which naturally inspires a bound
maximization algorithm by aligning the simulated and real data distributions.
To this end, we propose a novel model-based reinforcement learning framework
AMPO, which introduces unsupervised model adaptation to minimize the integral
probability metric (IPM) between feature distributions from real and simulated
data. Instantiating our framework with Wasserstein-1 distance gives a practical
model-based approach. Empirically, our approach achieves state-of-the-art
performance in terms of sample efficiency on a range of continuous control
benchmark tasks.
</p>
<a href="http://arxiv.org/abs/2010.09546" target="_blank">arXiv:2010.09546</a> [<a href="http://arxiv.org/pdf/2010.09546" target="_blank">pdf</a>]

<h2>Do Deeper Convolutional Networks Perform Better?. (arXiv:2010.09610v1 [cs.LG])</h2>
<h3>Eshaan Nichani, Adityanarayanan Radhakrishnan, Caroline Uhler</h3>
<p>Over-parameterization is a recent topic of much interest in the machine
learning community. While over-parameterized neural networks are capable of
perfectly fitting (interpolating) training data, these networks often perform
well on test data, thereby contradicting classical learning theory. Recent work
provided an explanation for this phenomenon by introducing the double descent
curve, showing that increasing model capacity past the interpolation threshold
can lead to a decrease in test error. In line with this, it was recently shown
empirically and theoretically that increasing neural network capacity through
width leads to double descent. In this work, we analyze the effect of
increasing depth on test performance. In contrast to what is observed for
increasing width, we demonstrate through a variety of classification
experiments on CIFAR10 and ImageNet32 using ResNets and fully-convolutional
networks that test performance worsens beyond a critical depth. We posit an
explanation for this phenomenon by drawing intuition from the principle of
minimum norm solutions in linear networks.
</p>
<a href="http://arxiv.org/abs/2010.09610" target="_blank">arXiv:2010.09610</a> [<a href="http://arxiv.org/pdf/2010.09610" target="_blank">pdf</a>]

<h2>Semi-supervised Batch Active Learning via Bilevel Optimization. (arXiv:2010.09654v1 [cs.LG])</h2>
<h3>Zal&#xe1;n Borsos, Marco Tagliasacchi, Andreas Krause</h3>
<p>Active learning is an effective technique for reducing the labeling cost by
improving data efficiency. In this work, we propose a novel batch acquisition
strategy for active learning in the setting where the model training is
performed in a semi-supervised manner. We formulate our approach as a data
summarization problem via bilevel optimization, where the queried batch
consists of the points that best summarize the unlabeled data pool. We show
that our method is highly effective in keyword detection tasks in the regime
when only few labeled samples are available.
</p>
<a href="http://arxiv.org/abs/2010.09654" target="_blank">arXiv:2010.09654</a> [<a href="http://arxiv.org/pdf/2010.09654" target="_blank">pdf</a>]

<h2>Covariate powered cross-weighted multiple testing. (arXiv:1701.05179v5 [stat.ME] UPDATED)</h2>
<h3>Nikolaos Ignatiadis, Wolfgang Huber</h3>
<p>A fundamental task in the analysis of datasets with many variables is
screening for associations. This can be cast as a multiple testing task, where
the objective is achieving high detection power while controlling type I error.
We consider $m$ hypothesis tests represented by pairs $((P_i, X_i))_{1\leq i
\leq m}$ of p-values $P_i$ and covariates $X_i$, such that $P_i \perp X_i$ if
$H_i$ is null. Here, we show how to use information potentially available in
the covariates about heterogeneities among hypotheses to increase power
compared to conventional procedures that only use the $P_i$. To this end, we
upgrade existing weighted multiple testing procedures through the Independent
Hypothesis Weighting (IHW) framework to use data-driven weights that are
calculated as a function of the covariates. Finite sample guarantees, e.g.,
false discovery rate (FDR) control, are derived from cross-weighting, a
data-splitting approach that enables learning the weight-covariate function
without overfitting as long as the hypotheses can be partitioned into
independent folds, with arbitrary within-fold dependence. IHW has increased
power compared to methods that do not use covariate information. A key
implication of IHW is that hypothesis rejection in common multiple testing
setups should not proceed according to the ranking of the p-values, but by an
alternative ranking implied by the covariate-weighted p-values.
</p>
<a href="http://arxiv.org/abs/1701.05179" target="_blank">arXiv:1701.05179</a> [<a href="http://arxiv.org/pdf/1701.05179" target="_blank">pdf</a>]

<h2>False Discovery Rates to Detect Signals from Incomplete Spatially Aggregated Data. (arXiv:1905.06268v3 [stat.ME] UPDATED)</h2>
<h3>Hsin-Cheng Huang, Noel Cressie, Andrew Zammit-Mangion, Guowen Huang</h3>
<p>There are a number of ways to test for the absence/presence of a spatial
signal in a completely observed fine-resolution image. One of these is a
powerful nonparametric procedure called Enhanced False Discovery Rate (EFDR). A
drawback of EFDR is that it requires the data to be defined on regular pixels
in a rectangular spatial domain. Here, we develop an EFDR procedure for
possibly incomplete data defined on irregular small areas. Motivated by
statistical learning, we use conditional simulation (CS) to condition on the
available data and simulate the full rectangular image at its finest resolution
many times (M, say). EFDR is then applied to each of these simulations
resulting in M estimates of the signal and M statistically dependent p-values.
Averaging over these estimates yields a single, combined estimate of a possible
signal, but inference is needed to determine whether there really is a signal
present. We test the original null hypothesis of no signal by combining the M
p-values into a single p-value using copulas and a composite likelihood. If the
null hypothesis of no signal is rejected, we use the combined estimate. We call
this new procedure EFDR-CS and, to demonstrate its effectiveness, we show
results from a simulation study; an experiment where we introduce aggregation
and incompleteness into temperature-change data in the Asia-Pacific; and an
application to total-column carbon dioxide from satellite remote sensing data
over a region of the Middle East, Afghanistan, and the western part of
Pakistan.
</p>
<a href="http://arxiv.org/abs/1905.06268" target="_blank">arXiv:1905.06268</a> [<a href="http://arxiv.org/pdf/1905.06268" target="_blank">pdf</a>]

<h2>Bayesian joint modeling of chemical structure and dose response curves. (arXiv:1912.12228v2 [stat.AP] UPDATED)</h2>
<h3>Kelly R. Moran, David Dunson, Matthew W. Wheeler, Amy H. Herring</h3>
<p>Today there are approximately 85,000 chemicals regulated under the Toxic
Substances Control Act, with around 2,000 new chemicals introduced each year.
It is impossible to screen all of these chemicals for potential toxic effects
either via full organism in vivo studies or in vitro high-throughput screening
(HTS) programs. Toxicologists face the challenge of choosing which chemicals to
screen, and predicting the toxicity of as-yet-unscreened chemicals. Our goal is
to describe how variation in chemical structure relates to variation in
toxicological response to enable in silico toxicity characterization designed
to meet both of these challenges. With our Bayesian partially Supervised Sparse
and Smooth Factor Analysis ($\text{BS}^3\text{FA}$) model, we learn a distance
between chemicals targeted to toxicity, rather than one based on molecular
structure alone. Our model also enables the prediction of chemical
dose-response profiles based on chemical structure (that is, without in vivo or
in vitro testing) by taking advantage of a large database of chemicals that
have already been tested for toxicity in HTS programs. We show superior
simulation performance in distance learning and modest to large gains in
predictive ability compared to existing methods. Results from the
high-throughput screening data application elucidate the relationship between
chemical structure and a toxicity-relevant high-throughput assay. An R package
for $\text{BS}^3\text{FA}$ is available online at
https://github.com/kelrenmor/bs3fa.
</p>
<a href="http://arxiv.org/abs/1912.12228" target="_blank">arXiv:1912.12228</a> [<a href="http://arxiv.org/pdf/1912.12228" target="_blank">pdf</a>]

<h2>Minimal effect of prescribed burning on fire spread rate and intensity in savanna ecosystems. (arXiv:2005.07593v2 [q-bio.PE] UPDATED)</h2>
<h3>Aristides Moustakas, Orestis Davlias</h3>
<p>Fire is an integral part of the Earth for millennia. Several recent wildfires
have exhibited an unprecedented spatial and temporal extent and their control
is beyond national firefighting capabilities. Prescribed or controlled burning
treatments are debated as a potential measure for ameliorating the spread and
intensity of wildfires. Machine learning analysis using random forests was
performed in a spatio-temporal data set comprising a large number of savanna
fires across 22 years. Results indicate that controlled fire return interval
exhibited a feature importance of 3.5% regarding fire spread rate and 3.5%
regarding fire intensity. Manipulating burn seasonality showed a feature
importance of 5% regarding fire spread rate and 6% regarding fire intensity.
While manipulated fire return interval and seasonality moderated both fire
spread rate and intensity, their overall effects were low in comparison with
meteorological (hydrological and climatic) variables. Predicting fire spread
rate and intensity has been a poor endeavour thus far and we show that more
data of the variables already monitored would not result in higher predictive
accuracy.
</p>
<a href="http://arxiv.org/abs/2005.07593" target="_blank">arXiv:2005.07593</a> [<a href="http://arxiv.org/pdf/2005.07593" target="_blank">pdf</a>]

<h2>Daily Middle-Term Probabilistic Forecasting of Power Consumption in North-East England. (arXiv:2005.13005v2 [q-fin.ST] UPDATED)</h2>
<h3>Roberto Baviera, Giuseppe Messuti</h3>
<p>Probabilistic forecasting of power consumption in a middle-term horizon
(months to a year) is a main challenge in the energy sector. It plays a key
role in planning future generation plants and transmission grid. We propose a
new model that incorporates trend and seasonality features as in traditional
time-series analysis and weather conditions as explicative variables in a
parsimonious machine learning approach, known as Gaussian Process. Applying to
a daily power consumption dataset in North East England provided by one of the
largest energy suppliers, we obtain promising results in Out-of-Sample density
forecasts up to one year, even using a small dataset, with only a two-year
In-Sample data. In order to verify the quality of the achieved power
consumption probabilistic forecast we consider measures that are common in the
energy sector as pinball loss and Winkler score and backtesting conditional and
unconditional tests, standard in the banking sector after the introduction of
Basel II Accords.
</p>
<a href="http://arxiv.org/abs/2005.13005" target="_blank">arXiv:2005.13005</a> [<a href="http://arxiv.org/pdf/2005.13005" target="_blank">pdf</a>]

