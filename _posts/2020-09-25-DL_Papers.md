---
title: Latest Deep Learning Papers
date: 2020-11-07 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Cooperative Learning for P2P Energy Trading via Inverse Optimization and Interval Analysis. (arXiv:2011.02609v1 [eess.SY])</h2>
<h3>Dinh Hoa Nguyen</h3>
<p>Peer-to-peer (P2P) energy systems have recently emerged as a promising
approach for integrating renewable and distributed energy resources into energy
grids to reduce carbon emissions. However, market-clearing energy price and
amounts, resulted from solving optimal P2P energy management problems, might
not be satisfactory for peers/agents. This is because peers/agents in practice
do not know how to set their cost function parameters when participating into
P2P energy markets. To resolve such drawback, this paper proposes a novel
approach, in which an inverse optimization problem is formulated for
peers/agents to cooperatively learn to choose their objective function
parameters, given their intervals of desired energy prices and amounts. The
result is that peers/agents can set their objective function parameters in the
intervals computed analytically from the lower and upper bounds of their energy
price and amounts, if the ratio of their maximum total buying and selling
energy amounts lies in a certain interval subject to be learned by them. A case
study is then carried out, which validates the effectiveness of the proposed
approach.
</p>
<a href="http://arxiv.org/abs/2011.02609" target="_blank">arXiv:2011.02609</a> [<a href="http://arxiv.org/pdf/2011.02609" target="_blank">pdf</a>]

<h2>Binary Neural Network Aided CSI Feedback in Massive MIMO System. (arXiv:2011.02692v1 [cs.IT])</h2>
<h3>Zhilin Lu, Jintao Wang, Jian Song</h3>
<p>In massive multiple-input multiple-output (MIMO) system, channel state
information (CSI) is essential for the base station to achieve high performance
gain. Recently, deep learning is widely used in CSI compression to fight
against the growing feedback overhead brought by massive MIMO in frequency
division duplexing system. However, applying neural network brings extra memory
and computation cost, which is non-negligible especially for the resource
limited user equipment (UE). In this paper, a novel binarization aided feedback
network named BCsiNet is introduced. Moreover, BCsiNet variants are designed to
boost the performance under customized training and inference schemes.
Experiments shows that BCsiNet offers over 30$\times$ memory saving and around
2$\times$ inference acceleration for encoder at UE compared with CsiNet.
Furthermore, the feedback performance of BCsiNet is comparable with original
CsiNet. The key results can be reproduced with
https://github.com/Kylin9511/BCsiNet.
</p>
<a href="http://arxiv.org/abs/2011.02692" target="_blank">arXiv:2011.02692</a> [<a href="http://arxiv.org/pdf/2011.02692" target="_blank">pdf</a>]

<h2>Straggler Mitigation through Unequal Error Protection for Distributed Matrix Multiplication. (arXiv:2011.02749v1 [cs.IT])</h2>
<h3>Busra Tegin, Eduin E. Hernandez, Stefano Rini, Tolga M. Duman</h3>
<p>Large-scale machine learning and data mining methods routinely distribute
computations across multiple agents to parallelize processing. The time
required for computation at the agents is affected by the availability of local
resources: this gives rise to the "straggler problem" in which the computation
results are held back by unresponsive agents. For this problem, linear coding
of the matrix sub-blocks can be used to introduce resilience toward straggling.
The Parameter Server (PS) codes the matrix products and distributes the matrix
to the workers to perform multiplication. At a given deadline, it then produces
an approximation the desired matrix multiplication using the results of the
computation received so far. In this paper, we propose a novel coding strategy
for the straggler problem which relies on Unequal Error Protection (UEP) codes.
The resiliency level of each sub-block is chosen according to its norm, since
blocks with larger norms affect more the approximation of the matrix
multiplication. We validate the effectiveness of our scheme both theoretically,
as well as through numerical evaluations. We derive a theoretical
characterization of the performance of UPE using random linear codes and
compare it the case of equal error protection. We also apply the proposed
coding strategy to the computation of the back-propagation step in the training
a Deep Neural Network (DNN). In this scenario, we investigate the fundamental
trade-off between precision of the updates versus time required for their
computation.
</p>
<a href="http://arxiv.org/abs/2011.02749" target="_blank">arXiv:2011.02749</a> [<a href="http://arxiv.org/pdf/2011.02749" target="_blank">pdf</a>]

<h2>GMM-based Symbol Error Rate Prediction for Multicarrier Systems with Impulsive Noise Suppression. (arXiv:2011.02792v1 [cs.IT])</h2>
<h3>Nikola Rozic, Paolo Banelli, Dinko Begusic, Josko Radic</h3>
<p>Theoretical analysis of orthogonal frequency division multiplexing (OFDM)
systems equipped at the receiver by a non-linear impulsive noise suppressor is
a challenging topic in communication systems. Indeed, although an exact
closed-form expression for the output signal-to-noise ratio (SNR) of such OFDM
systems is available for widely used impulsive noise models, theoretical
analysis of the associated symbol error rate (SER) is still open. So far, the
analytical SER expressions available in the literature approximate the
time-domain impulsive noise, as Gaussian distributed in the discrete frequency
domain. Conversely, this work presents an accurate analysis of the distortion
noise at the nonlinearity output exploiting a Gaussian mixture model (GMM). By
using GMMs we unified the approach of SER prediction for unmitigated systems,
as well as for the mitigated ones, equipped by non-linear impulsive noise
suppressors, including blanking, clipping, clipping-blanking and attenuating
processors. Closed form expressions for the SER are derived both for non-fading
and frequency-selective Rayleigh and Rician fading channels affected by
impulsive noise which is represented by GMMs, thus including Bernoulli-Gaussian
(BG), Middleton Class-A, as well as (approximated) alpha-stable noise.
Theoretic SER performance are compared with simulations, showing very good
agreement for all the impulsive noise scenarios and the non-linear suppressors.
</p>
<a href="http://arxiv.org/abs/2011.02792" target="_blank">arXiv:2011.02792</a> [<a href="http://arxiv.org/pdf/2011.02792" target="_blank">pdf</a>]

<h2>Transfer Meta-Learning: Information-Theoretic Bounds and Information Meta-Risk Minimization. (arXiv:2011.02872v1 [cs.LG])</h2>
<h3>Sharu Theresa Jose, Osvaldo Simeone</h3>
<p>Meta-learning automatically infers an inductive bias by observing data from a
number of related tasks. The inductive bias is encoded by hyperparameters that
determine aspects of the model class or training algorithm, such as
initialization or learning rate. Meta-learning assumes that the learning tasks
belong to a task environment, and that tasks are drawn from the same task
environment both during meta-training and meta-testing. This, however, may not
hold true in practice. In this paper, we introduce the problem of transfer
meta-learning, in which tasks are drawn from a target task environment during
meta-testing that may differ from the source task environment observed during
meta-training. Novel information-theoretic upper bounds are obtained on the
transfer meta-generalization gap, which measures the difference between the
meta-training loss, available at the meta-learner, and the average loss on
meta-test data from a new, randomly selected, task in the target task
environment. The first bound, on the average transfer meta-generalization gap,
captures the meta-environment shift between source and target task environments
via the KL divergence between source and target data distributions. The second,
PAC-Bayesian bound, and the third, single-draw bound, account for this shift
via the log-likelihood ratio between source and target task distributions.
Furthermore, two transfer meta-learning solutions are introduced. For the
first, termed Empirical Meta-Risk Minimization (EMRM), we derive bounds on the
average optimality gap. The second, referred to as Information Meta-Risk
Minimization (IMRM), is obtained by minimizing the PAC-Bayesian bound. IMRM is
shown via experiments to potentially outperform EMRM.
</p>
<a href="http://arxiv.org/abs/2011.02872" target="_blank">arXiv:2011.02872</a> [<a href="http://arxiv.org/pdf/2011.02872" target="_blank">pdf</a>]

<h2>An SMT-Based Approach for Verifying Binarized Neural Networks. (arXiv:2011.02948v1 [cs.LG])</h2>
<h3>Guy Amir, Haoze Wu, Clark Barrett, Guy Katz</h3>
<p>Deep learning has emerged as an effective approach for creating modern
software systems, with neural networks often surpassing hand-crafted systems.
Unfortunately, neural networks are known to suffer from various safety and
security issues. Formal verification is a promising avenue for tackling this
difficulty, by formally certifying that networks are correct. We propose an
SMT-based technique for verifying \emph{binarized neural networks} - a popular
kind of neural networks, where some weights have been binarized in order to
render the neural network more memory and energy efficient, and quicker to
evaluate. One novelty of our technique is that it allows the verification of
neural networks that include both binarized and non-binarized components.
Neural network verification is computationally very difficult, and so we
propose here various optimizations, integrated into our SMT procedure as
deduction steps, as well as an approach for parallelizing verification queries.
We implement our technique as an extension to the Marabou framework, and use it
to evaluate the approach on popular binarized neural network architectures.
</p>
<a href="http://arxiv.org/abs/2011.02948" target="_blank">arXiv:2011.02948</a> [<a href="http://arxiv.org/pdf/2011.02948" target="_blank">pdf</a>]

<h2>Simple and optimal methods for stochastic variational inequalities, I: operator extrapolation. (arXiv:2011.02987v1 [math.OC])</h2>
<h3>Georgios Kotsalis, Guanghui Lan, Tianjiao Li</h3>
<p>In this paper we first present a novel operator extrapolation (OE) method for
solving deterministic variational inequality (VI) problems. Similar to the
gradient (operator) projection method, OE updates one single search sequence by
solving a single projection subproblem in each iteration. We show that OE can
achieve the optimal rate of convergence for solving a variety of VI problems in
a much simpler way than existing approaches. We then introduce the stochastic
operator extrapolation (SOE) method and establish its optimal convergence
behavior for solving different stochastic VI problems. In particular, SOE
achieves the optimal complexity for solving a fundamental problem, i.e.,
stochastic smooth and strongly monotone VI, for the first time in the
literature. We also present a stochastic block operator extrapolations (SBOE)
method to further reduce the iteration cost for the OE method applied to
large-scale deterministic VIs with a certain block structure. Numerical
experiments have been conducted to demonstrate the potential advantages of the
proposed algorithms. In fact, all these algorithms are applied to solve
generalized monotone variational inequality (GMVI) problems whose operator is
not necessarily monotone. We will also discuss optimal OE-based policy
evaluation methods for reinforcement learning in a companion paper.
</p>
<a href="http://arxiv.org/abs/2011.02987" target="_blank">arXiv:2011.02987</a> [<a href="http://arxiv.org/pdf/2011.02987" target="_blank">pdf</a>]

<h2>Fast Rates for Contextual Linear Optimization. (arXiv:2011.03030v1 [stat.ML])</h2>
<h3>Yichun Hu, Nathan Kallus, Xiaojie Mao</h3>
<p>Incorporating side observations of predictive features can help reduce
uncertainty in operational decision making, but it also requires we tackle a
potentially complex predictive relationship. Although one may use a variety of
off-the-shelf machine learning methods to learn a predictive model and then
plug it into our decision-making problem, a variety of recent work has instead
advocated integrating estimation and optimization by taking into consideration
downstream decision performance. Surprisingly, in the case of contextual linear
optimization, we show that the naive plug-in approach actually achieves regret
convergence rates that are significantly faster than the best-possible by
methods that directly optimize down-stream decision performance. We show this
by leveraging the fact that specific problem instances do not have arbitrarily
bad near-degeneracy. While there are other pros and cons to consider as we
discuss, our results highlight a very nuanced landscape for the enterprise to
integrate estimation and optimization.
</p>
<a href="http://arxiv.org/abs/2011.03030" target="_blank">arXiv:2011.03030</a> [<a href="http://arxiv.org/pdf/2011.03030" target="_blank">pdf</a>]

<h2>Inverse Learning: A Data-driven Framework to Infer Optimizations Models. (arXiv:2011.03038v1 [math.OC])</h2>
<h3>Farzin Ahmadi, Fardin Ganjkhanloo, Kimia Ghobadi</h3>
<p>We consider the problem of inferring optimal solutions and unknown parameters
of a partially-known constrained problem using a set of past decisions. We
assume that the constraints of the original optimization problem are known
while optimal decisions and the objective are to be inferred. In such
situations, the quality of the optimal solution is evaluated in relation to the
existing observations and the known parameters of the constrained problem. A
method previously used in such settings is inverse optimization. This method
can be used to infer the utility functions of a decision-maker and to find
optimal solutions based on these inferred parameters indirectly. However,
little effort has been made to generalize the inverse optimization methodology
to data-driven settings to address the quality of the inferred optimal
solutions. In this work, we present a data-driven inverse linear optimization
framework (Inverse Learning) that aims to infer the optimal solution to an
optimization problem directly based on the observed data and the existing known
parameters of the problem. We validate our model on a dataset in the diet
recommendation problem setting to find personalized diets for prediabetic
patients with hypertension. Our results show that our model obtains optimal
personalized daily food intakes that preserve the original data trends while
providing a range of options to patients and providers. The results show that
our proposed model is able to both capture optimal solutions with minimal
perturbation from the given observations and, at the same time, achieve the
inherent objectives of the original problem. We show an inherent trade-off in
the quality of the inferred solutions with different metrics and provide
insights into how a range of optimal solutions can be inferred in constrained
environments.
</p>
<a href="http://arxiv.org/abs/2011.03038" target="_blank">arXiv:2011.03038</a> [<a href="http://arxiv.org/pdf/2011.03038" target="_blank">pdf</a>]

<h2>Learning low-dimensional dynamical-system models from noisy frequency-response data with Loewner rational interpolation. (arXiv:1910.00110v2 [math.NA] UPDATED)</h2>
<h3>Zlatko Drma&#x10d;, Benjamin Peherstorfer</h3>
<p>Loewner rational interpolation provides a versatile tool to learn
low-dimensional dynamical-system models from frequency-response measurements.
This work investigates the robustness of the Loewner approach to noise. The key
finding is that if the measurements are polluted with Gaussian noise, then the
error due to noise grows at most linearly with the standard deviation with high
probability under certain conditions. The analysis gives insights into making
the Loewner approach robust against noise via linear transformations and
judicious selections of measurements. Numerical results demonstrate the linear
growth of the error on benchmark examples.
</p>
<a href="http://arxiv.org/abs/1910.00110" target="_blank">arXiv:1910.00110</a> [<a href="http://arxiv.org/pdf/1910.00110" target="_blank">pdf</a>]

<h2>Ground Metric Learning on Graphs. (arXiv:1911.03117v3 [stat.ML] UPDATED)</h2>
<h3>Matthieu Heitz, Nicolas Bonneel, David Coeurjolly, Marco Cuturi, Gabriel Peyr&#xe9;</h3>
<p>Optimal transport (OT) distances between probability distributions are
parameterized by the ground metric they use between observations. Their
relevance for real-life applications strongly hinges on whether that ground
metric parameter is suitably chosen. Selecting it adaptively and
algorithmically from prior knowledge, the so-called ground metric learning GML)
problem, has therefore appeared in various settings. We consider it in this
paper when the learned metric is constrained to be a geodesic distance on a
graph that supports the measures of interest. This imposes a rich structure for
candidate metrics, but also enables far more efficient learning procedures when
compared to a direct optimization over the space of all metric matrices. We use
this setting to tackle an inverse problem stemming from the observation of a
density evolving with time: we seek a graph ground metric such that the OT
interpolation between the starting and ending densities that result from that
ground metric agrees with the observed evolution. This OT dynamic framework is
relevant to model natural phenomena exhibiting displacements of mass, such as
for instance the evolution of the color palette induced by the modification of
lighting and materials.
</p>
<a href="http://arxiv.org/abs/1911.03117" target="_blank">arXiv:1911.03117</a> [<a href="http://arxiv.org/pdf/1911.03117" target="_blank">pdf</a>]

<h2>Minimax Value Interval for Off-Policy Evaluation and Policy Optimization. (arXiv:2002.02081v6 [cs.LG] UPDATED)</h2>
<h3>Nan Jiang, Jiawei Huang</h3>
<p>We study minimax methods for off-policy evaluation (OPE) using value
functions and marginalized importance weights. Despite that they hold promises
of overcoming the exponential variance in traditional importance sampling,
several key problems remain:

(1) They require function approximation and are generally biased. For the
sake of trustworthy OPE, is there anyway to quantify the biases?

(2) They are split into two styles ("weight-learning" vs "value-learning").
Can we unify them?

In this paper we answer both questions positively. By slightly altering the
derivation of previous methods (one from each style; Uehara et al., 2020), we
unify them into a single value interval that comes with a special type of
double robustness: when either the value-function or the importance-weight
class is well specified, the interval is valid and its length quantifies the
misspecification of the other class. Our interval also provides a unified view
of and new insights to some recent methods, and we further explore the
implications of our results on exploration and exploitation in off-policy
policy optimization with insufficient data coverage.
</p>
<a href="http://arxiv.org/abs/2002.02081" target="_blank">arXiv:2002.02081</a> [<a href="http://arxiv.org/pdf/2002.02081" target="_blank">pdf</a>]

<h2>Explore Aggressively, Update Conservatively: Stochastic Extragradient Methods with Variable Stepsize Scaling. (arXiv:2003.10162v2 [math.OC] UPDATED)</h2>
<h3>Yu-Guan Hsieh, Franck Iutzeler, J&#xe9;r&#xf4;me Malick, Panayotis Mertikopoulos</h3>
<p>Owing to their stability and convergence speed, extragradient methods have
become a staple for solving large-scale saddle-point problems in machine
learning. The basic premise of these algorithms is the use of an extrapolation
step before performing an update; thanks to this exploration step,
extra-gradient methods overcome many of the non-convergence issues that plague
gradient descent/ascent schemes. On the other hand, as we show in this paper,
running vanilla extragradient with stochastic gradients may jeopardize its
convergence, even in simple bilinear models. To overcome this failure, we
investigate a double stepsize extragradient algorithm where the exploration
step evolves at a more aggressive time-scale compared to the update step. We
show that this modification allows the method to converge even with stochastic
gradients, and we derive sharp convergence rates under an error bound
condition.
</p>
<a href="http://arxiv.org/abs/2003.10162" target="_blank">arXiv:2003.10162</a> [<a href="http://arxiv.org/pdf/2003.10162" target="_blank">pdf</a>]

<h2>Social welfare relations and irregular sets. (arXiv:2004.10843v2 [math.LO] UPDATED)</h2>
<h3>Ram Sewak Dubey, Giorgio Laguzzi</h3>
<p>Total social welfare relations satisfying Pareto and equity principles on
infinite utility streams has revealed a non-constructive nature. In this paper
we study more deeply the needed fragment of AC. In particular, we show that
such relations need a strictly larger fragment of AC than non-Lebesgue and
non-Ramsey sets. We also prove a connection with the Baire property, answering
Problem 11.14 posed in "Flutters and chameleon", by Mathias et al.
</p>
<a href="http://arxiv.org/abs/2004.10843" target="_blank">arXiv:2004.10843</a> [<a href="http://arxiv.org/pdf/2004.10843" target="_blank">pdf</a>]

<h2>On the Convergence of Consensus Algorithms with Markovian Noise and Gradient Bias. (arXiv:2008.07841v3 [math.OC] UPDATED)</h2>
<h3>Hoi-To Wai</h3>
<p>This paper presents a finite time convergence analysis for a decentralized
stochastic approximation (SA) scheme. The scheme generalizes several algorithms
for decentralized machine learning and multi-agent reinforcement learning. Our
proof technique involves separating the iterates into their respective
consensual parts and consensus error. The consensus error is bounded in terms
of the stationarity of the consensual part, while the updates of the consensual
part can be analyzed as a perturbed SA scheme. Under the Markovian noise and
time varying communication graph assumptions, the decentralized SA scheme has
an expected convergence rate of ${\cal O}(\log T/ \sqrt{T} )$, where $T$ is the
iteration number, in terms of squared norms of gradient for nonlinear SA with
smooth but non-convex cost function. This rate is comparable to the best known
performances of SA in a centralized setting with a non-convex potential
function.
</p>
<a href="http://arxiv.org/abs/2008.07841" target="_blank">arXiv:2008.07841</a> [<a href="http://arxiv.org/pdf/2008.07841" target="_blank">pdf</a>]

<h2>Learning from Human Feedback: Challenges for Real-World Reinforcement Learning in NLP. (arXiv:2011.02511v1 [cs.CL])</h2>
<h3>Julia Kreutzer, Stefan Riezler, Carolin Lawrence</h3>
<p>Large volumes of interaction logs can be collected from NLP systems that are
deployed in the real world. How can this wealth of information be leveraged?
Using such interaction logs in an offline reinforcement learning (RL) setting
is a promising approach. However, due to the nature of NLP tasks and the
constraints of production systems, a series of challenges arise. We present a
concise overview of these challenges and discuss possible solutions.
</p>
<a href="http://arxiv.org/abs/2011.02511" target="_blank">arXiv:2011.02511</a> [<a href="http://arxiv.org/pdf/2011.02511" target="_blank">pdf</a>]

<h2>Monitoring the Impact of Wildfires on Tree Species with Deep Learning. (arXiv:2011.02514v1 [cs.CV])</h2>
<h3>Wang Zhou, Levente Klein</h3>
<p>One of the impacts of climate change is the difficulty of tree regrowth after
wildfires over areas that traditionally were covered by certain tree species.
Here a deep learning model is customized to classify land covers from four-band
aerial imagery before and after wildfires to study the prolonged consequences
of wildfires on tree species. The tree species labels are generated from
manually delineated maps for five land cover classes: Conifer, Hardwood, Shrub,
ReforestedTree and Barren land. With an accuracy of $92\%$ on the test split,
the model is applied to three wildfires on data from 2009 to 2018. The model
accurately delineates areas damaged by wildfires, changes in tree species and
rebound of burned areas. The result shows clear evidence of wildfires impacting
the local ecosystem and the outlined approach can help monitor reforested
areas, observe changes in forest composition and track wildfire impact on tree
species.
</p>
<a href="http://arxiv.org/abs/2011.02514" target="_blank">arXiv:2011.02514</a> [<a href="http://arxiv.org/pdf/2011.02514" target="_blank">pdf</a>]

<h2>Hypersim: A Photorealistic Synthetic Dataset for Holistic Indoor Scene Understanding. (arXiv:2011.02523v1 [cs.CV])</h2>
<h3>Mike Roberts, Nathan Paczan</h3>
<p>For many fundamental scene understanding tasks, it is difficult or impossible
to obtain per-pixel ground truth labels from real images. We address this
challenge by introducing Hypersim, a photorealistic synthetic dataset for
holistic indoor scene understanding. To create our dataset, we leverage a large
repository of synthetic scenes created by professional artists, and we generate
77,400 images of 461 indoor scenes with detailed per-pixel labels and
corresponding ground truth geometry. Our dataset: (1) relies exclusively on
publicly available 3D assets; (2) includes complete scene geometry, material
information, and lighting information for every scene; (3) includes dense
per-pixel semantic instance segmentations for every image; and (4) factors
every image into diffuse reflectance, diffuse illumination, and a non-diffuse
residual term that captures view-dependent lighting effects. Together, these
features make our dataset well-suited for geometric learning problems that
require direct 3D supervision, multi-task learning problems that require
reasoning jointly over multiple input and output modalities, and inverse
rendering problems. We analyze our dataset at the level of scenes, objects, and
pixels, and we analyze costs in terms of money, annotation effort, and
computation time. Remarkably, we find that it is possible to generate our
entire dataset from scratch, for roughly half the cost of training a
state-of-the-art natural language processing model. All the code we used to
generate our dataset will be made available online.
</p>
<a href="http://arxiv.org/abs/2011.02523" target="_blank">arXiv:2011.02523</a> [<a href="http://arxiv.org/pdf/2011.02523" target="_blank">pdf</a>]

<h2>Direction Matters: On the Implicit Regularization Effect of Stochastic Gradient Descent with Moderate Learning Rate. (arXiv:2011.02538v1 [cs.LG])</h2>
<h3>Jingfeng Wu, Difan Zou, Vladimir Braverman, Quanquan Gu</h3>
<p>Understanding the algorithmic regularization effect of stochastic gradient
descent (SGD) is one of the key challenges in modern machine learning and deep
learning theory. Most of the existing works, however, focus on very small or
even infinitesimal learning rate regime, and fail to cover practical scenarios
where the learning rate is moderate and annealing. In this paper, we make an
initial attempt to characterize the particular regularization effect of SGD in
the moderate learning rate regime by studying its behavior for optimizing an
overparameterized linear regression problem. In this case, SGD and GD are known
to converge to the unique minimum-norm solution; however, with the moderate and
annealing learning rate, we show that they exhibit different directional bias:
SGD converges along the large eigenvalue directions of the data matrix, while
GD goes after the small eigenvalue directions. Furthermore, we show that such
directional bias does matter when early stopping is adopted, where the SGD
output is nearly optimal but the GD output is suboptimal. Finally, our theory
explains several folk arts in practice used for SGD hyperparameter tuning, such
as (1) linearly scaling the initial learning rate with batch size; and (2)
overrunning SGD with high learning rate even when the loss stops decreasing.
</p>
<a href="http://arxiv.org/abs/2011.02538" target="_blank">arXiv:2011.02538</a> [<a href="http://arxiv.org/pdf/2011.02538" target="_blank">pdf</a>]

<h2>MTLB-STRUCT @PARSEME 2020: Capturing Unseen Multiword Expressions Using Multi-task Learning and Pre-trained Masked Language Models. (arXiv:2011.02541v1 [cs.CL])</h2>
<h3>Shiva Taslimipoor, Sara Bahaadini, Ekaterina Kochmar</h3>
<p>This paper describes a semi-supervised system that jointly learns verbal
multiword expressions (VMWEs) and dependency parse trees as an auxiliary task.
The model benefits from pre-trained multilingual BERT. BERT hidden layers are
shared among the two tasks and we introduce an additional linear layer to
retrieve VMWE tags. The dependency parse tree prediction is modelled by a
linear layer and a bilinear one plus a tree CRF on top of BERT. The system has
participated in the open track of the PARSEME shared task 2020 and ranked first
in terms of F1-score in identifying unseen VMWEs as well as VMWEs in general,
averaged across all 14 languages.
</p>
<a href="http://arxiv.org/abs/2011.02541" target="_blank">arXiv:2011.02541</a> [<a href="http://arxiv.org/pdf/2011.02541" target="_blank">pdf</a>]

<h2>Mutual Modality Learning for Video Action Classification. (arXiv:2011.02543v1 [cs.CV])</h2>
<h3>Stepan Komkov, Maksim Dzabraev, Aleksandr Petiushko</h3>
<p>The construction of models for video action classification progresses
rapidly. However, the performance of those models can still be easily improved
by ensembling with the same models trained on different modalities (e.g.
Optical flow). Unfortunately, it is computationally expensive to use several
modalities during inference. Recent works examine the ways to integrate
advantages of multi-modality into a single RGB-model. Yet, there is still a
room for improvement. In this paper, we explore the various methods to embed
the ensemble power into a single model. We show that proper initialization, as
well as mutual modality learning, enhances single-modality models. As a result,
we achieve state-of-the-art results in the Something-Something-v2 benchmark.
</p>
<a href="http://arxiv.org/abs/2011.02543" target="_blank">arXiv:2011.02543</a> [<a href="http://arxiv.org/pdf/2011.02543" target="_blank">pdf</a>]

<h2>Polymers for Extreme Conditions Designed Using Syntax-Directed Variational Autoencoders. (arXiv:2011.02551v1 [cond-mat.soft])</h2>
<h3>Rohit Batra, Hanjun Dai, Tran Doan Huan, Lihua Chen, Chiho Kim, Will R. Gutekunst, Le Song, Rampi Ramprasad</h3>
<p>The design/discovery of new materials is highly non-trivial owing to the
near-infinite possibilities of material candidates, and multiple required
property/performance objectives. Thus, machine learning tools are now commonly
employed to virtually screen material candidates with desired properties by
learning a theoretical mapping from material-to-property space, referred to as
the \emph{forward} problem. However, this approach is inefficient, and severely
constrained by the candidates that human imagination can conceive. Thus, in
this work on polymers, we tackle the materials discovery challenge by solving
the \emph{inverse} problem: directly generating candidates that satisfy desired
property/performance objectives. We utilize syntax-directed variational
autoencoders (VAE) in tandem with Gaussian process regression (GPR) models to
discover polymers expected to be robust under three extreme conditions: (1)
high temperatures, (2) high electric field, and (3) high temperature \emph{and}
high electric field, useful for critical structural, electrical and energy
storage applications. This approach to learn from (and augment) human ingenuity
is general, and can be extended to discover polymers with other targeted
properties and performance measures.
</p>
<a href="http://arxiv.org/abs/2011.02551" target="_blank">arXiv:2011.02551</a> [<a href="http://arxiv.org/pdf/2011.02551" target="_blank">pdf</a>]

<h2>Re-Assessing the "Classify and Count" Quantification Method. (arXiv:2011.02552v1 [cs.LG])</h2>
<h3>Alejandro Moreo, Fabrizio Sebastiani</h3>
<p>Learning to quantify (a.k.a.\ quantification) is a task concerned with
training unbiased estimators of class prevalence via supervised learning. This
task originated with the observation that "Classify and Count" (CC), the
trivial method of obtaining class prevalence estimates, is often a biased
estimator, and thus delivers suboptimal quantification accuracy; following this
observation, several methods for learning to quantify have been proposed that
have been shown to outperform CC. In this work we contend that previous works
have failed to use properly optimised versions of CC. We thus reassess the real
merits of CC (and its variants), and argue that, while still inferior to some
cutting-edge methods, they deliver near-state-of-the-art accuracy once (a)
hyperparameter optimisation is performed, and (b) this optimisation is
performed by using a true quantification loss instead of a standard
classification-based loss. Experiments on three publicly available binary
sentiment classification datasets support these conclusions.
</p>
<a href="http://arxiv.org/abs/2011.02552" target="_blank">arXiv:2011.02552</a> [<a href="http://arxiv.org/pdf/2011.02552" target="_blank">pdf</a>]

<h2>Impact of delayed response on Wearable Cognitive Assistance. (arXiv:2011.02555v1 [cs.HC])</h2>
<h3>M. Olgu&#xed;n Mu&#xf1;oz (1), R. Klatzky (2), J. Wang (3), P. Pillai (4), M. Satyanarayanan (3), J. Gross (1) ((1) School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, (2) Department of Psychology, Carnegie Mellon University, (3) School of Computer Science, Carnegie Mellon University, (4) Intel Labs, Pittsburgh)</h3>
<p>Wearable Cognitive Assistants (WCA) are anticipated to become a widely-used
application class, in conjunction with emerging network infrastructures like 5G
that incorporate edge computing capabilities. While prototypical studies of
such applications exist today, the relationship between infrastructure service
provisioning and its implication for WCA usability is largely unexplored
despite the relevance that these applications have for future networks. This
paper presents an experimental study assessing how WCA users react to varying
end-to-end delays induced by the application pipeline or infrastructure.
Participants interacted directly with an instrumented task-guidance WCA as
delays were introduced into the system in a controllable fashion. System and
task state were tracked in real time, and biometric data from wearable sensors
on the participants were recorded. Our results show that periods of extended
system delay cause users to correspondingly (and substantially) slow down in
their guided task execution, an effect that persists for a time after the
system returns to a more responsive state. Furthermore, the slow-down in task
execution is correlated with a personality trait, neuroticism, associated with
intolerance for time delays. We show that our results implicate impaired
cognitive planning, as contrasted with resource depletion or emotional arousal,
as the reason for slowed user task executions under system delay. The findings
have several implications for the design and operation of WCA applications as
well as computational and communication infrastructure, and additionally for
the development of performance analysis tools for WCA.
</p>
<a href="http://arxiv.org/abs/2011.02555" target="_blank">arXiv:2011.02555</a> [<a href="http://arxiv.org/pdf/2011.02555" target="_blank">pdf</a>]

<h2>Predict and Write: Using K-Means Clustering to Extend the Lifetime of NVM Storage. (arXiv:2011.02556v1 [cs.DB])</h2>
<h3>Saeed Kargar, Heiner Litz, Faisal Nawab</h3>
<p>Non-volatile memory (NVM) technologies suffer from limited write endurance.
To address this challenge, we propose Predict and Write (PNW), a K/V-store that
uses a clustering-based machine learning approach to extend the lifetime of
NVMs. PNW decreases the number of bit flips for PUT/UPDATE operations by
determining the best memory location an updated value should be written to. PNW
leverages the indirection level of K/V-stores to freely choose the target
memory location for any given write based on its value. PNW organizes NVM
addresses in a dynamic address pool clustered by the similarity of the data
values they refer to. We show that, by choosing the right target memory
location for a given PUT/UPDATE operation, the number of total bit flips and
cache lines can be reduced by up to 85% and 56% over the state of the art.
</p>
<a href="http://arxiv.org/abs/2011.02556" target="_blank">arXiv:2011.02556</a> [<a href="http://arxiv.org/pdf/2011.02556" target="_blank">pdf</a>]

<h2>Adaptive Stress Testing of Trajectory Predictions in Flight Management Systems. (arXiv:2011.02559v1 [cs.LG])</h2>
<h3>Robert J. Moss, Ritchie Lee, Nicholas Visser, Joachim Hochwarth, James G. Lopez, Mykel J. Kochenderfer</h3>
<p>To find failure events and their likelihoods in flight-critical systems, we
investigate the use of an advanced black-box stress testing approach called
adaptive stress testing. We analyze a trajectory predictor from a developmental
commercial flight management system which takes as input a collection of
lateral waypoints and en-route environmental conditions. Our aim is to search
for failure events relating to inconsistencies in the predicted lateral
trajectories. The intention of this work is to find likely failures and report
them back to the developers so they can address and potentially resolve
shortcomings of the system before deployment. To improve search performance,
this work extends the adaptive stress testing formulation to be applied more
generally to sequential decision-making problems with episodic reward by
collecting the state transitions during the search and evaluating at the end of
the simulated rollout. We use a modified Monte Carlo tree search algorithm with
progressive widening as our adversarial reinforcement learner. The performance
is compared to direct Monte Carlo simulations and to the cross-entropy method
as an alternative importance sampling baseline. The goal is to find potential
problems otherwise not found by traditional requirements-based testing. Results
indicate that our adaptive stress testing approach finds more failures and
finds failures with higher likelihood relative to the baseline approaches.
</p>
<a href="http://arxiv.org/abs/2011.02559" target="_blank">arXiv:2011.02559</a> [<a href="http://arxiv.org/pdf/2011.02559" target="_blank">pdf</a>]

<h2>A Multi-Channel Temporal Attention Convolutional Neural Network Model for Environmental Sound Classification. (arXiv:2011.02561v1 [eess.AS])</h2>
<h3>You Wang, Chuyao Feng, David V. Anderson</h3>
<p>Recently, many attention-based deep neural networks have emerged and achieved
state-of-the-art performance in environmental sound classification. The essence
of attention mechanism is assigning contribution weights on different parts of
features, namely channels, spectral or spatial contents, and temporal frames.
In this paper, we propose an effective convolutional neural network structure
with a multi-channel temporal attention (MCTA) block, which applies a temporal
attention mechanism within each channel of the embedded features to extract
channel-wise relevant temporal information. This multi-channel temporal
attention structure will result in a distinct attention vector for each
channel, which enables the network to fully exploit the relevant temporal
information in different channels. The datasets used to test our model include
ESC-50 and its subset ESC-10, along with development sets of DCASE 2018 and
2019. In our experiments, MCTA performed better than the single-channel
temporal attention model and the non-attention model with the same number of
parameters. Furthermore, we compared our model with some successful
attention-based models and obtained competitive results with a relatively
lighter network.
</p>
<a href="http://arxiv.org/abs/2011.02561" target="_blank">arXiv:2011.02561</a> [<a href="http://arxiv.org/pdf/2011.02561" target="_blank">pdf</a>]

<h2>Diversity-Enriched Option-Critic. (arXiv:2011.02565v1 [cs.LG])</h2>
<h3>Anand Kamat, Doina Precup</h3>
<p>Temporal abstraction allows reinforcement learning agents to represent
knowledge and develop strategies over different temporal scales. The
option-critic framework has been demonstrated to learn temporally extended
actions, represented as options, end-to-end in a model-free setting. However,
feasibility of option-critic remains limited due to two major challenges,
multiple options adopting very similar behavior, or a shrinking set of task
relevant options. These occurrences not only void the need for temporal
abstraction, they also affect performance. In this paper, we tackle these
problems by learning a diverse set of options. We introduce an
information-theoretic intrinsic reward, which augments the task reward, as well
as a novel termination objective, in order to encourage behavioral diversity in
the option set. We show empirically that our proposed method is capable of
learning options end-to-end on several discrete and continuous control tasks,
outperforms option-critic by a wide margin. Furthermore, we show that our
approach sustainably generates robust, reusable, reliable and interpretable
options, in contrast to option-critic.
</p>
<a href="http://arxiv.org/abs/2011.02565" target="_blank">arXiv:2011.02565</a> [<a href="http://arxiv.org/pdf/2011.02565" target="_blank">pdf</a>]

<h2>DUDE: Deep Unsigned Distance Embeddings for Hi-Fidelity Representation of Complex 3D Surfaces. (arXiv:2011.02570v1 [cs.CV])</h2>
<h3>Rahul Venkatesh, Sarthak Sharma, Aurobrata Ghosh, Laszlo Jeni, Maneesh Singh</h3>
<p>High fidelity representation of shapes with arbitrary topology is an
important problem for a variety of vision and graphics applications. Owing to
their limited resolution, classical discrete shape representations using point
clouds, voxels and meshes produce low quality results when used in these
applications. Several implicit 3D shape representation approaches using deep
neural networks have been proposed leading to significant improvements in both
quality of representations as well as the impact on downstream applications.
However, these methods can only be used to represent topologically closed
shapes which greatly limits the class of shapes that they can represent. As a
consequence, they also often require clean, watertight meshes for training. In
this work, we propose DUDE - a Deep Unsigned Distance Embedding method which
alleviates both of these shortcomings. DUDE is a disentangled shape
representation that utilizes an unsigned distance field (uDF) to represent
proximity to a surface, and a normal vector field (nVF) to represent surface
orientation. We show that a combination of these two (uDF+nVF) can be used to
learn high fidelity representations for arbitrary open/closed shapes. As
opposed to prior work such as DeepSDF, our shape representations can be
directly learnt from noisy triangle soups, and do not need watertight meshes.
Additionally, we propose novel algorithms for extracting and rendering
iso-surfaces from the learnt representations. We validate DUDE on benchmark 3D
datasets and demonstrate that it produces significant improvements over the
state of the art.
</p>
<a href="http://arxiv.org/abs/2011.02570" target="_blank">arXiv:2011.02570</a> [<a href="http://arxiv.org/pdf/2011.02570" target="_blank">pdf</a>]

<h2>Multi-layer Feature Aggregation for Deep Scene Parsing Models. (arXiv:2011.02572v1 [cs.CV])</h2>
<h3>Litao Yu, Yongsheng Gao, Jun Zhou, Jian Zhang, Qiang Wu</h3>
<p>Scene parsing from images is a fundamental yet challenging problem in visual
content understanding. In this dense prediction task, the parsing model assigns
every pixel to a categorical label, which requires the contextual information
of adjacent image patches. So the challenge for this learning task is to
simultaneously describe the geometric and semantic properties of objects or a
scene. In this paper, we explore the effective use of multi-layer feature
outputs of the deep parsing networks for spatial-semantic consistency by
designing a novel feature aggregation module to generate the appropriate global
representation prior, to improve the discriminative power of features. The
proposed module can auto-select the intermediate visual features to correlate
the spatial and semantic information. At the same time, the multiple skip
connections form a strong supervision, making the deep parsing network easy to
train. Extensive experiments on four public scene parsing datasets prove that
the deep parsing network equipped with the proposed feature aggregation module
can achieve very promising results.
</p>
<a href="http://arxiv.org/abs/2011.02572" target="_blank">arXiv:2011.02572</a> [<a href="http://arxiv.org/pdf/2011.02572" target="_blank">pdf</a>]

<h2>Learning Trajectories for Visual-Inertial System Calibration via Model-based Heuristic Deep Reinforcement Learning. (arXiv:2011.02574v1 [cs.RO])</h2>
<h3>Le Chen, Yunke Ao, Florian Tschopp, Andrei Cramariuc, Michel Breyer, Jen Jen Chung, Roland Siegwart, Cesar Cadena</h3>
<p>Visual-inertial systems rely on precise calibrations of both camera
intrinsics and inter-sensor extrinsics, which typically require manually
performing complex motions in front of a calibration target. In this work we
present a novel approach to obtain favorable trajectories for visual-inertial
system calibration, using model-based deep reinforcement learning. Our key
contribution is to model the calibration process as a Markov decision process
and then use model-based deep reinforcement learning with particle swarm
optimization to establish a sequence of calibration trajectories to be
performed by a robot arm. Our experiments show that while maintaining similar
or shorter path lengths, the trajectories generated by our learned policy
result in lower calibration errors compared to random or handcrafted
trajectories.
</p>
<a href="http://arxiv.org/abs/2011.02574" target="_blank">arXiv:2011.02574</a> [<a href="http://arxiv.org/pdf/2011.02574" target="_blank">pdf</a>]

<h2>Learning and Evaluating Representations for Deep One-class Classification. (arXiv:2011.02578v1 [cs.CV])</h2>
<h3>Kihyuk Sohn, Chun-Liang Li, Jinsung Yoon, Minho Jin, Tomas Pfister</h3>
<p>We present a two-stage framework for deep one-class classification. We first
learn self-supervised representations from one-class data, and then build
one-class classifiers on learned representations. The framework not only allows
to learn better representations, but also permits building one-class
classifiers that are faithful to the target task. In particular, we present a
novel distribution-augmented contrastive learning that extends training
distributions via data augmentation to obstruct the uniformity of contrastive
representations. Moreover, we argue that classifiers inspired by the
statistical perspective in generative or discriminative models are more
effective than existing approaches, such as an average of normality scores from
a surrogate classifier. In experiments, we demonstrate state-of-the-art
performance on visual domain one-class classification benchmarks. Finally, we
present visual explanations, confirming that the decision-making process of our
deep one-class classifier is intuitive to humans. The code is available at:
https://github.com/google-research/google-research/tree/master/deep_representation_one_class.
</p>
<a href="http://arxiv.org/abs/2011.02578" target="_blank">arXiv:2011.02578</a> [<a href="http://arxiv.org/pdf/2011.02578" target="_blank">pdf</a>]

<h2>DeepReg: a deep learning toolkit for medical image registration. (arXiv:2011.02580v1 [eess.IV])</h2>
<h3>Yunguan Fu, Nina Monta&#xf1;a Brown, Shaheer U. Saeed, Adri&#xe0; Casamitjana, Zachary M. C. Baum, R&#xe9;mi Delaunay, Qianye Yang, Alexander Grimwood, Zhe Min, Stefano B. Blumberg, Juan Eugenio Iglesias, Dean C. Barratt, Ester Bonmati, Daniel C. Alexander, Matthew J. Clarkson, Tom Vercauteren, Yipeng Hu</h3>
<p>DeepReg (https://github.com/DeepRegNet/DeepReg) is a community-supported
open-source toolkit for research and education in medical image registration
using deep learning.
</p>
<a href="http://arxiv.org/abs/2011.02580" target="_blank">arXiv:2011.02580</a> [<a href="http://arxiv.org/pdf/2011.02580" target="_blank">pdf</a>]

<h2>AML-SVM: Adaptive Multilevel Learning with Support Vector Machines. (arXiv:2011.02592v1 [cs.LG])</h2>
<h3>Ehsan Sadrfaridpour, Korey Palmer, Ilya Safro (Clemson University)</h3>
<p>The support vector machines (SVM) is one of the most widely used and
practical optimization based classification models in machine learning because
of its interpretability and flexibility to produce high quality results.
However, the big data imposes a certain difficulty to the most sophisticated
but relatively slow versions of SVM, namely, the nonlinear SVM. The complexity
of nonlinear SVM solvers and the number of elements in the kernel matrix
quadratically increases with the number of samples in training data. Therefore,
both runtime and memory requirements are negatively affected. Moreover, the
parameter fitting has extra kernel parameters to tune, which exacerbate the
runtime even further. This paper proposes an adaptive multilevel learning
framework for the nonlinear SVM, which addresses these challenges, improves the
classification quality across the refinement process, and leverages
multi-threaded parallel processing for better performance. The integration of
parameter fitting in the hierarchical learning framework and adaptive process
to stop unnecessary computation significantly reduce the running time while
increase the overall performance. The experimental results demonstrate reduced
variance on prediction over validation and test data across levels in the
hierarchy, and significant speedup compared to state-of-the-art nonlinear SVM
libraries without a decrease in the classification quality. The code is
accessible at https://github.com/esadr/amlsvm.
</p>
<a href="http://arxiv.org/abs/2011.02592" target="_blank">arXiv:2011.02592</a> [<a href="http://arxiv.org/pdf/2011.02592" target="_blank">pdf</a>]

<h2>Detecting Hallucinated Content in Conditional Neural Sequence Generation. (arXiv:2011.02593v1 [cs.CL])</h2>
<h3>Chunting Zhou, Jiatao Gu, Mona Diab, Paco Guzman, Luke Zettlemoyer, Marjan Ghazvininejad</h3>
<p>Neural sequence models can generate highly fluent sentences but recent
studies have also shown that they are also prone to hallucinate additional
content not supported by the input, which can cause a lack of trust in the
model. To better assess the faithfulness of the machine outputs, we propose a
new task to predict whether each token in the output sequence is hallucinated
conditioned on the source input, and collect new manually annotated evaluation
sets for this task. We also introduce a novel method for learning to model
hallucination detection, based on pretrained language models fine tuned on
synthetic data that includes automatically inserted hallucinations. Experiments
on machine translation and abstract text summarization demonstrate the
effectiveness of our proposed approach -- we obtain an average F1 of around 0.6
across all the benchmark datasets and achieve significant improvements in
sentence-level hallucination scoring compared to baseline methods. We also
release our annotated data and code for future research at
https://github.com/violet-zct/fairseq-detect-hallucination.
</p>
<a href="http://arxiv.org/abs/2011.02593" target="_blank">arXiv:2011.02593</a> [<a href="http://arxiv.org/pdf/2011.02593" target="_blank">pdf</a>]

<h2>Binary classification with ambiguous training data. (arXiv:2011.02598v1 [cs.LG])</h2>
<h3>Naoya Otani, Yosuke Otsubo, Tetsuya Koike, Masashi Sugiyama</h3>
<p>In supervised learning, we often face with ambiguous (A) samples that are
difficult to label even by domain experts. In this paper, we consider a binary
classification problem in the presence of such A samples. This problem is
substantially different from semi-supervised learning since unlabeled samples
are not necessarily difficult samples. Also, it is different from 3-class
classification with the positive (P), negative (N), and A classes since we do
not want to classify test samples into the A class. Our proposed method extends
binary classification with reject option, which trains a classifier and a
rejector simultaneously using P and N samples based on the 0-1-$c$ loss with
rejection cost $c$. More specifically, we propose to train a classifier and a
rejector under the 0-1-$c$-$d$ loss using P, N, and A samples, where $d$ is the
misclassification penalty for ambiguous samples. In our practical
implementation, we use a convex upper bound of the 0-1-$c$-$d$ loss for
computational tractability. Numerical experiments demonstrate that our method
can successfully utilize the additional information brought by such A training
data.
</p>
<a href="http://arxiv.org/abs/2011.02598" target="_blank">arXiv:2011.02598</a> [<a href="http://arxiv.org/pdf/2011.02598" target="_blank">pdf</a>]

<h2>Merchant Category Identification Using Credit Card Transactions. (arXiv:2011.02602v1 [cs.LG])</h2>
<h3>Chin-Chia Michael Yeh, Zhongfang Zhuang, Yan Zheng, Liang Wang, Junpeng Wang, Wei Zhang</h3>
<p>Digital payment volume has proliferated in recent years with the rapid growth
of small businesses and online shops. When processing these digital
transactions, recognizing each merchant's real identity (i.e., business type)
is vital to ensure the integrity of payment processing systems. Conventionally,
this problem is formulated as a time series classification problem solely using
the merchant transaction history. However, with the large scale of the data,
and changing behaviors of merchants and consumers over time, it is extremely
challenging to achieve satisfying performance from off-the-shelf classification
methods. In this work, we approach this problem from a multi-modal learning
perspective, where we use not only the merchant time series data but also the
information of merchant-merchant relationship (i.e., affinity) to verify the
self-reported business type (i.e., merchant category) of a given merchant.
Specifically, we design two individual encoders, where one is responsible for
encoding temporal information and the other is responsible for affinity
information, and a mechanism to fuse the outputs of the two encoders to
accomplish the identification task. Our experiments on real-world credit card
transaction data between 71,668 merchants and 433,772,755 customers have
demonstrated the effectiveness and efficiency of the proposed model.
</p>
<a href="http://arxiv.org/abs/2011.02602" target="_blank">arXiv:2011.02602</a> [<a href="http://arxiv.org/pdf/2011.02602" target="_blank">pdf</a>]

<h2>Leveraging Post Hoc Context for Faster Learning in Bandit Settings with Applications in Robot-Assisted Feeding. (arXiv:2011.02604v1 [cs.RO])</h2>
<h3>Ethan K. Gordon, Sumegh Roychowdhury, Tapomayukh Bhattacharjee, Kevin Jamieson, Siddhartha S. Srinivasa</h3>
<p>Autonomous robot-assisted feeding requires the ability to acquire a wide
variety of food items. However, it is impossible for such a system to be
trained on all types of food in existence. Therefore, a key challenge is
choosing a manipulation strategy for a previously unseen food item. Previous
work showed that the problem can be represented as a linear contextual bandit
on visual information. However, food has a wide variety of multi-modal
properties relevant to manipulation that can be hard to distinguish visually.
Our key insight is that we can leverage the haptic information we collect
during manipulation to learn some of these properties and more quickly adapt
our visual model to previously unseen food. In general, we propose a modified
linear contextual bandit framework augmented with post hoc context observed
after action selection to empirically increase learning speed (as measured by
cross-validation mean square error) and reduce cumulative regret. Experiments
on synthetic data demonstrate that this effect is more pronounced when the
dimensionality of the context is large relative to the post hoc context or when
the post hoc context model is particularly easy to learn. Finally, we apply
this framework to the bite acquisition problem and demonstrate the acquisition
of 8 previously unseen types of food with 21% fewer failures across 64
attempts.
</p>
<a href="http://arxiv.org/abs/2011.02604" target="_blank">arXiv:2011.02604</a> [<a href="http://arxiv.org/pdf/2011.02604" target="_blank">pdf</a>]

<h2>Transforming Facial Weight of Real Images by Editing Latent Space of StyleGAN. (arXiv:2011.02606v1 [cs.CV])</h2>
<h3>V N S Rama Krishna Pinnimty, Matt Zhao, Palakorn Achananuparp, Ee-Peng Lim</h3>
<p>We present an invert-and-edit framework to automatically transform facial
weight of an input face image to look thinner or heavier by leveraging semantic
facial attributes encoded in the latent space of Generative Adversarial
Networks (GANs). Using a pre-trained StyleGAN as the underlying generator, we
first employ an optimization-based embedding method to invert the input image
into the StyleGAN latent space. Then, we identify the facial-weight attribute
direction in the latent space via supervised learning and edit the inverted
latent code by moving it positively or negatively along the extracted feature
axis. Our framework is empirically shown to produce high-quality and realistic
facial-weight transformations without requiring training GANs with a large
amount of labeled face images from scratch. Ultimately, our framework can be
utilized as part of an intervention to motivate individuals to make healthier
food choices by visualizing the future impacts of their behavior on appearance.
</p>
<a href="http://arxiv.org/abs/2011.02606" target="_blank">arXiv:2011.02606</a> [<a href="http://arxiv.org/pdf/2011.02606" target="_blank">pdf</a>]

<h2>Learning a Decentralized Multi-arm Motion Planner. (arXiv:2011.02608v1 [cs.RO])</h2>
<h3>Huy Ha, Jingxi Xu, Shuran Song</h3>
<p>We present a closed-loop multi-arm motion planner that is scalable and
flexible with team size. Traditional multi-arm robot systems have relied on
centralized motion planners, whose runtimes often scale exponentially with team
size, and thus, fail to handle dynamic environments with open-loop control. In
this paper, we tackle this problem with multi-agent reinforcement learning,
where a decentralized policy is trained to control one robot arm in the
multi-arm system to reach its target end-effector pose given observations of
its workspace state and target end-effector pose. The policy is trained using
Soft Actor-Critic with expert demonstrations from a sampling-based motion
planning algorithm (i.e., BiRRT). By leveraging classical planning algorithms,
we can improve the learning efficiency of the reinforcement learning algorithm
while retaining the fast inference time of neural networks. The resulting
policy scales sub-linearly and can be deployed on multi-arm systems with
variable team sizes. Thanks to the closed-loop and decentralized formulation,
our approach generalizes to 5-10 multi-arm systems and dynamic moving targets
(&gt;90% success rate for a 10-arm system), despite being trained on only 1-4 arm
planning tasks with static targets. Code and data links can be found at
https://multiarm.cs.columbia.edu.
</p>
<a href="http://arxiv.org/abs/2011.02608" target="_blank">arXiv:2011.02608</a> [<a href="http://arxiv.org/pdf/2011.02608" target="_blank">pdf</a>]

<h2>Harnessing Distribution Ratio Estimators for Learning Agents with Quality and Diversity. (arXiv:2011.02614v1 [cs.LG])</h2>
<h3>Tanmay Gangwani, Jian Peng, Yuan Zhou</h3>
<p>Quality-Diversity (QD) is a concept from Neuroevolution with some intriguing
applications to Reinforcement Learning. It facilitates learning a population of
agents where each member is optimized to simultaneously accumulate high
task-returns and exhibit behavioral diversity compared to other members. In
this paper, we build on a recent kernel-based method for training a QD policy
ensemble with Stein variational gradient descent. With kernels based on
$f$-divergence between the stationary distributions of policies, we convert the
problem to that of efficient estimation of the ratio of these stationary
distributions. We then study various distribution ratio estimators used
previously for off-policy evaluation and imitation and re-purpose them to
compute the gradients for policies in an ensemble such that the resultant
population is diverse and of high-quality.
</p>
<a href="http://arxiv.org/abs/2011.02614" target="_blank">arXiv:2011.02614</a> [<a href="http://arxiv.org/pdf/2011.02614" target="_blank">pdf</a>]

<h2>GPR-based Model Reconstruction System for Underground Utilities Using GPRNet. (arXiv:2011.02635v1 [cs.CV])</h2>
<h3>Jinglun Feng, Liang Yang, Ejup Hoxha, Stanislav Sotnikov, Diar Sanakov, Jizhong Xiao</h3>
<p>Ground Penetrating Radar (GPR) is one of the most important non-destructive
evaluation (NDE) instruments to detect and locate underground objects (i.e.
rebars, utility pipes). Many of the previous researches focus on GPR
image-based feature detection only, and none can process sparse GPR
measurements to successfully reconstruct a very fine and detailed 3D model of
underground objects for better visualization. To address this problem, this
paper presents a novel robotic system to collect GPR data, localize the
underground utilities, and reconstruct the underground objects' dense point
cloud model. This system is composed of three modules: 1) visual-inertial-based
GPR data collection module which tags the GPR measurements with positioning
information provided by an omnidirectional robot; 2) a deep neural network
(DNN) migration module to interpret the raw GPR B-scan image into a
cross-section of object model; 3) a DNN-based 3D reconstruction module, i.e.,
GPRNet, to generate underground utility model with the fine 3D point cloud. The
experiments show that our method can generate a dense and complete point cloud
model of pipe-shaped utilities based on a sparse input, i.e., GPR raw data,
with various levels of incompleteness and noise. The experiment results on
synthetic data as well as field test data verified the effectiveness of our
method.
</p>
<a href="http://arxiv.org/abs/2011.02635" target="_blank">arXiv:2011.02635</a> [<a href="http://arxiv.org/pdf/2011.02635" target="_blank">pdf</a>]

<h2>Unsupervised Learning for Asynchronous Resource Allocation in Ad-hoc Wireless Networks. (arXiv:2011.02644v1 [cs.NI])</h2>
<h3>Zhiyang Wang, Mark Eisen, Alejandro Ribeiro</h3>
<p>We consider optimal resource allocation problems under asynchronous wireless
network setting. Without explicit model knowledge, we design an unsupervised
learning method based on Aggregation Graph Neural Networks (Agg-GNNs).
Depending on the localized aggregated information structure on each network
node, the method can be learned globally and asynchronously while implemented
locally. We capture the asynchrony by modeling the activation pattern as a
characteristic of each node and train a policy-based resource allocation
method. We also propose a permutation invariance property which indicates the
transferability of the trained Agg-GNN. We finally verify our strategy by
numerical simulations compared with baseline methods.
</p>
<a href="http://arxiv.org/abs/2011.02644" target="_blank">arXiv:2011.02644</a> [<a href="http://arxiv.org/pdf/2011.02644" target="_blank">pdf</a>]

<h2>Restless-UCB, an Efficient and Low-complexity Algorithm for Online Restless Bandits. (arXiv:2011.02664v1 [cs.LG])</h2>
<h3>Siwei Wang, Longbo Huang, John C.S. Lui</h3>
<p>We study the online restless bandit problem, where the state of each arm
evolves according to a Markov chain, and the reward of pulling an arm depends
on both the pulled arm and the current state of the corresponding Markov chain.
In this paper, we propose Restless-UCB, a learning policy that follows the
explore-then-commit framework. In Restless-UCB, we present a novel method to
construct offline instances, which only requires $O(N)$ time-complexity ($N$ is
the number of arms) and is exponentially better than the complexity of existing
learning policy. We also prove that Restless-UCB achieves a regret upper bound
of $\tilde{O}((N+M^3)T^{2\over 3})$, where $M$ is the Markov chain state space
size and $T$ is the time horizon. Compared to existing algorithms, our result
eliminates the exponential factor (in $M,N$) in the regret upper bound, due to
a novel exploitation of the sparsity in transitions in general restless bandit
problems. As a result, our analysis technique can also be adopted to tighten
the regret bounds of existing algorithms. Finally, we conduct experiments based
on real-world dataset, to compare the Restless-UCB policy with state-of-the-art
benchmarks. Our results show that Restless-UCB outperforms existing algorithms
in regret, and significantly reduces the running time.
</p>
<a href="http://arxiv.org/abs/2011.02664" target="_blank">arXiv:2011.02664</a> [<a href="http://arxiv.org/pdf/2011.02664" target="_blank">pdf</a>]

<h2>Adversarial Context Aware Network Embeddings for Textual Networks. (arXiv:2011.02665v1 [cs.CL])</h2>
<h3>Tony Gracious, Ambedkar Dukkipati</h3>
<p>Representation learning of textual networks poses a significant challenge as
it involves capturing amalgamated information from two modalities: (i)
underlying network structure, and (ii) node textual attributes. For this, most
existing approaches learn embeddings of text and network structure by enforcing
embeddings of connected nodes to be similar. Then for achieving a modality
fusion they use the similarities between text embedding of a node with the
structure embedding of its connected node and vice versa. This implies that
these approaches require edge information for learning embeddings and they
cannot learn embeddings of unseen nodes. In this paper we propose an approach
that achieves both modality fusion and the capability to learn embeddings of
unseen nodes. The main feature of our model is that it uses an adversarial
mechanism between text embedding based discriminator, and structure embedding
based generator to learn efficient representations. Then for learning
embeddings of unseen nodes, we use the supervision provided by the text
embedding based discriminator. In addition this, we propose a novel
architecture for learning text embedding that can combine both mutual attention
and topological attention mechanism, which give more flexible text embeddings.
Through extensive experiments on real-world datasets, we demonstrate that our
model makes substantial gains over several state-of-the-art benchmarks. In
comparison with previous state-of-the-art, it gives up to 7% improvement in
performance in predicting links among nodes seen in the training and up to 12%
improvement in performance in predicting links involving nodes not seen in
training. Further, in the node classification task, it gives up to 2%
improvement in performance.
</p>
<a href="http://arxiv.org/abs/2011.02665" target="_blank">arXiv:2011.02665</a> [<a href="http://arxiv.org/pdf/2011.02665" target="_blank">pdf</a>]

<h2>Deep Active Learning with Augmentation-based Consistency Estimation. (arXiv:2011.02666v1 [cs.CV])</h2>
<h3>SeulGi Hong, Heonjin Ha, Junmo Kim, Min-Kook Choi</h3>
<p>In active learning, the focus is mainly on the selection strategy of
unlabeled data for enhancing the generalization capability of the next learning
cycle. For this, various uncertainty measurement methods have been proposed. On
the other hand, with the advent of data augmentation metrics as the regularizer
on general deep learning, we notice that there can be a mutual influence
between the method of unlabeled data selection and the data augmentation-based
regularization techniques in active learning scenarios. Through various
experiments, we confirmed that consistency-based regularization from analytical
learning theory could affect the generalization capability of the classifier in
combination with the existing uncertainty measurement method. By this fact, we
propose a methodology to improve generalization ability, by applying data
augmentation-based techniques to an active learning scenario. For the data
augmentation-based regularization loss, we redefined cutout (co) and cutmix
(cm) strategies as quantitative metrics and applied at both model training and
unlabeled data selection steps. We have shown that the augmentation-based
regularizer can lead to improved performance on the training step of active
learning, while that same approach can be effectively combined with the
uncertainty measurement metrics proposed so far. We used datasets such as
FashionMNIST, CIFAR10, CIFAR100, and STL10 to verify the performance of the
proposed active learning technique for multiple image classification tasks. Our
experiments show consistent performance gains for each dataset and budget
scenario.
</p>
<a href="http://arxiv.org/abs/2011.02666" target="_blank">arXiv:2011.02666</a> [<a href="http://arxiv.org/pdf/2011.02666" target="_blank">pdf</a>]

<h2>Learning to Utilize Shaping Rewards: A New Approach of Reward Shaping. (arXiv:2011.02669v1 [cs.LG])</h2>
<h3>Yujing Hu, Weixun Wang, Hangtian Jia, Yixiang Wang, Yingfeng Chen, Jianye Hao, Feng Wu, Changjie Fan</h3>
<p>Reward shaping is an effective technique for incorporating domain knowledge
into reinforcement learning (RL). Existing approaches such as potential-based
reward shaping normally make full use of a given shaping reward function.
However, since the transformation of human knowledge into numeric reward values
is often imperfect due to reasons such as human cognitive bias, completely
utilizing the shaping reward function may fail to improve the performance of RL
algorithms. In this paper, we consider the problem of adaptively utilizing a
given shaping reward function. We formulate the utilization of shaping rewards
as a bi-level optimization problem, where the lower level is to optimize policy
using the shaping rewards and the upper level is to optimize a parameterized
shaping weight function for true reward maximization. We formally derive the
gradient of the expected true reward with respect to the shaping weight
function parameters and accordingly propose three learning algorithms based on
different assumptions. Experiments in sparse-reward cartpole and MuJoCo
environments show that our algorithms can fully exploit beneficial shaping
rewards, and meanwhile ignore unbeneficial shaping rewards or even transform
them into beneficial ones.
</p>
<a href="http://arxiv.org/abs/2011.02669" target="_blank">arXiv:2011.02669</a> [<a href="http://arxiv.org/pdf/2011.02669" target="_blank">pdf</a>]

<h2>Black-Box Approach to Post-Quantum Zero-Knowledge in Constant Round. (arXiv:2011.02670v1 [quant-ph])</h2>
<h3>Nai-Hui Chia, Kai-Min Chung, Takashi Yamakawa</h3>
<p>In a recent seminal work, Bitansky and Shmueli (STOC '20) gave the first
construction of a constant round zero-knowledge argument for NP secure against
quantum attacks. However, their construction has several drawbacks compared to
the classical counterparts. Specifically, their construction only achieves
computational soundness, requires strong assumptions of quantum hardness of
learning with errors (QLWE assumption) and the existence of quantum fully
homomorphic encryption (QFHE), and relies on non-black-box simulation. In this
paper, we resolve these issues at the cost of weakening the notion of
zero-knowledge to what is called $\epsilon$-zero-knowledge. Concretely, we
construct the following protocols:

- We construct a constant round interactive proof for NP that satisfies
statistical soundness and black-box $\epsilon$-zero-knowledge against quantum
attacks assuming the existence of collapsing hash functions, which is a quantum
counterpart of collision-resistant hash functions. Interestingly, this
construction is just an adapted version of the classical protocol by Goldreich
and Kahan (JoC '96) though the proof of $\epsilon$-zero-knowledge property
against quantum adversaries requires novel ideas.

- We construct a constant round interactive argument for NP that satisfies
computational soundness and black-box $\epsilon$-zero-knowledge against quantum
attacks only assuming the existence of post-quantum one-way functions.

At the heart of our results is a new quantum rewinding technique that enables
a simulator to extract a committed message of a malicious verifier while
simulating verifier's internal state in an appropriate sense.
</p>
<a href="http://arxiv.org/abs/2011.02670" target="_blank">arXiv:2011.02670</a> [<a href="http://arxiv.org/pdf/2011.02670" target="_blank">pdf</a>]

<h2>HILONet: Hierarchical Imitation Learning from Non-Aligned Observations. (arXiv:2011.02671v1 [cs.LG])</h2>
<h3>Shanqi Liu, Junjie Cao, Wenzhou Chen, Licheng Wen, Yong Liu</h3>
<p>It is challenging learning from demonstrated observation-only trajectories in
a non-time-aligned environment because most imitation learning methods aim to
imitate experts by following the demonstration step-by-step. However, aligned
demonstrations are seldom obtainable in real-world scenarios. In this work, we
propose a new imitation learning approach called Hierarchical Imitation
Learning from Observation(HILONet), which adopts a hierarchical structure to
choose feasible sub-goals from demonstrated observations dynamically. Our
method can solve all kinds of tasks by achieving these sub-goals, whether it
has a single goal position or not. We also present three different ways to
increase sample efficiency in the hierarchical structure. We conduct extensive
experiments using several environments. The results show the improvement in
both performance and learning efficiency.
</p>
<a href="http://arxiv.org/abs/2011.02671" target="_blank">arXiv:2011.02671</a> [<a href="http://arxiv.org/pdf/2011.02671" target="_blank">pdf</a>]

<h2>AOT: Appearance Optimal Transport Based Identity Swapping for Forgery Detection. (arXiv:2011.02674v1 [cs.CV])</h2>
<h3>Hao Zhu, Chaoyou Fu, Qianyi Wu, Wayne Wu, Chen Qian, Ran He</h3>
<p>Recent studies have shown that the performance of forgery detection can be
improved with diverse and challenging Deepfakes datasets. However, due to the
lack of Deepfakes datasets with large variance in appearance, which can be
hardly produced by recent identity swapping methods, the detection algorithm
may fail in this situation. In this work, we provide a new identity swapping
algorithm with large differences in appearance for face forgery detection. The
appearance gaps mainly arise from the large discrepancies in illuminations and
skin colors that widely exist in real-world scenarios. However, due to the
difficulties of modeling the complex appearance mapping, it is challenging to
transfer fine-grained appearances adaptively while preserving identity traits.
This paper formulates appearance mapping as an optimal transport problem and
proposes an Appearance Optimal Transport model (AOT) to formulate it in both
latent and pixel space. Specifically, a relighting generator is designed to
simulate the optimal transport plan. It is solved via minimizing the
Wasserstein distance of the learned features in the latent space, enabling
better performance and less computation than conventional optimization. To
further refine the solution of the optimal transport plan, we develop a
segmentation game to minimize the Wasserstein distance in the pixel space. A
discriminator is introduced to distinguish the fake parts from a mix of real
and fake image patches. Extensive experiments reveal that the superiority of
our method when compared with state-of-the-art methods and the ability of our
generated data to improve the performance of face forgery detection.
</p>
<a href="http://arxiv.org/abs/2011.02674" target="_blank">arXiv:2011.02674</a> [<a href="http://arxiv.org/pdf/2011.02674" target="_blank">pdf</a>]

<h2>Defense-friendly Images in Adversarial Attacks: Dataset and Metrics forPerturbation Difficulty. (arXiv:2011.02675v1 [cs.CV])</h2>
<h3>Camilo Pestana, Wei Liu, David Glance, Ajmal Mian</h3>
<p>Dataset bias is a problem in adversarial machine learn-ing, especially in the
evaluation of defenses. An adversarial attack or defense algorithm may show
better results on the reported dataset than can be replicated on other
datasets.Even when two algorithms are compared, their relative performance can
vary depending on the dataset. Deep learn-ing offers state-of-the-art solutions
for image recognition, but deep models are vulnerable even to small
perturbations.Research in this area focuses primarily on adversarial at-tacks
and defense algorithms. In this paper, we report for the first time, a class of
robust images that are both resilient to attacks and that recover better than
random images un-der adversarial attacks using simple defense techniques.Thus,
a test dataset with a high proportion of robust images gives a misleading
impression about the performance of an adversarial attack or defense. We
propose three metrics to determine the proportion of robust images in a dataset
and provide scoring to determine the dataset bias. We also pro-vide an
ImageNet-R dataset of 15000+ robust images to facilitate further research on
this intriguing phenomenon of image strength under attack. Our dataset,
combined with the proposed metrics, is valuable for unbiased benchmark-ing of
adversarial attack and defense algorithms
</p>
<a href="http://arxiv.org/abs/2011.02675" target="_blank">arXiv:2011.02675</a> [<a href="http://arxiv.org/pdf/2011.02675" target="_blank">pdf</a>]

<h2>A Multi-resolution Model for Histopathology Image Classification and Localization with Multiple Instance Learning. (arXiv:2011.02679v1 [eess.IV])</h2>
<h3>Jiayun Li, Wenyuan Li, Anthony Sisk, Huihui Ye, W. Dean Wallace, William Speier, Corey W. Arnold</h3>
<p>Histopathological images provide rich information for disease diagnosis.
Large numbers of histopathological images have been digitized into high
resolution whole slide images, opening opportunities in developing
computational image analysis tools to reduce pathologists' workload and
potentially improve inter- and intra- observer agreement. Most previous work on
whole slide image analysis has focused on classification or segmentation of
small pre-selected regions-of-interest, which requires fine-grained annotation
and is non-trivial to extend for large-scale whole slide analysis. In this
paper, we proposed a multi-resolution multiple instance learning model that
leverages saliency maps to detect suspicious regions for fine-grained grade
prediction. Instead of relying on expensive region- or pixel-level annotations,
our model can be trained end-to-end with only slide-level labels. The model is
developed on a large-scale prostate biopsy dataset containing 20,229 slides
from 830 patients. The model achieved 92.7% accuracy, 81.8% Cohen's Kappa for
benign, low grade (i.e. Grade group 1) and high grade (i.e. Grade group &gt;= 2)
prediction, an area under the receiver operating characteristic curve (AUROC)
of 98.2% and an average precision (AP) of 97.4% for differentiating malignant
and benign slides. The model obtained an AUROC of 99.4% and an AP of 99.8% for
cancer detection on an external dataset.
</p>
<a href="http://arxiv.org/abs/2011.02679" target="_blank">arXiv:2011.02679</a> [<a href="http://arxiv.org/pdf/2011.02679" target="_blank">pdf</a>]

<h2>Multi-task learning for electronic structure to predict and explore molecular potential energy surfaces. (arXiv:2011.02680v1 [physics.chem-ph])</h2>
<h3>Zhuoran Qiao, Feizhi Ding, Matthew Welborn, Peter J. Bygrave, Animashree Anandkumar, Frederick R. Manby, Thomas F. Miller III</h3>
<p>We refine the OrbNet model to accurately predict energy, forces, and other
response properties for molecules using a graph neural-network architecture
based on features from low-cost approximated quantum operators in the
symmetry-adapted atomic orbital basis. The model is end-to-end differentiable
due to the derivation of analytic gradients for all electronic structure terms,
and is shown to be transferable across chemical space due to the use of
domain-specific features. The learning efficiency is improved by incorporating
physically motivated constraints on the electronic structure through multi-task
learning. The model outperforms existing methods on energy prediction tasks for
the QM9 dataset and for molecular geometry optimizations on conformer datasets,
at a computational cost that is thousand-fold or more reduced compared to
conventional quantum-chemistry calculations (such as density functional theory)
that offer similar accuracy.
</p>
<a href="http://arxiv.org/abs/2011.02680" target="_blank">arXiv:2011.02680</a> [<a href="http://arxiv.org/pdf/2011.02680" target="_blank">pdf</a>]

<h2>Context-Aware Answer Extraction in Question Answering. (arXiv:2011.02687v1 [cs.CL])</h2>
<h3>Yeon Seonwoo, Ji-Hoon Kim, Jung-Woo Ha, Alice Oh</h3>
<p>Extractive QA models have shown very promising performance in predicting the
correct answer to a question for a given passage. However, they sometimes
result in predicting the correct answer text but in a context irrelevant to the
given question. This discrepancy becomes especially important as the number of
occurrences of the answer text in a passage increases. To resolve this issue,
we propose \textbf{BLANC} (\textbf{BL}ock \textbf{A}ttentio\textbf{N} for
\textbf{C}ontext prediction) based on two main ideas: context prediction as an
auxiliary task in multi-task learning manner, and a block attention method that
learns the context prediction task. With experiments on reading comprehension,
we show that BLANC outperforms the state-of-the-art QA models, and the
performance gap increases as the number of answer text occurrences increases.
We also conduct an experiment of training the models using SQuAD and predicting
the supporting facts on HotpotQA and show that BLANC outperforms all baseline
models in this zero-shot setting.
</p>
<a href="http://arxiv.org/abs/2011.02687" target="_blank">arXiv:2011.02687</a> [<a href="http://arxiv.org/pdf/2011.02687" target="_blank">pdf</a>]

<h2>Amortized Conditional Normalized Maximum Likelihood. (arXiv:2011.02696v1 [cs.LG])</h2>
<h3>Aurick Zhou, Sergey Levine</h3>
<p>While deep neural networks provide good performance for a range of
challenging tasks, calibration and uncertainty estimation remain major
challenges. In this paper, we propose the amortized conditional normalized
maximum likelihood (ACNML) method as a scalable general-purpose approach for
uncertainty estimation, calibration, and out-of-distribution robustness with
deep networks. Our algorithm builds on the conditional normalized maximum
likelihood (CNML) coding scheme, which has minimax optimal properties according
to the minimum description length principle, but is computationally intractable
to evaluate exactly for all but the simplest of model classes. We propose to
use approximate Bayesian inference technqiues to produce a tractable
approximation to the CNML distribution. Our approach can be combined with any
approximate inference algorithm that provides tractable posterior densities
over model parameters. We demonstrate that ACNML compares favorably to a number
of prior techniques for uncertainty estimation in terms of calibration on
out-of-distribution inputs.
</p>
<a href="http://arxiv.org/abs/2011.02696" target="_blank">arXiv:2011.02696</a> [<a href="http://arxiv.org/pdf/2011.02696" target="_blank">pdf</a>]

<h2>Center-wise Local Image Mixture For Contrastive Representation Learning. (arXiv:2011.02697v1 [cs.CV])</h2>
<h3>Hao Li, Xiaopeng Zhang, Ruoyu Sun, Hongkai Xiong, Qi Tian</h3>
<p>Recent advances in unsupervised representation learning have experienced
remarkable progress, especially with the achievements of contrastive learning,
which regards each image as well its augmentations as a separate class, while
does not consider the semantic similarity among images. This paper proposes a
new kind of data augmentation, named Center-wise Local Image Mixture, to expand
the neighborhood space of an image. CLIM encourages both local similarity and
global aggregation while pulling similar images. This is achieved by searching
local similar samples of an image, and only selecting images that are closer to
the corresponding cluster center, which we denote as center-wise local
selection. As a result, similar representations are progressively approaching
the clusters, while do not break the local similarity. Furthermore, image
mixture is used as a smoothing regularization to avoid overconfidence on the
selected samples. Besides, we introduce multi-resolution augmentation, which
enables the representation to be scale invariant. Integrating the two
augmentations produces better feature representation on several unsupervised
benchmarks. Notably, we reach 75.5% top-1 accuracy with linear evaluation over
ResNet-50, and 59.3% top-1 accuracy when fine-tuned with only 1% labels, as
well as consistently outperforming supervised pretraining on several downstream
transfer tasks.
</p>
<a href="http://arxiv.org/abs/2011.02697" target="_blank">arXiv:2011.02697</a> [<a href="http://arxiv.org/pdf/2011.02697" target="_blank">pdf</a>]

<h2>A Comparison Study on Infant-Parent Voice Diarization. (arXiv:2011.02698v1 [eess.AS])</h2>
<h3>Junzhe Zhu, Mark Hasegawa-Johnson, Nancy McElwain</h3>
<p>We design a framework for studying prelinguistic child voicefrom 3 to 24
months based on state-of-the-art algorithms in di-arization. Our system
consists of a time-invariant feature ex-tractor, a context-dependent embedding
generator, and a clas-sifier. We study the effect of swapping out different
compo-nents of the system, as well as changing loss function, to findthe best
performance. We also present a multiple-instancelearning technique that allows
us to pre-train our parame-ters on larger datasets with coarser segment
boundary labels.We found that our best system achieved 43.8% DER on
testdataset, compared to 55.4% DER achieved by LENA soft-ware. We also found
that using convolutional feature extrac-tor instead of logmel features
significantly increases the per-formance of neural diarization.
</p>
<a href="http://arxiv.org/abs/2011.02698" target="_blank">arXiv:2011.02698</a> [<a href="http://arxiv.org/pdf/2011.02698" target="_blank">pdf</a>]

<h2>A Black-Box Attack Model for Visually-Aware Recommender Systems. (arXiv:2011.02701v1 [cs.LG])</h2>
<h3>Rami Cohen, Oren Sar Shalom, Dietmar Jannach, Amihood Amir</h3>
<p>Due to the advances in deep learning, visually-aware recommender systems (RS)
have recently attracted increased research interest. Such systems combine
collaborative signals with images, usually represented as feature vectors
outputted by pre-trained image models. Since item catalogs can be huge,
recommendation service providers often rely on images that are supplied by the
item providers. In this work, we show that relying on such external sources can
make an RS vulnerable to attacks, where the goal of the attacker is to unfairly
promote certain pushed items. Specifically, we demonstrate how a new visual
attack model can effectively influence the item scores and rankings in a
black-box approach, i.e., without knowing the parameters of the model. The main
underlying idea is to systematically create small human-imperceptible
perturbations of the pushed item image and to devise appropriate gradient
approximation methods to incrementally raise the pushed item's score.
Experimental evaluations on two datasets show that the novel attack model is
effective even when the contribution of the visual features to the overall
performance of the recommender system is modest.
</p>
<a href="http://arxiv.org/abs/2011.02701" target="_blank">arXiv:2011.02701</a> [<a href="http://arxiv.org/pdf/2011.02701" target="_blank">pdf</a>]

<h2>Sampled Nonlocal Gradients for Stronger Adversarial Attacks. (arXiv:2011.02707v1 [cs.LG])</h2>
<h3>Leo Schwinn, Daniel Tenbrinck, An Nguyen, Ren&#xe9; Raab, Martin Burger, Bjoern Eskofier</h3>
<p>The vulnerability of deep neural networks to small and even imperceptible
perturbations has become a central topic in deep learning research. The
evaluation of new defense mechanisms for these so-called adversarial attacks
has proven to be challenging. Although several sophisticated defense mechanisms
were introduced, most of them were later shown to be ineffective. However, a
reliable evaluation of model robustness is mandatory for deployment in
safety-critical real-world scenarios. We propose a simple yet effective
modification to the gradient calculation of state-of-the-art first-order
adversarial attacks, which increases their success rate and thus leads to more
accurate robustness estimates. Normally, the gradient update of an attack is
directly calculated for the given data point. In general, this approach is
sensitive to noise and small local optima of the loss function. Inspired by
gradient sampling techniques from non-convex optimization, we propose to
calculate the gradient direction of the adversarial attack as the weighted
average over multiple points in the local vicinity. We empirically show that by
incorporating this additional gradient information, we are able to give a more
accurate estimation of the global descent direction on noisy and non-convex
loss surfaces. Additionally, we show that the proposed method achieves higher
success rates than a variety of state-of-the-art attacks on the benchmark
datasets MNIST, Fashion-MNIST, and CIFAR10.
</p>
<a href="http://arxiv.org/abs/2011.02707" target="_blank">arXiv:2011.02707</a> [<a href="http://arxiv.org/pdf/2011.02707" target="_blank">pdf</a>]

<h2>An analysis of the transfer learning of convolutional neural networks for artistic images. (arXiv:2011.02727v1 [cs.CV])</h2>
<h3>Nicolas Gonthier, Yann Gousseau, Sa&#xef;d Ladjal</h3>
<p>Transfer learning from huge natural image datasets, fine-tuning of deep
neural networks and the use of the corresponding pre-trained networks have
become de facto the core of art analysis applications. Nevertheless, the
effects of transfer learning are still poorly understood. In this paper, we
first use techniques for visualizing the network internal representations in
order to provide clues to the understanding of what the network has learned on
artistic images. Then, we provide a quantitative analysis of the changes
introduced by the learning process thanks to metrics in both the feature and
parameter spaces, as well as metrics computed on the set of maximal activation
images. These analyses are performed on several variations of the transfer
learning procedure. In particular, we observed that the network could
specialize some pre-trained filters to the new image modality and also that
higher layers tend to concentrate classes. Finally, we have shown that a double
fine-tuning involving a medium-size artistic dataset can improve the
classification on smaller datasets, even when the task changes.
</p>
<a href="http://arxiv.org/abs/2011.02727" target="_blank">arXiv:2011.02727</a> [<a href="http://arxiv.org/pdf/2011.02727" target="_blank">pdf</a>]

<h2>Why robots should be technical: Correcting mental models through technical architecture concepts. (arXiv:2011.02731v1 [cs.RO])</h2>
<h3>Lukas Hindemith, Anna-Lisa Vollmer, Jan Phillip G&#xf6;pfert, Christiane B. Wiebel-Herboth, Britta Wrede</h3>
<p>Research in social robotics is commonly focused on designing robots that
imitate human behavior. While this might increase a user's satisfaction and
acceptance of robots at first glance, it does not automatically aid a
non-expert user in naturally interacting with robots, and might actually hurt
their ability to correctly anticipate a robot's capabilities. We argue that a
faulty mental model, that the user has of the robot, is one of the main sources
of confusion. In this work we investigate how communicating technical concepts
of robotic systems to users affects their mental models, and how this can
increase the quality of human-robot interaction. We conducted an online study
and investigated possible ways of improving users' mental models. Our results
underline that communicating technical concepts can form an improved mental
model. Consequently, we show the importance of consciously designing robots
that express their capabilities and limitations.
</p>
<a href="http://arxiv.org/abs/2011.02731" target="_blank">arXiv:2011.02731</a> [<a href="http://arxiv.org/pdf/2011.02731" target="_blank">pdf</a>]

<h2>Switching Scheme: A Novel Approach for Handling Incremental Concept Drift in Real-World Data Sets. (arXiv:2011.02738v1 [cs.LG])</h2>
<h3>Lucas Baier, Vincent Kellner, Niklas K&#xfc;hl, Gerhard Satzger</h3>
<p>Machine learning models nowadays play a crucial role for many applications in
business and industry. However, models only start adding value as soon as they
are deployed into production. One challenge of deployed models is the effect of
changing data over time, which is often described with the term concept drift.
Due to their nature, concept drifts can severely affect the prediction
performance of a machine learning system. In this work, we analyze the effects
of concept drift in the context of a real-world data set. For efficient concept
drift handling, we introduce the switching scheme which combines the two
principles of retraining and updating of a machine learning model. Furthermore,
we systematically analyze existing regular adaptation as well as triggered
adaptation strategies. The switching scheme is instantiated on New York City
taxi data, which is heavily influenced by changing demand patterns over time.
We can show that the switching scheme outperforms all other baselines and
delivers promising prediction results.
</p>
<a href="http://arxiv.org/abs/2011.02738" target="_blank">arXiv:2011.02738</a> [<a href="http://arxiv.org/pdf/2011.02738" target="_blank">pdf</a>]

<h2>Deep learning for biomedical photoacoustic imaging: A review. (arXiv:2011.02744v1 [physics.med-ph])</h2>
<h3>Janek Gr&#xf6;hl, Melanie Schellenberg, Kris Dreher, Lena Maier-Hein</h3>
<p>Photoacoustic imaging (PAI) is a promising emerging imaging modality that
enables spatially resolved imaging of optical tissue properties up to several
centimeters deep in tissue, creating the potential for numerous exciting
clinical applications. However, extraction of relevant tissue parameters from
the raw data requires the solving of inverse image reconstruction problems,
which have proven extremely difficult to solve. The application of deep
learning methods has recently exploded in popularity, leading to impressive
successes in the context of medical imaging and also finding first use in the
field of PAI. Deep learning methods possess unique advantages that can
facilitate the clinical translation of PAI, such as extremely fast computation
times and the fact that they can be adapted to any given problem. In this
review, we examine the current state of the art regarding deep learning in PAI
and identify potential directions of research that will help to reach the goal
of clinical applicability
</p>
<a href="http://arxiv.org/abs/2011.02744" target="_blank">arXiv:2011.02744</a> [<a href="http://arxiv.org/pdf/2011.02744" target="_blank">pdf</a>]

<h2>Goal-driven Long-Term Trajectory Prediction. (arXiv:2011.02751v1 [cs.CV])</h2>
<h3>Hung Tran, Vuong Le, Truyen Tran</h3>
<p>The prediction of humans' short-term trajectories has advanced significantly
with the use of powerful sequential modeling and rich environment feature
extraction. However, long-term prediction is still a major challenge for the
current methods as the errors could accumulate along the way. Indeed,
consistent and stable prediction far to the end of a trajectory inherently
requires deeper analysis into the overall structure of that trajectory, which
is related to the pedestrian's intention on the destination of the journey. In
this work, we propose to model a hypothetical process that determines
pedestrians' goals and the impact of such process on long-term future
trajectories. We design Goal-driven Trajectory Prediction model - a
dual-channel neural network that realizes such intuition. The two channels of
the network take their dedicated roles and collaborate to generate future
trajectories. Different than conventional goal-conditioned, planning-based
methods, the model architecture is designed to generalize the patterns and work
across different scenes with arbitrary geometrical and semantic structures. The
model is shown to outperform the state-of-the-art in various settings,
especially in large prediction horizons. This result is another evidence for
the effectiveness of adaptive structured representation of visual and
geometrical features in human behavior analysis.
</p>
<a href="http://arxiv.org/abs/2011.02751" target="_blank">arXiv:2011.02751</a> [<a href="http://arxiv.org/pdf/2011.02751" target="_blank">pdf</a>]

<h2>Robust Unsupervised Video Anomaly Detection by Multi-Path Frame Prediction. (arXiv:2011.02763v1 [cs.CV])</h2>
<h3>Xuanzhao Wang, Zhengping Che, Ke Yang, Bo Jiang, Jian Tang, Jieping Ye, Jingyu Wang, Qi Qi</h3>
<p>Video anomaly detection is commonly used in many applications such as
security surveillance and is very challenging. A majority of recent video
anomaly detection approaches utilize deep reconstruction models, but their
performance is often suboptimal because of insufficient reconstruction error
differences between normal and abnormal video frames in practice. Meanwhile,
frame prediction-based anomaly detection methods have shown promising
performance. In this paper, we propose a novel and robust unsupervised video
anomaly detection method by frame prediction with proper design which is more
in line with the characteristics of surveillance videos. The proposed method is
equipped with a multi-path ConvGRU-based frame prediction network that can
better handle semantically informative objects and areas of different scales
and capture spatial-temporal dependencies in normal videos. A noise tolerance
loss is introduced during training to mitigate the interference caused by
background noise. Extensive experiments have been conducted on the CUHK Avenue,
ShanghaiTech Campus, and UCSD Pedestrian datasets, and the results show that
our proposed method outperforms existing state-of-the-art approaches.
Remarkably, our proposed method obtains the frame-level AUC score of 88.3% on
the CUHK Avenue dataset.
</p>
<a href="http://arxiv.org/abs/2011.02763" target="_blank">arXiv:2011.02763</a> [<a href="http://arxiv.org/pdf/2011.02763" target="_blank">pdf</a>]

<h2>A Bregman Method for Structure Learning on Sparse Directed Acyclic Graphs. (arXiv:2011.02764v1 [stat.ML])</h2>
<h3>Manon Romain, Alexandre d&#x27;Aspremont</h3>
<p>We develop a Bregman proximal gradient method for structure learning on
linear structural causal models. While the problem is non-convex, has high
curvature and is in fact NP-hard, Bregman gradient methods allow us to
neutralize at least part of the impact of curvature by measuring smoothness
against a highly nonlinear kernel. This allows the method to make longer steps
and significantly improves convergence. Each iteration requires solving a
Bregman proximal step which is convex and efficiently solvable for our
particular choice of kernel. We test our method on various synthetic and real
data sets.
</p>
<a href="http://arxiv.org/abs/2011.02764" target="_blank">arXiv:2011.02764</a> [<a href="http://arxiv.org/pdf/2011.02764" target="_blank">pdf</a>]

<h2>Multi-Accent Adaptation based on Gate Mechanism. (arXiv:2011.02774v1 [eess.AS])</h2>
<h3>Han Zhu, Li Wang, Pengyuan Zhang, Yonghong Yan</h3>
<p>When only a limited amount of accented speech data is available, to promote
multi-accent speech recognition performance, the conventional approach is
accent-specific adaptation, which adapts the baseline model to multiple target
accents independently. To simplify the adaptation procedure, we explore
adapting the baseline model to multiple target accents simultaneously with
multi-accent mixed data. Thus, we propose using accent-specific top layer with
gate mechanism (AST-G) to realize multi-accent adaptation. Compared with the
baseline model and accent-specific adaptation, AST-G achieves 9.8% and 1.9%
average relative WER reduction respectively. However, in real-world
applications, we can't obtain the accent category label for inference in
advance. Therefore, we apply using an accent classifier to predict the accent
label. To jointly train the acoustic model and the accent classifier, we
propose the multi-task learning with gate mechanism (MTL-G). As the accent
label prediction could be inaccurate, it performs worse than the
accent-specific adaptation. Yet, in comparison with the baseline model, MTL-G
achieves 5.1% average relative WER reduction.
</p>
<a href="http://arxiv.org/abs/2011.02774" target="_blank">arXiv:2011.02774</a> [<a href="http://arxiv.org/pdf/2011.02774" target="_blank">pdf</a>]

<h2>Domain Adaptation Using Class Similarity for Robust Speech Recognition. (arXiv:2011.02782v1 [eess.AS])</h2>
<h3>Han Zhu, Jiangjiang Zhao, Yuling Ren, Li Wang, Pengyuan Zhang</h3>
<p>When only limited target domain data is available, domain adaptation could be
used to promote performance of deep neural network (DNN) acoustic model by
leveraging well-trained source model and target domain data. However, suffering
from domain mismatch and data sparsity, domain adaptation is very challenging.
This paper proposes a novel adaptation method for DNN acoustic model using
class similarity. Since the output distribution of DNN model contains the
knowledge of similarity among classes, which is applicable to both source and
target domain, it could be transferred from source to target model for the
performance improvement. In our approach, we first compute the frame level
posterior probabilities of source samples using source model. Then, for each
class, probabilities of this class are used to compute a mean vector, which we
refer to as mean soft labels. During adaptation, these mean soft labels are
used in a regularization term to train the target model. Experiments showed
that our approach outperforms fine-tuning using one-hot labels on both accent
and noise adaptation task, especially when source and target domain are highly
mismatched.
</p>
<a href="http://arxiv.org/abs/2011.02782" target="_blank">arXiv:2011.02782</a> [<a href="http://arxiv.org/pdf/2011.02782" target="_blank">pdf</a>]

<h2>Deep Metric Learning with Spherical Embedding. (arXiv:2011.02785v1 [cs.CV])</h2>
<h3>Dingyi Zhang, Yingming Li, Zhongfei Zhang</h3>
<p>Deep metric learning has attracted much attention in recent years, due to
seamlessly combining the distance metric learning and deep neural network. Many
endeavors are devoted to design different pair-based angular loss functions,
which decouple the magnitude and direction information for embedding vectors
and ensure the training and testing measure consistency. However, these
traditional angular losses cannot guarantee that all the sample embeddings are
on the surface of the same hypersphere during the training stage, which would
result in unstable gradient in batch optimization and may influence the quick
convergence of the embedding learning. In this paper, we first investigate the
effect of the embedding norm for deep metric learning with angular distance,
and then propose a spherical embedding constraint (SEC) to regularize the
distribution of the norms. SEC adaptively adjusts the embeddings to fall on the
same hypersphere and performs more balanced direction update. Extensive
experiments on deep metric learning, face recognition, and contrastive
self-supervised learning show that the SEC-based angular space learning
strategy significantly improves the performance of the state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2011.02785" target="_blank">arXiv:2011.02785</a> [<a href="http://arxiv.org/pdf/2011.02785" target="_blank">pdf</a>]

<h2>The State of AI Ethics Report (October 2020). (arXiv:2011.02787v1 [cs.CY])</h2>
<h3>Abhishek Gupta (1 and 2), Alexandrine Royer (1 and 3), Victoria Heath (1 and 4), Connor Wright (1 and 5), Camylle Lanteigne (1, 6, and 7), Allison Cohen (1, 8, and 9), Marianna Bergamaschi Ganapini (1 and 10), Muriam Fancy (1, 11, and 12), Erick Galinkin (1 and 13), Ryan Khurana (1), Mo Akif (1), Renjie Butalid (1), Falaah Arif Khan (1, 14, and 15), Masa Sweidan (1 and 16), Audrey Balogh (1 and 16) ((1) Montreal AI Ethics Institute, (2) Microsoft, (3) University of Cambridge, (4) Creative Commons, (5) University of Exeter, (6) Concordia University, (7) Algora Lab, (8) AI Global, (9) Mila, (10) Union College, (11) University of Toronto, (12) University of Ottawa, (13) Rapid7, (14) NYU Center for Responsible AI, (15) IIIT Hyderabad, (16) McGill University)</h3>
<p>The 2nd edition of the Montreal AI Ethics Institute's The State of AI Ethics
captures the most relevant developments in the field of AI Ethics since July
2020. This report aims to help anyone, from machine learning experts to human
rights activists and policymakers, quickly digest and understand the
ever-changing developments in the field. Through research and article
summaries, as well as expert commentary, this report distills the research and
reporting surrounding various domains related to the ethics of AI, including:
AI and society, bias and algorithmic justice, disinformation, humans and AI,
labor impacts, privacy, risk, and future of AI ethics.

In addition, The State of AI Ethics includes exclusive content written by
world-class AI Ethics experts from universities, research institutes,
consulting firms, and governments. These experts include: Danit Gal (Tech
Advisor, United Nations), Amba Kak (Director of Global Policy and Programs,
NYU's AI Now Institute), Rumman Chowdhury (Global Lead for Responsible AI,
Accenture), Brent Barron (Director of Strategic Projects and Knowledge
Management, CIFAR), Adam Murray (U.S. Diplomat working on tech policy, Chair of
the OECD Network on AI), Thomas Kochan (Professor, MIT Sloan School of
Management), and Katya Klinova (AI and Economy Program Lead, Partnership on
AI).

This report should be used not only as a point of reference and insight on
the latest thinking in the field of AI Ethics, but should also be used as a
tool for introspection as we aim to foster a more nuanced conversation
regarding the impacts of AI on the world.
</p>
<a href="http://arxiv.org/abs/2011.02787" target="_blank">arXiv:2011.02787</a> [<a href="http://arxiv.org/pdf/2011.02787" target="_blank">pdf</a>]

<h2>Learning to Approximate Functions Using Nb-doped SrTiO$_3$ Memristors. (arXiv:2011.02794v1 [cs.ET])</h2>
<h3>Thomas F. Tiotto, Anouk S. Goossens, Jelmer P. Borst, Tamalika Banerjee, Niels A. Taatgen</h3>
<p>Memristors have attracted interest as neuromorphic computation elements
because they show promise in enabling efficient hardware implementations of
artificial neurons and synapses. We performed measurements on interface-type
memristors to validate their use in neuromorphic hardware. Specifically, we
utilised Nb-doped SrTiO$_3$ memristors as synapses in a simulated neural
network by arranging them into differential synaptic pairs, with the weight of
the connection given by the difference in normalised conductance values between
the two paired memristors. This network learned to represent functions through
a training process based on a novel supervised learning algorithm, during which
discrete voltage pulses were applied to one of the two memristors in each pair.
To simulate the fact that both the initial state of the physical memristive
devices and the impact of each voltage pulse are unknown we injected noise at
each time step. Nevertheless, discrete updates based on local knowledge were
shown to result in robust learning performance. Using this class of memristive
devices as the synaptic weight element in a spiking neural network yields, to
our knowledge, one of the first models of this kind, capable of learning to be
a universal function approximator, and strongly suggests the suitability of
these memristors for usage in future computing platforms.
</p>
<a href="http://arxiv.org/abs/2011.02794" target="_blank">arXiv:2011.02794</a> [<a href="http://arxiv.org/pdf/2011.02794" target="_blank">pdf</a>]

<h2>FederBoost: Private Federated Learning for GBDT. (arXiv:2011.02796v1 [cs.CR])</h2>
<h3>Zhihua Tian, Rui Zhang, Xiaoyang Hou, Jian Liu, Kui Ren</h3>
<p>An emerging trend in machine learning and artificial intelligence is
federated learning (FL), which allows multiple participants to contribute
various training data to train a better model. It promises to keep the training
data local for each participant, leading to low communication complexity and
high privacy. However, there are still two problems in FL remain unsolved: (1)
unable to handle vertically partitioned data, and (2) unable to support
decision trees. Existing FL solutions for vertically partitioned data or
decision trees require heavy cryptographic operations. In this paper, we
propose a framework named FederBoost for private federated learning of gradient
boosting decision trees (GBDT). It supports running GBDT over both horizontally
and vertically partitioned data. The key observation for designing FederBoost
is that the whole training process of GBDT relies on the order of the data
instead of the values. Consequently, vertical FederBoost does not require any
cryptographic operation and horizontal FederBoost only requires lightweight
secure aggregation. We fully implement FederBoost and evaluate its utility and
efficiency through extensive experiments performed on three public datasets.
Our experimental results show that both vertical and horizontal FederBoost
achieve the same level of AUC with centralized training where all data are
collected in a central server; and both of them can finish training within half
an hour even in WAN.
</p>
<a href="http://arxiv.org/abs/2011.02796" target="_blank">arXiv:2011.02796</a> [<a href="http://arxiv.org/pdf/2011.02796" target="_blank">pdf</a>]

<h2>Intriguing Properties of Contrastive Losses. (arXiv:2011.02803v1 [cs.LG])</h2>
<h3>Ting Chen, Lala Li</h3>
<p>Contrastive loss and its variants have become very popular recently for
learning visual representations without supervision. In this work, we first
generalize the standard contrastive loss based on cross entropy to a broader
family of losses that share an abstract form of $\mathcal{L}_{\text{alignment}}
+ \lambda \mathcal{L}_{\text{distribution}}$, where hidden representations are
encouraged to (1) be aligned under some transformations/augmentations, and (2)
match a prior distribution of high entropy. We show that various instantiations
of the generalized loss perform similarly under the presence of a multi-layer
non-linear projection head, and the temperature scaling ($\tau$) widely used in
the standard contrastive loss is (within a range) inversely related to the
weighting ($\lambda$) between the two loss terms. We then study an intriguing
phenomenon of feature suppression among competing features shared acros
augmented views, such as "color distribution" vs "object class". We construct
datasets with explicit and controllable competing features, and show that, for
contrastive learning, a few bits of easy-to-learn shared features could
suppress, and even fully prevent, the learning of other sets of competing
features. Interestingly, this characteristic is much less detrimental in
autoencoders based on a reconstruction loss. Existing contrastive learning
methods critically rely on data augmentation to favor certain sets of features
than others, while one may wish that a network would learn all competing
features as much as its capacity allows.
</p>
<a href="http://arxiv.org/abs/2011.02803" target="_blank">arXiv:2011.02803</a> [<a href="http://arxiv.org/pdf/2011.02803" target="_blank">pdf</a>]

<h2>Challenges and strategies for running controlled crowdsourcing experiments. (arXiv:2011.02804v1 [cs.HC])</h2>
<h3>Jorge Ram&#xed;rez, Marcos Baez, Fabio Casati, Luca Cernuzzi, Boualem Benatallah</h3>
<p>This paper reports on the challenges and lessons we learned while running
controlled experiments in crowdsourcing platforms. Crowdsourcing is becoming an
attractive technique to engage a diverse and large pool of subjects in
experimental research, allowing researchers to achieve levels of scale and
completion times that would otherwise not be feasible in lab settings. However,
the scale and flexibility comes at the cost of multiple and sometimes unknown
sources of bias and confounding factors that arise from technical limitations
of crowdsourcing platforms and from the challenges of running controlled
experiments in the "wild". In this paper, we take our experience in running
systematic evaluations of task design as a motivating example to explore,
describe, and quantify the potential impact of running uncontrolled
crowdsourcing experiments and derive possible coping strategies. Among the
challenges identified, we can mention sampling bias, controlling the assignment
of subjects to experimental conditions, learning effects, and reliability of
crowdsourcing results. According to our empirical studies, the impact of
potential biases and confounding factors can amount to a 38\% loss in the
utility of the data collected in uncontrolled settings; and it can
significantly change the outcome of experiments. These issues ultimately
inspired us to implement CrowdHub, a system that sits on top of major
crowdsourcing platforms and allows researchers and practitioners to run
controlled crowdsourcing projects.
</p>
<a href="http://arxiv.org/abs/2011.02804" target="_blank">arXiv:2011.02804</a> [<a href="http://arxiv.org/pdf/2011.02804" target="_blank">pdf</a>]

<h2>Semi-supervised Learning for Singing Synthesis Timbre. (arXiv:2011.02809v1 [cs.SD])</h2>
<h3>Jordi Bonada, Merlijn Blaauw</h3>
<p>We propose a semi-supervised singing synthesizer, which is able to learn new
voices from audio data only, without any annotations such as phonetic
segmentation. Our system is an encoder-decoder model with two encoders,
linguistic and acoustic, and one (acoustic) decoder. In a first step, the
system is trained in a supervised manner, using a labelled multi-singer
dataset. Here, we ensure that the embeddings produced by both encoders are
similar, so that we can later use the model with either acoustic or linguistic
input features. To learn a new voice in an unsupervised manner, the pretrained
acoustic encoder is used to train a decoder for the target singer. Finally, at
inference, the pretrained linguistic encoder is used together with the decoder
of the new voice, to produce acoustic features from linguistic input. We
evaluate our system with a listening test and show that the results are
comparable to those obtained with an equivalent supervised approach.
</p>
<a href="http://arxiv.org/abs/2011.02809" target="_blank">arXiv:2011.02809</a> [<a href="http://arxiv.org/pdf/2011.02809" target="_blank">pdf</a>]

<h2>Efficient Online Learning of Optimal Rankings: Dimensionality Reduction via Gradient Descent. (arXiv:2011.02817v1 [cs.LG])</h2>
<h3>Dimitris Fotakis, Thanasis Lianeas, Georgios Piliouras, Stratis Skoulakis</h3>
<p>We consider a natural model of online preference aggregation, where sets of
preferred items $R_1, R_2, \ldots, R_t$ along with a demand for $k_t$ items in
each $R_t$, appear online. Without prior knowledge of $(R_t, k_t)$, the learner
maintains a ranking $\pi_t$ aiming that at least $k_t$ items from $R_t$ appear
high in $\pi_t$. This is a fundamental problem in preference aggregation with
applications to, e.g., ordering product or news items in web pages based on
user scrolling and click patterns. The widely studied Generalized
Min-Sum-Set-Cover (GMSSC) problem serves as a formal model for the setting
above. GMSSC is NP-hard and the standard application of no-regret online
learning algorithms is computationally inefficient, because they operate in the
space of rankings. In this work, we show how to achieve low regret for GMSSC in
polynomial-time. We employ dimensionality reduction from rankings to the space
of doubly stochastic matrices, where we apply Online Gradient Descent. A key
step is to show how subgradients can be computed efficiently, by solving the
dual of a configuration LP. Using oblivious deterministic and randomized
rounding schemes, we map doubly stochastic matrices back to rankings with a
small loss in the GMSSC objective.
</p>
<a href="http://arxiv.org/abs/2011.02817" target="_blank">arXiv:2011.02817</a> [<a href="http://arxiv.org/pdf/2011.02817" target="_blank">pdf</a>]

<h2>Learning a Centroidal Motion Planner for Legged Locomotion. (arXiv:2011.02818v1 [cs.RO])</h2>
<h3>Julian Viereck, Ludovic Righetti</h3>
<p>Whole-body optimizers have been successful at automatically computing complex
dynamic locomotion behaviors. However they are often limited to offline
planning as they are computationally too expensive to replan with a high
frequency. Simpler models are then typically used for online replanning. In
this paper we present a method to generate whole body movements in real-time
for locomotion tasks. Our approach consists in learning a centroidal neural
network that predicts the desired centroidal motion given the current state of
the robot and a desired contact plan. The network is trained using an existing
whole body motion optimizer. Our approach enables to learn with few training
samples dynamic motions that can be used in a complete whole-body control
framework at high frequency, which is usually not attainable with typical
full-body optimizers. We demonstrate our method to generate a rich set of
walking and jumping motions on a real quadruped robot.
</p>
<a href="http://arxiv.org/abs/2011.02818" target="_blank">arXiv:2011.02818</a> [<a href="http://arxiv.org/pdf/2011.02818" target="_blank">pdf</a>]

<h2>Local SGD: Unified Theory and New Efficient Methods. (arXiv:2011.02828v1 [cs.LG])</h2>
<h3>Eduard Gorbunov, Filip Hanzely, Peter Richt&#xe1;rik</h3>
<p>We present a unified framework for analyzing local SGD methods in the convex
and strongly convex regimes for distributed/federated training of supervised
machine learning models. We recover several known methods as a special case of
our general framework, including Local-SGD/FedAvg, SCAFFOLD, and several
variants of SGD not originally designed for federated learning. Our framework
covers both the identical and heterogeneous data settings, supports both random
and deterministic number of local steps, and can work with a wide array of
local stochastic gradient estimators, including shifted estimators which are
able to adjust the fixed points of local iterations for faster convergence. As
an application of our framework, we develop multiple novel FL optimizers which
are superior to existing methods. In particular, we develop the first linearly
converging local SGD method which does not require any data homogeneity or
other strong assumptions.
</p>
<a href="http://arxiv.org/abs/2011.02828" target="_blank">arXiv:2011.02828</a> [<a href="http://arxiv.org/pdf/2011.02828" target="_blank">pdf</a>]

<h2>Deep tree-ensembles for multi-output prediction. (arXiv:2011.02829v1 [cs.LG])</h2>
<h3>Felipe Kenji Nakano, Konstantinos Pliakos, Celine Vens</h3>
<p>Recently, deep neural networks have expanded the state-of-art in various
scientific fields and provided solutions to long standing problems across
multiple application domains. Nevertheless, they also suffer from weaknesses
since their optimal performance depends on massive amounts of training data and
the tuning of an extended number of parameters. As a countermeasure, some
deep-forest methods have been recently proposed, as efficient and low-scale
solutions. Despite that, these approaches simply employ label classification
probabilities as induced features and primarily focus on traditional
classification and regression tasks, leaving multi-output prediction
under-explored. Moreover, recent work has demonstrated that tree-embeddings are
highly representative, especially in structured output prediction. In this
direction, we propose a novel deep tree-ensemble (DTE) model, where every layer
enriches the original feature set with a representation learning component
based on tree-embeddings. In this paper, we specifically focus on two
structured output prediction tasks, namely multi-label classification and
multi-target regression. We conducted experiments using multiple benchmark
datasets and the obtained results confirm that our method provides superior
results to state-of-the-art methods in both tasks.
</p>
<a href="http://arxiv.org/abs/2011.02829" target="_blank">arXiv:2011.02829</a> [<a href="http://arxiv.org/pdf/2011.02829" target="_blank">pdf</a>]

<h2>Image Classification via Quantum Machine Learning. (arXiv:2011.02831v1 [quant-ph])</h2>
<h3>H&#xe9;ctor Iv&#xe1;n Garc&#xed;a Hern&#xe1;ndez, Raymundo Torres Ruiz, Guo-Hua Sun</h3>
<p>Quantum Computing and especially Quantum Machine Learning, in a short period
of time, has gained a lot of interest through research groups around the world.
This can be seen in the increasing number of proposed models for pattern
classification applying quantum principles to a certain degree. Despise the
increasing volume of models, there is a void in testing these models on real
datasets and not only on synthetic ones. The objective of this work is to
classify patterns with binary attributes using a quantum classifier. Specially,
we show results of a complete quantum classifier applied to image datasets. The
experiments show favorable output while dealing with balanced classification
problems as well as with imbalanced classes where the minority class is the
most relevant. This is promising in medical areas, where usually the important
class is also the minority class.
</p>
<a href="http://arxiv.org/abs/2011.02831" target="_blank">arXiv:2011.02831</a> [<a href="http://arxiv.org/pdf/2011.02831" target="_blank">pdf</a>]

<h2>Pitfalls in Machine Learning Research: Reexamining the Development Cycle. (arXiv:2011.02832v1 [cs.LG])</h2>
<h3>Stella Biderman, Walter J. Scheirer</h3>
<p>Machine learning has the potential to fuel further advances in data science,
but it is greatly hindered by an ad hoc design process, poor data hygiene, and
a lack of statistical rigor in model evaluation. Recently, these issues have
begun to attract more attention as they have caused public and embarrassing
issues in research and development. Drawing from our experience as machine
learning researchers, we follow the machine learning process from algorithm
design to data collection to model evaluation, drawing attention to common
pitfalls and providing practical recommendations for improvements. At each
step, case studies are introduced to highlight how these pitfalls occur in
practice, and where things could be improved.
</p>
<a href="http://arxiv.org/abs/2011.02832" target="_blank">arXiv:2011.02832</a> [<a href="http://arxiv.org/pdf/2011.02832" target="_blank">pdf</a>]

<h2>Digital Twins: State of the Art Theory and Practice, Challenges, and Open Research Questions. (arXiv:2011.02833v1 [cs.LG])</h2>
<h3>Angira Sharma, Edward Kosasih, Jie Zhang, Alexandra Brintrup, Anisoara Calinescu</h3>
<p>Digital Twin was introduced over a decade ago, as an innovative
all-encompassing tool, with perceived benefits including real-time monitoring,
simulation and forecasting. However, the theoretical framework and practical
implementations of digital twins (DT) are still far from this vision. Although
successful implementations exist, sufficient implementation details are not
publicly available, therefore it is difficult to assess their effectiveness,
draw comparisons and jointly advance the DT methodology. This work explores the
various DT features and current approaches, the shortcomings and reasons behind
the delay in the implementation and adoption of digital twin. Advancements in
machine learning, internet of things and big data have contributed hugely to
the improvements in DT with regards to its real-time monitoring and forecasting
properties. Despite this progress and individual company-based efforts, certain
research gaps exist in the field, which have caused delay in the widespread
adoption of this concept. We reviewed relevant works and identified that the
major reasons for this delay are the lack of a universal reference framework,
domain dependence, security concerns of shared data, reliance of digital twin
on other technologies, and lack of quantitative metrics. We define the
necessary components of a digital twin required for a universal reference
framework, which also validate its uniqueness as a concept compared to similar
concepts like simulation, autonomous systems, etc. This work further assesses
the digital twin applications in different domains and the current state of
machine learning and big data in it. It thus answers and identifies novel
research questions, both of which will help to better understand and advance
the theory and practice of digital twins.
</p>
<a href="http://arxiv.org/abs/2011.02833" target="_blank">arXiv:2011.02833</a> [<a href="http://arxiv.org/pdf/2011.02833" target="_blank">pdf</a>]

<h2>Augmenting Organizational Decision-Making with Deep Learning Algorithms: Principles, Promises, and Challenges. (arXiv:2011.02834v1 [cs.LG])</h2>
<h3>Yash Raj Shrestha, Vaibhav Krishna, Georg von Krogh</h3>
<p>The current expansion of theory and research on artificial intelligence in
management and organization studies has revitalized the theory and research on
decision-making in organizations. In particular, recent advances in deep
learning (DL) algorithms promise benefits for decision-making within
organizations, such as assisting employees with information processing, thereby
augment their analytical capabilities and perhaps help their transition to more
creative work.
</p>
<a href="http://arxiv.org/abs/2011.02834" target="_blank">arXiv:2011.02834</a> [<a href="http://arxiv.org/pdf/2011.02834" target="_blank">pdf</a>]

<h2>Dynamically Throttleable Neural Networks (TNN). (arXiv:2011.02836v1 [cs.LG])</h2>
<h3>Hengyue Liu, Samyak Parajuli, Jesse Hostetler, Sek Chai, Bir Bhanu</h3>
<p>Conditional computation for Deep Neural Networks (DNNs) reduce overall
computational load and improve model accuracy by running a subset of the
network. In this work, we present a runtime throttleable neural network (TNN)
that can adaptively self-regulate its own performance target and computing
resources. We designed TNN with several properties that enable more flexibility
for dynamic execution based on runtime context. TNNs are defined as
throttleable modules gated with a separately trained controller that generates
a single utilization control parameter. We validate our proposal on a number of
experiments, including Convolution Neural Networks (CNNs such as VGG, ResNet,
ResNeXt, DenseNet) using CiFAR-10 and ImageNet dataset, for object
classification and recognition tasks. We also demonstrate the effectiveness of
dynamic TNN execution on a 3D Convolustion Network (C3D) for a hand gesture
task. Results show that TNN can maintain peak accuracy performance compared to
vanilla solutions, while providing a graceful reduction in computational
requirement, down to 74% reduction in latency and 52% energy savings.
</p>
<a href="http://arxiv.org/abs/2011.02836" target="_blank">arXiv:2011.02836</a> [<a href="http://arxiv.org/pdf/2011.02836" target="_blank">pdf</a>]

<h2>DR-Unet104 for Multimodal MRI brain tumor segmentation. (arXiv:2011.02840v1 [eess.IV])</h2>
<h3>Jordan Colman, Lei Zhang, Wenting Duan, Xujiong Ye</h3>
<p>In this paper we propose a 2D deep residual Unet with 104 convolutional
layers (DR-Unet104) for lesion segmentation in brain MRIs. We make multiple
additions to the Unet architecture, including adding the 'bottleneck' residual
block to the Unet encoder and adding dropout after each convolution block
stack. We verified the effect of introducing the regularisation of dropout with
small rate (e.g. 0.2) on the architecture, and found a dropout of 0.2 improved
the overall performance compared to no dropout, or a dropout of 0.5. We
evaluated the proposed architecture as part of the Multimodal Brain Tumor
Segmentation (BraTS) 2020 Challenge and compared our method to DeepLabV3+ with
a ResNet-V2-152 backbone. We found that the DR-Unet104 achieved a mean dice
score coefficient of 0.8862, 0.6756 and 0.6721 for validation data, whole
tumor, enhancing tumor and tumor core respectively, an overall improvement on
0.8770, 0.65242 and 0.68134 achieved by DeepLabV3+. Our method produced a final
mean DSC of 0.8673, 0.7514 and 0.7983 on whole tumor, enhancing tumor and tumor
core on the challenge's testing data. We present this as a state-of-the-art 2D
lesion segmentation architecture that can be used on lower power computers than
a 3D architecture. The source code and trained model for this work is openly
available at https://github.com/jordan-colman/DR-Unet104.
</p>
<a href="http://arxiv.org/abs/2011.02840" target="_blank">arXiv:2011.02840</a> [<a href="http://arxiv.org/pdf/2011.02840" target="_blank">pdf</a>]

<h2>A generalized model for data science. (arXiv:2011.02842v1 [cs.LG])</h2>
<h3>Ziqi Zhang, Chuanxu Zhao</h3>
<p>Neural network is a powerful tool, which is often regarded as a black box.
However, different task requires different parameters to be set up or couldn't
work on, thus variable parameters might be a good solution for different tasks.
We present a two-stage model based on Deep reinforcement learning as well as
the pre-train method, this model could configure different parameters according
to different data, improving and optimizing those parameters furthermore
according to the returned loss value in each iteration. We apply this model to
Boston housing pricing dataset, and it got a good result in restricted
condition which was consistent with our expectations.
</p>
<a href="http://arxiv.org/abs/2011.02842" target="_blank">arXiv:2011.02842</a> [<a href="http://arxiv.org/pdf/2011.02842" target="_blank">pdf</a>]

<h2>UAV-AdNet: Unsupervised Anomaly Detection using Deep Neural Networks for Aerial Surveillance. (arXiv:2011.02853v1 [cs.CV])</h2>
<h3>Ilker Bozcan, Erdal Kayacan</h3>
<p>Anomaly detection is a key goal of autonomous surveillance systems that
should be able to alert unusual observations. In this paper, we propose a
holistic anomaly detection system using deep neural networks for surveillance
of critical infrastructures (e.g., airports, harbors, warehouses) using an
unmanned aerial vehicle (UAV). First, we present a heuristic method for the
explicit representation of spatial layouts of objects in bird-view images.
Then, we propose a deep neural network architecture for unsupervised anomaly
detection (UAV-AdNet), which is trained on environment representations and GPS
labels of bird-view images jointly. Unlike studies in the literature, we
combine GPS and image data to predict abnormal observations. We evaluate our
model against several baselines on our aerial surveillance dataset and show
that it performs better in scene reconstruction and several anomaly detection
tasks. The codes, trained models, dataset, and video will be available at
https://bozcani.github.io/uavadnet.
</p>
<a href="http://arxiv.org/abs/2011.02853" target="_blank">arXiv:2011.02853</a> [<a href="http://arxiv.org/pdf/2011.02853" target="_blank">pdf</a>]

<h2>This Looks Like That, Because ... Explaining Prototypes for Interpretable Image Recognition. (arXiv:2011.02863v1 [cs.CV])</h2>
<h3>Meike Nauta, Annemarie Jutte, Jesper Provoost, Christin Seifert</h3>
<p>Image recognition with prototypes is considered an interpretable alternative
for black box deep learning models. Classification depends on the extent to
which a test image "looks like" a prototype. However, perceptual similarity for
humans can be different from the similarity learnt by the model. A user is
unaware of the underlying classification strategy and does not know which image
characteristics (e.g., color or shape) is the dominant characteristic for the
decision. We address this ambiguity and argue that prototypes should be
explained. Only visualizing prototypes can be insufficient for understanding
what a prototype exactly represents, and why a prototype and an image are
considered similar. We improve interpretability by automatically enhancing
prototypes with extra information about visual characteristics considered
important by the model. Specifically, our method quantifies the influence of
color hue, shape, texture, contrast and saturation in a prototype. We apply our
method to the existing Prototypical Part Network (ProtoPNet) and show that our
explanations clarify the meaning of a prototype which might have been
interpreted incorrectly otherwise. We also reveal that visually similar
prototypes can have the same explanations, indicating redundancy. Because of
the generality of our approach, it can improve the interpretability of any
similarity-based method for prototypical image recognition.
</p>
<a href="http://arxiv.org/abs/2011.02863" target="_blank">arXiv:2011.02863</a> [<a href="http://arxiv.org/pdf/2011.02863" target="_blank">pdf</a>]

<h2>Against Adversarial Learning: Naturally Distinguish Known and Unknown in Open Set Domain Adaptation. (arXiv:2011.02876v1 [cs.LG])</h2>
<h3>Sitong Mao, Xiao Shen, Fu-lai Chung</h3>
<p>Open set domain adaptation refers to the scenario that the target domain
contains categories that do not exist in the source domain. It is a more common
situation in the reality compared with the typical closed set domain adaptation
where the source domain and the target domain contain the same categories. The
main difficulty of open set domain adaptation is that we need to distinguish
which target data belongs to the unknown classes when machine learning models
only have concepts about what they know. In this paper, we propose an "against
adversarial learning" method that can distinguish unknown target data and known
data naturally without setting any additional hyper parameters and the target
data predicted to the known classes can be classified at the same time.
Experimental results show that the proposed method can make significant
improvement in performance compared with several state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2011.02876" target="_blank">arXiv:2011.02876</a> [<a href="http://arxiv.org/pdf/2011.02876" target="_blank">pdf</a>]

<h2>Robust building footprint extraction from big multi-sensor data using deep competition network. (arXiv:2011.02879v1 [cs.CV])</h2>
<h3>Mehdi Khoshboresh-Masouleh, Mohammad R. Saradjian</h3>
<p>Building footprint extraction (BFE) from multi-sensor data such as optical
images and light detection and ranging (LiDAR) point clouds is widely used in
various fields of remote sensing applications. However, it is still challenging
research topic due to relatively inefficient building extraction techniques
from variety of complex scenes in multi-sensor data. In this study, we develop
and evaluate a deep competition network (DCN) that fuses very high spatial
resolution optical remote sensing images with LiDAR data for robust BFE. DCN is
a deep superpixelwise convolutional encoder-decoder architecture using the
encoder vector quantization with classified structure. DCN consists of five
encoding-decoding blocks with convolutional weights for robust binary
representation (superpixel) learning. DCN is trained and tested in a big
multi-sensor dataset obtained from the state of Indiana in the United States
with multiple building scenes. Comparison results of the accuracy assessment
showed that DCN has competitive BFE performance in comparison with other deep
semantic binary segmentation architectures. Therefore, we conclude that the
proposed model is a suitable solution to the robust BFE from big multi-sensor
data.
</p>
<a href="http://arxiv.org/abs/2011.02879" target="_blank">arXiv:2011.02879</a> [<a href="http://arxiv.org/pdf/2011.02879" target="_blank">pdf</a>]

<h2>Covariance Self-Attention Dual Path UNet for Rectal Tumor Segmentation. (arXiv:2011.02880v1 [eess.IV])</h2>
<h3>Haijun Gao, Bochuan Zheng, Dazhi Pan, Xiangyin Zeng</h3>
<p>Deep learning algorithms are preferable for rectal tumor segmentation.
However, it is still a challenge task to accurately segment and identify the
locations and sizes of rectal tumors by using deep learning methods. To
increase the capability of extracting enough feature information for rectal
tumor segmentation, we propose a Covariance Self-Attention Dual Path UNet
(CSA-DPUNet). The proposed network mainly includes two improvements on UNet: 1)
modify UNet that has only one path structure to consist of two contracting path
and two expansive paths (nam new network as DPUNet), which can help extract
more feature information from CT images; 2) employ the criss-cross
self-attention module into DPUNet, meanwhile, replace the original calculation
method of correlation operation with covariance operation, which can further
enhances the characterization ability of DPUNet and improves the segmentation
accuracy of rectal tumors. Experiments illustrate that compared with the
current state-of-the-art results, CSA-DPUNet brings 15.31%, 7.2%, 11.8%, and
9.5% improvement in Dice coefficient, P, R, F1, respectively, which
demonstrates that our proposed CSA-DPUNet is effective for rectal tumor
segmentation.
</p>
<a href="http://arxiv.org/abs/2011.02880" target="_blank">arXiv:2011.02880</a> [<a href="http://arxiv.org/pdf/2011.02880" target="_blank">pdf</a>]

<h2>Collaborative City Digital Twin For Covid-19 Pandemic: A Federated Learning Solution. (arXiv:2011.02883v1 [cs.LG])</h2>
<h3>Junjie Pang, Jianbo Li, Zhenzhen Xie, Yan Huang, Zhipeng Cai</h3>
<p>In this work, we propose a collaborative city digital twin based on FL, a
novel paradigm that allowing multiple city DT to share the local strategy and
status in a timely manner. In particular, an FL central server manages the
local updates of multiple collaborators (city DT), provides a global model
which is trained in multiple iterations at different city DT systems, until the
model gains the correlations between various response plan and infection trend.
That means, a collaborative city DT paradigm based on FL techniques can obtain
knowledge and patterns from multiple DTs, and eventually establish a `global
view' for city crisis management. Meanwhile, it also helps to improve each city
digital twin selves by consolidating other DT's respective data without
violating privacy rules. To validate the proposed solution, we take COVID-19
pandemic as a case study. The experimental results on the real dataset with
various response plan validate our proposed solution and demonstrate the
superior performance.
</p>
<a href="http://arxiv.org/abs/2011.02883" target="_blank">arXiv:2011.02883</a> [<a href="http://arxiv.org/pdf/2011.02883" target="_blank">pdf</a>]

<h2>Semantic and Relational Spaces in Science of Science: Deep Learning Models for Article Vectorisation. (arXiv:2011.02887v1 [cs.SI])</h2>
<h3>Diego Kozlowski, Jennifer Dusdal, Jun Pang, Andreas Zilian</h3>
<p>Over the last century, we observe a steady and exponentially growth of
scientific publications globally. The overwhelming amount of available
literature makes a holistic analysis of the research within a field and between
fields based on manual inspection impossible. Automatic techniques to support
the process of literature review are required to find the epistemic and social
patterns that are embedded in scientific publications. In computer sciences,
new tools have been developed to deal with large volumes of data. In
particular, deep learning techniques open the possibility of automated
end-to-end models to project observations to a new, low-dimensional space where
the most relevant information of each observation is highlighted. Using deep
learning to build new representations of scientific publications is a growing
but still emerging field of research. The aim of this paper is to discuss the
potential and limits of deep learning for gathering insights about scientific
research articles. We focus on document-level embeddings based on the semantic
and relational aspects of articles, using Natural Language Processing (NLP) and
Graph Neural Networks (GNNs). We explore the different outcomes generated by
those techniques. Our results show that using NLP we can encode a semantic
space of articles, while with GNN we are able to build a relational space where
the social practices of a research community are also encoded.
</p>
<a href="http://arxiv.org/abs/2011.02887" target="_blank">arXiv:2011.02887</a> [<a href="http://arxiv.org/pdf/2011.02887" target="_blank">pdf</a>]

<h2>Improving Robotic Grasping on Monocular Images Via Multi-Task Learning and Positional Loss. (arXiv:2011.02888v1 [cs.RO])</h2>
<h3>William Prew, Toby Breckon, Magnus Bordewich, Ulrik Beierholm</h3>
<p>In this paper, we introduce two methods of improving real-time object
grasping performance from monocular colour images in an end-to-end CNN
architecture. The first is the addition of an auxiliary task during model
training (multi-task learning). Our multi-task CNN model improves grasping
performance from a baseline average of 72.04% to 78.14% on the large Jacquard
grasping dataset when performing a supplementary depth reconstruction task. The
second is introducing a positional loss function that emphasises loss per pixel
for secondary parameters (gripper angle and width) only on points of an object
where a successful grasp can take place. This increases performance from a
baseline average of 72.04% to 78.92% as well as reducing the number of training
epochs required. These methods can be also performed in tandem resulting in a
further performance increase to 79.12% while maintaining sufficient inference
speed to afford real-time grasp processing.
</p>
<a href="http://arxiv.org/abs/2011.02888" target="_blank">arXiv:2011.02888</a> [<a href="http://arxiv.org/pdf/2011.02888" target="_blank">pdf</a>]

<h2>On the impact of predicate complexity in crowdsourced classification tasks. (arXiv:2011.02891v1 [cs.HC])</h2>
<h3>Jorge Ram&#xed;rez, Marcos Baez, Fabio Casati, Luca Cernuzzi, Boualem Benatallah, Ekaterina A. Taran, Veronika A. Malanina</h3>
<p>This paper explores and offers guidance on a specific and relevant problem in
task design for crowdsourcing: how to formulate a complex question used to
classify a set of items. In micro-task markets, classification is still among
the most popular tasks. We situate our work in the context of information
retrieval and multi-predicate classification, i.e., classifying a set of items
based on a set of conditions. Our experiments cover a wide range of tasks and
domains, and also consider crowd workers alone and in tandem with machine
learning classifiers. We provide empirical evidence into how the resulting
classification performance is affected by different predicate formulation
strategies, emphasizing the importance of predicate formulation as a task
design dimension in crowdsourcing.
</p>
<a href="http://arxiv.org/abs/2011.02891" target="_blank">arXiv:2011.02891</a> [<a href="http://arxiv.org/pdf/2011.02891" target="_blank">pdf</a>]

<h2>Hyperrealistic Image Inpainting with Hypergraphs. (arXiv:2011.02904v1 [cs.CV])</h2>
<h3>Gourav Wadhwa, Abhinav Dhall, Subrahmanyam Murala, Usman Tariq</h3>
<p>Image inpainting is a non-trivial task in computer vision due to multiple
possibilities for filling the missing data, which may be dependent on the
global information of the image. Most of the existing approaches use the
attention mechanism to learn the global context of the image. This attention
mechanism produces semantically plausible but blurry results because of
incapability to capture the global context. In this paper, we introduce
hypergraph convolution on spatial features to learn the complex relationship
among the data. We introduce a trainable mechanism to connect nodes using
hyperedges for hypergraph convolution. To the best of our knowledge, hypergraph
convolution have never been used on spatial features for any image-to-image
tasks in computer vision. Further, we introduce gated convolution in the
discriminator to enforce local consistency in the predicted image. The
experiments on Places2, CelebA-HQ, Paris Street View, and Facades datasets,
show that our approach achieves state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/2011.02904" target="_blank">arXiv:2011.02904</a> [<a href="http://arxiv.org/pdf/2011.02904" target="_blank">pdf</a>]

<h2>Pseudo Random Number Generation through Reinforcement Learning and Recurrent Neural Networks. (arXiv:2011.02909v1 [cs.CR])</h2>
<h3>Luca Pasqualini, Maurizio Parton</h3>
<p>A Pseudo-Random Number Generator (PRNG) is any algorithm generating a
sequence of numbers approximating properties of random numbers. These numbers
are widely employed in mid-level cryptography and in software applications.
Test suites are used to evaluate PRNGs quality by checking statistical
properties of the generated sequences. These sequences are commonly represented
bit by bit. This paper proposes a Reinforcement Learning (RL) approach to the
task of generating PRNGs from scratch by learning a policy to solve a partially
observable Markov Decision Process (MDP), where the full state is the period of
the generated sequence and the observation at each time step is the last
sequence of bits appended to such state. We use a Long-Short Term Memory (LSTM)
architecture to model the temporal relationship between observations at
different time steps, by tasking the LSTM memory with the extraction of
significant features of the hidden portion of the MDP's states. We show that
modeling a PRNG with a partially observable MDP and a LSTM architecture largely
improves the results of the fully observable feedforward RL approach introduced
in previous work.
</p>
<a href="http://arxiv.org/abs/2011.02909" target="_blank">arXiv:2011.02909</a> [<a href="http://arxiv.org/pdf/2011.02909" target="_blank">pdf</a>]

<h2>Machine Learning Framwork for Performance Anomaly in OpenMP Multi-Threaded Systems. (arXiv:2011.02914v1 [cs.DC])</h2>
<h3>Weidong Wang, Wangda Luo</h3>
<p>Some OpenMP multi-threaded applications increasingly suffer from performance
anomaly owning to shared resource contention as well as software- and
hardware-related problems. Such performance anomaly can result in failure and
inefficiencies, and are among the main challenges in system resiliency. To
minimize the impact of performance anomaly, one must quickly and accurately
detect and diagnose the performance anomalies that cause the failures. However,
it is difficult to identify anomalies in the dynamic and noisy data collected
by OpenMP multi-threaded monitoring infrastructures. This paper presents a
novel machine learning framework for performance anomaly in OpenMP
multi-threaded systems. To evaluate our framework, the NAS Parallel NPB
benchmark, EPCC OpenMP micro-benchmark suite, and Jacobi benchmark are used to
test the performance of our framework proposed. The experimental results
demonstrate that our framework successfully identifies 90.3\% of injected
anomalies of OpenMP multi-threaded applications.
</p>
<a href="http://arxiv.org/abs/2011.02914" target="_blank">arXiv:2011.02914</a> [<a href="http://arxiv.org/pdf/2011.02914" target="_blank">pdf</a>]

<h2>Domain-independent generation and classification of behavior traces. (arXiv:2011.02918v1 [cs.AI])</h2>
<h3>Daniel Borrajo, Manuela Veloso</h3>
<p>Financial institutions mostly deal with people. Therefore, characterizing
different kinds of human behavior can greatly help institutions for improving
their relation with customers and with regulatory offices. In many of such
interactions, humans have some internal goals, and execute some actions within
the financial system that lead them to achieve their goals. In this paper, we
tackle these tasks as a behavior-traces classification task. An observer agent
tries to learn characterizing other agents by observing their behavior when
taking actions in a given environment. The other agents can be of several types
and the goal of the observer is to identify the type of the other agent given a
trace of observations. We present CABBOT, a learning technique that allows the
agent to perform on-line classification of the type of planning agent whose
behavior is observing. In this work, the observer agent has partial and noisy
observability of the environment (state and actions of the other agents). In
order to evaluate the performance of the learning technique, we have generated
a domain-independent goal-based simulator of agents. We present experiments in
several (both financial and non-financial) domains with promising results.
</p>
<a href="http://arxiv.org/abs/2011.02918" target="_blank">arXiv:2011.02918</a> [<a href="http://arxiv.org/pdf/2011.02918" target="_blank">pdf</a>]

<h2>Asynchronous Deep Model Reference Adaptive Control. (arXiv:2011.02920v1 [cs.RO])</h2>
<h3>Girish Joshi, Jasvir Virdi, Girish Chowdhary</h3>
<p>In this paper, we present Asynchronous implementation of Deep Neural
Network-based Model Reference Adaptive Control (DMRAC). We evaluate this new
neuro-adaptive control architecture through flight tests on a small quadcopter.
We demonstrate that a single DMRAC controller can handle significant
nonlinearities due to severe system faults and deliberate wind disturbances
while executing high-bandwidth attitude control. We also show that the
architecture has long-term learning abilities across different flight regimes,
and can generalize to fly different flight trajectories than those on which it
was trained. These results demonstrating the efficacy of this architecture for
high bandwidth closed-loop attitude control of unstable and nonlinear robots
operating in adverse situations. To achieve these results, we designed a
software+communication architecture to ensure online real-time inference of the
deep network on a high-bandwidth computation-limited platform. We expect that
this architecture will benefit other deep learning in the closed-loop
experiments on robots.
</p>
<a href="http://arxiv.org/abs/2011.02920" target="_blank">arXiv:2011.02920</a> [<a href="http://arxiv.org/pdf/2011.02920" target="_blank">pdf</a>]

<h2>Paralinguistic Privacy Protection at the Edge. (arXiv:2011.02930v1 [cs.CL])</h2>
<h3>Ranya Aloufi, Hamed Haddadi, David Boyle</h3>
<p>Voice user interfaces and digital assistants are rapidly entering our homes
and becoming integrated with all our devices. These always-on services capture
and transmit our audio data to powerful cloud services for further processing
and subsequent actions. Our voices and raw audio signals collected through
these devices contain a host of sensitive paralinguistic information that is
transmitted to service providers regardless of deliberate or false triggers. As
sensitive attributes like our identity, gender, indicators of mental health
status, alongside moods, emotions and their temporal patterns, are easily
inferred using deep acoustic models, we encounter a new generation of privacy
risks by using these services. One approach to mitigate the risk of
paralinguistic-based privacy breaches is to exploit a combination of
cloud-based processing with privacy-preserving on-device paralinguistic
information filtering prior to transmitting voice data.

In this paper we introduce EDGY, a new lightweight disentangled
representation learning model that transforms and filters high-dimensional
voice data to remove sensitive attributes at the edge prior to offloading to
the cloud. We evaluate EDGY's on-device performance, and explore optimization
techniques, including model pruning and quantization, to enable private,
accurate and efficient representation learning on resource-constrained devices.
Our experimental results show that EDGY runs in tens of milliseconds with
minimal performance penalties or accuracy losses in speech recognition using
only a CPU and a single core ARM device without specialized hardware.
</p>
<a href="http://arxiv.org/abs/2011.02930" target="_blank">arXiv:2011.02930</a> [<a href="http://arxiv.org/pdf/2011.02930" target="_blank">pdf</a>]

<h2>Learning Efficient Task-Specific Meta-Embeddings with Word Prisms. (arXiv:2011.02944v1 [cs.CL])</h2>
<h3>Jingyi He, KC Tsiolis, Kian Kenyon-Dean, Jackie Chi Kit Cheung</h3>
<p>Word embeddings are trained to predict word cooccurrence statistics, which
leads them to possess different lexical properties (syntactic, semantic, etc.)
depending on the notion of context defined at training time. These properties
manifest when querying the embedding space for the most similar vectors, and
when used at the input layer of deep neural networks trained to solve
downstream NLP problems. Meta-embeddings combine multiple sets of differently
trained word embeddings, and have been shown to successfully improve intrinsic
and extrinsic performance over equivalent models which use just one set of
source embeddings. We introduce word prisms: a simple and efficient
meta-embedding method that learns to combine source embeddings according to the
task at hand. Word prisms learn orthogonal transformations to linearly combine
the input source embeddings, which allows them to be very efficient at
inference time. We evaluate word prisms in comparison to other meta-embedding
methods on six extrinsic evaluations and observe that word prisms offer
improvements in performance on all tasks.
</p>
<a href="http://arxiv.org/abs/2011.02944" target="_blank">arXiv:2011.02944</a> [<a href="http://arxiv.org/pdf/2011.02944" target="_blank">pdf</a>]

<h2>CODER: Knowledge infused cross-lingual medical term embedding for term normalization. (arXiv:2011.02947v1 [cs.CL])</h2>
<h3>Zheng Yuan, Zhengyun Zhao, Sheng Yu</h3>
<p>We propose a novel medical term embedding method named CODER, which stands
for mediCal knOwledge embeDded tErm Representation. CODER is designed for
medical term normalization by providing close vector representations for terms
that represent the same or similar concepts with multi-language support. CODER
is trained on top of BERT (Devlin et al., 2018) with the innovation that token
vector aggregation is trained using relations from the UMLS Metathesaurus
(Bodenreider, 2004), which is a comprehensive medical knowledge graph with
multi-language support. Training with relations injects medical knowledge into
term embeddings and aims to provide better normalization performances and
potentially better machine learning features. We evaluated CODER in term
normalization, semantic similarity, and relation classification benchmarks,
which showed that CODER outperformed various state-of-the-art biomedical word
embeddings, concept embeddings, and contextual embeddings.
</p>
<a href="http://arxiv.org/abs/2011.02947" target="_blank">arXiv:2011.02947</a> [<a href="http://arxiv.org/pdf/2011.02947" target="_blank">pdf</a>]

<h2>Anomalous Sound Detection as a Simple Binary Classification Problem with Careful Selection of Proxy Outlier Examples. (arXiv:2011.02949v1 [eess.AS])</h2>
<h3>Paul Primus, Verena Haunschmid, Patrick Praher, Gerhard Widmer</h3>
<p>Unsupervised anomalous sound detection is concerned with identifying sounds
that deviate from what is defined as 'normal', without explicitly specifying
the types of anomalies. A significant obstacle is the diversity and rareness of
outliers, which typically prevent us from collecting a representative set of
anomalous sounds. As a consequence, most anomaly detection methods use
unsupervised rather than supervised machine learning methods. Nevertheless, we
will show that anomalous sound detection can be effectively framed as a
supervised classification problem if the set of anomalous samples is carefully
substituted with what we call proxy outliers. Candidates for proxy outliers are
available in abundance as they potentially include all recordings that are
neither normal nor abnormal sounds. We experiment with the machine condition
monitoring data set of the 2020's DCASE Challenge and find proxy outliers with
matching recording conditions and high similarity to the target sounds
particularly informative. If no data with similar sounds and matching recording
conditions is available, data sets with a larger diversity in these two
dimensions are preferable. Our models based on supervised training with proxy
outliers achieved rank three in Task 2 of the DCASE2020 Challenge.
</p>
<a href="http://arxiv.org/abs/2011.02949" target="_blank">arXiv:2011.02949</a> [<a href="http://arxiv.org/pdf/2011.02949" target="_blank">pdf</a>]

<h2>Generalized Negative Correlation Learning for Deep Ensembling. (arXiv:2011.02952v1 [cs.LG])</h2>
<h3>Sebastian Buschj&#xe4;ger, Lukas Pfahler, Katharina Morik</h3>
<p>Ensemble algorithms offer state of the art performance in many machine
learning applications. A common explanation for their excellent performance is
due to the bias-variance decomposition of the mean squared error which shows
that the algorithm's error can be decomposed into its bias and variance. Both
quantities are often opposed to each other and ensembles offer an effective way
to manage them as they reduce the variance through a diverse set of base
learners while keeping the bias low at the same time. Even though there have
been numerous works on decomposing other loss functions, the exact mathematical
connection is rarely exploited explicitly for ensembling, but merely used as a
guiding principle. In this paper, we formulate a generalized bias-variance
decomposition for arbitrary twice differentiable loss functions and study it in
the context of Deep Learning. We use this decomposition to derive a Generalized
Negative Correlation Learning (GNCL) algorithm which offers explicit control
over the ensemble's diversity and smoothly interpolates between the two
extremes of independent training and the joint training of the ensemble. We
show how GNCL encapsulates many previous works and discuss under which
circumstances training of an ensemble of Neural Networks might fail and what
ensembling method should be favored depending on the choice of the individual
networks.
</p>
<a href="http://arxiv.org/abs/2011.02952" target="_blank">arXiv:2011.02952</a> [<a href="http://arxiv.org/pdf/2011.02952" target="_blank">pdf</a>]

<h2>Low-Complexity Models for Acoustic Scene Classification Based on Receptive Field Regularization and Frequency Damping. (arXiv:2011.02955v1 [cs.LG])</h2>
<h3>Khaled Koutini, Florian Henkel, Hamid Eghbal-zadeh, Gerhard Widmer</h3>
<p>Deep Neural Networks are known to be very demanding in terms of computing and
memory requirements. Due to the ever increasing use of embedded systems and
mobile devices with a limited resource budget, designing low-complexity models
without sacrificing too much of their predictive performance gained great
importance. In this work, we investigate and compare several well-known methods
to reduce the number of parameters in neural networks. We further put these
into the context of a recent study on the effect of the Receptive Field (RF) on
a model's performance, and empirically show that we can achieve high-performing
low-complexity models by applying specific restrictions on the RFs, in
combination with parameter reduction methods. Additionally, we propose a
filter-damping technique for regularizing the RF of models, without altering
their architecture and changing their parameter counts. We will show that
incorporating this technique improves the performance in various low-complexity
settings such as pruning and decomposed convolution. Using our proposed filter
damping, we achieved the 1st rank at the DCASE-2020 Challenge in the task of
Low-Complexity Acoustic Scene Classification.
</p>
<a href="http://arxiv.org/abs/2011.02955" target="_blank">arXiv:2011.02955</a> [<a href="http://arxiv.org/pdf/2011.02955" target="_blank">pdf</a>]

<h2>Conflicting Bundles: Adapting Architectures Towards the Improved Training of Deep Neural Networks. (arXiv:2011.02956v1 [cs.LG])</h2>
<h3>David Peer, Sebastian Stabinger, Antonio Rodriguez-Sanchez</h3>
<p>Designing neural network architectures is a challenging task and knowing
which specific layers of a model must be adapted to improve the performance is
almost a mystery. In this paper, we introduce a novel theory and metric to
identify layers that decrease the test accuracy of the trained models, this
identification is done as early as at the beginning of training. In the
worst-case, such a layer could lead to a network that can not be trained at
all. More precisely, we identified those layers that worsen the performance
because they produce conflicting training bundles as we show in our novel
theoretical analysis, complemented by our extensive empirical studies. Based on
these findings, a novel algorithm is introduced to remove performance
decreasing layers automatically. Architectures found by this algorithm achieve
a competitive accuracy when compared against the state-of-the-art
architectures. While keeping such high accuracy, our approach drastically
reduces memory consumption and inference time for different computer vision
tasks.
</p>
<a href="http://arxiv.org/abs/2011.02956" target="_blank">arXiv:2011.02956</a> [<a href="http://arxiv.org/pdf/2011.02956" target="_blank">pdf</a>]

<h2>Measuring Data Collection Quality for Community Healthcare. (arXiv:2011.02962v1 [cs.LG])</h2>
<h3>Ramesha Karunasena (1), Mohammad Sarparajul Ambiya (2), Arunesh Sinha (1), Ruchit Nagar (2), Saachi Dalal (2), Divy Thakkar (3), Milind Tambe (3) ((1) Singapore Management University, (2) Khushi Baby, India, (3) Google Research, India)</h3>
<p>Machine learning has tremendous potential to provide targeted interventions
in low-resource communities, however the availability of high-quality public
health data is a significant challenge. In this work, we partner with field
experts at an non-governmental organization (NGO) in India to define and test a
data collection quality score for each health worker who collects data. This
challenging unlabeled data problem is handled by building upon domain-expert's
guidance to design a useful data representation that is then clustered to infer
a data quality score. We also provide a more interpretable version of the
score. These scores already provide for a measurement of data collection
quality; in addition, we also predict the quality for future time steps and
find our results to be very accurate. Our work was successfully field tested
and is in the final stages of deployment in Rajasthan, India.
</p>
<a href="http://arxiv.org/abs/2011.02962" target="_blank">arXiv:2011.02962</a> [<a href="http://arxiv.org/pdf/2011.02962" target="_blank">pdf</a>]

<h2>CPR: Understanding and Improving Failure Tolerant Training for Deep Learning Recommendation with Partial Recovery. (arXiv:2011.02999v1 [cs.LG])</h2>
<h3>Kiwan Maeng, Shivam Bharuka, Isabel Gao, Mark C. Jeffrey, Vikram Saraph, Bor-Yiing Su, Caroline Trippel, Jiyan Yang, Mike Rabbat, Brandon Lucia, Carole-Jean Wu</h3>
<p>The paper proposes and optimizes a partial recovery training system, CPR, for
recommendation models. CPR relaxes the consistency requirement by enabling
non-failed nodes to proceed without loading checkpoints when a node fails
during training, improving failure-related overheads. The paper is the first to
the extent of our knowledge to perform a data-driven, in-depth analysis of
applying partial recovery to recommendation models and identified a trade-off
between accuracy and performance. Motivated by the analysis, we present CPR, a
partial recovery training system that can reduce the training time and maintain
the desired level of model accuracy by (1) estimating the benefit of partial
recovery, (2) selecting an appropriate checkpoint saving interval, and (3)
prioritizing to save updates of more frequently accessed parameters. Two
variants of CPR, CPR-MFU and CPR-SSU, reduce the checkpoint-related overhead
from 8.2-8.5% to 0.53-0.68% compared to full recovery, on a configuration
emulating the failure pattern and overhead of a production-scale cluster. While
reducing overhead significantly, CPR achieves model quality on par with the
more expensive full recovery scheme, training the state-of-the-art
recommendation model using Criteo's Ads CTR dataset. Our preliminary results
also suggest that CPR can speed up training on a real production-scale cluster,
without notably degrading the accuracy.
</p>
<a href="http://arxiv.org/abs/2011.02999" target="_blank">arXiv:2011.02999</a> [<a href="http://arxiv.org/pdf/2011.02999" target="_blank">pdf</a>]

<h2>Deep-Dup: An Adversarial Weight Duplication Attack Framework to Crush Deep Neural Network in Multi-Tenant FPGA. (arXiv:2011.03006v1 [cs.CR])</h2>
<h3>Adnan Siraj Rakin, Yukui Luo, Xiaolin Xu, Deliang Fan</h3>
<p>The wide deployment of Deep Neural Networks (DNN) in high-performance cloud
computing platforms has emerged field-programmable gate arrays (FPGA) as a
popular choice of accelerator to boost performance due to its hardware
reprogramming flexibility. To improve the efficiency of hardware resource
utilization, growing efforts have been invested in FPGA virtualization,
enabling the co-existence of multiple independent tenants in a shared FPGA
chip. Such a multi-tenant FPGA setup for DNN acceleration potentially exposes
the DNN interference task under severe threat from malicious users. This work,
to the best of our knowledge, is the first to explore DNN model vulnerabilities
in multi-tenant FPGAs. We propose a novel adversarial attack framework:
Deep-Dup, in which the adversarial tenant can inject faults to the DNN model of
victim tenant in FPGA. Specifically, she can aggressively overload the shared
power distribution system of FPGA with malicious power-plundering circuits,
achieving adversarial weight duplication (AWD) hardware attack that duplicates
certain DNN weight packages during data transmission between off-chip memory
and on-chip buffer, with the objective to hijack DNN function of the victim
tenant. Further, to identify the most vulnerable DNN weight packages for a
given malicious objective, we propose a generic vulnerable weight package
searching algorithm, called Progressive Differential Evolution Search (P-DES),
which is, for the first time, adaptive to both deep learning white-box and
black-box attack models. Unlike prior works only working in a deep learning
white-box setup, our adaptiveness mainly comes from the fact that the proposed
P-DES does not require any gradient information of DNN model.
</p>
<a href="http://arxiv.org/abs/2011.03006" target="_blank">arXiv:2011.03006</a> [<a href="http://arxiv.org/pdf/2011.03006" target="_blank">pdf</a>]

<h2>Data Augmentation via Structured Adversarial Perturbations. (arXiv:2011.03010v1 [cs.LG])</h2>
<h3>Calvin Luo, Hossein Mobahi, Samy Bengio</h3>
<p>Data augmentation is a major component of many machine learning methods with
state-of-the-art performance. Common augmentation strategies work by drawing
random samples from a space of transformations. Unfortunately, such sampling
approaches are limited in expressivity, as they are unable to scale to rich
transformations that depend on numerous parameters due to the curse of
dimensionality. Adversarial examples can be considered as an alternative scheme
for data augmentation. By being trained on the most difficult modifications of
the inputs, the resulting models are then hopefully able to handle other,
presumably easier, modifications as well. The advantage of adversarial
augmentation is that it replaces sampling with the use of a single, calculated
perturbation that maximally increases the loss. The downside, however, is that
these raw adversarial perturbations appear rather unstructured; applying them
often does not produce a natural transformation, contrary to a desirable data
augmentation technique. To address this, we propose a method to generate
adversarial examples that maintain some desired natural structure. We first
construct a subspace that only contains perturbations with the desired
structure. We then project the raw adversarial gradient onto this space to
select a structured transformation that would maximally increase the loss when
applied. We demonstrate this approach through two types of image
transformations: photometric and geometric. Furthermore, we show that training
on such structured adversarial images improves generalization.
</p>
<a href="http://arxiv.org/abs/2011.03010" target="_blank">arXiv:2011.03010</a> [<a href="http://arxiv.org/pdf/2011.03010" target="_blank">pdf</a>]

<h2>MEGA RST Discourse Treebanks with Structure and Nuclearity from Scalable Distant Sentiment Supervision. (arXiv:2011.03017v1 [cs.CL])</h2>
<h3>Patrick Huber, Giuseppe Carenini</h3>
<p>The lack of large and diverse discourse treebanks hinders the application of
data-driven approaches, such as deep-learning, to RST-style discourse parsing.
In this work, we present a novel scalable methodology to automatically generate
discourse treebanks using distant supervision from sentiment-annotated
datasets, creating and publishing MEGA-DT, a new large-scale
discourse-annotated corpus. Our approach generates discourse trees
incorporating structure and nuclearity for documents of arbitrary length by
relying on an efficient heuristic beam-search strategy, extended with a
stochastic component. Experiments on multiple datasets indicate that a
discourse parser trained on our MEGA-DT treebank delivers promising
inter-domain performance gains when compared to parsers trained on
human-annotated discourse corpora.
</p>
<a href="http://arxiv.org/abs/2011.03017" target="_blank">arXiv:2011.03017</a> [<a href="http://arxiv.org/pdf/2011.03017" target="_blank">pdf</a>]

<h2>Quantifying Intimacy in Language. (arXiv:2011.03020v1 [cs.CL])</h2>
<h3>Jiaxin Pei, David Jurgens</h3>
<p>Intimacy is a fundamental aspect of how we relate to others in social
settings. Language encodes the social information of intimacy through both
topics and other more subtle cues (such as linguistic hedging and swearing).
Here, we introduce a new computational framework for studying expressions of
the intimacy in language with an accompanying dataset and deep learning model
for accurately predicting the intimacy level of questions (Pearson's r=0.87).
Through analyzing a dataset of 80.5M questions across social media, books, and
films, we show that individuals employ interpersonal pragmatic moves in their
language to align their intimacy with social settings. Then, in three studies,
we further demonstrate how individuals modulate their intimacy to match social
norms around gender, social distance, and audience, each validating key
findings from studies in social psychology. Our work demonstrates that intimacy
is a pervasive and impactful social dimension of language.
</p>
<a href="http://arxiv.org/abs/2011.03020" target="_blank">arXiv:2011.03020</a> [<a href="http://arxiv.org/pdf/2011.03020" target="_blank">pdf</a>]

<h2>Language Model is All You Need: Natural Language Understanding as Question Answering. (arXiv:2011.03023v1 [cs.CL])</h2>
<h3>Mahdi Namazifar, Alexandros Papangelis, Gokhan Tur, Dilek Hakkani-T&#xfc;r</h3>
<p>Different flavors of transfer learning have shown tremendous impact in
advancing research and applications of machine learning. In this work we study
the use of a specific family of transfer learning, where the target domain is
mapped to the source domain. Specifically we map Natural Language Understanding
(NLU) problems to QuestionAnswering (QA) problems and we show that in low data
regimes this approach offers significant improvements compared to other
approaches to NLU. Moreover we show that these gains could be increased through
sequential transfer learning across NLU problems from different domains. We
show that our approach could reduce the amount of required data for the same
performance by up to a factor of 10.
</p>
<a href="http://arxiv.org/abs/2011.03023" target="_blank">arXiv:2011.03023</a> [<a href="http://arxiv.org/pdf/2011.03023" target="_blank">pdf</a>]

<h2>Teaching with Commentaries. (arXiv:2011.03037v1 [cs.LG])</h2>
<h3>Aniruddh Raghu, Maithra Raghu, Simon Kornblith, David Duvenaud, Geoffrey Hinton</h3>
<p>Effective training of deep neural networks can be challenging, and there
remain many open questions on how to best learn these models. Recently
developed methods to improve neural network training examine teaching:
providing learned information during the training process to improve downstream
model performance. In this paper, we take steps towards extending the scope of
teaching. We propose a flexible teaching framework using commentaries,
meta-learned information helpful for training on a particular task or dataset.
We present an efficient and scalable gradient-based method to learn
commentaries, leveraging recent work on implicit differentiation. We explore
diverse applications of commentaries, from learning weights for individual
training examples, to parameterizing label-dependent data augmentation
policies, to representing attention masks that highlight salient image regions.
In these settings, we find that commentaries can improve training speed and/or
performance and also provide fundamental insights about the dataset and
training process.
</p>
<a href="http://arxiv.org/abs/2011.03037" target="_blank">arXiv:2011.03037</a> [<a href="http://arxiv.org/pdf/2011.03037" target="_blank">pdf</a>]

<h2>Training Transformers for Information Security Tasks: A Case Study on Malicious URL Prediction. (arXiv:2011.03040v1 [cs.CR])</h2>
<h3>Ethan M. Rudd, Ahmed Abdallah</h3>
<p>Machine Learning (ML) for information security (InfoSec) utilizes distinct
data types and formats which require different treatments during
optimization/training on raw data. In this paper, we implement a
malicious/benign URL predictor based on a transformer architecture that is
trained from scratch. We show that in contrast to conventional natural language
processing (NLP) transformers, this model requires a different training
approach to work well. Specifically, we show that 1) pre-training on a massive
corpus of unlabeled URL data for an auto-regressive task does not readily
transfer to malicious/benign prediction but 2) that using an auxiliary
auto-regressive loss improves performance when training from scratch. We
introduce a method for mixed objective optimization, which dynamically balances
contributions from both loss terms so that neither one of them dominates. We
show that this method yields performance comparable to that of several
top-performing benchmark classifiers.
</p>
<a href="http://arxiv.org/abs/2011.03040" target="_blank">arXiv:2011.03040</a> [<a href="http://arxiv.org/pdf/2011.03040" target="_blank">pdf</a>]

<h2>Nonlinear Approximation via Compositions. (arXiv:1902.10170v5 [cs.LG] UPDATED)</h2>
<h3>Zuowei Shen, Haizhao Yang, Shijun Zhang</h3>
<p>Given a function dictionary $\cal D$ and an approximation budget
$N\in\mathbb{N}^+$, nonlinear approximation seeks the linear combination of the
best $N$ terms $\{T_n\}_{1\le n\le N}\subseteq{\cal D}$ to approximate a given
function $f$ with the minimum approximation
error\[\varepsilon_{L,f}:=\min_{\{g_n\}\subseteq{\mathbb{R}},\{T_n\}\subseteq{\cal
D}}\|f(x)-\sum_{n=1}^N g_n T_n(x)\|.\]Motivated by recent success of deep
learning, we propose dictionaries with functions in a form of compositions,
i.e.,\[T(x)=T^{(L)}\circ T^{(L-1)}\circ\cdots\circ T^{(1)}(x)\]for all
$T\in\cal D$, and implement $T$ using ReLU feed-forward neural networks (FNNs)
with $L$ hidden layers. We further quantify the improvement of the best
$N$-term approximation rate in terms of $N$ when $L$ is increased from $1$ to
$2$ or $3$ to show the power of compositions. In the case when $L&gt;3$, our
analysis shows that increasing $L$ cannot improve the approximation rate in
terms of $N$.

In particular, for any function $f$ on $[0,1]$, regardless of its smoothness
and even the continuity, if $f$ can be approximated using a dictionary when
$L=1$ with the best $N$-term approximation rate $\varepsilon_{L,f}={\cal
O}(N^{-\eta})$, we show that dictionaries with $L=2$ can improve the best
$N$-term approximation rate to $\varepsilon_{L,f}={\cal O}(N^{-2\eta})$. We
also show that for H\"older continuous functions of order $\alpha$ on
$[0,1]^d$, the application of a dictionary with $L=3$ in nonlinear
approximation can achieve an essentially tight best $N$-term approximation rate
$\varepsilon_{L,f}={\cal O}(N^{-2\alpha/d})$. Finally, we show that
dictionaries consisting of wide FNNs with a few hidden layers are more
attractive in terms of computational efficiency than dictionaries with narrow
and very deep FNNs for approximating H\"older continuous functions if the
number of computer cores is larger than $N$ in parallel computing.
</p>
<a href="http://arxiv.org/abs/1902.10170" target="_blank">arXiv:1902.10170</a> [<a href="http://arxiv.org/pdf/1902.10170" target="_blank">pdf</a>]

<h2>Unsupervised Data Augmentation for Consistency Training. (arXiv:1904.12848v6 [cs.LG] UPDATED)</h2>
<h3>Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, Quoc V. Le</h3>
<p>Semi-supervised learning lately has shown much promise in improving deep
learning models when labeled data is scarce. Common among recent approaches is
the use of consistency training on a large amount of unlabeled data to
constrain model predictions to be invariant to input noise. In this work, we
present a new perspective on how to effectively noise unlabeled examples and
argue that the quality of noising, specifically those produced by advanced data
augmentation methods, plays a crucial role in semi-supervised learning. By
substituting simple noising operations with advanced data augmentation methods
such as RandAugment and back-translation, our method brings substantial
improvements across six language and three vision tasks under the same
consistency training framework. On the IMDb text classification dataset, with
only 20 labeled examples, our method achieves an error rate of 4.20,
outperforming the state-of-the-art model trained on 25,000 labeled examples. On
a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms
all previous approaches and achieves an error rate of 5.43 with only 250
examples. Our method also combines well with transfer learning, e.g., when
finetuning from BERT, and yields improvements in high-data regime, such as
ImageNet, whether when there is only 10% labeled data or when a full labeled
set with 1.3M extra unlabeled examples is used. Code is available at
https://github.com/google-research/uda.
</p>
<a href="http://arxiv.org/abs/1904.12848" target="_blank">arXiv:1904.12848</a> [<a href="http://arxiv.org/pdf/1904.12848" target="_blank">pdf</a>]

<h2>Interpretable and Personalized Apprenticeship Scheduling: Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations. (arXiv:1906.06397v4 [cs.LG] UPDATED)</h2>
<h3>Rohan Paleja, Andrew Silva, Letian Chen, Matthew Gombolay</h3>
<p>Resource scheduling and coordination is an NP-hard optimization requiring an
efficient allocation of agents to a set of tasks with upper- and lower bound
temporal and resource constraints. Due to the large-scale and dynamic nature of
resource coordination in hospitals and factories, human domain experts manually
plan and adjust schedules on the fly. To perform this job, domain experts
leverage heterogeneous strategies and rules-of-thumb honed over years of
apprenticeship. What is critically needed is the ability to extract this domain
knowledge in a heterogeneous and interpretable apprenticeship learning
framework to scale beyond the power of a single human expert, a necessity in
safety-critical domains. We propose a personalized and interpretable
apprenticeship scheduling algorithm that infers an interpretable representation
of all human task demonstrators by extracting decision-making criteria via an
inferred, personalized embedding non-parametric in the number of demonstrator
types. We achieve near-perfect LfD accuracy in synthetic domains and 88.22\%
accuracy on a planning domain with real-world, outperforming baselines.
Finally, our user study showed our methodology produces more interpretable and
easier-to-use models than neural networks ($p &lt; 0.05$).
</p>
<a href="http://arxiv.org/abs/1906.06397" target="_blank">arXiv:1906.06397</a> [<a href="http://arxiv.org/pdf/1906.06397" target="_blank">pdf</a>]

<h2>Distributed Learning of Deep Neural Networks using Independent Subnet Training. (arXiv:1910.02120v5 [cs.LG] UPDATED)</h2>
<h3>Binhang Yuan, Cameron R. Wolfe, Chen Dun, Yuxin Tang, Anastasios Kyrillidis, Christopher M. Jermaine</h3>
<p>Distributed machine learning (ML) can bring more computational resources to
bear than single-machine learning, reducing training time. Further,
distribution allows models to be partitioned over many machines, allowing very
large models to be trained -- models that may be much larger than the available
memory of any individual machine. However, in practice, distributed ML remains
challenging, primarily due to high communication costs. We propose a new
approach to distributed neural network learning, called independent subnet
training (IST). In IST, a neural network is decomposed into a set of
subnetworks of the same depth as the original network, each of which is trained
locally, before the various subnets are exchanged and the process is repeated.
IST training has many advantages over standard data parallel approaches.
Because the subsets are independent, communication frequency is reduced.
Because the original network is decomposed into independent parts,
communication volume is reduced. Further, the decomposition makes IST naturally
model parallel, and so IST scales to very large models that cannot fit on any
single machine. We show experimentally that IST results in training time that
are much lower than data parallel approaches to distributed learning, and that
it scales to large models that cannot be learned using standard approaches.
</p>
<a href="http://arxiv.org/abs/1910.02120" target="_blank">arXiv:1910.02120</a> [<a href="http://arxiv.org/pdf/1910.02120" target="_blank">pdf</a>]

<h2>Multiplierless and Sparse Machine Learning based on Margin Propagation Networks. (arXiv:1910.02304v2 [cs.LG] UPDATED)</h2>
<h3>Nazreen P.M., Shantanu Chakrabartty, Chetan Singh Thakur</h3>
<p>The new generation of machine learning processors have evolved from
multi-core and parallel architectures that were designed to efficiently
implement matrix-vector-multiplications (MVMs). This is because at the
fundamental level, neural network and machine learning operations extensively
use MVM operations and hardware compilers exploit the inherent parallelism in
MVM operations to achieve hardware acceleration on GPUs and FPGAs. However,
many IoT and edge computing platforms require embedded ML devices close to the
network in order to compensate for communication cost and latency. Hence a
natural question to ask is whether MVM operations are even necessary to
implement ML algorithms and whether simpler hardware primitives can be used to
implement an ultra-energy-efficient ML processor/architecture. In this paper we
propose an alternate hardware-software codesign of ML and neural network
architectures where instead of using MVM operations and non-linear activation
functions, the architecture only uses simple addition and thresholding
operations to implement inference and learning. At the core of the proposed
approach is margin-propagation (MP) based computation that maps multiplications
into additions and additions into a dynamic rectifying-linear-unit (ReLU)
operations. This mapping results in significant improvement in computational
and hence energy cost. In this paper, we show how the MP network formulation
can be applied for designing linear classifiers, shallow multi-layer
perceptrons and support vector networks suitable fot IoT platforms and tiny ML
applications. We show that these MP based classifiers give comparable results
to that of their traditional counterparts for benchmark UCI datasets, with the
added advantage of reduction in computational complexity enabling an
improvement in energy efficiency.
</p>
<a href="http://arxiv.org/abs/1910.02304" target="_blank">arXiv:1910.02304</a> [<a href="http://arxiv.org/pdf/1910.02304" target="_blank">pdf</a>]

<h2>GraphAIR: Graph Representation Learning with Neighborhood Aggregation and Interaction. (arXiv:1911.01731v3 [cs.LG] UPDATED)</h2>
<h3>Fenyu Hu, Yanqiao Zhu, Shu Wu, Weiran Huang, Liang Wang, Tieniu Tan</h3>
<p>Graph representation learning is of paramount importance for a variety of
graph analytical tasks, ranging from node classification to community
detection. Recently, graph convolutional networks (GCNs) have been successfully
applied for graph representation learning. These GCNs generate node
representation by aggregating features from the neighborhoods, which follows
the "neighborhood aggregation" scheme. In spite of having achieved promising
performance on various tasks, existing GCN-based models have difficulty in well
capturing complicated non-linearity of graph data. In this paper, we first
theoretically prove that coefficients of the neighborhood interacting terms are
relatively small in current models, which explains why GCNs barely outperforms
linear models. Then, in order to better capture the complicated non-linearity
of graph data, we present a novel GraphAIR framework which models the
neighborhood interaction in addition to neighborhood aggregation. Comprehensive
experiments conducted on benchmark tasks including node classification and link
prediction using public datasets demonstrate the effectiveness of the proposed
method.
</p>
<a href="http://arxiv.org/abs/1911.01731" target="_blank">arXiv:1911.01731</a> [<a href="http://arxiv.org/pdf/1911.01731" target="_blank">pdf</a>]

<h2>Post-Comparison Mitigation of Demographic Bias in Face Recognition Using Fair Score Normalization. (arXiv:2002.03592v3 [cs.CV] UPDATED)</h2>
<h3>Philipp Terh&#xf6;rst, Jan Niklas Kolf, Naser Damer, Florian Kirchbuchner, Arjan Kuijper</h3>
<p>Current face recognition systems achieve high progress on several benchmark
tests. Despite this progress, recent works showed that these systems are
strongly biased against demographic sub-groups. Consequently, an easily
integrable solution is needed to reduce the discriminatory effect of these
biased systems. Previous work mainly focused on learning less biased face
representations, which comes at the cost of a strongly degraded overall
recognition performance. In this work, we propose a novel unsupervised fair
score normalization approach that is specifically designed to reduce the effect
of bias in face recognition and subsequently lead to a significant overall
performance boost. Our hypothesis is built on the notation of individual
fairness by designing a normalization approach that leads to treating similar
individuals similarly. Experiments were conducted on three publicly available
datasets captured under controlled and in-the-wild circumstances. Results
demonstrate that our solution reduces demographic biases, e.g. by up to 82.7%
in the case when gender is considered. Moreover, it mitigates the bias more
consistently than existing works. In contrast to previous works, our fair
normalization approach enhances the overall performance by up to 53.2% at false
match rate of 0.001 and up to 82.9% at a false match rate of 0.00001.
Additionally, it is easily integrable into existing recognition systems and not
limited to face biometrics.
</p>
<a href="http://arxiv.org/abs/2002.03592" target="_blank">arXiv:2002.03592</a> [<a href="http://arxiv.org/pdf/2002.03592" target="_blank">pdf</a>]

<h2>Instant recovery of shape from spectrum via latent space connections. (arXiv:2003.06523v4 [cs.CV] UPDATED)</h2>
<h3>Riccardo Marin, Arianna Rampini, Umberto Castellani, Emanuele Rodol&#xe0;, Maks Ovsjanikov, Simone Melzi</h3>
<p>We introduce the first learning-based method for recovering shapes from
Laplacian spectra. Given an auto-encoder, our model takes the form of a
cycle-consistent module to map latent vectors to sequences of eigenvalues. This
module provides an efficient and effective linkage between spectrum and
geometry of a given shape. Our data-driven approach replaces the need for
ad-hoc regularizers required by prior methods, while providing more accurate
results at a fraction of the computational cost. Our learning model applies
without modifications across different dimensions (2D and 3D shapes alike),
representations (meshes, contours and point clouds), as well as across
different shape classes, and admits arbitrary resolution of the input spectrum
without affecting complexity. The increased flexibility allows us to provide a
proxy to differentiable eigendecomposition and to address notoriously difficult
tasks in 3D vision and geometry processing within a unified framework,
including shape generation from spectrum, mesh super-resolution, shape
exploration, style transfer, spectrum estimation from point clouds,
segmentation transfer and point-to-point matching.
</p>
<a href="http://arxiv.org/abs/2003.06523" target="_blank">arXiv:2003.06523</a> [<a href="http://arxiv.org/pdf/2003.06523" target="_blank">pdf</a>]

<h2>Inferring the Material Properties of Granular Media for Robotic Tasks. (arXiv:2003.08032v4 [cs.RO] UPDATED)</h2>
<h3>Carolyn Matl, Yashraj Narang, Ruzena Bajcsy, Fabio Ramos, Dieter Fox</h3>
<p>Granular media (e.g., cereal grains, plastic resin pellets, and pills) are
ubiquitous in robotics-integrated industries, such as agriculture,
manufacturing, and pharmaceutical development. This prevalence mandates the
accurate and efficient simulation of these materials. This work presents a
software and hardware framework that automatically calibrates a fast physics
simulator to accurately simulate granular materials by inferring material
properties from real-world depth images of granular formations (i.e., piles and
rings). Specifically, coefficients of sliding friction, rolling friction, and
restitution of grains are estimated from summary statistics of grain formations
using likelihood-free Bayesian inference. The calibrated simulator accurately
predicts unseen granular formations in both simulation and experiment;
furthermore, simulator predictions are shown to generalize to more complex
tasks, including using a robot to pour grains into a bowl, as well as to create
a desired pattern of piles and rings. Visualizations of the framework and
experiments can be viewed at https://youtu.be/OBvV5h2NMKA
</p>
<a href="http://arxiv.org/abs/2003.08032" target="_blank">arXiv:2003.08032</a> [<a href="http://arxiv.org/pdf/2003.08032" target="_blank">pdf</a>]

<h2>Accelerating Deep Reinforcement Learning With the Aid of Partial Model: Energy-Efficient Predictive Video Streaming. (arXiv:2003.09708v2 [cs.LG] UPDATED)</h2>
<h3>Dong Liu, Jianyu Zhao, Chenyang Yang, Lajos Hanzo</h3>
<p>Predictive power allocation is conceived for energy-efficient video streaming
over mobile networks using deep reinforcement learning. The goal is to minimize
the accumulated energy consumption of each base station over a complete video
streaming session under the constraint that avoids video playback
interruptions. To handle the continuous state and action spaces, we resort to
deep deterministic policy gradient (DDPG) algorithm for solving the formulated
problem. In contrast to previous predictive power allocation policies that
first predict future information with historical data and then optimize the
power allocation based on the predicted information, the proposed policy
operates in an on-line and end-to-end manner. By judiciously designing the
action and state that only depend on slowly-varying average channel gains, we
reduce the signaling overhead between the edge server and the base stations,
and make it easier to learn a good policy. To further avoid playback
interruption throughout the learning process and improve the convergence speed,
we exploit the partially known model of the system dynamics by integrating the
concepts of safety layer, post-decision state, and virtual experiences into the
basic DDPG algorithm. Our simulation results show that the proposed policies
converge to the optimal policy that is derived based on perfect large-scale
channel prediction and outperform the first-predict-then-optimize policy in the
presence of prediction errors. By harnessing the partially known model, the
convergence speed can be dramatically improved.
</p>
<a href="http://arxiv.org/abs/2003.09708" target="_blank">arXiv:2003.09708</a> [<a href="http://arxiv.org/pdf/2003.09708" target="_blank">pdf</a>]

<h2>A Time-domain Monaural Speech Enhancement with Feedback Learning. (arXiv:2003.09815v3 [cs.SD] UPDATED)</h2>
<h3>Andong Li, Chengshi Zheng, Linjuan Cheng, Renhua Peng, Xiaodong Li</h3>
<p>In this paper, we propose a type of neural network with feedback learning in
the time domain called FTNet for monaural speech enhancement, where the
proposed network consists of three principal components. The first part is
called stage recurrent neural network, which is introduced to effectively
aggregate the deep feature dependencies across different stages with a memory
mechanism and also remove the interference stage by stage. The second part is
the convolutional auto-encoder. The third part consists of a series of
concatenated gated linear units, which are capable of facilitating the
information flow and gradually increasing the receptive fields. Feedback
learning is adopted to improve the parameter efficiency and therefore, the
number of trainable parameters is effectively reduced without sacrificing its
performance. Numerous experiments are conducted on TIMIT corpus and
experimental results demonstrate that the proposed network can achieve
consistently better performance in terms of both PESQ and STOI scores than two
state-of-the-art time domain-based baselines in different conditions.
</p>
<a href="http://arxiv.org/abs/2003.09815" target="_blank">arXiv:2003.09815</a> [<a href="http://arxiv.org/pdf/2003.09815" target="_blank">pdf</a>]

<h2>Reinforcement Learning with Augmented Data. (arXiv:2004.14990v5 [cs.LG] UPDATED)</h2>
<h3>Michael Laskin, Kimin Lee, Adam Stooke, Lerrel Pinto, Pieter Abbeel, Aravind Srinivas</h3>
<p>Learning from visual observations is a fundamental yet challenging problem in
Reinforcement Learning (RL). Although algorithmic advances combined with
convolutional neural networks have proved to be a recipe for success, current
methods are still lacking on two fronts: (a) data-efficiency of learning and
(b) generalization to new environments. To this end, we present Reinforcement
Learning with Augmented Data (RAD), a simple plug-and-play module that can
enhance most RL algorithms. We perform the first extensive study of general
data augmentations for RL on both pixel-based and state-based inputs, and
introduce two new data augmentations - random translate and random amplitude
scale. We show that augmentations such as random translate, crop, color jitter,
patch cutout, random convolutions, and amplitude scale can enable simple RL
algorithms to outperform complex state-of-the-art methods across common
benchmarks. RAD sets a new state-of-the-art in terms of data-efficiency and
final performance on the DeepMind Control Suite benchmark for pixel-based
control as well as OpenAI Gym benchmark for state-based control. We further
demonstrate that RAD significantly improves test-time generalization over
existing methods on several OpenAI ProcGen benchmarks. Our RAD module and
training code are available at https://www.github.com/MishaLaskin/rad.
</p>
<a href="http://arxiv.org/abs/2004.14990" target="_blank">arXiv:2004.14990</a> [<a href="http://arxiv.org/pdf/2004.14990" target="_blank">pdf</a>]

<h2>Robotics Meets Cosmetic Dermatology: Development of a Novel Vision-Guided System for Skin Photo-Rejuvenation. (arXiv:2005.10462v3 [cs.RO] UPDATED)</h2>
<h3>Muhammad Muddassir, Domingo Gomez, Shujian Chen, Luyin Hu, David Navarro-Alarcon</h3>
<p>In this paper, we present a novel robotic system for skin photo-rejuvenation
procedures, which can uniformly deliver the laser's energy over the skin of the
face. The robotised procedure is performed by a manipulator whose end-effector
is instrumented with a depth sensor, a thermal camera, and a cosmetic laser
generator. To plan the heat stimulating trajectories for the laser, the system
computes the surface model of the face and segments it into seven regions that
are automatically filled with laser shots. We report experimental results with
human subjects to validate the performance of the system. To the best of the
author's knowledge, this is the first time that facial skin rejuvenation has
been automated by robot manipulators.
</p>
<a href="http://arxiv.org/abs/2005.10462" target="_blank">arXiv:2005.10462</a> [<a href="http://arxiv.org/pdf/2005.10462" target="_blank">pdf</a>]

<h2>Hyperparameter optimization with REINFORCE and Transformers. (arXiv:2006.00939v4 [cs.LG] UPDATED)</h2>
<h3>Chepuri Shri Krishna, Ashish Gupta, Swarnim Narayan, Himanshu Rai, Diksha Manchanda</h3>
<p>Reinforcement Learning has yielded promising results for Neural Architecture
Search (NAS). In this paper, we demonstrate how its performance can be improved
by using a simplified Transformer block to model the policy network. The
simplified Transformer uses a 2-stream attention-based mechanism to model
hyper-parameter dependencies while avoiding layer normalization and position
encoding. We posit that this parsimonious design balances model complexity
against expressiveness, making it suitable for discovering optimal
architectures in high-dimensional search spaces with limited exploration
budgets. We demonstrate how the algorithm's performance can be further improved
by a) using an actor-critic style algorithm instead of plain vanilla policy
gradient and b) ensembling Transformer blocks with shared parameters, each
block conditioned on a different auto-regressive factorization order. Our
algorithm works well as both a NAS and generic hyper-parameter optimization
(HPO) algorithm: it outperformed most algorithms on NAS-Bench-101, a public
data-set for benchmarking NAS algorithms. In particular, it outperformed RL
based methods that use alternate architectures to model the policy network,
underlining the value of using attention-based networks in this setting. As a
generic HPO algorithm, it outperformed Random Search in discovering more
accurate multi-layer perceptron model architectures across 2 regression tasks.
We have adhered to guidelines listed in Lindauer and Hutter while designing
experiments and reporting results.
</p>
<a href="http://arxiv.org/abs/2006.00939" target="_blank">arXiv:2006.00939</a> [<a href="http://arxiv.org/pdf/2006.00939" target="_blank">pdf</a>]

<h2>All your loss are belong to Bayes. (arXiv:2006.04633v2 [cs.LG] UPDATED)</h2>
<h3>Christian Walder, Richard Nock</h3>
<p>Loss functions are a cornerstone of machine learning and the starting point
of most algorithms. Statistics and Bayesian decision theory have contributed,
via properness, to elicit over the past decades a wide set of admissible losses
in supervised learning, to which most popular choices belong (logistic, square,
Matsushita, etc.). Rather than making a potentially biased ad hoc choice of the
loss, there has recently been a boost in efforts to fit the loss to the domain
at hand while training the model itself. The key approaches fit a canonical
link, a function which monotonically relates the closed unit interval to R and
can provide a proper loss via integration. In this paper, we rely on a broader
view of proper composite losses and a recent construct from information
geometry, source functions, whose fitting alleviates constraints faced by
canonical links. We introduce a trick on squared Gaussian Processes to obtain a
random process whose paths are compliant source functions with many desirable
properties in the context of link estimation. Experimental results demonstrate
substantial improvements over the state of the art.
</p>
<a href="http://arxiv.org/abs/2006.04633" target="_blank">arXiv:2006.04633</a> [<a href="http://arxiv.org/pdf/2006.04633" target="_blank">pdf</a>]

<h2>Rethinking Importance Weighting for Deep Learning under Distribution Shift. (arXiv:2006.04662v2 [cs.LG] UPDATED)</h2>
<h3>Tongtong Fang, Nan Lu, Gang Niu, Masashi Sugiyama</h3>
<p>Under distribution shift (DS) where the training data distribution differs
from the test one, a powerful technique is importance weighting (IW) which
handles DS in two separate steps: weight estimation (WE) estimates the
test-over-training density ratio and weighted classification (WC) trains the
classifier from weighted training data. However, IW cannot work well on complex
data, since WE is incompatible with deep learning. In this paper, we rethink IW
and theoretically show it suffers from a circular dependency: we need not only
WE for WC, but also WC for WE where a trained deep classifier is used as the
feature extractor (FE). To cut off the dependency, we try to pretrain FE from
unweighted training data, which leads to biased FE. To overcome the bias, we
propose an end-to-end solution dynamic IW that iterates between WE and WC and
combines them in a seamless manner, and hence our WE can also enjoy deep
networks and stochastic optimizers indirectly. Experiments with two
representative types of DS on three popular datasets show that our dynamic IW
compares favorably with state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2006.04662" target="_blank">arXiv:2006.04662</a> [<a href="http://arxiv.org/pdf/2006.04662" target="_blank">pdf</a>]

<h2>In Proximity of ReLU DNN, PWA Function, and Explicit MPC. (arXiv:2006.05001v2 [cs.LG] UPDATED)</h2>
<h3>Saman Fahandezh-Saadi, Masayoshi Tomizuka</h3>
<p>Rectifier (ReLU) deep neural networks (DNN) and their connection with
piecewise affine (PWA) functions is analyzed. The paper is an effort to find
and study the possibility of representing explicit state feedback policy of
model predictive control (MPC) as a ReLU DNN, and vice versa. The complexity
and architecture of DNN has been examined through some theorems and
discussions. An approximate method has been developed for identification of
input-space in ReLU net which results a PWA function over polyhedral regions.
Also, inverse multiparametric linear or quadratic programs (mp-LP or mp-QP) has
been studied which deals with reconstruction of constraints and cost function
given a PWA function.
</p>
<a href="http://arxiv.org/abs/2006.05001" target="_blank">arXiv:2006.05001</a> [<a href="http://arxiv.org/pdf/2006.05001" target="_blank">pdf</a>]

<h2>GAIT-prop: A biologically plausible learning rule derived from backpropagation of error. (arXiv:2006.06438v3 [cs.LG] UPDATED)</h2>
<h3>Nasir Ahmad, Marcel A. J. van Gerven, Luca Ambrogioni</h3>
<p>Traditional backpropagation of error, though a highly successful algorithm
for learning in artificial neural network models, includes features which are
biologically implausible for learning in real neural circuits. An alternative
called target propagation proposes to solve this implausibility by using a
top-down model of neural activity to convert an error at the output of a neural
network into layer-wise and plausible 'targets' for every unit. These targets
can then be used to produce weight updates for network training. However, thus
far, target propagation has been heuristically proposed without demonstrable
equivalence to backpropagation. Here, we derive an exact correspondence between
backpropagation and a modified form of target propagation (GAIT-prop) where the
target is a small perturbation of the forward pass. Specifically,
backpropagation and GAIT-prop give identical updates when synaptic weight
matrices are orthogonal. In a series of simple computer vision experiments, we
show near-identical performance between backpropagation and GAIT-prop with a
soft orthogonality-inducing regularizer.
</p>
<a href="http://arxiv.org/abs/2006.06438" target="_blank">arXiv:2006.06438</a> [<a href="http://arxiv.org/pdf/2006.06438" target="_blank">pdf</a>]

<h2>Boosting Active Learning for Speech Recognition with Noisy Pseudo-labeled Samples. (arXiv:2006.11021v2 [eess.AS] UPDATED)</h2>
<h3>Jihwan Bang, Heesu Kim, YoungJoon Yoo, Jung-Woo Ha</h3>
<p>The cost of annotating transcriptions for large speech corpora becomes a
bottleneck to maximally enjoy the potential capacity of deep neural
network-based automatic speech recognition models. In this paper, we present a
new training pipeline boosting the conventional active learning approach
targeting label-efficient learning to resolve the mentioned problem. Existing
active learning methods only focus on selecting a set of informative samples
under a labeling budget. One step further, we suggest that the training
efficiency can be further improved by utilizing the unlabeled samples,
exceeding the labeling budget, by introducing sophisticatedly configured
unsupervised loss complementing supervised loss effectively. We propose new
unsupervised loss based on consistency regularization, and we configure
appropriate augmentation techniques for utterances to adopt consistency
regularization in the automatic speech recognition task. From the qualitative
and quantitative experiments on the real-world dataset and under real-usage
scenarios, we show that the proposed training pipeline can boost the efficacy
of active learning approaches, thus successfully reducing a sustainable amount
of human labeling cost.
</p>
<a href="http://arxiv.org/abs/2006.11021" target="_blank">arXiv:2006.11021</a> [<a href="http://arxiv.org/pdf/2006.11021" target="_blank">pdf</a>]

<h2>Artemis: tight convergence guarantees for bidirectional compression in Federated Learning. (arXiv:2006.14591v2 [cs.LG] UPDATED)</h2>
<h3>Constantin Philippenko, Aymeric Dieuleveut</h3>
<p>We introduce a new algorithm - Artemis - tackling the problem of learning in
a distributed framework with communication constraints. Several workers
(randomly sampled) perform the optimization process using a central server to
aggregate their computation. To alleviate the communication cost, Artemis
compresses the information sent in both directions (from the workers to the
server and conversely) combined with a memory mechanism. It improves on
existing quantized federated learning algorithms that only consider
unidirectional compression (to the server), or use very strong assumptions on
the compression operator, and often do not take into account devices partial
participation. We provide fast rates of convergence (linear up to a threshold)
under weak assumptions on the stochastic gradients (noise's variance bounded
only at optimal point) in non-i.i.d. setting, highlight the impact of memory
for unidirectional and bidirectional compression, analyze Polyak-Ruppert
averaging. We use convergence in distribution to obtain a lower bound of the
asymptotic variance that highlights practical limits of compression. And we
provide experimental results to demonstrate the validity of our analysis.
</p>
<a href="http://arxiv.org/abs/2006.14591" target="_blank">arXiv:2006.14591</a> [<a href="http://arxiv.org/pdf/2006.14591" target="_blank">pdf</a>]

<h2>CoPhy-PGNN: Learning Physics-guided Neural Networks withCompeting Loss Functions for Solving Eigenvalue Problems. (arXiv:2007.01420v4 [cs.LG] UPDATED)</h2>
<h3>Mohannad Elhamod, Jie Bu, Christopher Singh, Matthew Redell, Abantika Ghosh, Viktor Podolskiy, Wei-Cheng Lee, Anuj Karpatne</h3>
<p>Physics-guided Neural Networks (PGNNs) represent an emerging class of neural
networks that are trained using physics-guided (PG) loss functions (capturing
violations in network outputs with known physics), along with the supervision
contained in data. Existing work in PGNNs have demonstrated the efficacy of
adding single PG loss functions in the neural network objectives, using
constant trade-off parameters, to ensure better generalizability. However, in
the presence of multiple physics loss functions with competing gradient
directions, there is a need to adaptively tune the contribution of competing PG
loss functions during the course of training to arrive at generalizable
solutions. We demonstrate the presence of competing PG losses in the generic
neural network problem of solving for the lowest (or highest) eigenvector of a
physics-based eigenvalue equation, common to many scientific problems. We
present a novel approach to handle competing PG losses and demonstrate its
efficacy in learning generalizable solutions in two motivating applications of
quantum mechanics and electromagnetic propagation. All the code and data used
in this work is available at https://github.com/jayroxis/Cophy-PGNN.
</p>
<a href="http://arxiv.org/abs/2007.01420" target="_blank">arXiv:2007.01420</a> [<a href="http://arxiv.org/pdf/2007.01420" target="_blank">pdf</a>]

<h2>Benefiting from Bicubically Down-Sampled Images for Learning Real-World Image Super-Resolution. (arXiv:2007.03053v2 [eess.IV] UPDATED)</h2>
<h3>Mohammad Saeed Rad, Thomas Yu, Claudiu Musat, Hazim Kemal Ekenel, Behzad Bozorgtabar, Jean-Philippe Thiran</h3>
<p>Super-resolution (SR) has traditionally been based on pairs of
high-resolution images (HR) and their low-resolution (LR) counterparts obtained
artificially with bicubic downsampling. However, in real-world SR, there is a
large variety of realistic image degradations and analytically modeling these
realistic degradations can prove quite difficult. In this work, we propose to
handle real-world SR by splitting this ill-posed problem into two comparatively
more well-posed steps. First, we train a network to transform real LR images to
the space of bicubically downsampled images in a supervised manner, by using
both real LR/HR pairs and synthetic pairs. Second, we take a generic SR network
trained on bicubically downsampled images to super-resolve the transformed LR
image. The first step of the pipeline addresses the problem by registering the
large variety of degraded images to a common, well understood space of images.
The second step then leverages the already impressive performance of SR on
bicubically downsampled images, sidestepping the issues of end-to-end training
on datasets with many different image degradations. We demonstrate the
effectiveness of our proposed method by comparing it to recent methods in
real-world SR and show that our proposed approach outperforms the
state-of-the-art works in terms of both qualitative and quantitative results,
as well as results of an extensive user study conducted on several real image
datasets.
</p>
<a href="http://arxiv.org/abs/2007.03053" target="_blank">arXiv:2007.03053</a> [<a href="http://arxiv.org/pdf/2007.03053" target="_blank">pdf</a>]

<h2>Auxiliary Tasks Speed Up Learning PointGoal Navigation. (arXiv:2007.04561v2 [cs.CV] UPDATED)</h2>
<h3>Joel Ye, Dhruv Batra, Erik Wijmans, Abhishek Das</h3>
<p>PointGoal Navigation is an embodied task that requires agents to navigate to
a specified point in an unseen environment. Wijmans et al. showed that this
task is solvable but their method is computationally prohibitive, requiring 2.5
billion frames and 180 GPU-days. In this work, we develop a method to
significantly increase sample and time efficiency in learning PointNav using
self-supervised auxiliary tasks (e.g. predicting the action taken between two
egocentric observations, predicting the distance between two observations from
a trajectory,etc.).We find that naively combining multiple auxiliary tasks
improves sample efficiency,but only provides marginal gains beyond a point. To
overcome this, we use attention to combine representations learnt from
individual auxiliary tasks. Our best agent is 5.5x faster to reach the
performance of the previous state-of-the-art, DD-PPO, at 40M frames, and
improves on DD-PPO's performance at 40M frames by 0.16 SPL. Our code is
publicly available at https://github.com/joel99/habitat-pointnav-aux.
</p>
<a href="http://arxiv.org/abs/2007.04561" target="_blank">arXiv:2007.04561</a> [<a href="http://arxiv.org/pdf/2007.04561" target="_blank">pdf</a>]

<h2>Coarse-grained spectral projection (CGSP): a deep learning-assisted approach to quantum unitary dynamics. (arXiv:2007.09788v2 [quant-ph] UPDATED)</h2>
<h3>Pinchen Xie, Weinan E</h3>
<p>We propose the coarse-grained spectral projection method (CGSP), a deep
learning-assisted approach for tackling quantum unitary dynamic problems with
an emphasis on quench dynamics. We show CGSP can extract spectral components of
many-body quantum states systematically with sophisticated neural network
quantum ansatz. CGSP exploits fully the linear unitary nature of the quantum
dynamics, and is potentially superior to other quantum Monte Carlo methods for
ergodic dynamics. Preliminary numerical results on 1D XXZ models with periodic
boundary condition are carried out to demonstrate the practicality of CGSP.
</p>
<a href="http://arxiv.org/abs/2007.09788" target="_blank">arXiv:2007.09788</a> [<a href="http://arxiv.org/pdf/2007.09788" target="_blank">pdf</a>]

<h2>DeepHazard: neural network for time-varying risks. (arXiv:2007.13218v2 [stat.ML] UPDATED)</h2>
<h3>Denise Rava, Jelena Bradic</h3>
<p>Prognostic models in survival analysis are aimed at understanding the
relationship between patients' covariates and the distribution of survival
time. Traditionally, semi-parametric models, such as the Cox model, have been
assumed. These often rely on strong proportionality assumptions of the hazard
that might be violated in practice. Moreover, they do not often include
covariate information updated over time. We propose a new flexible method for
survival prediction: DeepHazard, a neural network for time-varying risks. Our
approach is tailored for a wide range of continuous hazards forms, with the
only restriction of being additive in time. A flexible implementation, allowing
different optimization methods, along with any norm penalty, is developed.
Numerical examples illustrate that our approach outperforms existing
state-of-the-art methodology in terms of predictive capability evaluated
through the C-index metric. The same is revealed on the popular real datasets
as METABRIC, GBSG, and ACTG.
</p>
<a href="http://arxiv.org/abs/2007.13218" target="_blank">arXiv:2007.13218</a> [<a href="http://arxiv.org/pdf/2007.13218" target="_blank">pdf</a>]

<h2>FedML: A Research Library and Benchmark for Federated Machine Learning. (arXiv:2007.13518v3 [cs.LG] UPDATED)</h2>
<h3>Chaoyang He, Songze Li, Jinhyun So, Xiao Zeng, Mi Zhang, Hongyi Wang, Xiaoyang Wang, Praneeth Vepakomma, Abhishek Singh, Hang Qiu, Xinghua Zhu, Jianzong Wang, Li Shen, Peilin Zhao, Yan Kang, Yang Liu, Ramesh Raskar, Qiang Yang, Murali Annavaram, Salman Avestimehr</h3>
<p>Federated learning (FL) is a rapidly growing research field in machine
learning. However, existing FL libraries cannot adequately support diverse
algorithmic development; inconsistent dataset and model usage make fair
algorithm comparison challenging. In this work, we introduce FedML, an open
research library and benchmark to facilitate FL algorithm development and fair
performance comparison. FedML supports three computing paradigms: on-device
training for edge devices, distributed computing, and single-machine
simulation. FedML also promotes diverse algorithmic research with flexible and
generic API design and comprehensive reference baseline implementations
(optimizer, models, and datasets). We hope FedML could provide an efficient and
reproducible means for developing and evaluating FL algorithms that would
benefit the FL research community. We maintain the source code, documents, and
user community at https://fedml.ai.
</p>
<a href="http://arxiv.org/abs/2007.13518" target="_blank">arXiv:2007.13518</a> [<a href="http://arxiv.org/pdf/2007.13518" target="_blank">pdf</a>]

<h2>Oblique Predictive Clustering Trees. (arXiv:2007.13617v2 [cs.LG] UPDATED)</h2>
<h3>Toma&#x17e; Stepi&#x161;nik, Dragi Kocev</h3>
<p>Predictive clustering trees (PCTs) are a well established generalization of
standard decision trees, which can be used to solve a variety of predictive
modeling tasks, including structured output prediction. Combining them into
ensembles yields state-of-the-art performance. Furthermore, the ensembles of
PCTs can be interpreted by calculating feature importance scores from the
learned models. However, their learning time scales poorly with the
dimensionality of the output space. This is often problematic, especially in
(hierarchical) multi-label classification, where the output can consist of
hundreds of potential labels. Also, learning of PCTs can not exploit the
sparsity of data to improve the computational efficiency, which is common in
both input (molecular fingerprints, bag of words representations) and output
spaces (in multi-label classification, examples are often labeled with only a
fraction of possible labels). In this paper, we propose oblique predictive
clustering trees, capable of addressing these limitations. We design and
implement two methods for learning oblique splits that contain linear
combinations of features in the tests, hence a split corresponds to an
arbitrary hyperplane in the input space. The methods are efficient for high
dimensional data and capable of exploiting sparse data. We experimentally
evaluate the proposed methods on 60 benchmark datasets for 6 predictive
modeling tasks. The results of the experiments show that oblique predictive
clustering trees achieve performance on-par with state-of-the-art methods and
are orders of magnitude faster than standard PCTs. We also show that meaningful
feature importance scores can be extracted from the models learned with the
proposed methods.
</p>
<a href="http://arxiv.org/abs/2007.13617" target="_blank">arXiv:2007.13617</a> [<a href="http://arxiv.org/pdf/2007.13617" target="_blank">pdf</a>]

<h2>Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge. (arXiv:2007.14513v4 [cs.LG] UPDATED)</h2>
<h3>Chaoyang He, Murali Annavaram, Salman Avestimehr</h3>
<p>Scaling up the convolutional neural network (CNN) size (e.g., width, depth,
etc.) is known to effectively improve model accuracy. However, the large model
size impedes training on resource-constrained edge devices. For instance,
federated learning (FL) may place undue burden on the compute capability of
edge nodes, even though there is a strong practical need for FL due to its
privacy and confidentiality properties. To address the resource-constrained
reality of edge devices, we reformulate FL as a group knowledge transfer
training algorithm, called FedGKT. FedGKT designs a variant of the alternating
minimization approach to train small CNNs on edge nodes and periodically
transfer their knowledge by knowledge distillation to a large server-side CNN.
FedGKT consolidates several advantages into a single framework: reduced demand
for edge computation, lower communication bandwidth for large CNNs, and
asynchronous training, all while maintaining model accuracy comparable to
FedAvg. We train CNNs designed based on ResNet-56 and ResNet-110 using three
distinct datasets (CIFAR-10, CIFAR-100, and CINIC-10) and their non-I.I.D.
variants. Our results show that FedGKT can obtain comparable or even slightly
higher accuracy than FedAvg. More importantly, FedGKT makes edge training
affordable. Compared to the edge training using FedAvg, FedGKT demands 9 to 17
times less computational power (FLOPs) on edge devices and requires 54 to 105
times fewer parameters in the edge CNN. Our source code is released at FedML
(https://fedml.ai).
</p>
<a href="http://arxiv.org/abs/2007.14513" target="_blank">arXiv:2007.14513</a> [<a href="http://arxiv.org/pdf/2007.14513" target="_blank">pdf</a>]

<h2>An Imitation from Observation Approach to Transfer Learning with Dynamics Mismatch. (arXiv:2008.01594v2 [cs.AI] UPDATED)</h2>
<h3>Siddarth Desai, Ishan Durugkar, Haresh Karnan, Garrett Warnell, Josiah Hanna, Peter Stone</h3>
<p>We examine the problem of transferring a policy learned in a source
environment to a target environment with different dynamics, particularly in
the case where it is critical to reduce the amount of interaction with the
target environment during learning. This problem is particularly important in
sim-to-real transfer because simulators inevitably model real-world dynamics
imperfectly. In this paper, we show that one existing solution to this transfer
problem - grounded action transformation - is closely related to the problem of
imitation from observation (IfO): learning behaviors that mimic the
observations of behavior demonstrations. After establishing this relationship,
we hypothesize that recent state-of-the-art approaches from the IfO literature
can be effectively repurposed for grounded transfer learning.To validate our
hypothesis we derive a new algorithm - generative adversarial reinforced action
transformation (GARAT) - based on adversarial imitation from observation
techniques. We run experiments in several domains with mismatched dynamics, and
find that agents trained with GARAT achieve higher returns in the target
environment compared to existing black-box transfer methods
</p>
<a href="http://arxiv.org/abs/2008.01594" target="_blank">arXiv:2008.01594</a> [<a href="http://arxiv.org/pdf/2008.01594" target="_blank">pdf</a>]

<h2>A Differentially Private Framework for Spatial Crowdsourcing with Historical Data Learning. (arXiv:2008.03475v3 [cs.CR] UPDATED)</h2>
<h3>Shun Zhang, Benfei Duan, Zhili Chen, Hong Zhong, Qizhi Yu</h3>
<p>Spatial crowdsourcing (SC) is an increasing popular category of crowdsourcing
in the era of mobile Internet and sharing economy. It requires workers to
arrive at a particular location for task fulfillment. Effective protection of
location privacy is essential for workers' enthusiasm and valid task
assignment. However, existing SC models with differential privacy usually
perturb real-time location data for both partition and data publication. Such a
way may produce large perturbations to counting queries that affect assignment
success rate and allocation accuracy. This paper proposes a framework (R-HT)
for protecting location privacy of workers taking advantage of both real-time
and historical data. We simulate locations by sampling the probability
distribution learned from historical data, use them for grid partition, and
then publish real-time data under this partitioning with differential privacy.
This realizes that most privacy budget is allocated to the worker count of each
cell and yields an improved Private Spatial Decomposition approach. Moreover,
we introduce some strategies for geocast region construction, including quality
scoring function and local maximum geocast radius. A series of experimental
results on real-world datasets shows that R-HT attains a stable success rate of
task assignment, saves performance overhead and fits for dynamic assignment on
crowdsourcing platforms.
</p>
<a href="http://arxiv.org/abs/2008.03475" target="_blank">arXiv:2008.03475</a> [<a href="http://arxiv.org/pdf/2008.03475" target="_blank">pdf</a>]

<h2>Metrics for Exposing the Biases of Content-Style Disentanglement. (arXiv:2008.12378v3 [cs.CV] UPDATED)</h2>
<h3>Xiao Liu, Spyridon Thermos, Gabriele Valvano, Agisilaos Chartsias, Alison O&#x27;Neil, Sotirios A. Tsaftaris</h3>
<p>A recent spate of state-of-the-art semi- and unsupervised solutions for
challenging computer vision tasks encode image "content" into a spatial tensor
and image appearance or "style" into a vector. Most of these solutions use the
term disentangled for their representations and employ different "biases" such
as model design, learning objectives, and data, to achieve good performance in
spatially equivariant tasks (e.g. image-to-image translation). While
considerable effort has been made to measure disentanglement in vector
representations, we have lacked metrics for spatial content and vector style
representations. In this paper, we propose such metrics to characterize the
degree of disentanglement in terms of how (un)correlated and informative the
content and style representations are, and we further examine its relation to
task performance. In particular, we first identify key design choices and
learning constraints on three popular models that employ content-style
disentanglement and derive ablated versions. Secondly, we use our metrics to
ascertain the role of each bias. Our experiments reveal a "sweet spot" between
disentanglement, task performance and latent space interpretability. Our
metrics are not task-dependent; thus, they can help guide either the design of
new future models or the selection of viable models such that this ideal "sweet
spot" is achieved in any task where content-style representations are useful.
</p>
<a href="http://arxiv.org/abs/2008.12378" target="_blank">arXiv:2008.12378</a> [<a href="http://arxiv.org/pdf/2008.12378" target="_blank">pdf</a>]

<h2>SketchEmbedNet: Learning Novel Concepts by Imitating Drawings. (arXiv:2009.04806v3 [cs.CV] UPDATED)</h2>
<h3>Alexander Wang, Mengye Ren, Richard Zemel</h3>
<p>Sketch drawings are an intuitive visual domain that appeals to human
instinct. Previous work has shown that recurrent neural networks are capable of
producing sketch drawings of a single or few classes at a time. In this work we
investigate representations developed by training a generative model to produce
sketches from pixel images across many classes in a sketch domain. We find that
the embeddings learned by this sketching model are informative for visual tasks
and capture some forms of visual understanding. We then use them to exceed
state-of-the-art performance in unsupervised few-shot classification on the
Omniglot and mini-ImageNet benchmarks. We also leverage the generative capacity
of our model to produce high quality sketches of novel classes based on just a
single example.
</p>
<a href="http://arxiv.org/abs/2009.04806" target="_blank">arXiv:2009.04806</a> [<a href="http://arxiv.org/pdf/2009.04806" target="_blank">pdf</a>]

<h2>Synbols: Probing Learning Algorithms with Synthetic Datasets. (arXiv:2009.06415v2 [cs.CV] UPDATED)</h2>
<h3>Alexandre Lacoste, Pau Rodr&#xed;guez, Fr&#xe9;d&#xe9;ric Branchaud-Charron, Parmida Atighehchian, Massimo Caccia, Issam Laradji, Alexandre Drouin, Matt Craddock, Laurent Charlin, David V&#xe1;zquez</h3>
<p>Progress in the field of machine learning has been fueled by the introduction
of benchmark datasets pushing the limits of existing algorithms. Enabling the
design of datasets to test specific properties and failure modes of learning
algorithms is thus a problem of high interest, as it has a direct impact on
innovation in the field. In this sense, we introduce Synbols -- Synthetic
Symbols -- a tool for rapidly generating new datasets with a rich composition
of latent features rendered in low resolution images. Synbols leverages the
large amount of symbols available in the Unicode standard and the wide range of
artistic font provided by the open font community. Our tool's high-level
interface provides a language for rapidly generating new distributions on the
latent features, including various types of textures and occlusions. To
showcase the versatility of Synbols, we use it to dissect the limitations and
flaws in standard learning algorithms in various learning setups including
supervised learning, active learning, out of distribution generalization,
unsupervised representation learning, and object counting.
</p>
<a href="http://arxiv.org/abs/2009.06415" target="_blank">arXiv:2009.06415</a> [<a href="http://arxiv.org/pdf/2009.06415" target="_blank">pdf</a>]

<h2>The EMPATHIC Framework for Task Learning from Implicit Human Feedback. (arXiv:2009.13649v2 [cs.HC] UPDATED)</h2>
<h3>Yuchen Cui, Qiping Zhang, Alessandro Allievi, Peter Stone, Scott Niekum, W. Bradley Knox</h3>
<p>Reactions such as gestures, facial expressions, and vocalizations are an
abundant, naturally occurring channel of information that humans provide during
interactions. A robot or other agent could leverage an understanding of such
implicit human feedback to improve its task performance at no cost to the
human. This approach contrasts with common agent teaching methods based on
demonstrations, critiques, or other guidance that need to be attentively and
intentionally provided. In this paper, we first define the general problem of
learning from implicit human feedback and then propose to address this problem
through a novel data-driven framework, EMPATHIC. This two-stage method consists
of (1) mapping implicit human feedback to relevant task statistics such as
reward, optimality, and advantage; and (2) using such a mapping to learn a
task. We instantiate the first stage and three second-stage evaluations of the
learned mapping. To do so, we collect a dataset of human facial reactions while
participants observe an agent execute a sub-optimal policy for a prescribed
training task. We train a deep neural network on this data and demonstrate its
ability to (1) infer relative reward ranking of events in the training task
from prerecorded human facial reactions; (2) improve the policy of an agent in
the training task using live human facial reactions; and (3) transfer to a
novel domain in which it evaluates robot manipulation trajectories.
</p>
<a href="http://arxiv.org/abs/2009.13649" target="_blank">arXiv:2009.13649</a> [<a href="http://arxiv.org/pdf/2009.13649" target="_blank">pdf</a>]

<h2>PettingZoo: Gym for Multi-Agent Reinforcement Learning. (arXiv:2009.14471v2 [cs.LG] UPDATED)</h2>
<h3>Justin K. Terry, Benjamin Black, Mario Jayakumar, Ananth Hari, Luis Santos, Clemens Dieffendahl, Niall L. Williams, Yashas Lokesh, Ryan Sullivan, Caroline Horsch, Praveen Ravi</h3>
<p>OpenAI's Gym library contains a large, diverse set of environments that are
useful benchmarks in reinforcement learning, under a single elegant Python API
(with tools to develop new compliant environments). The introduction of this
library has proven a watershed moment for the reinforcement learning community,
because it created an accessible set of benchmark environments that everyone
could use(including wrapper important existing libraries), and because a
standardized APIlets RL methods and environments from anywhere be trivially
exchanged. This paper similarly introduces PettingZoo, a library of diverse
sets of multi-agent environments under a single elegant Python API, with tools
to easily make new compliant environments.
</p>
<a href="http://arxiv.org/abs/2009.14471" target="_blank">arXiv:2009.14471</a> [<a href="http://arxiv.org/pdf/2009.14471" target="_blank">pdf</a>]

<h2>Time Matters: Time-Aware LSTMs for Predictive Business Process Monitoring. (arXiv:2010.00889v3 [cs.LG] UPDATED)</h2>
<h3>An Nguyen, Srijeet Chatterjee, Sven Weinzierl, Leo Schwinn, Martin Matzner, Bjoern Eskofier</h3>
<p>Predictive business process monitoring (PBPM) aims to predict future process
behavior during ongoing process executions based on event log data. Especially,
techniques for the next activity and timestamp prediction can help to improve
the performance of operational business processes. Recently, many PBPM
solutions based on deep learning were proposed by researchers. Due to the
sequential nature of event log data, a common choice is to apply recurrent
neural networks with long short-term memory (LSTM) cells. We argue, that the
elapsed time between events is informative. However, current PBPM techniques
mainly use 'vanilla' LSTM cells and hand-crafted time-related control flow
features. To better model the time dependencies between events, we propose a
new PBPM technique based on time-aware LSTM (T-LSTM) cells. T-LSTM cells
incorporate the elapsed time between consecutive events inherently to adjust
the cell memory. Furthermore, we introduce cost-sensitive learning to account
for the common class imbalance in event logs. Our experiments on publicly
available benchmark event logs indicate the effectiveness of the introduced
techniques.
</p>
<a href="http://arxiv.org/abs/2010.00889" target="_blank">arXiv:2010.00889</a> [<a href="http://arxiv.org/pdf/2010.00889" target="_blank">pdf</a>]

<h2>Policy learning in SE(3) action spaces. (arXiv:2010.02798v2 [cs.RO] UPDATED)</h2>
<h3>Dian Wang, Colin Kohler, Robert Platt</h3>
<p>In the spatial action representation, the action space spans the space of
target poses for robot motion commands, i.e. SE(2) or SE(3). This approach has
been used to solve challenging robotic manipulation problems and shows promise.
However, the method is often limited to a three dimensional action space and
short horizon tasks. This paper proposes ASRSE3, a new method for handling
higher dimensional spatial action spaces that transforms an original MDP with
high dimensional action space into a new MDP with reduced action space and
augmented state space. We also propose SDQfD, a variation of DQfD designed for
large action spaces. ASRSE3 and SDQfD are evaluated in the context of a set of
challenging block construction tasks. We show that both methods outperform
standard baselines and can be used in practice on real robotics systems.
</p>
<a href="http://arxiv.org/abs/2010.02798" target="_blank">arXiv:2010.02798</a> [<a href="http://arxiv.org/pdf/2010.02798" target="_blank">pdf</a>]

<h2>The DongNiao International Birds 10000 Dataset. (arXiv:2010.06454v2 [cs.CV] UPDATED)</h2>
<h3>Jian Mei, Hao Dong</h3>
<p>DongNiao International Birds 10000 (DIB-10K) is a challenging image dataset
which has more than 10 thousand different types of birds. It was created to
enable the study of machine learning and also ornithology research. DIB-10K
does not own the copyright of these images. It only provides thumbnails of
images, in a way similar to ImageNet.
</p>
<a href="http://arxiv.org/abs/2010.06454" target="_blank">arXiv:2010.06454</a> [<a href="http://arxiv.org/pdf/2010.06454" target="_blank">pdf</a>]

<h2>Robust path-following control design of heavy vehicles based on multiobjective evolutionary optimization. (arXiv:2010.07255v2 [eess.SY] UPDATED)</h2>
<h3>Gustavo Alves Prudencio de Morais, Lucas Barbosa Marcos, Filipe Marques Barbosa, Bruno Henrique Groenner Barbosa, Marco Henrique Terra, Valdir Grassi Jr</h3>
<p>The ability to deal with systems parametric uncertainties is an essential
issue for heavy self-driving vehicles in unconfined environments. In this
sense, robust controllers prove to be efficient for autonomous navigation.
However, uncertainty matrices for this class of systems are usually defined by
algebraic methods which demand prior knowledge of the system dynamics. In this
case, the control system designer depends, on the quality of the uncertain
model to obtain an optimal control performance. This work proposes a robust
recursive controller designed via multiobjective optimization to overcome these
shortcomings. Furthermore, a local search approach for multiobjective
optimization problems is presented. The proposed method applies to any
multiobjective evolutionary algorithm already established in the literature.
The results presented show that this combination of model-based controller and
machine learning improves the effectiveness of the system in terms of
robustness, stability and smoothness.
</p>
<a href="http://arxiv.org/abs/2010.07255" target="_blank">arXiv:2010.07255</a> [<a href="http://arxiv.org/pdf/2010.07255" target="_blank">pdf</a>]

<h2>CIMON: Towards High-quality Hash Codes. (arXiv:2010.07804v3 [cs.CV] UPDATED)</h2>
<h3>Xiao Luo, Daqing Wu, Zeyu Ma, Chong Chen, Huasong Zhong, Minghua Deng, Jianqiang Huang, Xian-sheng Hua</h3>
<p>Recently, hashing is widely-used in approximate nearest neighbor search for
its storage and computational efficiency. Due to the lack of labeled data in
practice, many studies focus on unsupervised hashing. Most of the unsupervised
hashing methods learn to map images into semantic similarity-preserving hash
codes by constructing local semantic similarity structure from the pre-trained
model as guiding information, i.e., treating each point pair similar if their
distance is small in feature space. However, due to the inefficient
representation ability of the pre-trained model, many false positives and
negatives in local semantic similarity will be introduced and lead to error
propagation during hash code learning. Moreover, most of hashing methods ignore
the basic characteristics of hash codes such as collisions, which will cause
instability of hash codes to disturbance. In this paper, we propose a new
method named Comprehensive sImilarity Mining and cOnsistency learNing (CIMON).
First, we use global constraint learning and similarity statistical
distribution to obtain reliable and smooth guidance. Second, image augmentation
and consistency learning will be introduced to explore both semantic and
contrastive consistency to derive robust hash codes with fewer collisions.
Extensive experiments on several benchmark datasets show that the proposed
method consistently outperforms a wide range of state-of-the-art methods in
both retrieval performance and robustness.
</p>
<a href="http://arxiv.org/abs/2010.07804" target="_blank">arXiv:2010.07804</a> [<a href="http://arxiv.org/pdf/2010.07804" target="_blank">pdf</a>]

<h2>What breach? Measuring online awareness of security incidents by studying real-world browsing behavior. (arXiv:2010.09843v3 [cs.CR] UPDATED)</h2>
<h3>Sruti Bhagavatula, Lujo Bauer, Apu Kapadia</h3>
<p>Awareness about security and privacy risks is important for developing good
security habits. Learning about real-world security incidents and data breaches
can alert people to the ways in which their information is vulnerable online,
thus playing a significant role in encouraging safe security behavior. This
paper examines 1) how often people read about security incidents online, 2) of
those people, whether and to what extent they follow up with an action, e.g.,
by trying to read more about the incident, and 3) what influences the
likelihood that they will read about an incident and take some action. We study
this by quantitatively examining real-world internet-browsing data from 303
participants.

Our findings present a bleak view of awareness of security incidents. Only
17% of participants visited any web pages related to six widely publicized
large-scale security incidents; few read about one even when an incident was
likely to have affected them (e.g., the Equifax breach almost universally
affected people with Equifax credit reports). We further found that more severe
incidents as well as articles that constructively spoke about the incident
inspired more action. We conclude with recommendations for specific future
research and for enabling useful security incident information to reach more
people.
</p>
<a href="http://arxiv.org/abs/2010.09843" target="_blank">arXiv:2010.09843</a> [<a href="http://arxiv.org/pdf/2010.09843" target="_blank">pdf</a>]

<h2>Towards Preference Learning for Autonomous Ground Robot Navigation Tasks. (arXiv:2010.16361v2 [cs.RO] UPDATED)</h2>
<h3>Cory Hayes, Matthew Marge</h3>
<p>We are interested in the design of autonomous robot behaviors that learn the
preferences of users over continued interactions, with the goal of efficiently
executing navigation behaviors in a way that the user expects. In this paper,
we discuss our work in progress to modify a general model for robot navigation
behaviors in an exploration task on a per-user basis using preference-based
reinforcement learning. The novel contribution of this approach is that it
combines reinforcement learning, motion planning, and natural language
processing to allow an autonomous agent to learn from sustained dialogue with a
human teammate as opposed to one-off instructions.
</p>
<a href="http://arxiv.org/abs/2010.16361" target="_blank">arXiv:2010.16361</a> [<a href="http://arxiv.org/pdf/2010.16361" target="_blank">pdf</a>]

<h2>Training EfficientNets at Supercomputer Scale: 83% ImageNet Top-1 Accuracy in One Hour. (arXiv:2011.00071v2 [cs.LG] UPDATED)</h2>
<h3>Arissa Wongpanich, Hieu Pham, James Demmel, Mingxing Tan, Quoc Le, Yang You, Sameer Kumar</h3>
<p>EfficientNets are a family of state-of-the-art image classification models
based on efficiently scaled convolutional neural networks. Currently,
EfficientNets can take on the order of days to train; for example, training an
EfficientNet-B0 model takes 23 hours on a Cloud TPU v2-8 node. In this paper,
we explore techniques to scale up the training of EfficientNets on TPU-v3 Pods
with 2048 cores, motivated by speedups that can be achieved when training at
such scales. We discuss optimizations required to scale training to a batch
size of 65536 on 1024 TPU-v3 cores, such as selecting large batch optimizers
and learning rate schedules as well as utilizing distributed evaluation and
batch normalization techniques. Additionally, we present timing and performance
benchmarks for EfficientNet models trained on the ImageNet dataset in order to
analyze the behavior of EfficientNets at scale. With our optimizations, we are
able to train EfficientNet on ImageNet to an accuracy of 83% in 1 hour and 4
minutes.
</p>
<a href="http://arxiv.org/abs/2011.00071" target="_blank">arXiv:2011.00071</a> [<a href="http://arxiv.org/pdf/2011.00071" target="_blank">pdf</a>]

<h2>PAC Confidence Predictions for Deep Neural Network Classifiers. (arXiv:2011.00716v2 [cs.LG] UPDATED)</h2>
<h3>Sangdon Park, Shuo Li, Osbert Bastani, Insup Lee</h3>
<p>A key challenge for deploying deep neural networks (DNNs) in safety critical
settings is the need to provide rigorous ways to quantify their uncertainty. In
this paper, we propose a novel algorithm for constructing predicted
classification confidences for DNNs that comes with provable correctness
guarantees. Our approach uses Clopper-Pearson confidence intervals for the
Binomial distribution in conjunction with the histogram binning approach to
calibrated prediction. In addition, we demonstrate how our predicted
confidences can be used to enable downstream guarantees in two settings: (i)
fast DNN inference, where we demonstrate how to compose a fast but inaccurate
DNN with an accurate but slow DNN in a rigorous way to improve performance
without sacrificing accuracy, and (ii) safe planning, where we guarantee safety
when using a DNN to predict whether a given action is safe based on visual
observations. In our experiments, we demonstrate that our approach can be used
to provide guarantees for state-of-the-art DNNs.
</p>
<a href="http://arxiv.org/abs/2011.00716" target="_blank">arXiv:2011.00716</a> [<a href="http://arxiv.org/pdf/2011.00716" target="_blank">pdf</a>]

<h2>Frequency-based Automated Modulation Classification in the Presence of Adversaries. (arXiv:2011.01132v2 [eess.SP] UPDATED)</h2>
<h3>Rajeev Sahay, Christopher G. Brinton, David J. Love</h3>
<p>Automatic modulation classification (AMC) aims to improve the efficiency of
crowded radio spectrums by automatically predicting the modulation
constellation of wireless RF signals. Recent work has demonstrated the ability
of deep learning to achieve robust AMC performance using raw in-phase and
quadrature (IQ) time samples. Yet, deep learning models are highly susceptible
to adversarial interference, which cause intelligent prediction models to
misclassify received samples with high confidence. Furthermore, adversarial
interference is often transferable, allowing an adversary to attack multiple
deep learning models with a single perturbation crafted for a particular
classification network. In this work, we present a novel receiver architecture
consisting of deep learning models capable of withstanding transferable
adversarial interference. Specifically, we show that adversarial attacks
crafted to fool models trained on time-domain features are not easily
transferable to models trained using frequency-domain features. In this
capacity, we demonstrate classification performance improvements greater than
30% on recurrent neural networks (RNNs) and greater than 50% on convolutional
neural networks (CNNs). We further demonstrate our frequency feature-based
classification models to achieve accuracies greater than 99% in the absence of
attacks.
</p>
<a href="http://arxiv.org/abs/2011.01132" target="_blank">arXiv:2011.01132</a> [<a href="http://arxiv.org/pdf/2011.01132" target="_blank">pdf</a>]

<h2>Estimating County-Level COVID-19 Exponential Growth Rates Using Generalized Random Forests. (arXiv:2011.01219v3 [cs.LG] UPDATED)</h2>
<h3>Zhaowei She, Zilong Wang, Turgay Ayer, Asmae Toumi, Jagpreet Chhatwal</h3>
<p>Rapid and accurate detection of community outbreaks is critical to address
the threat of resurgent waves of COVID-19. A practical challenge in outbreak
detection is balancing accuracy vs. speed. In particular, while estimation
accuracy improves with longer fitting windows, speed degrades. This paper
presents a machine learning framework to balance this tradeoff using
generalized random forests (GRF), and applies it to detect county level
COVID-19 outbreaks. This algorithm chooses an adaptive fitting window size for
each county based on relevant features affecting the disease spread, such as
changes in social distancing policies. Experiment results show that our method
outperforms any non-adaptive window size choices in 7-day ahead COVID-19
outbreak case number predictions.
</p>
<a href="http://arxiv.org/abs/2011.01219" target="_blank">arXiv:2011.01219</a> [<a href="http://arxiv.org/pdf/2011.01219" target="_blank">pdf</a>]

<h2>VEGA: Towards an End-to-End Configurable AutoML Pipeline. (arXiv:2011.01507v3 [cs.CV] UPDATED)</h2>
<h3>Bochao Wang, Hang Xu, Jiajin Zhang, Chen Chen, Xiaozhi Fang, Ning Kang, Lanqing Hong, Wei Zhang, Yong Li, Zhicheng Liu, Zhenguo Li, Wenzhi Liu, Tong Zhang</h3>
<p>Automated Machine Learning (AutoML) is an important industrial solution for
automatic discovery and deployment of the machine learning models. However,
designing an integrated AutoML system faces four great challenges of
configurability, scalability, integrability, and platform diversity. In this
work, we present VEGA, an efficient and comprehensive AutoML framework that is
compatible and optimized for multiple hardware platforms. a) The VEGA pipeline
integrates various modules of AutoML, including Neural Architecture Search
(NAS), Hyperparameter Optimization (HPO), Auto Data Augmentation, Model
Compression, and Fully Train. b) To support a variety of search algorithms and
tasks, we design a novel fine-grained search space and its description language
to enable easy adaptation to different search algorithms and tasks. c) We
abstract the common components of deep learning frameworks into a unified
interface. VEGA can be executed with multiple back-ends and hardwares.
Extensive benchmark experiments on multiple tasks demonstrate that VEGA can
improve the existing AutoML algorithms and discover new high-performance models
against SOTA methods, e.g. the searched DNet model zoo for Ascend 10x faster
than EfficientNet-B5 and 9.2x faster than RegNetX-32GF on ImageNet. VEGA is
open-sourced at https://github.com/huawei-noah/vega.
</p>
<a href="http://arxiv.org/abs/2011.01507" target="_blank">arXiv:2011.01507</a> [<a href="http://arxiv.org/pdf/2011.01507" target="_blank">pdf</a>]

<h2>Uncertainty Quantification of Darcy Flow through Porous Media using Deep Gaussian Process. (arXiv:2011.01647v2 [stat.ML] UPDATED)</h2>
<h3>A. Daneshkhah, O. Chatrabgoun, M. Esmaeilbeigi, T. Sedighi, S. Abolfathi</h3>
<p>A computational method based on the non-linear Gaussian process (GP), known
as deep Gaussian processes (deep GPs) for uncertainty quantification &amp;
propagation in modelling of flow through heterogeneous porous media is
presented. The method is also used for reducing dimensionality of model output
and consequently emulating highly complex relationship between hydrogeological
properties and reduced order fluid velocity field in a tractable manner. Deep
GPs are multi-layer hierarchical generalisations of GPs with multiple,
infinitely wide hidden layers that are very efficient models for deep learning
and modelling of high-dimensional complex systems by tackling the complexity
through several hidden layers connected with non-linear mappings. According to
this approach, the hydrogeological data is modelled as the output of a
multivariate GP whose inputs are governed by another GP such that each single
layer is either a standard GP or the Gaussian process latent variable model. A
variational approximation framework is used so that the posterior distribution
of the model outputs associated to given inputs can be analytically
approximated. In contrast to the other dimensionality reduction, methods that
do not provide any information about the dimensionality of each hidden layer,
the proposed method automatically selects the dimensionality of each hidden
layer and it can be used to propagate uncertainty obtained in each layer across
the hierarchy. Using this, dimensionality of the full input space consists of
both geometrical parameters of modelling domain and stochastic hydrogeological
parameters can be simultaneously reduced without the need for any
simplifications generally being assumed for stochastic modelling of subsurface
flow problems. It allows estimation of the flow statistics with greatly reduced
computational efforts compared to other stochastic approaches such as Monte
Carlo method.
</p>
<a href="http://arxiv.org/abs/2011.01647" target="_blank">arXiv:2011.01647</a> [<a href="http://arxiv.org/pdf/2011.01647" target="_blank">pdf</a>]

<h2>Generating Unobserved Alternatives: A Case Study through Super-Resolution and Decompression. (arXiv:2011.01926v2 [cs.LG] UPDATED)</h2>
<h3>Shichong Peng, Ke Li</h3>
<p>We consider problems where multiple predictions can be considered correct,
but only one of them is given as supervision. This setting differs from both
the regression and class-conditional generative modelling settings: in the
former, there is a unique observed output for each input, which is provided as
supervision; in the latter, there are many observed outputs for each input, and
many are provided as supervision. Applying either regression methods and
conditional generative models to the present setting often results in a model
that can only make a single prediction for each input. We explore several
problems that have this property and develop an approach that can generate
multiple high-quality predictions given the same input. As a result, it can be
used to generate high-quality outputs that are different from the observed
output.
</p>
<a href="http://arxiv.org/abs/2011.01926" target="_blank">arXiv:2011.01926</a> [<a href="http://arxiv.org/pdf/2011.01926" target="_blank">pdf</a>]

<h2>Self-Adaptively Learning to Demoire from Focused and Defocused Image Pairs. (arXiv:2011.02055v2 [eess.IV] UPDATED)</h2>
<h3>Lin Liu, Shanxin Yuan, Jianzhuang Liu, Liping Bao, Gregory Slabaugh, Qi Tian</h3>
<p>Moire artifacts are common in digital photography, resulting from the
interference between high-frequency scene content and the color filter array of
the camera. Existing deep learning-based demoireing methods trained on large
scale datasets are limited in handling various complex moire patterns, and
mainly focus on demoireing of photos taken of digital displays. Moreover,
obtaining moire-free ground-truth in natural scenes is difficult but needed for
training. In this paper, we propose a self-adaptive learning method for
demoireing a high-frequency image, with the help of an additional defocused
moire-free blur image. Given an image degraded with moire artifacts and a
moire-free blur image, our network predicts a moire-free clean image and a blur
kernel with a self-adaptive strategy that does not require an explicit training
stage, instead performing test-time adaptation. Our model has two sub-networks
and works iteratively. During each iteration, one sub-network takes the moire
image as input, removing moire patterns and restoring image details, and the
other sub-network estimates the blur kernel from the blur image. The two
sub-networks are jointly optimized. Extensive experiments demonstrate that our
method outperforms state-of-the-art methods and can produce high-quality
demoired results. It can generalize well to the task of removing moire
artifacts caused by display screens. In addition, we build a new moire dataset,
including images with screen and texture moire artifacts. As far as we know,
this is the first dataset with real texture moire patterns.
</p>
<a href="http://arxiv.org/abs/2011.02055" target="_blank">arXiv:2011.02055</a> [<a href="http://arxiv.org/pdf/2011.02055" target="_blank">pdf</a>]

<h2>Localization in Terahertz-Operating Energy Harvesting Software-Defined Metamaterials. (arXiv:2011.02335v2 [eess.SP] UPDATED)</h2>
<h3>Filip Lemic, Sergi Abadal, Chong Han, Johann Marquez-Barja, Eduard Alarc&#xf3;n, Jeroen Famaey</h3>
<p>Software-Defined Metamaterials (SDMs) show a strong potential for advancing
the engineered control of electromagnetic waves. As such, they are envisioned
to enable a variety of exciting applications, among others in the domains of
smart textiles, high-resolution structural monitoring, and sensing in
challenging environments. Many of the applications envisage deformations of the
SDM structure, such as its bending, stretching or rolling, which implies that
the locations of metamaterial elements will be changing relative to one
another. In this paper, we argue that if the metamaterial elements would be
accurately localizable, this location information could potentially be utilized
for enabling novel SDM applications, as well as for optimizing the control of
the elements themselves. To enable their localization, we assume that these
elements are controlled wirelessly through a Terahertz (THz)-operating
nanonetwork. We consider the elements to be energy-constrained, with their sole
powering option being to harvest environmental energy. By means of simulation,
we demonstrate sub-millimeter accuracy of the two-way Time of Flight
(ToF)-based localization, as well as high availability of the service (i.e.,
consistently more than 80% of the time), which is a result of the low energy
consumed during localization. Finally, we qualitatively characterize the
latency of the proposed localization service, as well as outline several
challenges and future research directions.
</p>
<a href="http://arxiv.org/abs/2011.02335" target="_blank">arXiv:2011.02335</a> [<a href="http://arxiv.org/pdf/2011.02335" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning Based Dynamic Route Planning for Minimizing Travel Time. (arXiv:2011.01771v1 [cs.LG] CROSS LISTED)</h2>
<h3>Yuanzhe Geng, Erwu Liu, Rui Wang, Yiming Liu</h3>
<p>Route planning is important in transportation. Existing works focus on
finding the shortest path solution or using metrics such as safety and energy
consumption to determine the planning. It is noted that most of these studies
rely on prior knowledge of road network, which may be not available in certain
situations. In this paper, we design a route planning algorithm based on deep
reinforcement learning (DRL) for pedestrians. We use travel time consumption as
the metric, and plan the route by predicting pedestrian flow in the road
network. We put an agent, which is an intelligent robot, on a virtual map.
Different from previous studies, our approach assumes that the agent does not
need any prior information about road network, but simply relies on the
interaction with the environment. We propose a dynamically adjustable route
planning (DARP) algorithm, where the agent learns strategies through a dueling
deep Q network to avoid congested roads. Simulation results show that the DARP
algorithm saves 52% of the time under congestion condition when compared with
traditional shortest path planning algorithms.
</p>
<a href="http://arxiv.org/abs/2011.01771" target="_blank">arXiv:2011.01771</a> [<a href="http://arxiv.org/pdf/2011.01771" target="_blank">pdf</a>]

