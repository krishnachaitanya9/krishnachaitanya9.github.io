---
title: Latest Deep Learning Papers
date: 2021-02-18 21:00:02 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (176 Articles)</h1>
<h2>Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts. (arXiv:2102.08981v1 [cs.CV])</h2>
<h3>Soravit Changpinyo, Piyush Sharma, Nan Ding, Radu Soricut</h3>
<p>The availability of large-scale image captioning and visual question
answering datasets has contributed significantly to recent successes in
vision-and-language pre-training. However, these datasets are often collected
with overrestrictive requirements, inherited from their original target tasks
(e.g., image caption generation), which limit the resulting dataset scale and
diversity. We take a step further in pushing the limits of vision-and-language
pre-training data by relaxing the data collection pipeline used in Conceptual
Captions 3M (CC3M) [Sharma et al. 2018] and introduce the Conceptual 12M
(CC12M), a dataset with 12 million image-text pairs specifically meant to be
used for vision-and-language pre-training. We perform an analysis of this
dataset, as well as benchmark its effectiveness against CC3M on multiple
downstream tasks with an emphasis on long-tail visual recognition. The
quantitative and qualitative results clearly illustrate the benefit of scaling
up pre-training data for vision-and-language tasks, as indicated by the new
state-of-the-art results on both the nocaps and Conceptual Captions benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.08981" target="_blank">arXiv:2102.08981</a> [<a href="http://arxiv.org/pdf/2102.08981" target="_blank">pdf</a>]

<h2>Automated Detection of Equine Facial Action Units. (arXiv:2102.08983v1 [cs.CV])</h2>
<h3>Zhenghong Li, Sofia Broom&#xe9;, Pia Haubro Andersen, Hedvig Kjellstr&#xf6;m</h3>
<p>The recently developed Equine Facial Action Coding System (EquiFACS) provides
a precise and exhaustive, but laborious, manual labelling method of facial
action units of the horse. To automate parts of this process, we propose a Deep
Learning-based method to detect EquiFACS units automatically from images. We
use a cascade framework; we firstly train several object detectors to detect
the predefined Region-of-Interest (ROI), and secondly apply binary classifiers
for each action unit in related regions. We experiment with both regular CNNs
and a more tailored model transferred from human facial action unit
recognition. Promising initial results are presented for nine action units in
the eye and lower face regions.
</p>
<a href="http://arxiv.org/abs/2102.08983" target="_blank">arXiv:2102.08983</a> [<a href="http://arxiv.org/pdf/2102.08983" target="_blank">pdf</a>]

<h2>BEDS: Bagging ensemble deep segmentation for nucleus segmentation with testing stage stain augmentation. (arXiv:2102.08990v1 [cs.CV])</h2>
<h3>Xing Li, Haichun Yang, Jiaxin He, Aadarsh Jha, Agnes B. Fogo, Lee E. Wheless, Shilin Zhao, Yuankai Huo</h3>
<p>Reducing outcome variance is an essential task in deep learning based medical
image analysis. Bootstrap aggregating, also known as bagging, is a canonical
ensemble algorithm for aggregating weak learners to become a strong learner.
Random forest is one of the most powerful machine learning algorithms before
deep learning era, whose superior performance is driven by fitting bagged
decision trees (weak learners). Inspired by the random forest technique, we
propose a simple bagging ensemble deep segmentation (BEDs) method to train
multiple U-Nets with partial training data to segment dense nuclei on
pathological images. The contributions of this study are three-fold: (1)
developing a self-ensemble learning framework for nucleus segmentation; (2)
aggregating testing stage augmentation with self-ensemble learning; and (3)
elucidating the idea that self-ensemble and testing stage stain augmentation
are complementary strategies for a superior segmentation performance.
Implementation Detail: https://github.com/xingli1102/BEDs.
</p>
<a href="http://arxiv.org/abs/2102.08990" target="_blank">arXiv:2102.08990</a> [<a href="http://arxiv.org/pdf/2102.08990" target="_blank">pdf</a>]

<h2>Using Distance Correlation for Efficient Bayesian Optimization. (arXiv:2102.08993v1 [cs.LG])</h2>
<h3>Takuya Kanazawa</h3>
<p>We propose a novel approach for Bayesian optimization, called
$\textsf{GP-DC}$, which combines Gaussian processes with distance correlation.
It balances exploration and exploitation automatically, and requires no manual
parameter tuning. We evaluate $\textsf{GP-DC}$ on a number of benchmark
functions and observe that it outperforms state-of-the-art methods such as
$\textsf{GP-UCB}$ and max-value entropy search, as well as the classical
expected improvement heuristic. We also apply $\textsf{GP-DC}$ to optimize
sequential integral observations with a variable integration range and verify
its empirical efficiency on both synthetic and real-world datasets.
</p>
<a href="http://arxiv.org/abs/2102.08993" target="_blank">arXiv:2102.08993</a> [<a href="http://arxiv.org/pdf/2102.08993" target="_blank">pdf</a>]

<h2>One-shot action recognition towards novel assistive therapies. (arXiv:2102.08997v1 [cs.CV])</h2>
<h3>Alberto Sabater, Laura Santos, Jose Santos-Victor, Alexandre Bernardino, Luis Montesano, Ana C. Murillo</h3>
<p>One-shot action recognition is a challenging problem, especially when the
target video can contain one, more or none repetitions of the target action.
Solutions to this problem can be used in many real world applications that
require automated processing of activity videos. In particular, this work is
motivated by the automated analysis of medical therapies that involve action
imitation games. The presented approach incorporates a pre-processing step that
standardizes heterogeneous motion data conditions and generates descriptive
movement representations with a Temporal Convolutional Network for a final
one-shot (or few-shot) action recognition. Our method achieves state-of-the-art
results on the public NTU-120 one-shot action recognition challenge. Besides,
we evaluate the approach on a real use-case of automated video analysis for
therapy support with autistic people. The promising results prove its
suitability for this kind of application in the wild, providing both
quantitative and qualitative measures, essential for the patient evaluation and
monitoring.
</p>
<a href="http://arxiv.org/abs/2102.08997" target="_blank">arXiv:2102.08997</a> [<a href="http://arxiv.org/pdf/2102.08997" target="_blank">pdf</a>]

<h2>Mobile Computational Photography: A Tour. (arXiv:2102.09000v1 [cs.CV])</h2>
<h3>Mauricio Delbracio, Damien Kelly, Michael S. Brown, Peyman Milanfar</h3>
<p>The first mobile camera phone was sold only 20 years ago, when taking
pictures with one's phone was an oddity, and sharing pictures online was
unheard of. Today, the smartphone is more camera than phone. How did this
happen? This transformation was enabled by advances in computational
photography -the science and engineering of making great images from small form
factor, mobile cameras. Modern algorithmic and computing advances, including
machine learning, have changed the rules of photography, bringing to it new
modes of capture, post-processing, storage, and sharing. In this paper, we give
a brief history of mobile computational photography and describe some of the
key technological components, including burst photography, noise reduction, and
super-resolution. At each step, we may draw naive parallels to the human visual
system.
</p>
<a href="http://arxiv.org/abs/2102.09000" target="_blank">arXiv:2102.09000</a> [<a href="http://arxiv.org/pdf/2102.09000" target="_blank">pdf</a>]

<h2>Domain Impression: A Source Data Free Domain Adaptation Method. (arXiv:2102.09003v1 [cs.CV])</h2>
<h3>Vinod K Kurmi, Venkatesh K Subramanian, Vinay P Namboodiri</h3>
<p>Unsupervised Domain adaptation methods solve the adaptation problem for an
unlabeled target set, assuming that the source dataset is available with all
labels. However, the availability of actual source samples is not always
possible in practical cases. It could be due to memory constraints, privacy
concerns, and challenges in sharing data. This practical scenario creates a
bottleneck in the domain adaptation problem. This paper addresses this
challenging scenario by proposing a domain adaptation technique that does not
need any source data. Instead of the source data, we are only provided with a
classifier that is trained on the source data. Our proposed approach is based
on a generative framework, where the trained classifier is used for generating
samples from the source classes. We learn the joint distribution of data by
using the energy-based modeling of the trained classifier. At the same time, a
new classifier is also adapted for the target domain. We perform various
ablation analysis under different experimental setups and demonstrate that the
proposed approach achieves better results than the baseline models in this
extremely novel scenario.
</p>
<a href="http://arxiv.org/abs/2102.09003" target="_blank">arXiv:2102.09003</a> [<a href="http://arxiv.org/pdf/2102.09003" target="_blank">pdf</a>]

<h2>An Efficient Diagnosis Algorithm for Inconsistent Constraint Sets. (arXiv:2102.09005v1 [cs.AI])</h2>
<h3>Alexander Felfernig, Monika Schubert, Christoph Zehentner</h3>
<p>Constraint sets can become inconsistent in different contexts. For example,
during a configuration session the set of customer requirements can become
inconsistent with the configuration knowledge base. Another example is the
engineering phase of a configuration knowledge base where the underlying
constraints can become inconsistent with a set of test cases. In such
situations we are in the need of techniques that support the identification of
minimal sets of faulty constraints that have to be deleted in order to restore
consistency. In this paper we introduce a divide-and-conquer based diagnosis
algorithm (FastDiag) which identifies minimal sets of faulty constraints in an
over-constrained problem. This algorithm is specifically applicable in
scenarios where the efficient identification of leading (preferred) diagnoses
is crucial. We compare the performance of FastDiag with the conflict-directed
calculation of hitting sets and present an in-depth performance analysis that
shows the advantages of our approach.
</p>
<a href="http://arxiv.org/abs/2102.09005" target="_blank">arXiv:2102.09005</a> [<a href="http://arxiv.org/pdf/2102.09005" target="_blank">pdf</a>]

<h2>BORE: Bayesian Optimization by Density-Ratio Estimation. (arXiv:2102.09009v1 [cs.LG])</h2>
<h3>Louis C. Tiao, Aaron Klein, Matthias Seeger, Edwin V. Bonilla, Cedric Archambeau, Fabio Ramos</h3>
<p>Bayesian optimization (BO) is among the most effective and widely-used
blackbox optimization methods. BO proposes solutions according to an
explore-exploit trade-off criterion encoded in an acquisition function, many of
which are computed from the posterior predictive of a probabilistic surrogate
model. Prevalent among these is the expected improvement (EI) function. The
need to ensure analytical tractability of the predictive often poses
limitations that can hinder the efficiency and applicability of BO. In this
paper, we cast the computation of EI as a binary classification problem,
building on the link between class-probability estimation and density-ratio
estimation, and the lesser-known link between density-ratios and EI. By
circumventing the tractability constraints, this reformulation provides
numerous advantages, not least in terms of expressiveness, versatility, and
scalability.
</p>
<a href="http://arxiv.org/abs/2102.09009" target="_blank">arXiv:2102.09009</a> [<a href="http://arxiv.org/pdf/2102.09009" target="_blank">pdf</a>]

<h2>Improving Hierarchical Adversarial Robustness of Deep Neural Networks. (arXiv:2102.09012v1 [cs.LG])</h2>
<h3>Avery Ma, Aladin Virmaux, Kevin Scaman, Juwei Lu</h3>
<p>Do all adversarial examples have the same consequences? An autonomous driving
system misclassifying a pedestrian as a car may induce a far more dangerous --
and even potentially lethal -- behavior than, for instance, a car as a bus. In
order to better tackle this important problematic, we introduce the concept of
hierarchical adversarial robustness. Given a dataset whose classes can be
grouped into coarse-level labels, we define hierarchical adversarial examples
as the ones leading to a misclassification at the coarse level. To improve the
resistance of neural networks to hierarchical attacks, we introduce a
hierarchical adversarially robust (HAR) network design that decomposes a single
classification task into one coarse and multiple fine classification tasks,
before being specifically trained by adversarial defense techniques. As an
alternative to an end-to-end learning approach, we show that HAR significantly
improves the robustness of the network against $\ell_2$ and $\ell_{\infty}$
bounded hierarchical attacks on the CIFAR-10 and CIFAR-100 dataset.
</p>
<a href="http://arxiv.org/abs/2102.09012" target="_blank">arXiv:2102.09012</a> [<a href="http://arxiv.org/pdf/2102.09012" target="_blank">pdf</a>]

<h2>A Visibility Roadmap Sampling Approach for a Multi-Robot Visibility-Based Pursuit-Evasion Problem. (arXiv:2102.09013v1 [cs.RO])</h2>
<h3>Trevor Olsen, Anne M. Tumlin, Nicholas M. Stiffler, Jason M. O&#x27;Kane</h3>
<p>Given a two-dimensional polygonal space, the multi-robot visibility-based
pursuit-evasion problem tasks several pursuer robots with the goal of
establishing visibility with an arbitrarily fast evader. The best known
complete algorithm for this problem takes time doubly exponential in the number
of robots. However, sampling-based techniques have shown promise in generating
feasible solutions in these scenarios. One of the primary drawbacks to
employing existing sampling-based methods is that existing algorithms have long
execution times and high failure rates for complex environments. This paper
addresses that limitation by proposing a new algorithm that takes an
environment as its input and returns a joint motion strategy which ensures that
the evader is captured by one of the pursuers. Starting with a single pursuer,
we sequentially construct Sample-Generated Pursuit-Evasion Graphs to create
such a joint motion strategy. This sequential graph structure ensures that our
algorithm will always terminate with a solution, regardless of the complexity
of the environment. We describe an implementation of this algorithm and present
quantitative results that show significant improvement in comparison to the
existing algorithm.
</p>
<a href="http://arxiv.org/abs/2102.09013" target="_blank">arXiv:2102.09013</a> [<a href="http://arxiv.org/pdf/2102.09013" target="_blank">pdf</a>]

<h2>Estimate Three-Phase Distribution Line Parameters With Physics-Informed Graphical Learning Method. (arXiv:2102.09023v1 [cs.LG])</h2>
<h3>Wenyu Wang, Nanpeng Yu</h3>
<p>Accurate estimates of network parameters are essential for modeling,
monitoring, and control in power distribution systems. In this paper, we
develop a physics-informed graphical learning algorithm to estimate network
parameters of three-phase power distribution systems. Our proposed algorithm
uses only readily available smart meter data to estimate the three-phase series
resistance and reactance of the primary distribution line segments. We first
develop a parametric physics-based model to replace the black-box deep neural
networks in the conventional graphical neural network (GNN). Then we derive the
gradient of the loss function with respect to the network parameters and use
stochastic gradient descent (SGD) to estimate the physical parameters. Prior
knowledge of network parameters is also considered to further improve the
accuracy of estimation. Comprehensive numerical study results show that our
proposed algorithm yields high accuracy and outperforms existing methods.
</p>
<a href="http://arxiv.org/abs/2102.09023" target="_blank">arXiv:2102.09023</a> [<a href="http://arxiv.org/pdf/2102.09023" target="_blank">pdf</a>]

<h2>Deep Learning Approaches for Forecasting Strawberry Yields and Prices Using Satellite Images and Station-Based Soil Parameters. (arXiv:2102.09024v1 [cs.LG])</h2>
<h3>Mohita Chaudhary, Mohamed Sadok Gastli, Lobna Nassar, Fakhri Karray</h3>
<p>Computational tools for forecasting yields and prices for fresh produce have
been based on traditional machine learning approaches or time series modelling.
We propose here an alternate approach based on deep learning algorithms for
forecasting strawberry yields and prices in Santa Barbara county, California.
Building the proposed forecasting model comprises three stages: first, the
station-based ensemble model (ATT-CNN-LSTM-SeriesNet_Ens) with its compound
deep learning components, SeriesNet with Gated Recurrent Unit (GRU) and
Convolutional Neural Network LSTM with Attention layer (Att-CNN-LSTM), are
trained and tested using the station-based soil temperature and moisture data
of SantaBarbara as input and the corresponding strawberry yields or prices as
output. Secondly, the remote sensing ensemble model (SIM_CNN-LSTM_Ens), which
is an ensemble model of Convolutional NeuralNetwork LSTM (CNN-LSTM) models, is
trained and tested using satellite images of the same county as input mapped to
the same yields and prices as output. These two ensembles forecast strawberry
yields and prices with minimal forecasting errors and highest model correlation
for five weeks ahead forecasts.Finally, the forecasts of these two models are
ensembled to have a final forecasted value for yields and prices by introducing
a voting ensemble. Based on an aggregated performance measure (AGM), it is
found that this voting ensemble not only enhances the forecasting performance
by 5% compared to its best performing component model but also outperforms the
Deep Learning (DL) ensemble model found in literature by 33% for forecasting
yields and 21% for forecasting prices
</p>
<a href="http://arxiv.org/abs/2102.09024" target="_blank">arXiv:2102.09024</a> [<a href="http://arxiv.org/pdf/2102.09024" target="_blank">pdf</a>]

<h2>Optimizing Large-Scale Hyperparameters via Automated Learning Algorithm. (arXiv:2102.09026v1 [cs.LG])</h2>
<h3>Bin Gu, Guodong Liu, Yanfu Zhang, Xiang Geng, Heng Huang</h3>
<p>Modern machine learning algorithms usually involve tuning multiple (from one
to thousands) hyperparameters which play a pivotal role in terms of model
generalizability. Black-box optimization and gradient-based algorithms are two
dominant approaches to hyperparameter optimization while they have totally
distinct advantages. How to design a new hyperparameter optimization technique
inheriting all benefits from both approaches is still an open problem. To
address this challenging problem, in this paper, we propose a new
hyperparameter optimization method with zeroth-order hyper-gradients (HOZOG).
Specifically, we first exactly formulate hyperparameter optimization as an
A-based constrained optimization problem, where A is a black-box optimization
algorithm (such as deep neural network). Then, we use the average zeroth-order
hyper-gradients to update hyperparameters. We provide the feasibility analysis
of using HOZOG to achieve hyperparameter optimization. Finally, the
experimental results on three representative hyperparameter (the size is from 1
to 1250) optimization tasks demonstrate the benefits of HOZOG in terms of
simplicity, scalability, flexibility, effectiveness and efficiency compared
with the state-of-the-art hyperparameter optimization methods.
</p>
<a href="http://arxiv.org/abs/2102.09026" target="_blank">arXiv:2102.09026</a> [<a href="http://arxiv.org/pdf/2102.09026" target="_blank">pdf</a>]

<h2>Differential Private Hogwild! over Distributed Local Data Sets. (arXiv:2102.09030v1 [cs.LG])</h2>
<h3>Marten van Dijk, Nhuong V. Nguyen, Toan N. Nguyen, Lam M. Nguyen, Phuong Ha Nguyen</h3>
<p>We consider the Hogwild! setting where clients use local SGD iterations with
Gaussian based Differential Privacy (DP) for their own local data sets with the
aim of (1) jointly converging to a global model (by interacting at a round to
round basis with a centralized server that aggregates local SGD updates into a
global model) while (2) keeping each local data set differentially private with
respect to the outside world (this includes all other clients who can monitor
client-server interactions). We show for a broad class of sample size sequences
(this defines the number of local SGD iterations for each round) that a local
data set is $(\epsilon,\delta)$-DP if the standard deviation $\sigma$ of the
added Gaussian noise per round interaction with the centralized server is at
least $\sqrt{2(\epsilon+ \ln(1/\delta))/\epsilon}$.
</p>
<a href="http://arxiv.org/abs/2102.09030" target="_blank">arXiv:2102.09030</a> [<a href="http://arxiv.org/pdf/2102.09030" target="_blank">pdf</a>]

<h2>Deep Extreme Value Copulas for Estimation and Sampling. (arXiv:2102.09042v1 [stat.ML])</h2>
<h3>Ali Hasan, Khalil Elkhalil, Joao M. Pereira, Sina Farsiu, Jose H. Blanchet, Vahid Tarokh</h3>
<p>We propose a new method for modeling the distribution function of high
dimensional extreme value distributions. The Pickands dependence function
models the relationship between the covariates in the tails, and we learn this
function using a neural network that is designed to satisfy its required
properties. Moreover, we present new methods for recovering the spectral
representation of extreme distributions and propose a generative model for
sampling from extreme copulas. Numerical examples are provided demonstrating
the efficacy and promise of our proposed methods.
</p>
<a href="http://arxiv.org/abs/2102.09042" target="_blank">arXiv:2102.09042</a> [<a href="http://arxiv.org/pdf/2102.09042" target="_blank">pdf</a>]

<h2>Communication-free Cohesive Flexible-Object Transport using Decentralized Robot Networks. (arXiv:2102.09056v1 [cs.RO])</h2>
<h3>Yoshua Gombo, Anuj Tiwari, Santosh Devasia</h3>
<p>Decentralized network theories focus on achieving consensus and in speeding
up the rate of convergence to consensus. However, network cohesion (i.e.,
maintaining consensus) during transitions between consensus values is also
important when transporting flexible structures. Deviations in the robot
positions due to loss of cohesion when moving flexible structures from one
position to another, such as uncuredcomposite aircraft wings, can cause large
deformations, which in turn, can result in potential damage. The major
contribution of this work is to develop a decentralized approach to transport
flexible objects in a cohesive manner using local force measurements, without
the need for additional communication between the robots. Additionally,
stability conditions are developed for discrete-time implementation of the
proposed cohesive transition approach, and experimental results are presented,
which show that the proposed cohesive transportation approach can reduce the
relative deformations by 85% when compared to the case without it.
</p>
<a href="http://arxiv.org/abs/2102.09056" target="_blank">arXiv:2102.09056</a> [<a href="http://arxiv.org/pdf/2102.09056" target="_blank">pdf</a>]

<h2>Grid Cell Path Integration For Movement-Based Visual Object Recognition. (arXiv:2102.09076v1 [cs.AI])</h2>
<h3>Niels Leadholm (1 and 2), Marcus Lewis (1), Subutai Ahmad (1) ((1) Numenta, (2) The University of Oxford)</h3>
<p>Grid cells enable the brain to model the physical space of the world and
navigate effectively via path integration, updating self-position using
information from self-movement. Recent proposals suggest that the brain might
use similar mechanisms to understand the structure of objects in diverse
sensory modalities, including vision. In machine vision, object recognition
given a sequence of sensory samples of an image, such as saccades, is a
challenging problem when the sequence does not follow a consistent, fixed
pattern - yet this is something humans do naturally and effortlessly. We
explore how grid cell-based path integration in a cortical network can support
reliable recognition of objects given an arbitrary sequence of inputs. Our
network (GridCellNet) uses grid cell computations to integrate visual
information and make predictions based on movements. We use local Hebbian
plasticity rules to learn rapidly from a handful of examples (few-shot
learning), and consider the task of recognizing MNIST digits given only a
sequence of image feature patches. We compare GridCellNet to k-Nearest
Neighbour (k-NN) classifiers as well as recurrent neural networks (RNNs), both
of which lack explicit mechanisms for handling arbitrary sequences of input
samples. We show that GridCellNet can reliably perform classification,
generalizing to both unseen examples and completely novel sequence
trajectories. We further show that inference is often successful after sampling
a fraction of the input space, enabling the predictive GridCellNet to
reconstruct the rest of the image given just a few movements. We propose that
dynamically moving agents with active sensors can use grid cell representations
not only for navigation, but also for efficient recognition and feature
prediction of seen objects.
</p>
<a href="http://arxiv.org/abs/2102.09076" target="_blank">arXiv:2102.09076</a> [<a href="http://arxiv.org/pdf/2102.09076" target="_blank">pdf</a>]

<h2>Consistent Non-Parametric Methods for Adaptive Robustness. (arXiv:2102.09086v1 [cs.LG])</h2>
<h3>Robi Bhattacharjee, Kamalika Chaudhuri</h3>
<p>Learning classifiers that are robust to adversarial examples has received a
great deal of recent attention. A major drawback of the standard robust
learning framework is the imposition of an artificial robustness radius $r$
that applies to all inputs, and ignores the fact that data may be highly
heterogeneous. In this paper, we address this limitation by proposing a new
framework for adaptive robustness, called neighborhood preserving robustness.
We present sufficient conditions under which general non-parametric methods
that can be represented as weight functions satisfy our notion of robustness,
and show that both nearest neighbors and kernel classifiers satisfy these
conditions in the large sample limit.
</p>
<a href="http://arxiv.org/abs/2102.09086" target="_blank">arXiv:2102.09086</a> [<a href="http://arxiv.org/pdf/2102.09086" target="_blank">pdf</a>]

<h2>NuCLS: A scalable crowdsourcing, deep learning approach and dataset for nucleus classification, localization and segmentation. (arXiv:2102.09099v1 [cs.CV])</h2>
<h3>Mohamed Amgad (1), Lamees A. Atteya (2), Hagar Hussein (3), Kareem Hosny Mohammed (4), Ehab Hafiz (5), Maha A.T. Elsebaie (6), Ahmed M. Alhusseiny (7), Mohamed Atef AlMoslemany (8), Abdelmagid M. Elmatboly (9), Philip A. Pappalardo (10), Rokia Adel Sakr (11), Pooya Mobadersany (1), Ahmad Rachid (12), Anas M. Saad (13), Ahmad M. Alkashash (14), Inas A. Ruhban (15), Anas Alrefai (12), Nada M. Elgazar (16), Ali Abdulkarim (17), Abo-Alela Farag (12), Amira Etman (8), Ahmed G. Elsaeed (16), Yahya Alagha (17), Yomna A. Amer (8), Ahmed M. Raslan (18), Menatalla K. Nadim (19), Mai A.T. Elsebaie (12), Ahmed Ayad (20), Liza E. Hanna (3), Ahmed Gadallah (12), Mohamed Elkady (21), Bradley Drumheller (22), David Jaye (22), David Manthey (23), David A. Gutman (24), Habiba Elfandy (25, 26), Lee A.D. Cooper (1, 27, 28) ((1) Department of Pathology, Northwestern University, Chicago, IL, USA, (2) Cairo Health Care Administration, Egyptian Ministry of Health, Cairo, Egypt, (3) Department of Pathology, Nasser institute for research and treatment, Cairo, Egypt, (4) Department of Pathology and Laboratory Medicine, University of Pennsylvania, PA, USA, (5) Department of Clinical Laboratory Research, Theodor Bilharz Research Institute, Giza, Egypt, (6) Department of Medicine, Cook County Hospital, Chicago, IL, USA, (7) Department of Pathology, Baystate Medical Center, University of Massachusetts, Springfield, MA, USA, (8) Faculty of Medicine, Menoufia University, Menoufia, Egypt, (9) Faculty of Medicine, Al-Azhar University, Cairo, Egypt, (10) Consultant for The Center for Applied Proteomics and Molecular Medicine (CAPMM), George Mason University, Manassas, VA, USA, (11) Department of Pathology, National Liver Institute, Menoufia University, Menoufia, Egypt, (12) Faculty of Medicine, Ain Shams University, Cairo, Egypt, (13) Cleveland Clinic Foundation, Cleveland, OH, USA, (14) Department of Pathology, Indiana University, Indianapolis, IN, USA, (15) Faculty of Medicine, Damascus University, Damascus, Syria, (16) Faculty of Medicine, Mansoura University, Mansoura, Egypt, (17) Faculty of Medicine, Cairo University, Cairo, Egypt, (18) Department of Anaesthesia and Critical Care, Menoufia University Hospital, Menoufia, Egypt, (19) Department of Clinical Pathology, Ain Shams University, Cairo, Egypt, (20) Research Department, Oncology Consultants, PA, Houston, TX, USA, (21) Siparadigm Diagnostic Informatics, Pine Brook, NJ, USA, (22) Department of Pathology and Laboratory Medicine, Emory University School of Medicine, Atlanta, GA, USA, (23) Kitware Inc., Clifton Park, NY, USA, (24) Department of Neurology, Emory University School of Medicine, Atlanta, GA, USA, (25) Department of Pathology, National Cancer Institute, Cairo, Egypt, (26) Department of Pathology, Children&#x27;s Cancer Hospital Egypt CCHE 57357, Cairo, Egypt, (27) Lurie Cancer Center, Northwestern University, Chicago, IL, USA, (28) Center for Computational Imaging and Signal Analytics, Northwestern University Feinberg School of Medicine, Chicago, IL, USA)</h3>
<p>High-resolution mapping of cells and tissue structures provides a foundation
for developing interpretable machine-learning models for computational
pathology. Deep learning algorithms can provide accurate mappings given large
numbers of labeled instances for training and validation. Generating adequate
volume of quality labels has emerged as a critical barrier in computational
pathology given the time and effort required from pathologists. In this paper
we describe an approach for engaging crowds of medical students and
pathologists that was used to produce a dataset of over 220,000 annotations of
cell nuclei in breast cancers. We show how suggested annotations generated by a
weak algorithm can improve the accuracy of annotations generated by non-experts
and can yield useful data for training segmentation algorithms without
laborious manual tracing. We systematically examine interrater agreement and
describe modifications to the MaskRCNN model to improve cell mapping. We also
describe a technique we call Decision Tree Approximation of Learned Embeddings
(DTALE) that leverages nucleus segmentations and morphologic features to
improve the transparency of nucleus classification models. The annotation data
produced in this study are freely available for algorithm development and
benchmarking at: https://sites.google.com/view/nucls.
</p>
<a href="http://arxiv.org/abs/2102.09099" target="_blank">arXiv:2102.09099</a> [<a href="http://arxiv.org/pdf/2102.09099" target="_blank">pdf</a>]

<h2>No-Substitution $k$-means Clustering with Low Center Complexity and Memory. (arXiv:2102.09101v1 [cs.LG])</h2>
<h3>Robi Bhattacharjee, Jacob Imola</h3>
<p>Clustering is a fundamental task in machine learning. Given a dataset $X =
\{x_1, \ldots x_n\}$, the goal of $k$-means clustering is to pick $k$ "centers"
from $X$ in a way that minimizes the sum of squared distances from each point
to its nearest center. We consider $k$-means clustering in the online, no
substitution setting, where one must decide whether to take $x_t$ as a center
immediately upon streaming it and cannot remove centers once taken.

The online, no substitution setting is challenging for clustering--one can
show that there exist datasets $X$ for which any $O(1)$-approximation $k$-means
algorithm must have center complexity $\Omega(n)$, meaning that it takes
$\Omega(n)$ centers in expectation. Bhattacharjee and Moshkovitz (2020) refined
this bound by defining a complexity measure called $Lower_{\alpha, k}(X)$, and
proving that any $\alpha$-approximation algorithm must have center complexity
$\Omega(Lower_{\alpha, k}(X))$. They then complemented their lower bound by
giving a $O(k^3)$-approximation algorithm with center complexity
$\tilde{O}(k^2Lower_{k^3, k}(X))$, thus showing that their parameter is a tight
measure of required center complexity. However, a major drawback of their
algorithm is its memory requirement, which is $O(n)$. This makes the algorithm
impractical for very large datasets.

In this work, we strictly improve upon their algorithm on all three fronts;
we develop a $36$-approximation algorithm with center complexity
$\tilde{O}(kLower_{36, k}(X))$ that uses only $O(k)$ additional memory. In
addition to having nearly optimal memory, this algorithm is the first known
algorithm with center complexity bounded by $Lower_{36, k}(X)$ that is a true
$O(1)$-approximation with its approximation factor being independent of $k$ or
$n$.
</p>
<a href="http://arxiv.org/abs/2102.09101" target="_blank">arXiv:2102.09101</a> [<a href="http://arxiv.org/pdf/2102.09101" target="_blank">pdf</a>]

<h2>Distributed Algorithms for Linearly-Solvable Optimal Control in Networked Multi-Agent Systems. (arXiv:2102.09104v1 [cs.LG])</h2>
<h3>Neng Wan, Aditya Gahlawat, Naira Hovakimyan, Evangelos A. Theodorou, Petros G. Voulgaris</h3>
<p>Distributed algorithms for both discrete-time and continuous-time linearly
solvable optimal control (LSOC) problems of networked multi-agent systems
(MASs) are investigated in this paper. A distributed framework is proposed to
partition the optimal control problem of a networked MAS into several local
optimal control problems in factorial subsystems, such that each (central)
agent behaves optimally to minimize the joint cost function of a subsystem that
comprises a central agent and its neighboring agents, and the local control
actions (policies) only rely on the knowledge of local observations. Under this
framework, we not only preserve the correlations between neighboring agents,
but moderate the communication and computational complexities by decentralizing
the sampling and computational processes over the network. For discrete-time
systems modeled by Markov decision processes, the joint Bellman equation of
each subsystem is transformed into a system of linear equations and solved
using parallel programming. For continuous-time systems modeled by It\^o
diffusion processes, the joint optimality equation of each subsystem is
converted into a linear partial differential equation, whose solution is
approximated by a path integral formulation and a sample-efficient relative
entropy policy search algorithm, respectively. The learned control policies are
generalized to solve the unlearned tasks by resorting to the compositionality
principle, and illustrative examples of cooperative UAV teams are provided to
verify the effectiveness and advantages of these algorithms.
</p>
<a href="http://arxiv.org/abs/2102.09104" target="_blank">arXiv:2102.09104</a> [<a href="http://arxiv.org/pdf/2102.09104" target="_blank">pdf</a>]

<h2>DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes with Biharmonic Coordinates. (arXiv:2102.09105v1 [cs.CV])</h2>
<h3>Minghua Liu, Minhyuk Sung, Radomir Mech, Hao Su</h3>
<p>We propose DeepMetaHandles, a 3D conditional generative model based on mesh
deformation. Given a collection of 3D meshes of a category and their
deformation handles (control points), our method learns a set of meta-handles
for each shape, which are represented as combinations of the given handles. The
disentangled meta-handles factorize all the plausible deformations of the
shape, while each of them corresponds to an intuitive deformation. A new
deformation can then be generated by sampling the coefficients of the
meta-handles in a specific range. We employ biharmonic coordinates as the
deformation function, which can smoothly propagate the control points'
translations to the entire mesh. To avoid learning zero deformation as
meta-handles, we incorporate a target-fitting module which deforms the input
mesh to match a random target. To enhance deformations' plausibility, we employ
a soft-rasterizer-based discriminator that projects the meshes to a 2D space.
Our experiments demonstrate the superiority of the generated deformations as
well as the interpretability and consistency of the learned meta-handles.
</p>
<a href="http://arxiv.org/abs/2102.09105" target="_blank">arXiv:2102.09105</a> [<a href="http://arxiv.org/pdf/2102.09105" target="_blank">pdf</a>]

<h2>Understanding and Creating Art with AI: Review and Outlook. (arXiv:2102.09109v1 [cs.CV])</h2>
<h3>Eva Cetinic, James She</h3>
<p>Technologies related to artificial intelligence (AI) have a strong impact on
the changes of research and creative practices in visual arts. The growing
number of research initiatives and creative applications that emerge in the
intersection of AI and art, motivates us to examine and discuss the creative
and explorative potentials of AI technologies in the context of art. This paper
provides an integrated review of two facets of AI and art: 1) AI is used for
art analysis and employed on digitized artwork collections; 2) AI is used for
creative purposes and generating novel artworks. In the context of AI-related
research for art understanding, we present a comprehensive overview of artwork
datasets and recent works that address a variety of tasks such as
classification, object detection, similarity retrieval, multimodal
representations, computational aesthetics, etc. In relation to the role of AI
in creating art, we address various practical and theoretical aspects of AI Art
and consolidate related works that deal with those topics in detail. Finally,
we provide a concise outlook on the future progression and potential impact of
AI technologies on our understanding and creation of art.
</p>
<a href="http://arxiv.org/abs/2102.09109" target="_blank">arXiv:2102.09109</a> [<a href="http://arxiv.org/pdf/2102.09109" target="_blank">pdf</a>]

<h2>Spatio-Temporal Graph Dual-Attention Network for Multi-Agent Prediction and Tracking. (arXiv:2102.09117v1 [cs.CV])</h2>
<h3>Jiachen Li, Hengbo Ma, Zhihao Zhang, Jinning Li, Masayoshi Tomizuka</h3>
<p>An effective understanding of the environment and accurate trajectory
prediction of surrounding dynamic obstacles are indispensable for intelligent
mobile systems (e.g. autonomous vehicles and social robots) to achieve safe and
high-quality planning when they navigate in highly interactive and crowded
scenarios. Due to the existence of frequent interactions and uncertainty in the
scene evolution, it is desired for the prediction system to enable relational
reasoning on different entities and provide a distribution of future
trajectories for each agent. In this paper, we propose a generic generative
neural system (called STG-DAT) for multi-agent trajectory prediction involving
heterogeneous agents. The system takes a step forward to explicit interaction
modeling by incorporating relational inductive biases with a dynamic graph
representation and leverages both trajectory and scene context information. We
also employ an efficient kinematic constraint layer applied to vehicle
trajectory prediction. The constraint not only ensures physical feasibility but
also enhances model performance. Moreover, the proposed prediction model can be
easily adopted by multi-target tracking frameworks. The tracking accuracy
proves to be improved by empirical results. The proposed system is evaluated on
three public benchmark datasets for trajectory prediction, where the agents
cover pedestrians, cyclists and on-road vehicles. The experimental results
demonstrate that our model achieves better performance than various baseline
approaches in terms of prediction and tracking accuracy.
</p>
<a href="http://arxiv.org/abs/2102.09117" target="_blank">arXiv:2102.09117</a> [<a href="http://arxiv.org/pdf/2102.09117" target="_blank">pdf</a>]

<h2>Learning Invariant Representation of Tasks for Robust Surgical State Estimation. (arXiv:2102.09119v1 [cs.RO])</h2>
<h3>Yidan Qin, Max Allan, Yisong Yue, Joel W. Burdick, Mahdi Azizian</h3>
<p>Surgical state estimators in robot-assisted surgery (RAS) - especially those
trained via learning techniques - rely heavily on datasets that capture surgeon
actions in laboratory or real-world surgical tasks. Real-world RAS datasets are
costly to acquire, are obtained from multiple surgeons who may use different
surgical strategies, and are recorded under uncontrolled conditions in highly
complex environments. The combination of high diversity and limited data calls
for new learning methods that are robust and invariant to operating conditions
and surgical techniques. We propose StiseNet, a Surgical Task Invariance State
Estimation Network with an invariance induction framework that minimizes the
effects of variations in surgical technique and operating environments inherent
to RAS datasets. StiseNet's adversarial architecture learns to separate
nuisance factors from information needed for surgical state estimation.
StiseNet is shown to outperform state-of-the-art state estimation methods on
three datasets (including a new real-world RAS dataset: HERNIA-20).
</p>
<a href="http://arxiv.org/abs/2102.09119" target="_blank">arXiv:2102.09119</a> [<a href="http://arxiv.org/pdf/2102.09119" target="_blank">pdf</a>]

<h2>FrugalMCT: Efficient Online ML API Selection for Multi-Label Classification Tasks. (arXiv:2102.09127v1 [cs.LG])</h2>
<h3>Lingjiao Chen, Matei Zaharia, James Zou</h3>
<p>Multi-label classification tasks such as OCR and multi-object recognition are
a major focus of the growing machine learning as a service industry. While many
multi-label prediction APIs are available, it is challenging for users to
decide which API to use for their own data and budget, due to the heterogeneity
in those APIs' price and performance. Recent work shows how to select from
single-label prediction APIs. However the computation complexity of the
previous approach is exponential in the number of labels and hence is not
suitable for settings like OCR. In this work, we propose FrugalMCT, a
principled framework that adaptively selects the APIs to use for different data
in an online fashion while respecting user's budget. The API selection problem
is cast as an integer linear program, which we show has a special structure
that we leverage to develop an efficient online API selector with strong
performance guarantees. We conduct systematic experiments using ML APIs from
Google, Microsoft, Amazon, IBM, Tencent and other providers for tasks including
multi-label image classification, scene text recognition and named entity
recognition. Across diverse tasks, FrugalMCT can achieve over 90% cost
reduction while matching the accuracy of the best single API, or up to 8%
better accuracy while matching the best API's cost.
</p>
<a href="http://arxiv.org/abs/2102.09127" target="_blank">arXiv:2102.09127</a> [<a href="http://arxiv.org/pdf/2102.09127" target="_blank">pdf</a>]

<h2>Densely Nested Top-Down Flows for Salient Object Detection. (arXiv:2102.09133v1 [cs.CV])</h2>
<h3>Chaowei Fang, Haibin Tian, Dingwen Zhang, Qiang Zhang, Jungong Han, Junwei Han</h3>
<p>With the goal of identifying pixel-wise salient object regions from each
input image, salient object detection (SOD) has been receiving great attention
in recent years. One kind of mainstream SOD methods is formed by a bottom-up
feature encoding procedure and a top-down information decoding procedure. While
numerous approaches have explored the bottom-up feature extraction for this
task, the design on top-down flows still remains under-studied. To this end,
this paper revisits the role of top-down modeling in salient object detection
and designs a novel densely nested top-down flows (DNTDF)-based framework. In
every stage of DNTDF, features from higher levels are read in via the
progressive compression shortcut paths (PCSP). The notable characteristics of
our proposed method are as follows. 1) The propagation of high-level features
which usually have relatively strong semantic information is enhanced in the
decoding procedure; 2) With the help of PCSP, the gradient vanishing issues
caused by non-linear operations in top-down information flows can be
alleviated; 3) Thanks to the full exploration of high-level features, the
decoding process of our method is relatively memory efficient compared against
those of existing methods. Integrating DNTDF with EfficientNet, we construct a
highly light-weighted SOD model, with very low computational complexity. To
demonstrate the effectiveness of the proposed model, comprehensive experiments
are conducted on six widely-used benchmark datasets. The comparisons to the
most state-of-the-art methods as well as the carefully-designed baseline models
verify our insights on the top-down flow modeling for SOD. The code of this
paper is available at https://github.com/new-stone-object/DNTD.
</p>
<a href="http://arxiv.org/abs/2102.09133" target="_blank">arXiv:2102.09133</a> [<a href="http://arxiv.org/pdf/2102.09133" target="_blank">pdf</a>]

<h2>Multi-Agent Reinforcement Learning of 3D Furniture Layout Simulation in Indoor Graphics Scenes. (arXiv:2102.09137v1 [cs.CV])</h2>
<h3>Xinhan Di, Pengqian Yu</h3>
<p>In the industrial interior design process, professional designers plan the
furniture layout to achieve a satisfactory 3D design for selling. In this
paper, we explore the interior graphics scenes design task as a Markov decision
process (MDP) in 3D simulation, which is solved by multi-agent reinforcement
learning. The goal is to produce furniture layout in the 3D simulation of the
indoor graphics scenes. In particular, we firstly transform the 3D interior
graphic scenes into two 2D simulated scenes. We then design the simulated
environment and apply two reinforcement learning agents to learn the optimal 3D
layout for the MDP formulation in a cooperative way. We conduct our experiments
on a large-scale real-world interior layout dataset that contains industrial
designs from professional designers. Our numerical results demonstrate that the
proposed model yields higher-quality layouts as compared with the state-of-art
model. The developed simulator and codes are available at
\url{https://github.com/CODE-SUBMIT/simulator2}.
</p>
<a href="http://arxiv.org/abs/2102.09137" target="_blank">arXiv:2102.09137</a> [<a href="http://arxiv.org/pdf/2102.09137" target="_blank">pdf</a>]

<h2>Improved Point Transformation Methods For Self-Supervised Depth Prediction. (arXiv:2102.09142v1 [cs.CV])</h2>
<h3>Chen Ziwen, Zixuan Guo, Jerod Weinman</h3>
<p>Given stereo or egomotion image pairs, a popular and successful method for
unsupervised learning of monocular depth estimation is to measure the quality
of image reconstructions resulting from the learned depth predictions.
Continued research has improved the overall approach in recent years, yet the
common framework still suffers from several important limitations, particularly
when dealing with points occluded after transformation to a novel viewpoint.
While prior work has addressed this problem heuristically, this paper
introduces a z-buffering algorithm that correctly and efficiently handles
occluded points. Because our algorithm is implemented with operators typical of
machine learning libraries, it can be incorporated into any existing
unsupervised depth learning framework with automatic support for
differentiation. Additionally, because points having negative depth after
transformation often signify erroneously shallow depth predictions, we
introduce a loss function to penalize this undesirable behavior explicitly.
Experimental results on the KITTI data set show that the z-buffer and negative
depth loss both improve the performance of a state of the art depth-prediction
network.
</p>
<a href="http://arxiv.org/abs/2102.09142" target="_blank">arXiv:2102.09142</a> [<a href="http://arxiv.org/pdf/2102.09142" target="_blank">pdf</a>]

<h2>Stochastic Spatio-Temporal Optimization for Control and Co-Design of Systems in Robotics and Applied Physics. (arXiv:2102.09144v1 [cs.RO])</h2>
<h3>Ethan N. Evans, Andrew P. Kendall, Evangelos A. Theodorou</h3>
<p>Correlated with the trend of increasing degrees of freedom in robotic systems
is a similar trend of rising interest in Spatio-Temporal systems described by
Partial Differential Equations (PDEs) among the robotics and control
communities. These systems often exhibit dramatic under-actuation, high
dimensionality, bifurcations, and multimodal instabilities. Their control
represents many of the current-day challenges facing the robotics and
automation communities. Not only are these systems challenging to control, but
the design of their actuation is an NP-hard problem on its own. Recent methods
either discretize the space before optimization, or apply tools from linear
systems theory under restrictive linearity assumptions in order to arrive at a
control solution. This manuscript provides a novel sampling-based stochastic
optimization framework based entirely in Hilbert spaces suitable for the
general class of \textit{semi-linear} SPDEs which describes many systems in
robotics and applied physics. This framework is utilized for simultaneous
policy optimization and actuator co-design optimization. The resulting
algorithm is based on variational optimization, and performs joint episodic
optimization of the feedback control law and the actuation design over
episodes. We study first and second order systems, and in doing so, extend
several results to the case of second order SPDEs. Finally, we demonstrate the
efficacy of the proposed approach with several simulated experiments on a
variety of SPDEs in robotics and applied physics including an infinite
degree-of-freedom soft robotic manipulator.
</p>
<a href="http://arxiv.org/abs/2102.09144" target="_blank">arXiv:2102.09144</a> [<a href="http://arxiv.org/pdf/2102.09144" target="_blank">pdf</a>]

<h2>An Enhanced Adversarial Network with Combined Latent Features for Spatio-Temporal Facial Affect Estimation in the Wild. (arXiv:2102.09150v1 [cs.CV])</h2>
<h3>Decky Aspandi, Federico Sukno, Bj&#xf6;rn Schuller, Xavier Binefa</h3>
<p>Affective Computing has recently attracted the attention of the research
community, due to its numerous applications in diverse areas. In this context,
the emergence of video-based data allows to enrich the widely used spatial
features with the inclusion of temporal information. However, such
spatio-temporal modelling often results in very high-dimensional feature spaces
and large volumes of data, making training difficult and time consuming. This
paper addresses these shortcomings by proposing a novel model that efficiently
extracts both spatial and temporal features of the data by means of its
enhanced temporal modelling based on latent features. Our proposed model
consists of three major networks, coined Generator, Discriminator, and
Combiner, which are trained in an adversarial setting combined with curriculum
learning to enable our adaptive attention modules. In our experiments, we show
the effectiveness of our approach by reporting our competitive results on both
the AFEW-VA and SEWA datasets, suggesting that temporal modelling improves the
affect estimates both in qualitative and quantitative terms. Furthermore, we
find that the inclusion of attention mechanisms leads to the highest accuracy
improvements, as its weights seem to correlate well with the appearance of
facial movements, both in terms of temporal localisation and intensity.
Finally, we observe the sequence length of around 160\,ms to be the optimum one
for temporal modelling, which is consistent with other relevant findings
utilising similar lengths.
</p>
<a href="http://arxiv.org/abs/2102.09150" target="_blank">arXiv:2102.09150</a> [<a href="http://arxiv.org/pdf/2102.09150" target="_blank">pdf</a>]

<h2>Robust and Differentially Private Mean Estimation. (arXiv:2102.09159v1 [cs.LG])</h2>
<h3>Xiyang Liu, Weihao Kong, Sham Kakade, Sewoong Oh</h3>
<p>Differential privacy has emerged as a standard requirement in a variety of
applications ranging from the U.S. Census to data collected in commercial
devices, initiating an extensive line of research in accurately and privately
releasing statistics of a database. An increasing number of such databases
consist of data from multiple sources, not all of which can be trusted. This
leaves existing private analyses vulnerable to attacks by an adversary who
injects corrupted data. Despite the significance of designing algorithms that
guarantee privacy and robustness (to a fraction of data being corrupted)
simultaneously, even the simplest questions remain open. For the canonical
problem of estimating the mean from i.i.d. samples, we introduce the first
efficient algorithm that achieves both privacy and robustness for a wide range
of distributions. This achieves optimal accuracy matching the known lower
bounds for robustness, but the sample complexity has a factor of $d^{1/2}$ gap
from known lower bounds. We further show that this gap is due to the
computational efficiency; we introduce the first family of algorithms that
close this gap but takes exponential time. The innovation is in exploiting
resilience (a key property in robust estimation) to adaptively bound the
sensitivity and improve privacy.
</p>
<a href="http://arxiv.org/abs/2102.09159" target="_blank">arXiv:2102.09159</a> [<a href="http://arxiv.org/pdf/2102.09159" target="_blank">pdf</a>]

<h2>Closing the Closed-Loop Distribution Shift in Safe Imitation Learning. (arXiv:2102.09161v1 [cs.LG])</h2>
<h3>Stephen Tu, Alexander Robey, Nikolai Matni</h3>
<p>Commonly used optimization-based control strategies such as model-predictive
and control Lyapunov/barrier function based controllers often enjoy provable
stability, robustness, and safety properties. However, implementing such
approaches requires solving optimization problems online at high-frequencies,
which may not be possible on resource-constrained commodity hardware.
Furthermore, how to extend the safety guarantees of such approaches to systems
that use rich perceptual sensing modalities, such as cameras, remains unclear.
In this paper, we address this gap by treating safe optimization-based control
strategies as experts in an imitation learning problem, and train a learned
policy that can be cheaply evaluated at run-time and that provably satisfies
the same safety guarantees as the expert. In particular, we propose Constrained
Mixing Iterative Learning (CMILe), a novel on-policy robust imitation learning
algorithm that integrates ideas from stochastic mixing iterative learning,
constrained policy optimization, and nonlinear robust control. Our approach
allows us to control errors introduced by both the learning task of imitating
an expert and by the distribution shift inherent to deviating from the original
expert policy. The value of using tools from nonlinear robust control to impose
stability constraints on learned policies is shown through sample-complexity
bounds that are independent of the task time-horizon. We demonstrate the
usefulness of CMILe through extensive experiments, including training a
provably safe perception-based controller using a state-feedback-based expert.
</p>
<a href="http://arxiv.org/abs/2102.09161" target="_blank">arXiv:2102.09161</a> [<a href="http://arxiv.org/pdf/2102.09161" target="_blank">pdf</a>]

<h2>Hierarchical Attention Fusion for Geo-Localization. (arXiv:2102.09186v1 [cs.CV])</h2>
<h3>Liqi Yan, Yiming Cui, Yingjie Chen, Dongfang Liu</h3>
<p>Geo-localization is a critical task in computer vision. In this work, we cast
the geo-localization as a 2D image retrieval task. Current state-of-the-art
methods for 2D geo-localization are not robust to locate a scene with drastic
scale variations because they only exploit features from one semantic level for
image representations. To address this limitation, we introduce a hierarchical
attention fusion network using multi-scale features for geo-localization. We
extract the hierarchical feature maps from a convolutional neural network (CNN)
and organically fuse the extracted features for image representations. Our
training is self-supervised using adaptive weights to control the attention of
feature emphasis from each hierarchical level. Evaluation results on the image
retrieval and the large-scale geo-localization benchmarks indicate that our
method outperforms the existing state-of-the-art methods. Code is available
here: \url{https://github.com/YanLiqi/HAF}.
</p>
<a href="http://arxiv.org/abs/2102.09186" target="_blank">arXiv:2102.09186</a> [<a href="http://arxiv.org/pdf/2102.09186" target="_blank">pdf</a>]

<h2>Edge Sparse Basis Network: An Deep Learning Framework for EEG Source Localization. (arXiv:2102.09188v1 [cs.LG])</h2>
<h3>Chen Wei, Kexin Lou, Zhengyang Wang, Mingqi Zhao, Dante Mantini, Quanying Liu</h3>
<p>EEG source localization is an important technical issue in EEG analysis.
Despite many numerical methods existed for EEG source localization, they all
rely on strong priors and the deep sources are intractable. Here we propose a
deep learning framework using spatial basis function decomposition for EEG
source localization. This framework combines the edge sparsity prior and
Gaussian source basis, called Edge Sparse Basis Network (ESBN). The performance
of ESBN is validated by both synthetic data and real EEG data during motor
tasks. The results suggest that the supervised ESBN outperforms the traditional
numerical methods in synthetic data and the unsupervised fine-tuning provides
more focal and accurate localizations in real data. Our proposed deep learning
framework can be extended to account for other source priors, and the real-time
property of ESBN can facilitate the applications of EEG in brain-computer
interfaces and clinics.
</p>
<a href="http://arxiv.org/abs/2102.09188" target="_blank">arXiv:2102.09188</a> [<a href="http://arxiv.org/pdf/2102.09188" target="_blank">pdf</a>]

<h2>Non-approximate Inference for Collective Graphical Models on Path Graphs via Discrete Difference of Convex Algorithm. (arXiv:2102.09191v1 [stat.ML])</h2>
<h3>Yasunori Akagi, Naoki Marumo, Hideaki Kim, Takeshi Kurashima, Hiroyuki Toda</h3>
<p>The importance of aggregated count data, which is calculated from the data of
multiple individuals, continues to increase. Collective Graphical Model (CGM)
is a probabilistic approach to the analysis of aggregated data. One of the most
important operations in CGM is maximum a posteriori (MAP) inference of
unobserved variables under given observations. Because the MAP inference
problem for general CGMs has been shown to be NP-hard, an approach that solves
an approximate problem has been proposed. However, this approach has two major
drawbacks. First, the quality of the solution deteriorates when the values in
the count tables are small, because the approximation becomes inaccurate.
Second, since continuous relaxation is applied, the integrality constraints of
the output are violated. To resolve these problems, this paper proposes a new
method for MAP inference for CGMs on path graphs. First we show that the MAP
inference problem can be formulated as a (non-linear) minimum cost flow
problem. Then, we apply Difference of Convex Algorithm (DCA), which is a
general methodology to minimize a function represented as the sum of a convex
function and a concave function. In our algorithm, important subroutines in DCA
can be efficiently calculated by minimum convex cost flow algorithms.
Experiments show that the proposed method outputs higher quality solutions than
the conventional approach.
</p>
<a href="http://arxiv.org/abs/2102.09191" target="_blank">arXiv:2102.09191</a> [<a href="http://arxiv.org/pdf/2102.09191" target="_blank">pdf</a>]

<h2>SeaPearl: A Constraint Programming Solver guided by Reinforcement Learning. (arXiv:2102.09193v1 [cs.LG])</h2>
<h3>F&#xe9;lix Chalumeau (1), Ilan Coulon (1), Quentin Cappart (2), Louis-Martin Rousseau (2) ((1) &#xc9;cole Polytechnique, Institut Polytechnique de Paris, (2) &#xc9;cole Polytechnique de Montr&#xe9;al)</h3>
<p>The design of efficient and generic algorithms for solving combinatorial
optimization problems has been an active field of research for many years.
Standard exact solving approaches are based on a clever and complete
enumeration of the solution set. A critical and non-trivial design choice with
such methods is the branching strategy, directing how the search is performed.
The last decade has shown an increasing interest in the design of machine
learning-based heuristics to solve combinatorial optimization problems. The
goal is to leverage knowledge from historical data to solve similar new
instances of a problem. Used alone, such heuristics are only able to provide
approximate solutions efficiently, but cannot prove optimality nor bounds on
their solution. Recent works have shown that reinforcement learning can be
successfully used for driving the search phase of constraint programming (CP)
solvers. However, it has also been shown that this hybridization is challenging
to build, as standard CP frameworks do not natively include machine learning
mechanisms, leading to some sources of inefficiencies. This paper presents the
proof of concept for SeaPearl, a new CP solver implemented in Julia, that
supports machine learning routines in order to learn branching decisions using
reinforcement learning. Support for modeling the learning component is also
provided. We illustrate the modeling and solution performance of this new
solver on two problems. Although not yet competitive with industrial solvers,
SeaPearl aims to provide a flexible and open-source framework in order to
facilitate future research in the hybridization of constraint programming and
machine learning.
</p>
<a href="http://arxiv.org/abs/2102.09193" target="_blank">arXiv:2102.09193</a> [<a href="http://arxiv.org/pdf/2102.09193" target="_blank">pdf</a>]

<h2>Learning Continuous Exponential Families Beyond Gaussian. (arXiv:2102.09198v1 [cs.LG])</h2>
<h3>Christopher X. Ren, Sidhant Misra, Marc Vuffray, Andrey Y. Lokhov</h3>
<p>We address the problem of learning of continuous exponential family
distributions with unbounded support. While a lot of progress has been made on
learning of Gaussian graphical models, we are still lacking scalable algorithms
for reconstructing general continuous exponential families modeling
higher-order moments of the data beyond the mean and the covariance. Here, we
introduce a computationally efficient method for learning continuous graphical
models based on the Interaction Screening approach. Through a series of
numerical experiments, we show that our estimator maintains similar
requirements in terms of accuracy and sample complexity compared to alternative
approaches such as maximization of conditional likelihood, while considerably
improving upon the algorithm's run-time.
</p>
<a href="http://arxiv.org/abs/2102.09198" target="_blank">arXiv:2102.09198</a> [<a href="http://arxiv.org/pdf/2102.09198" target="_blank">pdf</a>]

<h2>Minimizing false negative rate in melanoma detection and providing insight into the causes of classification. (arXiv:2102.09199v1 [cs.CV])</h2>
<h3>Ell&#xe1;k Somfai, Benj&#xe1;min Baffy, Kristian Fenech, Changlu Guo, Rita Hossz&#xfa;, Dorina Kor&#xf3;zs, Marcell P&#xf3;lik, Attila Ulbert, Andr&#xe1;s L&#x151;rincz</h3>
<p>Our goal is to bridge human and machine intelligence in melanoma detection.
We develop a classification system exploiting a combination of visual
pre-processing, deep learning, and ensembling for providing explanations to
experts and to minimize false negative rate while maintaining high accuracy in
melanoma detection. Source images are first automatically segmented using a
U-net CNN. The result of the segmentation is then used to extract image
sub-areas and specific parameters relevant in human evaluation, namely center,
border, and asymmetry measures. These data are then processed by tailored
neural networks which include structure searching algorithms. Partial results
are then ensembled by a committee machine. Our evaluation on the largest skin
lesion dataset which is publicly available today, ISIC-2019, shows improvement
in all evaluated metrics over a baseline using the original images only. We
also showed that indicative scores computed by the feature classifiers can
provide useful insight into the various features on which the decision can be
based.
</p>
<a href="http://arxiv.org/abs/2102.09199" target="_blank">arXiv:2102.09199</a> [<a href="http://arxiv.org/pdf/2102.09199" target="_blank">pdf</a>]

<h2>Unsupervised Clustering of Time Series Signals using Neuromorphic Energy-Efficient Temporal Neural Networks. (arXiv:2102.09200v1 [cs.LG])</h2>
<h3>Shreyas Chaudhari, Harideep Nair, Jos&#xe9; M.F. Moura, John Paul Shen</h3>
<p>Unsupervised time series clustering is a challenging problem with diverse
industrial applications such as anomaly detection, bio-wearables, etc. These
applications typically involve small, low-power devices on the edge that
collect and process real-time sensory signals. State-of-the-art time-series
clustering methods perform some form of loss minimization that is extremely
computationally intensive from the perspective of edge devices. In this work,
we propose a neuromorphic approach to unsupervised time series clustering based
on Temporal Neural Networks that is capable of ultra low-power, continuous
online learning. We demonstrate its clustering performance on a subset of UCR
Time Series Archive datasets. Our results show that the proposed approach
either outperforms or performs similarly to most of the existing algorithms
while being far more amenable for efficient hardware implementation. Our
hardware assessment analysis shows that in 7 nm CMOS the proposed architecture,
on average, consumes only about 0.005 mm^2 die area and 22 uW power and can
process each signal with about 5 ns latency.
</p>
<a href="http://arxiv.org/abs/2102.09200" target="_blank">arXiv:2102.09200</a> [<a href="http://arxiv.org/pdf/2102.09200" target="_blank">pdf</a>]

<h2>Towards a mathematical theory of trajectory inference. (arXiv:2102.09204v1 [stat.ML])</h2>
<h3>Hugo Lavenant, Stephen Zhang, Young-Heon Kim, Geoffrey Schiebinger</h3>
<p>We devise a theoretical framework and a numerical method to infer
trajectories of a stochastic process from snapshots of its temporal marginals.
This problem arises in the analysis of single cell RNA-sequencing data, which
provide high dimensional measurements of cell states but cannot track the
trajectories of the cells over time. We prove that for a class of stochastic
processes it is possible to recover the ground truth trajectories from limited
samples of the temporal marginals at each time-point, and provide an efficient
algorithm to do so in practice. The method we develop, Global Waddington-OT
(gWOT), boils down to a smooth convex optimization problem posed globally over
all time-points involving entropy-regularized optimal transport. We demonstrate
that this problem can be solved efficiently in practice and yields good
reconstructions, as we show on several synthetic and real datasets.
</p>
<a href="http://arxiv.org/abs/2102.09204" target="_blank">arXiv:2102.09204</a> [<a href="http://arxiv.org/pdf/2102.09204" target="_blank">pdf</a>]

<h2>Less is More: Pre-training a Strong Siamese Encoder Using a Weak Decoder. (arXiv:2102.09206v1 [cs.LG])</h2>
<h3>Shuqi Lu, Chenyan Xiong, Di He, Guolin Ke, Waleed Malik, Zhicheng Dou, Paul Bennett, Tieyan Liu, Arnold Overwijk</h3>
<p>Many real-world applications use Siamese networks to efficiently match text
sequences at scale, which require high-quality sequence encodings. This paper
pre-trains language models dedicated to sequence matching in Siamese
architectures. We first hypothesize that a representation is better for
sequence matching if the entire sequence can be reconstructed from it, which,
however, is unlikely to be achieved in standard autoencoders: A strong decoder
can rely on its capacity and natural language patterns to reconstruct and
bypass the needs of better sequence encodings. Therefore we propose a new
self-learning method that pretrains the encoder with a weak decoder, which
reconstructs the original sequence from the encoder's [CLS] representations but
is restricted in both capacity and attention span. In our experiments on web
search and recommendation, the pre-trained SEED-Encoder, "SiamEsE oriented
encoder by reconstructing from weak decoder", shows significantly better
generalization ability when fine-tuned in Siamese networks, improving overall
accuracy and few-shot performances. Our code and models will be released.
</p>
<a href="http://arxiv.org/abs/2102.09206" target="_blank">arXiv:2102.09206</a> [<a href="http://arxiv.org/pdf/2102.09206" target="_blank">pdf</a>]

<h2>Learning Memory-Dependent Continuous Control from Demonstrations. (arXiv:2102.09208v1 [cs.LG])</h2>
<h3>Siqing Hou, Dongqi Han, Jun Tani</h3>
<p>Efficient exploration has presented a long-standing challenge in
reinforcement learning, especially when rewards are sparse. A developmental
system can overcome this difficulty by learning from both demonstrations and
self-exploration. However, existing methods are not applicable to most
real-world robotic controlling problems because they assume that environments
follow Markov decision processes (MDP); thus, they do not extend to partially
observable environments where historical observations are necessary for
decision making. This paper builds on the idea of replaying demonstrations for
memory-dependent continuous control, by proposing a novel algorithm, Recurrent
Actor-Critic with Demonstration and Experience Replay (READER). Experiments
involving several memory-crucial continuous control tasks reveal significantly
reduce interactions with the environment using our method with a reasonably
small number of demonstration samples. The algorithm also shows better sample
efficiency and learning capabilities than a baseline reinforcement learning
algorithm for memory-based control from demonstrations.
</p>
<a href="http://arxiv.org/abs/2102.09208" target="_blank">arXiv:2102.09208</a> [<a href="http://arxiv.org/pdf/2102.09208" target="_blank">pdf</a>]

<h2>Continuous Doubly Constrained Batch Reinforcement Learning. (arXiv:2102.09225v1 [cs.LG])</h2>
<h3>Rasool Fakoor, Jonas Mueller, Pratik Chaudhari, Alexander J. Smola</h3>
<p>Reliant on too many experiments to learn good actions, current Reinforcement
Learning (RL) algorithms have limited applicability in real-world settings,
which can be too expensive to allow exploration. We propose an algorithm for
batch RL, where effective policies are learned using only a fixed offline
dataset instead of online interactions with the environment. The limited data
in batch RL produces inherent uncertainty in value estimates of states/actions
that were insufficiently represented in the training data. This leads to
particularly severe extrapolation when our candidate policies diverge from one
that generated the data. We propose to mitigate this issue via two
straightforward penalties: a policy-constraint to reduce this divergence and a
value-constraint that discourages overly optimistic estimates. Over a
comprehensive set of 32 continuous-action batch RL benchmarks, our approach
compares favorably to state-of-the-art methods, regardless of how the offline
data were collected.
</p>
<a href="http://arxiv.org/abs/2102.09225" target="_blank">arXiv:2102.09225</a> [<a href="http://arxiv.org/pdf/2102.09225" target="_blank">pdf</a>]

<h2>Random Projections for Improved Adversarial Robustness. (arXiv:2102.09230v1 [cs.LG])</h2>
<h3>Ginevra Carbone, Guido Sanguinetti, Luca Bortolussi</h3>
<p>We propose two training techniques for improving the robustness of Neural
Networks to adversarial attacks, i.e. manipulations of the inputs that are
maliciously crafted to fool networks into incorrect predictions. Both methods
are independent of the chosen attack and leverage random projections of the
original inputs, with the purpose of exploiting both dimensionality reduction
and some characteristic geometrical properties of adversarial perturbations.
The first technique is called RP-Ensemble and consists of an ensemble of
networks trained on multiple projected versions of the original inputs. The
second one, named RP-Regularizer, adds instead a regularization term to the
training objective.
</p>
<a href="http://arxiv.org/abs/2102.09230" target="_blank">arXiv:2102.09230</a> [<a href="http://arxiv.org/pdf/2102.09230" target="_blank">pdf</a>]

<h2>A Mathematical Principle of Deep Learning: Learn the Geodesic Curve in the Wasserstein Space. (arXiv:2102.09235v1 [cs.LG])</h2>
<h3>Kuo Gai, Shihua Zhang</h3>
<p>Recent studies revealed the mathematical connection of deep neural network
(DNN) and dynamic system. However, the fundamental principle of DNN has not
been fully characterized with dynamic system in terms of optimization and
generalization. To this end, we build the connection of DNN and continuity
equation where the measure is conserved to model the forward propagation
process of DNN which has not been addressed before. DNN learns the
transformation of the input distribution to the output one. However, in the
measure space, there are infinite curves connecting two distributions. Which
one can lead to good optimization and generaliztion for DNN? By diving the
optimal transport theory, we find DNN with weight decay attempts to learn the
geodesic curve in the Wasserstein space, which is induced by the optimal
transport map. Compared with plain network, ResNet is a better approximation to
the geodesic curve, which explains why ResNet can be optimized and generalize
better. Numerical experiments show that the data tracks of both plain network
and ResNet tend to be line-shape in term of line-shape score (LSS), and the map
learned by ResNet is closer to the optimal transport map in term of optimal
transport score (OTS). In a word, we conclude a mathematical principle of deep
learning is to learn the geodesic curve in the Wasserstein space; and deep
learning is a great engineering realization of continuous transformation in
high-dimensional space.
</p>
<a href="http://arxiv.org/abs/2102.09235" target="_blank">arXiv:2102.09235</a> [<a href="http://arxiv.org/pdf/2102.09235" target="_blank">pdf</a>]

<h2>DSRN: an Efficient Deep Network for Image Relighting. (arXiv:2102.09242v1 [cs.CV])</h2>
<h3>Sourya Dipta Das, Nisarg A. Shah, Saikat Dutta, Himanshu Kumar</h3>
<p>Custom and natural lighting conditions can be emulated in images of the scene
during post-editing. Extraordinary capabilities of the deep learning framework
can be utilized for such purpose. Deep image relighting allows automatic photo
enhancement by illumination-specific retouching. Most of the state-of-the-art
methods for relighting are run-time intensive and memory inefficient. In this
paper, we propose an efficient, real-time framework Deep Stacked Relighting
Network (DSRN) for image relighting by utilizing the aggregated features from
input image at different scales. Our model is very lightweight with total size
of about 42 MB and has an average inference time of about 0.0116s for image of
resolution $1024 \times 1024$ which is faster as compared to other multi-scale
models. Our solution is quite robust for translating image color temperature
from input image to target image and also performs moderately for light
gradient generation with respect to the target image. Additionally, we show
that if images illuminated from opposite directions are used as input, the
qualitative results improve over using a single input image.
</p>
<a href="http://arxiv.org/abs/2102.09242" target="_blank">arXiv:2102.09242</a> [<a href="http://arxiv.org/pdf/2102.09242" target="_blank">pdf</a>]

<h2>Improved Deep Reinforcement Learning with Expert Demonstrations for Urban Autonomous Driving. (arXiv:2102.09243v1 [cs.RO])</h2>
<h3>Haochen Liu, Zhiyu Huang, Chen Lv</h3>
<p>Currently, urban autonomous driving remains challenging because of the
complexity of the driving environment. Learning-based approaches, such as
reinforcement learning (RL) and imitation learning (IL), have indicated
superiority over rule-based approaches, showing great potential to make
decisions intelligently, but they still do not work well in urban driving
situations. To better tackle this problem, this paper proposes a novel
learning-based method that combines deep reinforcement learning with expert
demonstrations, focusing on longitudinal motion control in autonomous driving.
Our proposed method employs the actor-critic structure and modifies the
learning process of the policy network to incorporate both the goals of
maximizing reward and imitating the expert. Moreover, an adaptive prioritized
experience replay is designed to sample experience from both the agent's
self-exploration and expert demonstration, so as to improve the sample
efficiency. The proposed method is validated in a simulated urban roundabout
scenario and compared with various prevailing RL and IL baseline approaches.
The results manifest that the proposed method has a faster training speed, as
well as better performance in navigating safely and efficiently.
</p>
<a href="http://arxiv.org/abs/2102.09243" target="_blank">arXiv:2102.09243</a> [<a href="http://arxiv.org/pdf/2102.09243" target="_blank">pdf</a>]

<h2>HandTailor: Towards High-Precision Monocular 3D Hand Recovery. (arXiv:2102.09244v1 [cs.CV])</h2>
<h3>Jun Lv, Wenqiang Xu, Lixin Yang, Sucheng Qian, Chongzhao Mao, Cewu Lu</h3>
<p>3D hand pose estimation and shape recovery are challenging tasks in computer
vision. We introduce a novel framework HandTailor, which combines a
learning-based hand module and an optimization-based tailor module to achieve
high-precision hand mesh recovery from a monocular RGB image. The proposed hand
module unifies perspective projection and weak perspective projection in a
single network towards accuracy-oriented and in-the-wild scenarios. The
proposed tailor module then utilizes the coarsely reconstructed mesh model
provided by the hand module as initialization, and iteratively optimizes an
energy function to obtain better results. The tailor module is time-efficient,
costs only 8ms per frame on a modern CPU. We demonstrate that HandTailor can
get state-of-the-art performance on several public benchmarks, with impressive
qualitative results on in-the-wild experiments.
</p>
<a href="http://arxiv.org/abs/2102.09244" target="_blank">arXiv:2102.09244</a> [<a href="http://arxiv.org/pdf/2102.09244" target="_blank">pdf</a>]

<h2>Composable Generative Models. (arXiv:2102.09249v1 [cs.LG])</h2>
<h3>Johan Leduc, Nicolas Grislain</h3>
<p>Generative modeling has recently seen many exciting developments with the
advent of deep generative architectures such as Variational Auto-Encoders (VAE)
or Generative Adversarial Networks (GAN). The ability to draw synthetic i.i.d.
observations with the same joint probability distribution as a given dataset
has a wide range of applications including representation learning, compression
or imputation. It appears that it also has many applications in privacy
preserving data analysis, especially when used in conjunction with differential
privacy techniques. This paper focuses on synthetic data generation models with
privacy preserving applications in mind. It introduces a novel architecture,
the Composable Generative Model (CGM) that is state-of-the-art in tabular data
generation. Any conditional generative model can be used as a sub-component of
the CGM, including CGMs themselves, allowing the generation of numerical,
categorical data as well as images, text, or time series. The CGM has been
evaluated on 13 datasets (6 standard datasets and 7 simulated) and compared to
14 recent generative models. It beats the state of the art in tabular data
generation by a significant margin.
</p>
<a href="http://arxiv.org/abs/2102.09249" target="_blank">arXiv:2102.09249</a> [<a href="http://arxiv.org/pdf/2102.09249" target="_blank">pdf</a>]

<h2>Strategic bidding in freight transport using deep reinforcement learning. (arXiv:2102.09253v1 [cs.LG])</h2>
<h3>Wouter van Heeswijk</h3>
<p>This paper presents a multi-agent reinforcement learning algorithm to
represent strategic bidding behavior in freight transport markets. Using this
algorithm, we investigate whether feasible market equilibriums arise without
any central control or communication between agents. Studying behavior in such
environments may serve as a stepping stone towards self-organizing logistics
systems like the Physical Internet. We model an agent-based environment in
which a shipper and a carrier actively learn bidding strategies using policy
gradient methods, posing bid- and ask prices at the individual container level.
Both agents aim to learn the best response given the expected behavior of the
opposing agent. A neutral broker allocates jobs based on bid-ask spreads.

Our game-theoretical analysis and numerical experiments focus on behavioral
insights. To evaluate system performance, we measure adherence to Nash
equilibria, fairness of reward division and utilization of transport capacity.
We observe good performance both in predictable, deterministic settings (~95%
adherence to Nash equilibria) and highly stochastic environments (~85%
adherence). Risk-seeking behavior may increase an agent's reward share, as long
as the strategies are not overly aggressive. The results suggest a potential
for full automation and decentralization of freight transport markets.
</p>
<a href="http://arxiv.org/abs/2102.09253" target="_blank">arXiv:2102.09253</a> [<a href="http://arxiv.org/pdf/2102.09253" target="_blank">pdf</a>]

<h2>A matrix approach to detect temporal behavioral patterns at electric vehicle charging stations. (arXiv:2102.09260v1 [cs.LG])</h2>
<h3>Milan Straka, Lucia Piatrikov&#xe1;, Peter van Bokhoven, &#x13d;ubo&#x161; Buzna</h3>
<p>Based on the electric vehicle (EV) arrival times and the duration of EV
connection to the charging station, we identify charging patterns and derive
groups of charging stations with similar charging patterns applying two
approaches. The ruled based approach derives the charging patterns by
specifying a set of time intervals and a threshold value. In the second
approach, we combine the modified l-p norm (as a matrix dissimilarity measure)
with hierarchical clustering and apply them to automatically identify charging
patterns and groups of charging stations associated with such patterns. A
dataset collected in a large network of public charging stations is used to
test both approaches. Using both methods, we derived charging patterns. The
first, rule-based approach, performed well at deriving predefined patterns and
the latter, hierarchical clustering, showed the capability of delivering
unexpected charging patterns.
</p>
<a href="http://arxiv.org/abs/2102.09260" target="_blank">arXiv:2102.09260</a> [<a href="http://arxiv.org/pdf/2102.09260" target="_blank">pdf</a>]

<h2>PLAM: a Posit Logarithm-Approximate Multiplier for Power Efficient Posit-based DNNs. (arXiv:2102.09262v1 [cs.LG])</h2>
<h3>Raul Murillo, Alberto A. Del Barrio, Guillermo Botella, Min Soo Kim, HyunJin Kim, Nader Bagherzadeh</h3>
<p>The Posit Number System was introduced in 2017 as a replacement for
floating-point numbers. Since then, the community has explored its application
in Neural Network related tasks and produced some unit designs which are still
far from being competitive with their floating-point counterparts. This paper
proposes a Posit Logarithm-Approximate Multiplication (PLAM) scheme to
significantly reduce the complexity of posit multipliers, the most power-hungry
units within Deep Neural Network architectures. When comparing with
state-of-the-art posit multipliers, experiments show that the proposed
technique reduces the area, power, and delay of hardware multipliers up to
72.86%, 81.79%, and 17.01%, respectively, without accuracy degradation.
</p>
<a href="http://arxiv.org/abs/2102.09262" target="_blank">arXiv:2102.09262</a> [<a href="http://arxiv.org/pdf/2102.09262" target="_blank">pdf</a>]

<h2>DINO: A Conditional Energy-Based GAN for Domain Translation. (arXiv:2102.09281v1 [cs.LG])</h2>
<h3>Konstantinos Vougioukas, Stavros Petridis, Maja Pantic</h3>
<p>Domain translation is the process of transforming data from one domain to
another while preserving the common semantics. Some of the most popular domain
translation systems are based on conditional generative adversarial networks,
which use source domain data to drive the generator and as an input to the
discriminator. However, this approach does not enforce the preservation of
shared semantics since the conditional input can often be ignored by the
discriminator. We propose an alternative method for conditioning and present a
new framework, where two networks are simultaneously trained, in a supervised
manner, to perform domain translation in opposite directions. Our method is not
only better at capturing the shared information between two domains but is more
generic and can be applied to a broader range of problems. The proposed
framework performs well even in challenging cross-modal translations, such as
video-driven speech reconstruction, for which other systems struggle to
maintain correspondence.
</p>
<a href="http://arxiv.org/abs/2102.09281" target="_blank">arXiv:2102.09281</a> [<a href="http://arxiv.org/pdf/2102.09281" target="_blank">pdf</a>]

<h2>Reduced-Order Neural Network Synthesis with Robustness Guarantees. (arXiv:2102.09284v1 [cs.LG])</h2>
<h3>Ross Drummond, Mathew C. Turner, Stephen R. Duncan</h3>
<p>In the wake of the explosive growth in smartphones and cyberphysical systems,
there has been an accelerating shift in how data is generated away from
centralised data towards on-device generated data. In response, machine
learning algorithms are being adapted to run locally on board, potentially
hardware limited, devices to improve user privacy, reduce latency and be more
energy efficient. However, our understanding of how these device orientated
algorithms behave and should be trained is still fairly limited. To address
this issue, a method to automatically synthesize reduced-order neural networks
(having fewer neurons) approximating the input/output mapping of a larger one
is introduced. The reduced-order neural network's weights and biases are
generated from a convex semi-definite programme that minimises the worst-case
approximation error with respect to the larger network. Worst-case bounds for
this approximation error are obtained and the approach can be applied to a wide
variety of neural networks architectures. What differentiates the proposed
approach to existing methods for generating small neural networks, e.g.
pruning, is the inclusion of the worst-case approximation error directly within
the training cost function, which should add robustness. Numerical examples
highlight the potential of the proposed approach. The overriding goal of this
paper is to generalise recent results in the robustness analysis of neural
networks to a robust synthesis problem for their weights and biases.
</p>
<a href="http://arxiv.org/abs/2102.09284" target="_blank">arXiv:2102.09284</a> [<a href="http://arxiv.org/pdf/2102.09284" target="_blank">pdf</a>]

<h2>Sliced $\mathcal{L}_2$ Distance for Colour Grading. (arXiv:2102.09297v1 [cs.CV])</h2>
<h3>Hana Alghamdi, Rozenn Dahyot</h3>
<p>We propose a new method with $\mathcal{L}_2$ distance that maps one
$N$-dimensional distribution to another, taking into account available
information about correspondences. We solve the high-dimensional problem in 1D
space using an iterative projection approach. To show the potentials of this
mapping, we apply it to colour transfer between two images that exhibit
overlapped scenes. Experiments show quantitative and qualitative competitive
results as compared with the state of the art colour transfer methods.
</p>
<a href="http://arxiv.org/abs/2102.09297" target="_blank">arXiv:2102.09297</a> [<a href="http://arxiv.org/pdf/2102.09297" target="_blank">pdf</a>]

<h2>GradFreeBits: Gradient Free Bit Allocation for Dynamic Low Precision Neural Networks. (arXiv:2102.09298v1 [cs.LG])</h2>
<h3>Benjamin J. Bodner, Gil Ben Shalom, Eran Treister</h3>
<p>Quantized neural networks (QNNs) are among the main approaches for deploying
deep neural networks on low resource edge devices. Training QNNs using
different levels of precision throughout the network (dynamic quantization)
typically achieves superior trade-offs between performance and computational
load. However, optimizing the different precision levels of QNNs can be
complicated, as the values of the bit allocations are discrete and difficult to
differentiate for. Also, adequately accounting for the dependencies between the
bit allocation of different layers is not straight-forward. To meet these
challenges, in this work we propose GradFreeBits: a novel joint optimization
scheme for training dynamic QNNs, which alternates between gradient-based
optimization for the weights, and gradient-free optimization for the bit
allocation. Our method achieves better or on par performance with current state
of the art low precision neural networks on CIFAR10/100 and ImageNet
classification. Furthermore, our approach can be extended to a variety of other
applications involving neural networks used in conjunction with parameters
which are difficult to optimize for.
</p>
<a href="http://arxiv.org/abs/2102.09298" target="_blank">arXiv:2102.09298</a> [<a href="http://arxiv.org/pdf/2102.09298" target="_blank">pdf</a>]

<h2>Boosting for Online Convex Optimization. (arXiv:2102.09305v1 [cs.LG])</h2>
<h3>Elad Hazan, Karan Singh</h3>
<p>We consider the decision-making framework of online convex optimization with
a very large number of experts. This setting is ubiquitous in contextual and
reinforcement learning problems, where the size of the policy class renders
enumeration and search within the policy class infeasible.

Instead, we consider generalizing the methodology of online boosting. We
define a weak learning algorithm as a mechanism that guarantees
multiplicatively approximate regret against a base class of experts. In this
access model, we give an efficient boosting algorithm that guarantees
near-optimal regret against the convex hull of the base class. We consider both
full and partial (a.k.a. bandit) information feedback models. We also give an
analogous efficient boosting algorithm for the i.i.d. statistical setting.

Our results simultaneously generalize online boosting and gradient boosting
guarantees to contextual learning model, online convex optimization and bandit
linear optimization settings.
</p>
<a href="http://arxiv.org/abs/2102.09305" target="_blank">arXiv:2102.09305</a> [<a href="http://arxiv.org/pdf/2102.09305" target="_blank">pdf</a>]

<h2>VAE Approximation Error: ELBO and Conditional Independence. (arXiv:2102.09310v1 [cs.LG])</h2>
<h3>Dmitrij Schlesinger, Alexander Shekhovtsov, Boris Flach</h3>
<p>The importance of Variational Autoencoders reaches far beyond standalone
generative models -- the approach is also used for learning latent
representations and can be generalized to semi-supervised learning. This
requires a thorough analysis of their commonly known shortcomings: posterior
collapse and approximation errors. This paper analyzes VAE approximation errors
caused by the combination of the ELBO objective with the choice of the encoder
probability family, in particular under conditional independence assumptions.
We identify the subclass of generative models consistent with the encoder
family. We show that the ELBO optimizer is pulled from the likelihood optimizer
towards this consistent subset. Furthermore, this subset can not be enlarged,
and the respective error cannot be decreased, by only considering deeper
encoder networks.
</p>
<a href="http://arxiv.org/abs/2102.09310" target="_blank">arXiv:2102.09310</a> [<a href="http://arxiv.org/pdf/2102.09310" target="_blank">pdf</a>]

<h2>Hierarchical Learning Using Deep Optimum-Path Forest. (arXiv:2102.09312v1 [cs.AI])</h2>
<h3>Luis C. S. Afonso, Clayton R. Pereira, Silke A. T. Weber, Christian Hook, Alexandre X. Falc&#xe3;o, Jo&#xe3;o P. Papa</h3>
<p>Bag-of-Visual Words (BoVW) and deep learning techniques have been widely used
in several domains, which include computer-assisted medical diagnoses. In this
work, we are interested in developing tools for the automatic identification of
Parkinson's disease using machine learning and the concept of BoVW. The
proposed approach concerns a hierarchical-based learning technique to design
visual dictionaries through the Deep Optimum-Path Forest classifier. The
proposed method was evaluated in six datasets derived from data collected from
individuals when performing handwriting exams. Experimental results showed the
potential of the technique, with robust achievements.
</p>
<a href="http://arxiv.org/abs/2102.09312" target="_blank">arXiv:2102.09312</a> [<a href="http://arxiv.org/pdf/2102.09312" target="_blank">pdf</a>]

<h2>Finite-Sample Analysis of Off-Policy Natural Actor-Critic Algorithm. (arXiv:2102.09318v1 [cs.LG])</h2>
<h3>Sajad Khodadadian, Zaiwei Chen, Siva Theja Maguluri</h3>
<p>In this paper, we provide finite-sample convergence guarantees for an
off-policy variant of the natural actor-critic (NAC) algorithm based on
Importance Sampling. In particular, we show that the algorithm converges to a
global optimal policy with a sample complexity of
$\mathcal{O}(\epsilon^{-3}\log^2(1/\epsilon))$ under an appropriate choice of
stepsizes. In order to overcome the issue of large variance due to Importance
Sampling, we propose the $Q$-trace algorithm for the critic, which is inspired
by the V-trace algorithm (Espeholt et al., 2018). This enables us to explicitly
control the bias and variance, and characterize the trade-off between them. As
an advantage of off-policy sampling, a major feature of our result is that we
do not need any additional assumptions, beyond the ergodicity of the Markov
chain induced by the behavior policy.
</p>
<a href="http://arxiv.org/abs/2102.09318" target="_blank">arXiv:2102.09318</a> [<a href="http://arxiv.org/pdf/2102.09318" target="_blank">pdf</a>]

<h2>Combining Events and Frames using Recurrent Asynchronous Multimodal Networks for Monocular Depth Prediction. (arXiv:2102.09320v1 [cs.CV])</h2>
<h3>Daniel Gehrig, Michelle R&#xfc;egg, Mathias Gehrig, Javier Hidalgo Carrio, Davide Scaramuzza</h3>
<p>Event cameras are novel vision sensors that report per-pixel brightness
changes as a stream of asynchronous "events". They offer significant advantages
compared to standard cameras due to their high temporal resolution, high
dynamic range and lack of motion blur. However, events only measure the varying
component of the visual signal, which limits their ability to encode scene
context. By contrast, standard cameras measure absolute intensity frames, which
capture a much richer representation of the scene. Both sensors are thus
complementary. However, due to the asynchronous nature of events, combining
them with synchronous images remains challenging, especially for learning-based
methods. This is because traditional recurrent neural networks (RNNs) are not
designed for asynchronous and irregular data from additional sensors. To
address this challenge, we introduce Recurrent Asynchronous Multimodal (RAM)
networks, which generalize traditional RNNs to handle asynchronous and
irregular data from multiple sensors. Inspired by traditional RNNs, RAM
networks maintain a hidden state that is updated asynchronously and can be
queried at any time to generate a prediction. We apply this novel architecture
to monocular depth estimation with events and frames where we show an
improvement over state-of-the-art methods by up to 30% in terms of mean
absolute depth error. To enable further research on multimodal learning with
events, we release EventScape, a new dataset with events, intensity frames,
semantic labels, and depth maps recorded in the CARLA simulator.
</p>
<a href="http://arxiv.org/abs/2102.09320" target="_blank">arXiv:2102.09320</a> [<a href="http://arxiv.org/pdf/2102.09320" target="_blank">pdf</a>]

<h2>Deep Miner: A Deep and Multi-branch Network which Mines Rich and Diverse Features for Person Re-identification. (arXiv:2102.09321v1 [cs.CV])</h2>
<h3>Abdallah Benzine, Mohamed El Amine Seddik, Julien Desmarais</h3>
<p>Most recent person re-identification approaches are based on the use of deep
convolutional neural networks (CNNs). These networks, although effective in
multiple tasks such as classification or object detection, tend to focus on the
most discriminative part of an object rather than retrieving all its relevant
features. This behavior penalizes the performance of a CNN for the
re-identification task, since it should identify diverse and fine grained
features. It is then essential to make the network learn a wide variety of
finer characteristics in order to make the re-identification process of people
effective and robust to finer changes. In this article, we introduce Deep
Miner, a method that allows CNNs to "mine" richer and more diverse features
about people for their re-identification. Deep Miner is specifically composed
of three types of branches: a Global branch (G-branch), a Local branch
(L-branch) and an Input-Erased branch (IE-branch). G-branch corresponds to the
initial backbone which predicts global characteristics, while L-branch
retrieves part level resolution features. The IE-branch for its part, receives
partially suppressed feature maps as input thereby allowing the network to
"mine" new features (those ignored by G-branch) as output. For this special
purpose, a dedicated suppression procedure for identifying and removing
features within a given CNN is introduced. This suppression procedure has the
major benefit of being simple, while it produces a model that significantly
outperforms state-of-the-art (SOTA) re-identification methods. Specifically, we
conduct experiments on four standard person re-identification benchmarks and
witness an absolute performance gain up to 6.5% mAP compared to SOTA.
</p>
<a href="http://arxiv.org/abs/2102.09321" target="_blank">arXiv:2102.09321</a> [<a href="http://arxiv.org/pdf/2102.09321" target="_blank">pdf</a>]

<h2>Harnessing Tensor Structures -- Multi-Mode Reservoir Computing and Its Application in Massive MIMO. (arXiv:2102.09322v1 [cs.LG])</h2>
<h3>Zhou Zhou, Lingjia Liu, Jiarui Xu</h3>
<p>In this paper, we introduce a new neural network (NN) structure, multi-mode
reservoir computing (Multi-Mode RC). It inherits the dynamic mechanism of RC
and processes the forward path and loss optimization of the NN using tensor as
the underlying data format. Multi-Mode RC exhibits less complexity compared
with conventional RC structures (e.g. single-mode RC) with comparable
generalization performance. Furthermore, we introduce an alternating least
square-based learning algorithm for Multi-Mode RC as well as conduct the
associated theoretical analysis. The result can be utilized to guide the
configuration of NN parameters to sufficiently circumvent over-fitting issues.
As a key application, we consider the symbol detection task in
multiple-input-multiple-output (MIMO)
orthogonal-frequency-division-multiplexing (OFDM) systems with massive MIMO
employed at the base stations (BSs). Thanks to the tensor structure of massive
MIMO-OFDM signals, our online learning-based symbol detection method
generalizes well in terms of bit error rate even using a limited online
training set. Evaluation results suggest that the Multi-Mode RC-based learning
framework can efficiently and effectively combat practical constraints of
wireless systems (i.e. channel state information (CSI) errors and hardware
non-linearity) to enable robust and adaptive learning-based communications over
the air.
</p>
<a href="http://arxiv.org/abs/2102.09322" target="_blank">arXiv:2102.09322</a> [<a href="http://arxiv.org/pdf/2102.09322" target="_blank">pdf</a>]

<h2>HVAQ: A High-Resolution Vision-Based Air Quality Dataset. (arXiv:2102.09332v1 [cs.CV])</h2>
<h3>Zuohui Chen, Tony Zhang, Zhuangzhi Chen, Yun Xiang, Qi Xuan, Robert P. Dick</h3>
<p>Air pollutants, such as particulate matter, strongly impact human health.
Most existing pollution monitoring techniques use stationary sensors, which are
typically sparsely deployed. However, real-world pollution distributions vary
rapidly in space and the visual effects of air pollutant can be used to
estimate concentration, potentially at high spatial resolution. Accurate
pollution monitoring requires either densely deployed conventional point
sensors, at-a-distance vision-based pollution monitoring, or a combination of
both.

This paper makes the following contributions: (1) we present a high temporal
and spatial resolution air quality dataset consisting of PM2.5, PM10,
temperature, and humidity data; (2) we simultaneously take images covering the
locations of the particle counters; and (3) we evaluate several vision-based
state-of-art PM concentration prediction algorithms on our dataset and
demonstrate that prediction accuracy increases with sensor density and image.
It is our intent and belief that this dataset can enable advances by other
research teams working on air quality estimation.
</p>
<a href="http://arxiv.org/abs/2102.09332" target="_blank">arXiv:2102.09332</a> [<a href="http://arxiv.org/pdf/2102.09332" target="_blank">pdf</a>]

<h2>StablePose: Learning 6D Object Poses from Geometrically Stable Patches. (arXiv:2102.09334v1 [cs.CV])</h2>
<h3>Junwen Huang, Yifei Shi, Xin Xu, Yifan Zhang, Kai Xu</h3>
<p>We introduce the concept of geometric stability to the problem of 6D object
pose estimation and propose to learn pose inference based on geometrically
stable patches extracted from observed 3D point clouds. According to the theory
of geometric stability analysis, a minimal set of three planar/cylindrical
patches are geometrically stable and determine the full 6DoFs of the object
pose. We train a deep neural network to regress 6D object pose based on
geometrically stable patch groups via learning both intra-patch geometric
features and inter-patch contextual features. A subnetwork is jointly trained
to predict per-patch poses. This auxiliary task is a relaxation of the group
pose prediction: A single patch cannot determine the full 6DoFs but is able to
improve pose accuracy in its corresponding DoFs. Working with patch groups
makes our method generalize well for random occlusion and unseen instances. The
method is easily amenable to resolve symmetry ambiguities. Our method achieves
the state-of-the-art results on public benchmarks compared not only to
depth-only but also to RGBD methods. It also performs well in category-level
pose estimation.
</p>
<a href="http://arxiv.org/abs/2102.09334" target="_blank">arXiv:2102.09334</a> [<a href="http://arxiv.org/pdf/2102.09334" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Datacenter Congestion Control. (arXiv:2102.09337v1 [cs.LG])</h2>
<h3>Chen Tessler, Yuval Shpigelman, Gal Dalal, Amit Mandelbaum, Doron Haritan Kazakov, Benjamin Fuhrer, Gal Chechik, Shie Mannor</h3>
<p>We approach the task of network congestion control in datacenters using
Reinforcement Learning (RL). Successful congestion control algorithms can
dramatically improve latency and overall network throughput. Until today, no
such learning-based algorithms have shown practical potential in this domain.
Evidently, the most popular recent deployments rely on rule-based heuristics
that are tested on a predetermined set of benchmarks. Consequently, these
heuristics do not generalize well to newly-seen scenarios. Contrarily, we
devise an RL-based algorithm with the aim of generalizing to different
configurations of real-world datacenter networks. We overcome challenges such
as partial-observability, non-stationarity, and multi-objectiveness. We further
propose a policy gradient algorithm that leverages the analytical structure of
the reward function to approximate its derivative and improve stability. We
show that this scheme outperforms alternative popular RL approaches, and
generalizes to scenarios that were not seen during training. Our experiments,
conducted on a realistic simulator that emulates communication networks'
behavior, exhibit improved performance concurrently on the multiple considered
metrics compared to the popular algorithms deployed today in real datacenters.
Our algorithm is being productized to replace heuristics in some of the largest
datacenters in the world.
</p>
<a href="http://arxiv.org/abs/2102.09337" target="_blank">arXiv:2102.09337</a> [<a href="http://arxiv.org/pdf/2102.09337" target="_blank">pdf</a>]

<h2>Domain Adaptive Learning Based on Sample-Dependent and Learnable Kernels. (arXiv:2102.09340v1 [cs.LG])</h2>
<h3>Xinlong Lu, Zhengming Ma, Yuanping Lin</h3>
<p>Reproducing Kernel Hilbert Space (RKHS) is the common mathematical platform
for various kernel methods in machine learning. The purpose of kernel learning
is to learn an appropriate RKHS according to different machine learning
scenarios and training samples. Because RKHS is uniquely generated by the
kernel function, kernel learning can be regarded as kernel function learning.
This paper proposes a Domain Adaptive Learning method based on Sample-Dependent
and Learnable Kernels (SDLK-DAL). The first contribution of our work is to
propose a sample-dependent and learnable Positive Definite Quadratic Kernel
function (PDQK) framework. Unlike learning the exponential parameter of
Gaussian kernel function or the coefficient of kernel combinations, the
proposed PDQK is a positive definite quadratic function, in which the symmetric
positive semi-definite matrix is the learnable part in machine learning
applications. The second contribution lies on that we apply PDQK to Domain
Adaptive Learning (DAL). Our approach learns the PDQK through minimizing the
mean discrepancy between the data of source domain and target domain and then
transforms the data into an optimized RKHS generated by PDQK. We conduct a
series of experiments that the RKHS determined by PDQK replaces those in
several state-of-the-art DAL algorithms, and our approach achieves better
performance.
</p>
<a href="http://arxiv.org/abs/2102.09340" target="_blank">arXiv:2102.09340</a> [<a href="http://arxiv.org/pdf/2102.09340" target="_blank">pdf</a>]

<h2>A Comprehensive Review of Deep Learning-based Single Image Super-resolution. (arXiv:2102.09351v1 [cs.CV])</h2>
<h3>Syed Muhammad Arsalan Bashir, Yi Wang, Mahrukh Khan</h3>
<p>Image super-resolution (SR) is one of the vital image processing methods that
improve the resolution of an image in the field of computer vision. In the last
two decades, significant progress has been made in the field of
super-resolution, especially utilizing deep learning methods. This survey is an
effort to provide a detailed survey of recent progress in the field of
super-resolution in the perspective of deep learning while also informing about
the initial classical methods used for achieving super-resolution. The survey
classifies the image SR methods into four categories, i.e., classical methods,
supervised learning-based methods, unsupervised learning-based methods, and
domain-specific SR methods. We also introduce the problem of SR to provide
intuition about image quality metrics, available reference datasets, and SR
challenges. Deep learning-based approaches of SR are evaluated using a
reference dataset. Finally, this survey is concluded with future directions and
trends in the field of SR and open problems in SR to be addressed by the
researchers.
</p>
<a href="http://arxiv.org/abs/2102.09351" target="_blank">arXiv:2102.09351</a> [<a href="http://arxiv.org/pdf/2102.09351" target="_blank">pdf</a>]

<h2>Efficient Reinforcement Learning in Resource Allocation Problems Through Permutation Invariant Multi-task Learning. (arXiv:2102.09361v1 [cs.LG])</h2>
<h3>Desmond Cai, Shiau Hong Lim, Laura Wynter</h3>
<p>One of the main challenges in real-world reinforcement learning is to learn
successfully from limited training samples. We show that in certain settings,
the available data can be dramatically increased through a form of multi-task
learning, by exploiting an invariance property in the tasks. We provide a
theoretical performance bound for the gain in sample efficiency under this
setting. This motivates a new approach to multi-task learning, which involves
the design of an appropriate neural network architecture and a prioritized
task-sampling strategy. We demonstrate empirically the effectiveness of the
proposed approach on two real-world sequential resource allocation tasks where
this invariance property occurs: financial portfolio optimization and meta
federated learning.
</p>
<a href="http://arxiv.org/abs/2102.09361" target="_blank">arXiv:2102.09361</a> [<a href="http://arxiv.org/pdf/2102.09361" target="_blank">pdf</a>]

<h2>Hierarchical Similarity Learning for Language-based Product Image Retrieval. (arXiv:2102.09375v1 [cs.CV])</h2>
<h3>Zhe Ma, Fenghao Liu, Jianfeng Dong, Xiaoye Qu, Yuan He, Shouling Ji</h3>
<p>This paper aims for the language-based product image retrieval task. The
majority of previous works have made significant progress by designing network
structure, similarity measurement, and loss function. However, they typically
perform vision-text matching at certain granularity regardless of the intrinsic
multiple granularities of images. In this paper, we focus on the cross-modal
similarity measurement, and propose a novel Hierarchical Similarity Learning
(HSL) network. HSL first learns multi-level representations of input data by
stacked encoders, and object-granularity similarity and image-granularity
similarity are computed at each level. All the similarities are combined as the
final hierarchical cross-modal similarity. Experiments on a large-scale product
retrieval dataset demonstrate the effectiveness of our proposed method. Code
and data are available at https://github.com/liufh1/hsl.
</p>
<a href="http://arxiv.org/abs/2102.09375" target="_blank">arXiv:2102.09375</a> [<a href="http://arxiv.org/pdf/2102.09375" target="_blank">pdf</a>]

<h2>L2E: Learning to Exploit Your Opponent. (arXiv:2102.09381v1 [cs.LG])</h2>
<h3>Zhe Wu, Kai Li, Enmin Zhao, Hang Xu, Meng Zhang, Haobo Fu, Bo An, Junliang Xing</h3>
<p>Opponent modeling is essential to exploit sub-optimal opponents in strategic
interactions. Most previous works focus on building explicit models to directly
predict the opponents' styles or strategies, which require a large amount of
data to train the model and lack adaptability to unknown opponents. In this
work, we propose a novel Learning to Exploit (L2E) framework for implicit
opponent modeling. L2E acquires the ability to exploit opponents by a few
interactions with different opponents during training, thus can adapt to new
opponents with unknown styles during testing quickly. We propose a novel
opponent strategy generation algorithm that produces effective opponents for
training automatically. We evaluate L2E on two poker games and one grid soccer
game, which are the commonly used benchmarks for opponent modeling.
Comprehensive experimental results indicate that L2E quickly adapts to diverse
styles of unknown opponents.
</p>
<a href="http://arxiv.org/abs/2102.09381" target="_blank">arXiv:2102.09381</a> [<a href="http://arxiv.org/pdf/2102.09381" target="_blank">pdf</a>]

<h2>Recommending Training Set Sizes for Classification. (arXiv:2102.09382v1 [cs.LG])</h2>
<h3>Phillip Koshute, Jared Zook, Ian McCulloh</h3>
<p>Based on a comprehensive study of 20 established data sets, we recommend
training set sizes for any classification data set. We obtain our
recommendations by systematically withholding training data and developing
models through five different classification methods for each resulting
training set. Based on these results, we construct accuracy confidence
intervals for each training set size and fit the lower bounds to inverse power
low learning curves. We also estimate a sufficient training set size (STSS) for
each data set based on established convergence criteria. We compare STSS to the
data sets' characteristics; based on identified trends, we recommend training
set sizes between 3000 and 30000 data points, according to a data set's number
of classes and number of features. Because obtaining and preparing training
data has non-negligible costs that are proportional to data set size, these
results afford the potential opportunity for substantial savings for predictive
modeling efforts.
</p>
<a href="http://arxiv.org/abs/2102.09382" target="_blank">arXiv:2102.09382</a> [<a href="http://arxiv.org/pdf/2102.09382" target="_blank">pdf</a>]

<h2>Convergence of stochastic gradient descent schemes for Lojasiewicz-landscapes. (arXiv:2102.09385v1 [cs.LG])</h2>
<h3>Steffen Dereich, Sebastian Kassing</h3>
<p>In this article, we consider convergence of stochastic gradient descent
schemes (SGD) under weak assumptions on the underlying landscape. More
explicitly, we show that on the event that the SGD stays local we have
convergence of the SGD if there is only a countable number of critical points
or if the target function/landscape satisfies Lojasiewicz-inequalities around
all critical levels as all analytic functions do. In particular, we show that
for neural networks with analytic activation function such as softplus, sigmoid
and the hyperbolic tangent, SGD converges on the event of staying local, if the
random variables modeling the signal and response in the training are compactly
supported.
</p>
<a href="http://arxiv.org/abs/2102.09385" target="_blank">arXiv:2102.09385</a> [<a href="http://arxiv.org/pdf/2102.09385" target="_blank">pdf</a>]

<h2>Early Detection of Fish Diseases by Analyzing Water Quality Using Machine Learning Algorithm. (arXiv:2102.09390v1 [cs.LG])</h2>
<h3>Al-Akhir Nayan, Ahamad Nokib Mozumder, Joyeta Saha, Khan Raqib Mahmud, Abul Kalam Al Azad</h3>
<p>Early detection of fish diseases and identifying the underlying causes are
crucial for farmers to take necessary steps to mitigate the potential outbreak,
and thus to avert financial losses with apparent negative implications to
national economy. Typically, fish diseases are caused by virus and bacteria;
according to biochemical studies, the presence of certain bacteria and virus
may affect the level of pH, DO, BOD, COD, TSS, TDS, EC, PO43-, NO3-N, and NH3-N
in water, resulting in the death of fishes. Besides, natural processes, e.g.,
photosynthesis, respiration, and decomposition also contribute to the
alteration of water quality that adversely affects fish health. Being motivated
by the recent successes of machine learning techniques in complex relational
data analyses in accurate classification and decision-making tasks, a
state-of-art machine learning algorithm has been adopted in this paper to
detect and predict the degradation of water quality timely and accurately, thus
it helps taking pre-emptive steps against potential fish diseases. The
experimental results show a high accuracy in detecting fish diseases particular
to specific water quality based on the algorithm with real datasets.
</p>
<a href="http://arxiv.org/abs/2102.09390" target="_blank">arXiv:2102.09390</a> [<a href="http://arxiv.org/pdf/2102.09390" target="_blank">pdf</a>]

<h2>Robust PDF Document Conversion Using Recurrent Neural Networks. (arXiv:2102.09395v1 [cs.LG])</h2>
<h3>Nikolaos Livathinos (1), Cesar Berrospi (1), Maksym Lysak (1), Viktor Kuropiatnyk (1), Ahmed Nassar (1), Andre Carvalho (1), Michele Dolfi (1), Christoph Auer (1), Kasper Dinkla (1), Peter Staar (1) ((1) IBM Research)</h3>
<p>The number of published PDF documents has increased exponentially in recent
decades. There is a growing need to make their rich content discoverable to
information retrieval tools. In this paper, we present a novel approach to
document structure recovery in PDF using recurrent neural networks to process
the low-level PDF data representation directly, instead of relying on a visual
re-interpretation of the rendered PDF page, as has been proposed in previous
literature. We demonstrate how a sequence of PDF printing commands can be used
as input into a neural network and how the network can learn to classify each
printing command according to its structural function in the page. This
approach has three advantages: First, it can distinguish among more
fine-grained labels (typically 10-20 labels as opposed to 1-5 with visual
methods), which results in a more accurate and detailed document structure
resolution. Second, it can take into account the text flow across pages more
naturally compared to visual methods because it can concatenate the printing
commands of sequential pages. Last, our proposed method needs less memory and
it is computationally less expensive than visual methods. This allows us to
deploy such models in production environments at a much lower cost. Through
extensive architectural search in combination with advanced feature
engineering, we were able to implement a model that yields a weighted average
F1 score of 97% across 17 distinct structural labels. The best model we
achieved is currently served in production environments on our Corpus
Conversion Service (CCS), which was presented at KDD18 (arXiv:1806.02284). This
model enhances the capabilities of CCS significantly, as it eliminates the need
for human annotated label ground-truth for every unseen document layout. This
proved particularly useful when applied to a huge corpus of PDF articles
related to COVID-19.
</p>
<a href="http://arxiv.org/abs/2102.09395" target="_blank">arXiv:2102.09395</a> [<a href="http://arxiv.org/pdf/2102.09395" target="_blank">pdf</a>]

<h2>A Reinforcement learning method for Optical Thin-Film Design. (arXiv:2102.09398v1 [cs.LG])</h2>
<h3>Anqing Jiang, Liangyao Chen, Osamu Yoshie</h3>
<p>Machine learning, especially deep learning, is dramatically changing the
methods associated with optical thin-film inverse design. The vast majority of
this research has focused on the parameter optimization (layer thickness, and
structure size) of optical thin-films. A challenging problem that arises is an
automated material search. In this work, we propose a new end-to-end algorithm
for optical thin-film inverse design. This method combines the ability of
unsupervised learning, reinforcement learning(RL) and includes a genetic
algorithm to design an optical thin-film without any human intervention.
Furthermore, with several concrete examples, we have shown how one can use this
technique to optimize the spectra of a multi-layer solar absorber device.
</p>
<a href="http://arxiv.org/abs/2102.09398" target="_blank">arXiv:2102.09398</a> [<a href="http://arxiv.org/pdf/2102.09398" target="_blank">pdf</a>]

<h2>The Wavefunction of Continuous-Time Recurrent Neural Networks. (arXiv:2102.09399v1 [cs.LG])</h2>
<h3>Ikjyot Singh Kohli, Michael C. Haslam</h3>
<p>In this paper, we explore the possibility of deriving a quantum wavefunction
for continuous-time recurrent neural network (CTRNN). We did this by first
starting with a two-dimensional dynamical system that describes the classical
dynamics of a continuous-time recurrent neural network, and then deriving a
Hamiltonian. After this, we quantized this Hamiltonian on a Hilbert space
$\mathbb{H} = L^2(\mathbb{R})$ using Weyl quantization. We then solved the
Schrodinger equation which gave us the wavefunction in terms of Kummer's
confluent hypergeometric function corresponding to the neural network
structure. Upon applying spatial boundary conditions at infinity, we were able
to derive conditions/restrictions on the weights and hyperparameters of the
neural network, which could potentially give insights on the the nature of
finding optimal weights of said neural networks.
</p>
<a href="http://arxiv.org/abs/2102.09399" target="_blank">arXiv:2102.09399</a> [<a href="http://arxiv.org/pdf/2102.09399" target="_blank">pdf</a>]

<h2>Recurrent Rational Networks. (arXiv:2102.09407v1 [cs.LG])</h2>
<h3>Quentin Delfosse, Patrick Schramowski, Alejandro Molina, Kristian Kersting</h3>
<p>Latest insights from biology show that intelligence does not only emerge from
the connections between the neurons, but that individual neurons shoulder more
computational responsibility. Current Neural Network architecture design and
search are biased on fixed activation functions. Using more advanced learnable
activation functions provide Neural Networks with higher learning capacity.
However, general guidance for building such networks is still missing. In this
work, we first explain why rationals offer an optimal choice for activation
functions. We then show that they are closed under residual connections, and
inspired by recurrence for residual networks we derive a self-regularized
version of Rationals: Recurrent Rationals. We demonstrate that (Recurrent)
Rational Networks lead to high performance improvements on Image Classification
and Deep Reinforcement Learning.
</p>
<a href="http://arxiv.org/abs/2102.09407" target="_blank">arXiv:2102.09407</a> [<a href="http://arxiv.org/pdf/2102.09407" target="_blank">pdf</a>]

<h2>A Machine Learning model of the combination of normalized SD1 and SD2 indexes from 24h-Heart Rate Variability as a predictor of myocardial infarction. (arXiv:2102.09410v1 [cs.LG])</h2>
<h3>Antonio Carlos Silva-Filho, Sara Raquel Dutra-Macedo, Adeilson Serra Mendes Vieira, Cristiano Mostarda</h3>
<p>Aim: to evaluate the ability of the nonlinear 24-HRV as a predictor of MI
using Machine Learning Methods: The sample was composed of 218 patients divided
into two groups (Healthy, n=128; MI n=90). The sample dataset is part of the
Telemetric and Holter Electrocardiogram Warehouse (THEW) database, from the
University of Rochester Medical Center. We used the most common ML algorithms
for accuracy comparison with a setting of 10-fold cross-validation (briefly,
Linear Regression, Linear Discriminant Analysis, k-Nearest Neighbour, Random
Forest, Supporting Vector Machine, Na\"ive Bayes, C 5.0 and Stochastic Gradient
Boosting). Results: The main findings of this study show that the combination
of SD1nu + SD2nu has greater predictive power for MI in comparison to other HRV
indexes. Conclusion: The ML model using nonlinear HRV indexes showed to be more
effective than the linear domain, evidenced through the application of ML,
represented by a good precision of the Stochastic Gradient Boosting model.

Keywords: heart rate variability, machine learning, nonlinear domain,
cardiovascular disease
</p>
<a href="http://arxiv.org/abs/2102.09410" target="_blank">arXiv:2102.09410</a> [<a href="http://arxiv.org/pdf/2102.09410" target="_blank">pdf</a>]

<h2>ReSonAte: A Runtime Risk Assessment Framework for Autonomous Systems. (arXiv:2102.09419v1 [cs.RO])</h2>
<h3>Charles Hartsell, Shreyas Ramakrishna, Abhishek Dubey, Daniel Stojcsics, Nagabhushan Mahadevan, Gabor Karsai</h3>
<p>Autonomous CPSs are often required to handle uncertainties and self-manage
the system operation in response to problems and increasing risk in the
operating paradigm. This risk may arise due to distribution shifts,
environmental context, or failure of software or hardware components.
Traditional techniques for risk assessment focus on design-time techniques such
as hazard analysis, risk reduction, and assurance cases among others. However,
these static, design-time techniques do not consider the dynamic contexts and
failures the systems face at runtime. We hypothesize that this requires a
dynamic assurance approach that computes the likelihood of unsafe conditions or
system failures considering the safety requirements, assumptions made at design
time, past failures in a given operating context, and the likelihood of system
component failures. We introduce the ReSonAte dynamic risk estimation framework
for autonomous systems. ReSonAte reasons over Bow-Tie Diagrams (BTDs) which
capture information about hazard propagation paths and control strategies. Our
innovation is the extension of the BTD formalism with attributes for modeling
the conditional relationships with the state of the system and environment. We
also describe a technique for estimating these conditional relationships and
equations for estimating risk based on the state of the system and environment.
To help with this process, we provide a scenario modeling procedure that can
use the prior distributions of the scenes and threat conditions to generate the
data required for estimating the conditional relationships. To improve
scalability and reduce the amount of data required, this process considers each
control strategy in isolation and composes several single-variate distributions
into one complete multi-variate distribution for the control strategy in
question.
</p>
<a href="http://arxiv.org/abs/2102.09419" target="_blank">arXiv:2102.09419</a> [<a href="http://arxiv.org/pdf/2102.09419" target="_blank">pdf</a>]

<h2>Deep Learning for Suicide and Depression Identification with Unsupervised Label Correction. (arXiv:2102.09427v1 [cs.LG])</h2>
<h3>Ayaan Haque, Viraaj Reddi, Tyler Giallanza</h3>
<p>Early detection of suicidal ideation in depressed individuals can allow for
adequate medical attention and support, which in many cases is life-saving.
Recent NLP research focuses on classifying, from a given piece of text, if an
individual is suicidal or clinically healthy. However, there have been no major
attempts to differentiate between depression and suicidal ideation, which is an
important clinical challenge. Due to the scarce availability of EHR data,
suicide notes, or other similar verified sources, web query data has emerged as
a promising alternative. Online sources, such as Reddit, allow for anonymity
that prompts honest disclosure of symptoms, making it a plausible source even
in a clinical setting. However, these online datasets also result in lower
performance, which can be attributed to the inherent noise in web-scraped
labels, which necessitates a noise-removal process. Thus, we propose SDCNL, a
suicide versus depression classification method through a deep learning
approach. We utilize online content from Reddit to train our algorithm, and to
verify and correct noisy labels, we propose a novel unsupervised label
correction method which, unlike previous work, does not require prior noise
distribution information. Our extensive experimentation with multiple deep word
embedding models and classifiers display the strong performance of the method
in anew, challenging classification application. We make our code and dataset
available at https://github.com/ayaanzhaque/SDCNL
</p>
<a href="http://arxiv.org/abs/2102.09427" target="_blank">arXiv:2102.09427</a> [<a href="http://arxiv.org/pdf/2102.09427" target="_blank">pdf</a>]

<h2>State Entropy Maximization with Random Encoders for Efficient Exploration. (arXiv:2102.09430v1 [cs.LG])</h2>
<h3>Younggyo Seo, Lili Chen, Jinwoo Shin, Honglak Lee, Pieter Abbeel, Kimin Lee</h3>
<p>Recent exploration methods have proven to be a recipe for improving
sample-efficiency in deep reinforcement learning (RL). However, efficient
exploration in high-dimensional observation spaces still remains a challenge.
This paper presents Random Encoders for Efficient Exploration (RE3), an
exploration method that utilizes state entropy as an intrinsic reward. In order
to estimate state entropy in environments with high-dimensional observations,
we utilize a k-nearest neighbor entropy estimator in the low-dimensional
representation space of a convolutional encoder. In particular, we find that
the state entropy can be estimated in a stable and compute-efficient manner by
utilizing a randomly initialized encoder, which is fixed throughout training.
Our experiments show that RE3 significantly improves the sample-efficiency of
both model-free and model-based RL methods on locomotion and navigation tasks
from DeepMind Control Suite and MiniGrid benchmarks. We also show that RE3
allows learning diverse behaviors without extrinsic rewards, effectively
improving sample-efficiency in downstream tasks. Source code and videos are
available at https://sites.google.com/view/re3-rl.
</p>
<a href="http://arxiv.org/abs/2102.09430" target="_blank">arXiv:2102.09430</a> [<a href="http://arxiv.org/pdf/2102.09430" target="_blank">pdf</a>]

<h2>Don't Fix What ain't Broke: Near-optimal Local Convergence of Alternating Gradient Descent-Ascent for Minimax Optimization. (arXiv:2102.09468v1 [cs.LG])</h2>
<h3>Guodong Zhang, Yuanhao Wang, Laurent Lessard, Roger Grosse</h3>
<p>Minimax optimization has recently gained a lot of attention as adversarial
architectures and algorithms proliferate. Often, smooth minimax games proceed
by simultaneous or alternating gradient updates. Although algorithms with
alternating updates are commonly used in practice for many applications (e.g.,
GAN training), the majority of existing theoretical analyses focus on
simultaneous algorithms. In this paper, we study alternating gradient
descent-ascent (Alt-GDA) in minimax games and show that Alt-GDA is superior to
its simultaneous counterpart (Sim-GDA) in many settings. In particular, we
prove that Alt-GDA achieves a near-optimal local convergence rate for
strongly-convex strongly-concave problems while Sim-GDA converges with a much
slower rate. Moreover, we show that the acceleration effect of alternating
updates remains when the minimax problem has only strong concavity in the dual
variables. Numerical experiments on quadratic minimax games validate our
claims. Additionally, we demonstrate that alternating updates speed up GAN
training significantly and the use of optimism only helps for simultaneous
algorithms.
</p>
<a href="http://arxiv.org/abs/2102.09468" target="_blank">arXiv:2102.09468</a> [<a href="http://arxiv.org/pdf/2102.09468" target="_blank">pdf</a>]

<h2>Optimising Long-Term Outcomes using Real-World Fluent Objectives: An Application to Football. (arXiv:2102.09469v1 [cs.AI])</h2>
<h3>Ryan Beal, Georgios Chalkiadakis, Timothy J. Norman, Sarvapali D. Ramchurn</h3>
<p>In this paper, we present a novel approach for optimising long-term tactical
and strategic decision-making in football (soccer) by encapsulating events in a
league environment across a given time frame. We model the teams' objectives
for a season and track how these evolve as games unfold to give a fluent
objective that can aid in decision-making games. We develop Markov chain Monte
Carlo and deep learning-based algorithms that make use of the fluent objectives
in order to learn from prior games and other games in the environment and
increase the teams' long-term performance. Simulations of our approach using
real-world datasets from 760 matches shows that by using optimised tactics with
our fluent objective and prior games, we can on average increase teams mean
expected finishing distribution in the league by up to 35.6%.
</p>
<a href="http://arxiv.org/abs/2102.09469" target="_blank">arXiv:2102.09469</a> [<a href="http://arxiv.org/pdf/2102.09469" target="_blank">pdf</a>]

<h2>DeeperForensics Challenge 2020 on Real-World Face Forgery Detection: Methods and Results. (arXiv:2102.09471v1 [cs.CV])</h2>
<h3>Liming Jiang, Zhengkui Guo, Wayne Wu, Zhaoyang Liu, Ziwei Liu, Chen Change Loy, Shuo Yang, Yuanjun Xiong, Wei Xia, Baoying Chen, Peiyu Zhuang, Sili Li, Shen Chen, Taiping Yao, Shouhong Ding, Jilin Li, Feiyue Huang, Liujuan Cao, Rongrong Ji, Changlei Lu, Ganchao Tan</h3>
<p>This paper reports methods and results in the DeeperForensics Challenge 2020
on real-world face forgery detection. The challenge employs the
DeeperForensics-1.0 dataset, one of the most extensive publicly available
real-world face forgery detection datasets, with 60,000 videos constituted by a
total of 17.6 million frames. The model evaluation is conducted online on a
high-quality hidden test set with multiple sources and diverse distortions. A
total of 115 participants registered for the competition, and 25 teams made
valid submissions. We will summarize the winning solutions and present some
discussions on potential research directions.
</p>
<a href="http://arxiv.org/abs/2102.09471" target="_blank">arXiv:2102.09471</a> [<a href="http://arxiv.org/pdf/2102.09471" target="_blank">pdf</a>]

<h2>Gifsplanation via Latent Shift: A Simple Autoencoder Approach to Progressive Exaggeration on Chest X-rays. (arXiv:2102.09475v1 [cs.CV])</h2>
<h3>Joseph Paul Cohen, Rupert Brooks, Sovann En, Evan Zucker, Anuj Pareek, Matthew P. Lungren, Akshay Chaudhari</h3>
<p>Motivation: Traditional image attribution methods struggle to satisfactorily
explain predictions of neural networks. Prediction explanation is important,
especially in the medical imaging, for avoiding the unintended consequences of
deploying AI systems when false positive predictions can impact patient care.
Thus, there is a pressing need to develop improved models for model
explainability and introspection.

Specific Problem: A new approach is to transform input images to increase or
decrease features which cause the prediction. However, current approaches are
difficult to implement as they are monolithic or rely on GANs. These hurdles
prevent wide adoption.

Our approach: Given an arbitrary classifier, we propose a simple autoencoder
and gradient update (Latent Shift) that can transform the latent representation
of an input image to exaggerate or curtail the features used for prediction. We
use this method to study chest X-ray classifiers and evaluate their
performance. We conduct a reader study with two radiologists assessing 240
chest X-ray predictions to identify which ones are false positives (half are)
using traditional attribution maps or our proposed method.

Results: We found low overlap with ground truth pathology masks for models
with reasonably high accuracy. However, the results from our reader study
indicate that these models are generally looking at the correct features. We
also found that the Latent Shift explanation allows a user to have more
confidence in true positive predictions compared to traditional approaches
(0.15$\pm$0.95 in a 5 point scale with p=0.01) with only a small increase in
false positive predictions (0.04$\pm$1.06 with p=0.57).

Accompanying webpage: https://mlmed.org/gifsplanation

Source code: https://github.com/mlmed/gifsplanation
</p>
<a href="http://arxiv.org/abs/2102.09475" target="_blank">arXiv:2102.09475</a> [<a href="http://arxiv.org/pdf/2102.09475" target="_blank">pdf</a>]

<h2>Verifying Probabilistic Specifications with Functional Lagrangians. (arXiv:2102.09479v1 [cs.LG])</h2>
<h3>Leonard Berrada, Sumanth Dathathri, Krishnamurthy (Dj) Dvijotham, Robert Stanforth, Rudy Bunel, Jonathan Uesato, Sven Gowal, M. Pawan Kumar</h3>
<p>We propose a general framework for verifying input-output specifications of
neural networks using functional Lagrange multipliers that generalizes standard
Lagrangian duality. We derive theoretical properties of the framework, which
can handle arbitrary probabilistic specifications, showing that it provably
leads to tight verification when a sufficiently flexible class of functional
multipliers is chosen. With a judicious choice of the class of functional
multipliers, the framework can accommodate desired trade-offs between tightness
and complexity. We demonstrate empirically that the framework can handle a
diverse set of networks, including Bayesian neural networks with Gaussian
posterior approximations, MC-dropout networks, and verify specifications on
adversarial robustness and out-of-distribution(OOD) detection. Our framework
improves upon prior work in some settings and also generalizes to new
stochastic networks and probabilistic specifications, like distributionally
robust OOD detection.
</p>
<a href="http://arxiv.org/abs/2102.09479" target="_blank">arXiv:2102.09479</a> [<a href="http://arxiv.org/pdf/2102.09479" target="_blank">pdf</a>]

<h2>Unbiased Teacher for Semi-Supervised Object Detection. (arXiv:2102.09480v1 [cs.CV])</h2>
<h3>Yen-Cheng Liu, Chih-Yao Ma, Zijian He, Chia-Wen Kuo, Kan Chen, Peizhao Zhang, Bichen Wu, Zsolt Kira, Peter Vajda</h3>
<p>Semi-supervised learning, i.e., training networks with both labeled and
unlabeled data, has made significant progress recently. However, existing works
have primarily focused on image classification tasks and neglected object
detection which requires more annotation effort. In this work, we revisit the
Semi-Supervised Object Detection (SS-OD) and identify the pseudo-labeling bias
issue in SS-OD. To address this, we introduce Unbiased Teacher, a simple yet
effective approach that jointly trains a student and a gradually progressing
teacher in a mutually-beneficial manner. Together with a class-balance loss to
downweight overly confident pseudo-labels, Unbiased Teacher consistently
improved state-of-the-art methods by significant margins on COCO-standard,
COCO-additional, and VOC datasets. Specifically, Unbiased Teacher achieves 6.8
absolute mAP improvements against state-of-the-art method when using 1% of
labeled data on MS-COCO, achieves around 10 mAP improvements against the
supervised baseline when using only 0.5, 1, 2% of labeled data on MS-COCO.
</p>
<a href="http://arxiv.org/abs/2102.09480" target="_blank">arXiv:2102.09480</a> [<a href="http://arxiv.org/pdf/2102.09480" target="_blank">pdf</a>]

<h2>A Novel Non-Invasive Estimation of Respiration Rate from Photoplethysmograph Signal Using Machine Learning Model. (arXiv:2102.09483v1 [cs.LG])</h2>
<h3>Md Nazmul Islam Shuzan, Moajjem Hossain Chowdhury, Muhammad E.H. Chowdhury, M. Monir Uddin, Amith Khandakar, Zaid B. Mahbub, Naveed Nawaz</h3>
<p>Respiratory ailments such as asthma, chronic obstructive pulmonary disease
(COPD), pneumonia, and lung cancer are life-threatening. Respiration rate (RR)
is a vital indicator of the wellness of a patient. Continuous monitoring of RR
can provide early indication and thereby save lives. However, a real-time
continuous RR monitoring facility is only available at the intensive care unit
(ICU) due to the size and cost of the equipment. Recent researches have
proposed Photoplethysmogram (PPG) and/ Electrocardiogram (ECG) signals for RR
estimation however, the usage of ECG is limited due to the unavailability of it
in wearable devices. Due to the advent of wearable smartwatches with built-in
PPG sensors, it is now being considered for continuous monitoring of RR. This
paper describes a novel approach to RR estimation using machine learning (ML)
models with the PPG signal features. Feature selection algorithms were used to
reduce computational complexity and the chance of overfitting. The best ML
model and the best feature selection algorithm combination was fine-tuned to
optimize its performance using hyperparameter optimization. Gaussian Process
Regression (GPR) with fitrgp feature selection algorithm outperformed all other
combinations and exhibits a root mean squared error (RMSE), mean absolute error
(MAE), and two-standard deviation (2SD) of 2.57, 1.91, and 5.13 breaths per
minute, respectively. This ML model based RR estimation can be embedded in
wearable devices for real-time continuous monitoring of the patient.
</p>
<a href="http://arxiv.org/abs/2102.09483" target="_blank">arXiv:2102.09483</a> [<a href="http://arxiv.org/pdf/2102.09483" target="_blank">pdf</a>]

<h2>A Bit Better? Quantifying Information for Bandit Learning. (arXiv:2102.09488v1 [cs.LG])</h2>
<h3>Adithya M. Devraj, Benjamin Van Roy, Kuang Xu</h3>
<p>The information ratio offers an approach to assessing the efficacy with which
an agent balances between exploration and exploitation. Originally, this was
defined to be the ratio between squared expected regret and the mutual
information between the environment and action-observation pair, which
represents a measure of information gain. Recent work has inspired
consideration of alternative information measures, particularly for use in
analysis of bandit learning algorithms to arrive at tighter regret bounds. We
investigate whether quantification of information via such alternatives can
improve the realized performance of information-directed sampling, which aims
to minimize the information ratio.
</p>
<a href="http://arxiv.org/abs/2102.09488" target="_blank">arXiv:2102.09488</a> [<a href="http://arxiv.org/pdf/2102.09488" target="_blank">pdf</a>]

<h2>Optimizing Black-box Metrics with Iterative Example Weighting. (arXiv:2102.09492v1 [cs.LG])</h2>
<h3>Gaurush Hiranandani, Jatin Mathur, Oluwasanmi Koyejo, Mahdi Milani Fard, Harikrishna Narasimhan</h3>
<p>We consider learning to optimize a classification metric defined by a
black-box function of the confusion matrix. Such black-box learning settings
are ubiquitous, for example, when the learner only has query access to the
metric of interest, or in noisy-label and domain adaptation applications where
the learner must evaluate the metric via performance evaluation using a small
validation sample. Our approach is to adaptively learn example weights on the
training dataset such that the resulting weighted objective best approximates
the metric on the validation sample. We show how to model and estimate the
example weights and use them to iteratively post-shift a pre-trained class
probability estimator to construct a classifier. We also analyze the resulting
procedure's statistical properties. Experiments on various label noise, domain
shift, and fair classification setups confirm that our proposal is better than
the individual state-of-the-art baselines for each application.
</p>
<a href="http://arxiv.org/abs/2102.09492" target="_blank">arXiv:2102.09492</a> [<a href="http://arxiv.org/pdf/2102.09492" target="_blank">pdf</a>]

<h2>Domain Adaptation for Medical Image Analysis: A Survey. (arXiv:2102.09508v1 [cs.CV])</h2>
<h3>Hao Guan, Mingxia Liu</h3>
<p>Machine learning techniques used in computer-aided medical image analysis
usually suffer from the domain shift problem caused by different distributions
between source/reference data and target data. As a promising solution, domain
adaptation has attracted considerable attention in recent years. The aim of
this paper is to survey the recent advances of domain adaptation methods in
medical image analysis. We first present the motivation of introducing domain
adaptation techniques to tackle domain heterogeneity issues for medical image
analysis. Then we provide a review of recent domain adaptation models in
various medical image analysis tasks. We categorize the existing methods into
shallow and deep models, and each of them is further divided into supervised,
semi-supervised and unsupervised methods. We also provide a brief summary of
the benchmark medical image datasets that support current domain adaptation
research. This survey will enable researchers to gain a better understanding of
the current status, challenges.
</p>
<a href="http://arxiv.org/abs/2102.09508" target="_blank">arXiv:2102.09508</a> [<a href="http://arxiv.org/pdf/2102.09508" target="_blank">pdf</a>]

<h2>Essentials for Class Incremental Learning. (arXiv:2102.09517v1 [cs.CV])</h2>
<h3>Sudhanshu Mittal, Silvio Galesso, Thomas Brox</h3>
<p>Contemporary neural networks are limited in their ability to learn from
evolving streams of training data. When trained sequentially on new or evolving
tasks, their accuracy drops sharply, making them unsuitable for many real-world
applications. In this work, we shed light on the causes of this well-known yet
unsolved phenomenon - often referred to as catastrophic forgetting - in a
class-incremental setup. We show that a combination of simple components and a
loss that balances intra-task and inter-task learning can already resolve
forgetting to the same extent as more complex measures proposed in literature.
Moreover, we identify poor quality of the learned representation as another
reason for catastrophic forgetting in class-IL. We show that performance is
correlated with secondary class information (dark knowledge) learned by the
model and it can be improved by an appropriate regularizer. With these lessons
learned, class-incremental learning results on CIFAR-100 and ImageNet improve
over the state-of-the-art by a large margin, while keeping the approach simple.
</p>
<a href="http://arxiv.org/abs/2102.09517" target="_blank">arXiv:2102.09517</a> [<a href="http://arxiv.org/pdf/2102.09517" target="_blank">pdf</a>]

<h2>Convex regularization in statistical inverse learning problems. (arXiv:2102.09526v1 [stat.ML])</h2>
<h3>Tatiana A. Bubba, Martin Burger, Tapio Helin and</h3>
<p>We consider a statistical inverse learning problem, where the task is to
estimate a function $f$ based on noisy point evaluations of $Af$, where $A$ is
a linear operator. The function $Af$ is evaluated at i.i.d. random design
points $u_n$, $n=1,...,N$ generated by an unknown general probability
distribution. We consider Tikhonov regularization with general convex and
$p$-homogeneous penalty functionals and derive concentration rates of the
regularized solution to the ground truth measured in the symmetric Bregman
distance induced by the penalty functional. We derive concrete rates for Besov
norm penalties and numerically demonstrate the correspondence with the observed
rates in the context of X-ray tomography.
</p>
<a href="http://arxiv.org/abs/2102.09526" target="_blank">arXiv:2102.09526</a> [<a href="http://arxiv.org/pdf/2102.09526" target="_blank">pdf</a>]

<h2>Image Compositing for Segmentation of Surgical Tools without Manual Annotations. (arXiv:2102.09528v1 [cs.CV])</h2>
<h3>Luis C. Garcia-Peraza-Herrera, Lucas Fidon, Claudia D&#x27;Ettorre, Danail Stoyanov, Tom Vercauteren, Sebastien Ourselin</h3>
<p>Producing manual, pixel-accurate, image segmentation labels is tedious and
time-consuming. This is often a rate-limiting factor when large amounts of
labeled images are required, such as for training deep convolutional networks
for instrument-background segmentation in surgical scenes. No large datasets
comparable to industry standards in the computer vision community are available
for this task. To circumvent this problem, we propose to automate the creation
of a realistic training dataset by exploiting techniques stemming from special
effects and harnessing them to target training performance rather than visual
appeal. Foreground data is captured by placing sample surgical instruments over
a chroma key (a.k.a. green screen) in a controlled environment, thereby making
extraction of the relevant image segment straightforward. Multiple lighting
conditions and viewpoints can be captured and introduced in the simulation by
moving the instruments and camera and modulating the light source. Background
data is captured by collecting videos that do not contain instruments. In the
absence of pre-existing instrument-free background videos, minimal labeling
effort is required, just to select frames that do not contain surgical
instruments from videos of surgical interventions freely available online. We
compare different methods to blend instruments over tissue and propose a novel
data augmentation approach that takes advantage of the plurality of options. We
show that by training a vanilla U-Net on semi-synthetic data only and applying
a simple post-processing, we are able to match the results of the same network
trained on a publicly available manually labeled real dataset.
</p>
<a href="http://arxiv.org/abs/2102.09528" target="_blank">arXiv:2102.09528</a> [<a href="http://arxiv.org/pdf/2102.09528" target="_blank">pdf</a>]

<h2>Fuzzy clustering algorithms with distance metric learning and entropy regularization. (arXiv:2102.09529v1 [cs.LG])</h2>
<h3>Sara Ines Rizo Rodriguez, Francisco de Assis Tenorio de Carvalho</h3>
<p>The clustering methods have been used in a variety of fields such as image
processing, data mining, pattern recognition, and statistical analysis.
Generally, the clustering algorithms consider all variables equally relevant or
not correlated for the clustering task. Nevertheless, in real situations, some
variables can be correlated or may be more or less relevant or even irrelevant
for this task. This paper proposes partitioning fuzzy clustering algorithms
based on Euclidean, City-block and Mahalanobis distances and entropy
regularization. These methods are an iterative three steps algorithms which
provide a fuzzy partition, a representative for each fuzzy cluster, and the
relevance weight of the variables or their correlation by minimizing a suitable
objective function. Several experiments on synthetic and real datasets,
including its application to noisy image texture segmentation, demonstrate the
usefulness of these adaptive clustering methods.
</p>
<a href="http://arxiv.org/abs/2102.09529" target="_blank">arXiv:2102.09529</a> [<a href="http://arxiv.org/pdf/2102.09529" target="_blank">pdf</a>]

<h2>Clockwork Variational Autoencoders for Video Prediction. (arXiv:2102.09532v1 [cs.CV])</h2>
<h3>Vaibhav Saxena, Jimmy Ba, Danijar Hafner</h3>
<p>Deep learning has enabled algorithms to generate realistic images. However,
accurately predicting long video sequences requires understanding long-term
dependencies and remains an open challenge. While existing video prediction
models succeed at generating sharp images, they tend to fail at accurately
predicting far into the future. We introduce the Clockwork VAE (CW-VAE), a
video prediction model that leverages a hierarchy of latent sequences, where
higher levels tick at slower intervals. We demonstrate the benefits of both
hierarchical latents and temporal abstraction on 4 diverse video prediction
datasets with sequences of up to 1000 frames, where CW-VAE outperforms top
video prediction models. Additionally, we propose a Minecraft benchmark for
long-term video prediction. We conduct several experiments to gain insights
into CW-VAE and confirm that slower levels learn to represent objects that
change more slowly in the video, and faster levels learn to represent faster
objects.
</p>
<a href="http://arxiv.org/abs/2102.09532" target="_blank">arXiv:2102.09532</a> [<a href="http://arxiv.org/pdf/2102.09532" target="_blank">pdf</a>]

<h2>iX-BSP: Incremental Belief Space Planning. (arXiv:2102.09539v1 [cs.RO])</h2>
<h3>Elad I. Farhi, Vadim Indelman</h3>
<p>Deciding what's next? is a fundamental problem in robotics and Artificial
Intelligence. Under belief space planning (BSP), in a partially observable
setting, it involves calculating the expected accumulated belief-dependent
reward, where the expectation is with respect to all future measurements. Since
solving this general un-approximated problem quickly becomes intractable, state
of the art approaches turn to approximations while still calculating planning
sessions from scratch. In this work we propose a novel paradigm, Incremental
BSP (iX-BSP), based on the key insight that calculations across planning
sessions are similar in nature and can be appropriately re-used. We calculate
the expectation incrementally by utilizing Multiple Importance Sampling
techniques for selective re-sampling and re-use of measurement from previous
planning sessions. The formulation of our approach considers general
distributions and accounts for data association aspects. We demonstrate how
iX-BSP could benefit existing approximations of the general problem,
introducing iML-BSP, which re-uses calculations across planning sessions under
the common Maximum Likelihood assumption. We evaluate both methods and
demonstrate a substantial reduction in computation time while statistically
preserving accuracy. The evaluation includes both simulation and real-world
experiments considering autonomous vision-based navigation and SLAM. As a
further contribution, we introduce to iX-BSP the non-integral wildfire
approximation, allowing one to trade accuracy for computational performance by
averting from updating re-used beliefs when they are "close enough". We
evaluate iX-BSP under wildfire demonstrating a substantial reduction in
computation time while controlling the accuracy sacrifice. We also provide
analytical and empirical bounds of the effect wildfire holds over the objective
value.
</p>
<a href="http://arxiv.org/abs/2102.09539" target="_blank">arXiv:2102.09539</a> [<a href="http://arxiv.org/pdf/2102.09539" target="_blank">pdf</a>]

<h2>Off-policy Confidence Sequences. (arXiv:2102.09540v1 [cs.LG])</h2>
<h3>Nikos Karampatziakis, Paul Mineiro, Aaditya Ramdas</h3>
<p>We develop confidence bounds that hold uniformly over time for off-policy
evaluation in the contextual bandit setting. These confidence sequences are
based on recent ideas from martingale analysis and are non-asymptotic,
non-parametric, and valid at arbitrary stopping times. We provide algorithms
for computing these confidence sequences that strike a good balance between
computational and statistical efficiency. We empirically demonstrate the
tightness of our approach in terms of failure probability and width and apply
it to the "gated deployment" problem of safely upgrading a production
contextual bandit system.
</p>
<a href="http://arxiv.org/abs/2102.09540" target="_blank">arXiv:2102.09540</a> [<a href="http://arxiv.org/pdf/2102.09540" target="_blank">pdf</a>]

<h2>SLAKE: A Semantically-Labeled Knowledge-Enhanced Dataset for Medical Visual Question Answering. (arXiv:2102.09542v1 [cs.CV])</h2>
<h3>Bo Liu, Li-Ming Zhan, Li Xu, Lin Ma, Yan Yang, Xiao-Ming Wu</h3>
<p>Medical visual question answering (Med-VQA) has tremendous potential in
healthcare. However, the development of this technology is hindered by the
lacking of publicly-available and high-quality labeled datasets for training
and evaluation. In this paper, we present a large bilingual dataset, SLAKE,
with comprehensive semantic labels annotated by experienced physicians and a
new structural medical knowledge base for Med-VQA. Besides, SLAKE includes
richer modalities and covers more human body parts than the currently available
dataset. We show that SLAKE can be used to facilitate the development and
evaluation of Med-VQA systems. The dataset can be downloaded from
this http URL
</p>
<a href="http://arxiv.org/abs/2102.09542" target="_blank">arXiv:2102.09542</a> [<a href="http://arxiv.org/pdf/2102.09542" target="_blank">pdf</a>]

<h2>Combinatorial optimization and reasoning with graph neural networks. (arXiv:2102.09544v1 [cs.LG])</h2>
<h3>Quentin Cappart, Didier Ch&#xe9;telat, Elias Khalil, Andrea Lodi, Christopher Morris, Petar Veli&#x10d;kovi&#x107;</h3>
<p>Combinatorial optimization is a well-established area in operations research
and computer science. Until recently, its methods have focused on solving
problem instances in isolation, ignoring the fact that they often stem from
related data distributions in practice. However, recent years have seen a surge
of interest in using machine learning, especially graph neural networks (GNNs),
as a key building block for combinatorial tasks, either as solvers or as helper
functions. GNNs are an inductive bias that effectively encodes combinatorial
and relational input due to their permutation-invariance and sparsity
awareness. This paper presents a conceptual review of recent key advancements
in this emerging field, aiming at both the optimization and machine learning
researcher.
</p>
<a href="http://arxiv.org/abs/2102.09544" target="_blank">arXiv:2102.09544</a> [<a href="http://arxiv.org/pdf/2102.09544" target="_blank">pdf</a>]

<h2>Deep Gait Recognition: A Survey. (arXiv:2102.09546v1 [cs.CV])</h2>
<h3>Alireza Sepas-Moghaddam, Ali Etemad</h3>
<p>Gait recognition is an appealing biometric modality which aims to identify
individuals based on the way they walk. Deep learning has reshaped the research
landscape in this area since 2015 through the ability to automatically learn
discriminative representations. Gait recognition methods based on deep learning
now dominate the state-of-the-art in the field and have fostered real-world
applications. In this paper, we present a comprehensive overview of
breakthroughs and recent developments in gait recognition with deep learning,
and cover broad topics including datasets, test protocols, state-of-the-art
solutions, challenges, and future research directions. We first review the
commonly used gait datasets along with the principles designed for evaluating
them. We then propose a novel taxonomy made up of four separate dimensions
namely body representation, temporal representation, feature representation,
and neural architecture, to help characterize and organize the research
landscape and literature in this area. Following our proposed taxonomy, a
comprehensive survey of gait recognition methods using deep learning is
presented with discussions on their performances, characteristics, advantages,
and limitations. We conclude this survey with a discussion on current
challenges and mention a number of promising directions for future research in
gait recognition.
</p>
<a href="http://arxiv.org/abs/2102.09546" target="_blank">arXiv:2102.09546</a> [<a href="http://arxiv.org/pdf/2102.09546" target="_blank">pdf</a>]

<h2>Therapeutics Data Commons: Machine Learning Datasets and Tasks for Therapeutics. (arXiv:2102.09548v1 [cs.LG])</h2>
<h3>Kexin Huang, Tianfan Fu, Wenhao Gao, Yue Zhao, Yusuf Roohani, Jure Leskovec, Connor W. Coley, Cao Xiao, Jimeng Sun, Marinka Zitnik</h3>
<p>Machine learning for therapeutics is an emerging field with incredible
opportunities for innovation and expansion. Despite the initial success, many
key challenges remain open. Here, we introduce Therapeutics Data Commons (TDC),
the first unifying framework to systematically access and evaluate machine
learning across the entire range of therapeutics. At its core, TDC is a
collection of curated datasets and learning tasks that can translate
algorithmic innovation into biomedical and clinical implementation. To date,
TDC includes 66 machine learning-ready datasets from 22 learning tasks,
spanning the discovery and development of safe and effective medicines. TDC
also provides an ecosystem of tools, libraries, leaderboards, and community
resources, including data functions, strategies for systematic model
evaluation, meaningful data splits, data processors, and molecule generation
oracles. All datasets and learning tasks are integrated and accessible via an
open-source library. We envision that TDC can facilitate algorithmic and
scientific advances and accelerate development, validation, and transition into
production and clinical implementation. TDC is a continuous, open-source
initiative, and we invite contributions from the research community. TDC is
publicly available at https://tdcommons.ai.
</p>
<a href="http://arxiv.org/abs/2102.09548" target="_blank">arXiv:2102.09548</a> [<a href="http://arxiv.org/pdf/2102.09548" target="_blank">pdf</a>]

<h2>Delving into Deep Imbalanced Regression. (arXiv:2102.09554v1 [cs.LG])</h2>
<h3>Yuzhe Yang, Kaiwen Zha, Ying-Cong Chen, Hao Wang, Dina Katabi</h3>
<p>Real-world data often exhibit imbalanced distributions, where certain target
values have significantly fewer observations. Existing techniques for dealing
with imbalanced data focus on targets with categorical indices, i.e., different
classes. However, many tasks involve continuous targets, where hard boundaries
between classes do not exist. We define Deep Imbalanced Regression (DIR) as
learning from such imbalanced data with continuous targets, dealing with
potential missing data for certain target values, and generalizing to the
entire target range. Motivated by the intrinsic difference between categorical
and continuous label space, we propose distribution smoothing for both labels
and features, which explicitly acknowledges the effects of nearby targets, and
calibrates both label and learned feature distributions. We curate and
benchmark large-scale DIR datasets from common real-world tasks in computer
vision, natural language processing, and healthcare domains. Extensive
experiments verify the superior performance of our strategies. Our work fills
the gap in benchmarks and techniques for practical imbalanced regression
problems. Code and data are available at
https://github.com/YyzHarry/imbalanced-regression.
</p>
<a href="http://arxiv.org/abs/2102.09554" target="_blank">arXiv:2102.09554</a> [<a href="http://arxiv.org/pdf/2102.09554" target="_blank">pdf</a>]

<h2>Knowledge Hypergraph Embedding Meets Relational Algebra. (arXiv:2102.09557v1 [cs.LG])</h2>
<h3>Bahare Fatemi, Perouz Taslakian, David Vazquez, David Poole</h3>
<p>Embedding-based methods for reasoning in knowledge hypergraphs learn a
representation for each entity and relation. Current methods do not capture the
procedural rules underlying the relations in the graph. We propose a simple
embedding-based model called ReAlE that performs link prediction in knowledge
hypergraphs (generalized knowledge graphs) and can represent high-level
abstractions in terms of relational algebra operations. We show theoretically
that ReAlE is fully expressive and provide proofs and empirical evidence that
it can represent a large subset of the primitive relational algebra operations,
namely renaming, projection, set union, selection, and set difference. We also
verify experimentally that ReAlE outperforms state-of-the-art models in
knowledge hypergraph completion, and in representing each of these primitive
relational algebra operations. For the latter experiment, we generate a
synthetic knowledge hypergraph, for which we design an algorithm based on the
Erdos-R'enyi model for generating random graphs.
</p>
<a href="http://arxiv.org/abs/2102.09557" target="_blank">arXiv:2102.09557</a> [<a href="http://arxiv.org/pdf/2102.09557" target="_blank">pdf</a>]

<h2>CReST: A Class-Rebalancing Self-Training Framework for Imbalanced Semi-Supervised Learning. (arXiv:2102.09559v1 [cs.CV])</h2>
<h3>Chen Wei, Kihyuk Sohn, Clayton Mellina, Alan Yuille, Fan Yang</h3>
<p>Semi-supervised learning on class-imbalanced data, although a realistic
problem, has been under studied. While existing semi-supervised learning (SSL)
methods are known to perform poorly on minority classes, we find that they
still generate high precision pseudo-labels on minority classes. By exploiting
this property, in this work, we propose Class-Rebalancing Self-Training
(CReST), a simple yet effective framework to improve existing SSL methods on
class-imbalanced data. CReST iteratively retrains a baseline SSL model with a
labeled set expanded by adding pseudo-labeled samples from an unlabeled set,
where pseudo-labeled samples from minority classes are selected more frequently
according to an estimated class distribution. We also propose a progressive
distribution alignment to adaptively adjust the rebalancing strength dubbed
CReST+. We show that CReST and CReST+ improve state-of-the-art SSL algorithms
on various class-imbalanced datasets and consistently outperform other popular
rebalancing methods.
</p>
<a href="http://arxiv.org/abs/2102.09559" target="_blank">arXiv:2102.09559</a> [<a href="http://arxiv.org/pdf/2102.09559" target="_blank">pdf</a>]

<h2>Butterfly: One-step Approach towards Wildly Unsupervised Domain Adaptation. (arXiv:1905.07720v3 [cs.LG] UPDATED)</h2>
<h3>Feng Liu, Jie Lu, Bo Han, Gang Niu, Guangquan Zhang, Masashi Sugiyama</h3>
<p>In unsupervised domain adaptation (UDA), classifiers for the target domain
(TD) are trained with clean labeled data from the source domain (SD) and
unlabeled data from TD. However, in the wild, it is difficult to acquire a
large amount of perfectly clean labeled data in SD given limited budget. Hence,
we consider a new, more realistic and more challenging problem setting, where
classifiers have to be trained with noisy labeled data from SD and unlabeled
data from TD -- we name it wildly UDA (WUDA). We show that WUDA ruins all UDA
methods if taking no care of label noise in SD, and to this end, we propose a
Butterfly framework, a powerful and efficient solution to WUDA. Butterfly
maintains four deep networks simultaneously, where two take care of all
adaptations (i.e., noisy-to-clean, labeled-to-unlabeled, and
SD-to-TD-distributional) and then the other two can focus on classification in
TD. As a consequence, Butterfly possesses all the conceptually necessary
components for solving WUDA. Experiments demonstrate that, under WUDA,
Butterfly significantly outperforms existing baseline methods.
</p>
<a href="http://arxiv.org/abs/1905.07720" target="_blank">arXiv:1905.07720</a> [<a href="http://arxiv.org/pdf/1905.07720" target="_blank">pdf</a>]

<h2>Reward Tampering Problems and Solutions in Reinforcement Learning: A Causal Influence Diagram Perspective. (arXiv:1908.04734v4 [cs.AI] UPDATED)</h2>
<h3>Tom Everitt, Marcus Hutter, Ramana Kumar, Victoria Krakovna</h3>
<p>Can humans get arbitrarily capable reinforcement learning (RL) agents to do
their bidding? Or will sufficiently capable RL agents always find ways to
bypass their intended objectives by shortcutting their reward signal? This
question impacts how far RL can be scaled, and whether alternative paradigms
must be developed in order to build safe artificial general intelligence. In
this paper, we study when an RL agent has an instrumental goal to tamper with
its reward process, and describe design principles that prevent instrumental
goals for two different types of reward tampering (reward function tampering
and RF-input tampering). Combined, the design principles can prevent both types
of reward tampering from being instrumental goals. The analysis benefits from
causal influence diagrams to provide intuitive yet precise formalizations.
</p>
<a href="http://arxiv.org/abs/1908.04734" target="_blank">arXiv:1908.04734</a> [<a href="http://arxiv.org/pdf/1908.04734" target="_blank">pdf</a>]

<h2>What's in my Room? Object Recognition on Indoor Panoramic Images. (arXiv:1910.06138v2 [cs.CV] UPDATED)</h2>
<h3>Julia Guerrero-Viu, Clara Fernandez-Labrador, C&#xe9;dric Demonceaux, Jose J. Guerrero</h3>
<p>In the last few years, there has been a growing interest in taking advantage
of the 360 panoramic images potential, while managing the new challenges they
imply. While several tasks have been improved thanks to the contextual
information these images offer, object recognition in indoor scenes still
remains a challenging problem that has not been deeply investigated. This paper
provides an object recognition system that performs object detection and
semantic segmentation tasks by using a deep learning model adapted to match the
nature of equirectangular images. From these results, instance segmentation
masks are recovered, refined and transformed into 3D bounding boxes that are
placed into the 3D model of the room. Quantitative and qualitative results
support that our method outperforms the state of the art by a large margin and
show a complete understanding of the main objects in indoor scenes.
</p>
<a href="http://arxiv.org/abs/1910.06138" target="_blank">arXiv:1910.06138</a> [<a href="http://arxiv.org/pdf/1910.06138" target="_blank">pdf</a>]

<h2>On model selection for scalable time series forecasting in transport networks. (arXiv:1911.13042v3 [cs.LG] UPDATED)</h2>
<h3>Julien Monteil, Anton Dekusar, Claudio Gambella, Yassine Lassoued, Martin Mevissen</h3>
<p>The transport literature is dense regarding short-term traffic predictions,
up to the scale of 1 hour, yet less dense for long-term traffic predictions.
The transport literature is also sparse when it comes to city-scale traffic
predictions, mainly because of low data availability. In this work, we report
an effort to investigate whether deep learning models can be useful for the
long-term large-scale traffic prediction task, while focusing on the
scalability of the models. We investigate a city-scale traffic dataset with 14
weeks of speed observations collected every 15 minutes over 1098 segments in
the hypercenter of Los Angeles, California. We look at a variety of
state-of-the-art machine learning and deep learning predictors for link-based
predictions, and investigate how such predictors can scale up to larger areas
with clustering, and graph convolutional approaches. We discuss that modelling
temporal and spatial features into deep learning predictors can be helpful for
long-term predictions, while simpler, not deep learning-based predictors,
achieve very satisfactory performance for link-based and short-term
forecasting. The trade-off is discussed not only in terms of prediction
accuracy vs prediction horizon but also in terms of training time and model
sizing.
</p>
<a href="http://arxiv.org/abs/1911.13042" target="_blank">arXiv:1911.13042</a> [<a href="http://arxiv.org/pdf/1911.13042" target="_blank">pdf</a>]

<h2>Universal Adversarial Perturbations for CNN Classifiers in EEG-Based BCIs. (arXiv:1912.01171v4 [cs.LG] UPDATED)</h2>
<h3>Zihan Liu, Lubin Meng, Xiao Zhang, Weili Fang, Dongrui Wu</h3>
<p>Multiple convolutional neural network (CNN) classifiers have been proposed
for electroencephalogram (EEG) based brain-computer interfaces (BCIs). However,
CNN models have been found vulnerable to universal adversarial perturbations
(UAPs), which are small and example-independent, yet powerful enough to degrade
the performance of a CNN model, when added to a benign example. This paper
proposes a novel total loss minimization (TLM) approach to generate UAPs for
EEG-based BCIs. Experimental results demonstrated the effectiveness of TLM on
three popular CNN classifiers for both target and non-target attacks. We also
verified the transferability of UAPs in EEG-based BCI systems. To our
knowledge, this is the first study on UAPs of CNN classifiers in EEG-based
BCIs, and also the first study on optimization based UAPs for target attacks.
UAPs are easy to construct, and can attack BCIs in real-time, exposing a
potentially critical security concern of BCIs.
</p>
<a href="http://arxiv.org/abs/1912.01171" target="_blank">arXiv:1912.01171</a> [<a href="http://arxiv.org/pdf/1912.01171" target="_blank">pdf</a>]

<h2>Fast Geometric Projections for Local Robustness Certification. (arXiv:2002.04742v3 [cs.LG] UPDATED)</h2>
<h3>Aymeric Fromherz, Klas Leino, Matt Fredrikson, Bryan Parno, Corina P&#x103;s&#x103;reanu</h3>
<p>Local robustness ensures that a model classifies all inputs within an
$\ell_2$-ball consistently, which precludes various forms of adversarial
inputs. In this paper, we present a fast procedure for checking local
robustness in feed-forward neural networks with piecewise-linear activation
functions. Such networks partition the input space into a set of convex
polyhedral regions in which the network's behavior is linear; hence, a
systematic search for decision boundaries within the regions around a given
input is sufficient for assessing robustness. Crucially, we show how the
regions around a point can be analyzed using simple geometric projections, thus
admitting an efficient, highly-parallel GPU implementation that excels
particularly for the $\ell_2$ norm, where previous work has been less
effective. Empirically we find this approach to be far more precise than many
approximate verification approaches, while at the same time performing multiple
orders of magnitude faster than complete verifiers, and scaling to much deeper
networks.
</p>
<a href="http://arxiv.org/abs/2002.04742" target="_blank">arXiv:2002.04742</a> [<a href="http://arxiv.org/pdf/2002.04742" target="_blank">pdf</a>]

<h2>PHOTONAI -- A Python API for Rapid Machine Learning Model Development. (arXiv:2002.05426v3 [cs.LG] UPDATED)</h2>
<h3>Ramona Leenings, Nils Ralf Winter, Lucas Plagwitz, Vincent Holstein, Jan Ernsting, Jakob Steenweg, Julian Gebker, Kelvin Sarink, Daniel Emden, Dominik Grotegerd, Nils Opel, Benjamin Risse, Xiaoyi Jiang, Udo Dannlowski, Tim Hahn</h3>
<p>PHOTONAI is a high-level Python API designed to simplify and accelerate
machine learning model development. It offers a unified framework to access
existing machine learning implementations and integrate user-designed
algorithms. PHOTONAI extends existing solutions with novel pipeline
construction functionality that allows for a more complex design of data
streams, feature combinations, and algorithm selection. In addition, the
repetitive training, hyperparameter optimization and evaluation workflow is
fully automatized, enabling rapid prototyping and ensuring an unbiased estimate
of predictive performance. Metrics and results can be conveniently visualized
using the PHOTONAI Explorer and predictive models are shareable in a
standardized format for further external validation or application. A growing
add-on eco-system allows researchers to offer data-modality specific algorithms
to the community and enhance machine learning in the areas of life science.
Source code is publicly available on Github, while examples and documentation
can be found at www.photon-ai.com.
</p>
<a href="http://arxiv.org/abs/2002.05426" target="_blank">arXiv:2002.05426</a> [<a href="http://arxiv.org/pdf/2002.05426" target="_blank">pdf</a>]

<h2>Making Method of Moments Great Again? -- How can GANs learn distributions. (arXiv:2003.04033v3 [cs.LG] UPDATED)</h2>
<h3>Yuanzhi Li, Zehao Dou</h3>
<p>Generative Adversarial Networks (GANs) are widely used models to learn
complex real-world distributions. In GANs, the training of the generator
usually stops when the discriminator can no longer distinguish the generator's
output from the set of training examples. A central question of GANs is that
when the training stops, whether the generated distribution is actually close
to the target distribution, and how the training process reaches to such
configurations efficiently? In this paper, we established a theoretical results
towards understanding this generator-discriminator training process. We
empirically observe that during the earlier stage of the GANs training, the
discriminator is trying to force the generator to match the low degree moments
between the generator's output and the target distribution. Moreover, only by
matching these empirical moments over polynomially many training examples, we
prove that the generator can already learn notable class of distributions,
including those that can be generated by two-layer neural networks.
</p>
<a href="http://arxiv.org/abs/2003.04033" target="_blank">arXiv:2003.04033</a> [<a href="http://arxiv.org/pdf/2003.04033" target="_blank">pdf</a>]

<h2>Explainable Agents Through Social Cues: A Review. (arXiv:2003.05251v3 [cs.RO] UPDATED)</h2>
<h3>Sebastian Wallkotter, Silvia Tulli, Ginevra Castellano, Ana Paiva, Mohamed Chetouani</h3>
<p>The issue of how to make embodied agents explainable has experienced a surge
of interest over the last three years, and, there are many terms that refer to
this concept, e.g., transparency or legibility. One reason for this high
variance in terminology is the unique array of social cues that embodied agents
can access in contrast to that accessed by non-embodied agents. Another reason
is that different authors use these terms in different ways. Hence, we review
the existing literature on explainability and organize it by (1) providing an
overview of existing definitions, (2) showing how explainability is implemented
and how it exploits different social cues, and (3) showing how the impact of
explainability is measured. Additionally, we present a list of open questions
and challenges that highlight areas that require further investigation by the
community. This provides the interested reader with an overview of the current
state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2003.05251" target="_blank">arXiv:2003.05251</a> [<a href="http://arxiv.org/pdf/2003.05251" target="_blank">pdf</a>]

<h2>VisuoSpatial Foresight for Multi-Step, Multi-Task Fabric Manipulation. (arXiv:2003.09044v3 [cs.RO] UPDATED)</h2>
<h3>Ryan Hoque, Daniel Seita, Ashwin Balakrishna, Aditya Ganapathi, Ajay Kumar Tanwani, Nawid Jamali, Katsu Yamane, Soshi Iba, Ken Goldberg</h3>
<p>Robotic fabric manipulation has applications in home robotics, textiles,
senior care and surgery. Existing fabric manipulation techniques, however, are
designed for specific tasks, making it difficult to generalize across different
but related tasks. We extend the Visual Foresight framework to learn fabric
dynamics that can be efficiently reused to accomplish different fabric
manipulation tasks with a single goal-conditioned policy. We introduce
VisuoSpatial Foresight (VSF), which builds on prior work by learning visual
dynamics on domain randomized RGB images and depth maps simultaneously and
completely in simulation. We experimentally evaluate VSF on multi-step fabric
smoothing and folding tasks against 5 baseline methods in simulation and on the
da Vinci Research Kit (dVRK) surgical robot without any demonstrations at train
or test time. Furthermore, we find that leveraging depth significantly improves
performance. RGBD data yields an 80% improvement in fabric folding success rate
over pure RGB data. Code, data, videos, and supplementary material are
available at https://sites.google.com/view/fabric-vsf/.
</p>
<a href="http://arxiv.org/abs/2003.09044" target="_blank">arXiv:2003.09044</a> [<a href="http://arxiv.org/pdf/2003.09044" target="_blank">pdf</a>]

<h2>LineaRE: Simple but Powerful Knowledge Graph Embedding for Link Prediction. (arXiv:2004.10037v2 [cs.AI] UPDATED)</h2>
<h3>Yanhui Peng, Jing Zhang</h3>
<p>The task of link prediction for knowledge graphs is to predict missing
relationships between entities. Knowledge graph embedding, which aims to
represent entities and relations of a knowledge graph as low dimensional
vectors in a continuous vector space, has achieved promising predictive
performance. If an embedding model can cover different types of connectivity
patterns and mapping properties of relations as many as possible, it will
potentially bring more benefits for link prediction tasks. In this paper, we
propose a novel embedding model, namely LineaRE, which is capable of modeling
four connectivity patterns (i.e., symmetry, antisymmetry, inversion, and
composition) and four mapping properties (i.e., one-to-one, one-to-many,
many-to-one, and many-to-many) of relations. Specifically, we regard knowledge
graph embedding as a simple linear regression task, where a relation is modeled
as a linear function of two low-dimensional vector-presented entities with two
weight vectors and a bias vector. Since the vectors are defined in a real
number space and the scoring function of the model is linear, our model is
simple and scalable to large knowledge graphs. Experimental results on multiple
widely used real-world datasets show that the proposed LineaRE model
significantly outperforms existing state-of-the-art models for link prediction
tasks.
</p>
<a href="http://arxiv.org/abs/2004.10037" target="_blank">arXiv:2004.10037</a> [<a href="http://arxiv.org/pdf/2004.10037" target="_blank">pdf</a>]

<h2>Dynamic Language Binding in Relational Visual Reasoning. (arXiv:2004.14603v3 [cs.CV] UPDATED)</h2>
<h3>Thao Minh Le, Vuong Le, Svetha Venkatesh, Truyen Tran</h3>
<p>We present Language-binding Object Graph Network, the first neural reasoning
method with dynamic relational structures across both visual and textual
domains with applications in visual question answering. Relaxing the common
assumption made by current models that the object predicates pre-exist and stay
static, passive to the reasoning process, we propose that these dynamic
predicates expand across the domain borders to include pair-wise
visual-linguistic object binding. In our method, these contextualized object
links are actively found within each recurrent reasoning step without relying
on external predicative priors. These dynamic structures reflect the
conditional dual-domain object dependency given the evolving context of the
reasoning through co-attention. Such discovered dynamic graphs facilitate
multi-step knowledge combination and refinements that iteratively deduce the
compact representation of the final answer. The effectiveness of this model is
demonstrated on image question answering demonstrating favorable performance on
major VQA datasets. Our method outperforms other methods in sophisticated
question-answering tasks wherein multiple object relations are involved. The
graph structure effectively assists the progress of training, and therefore the
network learns efficiently compared to other reasoning models.
</p>
<a href="http://arxiv.org/abs/2004.14603" target="_blank">arXiv:2004.14603</a> [<a href="http://arxiv.org/pdf/2004.14603" target="_blank">pdf</a>]

<h2>Adaptive Robust Kernels for Non-Linear Least Squares Problems. (arXiv:2004.14938v3 [cs.RO] UPDATED)</h2>
<h3>Nived Chebrolu, Thomas L&#xe4;be, Olga Vysotska, Jens Behley, Cyrill Stachniss</h3>
<p>State estimation is a key ingredient in most robotic systems. Often, state
estimation is performed using some form of least squares minimization.
Basically, all error minimization procedures that work on real-world data use
robust kernels as the standard way for dealing with outliers in the data. These
kernels, however, are often hand-picked, sometimes in different combinations,
and their parameters need to be tuned manually for a particular problem. In
this paper, we propose the use of a generalized robust kernel family, which is
automatically tuned based on the distribution of the residuals and includes the
common m-estimators. We tested our adaptive kernel with two popular estimation
problems in robotics, namely ICP and bundle adjustment. The experiments
presented in this paper suggest that our approach provides higher robustness
while avoiding a manual tuning of the kernel parameters.
</p>
<a href="http://arxiv.org/abs/2004.14938" target="_blank">arXiv:2004.14938</a> [<a href="http://arxiv.org/pdf/2004.14938" target="_blank">pdf</a>]

<h2>Echo State Networks trained by Tikhonov least squares are L2({\mu}) approximators of ergodic dynamical systems. (arXiv:2005.06967v2 [cs.LG] UPDATED)</h2>
<h3>Allen G Hart, James L Hook, Jonathan H P Dawes</h3>
<p>Echo State Networks (ESNs) are a class of single-layer recurrent neural
networks with randomly generated internal weights, and a single layer of
tuneable outer weights, which are usually trained by regularised linear least
squares regression. Remarkably, ESNs still enjoy the universal approximation
property despite the training procedure being entirely linear. In this paper,
we prove that an ESN trained on a sequence of observations from an ergodic
dynamical system (with invariant measure $\mu$) using Tikhonov least squares
regression against a set of targets, will approximate the target function in
the $L^2(\mu)$ norm. In the special case that the targets are future
observations, the ESN is learning the next step map, which allows time series
forecasting. We demonstrate the theory numerically by training an ESN using
Tikhonov least squares on a sequence of scalar observations of the Lorenz
system.
</p>
<a href="http://arxiv.org/abs/2005.06967" target="_blank">arXiv:2005.06967</a> [<a href="http://arxiv.org/pdf/2005.06967" target="_blank">pdf</a>]

<h2>Probably Approximately Correct Constrained Learning. (arXiv:2006.05487v2 [cs.LG] UPDATED)</h2>
<h3>Luiz F. O. Chamon, Alejandro Ribeiro</h3>
<p>As learning solutions reach critical applications in social, industrial, and
medical domains, the need to curtail their behavior has become paramount. There
is now ample evidence that without explicit tailoring, learning can lead to
biased, unsafe, and prejudiced solutions. To tackle these problems, we develop
a generalization theory of constrained learning based on the probably
approximately correct (PAC) learning framework. In particular, we show that
imposing requirements does not make a learning problem harder in the sense that
any PAC learnable class is also PAC constrained learnable using a constrained
counterpart of the empirical risk minimization (ERM) rule. For typical
parametrized models, however, this learner involves solving a constrained
non-convex optimization program for which even obtaining a feasible solution is
challenging. To overcome this issue, we prove that under mild conditions the
empirical dual problem of constrained learning is also a PAC constrained
learner that now leads to a practical constrained learning algorithm based
solely on solving unconstrained problems. We analyze the generalization
properties of this solution and use it to illustrate how constrained learning
can address problems in fair and robust classification.
</p>
<a href="http://arxiv.org/abs/2006.05487" target="_blank">arXiv:2006.05487</a> [<a href="http://arxiv.org/pdf/2006.05487" target="_blank">pdf</a>]

<h2>A Probabilistic Model for Discriminative and Neuro-Symbolic Semi-Supervised Learning. (arXiv:2006.05896v3 [cs.LG] UPDATED)</h2>
<h3>Carl Allen, Ivana Bala&#x17e;evi&#x107;, Timothy Hospedales</h3>
<p>Recent progress has been made in semi-supervised learning (SSL) by combining
methods that exploit various aspects of the data distribution, e.g. image
augmentation and consistency regularisation, rely on properties of $p(x)$,
whereas others, such as entropy minimisation and pseudo-labelling, pertain to
the sample-specific label distributions $p(y|x)$. Focusing on the latter, we
propose a probabilistic model for discriminative SSL that mirrors its classical
generative counterpart, filling a gap in existing semi-supervised learning
theory. Under this model, several well-known SSL methods can be interpreted as
imposing relaxations of an appropriate prior over learned parameters of
$p(y|x)$. The same model extends naturally to neuro-symbolic SSL, often treated
as a separate field, in which binary label attributes are subject to logical
rules. The model thus also theoretically justifies a family of neuro-symbolic
SSL methods and unifies them with standard SSL, taking a step towards bridging
the divide between statistical learning and logical reasoning.
</p>
<a href="http://arxiv.org/abs/2006.05896" target="_blank">arXiv:2006.05896</a> [<a href="http://arxiv.org/pdf/2006.05896" target="_blank">pdf</a>]

<h2>Memory-Efficient Pipeline-Parallel DNN Training. (arXiv:2006.09503v2 [cs.LG] UPDATED)</h2>
<h3>Deepak Narayanan, Amar Phanishayee, Kaiyu Shi, Xie Chen, Matei Zaharia</h3>
<p>Many state-of-the-art ML results have been obtained by scaling up the number
of parameters in existing models. However, parameters and activations for such
large models often do not fit in the memory of a single accelerator device;
this means that it is necessary to distribute training of large models over
multiple accelerators. In this work, we propose PipeDream-2BW, a system that
supports memory-efficient pipeline parallelism, a hybrid form of parallelism
that combines data and model parallelism with input pipelining. PipeDream-2BW
uses a novel pipelining and weight gradient coalescing strategy, combined with
the double buffering of weights, to ensure high throughput, low memory
footprint, and weight update semantics similar to data parallelism. In
addition, PipeDream-2BW automatically partitions the model over the available
hardware resources, while respecting hardware constraints such as memory
capacities of accelerators, and topologies and bandwidths of interconnects.
PipeDream-2BW also determines when to employ existing memory-savings
techniques, such as activation recomputation, that trade off extra computation
for lower memory footprint. PipeDream-2BW can accelerate the training of large
GPT and BERT language models by up to 20x compared to optimized baselines
without affecting the model's final accuracy.
</p>
<a href="http://arxiv.org/abs/2006.09503" target="_blank">arXiv:2006.09503</a> [<a href="http://arxiv.org/pdf/2006.09503" target="_blank">pdf</a>]

<h2>Clinical Risk Prediction with Temporal Probabilistic Asymmetric Multi-Task Learning. (arXiv:2006.12777v4 [cs.LG] UPDATED)</h2>
<h3>A. Tuan Nguyen, Hyewon Jeong, Eunho Yang, Sung Ju Hwang</h3>
<p>Although recent multi-task learning methods have shown to be effective in
improving the generalization of deep neural networks, they should be used with
caution for safety-critical applications, such as clinical risk prediction.
This is because even if they achieve improved task-average performance, they
may still yield degraded performance on individual tasks, which may be critical
(e.g., prediction of mortality risk). Existing asymmetric multi-task learning
methods tackle this negative transfer problem by performing knowledge transfer
from tasks with low loss to tasks with high loss. However, using loss as a
measure of reliability is risky since it could be a result of overfitting. In
the case of time-series prediction tasks, knowledge learned for one task (e.g.,
predicting the sepsis onset) at a specific timestep may be useful for learning
another task (e.g., prediction of mortality) at a later timestep, but lack of
loss at each timestep makes it difficult to measure the reliability at each
timestep. To capture such dynamically changing asymmetric relationships between
tasks in time-series data, we propose a novel temporal asymmetric multi-task
learning model that performs knowledge transfer from certain tasks/timesteps to
relevant uncertain tasks, based on feature-level uncertainty. We validate our
model on multiple clinical risk prediction tasks against various deep learning
models for time-series prediction, which our model significantly outperforms,
without any sign of negative transfer. Further qualitative analysis of learned
knowledge graphs by clinicians shows that they are helpful in analyzing the
predictions of the model. Our final code is available at
https://github.com/anhtuan5696/TPAMTL.
</p>
<a href="http://arxiv.org/abs/2006.12777" target="_blank">arXiv:2006.12777</a> [<a href="http://arxiv.org/pdf/2006.12777" target="_blank">pdf</a>]

<h2>Adversarial Learning for Debiasing Knowledge Graph Embeddings. (arXiv:2006.16309v2 [cs.LG] UPDATED)</h2>
<h3>Mario Arduini, Lorenzo Noci, Federico Pirovano, Ce Zhang, Yash Raj Shrestha, Bibek Paudel</h3>
<p>Knowledge Graphs (KG) are gaining increasing attention in both academia and
industry. Despite their diverse benefits, recent research have identified
social and cultural biases embedded in the representations learned from KGs.
Such biases can have detrimental consequences on different population and
minority groups as applications of KG begin to intersect and interact with
social spheres. This paper aims at identifying and mitigating such biases in
Knowledge Graph (KG) embeddings. As a first step, we explore popularity bias --
the relationship between node popularity and link prediction accuracy. In case
of node2vec graph embeddings, we find that prediction accuracy of the embedding
is negatively correlated with the degree of the node. However, in case of
knowledge-graph embeddings (KGE), we observe an opposite trend. As a second
step, we explore gender bias in KGE, and a careful examination of popular KGE
algorithms suggest that sensitive attribute like the gender of a person can be
predicted from the embedding. This implies that such biases in popular KGs is
captured by the structural properties of the embedding. As a preliminary
solution to debiasing KGs, we introduce a novel framework to filter out the
sensitive attribute information from the KG embeddings, which we call FAN
(Filtering Adversarial Network). We also suggest the applicability of FAN for
debiasing other network embeddings which could be explored in future work.
</p>
<a href="http://arxiv.org/abs/2006.16309" target="_blank">arXiv:2006.16309</a> [<a href="http://arxiv.org/pdf/2006.16309" target="_blank">pdf</a>]

<h2>Efficient computation and analysis of distributional Shapley values. (arXiv:2007.01357v3 [stat.ML] UPDATED)</h2>
<h3>Yongchan Kwon, Manuel A. Rivas, James Zou</h3>
<p>Distributional data Shapley value (DShapley) has recently been proposed as a
principled framework to quantify the contribution of individual datum in
machine learning. DShapley develops the foundational game theory concept of
Shapley values into a statistical framework and can be applied to identify data
points that are useful (or harmful) to a learning algorithm. Estimating
DShapley is computationally expensive, however, and this can be a major
challenge to using it in practice. Moreover, there has been little mathematical
analyses of how this value depends on data characteristics. In this paper, we
derive the first analytic expressions for DShapley for the canonical problems
of linear regression, binary classification, and non-parametric density
estimation. These analytic forms provide new algorithms to estimate DShapley
that are several orders of magnitude faster than previous state-of-the-art
methods. Furthermore, our formulas are directly interpretable and provide
quantitative insights into how the value varies for different types of data. We
demonstrate the practical efficacy of our approach on multiple real and
synthetic datasets.
</p>
<a href="http://arxiv.org/abs/2007.01357" target="_blank">arXiv:2007.01357</a> [<a href="http://arxiv.org/pdf/2007.01357" target="_blank">pdf</a>]

<h2>Re-thinking Co-Salient Object Detection. (arXiv:2007.03380v3 [cs.CV] UPDATED)</h2>
<h3>Deng-Ping Fan, Tengpeng Li, Zheng Lin, Ge-Peng Ji, Dingwen Zhang, Ming-Ming Cheng, Huazhu Fu, Jianbing Shen</h3>
<p>In this paper, we conduct a comprehensive study on the co-salient object
detection (CoSOD) problem for images. CoSOD is an emerging and rapidly growing
extension of salient object detection (SOD), which aims to detect the
co-occurring salient objects in a group of images. However, existing CoSOD
datasets often have a serious data bias, assuming that each group of images
contains salient objects of similar visual appearances. This bias can lead to
the ideal settings and effectiveness of models trained on existing datasets,
being impaired in real-life situations, where similarities are usually semantic
or conceptual. To tackle this issue, we first introduce a new benchmark, called
CoSOD3k in the wild, which requires a large amount of semantic context, making
it more challenging than existing CoSOD datasets. Our CoSOD3k consists of 3,316
high-quality, elaborately selected images divided into 160 groups with
hierarchical annotations. The images span a wide range of categories, shapes,
object sizes, and backgrounds. Second, we integrate the existing SOD techniques
to build a unified, trainable CoSOD framework, which is long overdue in this
field. Specifically, we propose a novel CoEG-Net that augments our prior model
EGNet with a co-attention projection strategy to enable fast common information
learning. CoEG-Net fully leverages previous large-scale SOD datasets and
significantly improves the model scalability and stability. Third, we
comprehensively summarize 40 cutting-edge algorithms, benchmarking 18 of them
over three challenging CoSOD datasets (iCoSeg, CoSal2015, and our CoSOD3k), and
reporting more detailed (i.e., group-level) performance analysis. Finally, we
discuss the challenges and future works of CoSOD. We hope that our study will
give a strong boost to growth in the CoSOD community. The benchmark toolbox and
results are available on our project page at this http URL
</p>
<a href="http://arxiv.org/abs/2007.03380" target="_blank">arXiv:2007.03380</a> [<a href="http://arxiv.org/pdf/2007.03380" target="_blank">pdf</a>]

<h2>A Study on Encodings for Neural Architecture Search. (arXiv:2007.04965v2 [cs.LG] UPDATED)</h2>
<h3>Colin White, Willie Neiswanger, Sam Nolen, Yash Savani</h3>
<p>Neural architecture search (NAS) has been extensively studied in the past few
years. A popular approach is to represent each neural architecture in the
search space as a directed acyclic graph (DAG), and then search over all DAGs
by encoding the adjacency matrix and list of operations as a set of
hyperparameters. Recent work has demonstrated that even small changes to the
way each architecture is encoded can have a significant effect on the
performance of NAS algorithms.

In this work, we present the first formal study on the effect of architecture
encodings for NAS, including a theoretical grounding and an empirical study.
First we formally define architecture encodings and give a theoretical
characterization on the scalability of the encodings we study Then we identify
the main encoding-dependent subroutines which NAS algorithms employ, running
experiments to show which encodings work best with each subroutine for many
popular algorithms. The experiments act as an ablation study for prior work,
disentangling the algorithmic and encoding-based contributions, as well as a
guideline for future work. Our results demonstrate that NAS encodings are an
important design decision which can have a significant impact on overall
performance. Our code is available at
https://github.com/naszilla/nas-encodings.
</p>
<a href="http://arxiv.org/abs/2007.04965" target="_blank">arXiv:2007.04965</a> [<a href="http://arxiv.org/pdf/2007.04965" target="_blank">pdf</a>]

<h2>Black-Box Control for Linear Dynamical Systems. (arXiv:2007.06650v3 [cs.LG] UPDATED)</h2>
<h3>Xinyi Chen, Elad Hazan</h3>
<p>We consider the problem of controlling an unknown linear time-invariant
dynamical system from a single chain of black-box interactions, with no access
to resets or offline simulation. Under the assumption that the system is
controllable, we give the first efficient algorithm that is capable of
attaining sublinear regret in a single trajectory under the setting of online
nonstochastic control. This resolves an open problem on the stochastic LQR
problem, and in a more challenging setting that allows for adversarial
perturbations and adversarially chosen and changing convex loss functions.

We give finite-time regret bounds for our algorithm on the order of
$2^{\tilde{O}(\mathcal{L})} + \tilde{O}(\text{poly}(\mathcal{L}) T^{2/3})$ for
general nonstochastic control, and $2^{\tilde{O}(\mathcal{L})} +
\tilde{O}(\text{poly}(\mathcal{L}) \sqrt{T})$ for black-box LQR, where
$\mathcal{L}$ is the system size which is an upper bound on the dimension. The
crucial step is a new system identification method that is robust to
adversarial noise, but incurs exponential cost.

To complete the picture, we investigate the complexity of the online
black-box control problem, and give a matching lower bound of
$2^{\Omega(\mathcal{L})}$ on the regret, showing that the additional
exponential cost is inevitable. This lower bound holds even in the noiseless
setting, and applies to any, randomized or deterministic, black-box control
method.
</p>
<a href="http://arxiv.org/abs/2007.06650" target="_blank">arXiv:2007.06650</a> [<a href="http://arxiv.org/pdf/2007.06650" target="_blank">pdf</a>]

<h2>A Self-Training Approach for Point-Supervised Object Detection and Counting in Crowds. (arXiv:2007.12831v3 [cs.CV] UPDATED)</h2>
<h3>Yi Wang, Junhui Hou, Xinyu Hou, Lap-Pui Chau</h3>
<p>In this paper, we propose a novel self-training approach named Crowd-SDNet
that enables a typical object detector trained only with point-level
annotations (i.e., objects are labeled with points) to estimate both the center
points and sizes of crowded objects. Specifically, during training, we utilize
the available point annotations to supervise the estimation of the center
points of objects directly. Based on a locally-uniform distribution assumption,
we initialize pseudo object sizes from the point-level supervisory information,
which are then leveraged to guide the regression of object sizes via a
crowdedness-aware loss. Meanwhile, we propose a confidence and order-aware
refinement scheme to continuously refine the initial pseudo object sizes such
that the ability of the detector is increasingly boosted to detect and count
objects in crowds simultaneously. Moreover, to address extremely crowded
scenes, we propose an effective decoding method to improve the detector's
representation ability. Experimental results on the WiderFace benchmark show
that our approach significantly outperforms state-of-the-art point-supervised
methods under both detection and counting tasks, i.e., our method improves the
average precision by more than 10% and reduces the counting error by 31.2%.
Besides, our method obtains the best results on the crowd counting and
localization datasets (i.e., ShanghaiTech and NWPU-Crowd) and vehicle counting
datasets (i.e., CARPK and PUCPR+) compared with state-of-the-art
counting-by-detection methods. The code will be publicly available at
https://github.com/WangyiNTU/Point-supervised-crowd-detection.
</p>
<a href="http://arxiv.org/abs/2007.12831" target="_blank">arXiv:2007.12831</a> [<a href="http://arxiv.org/pdf/2007.12831" target="_blank">pdf</a>]

<h2>Learning "What-if" Explanations for Sequential Decision-Making. (arXiv:2007.13531v2 [cs.LG] UPDATED)</h2>
<h3>Ioana Bica, Daniel Jarrett, Alihan H&#xfc;y&#xfc;k, Mihaela van der Schaar</h3>
<p>Building interpretable parameterizations of real-world decision-making on the
basis of demonstrated behavior -- i.e. trajectories of observations and actions
made by an expert maximizing some unknown reward function -- is essential for
introspecting and auditing policies in different institutions. In this paper,
we propose learning explanations of expert decisions by modeling their reward
function in terms of preferences with respect to "what if" outcomes: Given the
current history of observations, what would happen if we took a particular
action? To learn these cost-benefit tradeoffs associated with the expert's
actions, we integrate counterfactual reasoning into batch inverse reinforcement
learning. This offers a principled way of defining reward functions and
explaining expert behavior, and also satisfies the constraints of real-world
decision-making -- where active experimentation is often impossible (e.g. in
healthcare). Additionally, by estimating the effects of different actions,
counterfactuals readily tackle the off-policy nature of policy evaluation in
the batch setting, and can naturally accommodate settings where the expert
policies depend on histories of observations rather than just current states.
Through illustrative experiments in both real and simulated medical
environments, we highlight the effectiveness of our batch, counterfactual
inverse reinforcement learning approach in recovering accurate and
interpretable descriptions of behavior.
</p>
<a href="http://arxiv.org/abs/2007.13531" target="_blank">arXiv:2007.13531</a> [<a href="http://arxiv.org/pdf/2007.13531" target="_blank">pdf</a>]

<h2>Deep Samplable Observation Model for Global Localization and Kidnapping. (arXiv:2009.00211v3 [cs.RO] UPDATED)</h2>
<h3>Runjian Chen, Huan Yin, Yanmei Jiao, Gamini Dissanayake, Yue Wang, Rong Xiong</h3>
<p>Global localization and kidnapping are two challenging problems in robot
localization. The popular method, Monte Carlo Localization (MCL) addresses the
problem by iteratively updating a set of particles with a "sampling-weighting"
loop. Sampling is decisive to the performance of MCL [1]. However, traditional
MCL can only sample from a uniform distribution over the state space. Although
variants of MCL propose different sampling models, they fail to provide an
accurate distribution or generalize across scenes. To better deal with these
problems, we present a distribution proposal model, named Deep Samplable
Observation Model (DSOM). DSOM takes a map and a 2D laser scan as inputs and
outputs a conditional multimodal probability distribution of the pose, making
the samples more focusing on the regions with higher likelihood. With such
samples, the convergence is expected to be more effective and efficient.
Considering that the learning-based sampling model may fail to capture the true
pose sometimes, we furthermore propose the Adaptive Mixture MCL (AdaM MCL),
which deploys a trusty mechanism to adaptively select updating mode for each
particle to tolerate this situation. Equipped with DSOM, AdaM MCL can achieve
more accurate estimation, faster convergence and better scalability compared to
previous methods in both synthetic and real scenes. Even in real environments
with long-term changing, AdaM MCL is able to localize the robot using DSOM
trained only by simulation observations from a SLAM map or a blueprint map.
</p>
<a href="http://arxiv.org/abs/2009.00211" target="_blank">arXiv:2009.00211</a> [<a href="http://arxiv.org/pdf/2009.00211" target="_blank">pdf</a>]

<h2>A Practical Layer-Parallel Training Algorithm for Residual Networks. (arXiv:2009.01462v2 [cs.LG] UPDATED)</h2>
<h3>Qi Sun, Hexin Dong, Zewei Chen, Weizhen Dian, Jiacheng Sun, Yitong Sun, Zhenguo Li, Bin Dong</h3>
<p>Gradient-based algorithms for training ResNets typically require a forward
pass of the input data, followed by back-propagating the objective gradient to
update parameters, which are time-consuming for deep ResNets. To break the
dependencies between modules in both the forward and backward modes,
auxiliary-variable methods such as the penalty and augmented Lagrangian (AL)
approaches have attracted much interest lately due to their ability to exploit
layer-wise parallelism. However, we observe that large communication overhead
and lacking data augmentation are two key challenges of these methods, which
may lead to low speedup ratio and accuracy drop across multiple compute
devices. Inspired by the optimal control formulation of ResNets, we propose a
novel serial-parallel hybrid training strategy to enable the use of data
augmentation, together with downsampling filters to reduce the communication
cost. The proposed strategy first trains the network parameters by solving a
succession of independent sub-problems in parallel and then corrects the
network parameters through a full serial forward-backward propagation of data.
Such a strategy can be applied to most of the existing layer-parallel training
methods using auxiliary variables. As an example, we validate the proposed
strategy using penalty and AL methods on ResNet and WideResNet across MNIST,
CIFAR-10 and CIFAR-100 datasets, achieving significant speedup over the
traditional layer-serial training methods while maintaining comparable
accuracy.
</p>
<a href="http://arxiv.org/abs/2009.01462" target="_blank">arXiv:2009.01462</a> [<a href="http://arxiv.org/pdf/2009.01462" target="_blank">pdf</a>]

<h2>Dual Encoding for Video Retrieval by Text. (arXiv:2009.05381v2 [cs.CV] UPDATED)</h2>
<h3>Jianfeng Dong, Xirong Li, Chaoxi Xu, Xun Yang, Gang Yang, Xun Wang, Meng Wang</h3>
<p>This paper attacks the challenging problem of video retrieval by text. In
such a retrieval paradigm, an end user searches for unlabeled videos by ad-hoc
queries described exclusively in the form of a natural-language sentence, with
no visual example provided. Given videos as sequences of frames and queries as
sequences of words, an effective sequence-to-sequence cross-modal matching is
crucial. To that end, the two modalities need to be first encoded into
real-valued vectors and then projected into a common space. In this paper we
achieve this by proposing a dual deep encoding network that encodes videos and
queries into powerful dense representations of their own. Our novelty is
two-fold. First, different from prior art that resorts to a specific
single-level encoder, the proposed network performs multi-level encoding that
represents the rich content of both modalities in a coarse-to-fine fashion.
Second, different from a conventional common space learning algorithm which is
either concept based or latent space based, we introduce hybrid space learning
which combines the high performance of the latent space and the good
interpretability of the concept space. Dual encoding is conceptually simple,
practically effective and end-to-end trained with hybrid space learning.
Extensive experiments on four challenging video datasets show the viability of
the new method.
</p>
<a href="http://arxiv.org/abs/2009.05381" target="_blank">arXiv:2009.05381</a> [<a href="http://arxiv.org/pdf/2009.05381" target="_blank">pdf</a>]

<h2>Inductive Learning on Commonsense Knowledge Graph Completion. (arXiv:2009.09263v2 [cs.AI] UPDATED)</h2>
<h3>Bin Wang, Guangtao Wang, Jing Huang, Jiaxuan You, Jure Leskovec, C.-C. Jay Kuo</h3>
<p>Commonsense knowledge graph (CKG) is a special type of knowledge graph (KG),
where entities are composed of free-form text. However, most existing CKG
completion methods focus on the setting where all the entities are presented at
training time. Although this setting is standard for conventional KG
completion, it has limitations for CKG completion. At test time, entities in
CKGs can be unseen because they may have unseen text/names and entities may be
disconnected from the training graph, since CKGs are generally very sparse.
Here, we propose to study the inductive learning setting for CKG completion
where unseen entities may present at test time. We develop a novel learning
framework named InductivE. Different from previous approaches, InductiveE
ensures the inductive learning capability by directly computing entity
embeddings from raw entity attributes/text. InductiveE consists of a free-text
encoder, a graph encoder, and a KG completion decoder. Specifically, the
free-text encoder first extracts the textual representation of each entity
based on the pre-trained language model and word embedding. The graph encoder
is a gated relational graph convolutional neural network that learns from a
densified graph for more informative entity representation learning. We develop
a method that densifies CKGs by adding edges among semantic-related entities
and provide more supportive information for unseen entities, leading to better
generalization ability of entity embedding for unseen entities. Finally,
inductiveE employs Conv-TransE as the CKG completion decoder. Experimental
results show that InductiveE significantly outperforms state-of-the-art
baselines in both standard and inductive settings on ATOMIC and ConceptNet
benchmarks. InductivE performs especially well on inductive scenarios where it
achieves above 48% improvement over present methods.
</p>
<a href="http://arxiv.org/abs/2009.09263" target="_blank">arXiv:2009.09263</a> [<a href="http://arxiv.org/pdf/2009.09263" target="_blank">pdf</a>]

<h2>Probabilistic Programs with Stochastic Conditioning. (arXiv:2010.00282v2 [cs.LG] UPDATED)</h2>
<h3>David Tolpin, Yuan Zhou, Hongseok Yang</h3>
<p>We tackle the problem of conditioning probabilistic programs on distributions
of observable variables. Probabilistic programs are usually conditioned on
samples from the joint data distribution, which we refer to as deterministic
conditioning. However, in many real-life scenarios, the observations are given
as marginal distributions, summary statistics, or samplers. Conventional
probabilistic programming systems lack adequate means for modeling and
inference in such scenarios. We propose a generalization of deterministic
conditioning to stochastic conditioning, that is, conditioning on the marginal
distribution of a variable taking a particular form. To this end, we first
define the formal notion of stochastic conditioning and discuss its key
properties. We then show how to perform inference in the presence of stochastic
conditioning. We demonstrate potential usage of stochastic conditioning on
several case studies which involve various kinds of stochastic conditioning and
are difficult to solve otherwise. Although we present stochastic conditioning
in the context of probabilistic programming, our formalization is general and
applicable to other settings.
</p>
<a href="http://arxiv.org/abs/2010.00282" target="_blank">arXiv:2010.00282</a> [<a href="http://arxiv.org/pdf/2010.00282" target="_blank">pdf</a>]

<h2>Nearly Minimax Optimal Reinforcement Learning for Discounted MDPs. (arXiv:2010.00587v2 [cs.LG] UPDATED)</h2>
<h3>Jiafan He, Dongruo Zhou, Quanquan Gu</h3>
<p>We study the reinforcement learning problem for discounted Markov Decision
Processes (MDPs) under the tabular setting. We propose a model-based algorithm
named UCBVI-$\gamma$, which is based on the \emph{optimism in the face of
uncertainty principle} and the Bernstein-type bonus. We show that
UCBVI-$\gamma$ achieves an $\tilde{O}\big({\sqrt{SAT}}/{(1-\gamma)^{1.5}}\big)$
regret, where $S$ is the number of states, $A$ is the number of actions,
$\gamma$ is the discount factor and $T$ is the number of steps. In addition, we
construct a class of hard MDPs and show that for any algorithm, the expected
regret is at least $\tilde{\Omega}\big({\sqrt{SAT}}/{(1-\gamma)^{1.5}}\big)$.
Our upper bound matches the minimax lower bound up to logarithmic factors,
which suggests that UCBVI-$\gamma$ is nearly minimax optimal for discounted
MDPs.
</p>
<a href="http://arxiv.org/abs/2010.00587" target="_blank">arXiv:2010.00587</a> [<a href="http://arxiv.org/pdf/2010.00587" target="_blank">pdf</a>]

<h2>Distributed Saddle-Point Problems: Lower Bounds, Optimal Algorithms and Federated GANs. (arXiv:2010.13112v4 [cs.LG] UPDATED)</h2>
<h3>Aleksandr Beznosikov, Valentin Samokhin, Alexander Gasnikov</h3>
<p>GAN is one of the most popular and commonly used neural network models. When
the model is large and there is a lot of data, the learning process can be
delayed. The standard way out is to use multiple devices. Therefore, the
methods of distributed and federated training for GANs are an important
question. But from an optimization point of view, GANs are saddle-point
problems: $\min_x \max_y f(x,y)$. Therefore, this paper focuses on the
distributed optimization of smooth stochastic saddle-point problems. The first
part of the paper is devoted to lower bounds for the distributed methods for
saddle-point problems as well as the optimal algorithms by which these bounds
are achieved. Next, we present a new algorithm for distributed saddle-point
problems - Extra Step Local SGD. In the experimental part of the paper, we use
the Local SGD technique in practice. In particular, we train GANs in a
distributed manner.
</p>
<a href="http://arxiv.org/abs/2010.13112" target="_blank">arXiv:2010.13112</a> [<a href="http://arxiv.org/pdf/2010.13112" target="_blank">pdf</a>]

<h2>On the Stability of Graph Convolutional Neural Networks under Edge Rewiring. (arXiv:2010.13747v2 [cs.LG] UPDATED)</h2>
<h3>Henry Kenlay, Dorina Thanou, Xiaowen Dong</h3>
<p>Graph neural networks are experiencing a surge of popularity within the
machine learning community due to their ability to adapt to non-Euclidean
domains and instil inductive biases. Despite this, their stability, i.e., their
robustness to small perturbations in the input, is not yet well understood.
Although there exists some results showing the stability of graph neural
networks, most take the form of an upper bound on the magnitude of change due
to a perturbation in the graph topology. However, the change in the graph
topology captured in existing bounds tend not to be expressed in terms of
structural properties, limiting our understanding of the model robustness
properties. In this work, we develop an interpretable upper bound elucidating
that graph neural networks are stable to rewiring between high degree nodes.
This bound and further research in bounds of similar type provide further
understanding of the stability properties of graph neural networks.
</p>
<a href="http://arxiv.org/abs/2010.13747" target="_blank">arXiv:2010.13747</a> [<a href="http://arxiv.org/pdf/2010.13747" target="_blank">pdf</a>]

<h2>Bayesian Deep Learning via Subnetwork Inference. (arXiv:2010.14689v2 [cs.LG] UPDATED)</h2>
<h3>Erik Daxberger, Eric Nalisnick, James Urquhart Allingham, Javier Antor&#xe1;n, Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</h3>
<p>The Bayesian paradigm has the potential to solve core issues of deep neural
networks such as poor calibration and data inefficiency. Alas, scaling Bayesian
inference to large weight spaces often requires restrictive approximations. In
this work, we show that it suffices to perform inference over a small subset of
model weights in order to obtain accurate predictive posteriors. The other
weights are kept as point estimates. This subnetwork inference framework
enables us to use expressive, otherwise intractable, posterior approximations
over such subsets. In particular, we implement subnetwork linearized Laplace:
We first obtain a MAP estimate of all weights and then infer a full-covariance
Gaussian posterior over a subnetwork. We propose a subnetwork selection
strategy that aims to maximally preserve the model's predictive uncertainty.
Empirically, our approach is effective compared to ensembles and less
expressive posterior approximations over full networks.
</p>
<a href="http://arxiv.org/abs/2010.14689" target="_blank">arXiv:2010.14689</a> [<a href="http://arxiv.org/pdf/2010.14689" target="_blank">pdf</a>]

<h2>Causal Campbell-Goodhart's law and Reinforcement Learning. (arXiv:2011.01010v2 [cs.LG] UPDATED)</h2>
<h3>Hal Ashton</h3>
<p>Campbell-Goodhart's law relates to the causal inference error whereby
decision-making agents aim to influence variables which are correlated to their
goal objective but do not reliably cause it. This is a well known error in
Economics and Political Science but not widely labelled in Artificial
Intelligence research. Through a simple example, we show how off-the-shelf deep
Reinforcement Learning (RL) algorithms are not necessarily immune to this
cognitive error. The off-policy learning method is tricked, whilst the
on-policy method is not. The practical implication is that naive application of
RL to complex real life problems can result in the same types of policy errors
that humans make. Great care should be taken around understanding the causal
model that underpins a solution derived from Reinforcement Learning.
</p>
<a href="http://arxiv.org/abs/2011.01010" target="_blank">arXiv:2011.01010</a> [<a href="http://arxiv.org/pdf/2011.01010" target="_blank">pdf</a>]

<h2>Loss Bounds for Approximate Influence-Based Abstraction. (arXiv:2011.01788v2 [cs.AI] UPDATED)</h2>
<h3>Elena Congeduti, Alexander Mey, Frans A. Oliehoek</h3>
<p>Sequential decision making techniques hold great promise to improve the
performance of many real-world systems, but computational complexity hampers
their principled application. Influence-based abstraction aims to gain leverage
by modeling local subproblems together with the 'influence' that the rest of
the system exerts on them. While computing exact representations of such
influence might be intractable, learning approximate representations offers a
promising approach to enable scalable solutions. This paper investigates the
performance of such approaches from a theoretical perspective. The primary
contribution is the derivation of sufficient conditions on approximate
influence representations that can guarantee solutions with small value loss.
In particular we show that neural networks trained with cross entropy are well
suited to learn approximate influence representations. Moreover, we provide a
sample based formulation of the bounds, which reduces the gap to applications.
Finally, driven by our theoretical insights, we propose approximation error
estimators, which empirically reveal to correlate well with the value loss.
</p>
<a href="http://arxiv.org/abs/2011.01788" target="_blank">arXiv:2011.01788</a> [<a href="http://arxiv.org/pdf/2011.01788" target="_blank">pdf</a>]

<h2>Weed Density and Distribution Estimation for Precision Agriculture using Semi-Supervised Learning. (arXiv:2011.02193v2 [cs.CV] UPDATED)</h2>
<h3>Shantam Shorewala, Armaan Ashfaque, Sidharth R, Ujjwal Verma</h3>
<p>Uncontrolled growth of weeds can severely affect the crop yield and quality.
Unrestricted use of herbicide for weed removal alters biodiversity and cause
environmental pollution. Instead, identifying weed-infested regions can aid
selective chemical treatment of these regions. Advances in analyzing farm
images have resulted in solutions to identify weed plants. However, a majority
of these approaches are based on supervised learning methods which requires
huge amount of manually annotated images. As a result, these supervised
approaches are economically infeasible for the individual farmer because of the
wide variety of plant species being cultivated. In this paper, we propose a
deep learning-based semi-supervised approach for robust estimation of weed
density and distribution across farmlands using only limited color images
acquired from autonomous robots. This weed density and distribution can be
useful in a site-specific weed management system for selective treatment of
infected areas using autonomous robots. In this work, the foreground vegetation
pixels containing crops and weeds are first identified using a Convolutional
Neural Network (CNN) based unsupervised segmentation. Subsequently, the weed
infected regions are identified using a fine-tuned CNN, eliminating the need
for designing hand-crafted features. The approach is validated on two datasets
of different crop/weed species (1) Crop Weed Field Image Dataset (CWFID), which
consists of carrot plant images and the (2) Sugar Beets dataset. The proposed
method is able to localize weed-infested regions a maximum recall of 0.99 and
estimate weed density with a maximum accuracy of 82.13%. Hence, the proposed
approach is shown to generalize to different plant species without the need for
extensive labeled data.
</p>
<a href="http://arxiv.org/abs/2011.02193" target="_blank">arXiv:2011.02193</a> [<a href="http://arxiv.org/pdf/2011.02193" target="_blank">pdf</a>]

<h2>From Eye-blinks to State Construction: Diagnostic Benchmarks for Online Representation Learning. (arXiv:2011.04590v3 [cs.AI] UPDATED)</h2>
<h3>Banafsheh Rafiee, Zaheer Abbas, Sina Ghiassian, Raksha Kumaraswamy, Richard Sutton, Elliot Ludvig, Adam White</h3>
<p>Experiments in classical conditioning show that animals such as rabbits,
pigeons, and dogs can make long temporal associations that enable multi-step
prediction. To replicate this remarkable ability, an agent must construct an
internal state representation that summarizes its interaction history.
Recurrent neural networks can automatically construct state and learn temporal
associations. But the current training methods are prohibitively expensive for
online prediction -- continual learning on every time step -- which is the
focus of this paper. To facilitate research in online prediction, we present
three new diagnostic prediction problems inspired by classical-conditioning
experiments. The proposed problems test the learning capabilities that animals
readily exhibit and highlight the current recurrent learning methods'
limitations. While the proposed problems are nontrivial, they are still
amenable to extensive testing and analysis in the small-compute regime, thereby
enabling researchers to study issues in isolation carefully, ultimately
accelerating progress towards scalable online representation learning methods.
</p>
<a href="http://arxiv.org/abs/2011.04590" target="_blank">arXiv:2011.04590</a> [<a href="http://arxiv.org/pdf/2011.04590" target="_blank">pdf</a>]

<h2>Federated Composite Optimization. (arXiv:2011.08474v2 [cs.LG] UPDATED)</h2>
<h3>Honglin Yuan, Manzil Zaheer, Sashank Reddi</h3>
<p>Federated Learning (FL) is a distributed learning paradigm that scales
on-device learning collaboratively and privately. Standard FL algorithms such
as FedAvg are primarily geared towards smooth unconstrained settings. In this
paper, we study the Federated Composite Optimization (FCO) problem, in which
the loss function contains a non-smooth regularizer. Such problems arise
naturally in FL applications that involve sparsity, low-rank, monotonicity, or
more general constraints. We first show that straightforward extensions of
primal algorithms such as FedAvg are not well-suited for FCO since they suffer
from the "curse of primal averaging," resulting in poor convergence. As a
solution, we propose a new primal-dual algorithm, Federated Dual Averaging
(FedDualAvg), which by employing a novel server dual averaging procedure
circumvents the curse of primal averaging. Our theoretical analysis and
empirical experiments demonstrate that FedDualAvg outperforms the other
baselines.
</p>
<a href="http://arxiv.org/abs/2011.08474" target="_blank">arXiv:2011.08474</a> [<a href="http://arxiv.org/pdf/2011.08474" target="_blank">pdf</a>]

<h2>Logarithmic Regret for Reinforcement Learning with Linear Function Approximation. (arXiv:2011.11566v2 [cs.LG] UPDATED)</h2>
<h3>Jiafan He, Dongruo Zhou, Quanquan Gu</h3>
<p>Reinforcement learning (RL) with linear function approximation has received
increasing attention recently. However, existing work has focused on obtaining
$\sqrt{T}$-type regret bound, where $T$ is the number of interactions with the
MDP. In this paper, we show that logarithmic regret is attainable under two
recently proposed linear MDP assumptions provided that there exists a positive
sub-optimality gap for the optimal action-value function. More specifically,
under the linear MDP assumption (Jin et al. 2019), the LSVI-UCB algorithm can
achieve $\tilde{O}(d^{3}H^5/\text{gap}_{\text{min}}\cdot \log(T))$ regret; and
under the linear mixture MDP assumption (Ayoub et al. 2020), the UCRL-VTR
algorithm can achieve $\tilde{O}(d^{2}H^5/\text{gap}_{\text{min}}\cdot
\log^3(T))$ regret, where $d$ is the dimension of feature mapping, $H$ is the
length of episode, $\text{gap}_{\text{min}}$ is the minimal sub-optimality gap,
and $\tilde O$ hides all logarithmic terms except $\log(T)$. To the best of our
knowledge, these are the first logarithmic regret bounds for RL with linear
function approximation. We also establish gap-dependent lower bounds for the
two linear MDP models.
</p>
<a href="http://arxiv.org/abs/2011.11566" target="_blank">arXiv:2011.11566</a> [<a href="http://arxiv.org/pdf/2011.11566" target="_blank">pdf</a>]

<h2>Differentially Private Learning Needs Better Features (or Much More Data). (arXiv:2011.11660v3 [cs.LG] UPDATED)</h2>
<h3>Florian Tram&#xe8;r, Dan Boneh</h3>
<p>We demonstrate that differentially private machine learning has not yet
reached its "AlexNet moment" on many canonical vision tasks: linear models
trained on handcrafted features significantly outperform end-to-end deep neural
networks for moderate privacy budgets. To exceed the performance of handcrafted
features, we show that private learning requires either much more private data,
or access to features learned on public data from a similar domain. Our work
introduces simple yet strong baselines for differentially private learning that
can inform the evaluation of future progress in this area.
</p>
<a href="http://arxiv.org/abs/2011.11660" target="_blank">arXiv:2011.11660</a> [<a href="http://arxiv.org/pdf/2011.11660" target="_blank">pdf</a>]

<h2>Temporal Action Detection with Multi-level Supervision. (arXiv:2011.11893v2 [cs.CV] UPDATED)</h2>
<h3>Baifeng Shi, Qi Dai, Judy Hoffman, Kate Saenko, Trevor Darrell, Huijuan Xu</h3>
<p>Training temporal action detection in videos requires large amounts of
labeled data, yet such annotation is expensive to collect. Incorporating
unlabeled or weakly-labeled data to train action detection model could help
reduce annotation cost. In this work, we first introduce the Semi-supervised
Action Detection (SSAD) task with a mixture of labeled and unlabeled data and
analyze different types of errors in the proposed SSAD baselines which are
directly adapted from the semi-supervised classification task. To alleviate the
main error of action incompleteness (i.e., missing parts of actions) in SSAD
baselines, we further design an unsupervised foreground attention (UFA) module
utilizing the "independence" between foreground and background motion. Then we
incorporate weakly-labeled data into SSAD and propose Omni-supervised Action
Detection (OSAD) with three levels of supervision. An information bottleneck
(IB) suppressing the scene information in non-action frames while preserving
the action information is designed to help overcome the accompanying
action-context confusion problem in OSAD baselines. We extensively benchmark
against the baselines for SSAD and OSAD on our created data splits in THUMOS14
and ActivityNet1.2, and demonstrate the effectiveness of the proposed UFA and
IB methods. Lastly, the benefit of our full OSAD-IB model under limited
annotation budgets is shown by exploring the optimal annotation strategy for
labeled, unlabeled and weakly-labeled data.
</p>
<a href="http://arxiv.org/abs/2011.11893" target="_blank">arXiv:2011.11893</a> [<a href="http://arxiv.org/pdf/2011.11893" target="_blank">pdf</a>]

<h2>Energy-Based Models for Continual Learning. (arXiv:2011.12216v2 [cs.LG] UPDATED)</h2>
<h3>Shuang Li, Yilun Du, Gido M. van de Ven, Igor Mordatch</h3>
<p>We motivate Energy-Based Models (EBMs) as a promising model class for
continual learning problems. Instead of tackling continual learning via the use
of external memory, growing models, or regularization, EBMs have a natural way
to support a dynamically-growing number of tasks or classes that causes less
interference with previously learned information. Our proposed version of EBMs
for continual learning is simple, efficient and outperforms baseline methods by
a large margin on several benchmarks. Moreover, our proposed contrastive
divergence based training objective can be applied to other continual learning
methods, resulting in substantial boosts in their performance. We also show
that EBMs are adaptable to a more general continual learning setting where the
data distribution changes without the notion of explicitly delineated tasks.
These observations point towards EBMs as a class of models naturally inclined
towards the continual learning regime.
</p>
<a href="http://arxiv.org/abs/2011.12216" target="_blank">arXiv:2011.12216</a> [<a href="http://arxiv.org/pdf/2011.12216" target="_blank">pdf</a>]

<h2>Inductive Biases for Deep Learning of Higher-Level Cognition. (arXiv:2011.15091v3 [cs.LG] UPDATED)</h2>
<h3>Anirudh Goyal, Yoshua Bengio</h3>
<p>A fascinating hypothesis is that human and animal intelligence could be
explained by a few principles (rather than an encyclopedic list of heuristics).
If that hypothesis was correct, we could more easily both understand our own
intelligence and build intelligent machines. Just like in physics, the
principles themselves would not be sufficient to predict the behavior of
complex systems like brains, and substantial computation might be needed to
simulate human-like intelligence. This hypothesis would suggest that studying
the kind of inductive biases that humans and animals exploit could help both
clarify these principles and provide inspiration for AI research and
neuroscience theories. Deep learning already exploits several key inductive
biases, and this work considers a larger list, focusing on those which concern
mostly higher-level and sequential conscious processing. The objective of
clarifying these particular principles is that they could potentially help us
build AI systems benefiting from humans' abilities in terms of flexible
out-of-distribution and systematic generalization, which is currently an area
where a large gap exists between state-of-the-art machine learning and human
intelligence.
</p>
<a href="http://arxiv.org/abs/2011.15091" target="_blank">arXiv:2011.15091</a> [<a href="http://arxiv.org/pdf/2011.15091" target="_blank">pdf</a>]

<h2>Interpretable Graph Capsule Networks for Object Recognition. (arXiv:2012.01674v2 [cs.CV] UPDATED)</h2>
<h3>Jindong Gu</h3>
<p>Capsule Networks, as alternatives to Convolutional Neural Networks, have been
proposed to recognize objects from images. The current literature demonstrates
many advantages of CapsNets over CNNs. However, how to create explanations for
individual classifications of CapsNets has not been well explored. The widely
used saliency methods are mainly proposed for explaining CNN-based
classifications; they create saliency map explanations by combining activation
values and the corresponding gradients, e.g., Grad-CAM. These saliency methods
require a specific architecture of the underlying classifiers and cannot be
trivially applied to CapsNets due to the iterative routing mechanism therein.
To overcome the lack of interpretability, we can either propose new post-hoc
interpretation methods for CapsNets or modifying the model to have build-in
explanations. In this work, we explore the latter. Specifically, we propose
interpretable Graph Capsule Networks (GraCapsNets), where we replace the
routing part with a multi-head attention-based Graph Pooling approach. In the
proposed model, individual classification explanations can be created
effectively and efficiently. Our model also demonstrates some unexpected
benefits, even though it replaces the fundamental part of CapsNets. Our
GraCapsNets achieve better classification performance with fewer parameters and
better adversarial robustness, when compared to CapsNets. Besides, GraCapsNets
also keep other advantages of CapsNets, namely, disentangled representations
and affine transformation robustness.
</p>
<a href="http://arxiv.org/abs/2012.01674" target="_blank">arXiv:2012.01674</a> [<a href="http://arxiv.org/pdf/2012.01674" target="_blank">pdf</a>]

<h2>Reconstruction of Backbone Curves for Snake Robots. (arXiv:2012.04855v2 [cs.RO] UPDATED)</h2>
<h3>Tianyu Wang, Bo Lin, Baxi Chong, Julian Whitman, Matthew Travers, Daniel I. Goldman, Greg Blekherman, Howie Choset</h3>
<p>Snake robots composed of alternating single-axis pitch and yaw joints have
many internal degrees of freedom, which make them capable of versatile
three-dimensional locomotion. In motion planning process, snake robot motions
are often designed kinematically by a chronological sequence of continuous
backbone curves that capture desired macroscopic shapes of the robot. However,
as the geometric arrangement of single-axis rotary joints creates constraints
on the rotations in the robot, it is challenging for the robot to reconstruct
an arbitrary 3D curve. When the robot configuration does not accurately achieve
the desired shapes defined by these backbone curves, the robot can have
unexpected contacts with the environment, such that the robot does not achieve
the desired motion. In this work, we propose a method for snake robots to
reconstruct desired backbone curves by posing an optimization problem that
exploits the robot's geometric structure. We verified that our method enables
fast and accurate curve-configuration conversions through its applications to
commonly used 3D gaits. We also demonstrated via robot experiments that 1) our
method results in smooth locomotion on the robot; 2) our method allows the
robot to approach the numerically predicted locomotive performance of a
sequence of continuous backbone curve.
</p>
<a href="http://arxiv.org/abs/2012.04855" target="_blank">arXiv:2012.04855</a> [<a href="http://arxiv.org/pdf/2012.04855" target="_blank">pdf</a>]

<h2>DETR for Crowd Pedestrian Detection. (arXiv:2012.06785v3 [cs.CV] UPDATED)</h2>
<h3>Matthieu Lin, Chuming Li, Xingyuan Bu, Ming Sun, Chen Lin, Junjie Yan, Wanli Ouyang, Zhidong Deng</h3>
<p>Pedestrian detection in crowd scenes poses a challenging problem due to the
heuristic defined mapping from anchors to pedestrians and the conflict between
NMS and highly overlapped pedestrians. The recently proposed end-to-end
detectors(ED), DETR and deformable DETR, replace hand designed components such
as NMS and anchors using the transformer architecture, which gets rid of
duplicate predictions by computing all pairwise interactions between queries.
Inspired by these works, we explore their performance on crowd pedestrian
detection. Surprisingly, compared to Faster-RCNN with FPN, the results are
opposite to those obtained on COCO. Furthermore, the bipartite match of ED
harms the training efficiency due to the large ground truth number in crowd
scenes. In this work, we identify the underlying motives driving ED's poor
performance and propose a new decoder to address them. Moreover, we design a
mechanism to leverage the less occluded visible parts of pedestrian
specifically for ED, and achieve further improvements. A faster bipartite match
algorithm is also introduced to make ED training on crowd dataset more
practical. The proposed detector PED(Pedestrian End-to-end Detector)
outperforms both previous EDs and the baseline Faster-RCNN on CityPersons and
CrowdHuman. It also achieves comparable performance with state-of-the-art
pedestrian detection methods. Code will be released soon.
</p>
<a href="http://arxiv.org/abs/2012.06785" target="_blank">arXiv:2012.06785</a> [<a href="http://arxiv.org/pdf/2012.06785" target="_blank">pdf</a>]

<h2>Hybrid Federated Learning: Algorithms and Implementation. (arXiv:2012.12420v3 [cs.LG] UPDATED)</h2>
<h3>Xinwei Zhang, Wotao Yin, Mingyi Hong, Tianyi Chen</h3>
<p>Federated learning (FL) is a recently proposed distributed machine learning
paradigm dealing with distributed and private data sets. Based on the data
partition pattern, FL is often categorized into horizontal, vertical, and
hybrid settings. Despite the fact that many works have been developed for the
first two approaches, the hybrid FL setting (which deals with partially
overlapped feature space and sample space) remains less explored, though this
setting is extremely important in practice. In this paper, we first set up a
new model-matching-based problem formulation for hybrid FL, then propose an
efficient algorithm that can collaboratively train the global and local models
to deal with full and partial featured data. We conduct numerical experiments
on the multi-view ModelNet40 data set to validate the performance of the
proposed algorithm. To the best of our knowledge, this is the first formulation
and algorithm developed for the hybrid FL.
</p>
<a href="http://arxiv.org/abs/2012.12420" target="_blank">arXiv:2012.12420</a> [<a href="http://arxiv.org/pdf/2012.12420" target="_blank">pdf</a>]

<h2>Using the Naive Bayes as a discriminative classifier. (arXiv:2012.13572v2 [stat.ML] UPDATED)</h2>
<h3>Elie Azeraf, Emmanuel Monfrini, Wojciech Pieczynski</h3>
<p>For classification tasks, probabilistic models can be categorized into two
disjoint classes: generative or discriminative. It depends on the posterior
probability computation of the label $x$ given the observation $y$, $p(x | y)$.
On the one hand, generative classifiers, like the Naive Bayes or the Hidden
Markov Model (HMM), need the computation of the joint probability p(x,y),
before using the Bayes rule to compute $p(x | y)$. On the other hand,
discriminative classifiers compute $p(x | y)$ directly, regardless of the
observations' law. They are intensively used nowadays, with models as Logistic
Regression, Conditional Random Fields (CRF), and Artificial Neural Networks.
However, the recent Entropic Forward-Backward algorithm shows that the HMM,
considered as a generative model, can also match the discriminative one's
definition. This example leads to question if it is the case for other
generative models. In this paper, we show that the Naive Bayes classifier can
also match the discriminative classifier definition, so it can be used in
either a generative or a discriminative way. Moreover, this observation also
discusses the notion of Generative-Discriminative pairs, linking, for example,
Naive Bayes and Logistic Regression, or HMM and CRF. Related to this point, we
show that the Logistic Regression can be viewed as a particular case of the
Naive Bayes used in a discriminative way.
</p>
<a href="http://arxiv.org/abs/2012.13572" target="_blank">arXiv:2012.13572</a> [<a href="http://arxiv.org/pdf/2012.13572" target="_blank">pdf</a>]

<h2>Learning General Policies from Small Examples Without Supervision. (arXiv:2101.00692v2 [cs.AI] UPDATED)</h2>
<h3>Guillem Franc&#xe8;s, Blai Bonet, Hector Geffner</h3>
<p>Generalized planning is concerned with the computation of general policies
that solve multiple instances of a planning domain all at once. It has been
recently shown that these policies can be computed in two steps: first, a
suitable abstraction in the form of a qualitative numerical planning problem
(QNP) is learned from sample plans, then the general policies are obtained from
the learned QNP using a planner. In this work, we introduce an alternative
approach for computing more expressive general policies which does not require
sample plans or a QNP planner. The new formulation is very simple and can be
cast in terms that are more standard in machine learning: a large but finite
pool of features is defined from the predicates in the planning examples using
a general grammar, and a small subset of features is sought for separating
"good" from "bad" state transitions, and goals from non-goals. The problems of
finding such a "separating surface" while labeling the transitions as "good" or
"bad" are jointly addressed as a single combinatorial optimization problem
expressed as a Weighted Max-SAT problem. The advantage of looking for the
simplest policy in the given feature space that solves the given examples,
possibly non-optimally, is that many domains have no general, compact policies
that are optimal. The approach yields general policies for a number of
benchmark domains.
</p>
<a href="http://arxiv.org/abs/2101.00692" target="_blank">arXiv:2101.00692</a> [<a href="http://arxiv.org/pdf/2101.00692" target="_blank">pdf</a>]

<h2>How to Train Your Energy-Based Models. (arXiv:2101.03288v2 [cs.LG] UPDATED)</h2>
<h3>Yang Song, Diederik P. Kingma</h3>
<p>Energy-Based Models (EBMs), also known as non-normalized probabilistic
models, specify probability density or mass functions up to an unknown
normalizing constant. Unlike most other probabilistic models, EBMs do not place
a restriction on the tractability of the normalizing constant, thus are more
flexible to parameterize and can model a more expressive family of probability
distributions. However, the unknown normalizing constant of EBMs makes training
particularly difficult. Our goal is to provide a friendly introduction to
modern approaches for EBM training. We start by explaining maximum likelihood
training with Markov chain Monte Carlo (MCMC), and proceed to elaborate on
MCMC-free approaches, including Score Matching (SM) and Noise Constrastive
Estimation (NCE). We highlight theoretical connections among these three
approaches, and end with a brief survey on alternative training methods, which
are still under active research. Our tutorial is targeted at an audience with
basic understanding of generative models who want to apply EBMs or start a
research project in this direction.
</p>
<a href="http://arxiv.org/abs/2101.03288" target="_blank">arXiv:2101.03288</a> [<a href="http://arxiv.org/pdf/2101.03288" target="_blank">pdf</a>]

<h2>TypeNet: Deep Learning Keystroke Biometrics. (arXiv:2101.05570v2 [cs.CV] UPDATED)</h2>
<h3>Alejandro Acien, Aythami Morales, John V. Monaco, Ruben Vera-Rodriguez, Julian Fierrez</h3>
<p>We study the performance of Long Short-Term Memory networks for keystroke
biometric authentication at large scale in free-text scenarios. For this we
introduce TypeNet, a Recurrent Neural Network (RNN) trained with a moderate
number of keystrokes per identity. We evaluate different learning approaches
depending on the loss function (softmax, contrastive, and triplet loss), number
of gallery samples, length of the keystroke sequences, and device type
(physical vs touchscreen keyboard). With 5 gallery sequences and test sequences
of length 50, TypeNet achieves state-of-the-art keystroke biometric
authentication performance with an Equal Error Rate of 2.2% and 9.2% for
physical and touchscreen keyboards, respectively, significantly outperforming
previous approaches. Our experiments demonstrate a moderate increase in error
with up to 100,000 subjects, demonstrating the potential of TypeNet to operate
at an Internet scale. We utilize two Aalto University keystroke databases, one
captured on physical keyboards and the second on mobile devices (touchscreen
keyboards). To the best of our knowledge, both databases are the largest
existing free-text keystroke databases available for research with more than
136 million keystrokes from 168,000 subjects in physical keyboards, and 60,000
subjects with more than 63 million keystrokes acquired on mobile touchscreens.
</p>
<a href="http://arxiv.org/abs/2101.05570" target="_blank">arXiv:2101.05570</a> [<a href="http://arxiv.org/pdf/2101.05570" target="_blank">pdf</a>]

<h2>Bayesian Inference Forgetting. (arXiv:2101.06417v2 [cs.LG] UPDATED)</h2>
<h3>Shaopeng Fu, Fengxiang He, Yue Xu, Dacheng Tao</h3>
<p>The right to be forgotten has been legislated in many countries but the
enforcement in machine learning would cause unbearable costs: companies may
need to delete whole models learned from massive resources due to single
individual requests. Existing works propose to remove the knowledge learned
from the requested data via its influence function which is no longer naturally
well-defined in Bayesian inference. This paper proposes a {\it Bayesian
inference forgetting} (BIF) framework to realize the right to be forgotten in
Bayesian inference. In the BIF framework, we develop forgetting algorithms for
variational inference and Markov chain Monte Carlo. We show that our algorithms
can provably remove the influence of single datums on the learned models.
Theoretical analysis demonstrates that our algorithms have guaranteed
generalizability. Experiments of Gaussian mixture models on the synthetic
dataset and Bayesian neural networks on the real-world data verify the
feasibility of our methods. The source code package is available at
\url{https://github.com/fshp971/BIF}.
</p>
<a href="http://arxiv.org/abs/2101.06417" target="_blank">arXiv:2101.06417</a> [<a href="http://arxiv.org/pdf/2101.06417" target="_blank">pdf</a>]

<h2>Safe Learning and Optimization Techniques: Towards a Survey of the State of the Art. (arXiv:2101.09505v2 [cs.LG] UPDATED)</h2>
<h3>Youngmin Kim, Richard Allmendinger, Manuel L&#xf3;pez-Ib&#xe1;&#xf1;ez</h3>
<p>Safe learning and optimization deals with learning and optimization problems
that avoid, as much as possible, the evaluation of non-safe input points, which
are solutions, policies, or strategies that cause an irrecoverable loss (e.g.,
breakage of a machine or equipment, or life threat). Although a comprehensive
survey of safe reinforcement learning algorithms was published in 2015, a
number of new algorithms have been proposed thereafter, and related works in
active learning and in optimization were not considered. This paper reviews
those algorithms from a number of domains including reinforcement learning,
Gaussian process regression and classification, evolutionary algorithms, and
active learning. We provide the fundamental concepts on which the reviewed
algorithms are based and a characterization of the individual algorithms. We
conclude by explaining how the algorithms are connected and suggestions for
future research.
</p>
<a href="http://arxiv.org/abs/2101.09505" target="_blank">arXiv:2101.09505</a> [<a href="http://arxiv.org/pdf/2101.09505" target="_blank">pdf</a>]

<h2>The GRIFFIN Perception Dataset: Bridging the Gap Between Flapping-Wing Flight and Robotic Perception. (arXiv:2101.10371v2 [cs.RO] UPDATED)</h2>
<h3>J.P. Rodr&#xed;guez-G&#xf3;mez, R. Tapia, J. L. Paneque, P. Grau, A. G&#xf3;mez Egu&#xed;luz, J.R. Mart&#xed;nez-de Dios, A. Ollero</h3>
<p>The development of automatic perception systems and techniques for
bio-inspired flapping-wing robots is severely hampered by the high technical
complexity of these platforms and the installation of onboard sensors and
electronics. Besides, flapping-wing robot perception suffers from high
vibration levels and abrupt movements during flight, which cause motion blur
and strong changes in lighting conditions. This paper presents a perception
dataset for bird-scale flapping-wing robots as a tool to help alleviate the
aforementioned problems. The presented data include measurements from onboard
sensors widely used in aerial robotics and suitable to deal with the perception
challenges of flapping-wing robots, such as an event camera, a conventional
camera, and two Inertial Measurement Units (IMUs), as well as ground truth
measurements from a laser tracker or a motion capture system. A total of 21
datasets of different types of flights were collected in three different
scenarios (one indoor and two outdoor). To the best of the authors' knowledge
this is the first dataset for flapping-wing robot perception.
</p>
<a href="http://arxiv.org/abs/2101.10371" target="_blank">arXiv:2101.10371</a> [<a href="http://arxiv.org/pdf/2101.10371" target="_blank">pdf</a>]

<h2>Deep Learning-Based Autoencoder for Data-Driven Modeling of an RF Photoinjector. (arXiv:2101.10437v2 [cs.LG] UPDATED)</h2>
<h3>Jun Zhu, Ye Chen, Frank Brinker, Winfried Decking, Sergey Tomin, Holger Schlarb</h3>
<p>We adopt a data-driven approach to model the longitudinal phase-space
diagnostic beamline at the European XFEL photoinjector. A deep convolutional
neural network (decoder) is used to build a 2D distribution from a small
feature space learned by another neural network (encoder). We demonstrate that
the autoencoder trained on experimental data can make very high-quality
predictions of megapixel images for the longitudinal phase-space measurement.
The prediction significantly outperforms existing methods. We also show the
explicability of the autoencoder by sharing the same decoder with more than one
encoder used for different setups of the photoinjector. This opens the door to
a new way of accurately modeling a photoinjector using neural networks. The
approach can possibly be extended to the whole accelerator and even the photon
beamlines.
</p>
<a href="http://arxiv.org/abs/2101.10437" target="_blank">arXiv:2101.10437</a> [<a href="http://arxiv.org/pdf/2101.10437" target="_blank">pdf</a>]

<h2>Self-supervised Cross-silo Federated Neural Architecture Search. (arXiv:2101.11896v2 [cs.LG] UPDATED)</h2>
<h3>Xinle Liang, Yang Liu, Jiahuan Luo, Yuanqin He, Tianjian Chen, Qiang Yang</h3>
<p>Federated Learning (FL) provides both model performance and data privacy for
machine learning tasks where samples or features are distributed among
different parties. In the training process of FL, no party has a global view of
data distributions or model architectures of other parties. Thus the
manually-designed architectures may not be optimal. In the past, Neural
Architecture Search (NAS) has been applied to FL to address this critical
issue. However, existing Federated NAS approaches require prohibitive
communication and computation effort, as well as the availability of
high-quality labels. In this work, we present Self-supervised Vertical
Federated Neural Architecture Search (SS-VFNAS) for automating FL where
participants hold feature-partitioned data, a common cross-silo scenario called
Vertical Federated Learning (VFL). In the proposed framework, each party first
conducts NAS using self-supervised approach to find a local optimal
architecture with its own data. Then, parties collaboratively improve the local
optimal architecture in a VFL framework with supervision. We demonstrate
experimentally that our approach has superior performance, communication
efficiency and privacy compared to Federated NAS and is capable of generating
high-performance and highly-transferable heterogeneous architectures even with
insufficient overlapping samples, providing automation for those parties
without deep learning expertise.
</p>
<a href="http://arxiv.org/abs/2101.11896" target="_blank">arXiv:2101.11896</a> [<a href="http://arxiv.org/pdf/2101.11896" target="_blank">pdf</a>]

<h2>Forensicability of Deep Neural Network Inference Pipelines. (arXiv:2102.00921v2 [cs.LG] UPDATED)</h2>
<h3>Alexander Schl&#xf6;gl, Tobias Kupek, Rainer B&#xf6;hme</h3>
<p>We propose methods to infer properties of the execution environment of
machine learning pipelines by tracing characteristic numerical deviations in
observable outputs. Results from a series of proof-of-concept experiments
obtained on local and cloud-hosted machines give rise to possible forensic
applications, such as the identification of the hardware platform used to
produce deep neural network predictions. Finally, we introduce boundary samples
that amplify the numerical deviations in order to distinguish machines by their
predicted label only.
</p>
<a href="http://arxiv.org/abs/2102.00921" target="_blank">arXiv:2102.00921</a> [<a href="http://arxiv.org/pdf/2102.00921" target="_blank">pdf</a>]

<h2>Recent Advances in Adversarial Training for Adversarial Robustness. (arXiv:2102.01356v3 [cs.LG] UPDATED)</h2>
<h3>Tao Bai, Jinqi Luo, Jun Zhao, Bihan Wen, Qian Wang</h3>
<p>Adversarial training is one of the most effective approaches defending
against adversarial examples for deep learning models. Unlike other defense
strategies, adversarial training aims to promote the robustness of models
intrinsically. During the last few years, adversarial training has been studied
and discussed from various aspects. A variety of improvements and developments
of adversarial training are proposed, but neglected in existing surveys. In
this survey, we systematically review the recent progress on adversarial
training with a novel taxonomy for the first time. Then we discuss the
generalization problems in adversarial training from three perspectives.
Finally, we highlight the challenges which are not fully solved and present
potential future directions.
</p>
<a href="http://arxiv.org/abs/2102.01356" target="_blank">arXiv:2102.01356</a> [<a href="http://arxiv.org/pdf/2102.01356" target="_blank">pdf</a>]

<h2>Scattering Networks on the Sphere for Scalable and Rotationally Equivariant Spherical CNNs. (arXiv:2102.02828v2 [cs.CV] UPDATED)</h2>
<h3>Jason D. McEwen, Christopher G. R. Wallis, Augustine N. Mavor-Parker</h3>
<p>Convolutional neural networks (CNNs) constructed natively on the sphere have
been developed recently and shown to be highly effective for the analysis of
spherical data. While an efficient framework has been formulated, spherical
CNNs are nevertheless highly computationally demanding; typically they cannot
scale beyond spherical signals of thousands of pixels. We develop scattering
networks constructed natively on the sphere that provide a powerful
representational space for spherical data. Spherical scattering networks are
computationally scalable and exhibit rotational equivariance, while their
representational space is invariant to isometries and provides efficient and
stable signal representations. By integrating scattering networks as an
additional type of layer in the generalized spherical CNN framework, we show
how they can be leveraged to scale spherical CNNs to the high-resolution data
typical of many practical applications, with spherical signals of many tens of
megapixels and beyond.
</p>
<a href="http://arxiv.org/abs/2102.02828" target="_blank">arXiv:2102.02828</a> [<a href="http://arxiv.org/pdf/2102.02828" target="_blank">pdf</a>]

<h2>NRTSI: Non-Recurrent Time Series Imputation for Irregularly-sampled Data. (arXiv:2102.03340v2 [cs.LG] UPDATED)</h2>
<h3>Siyuan Shan, Junier B. Oliva</h3>
<p>Time series imputation is a fundamental task for understanding time series
with missing data. Existing imputation methods often rely on recurrent models
such as RNNs and ordinary differential equations, both of which suffer from the
error compounding problems of recurrent models. In this work, we view the
imputation task from the perspective of permutation equivariant modeling of
sets and propose a novel imputation model called NRTSI without any recurrent
modules. Taking advantage of the permutation equivariant nature of NRTSI, we
design a principled and efficient hierarchical imputation procedure. NRTSI can
easily handle irregularly-sampled data, perform multiple-mode stochastic
imputation, and handle the scenario where dimensions are partially observed. We
show that NRTSI achieves state-of-the-art performance across a wide range of
commonly used time series imputation benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.03340" target="_blank">arXiv:2102.03340</a> [<a href="http://arxiv.org/pdf/2102.03340" target="_blank">pdf</a>]

<h2>Meta Discovery: Learning to Discover Novel Classes given Very Limited Data. (arXiv:2102.04002v2 [cs.LG] UPDATED)</h2>
<h3>Haoang Chi, Feng Liu, Wenjing Yang, Long Lan, Tongliang Liu, Gang Niu, Bo Han</h3>
<p>In learning to discover novel classes(L2DNC), we are given labeled data from
seen classes and unlabeled data from unseen classes, and we need to train
clustering models for the unseen classes. Since L2DNC is a new problem, its
application scenario and implicit assumption are unclear. In this paper, we
analyze and improve it by linking it to meta-learning: although there are no
meta-training and meta-test phases, the underlying assumption is exactly the
same, namely high-level semantic features are shared among the seen and unseen
classes. Under this assumption, L2DNC is not only theoretically solvable, but
also can be empirically solved by meta-learning algorithms slightly modified to
fit our proposed framework. This L2DNC methodology significantly reduces the
amount of unlabeled data needed for training and makes it more practical, as
demonstrated in experiments. The use of very limited data is also justified by
the application scenario of L2DNC: since it is unnatural to label only
seen-class data, L2DNC is causally sampling instead of labeling. The
unseen-class data should be collected on the way of collecting seen-class data,
which is why they are novel and first need to be clustered.
</p>
<a href="http://arxiv.org/abs/2102.04002" target="_blank">arXiv:2102.04002</a> [<a href="http://arxiv.org/pdf/2102.04002" target="_blank">pdf</a>]

<h2>A Hybrid Bandit Model with Visual Priors for Creative Ranking in Display Advertising. (arXiv:2102.04033v2 [cs.CV] UPDATED)</h2>
<h3>Shiyao Wang, Qi Liu, Tiezheng Ge, Defu Lian, Zhiqiang Zhang</h3>
<p>Creative plays a great important role in e-commerce for exhibiting products.
Sellers usually create multiple creatives for comprehensive demonstrations,
thus it is crucial to display the most appealing design to maximize the
Click-Through Rate~(CTR). For this purpose, modern recommender systems
dynamically rank creatives when a product is proposed for a user. However, this
task suffers more cold-start problem than conventional products recommendation
In this paper, we propose a hybrid bandit model with visual priors which first
makes predictions with a visual evaluation, and then naturally evolves to focus
on the specialities through the hybrid bandit model. Our contributions are
three-fold: 1) We present a visual-aware ranking model (called VAM) that
incorporates a list-wise ranking loss for ordering the creatives according to
the visual appearance. 2) Regarding visual evaluations as a prior, the hybrid
bandit model (called HBM) is proposed to evolve consistently to make better
posteriori estimations by taking more observations into consideration for
online scenarios. 3) A first large-scale creative dataset, CreativeRanking, is
constructed, which contains over 1.7M creatives of 500k products as well as
their real impression and click data. Extensive experiments have also been
conducted on both our dataset and public Mushroom dataset, demonstrating the
effectiveness of the proposed method.
</p>
<a href="http://arxiv.org/abs/2102.04033" target="_blank">arXiv:2102.04033</a> [<a href="http://arxiv.org/pdf/2102.04033" target="_blank">pdf</a>]

<h2>Adversarial Robustness: What fools you makes you stronger. (arXiv:2102.05475v2 [cs.LG] UPDATED)</h2>
<h3>Grzegorz G&#x142;uch, R&#xfc;diger Urbanke</h3>
<p>We prove an exponential separation for the sample complexity between the
standard PAC-learning model and a version of the Equivalence-Query-learning
model. We then show that this separation has interesting implications for
adversarial robustness. We explore a vision of designing an adaptive defense
that in the presence of an attacker computes a model that is provably robust.
In particular, we show how to realize this vision in a simplified setting.

In order to do so, we introduce a notion of a strong adversary: he is not
limited by the type of perturbations he can apply but when presented with a
classifier can repetitively generate different adversarial examples. We explain
why this notion is interesting to study and use it to prove the following.
There exists an efficient adversarial-learning-like scheme such that for every
strong adversary $\mathbf{A}$ it outputs a classifier that (a) cannot be
strongly attacked by $\mathbf{A}$, or (b) has error at most $\epsilon$. In both
cases our scheme uses exponentially (in $\epsilon$) fewer samples than what the
PAC bound requires.
</p>
<a href="http://arxiv.org/abs/2102.05475" target="_blank">arXiv:2102.05475</a> [<a href="http://arxiv.org/pdf/2102.05475" target="_blank">pdf</a>]

<h2>Attention-based Domain Adaptation for Time Series Forecasting. (arXiv:2102.06828v2 [cs.LG] UPDATED)</h2>
<h3>Xiaoyong Jin, Youngsuk Park, Danielle C. Maddix, Yuyang Wang, Xifeng Yan</h3>
<p>Recent years have witnessed deep neural networks gaining increasing
popularity in the field of time series forecasting. A primary reason of their
success is their ability to effectively capture complex temporal dynamics
across multiple related time series. However, the advantages of these deep
forecasters only start to emerge in the presence of a sufficient amount of
data. This poses a challenge for typical forecasting problems in practice,
where one either has a small number of time series, or limited observations per
time series, or both. To cope with the issue of data scarcity, we propose a
novel domain adaptation framework, Domain Adaptation Forecaster (DAF), that
leverages the statistical strengths from another relevant domain with abundant
data samples (source) to improve the performance on the domain of interest with
limited data (target). In particular, we propose an attention-based shared
module with a domain discriminator across domains as well as private modules
for individual domains. This allows us to jointly train the source and target
domains by generating domain-invariant latent features while retraining
domain-specific features. Extensive experiments on various domains demonstrate
that our proposed method outperforms state-of-the-art baselines on synthetic
and real-world datasets.
</p>
<a href="http://arxiv.org/abs/2102.06828" target="_blank">arXiv:2102.06828</a> [<a href="http://arxiv.org/pdf/2102.06828" target="_blank">pdf</a>]

<h2>On the Theory of Implicit Deep Learning: Global Convergence with Implicit Layers. (arXiv:2102.07346v2 [cs.LG] UPDATED)</h2>
<h3>Kenji Kawaguchi</h3>
<p>A deep equilibrium model uses implicit layers, which are implicitly defined
through an equilibrium point of an infinite sequence of computation. It avoids
any explicit computation of the infinite sequence by finding an equilibrium
point directly via root-finding and by computing gradients via implicit
differentiation. In this paper, we analyze the gradient dynamics of deep
equilibrium models with nonlinearity only on weight matrices and non-convex
objective functions of weights for regression and classification. Despite
non-convexity, convergence to global optimum at a linear rate is guaranteed
without any assumption on the width of the models, allowing the width to be
smaller than the output dimension and the number of data points. Moreover, we
prove a relation between the gradient dynamics of the deep implicit layer and
the dynamics of trust region Newton method of a shallow explicit layer. This
mathematically proven relation along with our numerical observation suggests
the importance of understanding implicit bias of implicit layers and an open
problem on the topic. Our proofs deal with implicit layers, weight tying and
nonlinearity on weights, and differ from those in the related literature.
</p>
<a href="http://arxiv.org/abs/2102.07346" target="_blank">arXiv:2102.07346</a> [<a href="http://arxiv.org/pdf/2102.07346" target="_blank">pdf</a>]

<h2>Hough2Map -- Iterative Event-based Hough Transform for High-Speed Railway Mapping. (arXiv:2102.08145v2 [cs.RO] UPDATED)</h2>
<h3>Florian Tschopp, Cornelius von Einem, Andrei Cramariuc, David Hug, Andrew William Palmer, Roland Siegwart, Margarita Chli, Juan Nieto</h3>
<p>To cope with the growing demand for transportation on the railway system,
accurate, robust, and high-frequency positioning is required to enable a safe
and efficient utilization of the existing railway infrastructure. As a basis
for a localization system we propose a complete on-board mapping pipeline able
to map robust meaningful landmarks, such as poles from power lines, in the
vicinity of the vehicle. Such poles are good candidates for reliable and long
term landmarks even through difficult weather conditions or seasonal changes.
To address the challenges of motion blur and illumination changes in railway
scenarios we employ a Dynamic Vision Sensor, a novel event-based camera. Using
a sideways oriented on-board camera, poles appear as vertical lines. To map
such lines in a real-time event stream, we introduce Hough2Map, a novel
consecutive iterative event-based Hough transform framework capable of
detecting, tracking, and triangulating close-by structures. We demonstrate the
mapping reliability and accuracy of Hough2Map on real-world data in typical
usage scenarios and evaluate using surveyed infrastructure ground truth maps.
Hough2Map achieves a detection reliability of up to 92% and a mapping root mean
square error accuracy of 1.1518m.
</p>
<a href="http://arxiv.org/abs/2102.08145" target="_blank">arXiv:2102.08145</a> [<a href="http://arxiv.org/pdf/2102.08145" target="_blank">pdf</a>]

<h2>StatEcoNet: Statistical Ecology Neural Networks for Species Distribution Modeling. (arXiv:2102.08534v2 [cs.LG] UPDATED)</h2>
<h3>Eugene Seo, Rebecca A. Hutchinson, Xiao Fu, Chelsea Li, Tyler A. Hallman, John Kilbride, W. Douglas Robinson</h3>
<p>This paper focuses on a core task in computational sustainability and
statistical ecology: species distribution modeling (SDM). In SDM, the
occurrence pattern of a species on a landscape is predicted by environmental
features based on observations at a set of locations. At first, SDM may appear
to be a binary classification problem, and one might be inclined to employ
classic tools (e.g., logistic regression, support vector machines, neural
networks) to tackle it. However, wildlife surveys introduce structured noise
(especially under-counting) in the species observations. If unaccounted for,
these observation errors systematically bias SDMs. To address the unique
challenges of SDM, this paper proposes a framework called StatEcoNet.
Specifically, this work employs a graphical generative model in statistical
ecology to serve as the skeleton of the proposed computational framework and
carefully integrates neural networks under the framework. The advantages of
StatEcoNet over related approaches are demonstrated on simulated datasets as
well as bird species data. Since SDMs are critical tools for ecological science
and natural resource management, StatEcoNet may offer boosted computational and
analytical powers to a wide range of applications that have significant social
impacts, e.g., the study and conservation of threatened species.
</p>
<a href="http://arxiv.org/abs/2102.08534" target="_blank">arXiv:2102.08534</a> [<a href="http://arxiv.org/pdf/2102.08534" target="_blank">pdf</a>]

