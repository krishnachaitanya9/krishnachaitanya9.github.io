---
title: Latest Deep Learning Papers
date: 2021-02-15 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (275 Articles)</h1>
<h2>Neural Network Libraries: A Deep Learning Framework Designed from Engineers' Perspectives. (arXiv:2102.06725v1 [cs.LG])</h2>
<h3>Akio Hayakawa, Masato Ishii, Yoshiyuki Kobayashi, Akira Nakamura, Takuya Narihira, Yukio Obuchi, Andrew Shin, Takuya Yashima, Kazuki Yoshiyama</h3>
<p>While there exist a plethora of deep learning tools and frameworks, the
fast-growing complexity of the field brings new demands and challenges, such as
more flexible network design, speedy computation on distributed setting, and
compatibility between different tools. In this paper, we introduce Neural
Network Libraries (https://nnabla.org), a deep learning framework designed from
engineer's perspective, with emphasis on usability and compatibility as its
core design principles. We elaborate on each of our design principles and its
merits, and validate our attempts via experiments.
</p>
<a href="http://arxiv.org/abs/2102.06725" target="_blank">arXiv:2102.06725</a> [<a href="http://arxiv.org/pdf/2102.06725" target="_blank">pdf</a>]

<h2>A novel method for object detection using deep learning and CAD models. (arXiv:2102.06729v1 [cs.CV])</h2>
<h3>Igor Garcia Ballhausen Sampaio, Luigy Machaca, Jos&#xe9; Viterbo, Joris Gu&#xe9;rin</h3>
<p>Object Detection (OD) is an important computer vision problem for industry,
which can be used for quality control in the production lines, among other
applications. Recently, Deep Learning (DL) methods have enabled practitioners
to train OD models performing well on complex real world images. However, the
adoption of these models in industry is still limited by the difficulty and the
significant cost of collecting high quality training datasets. On the other
hand, when applying OD to the context of production lines, CAD models of the
objects to be detected are often available. In this paper, we introduce a fully
automated method that uses a CAD model of an object and returns a fully trained
OD model for detecting this object. To do this, we created a Blender script
that generates realistic labeled datasets of images containing the object,
which are then used for training the OD model. The method is validated
experimentally on two practical examples, showing that this approach can
generate OD models performing well on real images, while being trained only on
synthetic images. The proposed method has potential to facilitate the adoption
of object detection models in industry as it is easy to adapt for new objects
and highly flexible. Hence, it can result in significant costs reduction, gains
in productivity and improved products quality.
</p>
<a href="http://arxiv.org/abs/2102.06729" target="_blank">arXiv:2102.06729</a> [<a href="http://arxiv.org/pdf/2102.06729" target="_blank">pdf</a>]

<h2>Towards Robust Visual Information Extraction in Real World: New Dataset and Novel Solution. (arXiv:2102.06732v1 [cs.CV])</h2>
<h3>Jiapeng Wang, Chongyu Liu, Lianwen Jin, Guozhi Tang, Jiaxin Zhang, Shuaitao Zhang, Qianying Wang, Yaqiang Wu, Mingxiang Cai</h3>
<p>Visual information extraction (VIE) has attracted considerable attention
recently owing to its various advanced applications such as document
understanding, automatic marking and intelligent education. Most existing works
decoupled this problem into several independent sub-tasks of text spotting
(text detection and recognition) and information extraction, which completely
ignored the high correlation among them during optimization. In this paper, we
propose a robust visual information extraction system (VIES) towards real-world
scenarios, which is a unified end-to-end trainable framework for simultaneous
text detection, recognition and information extraction by taking a single
document image as input and outputting the structured information.
Specifically, the information extraction branch collects abundant visual and
semantic representations from text spotting for multimodal feature fusion and
conversely, provides higher-level semantic clues to contribute to the
optimization of text spotting. Moreover, regarding the shortage of public
benchmarks, we construct a fully-annotated dataset called EPHOIE
(https://github.com/HCIILAB/EPHOIE), which is the first Chinese benchmark for
both text spotting and visual information extraction. EPHOIE consists of 1,494
images of examination paper head with complex layouts and background, including
a total of 15,771 Chinese handwritten or printed text instances. Compared with
the state-of-the-art methods, our VIES shows significant superior performance
on the EPHOIE dataset and achieves a 9.01% F-score gain on the widely used
SROIE dataset under the end-to-end scenario.
</p>
<a href="http://arxiv.org/abs/2102.06732" target="_blank">arXiv:2102.06732</a> [<a href="http://arxiv.org/pdf/2102.06732" target="_blank">pdf</a>]

<h2>Revisiting the details when evaluating a visual tracker. (arXiv:2102.06733v1 [cs.CV])</h2>
<h3>Zan Huang</h3>
<p>Visual tracking algorithms are naturally adopted in various applications,
there have been several benchmarks and many tracking algorithms, more expected
to appear in the future. In this report, I focus on single object tracking and
revisit the details of tracker evaluation based on widely used OTB\cite{otb}
benchmark by introducing a simpler, accurate, and extensible method for tracker
evaluation and comparison. Experimental results suggest that there may not be
an absolute winner among tracking algorithms. We have to perform detailed
analysis to select suitable trackers for use cases.
</p>
<a href="http://arxiv.org/abs/2102.06733" target="_blank">arXiv:2102.06733</a> [<a href="http://arxiv.org/pdf/2102.06733" target="_blank">pdf</a>]

<h2>Learning Deep Neural Networks under Agnostic Corrupted Supervision. (arXiv:2102.06735v1 [cs.LG])</h2>
<h3>Boyang Liu, Mengying Sun, Ding Wang, Pang-Ning Tan, Jiayu Zhou</h3>
<p>Training deep neural models in the presence of corrupted supervision is
challenging as the corrupted data points may significantly impact the
generalization performance. To alleviate this problem, we present an efficient
robust algorithm that achieves strong guarantees without any assumption on the
type of corruption and provides a unified framework for both classification and
regression problems. Unlike many existing approaches that quantify the quality
of the data points (e.g., based on their individual loss values), and filter
them accordingly, the proposed algorithm focuses on controlling the collective
impact of data points on the average gradient. Even when a corrupted data point
failed to be excluded by our algorithm, the data point will have a very limited
impact on the overall loss, as compared with state-of-the-art filtering methods
based on loss values. Extensive experiments on multiple benchmark datasets have
demonstrated the robustness of our algorithm under different types of
corruption.
</p>
<a href="http://arxiv.org/abs/2102.06735" target="_blank">arXiv:2102.06735</a> [<a href="http://arxiv.org/pdf/2102.06735" target="_blank">pdf</a>]

<h2>Kronecker-factored Quasi-Newton Methods for Convolutional Neural Networks. (arXiv:2102.06737v1 [cs.LG])</h2>
<h3>Yi Ren, Donald Goldfarb</h3>
<p>Second-order methods have the capability of accelerating optimization by
using much richer curvature information than first-order methods. However, most
are impractical in a deep learning setting where the number of training
parameters is huge. In this paper, we propose KF-QN-CNN, a new
Kronecker-factored quasi-Newton method for training convolutional neural
networks (CNNs), where the Hessian is approximated by a layer-wise block
diagonal matrix and each layer's diagonal block is further approximated by a
Kronecker product corresponding to the structure of the Hessian restricted to
that layer. New damping and Hessian-action techniques for BFGS are designed to
deal with the non-convexity and the particularly large size of Kronecker
matrices in CNN models and convergence results are proved for a variant of
KF-QN-CNN under relatively mild conditions. KF-QN-CNN has memory requirements
comparable to first-order methods and much less per-iteration time complexity
than traditional second-order methods. Compared with state-of-the-art first-
and second-order methods on several CNN models, KF-QN-CNN consistently
exhibited superior performance in all of our tests.
</p>
<a href="http://arxiv.org/abs/2102.06737" target="_blank">arXiv:2102.06737</a> [<a href="http://arxiv.org/pdf/2102.06737" target="_blank">pdf</a>]

<h2>Applicability of Random Matrix Theory in Deep Learning. (arXiv:2102.06740v1 [cs.LG])</h2>
<h3>Nicholas P Baskerville, Diego Granziol, Jonathan P Keating</h3>
<p>We investigate the local spectral statistics of the loss surface Hessians of
artificial neural networks, where we discover excellent agreement with Gaussian
Orthogonal Ensemble statistics across several network architectures and
datasets. These results shed new light on the applicability of Random Matrix
Theory to modelling neural networks and suggest a previously unrecognised role
for it in the study of loss surfaces in deep learning. Inspired by these
observations, we propose a novel model for the true loss surfaces of neural
networks, consistent with our observations, which allows for Hessian spectral
densities with rank degeneracy and outliers, extensively observed in practice,
and predicts a growing independence of loss gradients as a function of distance
in weight-space. We further investigate the importance of the true loss surface
in neural networks and find, in contrast to previous work, that the exponential
hardness of locating the global minimum has practical consequences for
achieving state of the art performance.
</p>
<a href="http://arxiv.org/abs/2102.06740" target="_blank">arXiv:2102.06740</a> [<a href="http://arxiv.org/pdf/2102.06740" target="_blank">pdf</a>]

<h2>Discovery of Options via Meta-Learned Subgoals. (arXiv:2102.06741v1 [cs.LG])</h2>
<h3>Vivek Veeriah, Tom Zahavy, Matteo Hessel, Zhongwen Xu, Junhyuk Oh, Iurii Kemaev, Hado van Hasselt, David Silver, Satinder Singh</h3>
<p>Temporal abstractions in the form of options have been shown to help
reinforcement learning (RL) agents learn faster. However, despite prior work on
this topic, the problem of discovering options through interaction with an
environment remains a challenge. In this paper, we introduce a novel
meta-gradient approach for discovering useful options in multi-task RL
environments. Our approach is based on a manager-worker decomposition of the RL
agent, in which a manager maximises rewards from the environment by learning a
task-dependent policy over both a set of task-independent discovered-options
and primitive actions. The option-reward and termination functions that define
a subgoal for each option are parameterised as neural networks and trained via
meta-gradients to maximise their usefulness. Empirical analysis on gridworld
and DeepMind Lab tasks show that: (1) our approach can discover meaningful and
diverse temporally-extended options in multi-task RL domains, (2) the
discovered options are frequently used by the agent while learning to solve the
training tasks, and (3) that the discovered options help a randomly initialised
manager learn faster in completely new tasks.
</p>
<a href="http://arxiv.org/abs/2102.06741" target="_blank">arXiv:2102.06741</a> [<a href="http://arxiv.org/pdf/2102.06741" target="_blank">pdf</a>]

<h2>Edge Minimizing the Student Conflict Graph. (arXiv:2102.06743v1 [cs.AI])</h2>
<h3>Joshua S. Friedman</h3>
<p>In many schools, courses are given in sections. Prior to timetabling students
need to be assigned to individual sections. We give a hybrid approximation
sectioning algorithm that minimizes the number of edges (potential conflicts)
in the student conflict graph (SCG). We start with a greedy algorithm to obtain
a starting solution and then continue with a constraint programming based
algorithm (CP-SAT) that reduces the number of edges. We apply the sectioning
algorithm to a highly constrained timetabling model which we specify.
</p>
<a href="http://arxiv.org/abs/2102.06743" target="_blank">arXiv:2102.06743</a> [<a href="http://arxiv.org/pdf/2102.06743" target="_blank">pdf</a>]

<h2>Unpacking Human Teachers' Intentions For Natural Interactive Task Learning. (arXiv:2102.06755v1 [cs.RO])</h2>
<h3>Preeti Ramaraj, Charles L. Ortiz Jr, Matthew Klenk, Shiwali Mohan</h3>
<p>Interactive Task Learning (ITL) is an emerging research agenda that studies
the design of complex intelligent robots that can acquire new knowledge through
natural human teacher-robot learner interactions. ITL methods are particularly
useful for designing intelligent robots whose behavior can be adapted by humans
collaborating with them. Various research communities are contributing methods
for ITL and a large subset of this research is robot-centered with a focus on
developing algorithms that can learn online, quickly. This paper studies the
ITL problem from a human-centered perspective to provide guidance for robot
design so that human teachers can interact with ITL robots naturally. In this
paper, we present 1) a cognitive task analysis of an interactive teaching study
(N=10) that extracts and classify various actions intended and executed by
human teachers when teaching a robot; 2) in-depth discussion of the teaching
approach employed by two participants to understand the need for personal
adaptation to individual styles; and 3) requirements for ITL robot design based
on our analyses informed by plan-based theories of dialogue, specifically
SharedPlans.
</p>
<a href="http://arxiv.org/abs/2102.06755" target="_blank">arXiv:2102.06755</a> [<a href="http://arxiv.org/pdf/2102.06755" target="_blank">pdf</a>]

<h2>Multimodal data visualization, denoising and clustering with integrated diffusion. (arXiv:2102.06757v1 [cs.LG])</h2>
<h3>Manik Kuchroo, Abhinav Godavarthi, Guy Wolf, Smita Krishnaswamy</h3>
<p>We propose a method called integrated diffusion for combining multimodal
datasets, or data gathered via several different measurements on the same
system, to create a joint data diffusion operator. As real world data suffers
from both local and global noise, we introduce mechanisms to optimally
calculate a diffusion operator that reflects the combined information from both
modalities. We show the utility of this joint operator in data denoising,
visualization and clustering, performing better than other methods to integrate
and analyze multimodal data. We apply our method to multi-omic data generated
from blood cells, measuring both gene expression and chromatin accessibility.
Our approach better visualizes the geometry of the joint data, captures known
cross-modality associations and identifies known cellular populations. More
generally, integrated diffusion is broadly applicable to multimodal datasets
generated in many medical and biological systems.
</p>
<a href="http://arxiv.org/abs/2102.06757" target="_blank">arXiv:2102.06757</a> [<a href="http://arxiv.org/pdf/2102.06757" target="_blank">pdf</a>]

<h2>Towards automatic extraction and validation of on-street parking spaces using park-out events data. (arXiv:2102.06758v1 [cs.LG])</h2>
<h3>Martin Gebert, J.-Emeterio Navarro-B</h3>
<p>This article proposes two different approaches to automatically create a map
for valid on-street car parking spaces. For this, we use park-out events data
from car2go. The first one uses spatial aggregation and the second a machine
learning algorithm. For the former, we chose rasterization and road sectioning;
for the latter we chose decision trees. We compare the results of these
approaches and discuss their advantages and disadvantages. Furthermore, we show
our results for a neighborhood in the city of Berlin and report a
classification accuracy of 92% on the original imbalanced data. Finally, we
discuss further work; from gathering more data over a longer period of time to
fitting spatial Gaussian densities to the data and the usage of apps for manual
validation and annotation of parking spaces to improve ground truth data.
</p>
<a href="http://arxiv.org/abs/2102.06758" target="_blank">arXiv:2102.06758</a> [<a href="http://arxiv.org/pdf/2102.06758" target="_blank">pdf</a>]

<h2>Stochastic Gradient Langevin Dynamics with Variance Reduction. (arXiv:2102.06759v1 [cs.LG])</h2>
<h3>Zhishen Huang, Stephen Becker</h3>
<p>Stochastic gradient Langevin dynamics (SGLD) has gained the attention of
optimization researchers due to its global optimization properties. This paper
proves an improved convergence property to local minimizers of nonconvex
objective functions using SGLD accelerated by variance reductions. Moreover, we
prove an ergodicity property of the SGLD scheme, which gives insights on its
potential to find global minimizers of nonconvex objectives.
</p>
<a href="http://arxiv.org/abs/2102.06759" target="_blank">arXiv:2102.06759</a> [<a href="http://arxiv.org/pdf/2102.06759" target="_blank">pdf</a>]

<h2>MIMIC-IF: Interpretability and Fairness Evaluation of Deep Learning Models on MIMIC-IV Dataset. (arXiv:2102.06761v1 [cs.LG])</h2>
<h3>Chuizheng Meng, Loc Trinh, Nan Xu, Yan Liu</h3>
<p>The recent release of large-scale healthcare datasets has greatly propelled
the research of data-driven deep learning models for healthcare applications.
However, due to the nature of such deep black-boxed models, concerns about
interpretability, fairness, and biases in healthcare scenarios where human
lives are at stake call for a careful and thorough examinations of both
datasets and models. In this work, we focus on MIMIC-IV (Medical Information
Mart for Intensive Care, version IV), the largest publicly available healthcare
dataset, and conduct comprehensive analyses of dataset representation bias as
well as interpretability and prediction fairness of deep learning models for
in-hospital mortality prediction. In terms of interpretabilty, we observe that
(1) the best performing interpretability method successfully identifies
critical features for mortality prediction on various prediction models; (2)
demographic features are important for prediction. In terms of fairness, we
observe that (1) there exists disparate treatment in prescribing mechanical
ventilation among patient groups across ethnicity, gender and age; (2) all of
the studied mortality predictors are generally fair while the IMV-LSTM
(Interpretable Multi-Variable Long Short-Term Memory) model provides the most
accurate and unbiased predictions across all protected groups. We further draw
concrete connections between interpretability methods and fairness metrics by
showing how feature importance from interpretability methods can be beneficial
in quantifying potential disparities in mortality predictors.
</p>
<a href="http://arxiv.org/abs/2102.06761" target="_blank">arXiv:2102.06761</a> [<a href="http://arxiv.org/pdf/2102.06761" target="_blank">pdf</a>]

<h2>Technical Challenges for Training Fair Neural Networks. (arXiv:2102.06764v1 [cs.LG])</h2>
<h3>Valeriia Cherepanova, Vedant Nanda, Micah Goldblum, John P. Dickerson, Tom Goldstein</h3>
<p>As machine learning algorithms have been widely deployed across applications,
many concerns have been raised over the fairness of their predictions,
especially in high stakes settings (such as facial recognition and medical
imaging). To respond to these concerns, the community has proposed and
formalized various notions of fairness as well as methods for rectifying unfair
behavior. While fairness constraints have been studied extensively for
classical models, the effectiveness of methods for imposing fairness on deep
neural networks is unclear. In this paper, we observe that these large models
overfit to fairness objectives, and produce a range of unintended and
undesirable consequences. We conduct our experiments on both facial recognition
and automated medical diagnosis datasets using state-of-the-art architectures.
</p>
<a href="http://arxiv.org/abs/2102.06764" target="_blank">arXiv:2102.06764</a> [<a href="http://arxiv.org/pdf/2102.06764" target="_blank">pdf</a>]

<h2>Generalizing Decision Making for Automated Driving with an Invariant Environment Representation using Deep Reinforcement Learning. (arXiv:2102.06765v1 [cs.LG])</h2>
<h3>Karl Kurzer, Philip Sch&#xf6;rner, Alexander Albers, Hauke Thomsen, Karam Daaboul, J. Marius Z&#xf6;llner</h3>
<p>Data driven approaches for decision making applied to automated driving
require appropriate generalization strategies, to ensure applicability to the
world's variability. Current approaches either do not generalize well beyond
the training data or are not capable to consider a variable number of traffic
participants. Therefore we propose an invariant environment representation from
the perspective of the ego vehicle. The representation encodes all necessary
information for safe decision making. To assess the generalization capabilities
of the novel environment representation, we train our agents on a small subset
of scenarios and evaluate on the entire set. Here we show that the agents are
capable to generalize successfully to unseen scenarios, due to the abstraction.
In addition we present a simple occlusion model that enables our agents to
navigate intersections with occlusions without a significant change in
performance.
</p>
<a href="http://arxiv.org/abs/2102.06765" target="_blank">arXiv:2102.06765</a> [<a href="http://arxiv.org/pdf/2102.06765" target="_blank">pdf</a>]

<h2>INSTA-YOLO: Real-Time Instance Segmentation. (arXiv:2102.06777v1 [cs.CV])</h2>
<h3>Eslam Mohamed, Abdelrahman Shaker, Hazem Rashed, Ahmad El-Sallab, Mayada Hadhoud</h3>
<p>Instance segmentation has gained recently huge attention in various computer
vision applications. It aims at providing different IDs to different objects of
the scene, even if they belong to the same class. Instance segmentation is
usually performed as a two-stage pipeline. First, an object is detected, then
semantic segmentation within the detected box area is performed which involves
costly up-sampling. In this paper, we propose Insta-YOLO, a novel one-stage
end-to-end deep learning model for real-time instance segmentation. Instead of
pixel-wise prediction, our model predicts instances as object contours
represented by 2D points in Cartesian space. We evaluate our model on three
datasets, namely, Carvana,Cityscapes and Airbus. We compare our results to the
state-of-the-art models for instance segmentation. The results show our model
achieves competitive accuracy in terms of mAP at twice the speed on GTX-1080
GPU.
</p>
<a href="http://arxiv.org/abs/2102.06777" target="_blank">arXiv:2102.06777</a> [<a href="http://arxiv.org/pdf/2102.06777" target="_blank">pdf</a>]

<h2>Machine Learning for Mechanical Ventilation Control. (arXiv:2102.06779v1 [cs.LG])</h2>
<h3>Daniel Suo, Udaya Ghai, Edgar Minasyan, Paula Gradu, Xinyi Chen, Naman Agarwal, Cyril Zhang, Karan Singh, Julienne LaChance, Tom Zadjel, Manuel Schottdorf, Daniel Cohen, Elad Hazan</h3>
<p>We consider the problem of controlling an invasive mechanical ventilator for
pressure-controlled ventilation: a controller must let air in and out of a
sedated patient's lungs according to a trajectory of airway pressures specified
by a clinician.

Hand-tuned PID controllers and similar variants have comprised the industry
standard for decades, yet can behave poorly by over- or under-shooting their
target or oscillating rapidly.

We consider a data-driven machine learning approach: First, we train a
simulator based on data we collect from an artificial lung. Then, we train deep
neural network controllers on these simulators.We show that our controllers are
able to track target pressure waveforms significantly better than PID
controllers.

We further show that a learned controller generalizes across lungs with
varying characteristics much more readily than PID controllers do.
</p>
<a href="http://arxiv.org/abs/2102.06779" target="_blank">arXiv:2102.06779</a> [<a href="http://arxiv.org/pdf/2102.06779" target="_blank">pdf</a>]

<h2>Q-Value Weighted Regression: Reinforcement Learning with Limited Data. (arXiv:2102.06782v1 [cs.LG])</h2>
<h3>Piotr Kozakowski, &#x141;ukasz Kaiser, Henryk Michalewski, Afroz Mohiuddin, Katarzyna Ka&#x144;ska</h3>
<p>Sample efficiency and performance in the offline setting have emerged as
significant challenges of deep reinforcement learning. We introduce Q-Value
Weighted Regression (QWR), a simple RL algorithm that excels in these aspects.
QWR is an extension of Advantage Weighted Regression (AWR), an off-policy
actor-critic algorithm that performs very well on continuous control tasks,
also in the offline setting, but has low sample efficiency and struggles with
high-dimensional observation spaces. We perform an analysis of AWR that
explains its shortcomings and use these insights to motivate QWR. We show
experimentally that QWR matches the state-of-the-art algorithms both on tasks
with continuous and discrete actions. In particular, QWR yields results on par
with SAC on the MuJoCo suite and - with the same set of hyperparameters -
yields results on par with a highly tuned Rainbow implementation on a set of
Atari games. We also verify that QWR performs well in the offline RL setting.
</p>
<a href="http://arxiv.org/abs/2102.06782" target="_blank">arXiv:2102.06782</a> [<a href="http://arxiv.org/pdf/2102.06782" target="_blank">pdf</a>]

<h2>A Unified Lottery Ticket Hypothesis for Graph Neural Networks. (arXiv:2102.06790v1 [cs.LG])</h2>
<h3>Tianlong Chen, Yongduo Sui, Xuxi Chen, Aston Zhang, Zhangyang Wang</h3>
<p>With graphs rapidly growing in size and deeper graph neural networks (GNNs)
emerging, the training and inference of GNNs become increasingly expensive.
Existing network weight pruning algorithms cannot address the main space and
computational bottleneck in GNNs, caused by the size and connectivity of the
graph. To this end, this paper first presents a unified GNN sparsification
(UGS) framework that simultaneously prunes the graph adjacency matrix and the
model weights, for effectively accelerating GNN inference on large-scale
graphs. Leveraging this new tool, we further generalize the recently popular
lottery ticket hypothesis to GNNs for the first time, by defining a graph
lottery ticket (GLT) as a pair of core sub-dataset and sparse sub-network,
which can be jointly identified from the original GNN and the full dense graph
by iteratively applying UGS. Like its counterpart in convolutional neural
networks, GLT can be trained in isolation to match the performance of training
with the full model and graph, and can be drawn from both randomly initialized
and self-supervised pre-trained GNNs. Our proposal has been experimentally
verified across various GNN architectures and diverse tasks, on both
small-scale graph datasets (Cora, Citeseer and PubMed), and large-scale
datasets from the challenging Open Graph Benchmark (OGB). Specifically, for
node classification, our found GLTs achieve the same accuracies with 20%~98%
MACs saving on small graphs and 25%~85% MACs saving on large ones. For link
prediction, GLTs lead to 48%~97% and 70% MACs saving on small and large graph
datasets, respectively, without compromising predictive performance. Codes
available at https://github.com/VITA-Group/Unified-LTH-GNN.
</p>
<a href="http://arxiv.org/abs/2102.06790" target="_blank">arXiv:2102.06790</a> [<a href="http://arxiv.org/pdf/2102.06790" target="_blank">pdf</a>]

<h2>VIPPrint: A Large Scale Dataset of Printed and Scanned Images for Synthetic Face Images Detection and Source Linking. (arXiv:2102.06792v1 [cs.CV])</h2>
<h3>Anselmo Ferreira, Ehsan Nowroozi, Mauro Barni</h3>
<p>The possibility of carrying out a meaningful forensics analysis on printed
and scanned images plays a major role in many applications. First of all,
printed documents are often associated with criminal activities, such as
terrorist plans, child pornography pictures, and even fake packages.
Additionally, printing and scanning can be used to hide the traces of image
manipulation or the synthetic nature of images, since the artifacts commonly
found in manipulated and synthetic images are gone after the images are printed
and scanned. A problem hindering research in this area is the lack of large
scale reference datasets to be used for algorithm development and benchmarking.
Motivated by this issue, we present a new dataset composed of a large number of
synthetic and natural printed face images. To highlight the difficulties
associated with the analysis of the images of the dataset, we carried out an
extensive set of experiments comparing several printer attribution methods. We
also verified that state-of-the-art methods to distinguish natural and
synthetic face images fail when applied to print and scanned images. We
envision that the availability of the new dataset and the preliminary
experiments we carried out will motivate and facilitate further research in
this area.
</p>
<a href="http://arxiv.org/abs/2102.06792" target="_blank">arXiv:2102.06792</a> [<a href="http://arxiv.org/pdf/2102.06792" target="_blank">pdf</a>]

<h2>Unanswerable Questions about Images and Texts. (arXiv:2102.06793v1 [cs.CV])</h2>
<h3>Ernest Davis</h3>
<p>Questions about a text or an image that cannot be answered raise distinctive
issues for an AI. This note discusses the problem of unanswerable questions in
VQA (visual question answering), in QA (visual question answering), and in AI
generally.
</p>
<a href="http://arxiv.org/abs/2102.06793" target="_blank">arXiv:2102.06793</a> [<a href="http://arxiv.org/pdf/2102.06793" target="_blank">pdf</a>]

<h2>A Differentiable Contact Model to Extend Lagrangian and Hamiltonian Neural Networks for Modeling Hybrid Dynamics. (arXiv:2102.06794v1 [cs.RO])</h2>
<h3>Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty</h3>
<p>The incorporation of appropriate inductive bias plays a critical role in
learning dynamics from data. A growing body of work has been exploring ways to
enforce energy conservation in the learned dynamics by incorporating Lagrangian
or Hamiltonian dynamics into the design of the neural network architecture.
However, these existing approaches are based on differential equations, which
does not allow discontinuity in the states, and thereby limits the class of
systems one can learn. Real systems, such as legged robots and robotic
manipulators, involve contacts and collisions, which introduce discontinuities
in the states. In this paper, we introduce a differentiable contact model,
which can capture contact mechanics, both frictionless and frictional, as well
as both elastic and inelastic. This model can also accommodate inequality
constraints, such as limits on the joint angles. The proposed contact model
extends the scope of Lagrangian and Hamiltonian neural networks by allowing
simultaneous learning of contact properties and system properties. We
demonstrate this framework on a series of challenging 2D and 3D physical
systems with different coefficients of restitution and friction.
</p>
<a href="http://arxiv.org/abs/2102.06794" target="_blank">arXiv:2102.06794</a> [<a href="http://arxiv.org/pdf/2102.06794" target="_blank">pdf</a>]

<h2>Reinforcement Learning For Data Poisoning on Graph Neural Networks. (arXiv:2102.06800v1 [cs.LG])</h2>
<h3>Jacob Dineen, A S M Ahsan-Ul Haque, Matthew Bielskas</h3>
<p>Adversarial Machine Learning has emerged as a substantial subfield of
Computer Science due to a lack of robustness in the models we train along with
crowdsourcing practices that enable attackers to tamper with data. In the last
two years, interest has surged in adversarial attacks on graphs yet the Graph
Classification setting remains nearly untouched. Since a Graph Classification
dataset consists of discrete graphs with class labels, related work has forgone
direct gradient optimization in favor of an indirect Reinforcement Learning
approach. We will study the novel problem of Data Poisoning (training time)
attack on Neural Networks for Graph Classification using Reinforcement Learning
Agents.
</p>
<a href="http://arxiv.org/abs/2102.06800" target="_blank">arXiv:2102.06800</a> [<a href="http://arxiv.org/pdf/2102.06800" target="_blank">pdf</a>]

<h2>Robust and Efficient Planning using Adaptive Entropy Tree Search. (arXiv:2102.06808v1 [cs.AI])</h2>
<h3>Piotr Kozakowski, Miko&#x142;aj Pacek, Piotr Mi&#x142;o&#x15b;</h3>
<p>In this paper, we present the Adaptive EntropyTree Search (ANTS) algorithm.
ANTS builds on recent successes of maximum entropy planning while mitigating
its arguably major drawback - sensitivity to the temperature setting. We endow
ANTS with a mechanism, which adapts the temperature to match a given range of
action selection entropy in the nodes of the planning tree. With this
mechanism, the ANTS planner enjoys remarkable hyper-parameter robustness,
achieves high scores on the Atari benchmark, and is a capable component of a
planning-learning loop akin to AlphaZero. We believe that all these features
make ANTS a compelling choice for a general planner for complex tasks.
</p>
<a href="http://arxiv.org/abs/2102.06808" target="_blank">arXiv:2102.06808</a> [<a href="http://arxiv.org/pdf/2102.06808" target="_blank">pdf</a>]

<h2>Understanding self-supervised Learning Dynamics without Contrastive Pairs. (arXiv:2102.06810v1 [cs.LG])</h2>
<h3>Yuandong Tian, Xinlei Chen, Surya Ganguli</h3>
<p>Contrastive approaches to self-supervised learning (SSL) learn
representations by minimizing the distance between two augmented views of the
same data point (positive pairs) and maximizing the same from different data
points (negative pairs). However, recent approaches like BYOL and SimSiam, show
remarkable performance {\it without} negative pairs, raising a fundamental
theoretical question: how can SSL with only positive pairs avoid
representational collapse? We study the nonlinear learning dynamics of
non-contrastive SSL in simple linear networks. Our analysis yields conceptual
insights into how non-contrastive SSL methods learn, how they avoid
representational collapse, and how multiple factors, like predictor networks,
stop-gradients, exponential moving averages, and weight decay all come into
play. Our simple theory recapitulates the results of real-world ablation
studies in both STL-10 and ImageNet. Furthermore, motivated by our theory we
propose a novel approach that \emph{directly} sets the predictor based on the
statistics of its inputs. In the case of linear predictors, our approach
outperforms gradient training of the predictor by $5\%$ and on ImageNet it
performs comparably with more complex two-layer non-linear predictors that
employ BatchNorm. Code is released in
https://github.com/facebookresearch/luckmatters/tree/master/ssl.
</p>
<a href="http://arxiv.org/abs/2102.06810" target="_blank">arXiv:2102.06810</a> [<a href="http://arxiv.org/pdf/2102.06810" target="_blank">pdf</a>]

<h2>Demystifying Inductive Biases for $\beta$-VAE Based Architectures. (arXiv:2102.06822v1 [cs.LG])</h2>
<h3>Dominik Zietlow, Michal Rolinek, Georg Martius</h3>
<p>The performance of $\beta$-Variational-Autoencoders ($\beta$-VAEs) and their
variants on learning semantically meaningful, disentangled representations is
unparalleled. On the other hand, there are theoretical arguments suggesting the
impossibility of unsupervised disentanglement. In this work, we shed light on
the inductive bias responsible for the success of VAE-based architectures. We
show that in classical datasets the structure of variance, induced by the
generating factors, is conveniently aligned with the latent directions fostered
by the VAE objective. This builds the pivotal bias on which the disentangling
abilities of VAEs rely. By small, elaborate perturbations of existing datasets,
we hide the convenient correlation structure that is easily exploited by a
variety of architectures. To demonstrate this, we construct modified versions
of standard datasets in which (i) the generative factors are perfectly
preserved; (ii) each image undergoes a mild transformation causing a small
change of variance; (iii) the leading \textbf{VAE-based disentanglement
architectures fail to produce disentangled representations whilst the
performance of a non-variational method remains unchanged}. The construction of
our modifications is nontrivial and relies on recent progress on mechanistic
understanding of $\beta$-VAEs and their connection to PCA. We strengthen that
connection by providing additional insights that are of stand-alone interest.
</p>
<a href="http://arxiv.org/abs/2102.06822" target="_blank">arXiv:2102.06822</a> [<a href="http://arxiv.org/pdf/2102.06822" target="_blank">pdf</a>]

<h2>Cross-domain Time Series Forecasting with Attention Sharing. (arXiv:2102.06828v1 [cs.LG])</h2>
<h3>Xiaoyong Jin, Youngsuk Park, Danielle Maddix, Bernie Wang, Xifeng Yan</h3>
<p>Recent years have witnessed deep neural net-works gaining increasing
popularity in the field oftime series forecasting. A primary reason of
theirsuccess is their ability to effectively capture com-plex temporal dynamics
across multiple relatedtime series. However, the advantages of thesedeep
forecasters only start to emerge in the pres-ence of a sufficient amount of
data. This poses achallenge for typical forecasting problems in prac-tice,
where one either has a small number of timeseries, or limited observations per
time series, orboth. To cope with the issue of data scarcity, wepropose a novel
domain adaptation framework,Domain Adaptation Forecaster (DAF), that lever-ages
the statistical strengths from another relevantdomain with abundant data
samples (source) toimprove the performance on the domain of inter-est with
limited data (target). In particular, we pro-pose an attention-based shared
module with a do-main discriminator across domains as well as pri-vate modules
for individual domains. This allowsus to jointly train the source and target
domains bygenerating domain-invariant latent features whileretraining
domain-specific features. Extensive ex-periments on various domains demonstrate
thatour proposed method outperforms state-of-the-artbaselines on synthetic and
real-world datasets.
</p>
<a href="http://arxiv.org/abs/2102.06828" target="_blank">arXiv:2102.06828</a> [<a href="http://arxiv.org/pdf/2102.06828" target="_blank">pdf</a>]

<h2>Learning Speech-driven 3D Conversational Gestures from Video. (arXiv:2102.06837v1 [cs.CV])</h2>
<h3>Ikhsanul Habibie, Weipeng Xu, Dushyant Mehta, Lingjie Liu, Hans-Peter Seidel, Gerard Pons-Moll, Mohamed Elgharib, Christian Theobalt</h3>
<p>We propose the first approach to automatically and jointly synthesize both
the synchronous 3D conversational body and hand gestures, as well as 3D face
and head animations, of a virtual character from speech input. Our algorithm
uses a CNN architecture that leverages the inherent correlation between facial
expression and hand gestures. Synthesis of conversational body gestures is a
multi-modal problem since many similar gestures can plausibly accompany the
same input speech. To synthesize plausible body gestures in this setting, we
train a Generative Adversarial Network (GAN) based model that measures the
plausibility of the generated sequences of 3D body motion when paired with the
input audio features. We also contribute a new way to create a large corpus of
more than 33 hours of annotated body, hand, and face data from in-the-wild
videos of talking people. To this end, we apply state-of-the-art monocular
approaches for 3D body and hand pose estimation as well as dense 3D face
performance capture to the video corpus. In this way, we can train on orders of
magnitude more data than previous algorithms that resort to complex in-studio
motion capture solutions, and thereby train more expressive synthesis
algorithms. Our experiments and user study show the state-of-the-art quality of
our speech-synthesized full 3D character animations.
</p>
<a href="http://arxiv.org/abs/2102.06837" target="_blank">arXiv:2102.06837</a> [<a href="http://arxiv.org/pdf/2102.06837" target="_blank">pdf</a>]

<h2>Learning Variable Impedance Control via Inverse Reinforcement Learning for Force-Related Tasks. (arXiv:2102.06838v1 [cs.RO])</h2>
<h3>Xiang Zhang, Liting Sun, Zhian Kuang, Masayoshi Tomizuka</h3>
<p>Many manipulation tasks require robots to interact with unknown environments.
In such applications, the ability to adapt the impedance according to different
task phases and environment constraints is crucial for safety and performance.
Although many approaches based on deep reinforcement learning (RL) and learning
from demonstration (LfD) have been proposed to obtain variable impedance skills
on contact-rich manipulation tasks, these skills are typically task-specific
and could be sensitive to changes in task settings. This paper proposes an
inverse reinforcement learning (IRL) based approach to recover both the
variable impedance policy and reward function from expert demonstrations. We
explore different action space of the reward functions to achieve a more
general representation of expert variable impedance skills. Experiments on two
variable impedance tasks (Peg-in-Hole and Cup-on-Plate) were conducted in both
simulations and on a real FANUC LR Mate 200iD/7L industrial robot. The
comparison results with behavior cloning and force-based IRL proved that the
learned reward function in the gain action space has better transferability
than in the force space. Experiment videos are available at
https://msc.berkeley.edu/research/impedance-irl.html.
</p>
<a href="http://arxiv.org/abs/2102.06838" target="_blank">arXiv:2102.06838</a> [<a href="http://arxiv.org/pdf/2102.06838" target="_blank">pdf</a>]

<h2>Distilling Double Descent. (arXiv:2102.06849v1 [cs.LG])</h2>
<h3>Andrew Cotter, Aditya Krishna Menon, Harikrishna Narasimhan, Ankit Singh Rawat, Sashank J. Reddi, Yichen Zhou</h3>
<p>Distillation is the technique of training a "student" model based on examples
that are labeled by a separate "teacher" model, which itself is trained on a
labeled dataset. The most common explanations for why distillation "works" are
predicated on the assumption that student is provided with \emph{soft} labels,
\eg probabilities or confidences, from the teacher model. In this work, we
show, that, even when the teacher model is highly overparameterized, and
provides \emph{hard} labels, using a very large held-out unlabeled dataset to
train the student model can result in a model that outperforms more
"traditional" approaches.

Our explanation for this phenomenon is based on recent work on "double
descent". It has been observed that, once a model's complexity roughly exceeds
the amount required to memorize the training data, increasing the complexity
\emph{further} can, counterintuitively, result in \emph{better} generalization.
Researchers have identified several settings in which it takes place, while
others have made various attempts to explain it (thus far, with only partial
success). In contrast, we avoid these questions, and instead seek to
\emph{exploit} this phenomenon by demonstrating that a highly-overparameterized
teacher can avoid overfitting via double descent, while a student trained on a
larger independent dataset labeled by this teacher will avoid overfitting due
to the size of its training set.
</p>
<a href="http://arxiv.org/abs/2102.06849" target="_blank">arXiv:2102.06849</a> [<a href="http://arxiv.org/pdf/2102.06849" target="_blank">pdf</a>]

<h2>Equilibrium Inverse Reinforcement Learning for Ride-hailing Vehicle Network. (arXiv:2102.06854v1 [cs.LG])</h2>
<h3>Takuma Oda</h3>
<p>Ubiquitous mobile computing have enabled ride-hailing services to collect
vast amounts of behavioral data of riders and drivers and optimize supply and
demand matching in real time. While these mobility service providers have some
degree of control over the market by assigning vehicles to requests, they need
to deal with the uncertainty arising from self-interested driver behavior since
workers are usually free to drive when they are not assigned tasks. In this
work, we formulate the problem of passenger-vehicle matching in a sparsely
connected graph and proposed an algorithm to derive an equilibrium policy in a
multi-agent environment. Our framework combines value iteration methods to
estimate the optimal policy given expected state visitation and policy
propagation to compute multi-agent state visitation frequencies. Furthermore,
we developed a method to learn the driver's reward function transferable to an
environment with significantly different dynamics from training data. We
evaluated the robustness to changes in spatio-temporal supply-demand
distributions and deterioration in data quality using a real-world taxi
trajectory dataset; our approach significantly outperforms several baselines in
terms of imitation accuracy. The computational time required to obtain an
equilibrium policy shared by all vehicles does not depend on the number of
agents, and even on the scale of real-world services, it takes only a few
seconds on a single CPU.
</p>
<a href="http://arxiv.org/abs/2102.06854" target="_blank">arXiv:2102.06854</a> [<a href="http://arxiv.org/pdf/2102.06854" target="_blank">pdf</a>]

<h2>On Robust Optimal Transport: Computational Complexity, Low-rank Approximation, and Barycenter Computation. (arXiv:2102.06857v1 [cs.LG])</h2>
<h3>Khang Le, Huy Nguyen, Quang Nguyen, Nhat Ho, Tung Pham, Hung Bui</h3>
<p>We consider two robust versions of optimal transport, named $\textit{Robust
Semi-constrained Optimal Transport}$ (RSOT) and $\textit{Robust Unconstrained
Optimal Transport}$ (ROT), formulated by relaxing the marginal constraints with
Kullback-Leibler divergence. For both problems in the discrete settings, we
propose Sinkhorn-based algorithms that produce $\varepsilon$-approximations of
RSOT and ROT in $\widetilde{\mathcal{O}}(\frac{n^2}{\varepsilon})$ time, where
$n$ is the number of supports of the probability distributions. Furthermore, to
reduce the dependency of the complexity of the Sinkhorn-based algorithms on
$n$, we apply Nystr\"{o}m method to approximate the kernel matrix in both RSOT
and ROT by a matrix of rank $r$ before passing it to these Sinkhorn-based
algorithms. We demonstrate that these new algorithms have
$\widetilde{\mathcal{O}}(n r^2 + \frac{nr}{\varepsilon})$ runtime to obtain the
RSOT and ROT $\varepsilon$-approximations. Finally, we consider a barycenter
problem based on RSOT, named $\textit{Robust Semi-Constrained Barycenter}$
problem (RSBP), and develop a robust iterative Bregman projection algorithm,
called $\textbf{Normalized-RobustIBP}$ algorithm, to solve the RSBP in the
discrete settings of probability distributions. We show that an
$\varepsilon$-approximated solution of the RSBP can be achieved in
$\widetilde{\mathcal{O}}(\frac{mn^2}{\varepsilon})$ time using
$\textbf{Normalized-RobustIBP}$ algorithm when $m = 2$, which is better than
the previous complexity $\widetilde{\mathcal{O}}(\frac{mn^2}{\varepsilon^2})$
of IBP algorithm for approximating the Wasserstein barycenter. Extensive
experiments confirm our theoretical results.
</p>
<a href="http://arxiv.org/abs/2102.06857" target="_blank">arXiv:2102.06857</a> [<a href="http://arxiv.org/pdf/2102.06857" target="_blank">pdf</a>]

<h2>LTL2Action: Generalizing LTL Instructions for Multi-Task RL. (arXiv:2102.06858v1 [cs.AI])</h2>
<h3>Pashootan Vaezipoor, Andrew Li, Rodrigo Toro Icarte, Sheila McIlraith</h3>
<p>We address the problem of teaching a deep reinforcement learning (RL) agent
to follow instructions in multi-task environments. We employ a well-known
formal language -- linear temporal logic (LTL) -- to specify instructions,
using a domain-specific vocabulary. We propose a novel approach to learning
that exploits the compositional syntax and the semantics of LTL, enabling our
RL agent to learn task-conditioned policies that generalize to new
instructions, not observed during training. The expressive power of LTL
supports the specification of a diversity of complex temporally extended
behaviours that include conditionals and alternative realizations. Experiments
on discrete and continuous domains demonstrate the strength of our approach in
learning to solve (unseen) tasks, given LTL instructions.
</p>
<a href="http://arxiv.org/abs/2102.06858" target="_blank">arXiv:2102.06858</a> [<a href="http://arxiv.org/pdf/2102.06858" target="_blank">pdf</a>]

<h2>Wasserstein Proximal of GANs. (arXiv:2102.06862v1 [cs.LG])</h2>
<h3>Alex Tong Lin, Wuchen Li, Stanley Osher, Guido Montufar</h3>
<p>We introduce a new method for training generative adversarial networks by
applying the Wasserstein-2 metric proximal on the generators. The approach is
based on Wasserstein information geometry. It defines a parametrization
invariant natural gradient by pulling back optimal transport structures from
probability space to parameter space. We obtain easy-to-implement iterative
regularizers for the parameter updates of implicit deep generative models. Our
experiments demonstrate that this method improves the speed and stability of
training in terms of wall-clock time and Fr\'echet Inception Distance.
</p>
<a href="http://arxiv.org/abs/2102.06862" target="_blank">arXiv:2102.06862</a> [<a href="http://arxiv.org/pdf/2102.06862" target="_blank">pdf</a>]

<h2>Adversarial Unsupervised Domain Adaptation Guided with Deep Clustering for Face Presentation Attack Detection. (arXiv:2102.06864v1 [cs.CV])</h2>
<h3>Yomna Safaa El-Din, Mohamed N. Moustafa, Hani Mahdi</h3>
<p>Face Presentation Attack Detection (PAD) has drawn increasing attentions to
secure the face recognition systems that are widely used in many applications.
Conventional face anti-spoofing methods have been proposed, assuming that
testing is from the same domain used for training, and so cannot generalize
well on unseen attack scenarios. The trained models tend to overfit to the
acquisition sensors and attack types available in the training data. In light
of this, we propose an end-to-end learning framework based on Domain Adaptation
(DA) to improve PAD generalization capability. Labeled source-domain samples
are used to train the feature extractor and classifier via cross-entropy loss,
while unsupervised data from the target domain are utilized in adversarial DA
approach causing the model to learn domain-invariant features. Using DA alone
in face PAD fails to adapt well to target domain that is acquired in different
conditions with different devices and attack types than the source domain. And
so, in order to keep the intrinsic properties of the target domain, deep
clustering of target samples is performed. Training and deep clustering are
performed end-to-end, and experiments performed on several public benchmark
datasets validate that our proposed Deep Clustering guided Unsupervised Domain
Adaptation (DCDA) can learn more generalized information compared with the
state-of-the-art classification error on the target domain.
</p>
<a href="http://arxiv.org/abs/2102.06864" target="_blank">arXiv:2102.06864</a> [<a href="http://arxiv.org/pdf/2102.06864" target="_blank">pdf</a>]

<h2>Understanding Negative Samples in Instance Discriminative Self-supervised Representation Learning. (arXiv:2102.06866v1 [cs.LG])</h2>
<h3>Kento Nozawa, Issei Sato</h3>
<p>Instance discriminative self-supervised representation learning has been
attracted attention thanks to its unsupervised nature and informative feature
representation for downstream tasks. Self-supervised representation learning
commonly uses more negative samples than the number of supervised classes in
practice. However, there is an inconsistency in the existing analysis;
theoretically, a large number of negative samples degrade supervised
performance, while empirically, they improve the performance. We theoretically
explain this empirical result regarding negative samples. We empirically
confirm our analysis by conducting numerical experiments on CIFAR-10/100
datasets.
</p>
<a href="http://arxiv.org/abs/2102.06866" target="_blank">arXiv:2102.06866</a> [<a href="http://arxiv.org/pdf/2102.06866" target="_blank">pdf</a>]

<h2>CPP-Net: Context-aware Polygon Proposal Network for Nucleus Segmentation. (arXiv:2102.06867v1 [cs.CV])</h2>
<h3>Shengcong Chen, Changxing Ding, Minfeng Liu, Dacheng Tao</h3>
<p>Nucleus segmentation is a challenging task due to the crowded distribution
and blurry boundaries of nuclei. Recent approaches represent nuclei by means of
polygons to differentiate between touching and overlapping nuclei and have
accordingly achieved promising performance. Each polygon is represented by a
set of centroid-to-boundary distances, which are in turn predicted by features
of the centroid pixel for a single nucleus. However, using the centroid pixel
alone does not provide sufficient contextual information for robust prediction.
To handle this problem, we propose a Context-aware Polygon Proposal Network
(CPP-Net) for nucleus segmentation. First, we sample a point set rather than
one single pixel within each cell for distance prediction. This strategy
substantially enhances contextual information and thereby improves the
robustness of the prediction. Second, we propose a Confidence-based Weighting
Module, which adaptively fuses the predictions from the sampled point set.
Third, we introduce a novel Shape-Aware Perceptual (SAP) loss that constrains
the shape of the predicted polygons. Here, the SAP loss is based on an
additional network that is pre-trained by means of mapping the centroid
probability map and the pixel-to-boundary distance maps to a different nucleus
representation. Extensive experiments justify the effectiveness of each
component in the proposed CPP-Net. Finally, CPP-Net is found to achieve
state-of-the-art performance on three publicly available databases, namely
DSB2018, BBBC06, and PanNuke. Code of this paper will be released.
</p>
<a href="http://arxiv.org/abs/2102.06867" target="_blank">arXiv:2102.06867</a> [<a href="http://arxiv.org/pdf/2102.06867" target="_blank">pdf</a>]

<h2>Fast, Accurate Barcode Detection in Ultra High-Resolution Images. (arXiv:2102.06868v1 [cs.CV])</h2>
<h3>Jerome Quenum, Kehan Wang, Avideh Zakhor</h3>
<p>Object detection in Ultra High-Resolution (UHR) images has long been a
challenging problem in computer vision due to the varying scales of the
targeted objects. When it comes to barcode detection, resizing UHR input images
to smaller sizes often leads to the loss of pertinent information, while
processing them directly is highly inefficient and computationally expensive.
In this paper, we propose using semantic segmentation to achieve a fast and
accurate detection of barcodes of various scales in UHR images. Our pipeline
involves a modified Region Proposal Network (RPN) on images of size greater
than 10k$\times$10k and a newly proposed Y-Net segmentation network, followed
by a post-processing workflow for fitting a bounding box around each segmented
barcode mask. The end-to-end system has a latency of 16 milliseconds, which is
$2.5\times$ faster than YOLOv4 and $5.9\times$ faster than Mask RCNN. In terms
of accuracy, our method outperforms YOLOv4 and Mask R-CNN by a $mAP$ of 5.5%
and 47.1% respectively, on a synthetic dataset. We have made available the
generated synthetic barcode dataset and its code at
this http URL
</p>
<a href="http://arxiv.org/abs/2102.06868" target="_blank">arXiv:2102.06868</a> [<a href="http://arxiv.org/pdf/2102.06868" target="_blank">pdf</a>]

<h2>Self-Reorganizing and Rejuvenating CNNs for Increasing Model Capacity Utilization. (arXiv:2102.06870v1 [cs.LG])</h2>
<h3>Wissam J. Baddar, Seungju Han, Seonmin Rhee, Jae-Joon Han</h3>
<p>In this paper, we propose self-reorganizing and rejuvenating convolutional
neural networks; a biologically inspired method for improving the computational
resource utilization of neural networks. The proposed method utilizes the
channel activations of a convolution layer in order to reorganize that layers
parameters. The reorganized parameters are clustered to avoid parameter
redundancies. As such, redundant neurons with similar activations are merged
leaving room for the remaining parameters to rejuvenate. The rejuvenated
parameters learn different features to supplement those learned by the
reorganized surviving parameters. As a result, the network capacity utilization
increases improving the baseline network performance without any changes to the
network structure. The proposed method can be applied to various network
architectures during the training stage, or applied to a pre-trained model
improving its performance. Experimental results showed that the proposed method
is model-agnostic and can be applied to any backbone architecture increasing
its performance due to the elevated utilization of the network capacity.
</p>
<a href="http://arxiv.org/abs/2102.06870" target="_blank">arXiv:2102.06870</a> [<a href="http://arxiv.org/pdf/2102.06870" target="_blank">pdf</a>]

<h2>Improved Corruption Robust Algorithms for Episodic Reinforcement Learning. (arXiv:2102.06875v1 [cs.LG])</h2>
<h3>Yifang Chen, Simon S. Du, Kevin Jamieson</h3>
<p>We study episodic reinforcement learning under unknown adversarial
corruptions in both the rewards and the transition probabilities of the
underlying system. We propose new algorithms which, compared to the existing
results in (Lykouris et al., 2020), achieve strictly better regret bounds in
terms of total corruptions for the tabular setting. To be specific, firstly,
our regret bounds depend on more precise numerical values of total rewards
corruptions and transition corruptions, instead of only on the total number of
corrupted episodes. Secondly, our regret bounds are the first of their kind in
the reinforcement learning setting to have the number of corruptions show up
additively with respect to $\sqrt{T}$ rather than multiplicatively. Our results
follow from a general algorithmic framework that combines corruption-robust
policy elimination meta-algorithms, and plug-in reward-free exploration
sub-algorithms. Replacing the meta-algorithm or sub-algorithm may extend the
framework to address other corrupted settings with potentially more structure.
</p>
<a href="http://arxiv.org/abs/2102.06875" target="_blank">arXiv:2102.06875</a> [<a href="http://arxiv.org/pdf/2102.06875" target="_blank">pdf</a>]

<h2>Learning from Similarity-Confidence Data. (arXiv:2102.06879v1 [stat.ML])</h2>
<h3>Yuzhou Cao, Lei Feng, Yitian Xu, Bo An, Gang Niu, Masashi Sugiyama</h3>
<p>Weakly supervised learning has drawn considerable attention recently to
reduce the expensive time and labor consumption of labeling massive data. In
this paper, we investigate a novel weakly supervised learning problem of
learning from similarity-confidence (Sconf) data, where we aim to learn an
effective binary classifier from only unlabeled data pairs equipped with
confidence that illustrates their degree of similarity (two examples are
similar if they belong to the same class). To solve this problem, we propose an
unbiased estimator of the classification risk that can be calculated from only
Sconf data and show that the estimation error bound achieves the optimal
convergence rate. To alleviate potential overfitting when flexible models are
used, we further employ a risk correction scheme on the proposed risk
estimator. Experimental results demonstrate the effectiveness of the proposed
methods.
</p>
<a href="http://arxiv.org/abs/2102.06879" target="_blank">arXiv:2102.06879</a> [<a href="http://arxiv.org/pdf/2102.06879" target="_blank">pdf</a>]

<h2>Saliency-Aware Class-Agnostic Food Image Segmentation. (arXiv:2102.06882v1 [cs.CV])</h2>
<h3>Sri Kalyan Yarlagadda, Daniel Mas Montserrat, David Guerra, Carol J. Boushey, Deborah A. Kerr, Fengqing Zhu</h3>
<p>Advances in image-based dietary assessment methods have allowed nutrition
professionals and researchers to improve the accuracy of dietary assessment,
where images of food consumed are captured using smartphones or wearable
devices. These images are then analyzed using computer vision methods to
estimate energy and nutrition content of the foods. Food image segmentation,
which determines the regions in an image where foods are located, plays an
important role in this process. Current methods are data dependent, thus cannot
generalize well for different food types. To address this problem, we propose a
class-agnostic food image segmentation method. Our method uses a pair of eating
scene images, one before start eating and one after eating is completed. Using
information from both the before and after eating images, we can segment food
images by finding the salient missing objects without any prior information
about the food class. We model a paradigm of top down saliency which guides the
attention of the human visual system (HVS) based on a task to find the salient
missing objects in a pair of images. Our method is validated on food images
collected from a dietary study which showed promising results.
</p>
<a href="http://arxiv.org/abs/2102.06882" target="_blank">arXiv:2102.06882</a> [<a href="http://arxiv.org/pdf/2102.06882" target="_blank">pdf</a>]

<h2>Segmenting two-dimensional structures with strided tensor networks. (arXiv:2102.06900v1 [cs.CV])</h2>
<h3>Raghavendra Selvan, Erik B Dam, Jens Petersen</h3>
<p>Tensor networks provide an efficient approximation of operations involving
high dimensional tensors and have been extensively used in modelling quantum
many-body systems. More recently, supervised learning has been attempted with
tensor networks, primarily focused on tasks such as image classification. In
this work, we propose a novel formulation of tensor networks for supervised
image segmentation which allows them to operate on high resolution medical
images. We use the matrix product state (MPS) tensor network on non-overlapping
patches of a given input image to predict the segmentation mask by learning a
pixel-wise linear classification rule in a high dimensional space. The proposed
model is end-to-end trainable using backpropagation. It is implemented as a
Strided Tensor Network to reduce the parameter complexity. The performance of
the proposed method is evaluated on two public medical imaging datasets and
compared to relevant baselines. The evaluation shows that the strided tensor
network yields competitive performance compared to CNN-based models while using
fewer resources. Additionally, based on the experiments we discuss the
feasibility of using fully linear models for segmentation tasks.
</p>
<a href="http://arxiv.org/abs/2102.06900" target="_blank">arXiv:2102.06900</a> [<a href="http://arxiv.org/pdf/2102.06900" target="_blank">pdf</a>]

<h2>Online Apprenticeship Learning. (arXiv:2102.06924v1 [cs.LG])</h2>
<h3>Lior Shani, Tom Zahavy, Shie Mannor</h3>
<p>In Apprenticeship Learning (AL), we are given a Markov Decision Process (MDP)
without access to the cost function. Instead, we observe trajectories sampled
by an expert that acts according to some policy. The goal is to find a policy
that matches the expert's performance on some predefined set of cost functions.
We introduce an online variant of AL (Online Apprenticeship Learning; OAL),
where the agent is expected to perform comparably to the expert while
interacting with the environment. We show that the OAL problem can be
effectively solved by combining two mirror descent based no-regret algorithms:
one for policy optimization and another for learning the worst case cost. To
this end, we derive a convergent algorithm with $O(\sqrt{K})$ regret, where $K$
is the number of interactions with the MDP, and an additional linear error term
that depends on the amount of expert trajectories available. Importantly, our
algorithm avoids the need to solve an MDP at each iteration, making it more
practical compared to prior AL methods. Finally, we implement a deep variant of
our algorithm which shares some similarities to GAIL \cite{ho2016generative},
but where the discriminator is replaced with the costs learned by the OAL
problem. Our simulations demonstrate our theoretically grounded approach
outperforms the baselines.
</p>
<a href="http://arxiv.org/abs/2102.06924" target="_blank">arXiv:2102.06924</a> [<a href="http://arxiv.org/pdf/2102.06924" target="_blank">pdf</a>]

<h2>Hybrid Artificial Intelligence Methods for Predicting Air Demand in Dam Bottom Outlet. (arXiv:2102.06929v1 [cs.LG])</h2>
<h3>Aliakbar Narimani, Mahdi Moghimi, Amir Mosavi</h3>
<p>In large infrastructures such as dams, which have a relatively high economic
value, ensuring the proper operation of the associated hydraulic facilities in
different operating conditions is of utmost importance. To ensure the correct
and successful operation of the dam's hydraulic equipment and prevent possible
damages, including gates and downstream tunnel, to build laboratory models and
perform some tests are essential (the advancement of the smart sensors based on
artificial intelligence is essential). One of the causes of damage to dam
bottom outlets is cavitation in downstream and between the gates, which can
impact on dam facilities, and air aeration can be a solution to improve it. In
the present study, six dams in different provinces in Iran has been chosen to
evaluate the air entrainment in the downstream tunnel experimentally. Three
artificial neural networks (ANN) based machine learning (ML) algorithms are
used to model and predict the air aeration in the bottom outlet. The proposed
models are trained with genetic algorithms (GA), particle swarm optimization
(PSO), i.e., ANN-GA, ANN-PSO, and ANFIS-PSO. Two hydrodynamic variables, namely
volume rate and opening percentage of the gate, are used as inputs into all
bottom outlet models. The results showed that the most optimal model is
ANFIS-PSO to predict the dependent value compared with ANN-GA and ANN-PSO. The
importance of the volume rate and opening percentage of the dams' gate
parameters is more effective for suitable air aeration.
</p>
<a href="http://arxiv.org/abs/2102.06929" target="_blank">arXiv:2102.06929</a> [<a href="http://arxiv.org/pdf/2102.06929" target="_blank">pdf</a>]

<h2>Revisiting Smoothed Online Learning. (arXiv:2102.06933v1 [cs.LG])</h2>
<h3>Lijun Zhang, Wei Jiang, Shiyin Lu, Tianbao Yang</h3>
<p>In this paper, we revisit the problem of smoothed online learning, in which
the online learner suffers both a hitting cost and a switching cost, and target
two performance metrics: competitive ratio and dynamic regret with switching
cost. To bound the competitive ratio, we assume the hitting cost is known to
the learner in each round, and investigate the greedy algorithm which simply
minimizes the weighted sum of the hitting cost and the switching cost. Our
theoretical analysis shows that the greedy algorithm, although straightforward,
is $1+ \frac{2}{\alpha}$-competitive for $\alpha$-polyhedral functions,
$1+O(\frac{1}{\lambda})$-competitive for $\lambda$-quadratic growth functions,
and $1 + \frac{2}{\sqrt{\lambda}}$-competitive for convex and
$\lambda$-quadratic growth functions. To bound the dynamic regret with
switching cost, we follow the standard setting of online convex optimization,
in which the hitting cost is convex but hidden from the learner before making
predictions. We modify Ader, an existing algorithm designed for dynamic regret,
slightly to take into account the switching cost when measuring the
performance. The proposed algorithm, named as Smoothed Ader, attains an optimal
$O(\sqrt{T(1+P_T)})$ bound for dynamic regret with switching cost, where $P_T$
is the path-length of the comparator sequence. Furthermore, if the hitting cost
is accessible in the beginning of each round, we obtain a similar guarantee
without the bounded gradient condition.
</p>
<a href="http://arxiv.org/abs/2102.06933" target="_blank">arXiv:2102.06933</a> [<a href="http://arxiv.org/pdf/2102.06933" target="_blank">pdf</a>]

<h2>Rotation-Equivariant Deep Learning for Diffusion MRI. (arXiv:2102.06942v1 [cs.CV])</h2>
<h3>Philip M&#xfc;ller, Vladimir Golkov, Valentina Tomassini, Daniel Cremers</h3>
<p>Convolutional networks are successful, but they have recently been
outperformed by new neural networks that are equivariant under rotations and
translations. These new networks work better because they do not struggle with
learning each possible orientation of each image feature separately. So far,
they have been proposed for 2D and 3D data. Here we generalize them to 6D
diffusion MRI data, ensuring joint equivariance under 3D roto-translations in
image space and the matching 3D rotations in $q$-space, as dictated by the
image formation. Such equivariant deep learning is appropriate for diffusion
MRI, because microstructural and macrostructural features such as neural fibers
can appear at many different orientations, and because even
non-rotation-equivariant deep learning has so far been the best method for many
diffusion MRI tasks. We validate our equivariant method on multiple-sclerosis
lesion segmentation. Our proposed neural networks yield better results and
require fewer scans for training compared to non-rotation-equivariant deep
learning. They also inherit all the advantages of deep learning over classical
diffusion MRI methods. Our implementation is available at
https://github.com/philip-mueller/equivariant-deep-dmri and can be used off the
shelf without understanding the mathematical background.
</p>
<a href="http://arxiv.org/abs/2102.06942" target="_blank">arXiv:2102.06942</a> [<a href="http://arxiv.org/pdf/2102.06942" target="_blank">pdf</a>]

<h2>Goods Transportation Problem Solving via Routing Algorithm. (arXiv:2102.06943v1 [cs.AI])</h2>
<h3>Mikhail Shchukin, Aymen Ben Said, Andre Lobo Teixeira</h3>
<p>This paper outlines the ideas behind developing a graph-based
heuristic-driven routing algorithm designed for a particular instance of a
goods transportation problem with a single good type. The proposed algorithm
solves the optimization problem of satisfying the demand of goods on a given
undirected transportation graph with minimizing the estimated cost for each
traversed segment of the delivery path. The operation of the routing algorithm
is discussed and overall evaluation of the proposed problem solving technique
is given.
</p>
<a href="http://arxiv.org/abs/2102.06943" target="_blank">arXiv:2102.06943</a> [<a href="http://arxiv.org/pdf/2102.06943" target="_blank">pdf</a>]

<h2>Multi-class Generative Adversarial Nets for Semi-supervised Image Classification. (arXiv:2102.06944v1 [cs.CV])</h2>
<h3>Saman Motamed, Farzad Khalvati</h3>
<p>From generating never-before-seen images to domain adaptation, applications
of Generative Adversarial Networks (GANs) spread wide in the domain of vision
and graphics problems. With the remarkable ability of GANs in learning the
distribution and generating images of a particular class, they can be used for
semi-supervised classification tasks. However, the problem is that if two
classes of images share similar characteristics, the GAN might learn to
generalize and hinder the classification of the two classes. In this paper, we
use various images from MNIST and Fashion-MNIST datasets to illustrate how
similar images cause the GAN to generalize, leading to the poor classification
of images. We propose a modification to the traditional training of GANs that
allows for improved multi-class classification in similar classes of images in
a semi-supervised learning framework.
</p>
<a href="http://arxiv.org/abs/2102.06944" target="_blank">arXiv:2102.06944</a> [<a href="http://arxiv.org/pdf/2102.06944" target="_blank">pdf</a>]

<h2>Sequential Recommendation in Online Games with Multiple Sequences, Tasks and User Levels. (arXiv:2102.06950v1 [cs.AI])</h2>
<h3>Si Chen, Yuqiu Qian, Hui Li, Chen Lin</h3>
<p>Online gaming is a multi-billion-dollar industry, which is growing faster
than ever before. Recommender systems (RS) for online games face unique
challenges since they must fulfill players' distinct desires, at different user
levels, based on their action sequences of various action types. Although many
sequential RS already exist, they are mainly single-sequence, single-task, and
single-user-level. In this paper, we introduce a new sequential recommendation
model for multiple sequences, multiple tasks, and multiple user levels
(abbreviated as M$^3$Rec) in Tencent Games platform, which can fully utilize
complex data in online games. We leverage Graph Neural Network and multi-task
learning to design M$^3$Rec in order to model the complex information in the
heterogeneous sequential recommendation scenario of Tencent Games. We verify
the effectiveness of M$^3$Rec on three online games of Tencent Games platform,
in both offline and online evaluations. The results show that M$^3$Rec
successfully addresses the challenges of recommendation in online games, and it
generates superior recommendations compared with state-of-the-art sequential
recommendation approaches.
</p>
<a href="http://arxiv.org/abs/2102.06950" target="_blank">arXiv:2102.06950</a> [<a href="http://arxiv.org/pdf/2102.06950" target="_blank">pdf</a>]

<h2>Improving Automated Visual Fault Detection by Combining a Biologically Plausible Model of Visual Attention with Deep Learning. (arXiv:2102.06955v1 [cs.CV])</h2>
<h3>Frederik Beuth, Tobias Schlosser, Michael Friedrich, Danny Kowerko</h3>
<p>It is a long-term goal to transfer biological processing principles as well
as the power of human recognition into machine vision and engineering systems.
One of such principles is visual attention, a smart human concept which focuses
processing on a part of a scene. In this contribution, we utilize attention to
improve the automatic detection of defect patterns for wafers within the domain
of semiconductor manufacturing. Previous works in the domain have often
utilized classical machine learning approaches such as KNNs, SVMs, or MLPs,
while a few have already used modern approaches like deep neural networks
(DNNs). However, one problem in the domain is that the faults are often very
small and have to be detected within a larger size of the chip or even the
wafer. Therefore, small structures in the size of pixels have to be detected in
a vast amount of image data. One interesting principle of the human brain for
solving this problem is visual attention. Hence, we employ here a biologically
plausible model of visual attention for automatic visual inspection. We propose
a hybrid system of visual attention and a deep neural network. As demonstrated,
our system achieves among other decisive advantages an improvement in accuracy
from 81% to 92%, and an increase in accuracy for detecting faults from 67% to
88%. Hence, the error rates are reduced from 19% to 8%, and notably from 33% to
12% for detecting a fault in a chip. These results show that attention can
greatly improve the performance of visual inspection systems. Furthermore, we
conduct a broad evaluation, identifying specific advantages of the biological
attention model in this application, and benchmarks standard deep learning
approaches as an alternative with and without attention.

This work is an extended arXiv version of the original conference article
published in "IECON 2020", which has been extended regarding visual attention.
</p>
<a href="http://arxiv.org/abs/2102.06955" target="_blank">arXiv:2102.06955</a> [<a href="http://arxiv.org/pdf/2102.06955" target="_blank">pdf</a>]

<h2>CrossLight: A Cross-Layer Optimized Silicon Photonic Neural Network Accelerator. (arXiv:2102.06960v1 [cs.LG])</h2>
<h3>Febin Sunny, Asif Mirza, Mahdi Nikdast, Sudeep Pasricha</h3>
<p>Domain-specific neural network accelerators have seen growing interest in
recent years due to their improved energy efficiency and inference performance
compared to CPUs and GPUs. In this paper, we propose a novel cross-layer
optimized neural network accelerator called CrossLight that leverages silicon
photonics. CrossLight includes device-level engineering for resilience to
process variations and thermal crosstalk, circuit-level tuning enhancements for
inference latency reduction, and architecture-level optimization to enable
higher resolution, better energy-efficiency, and improved throughput. On
average, CrossLight offers 9.5x lower energy-per-bit and 15.9x higher
performance-per-watt at 16-bit resolution than state-of-the-art photonic deep
learning accelerators.
</p>
<a href="http://arxiv.org/abs/2102.06960" target="_blank">arXiv:2102.06960</a> [<a href="http://arxiv.org/pdf/2102.06960" target="_blank">pdf</a>]

<h2>PerSim: Data-Efficient Offline Reinforcement Learning with Heterogeneous Agents via Personalized Simulators. (arXiv:2102.06961v1 [cs.LG])</h2>
<h3>Anish Agarwal, Abdullah Alomar, Varkey Alumootil, Devavrat Shah, Dennis Shen, Zhi Xu, Cindy Yang</h3>
<p>We consider offline reinforcement learning (RL) with heterogeneous agents
under severe data scarcity, i.e., we only observe a single historical
trajectory for every agent under an unknown, potentially sub-optimal policy. We
find that the performance of state-of-the-art offline and model-based RL
methods degrade significantly given such limited data availability, even for
commonly perceived "solved" benchmark settings such as "MountainCar" and
"CartPole". To address this challenge, we propose a model-based offline RL
approach, called PerSim, where we first learn a personalized simulator for each
agent by collectively using the historical trajectories across all agents prior
to learning a policy. We do so by positing that the transition dynamics across
agents can be represented as a latent function of latent factors associated
with agents, states, and actions; subsequently, we theoretically establish that
this function is well-approximated by a "low-rank" decomposition of separable
agent, state, and action latent functions. This representation suggests a
simple, regularized neural network architecture to effectively learn the
transition dynamics per agent, even with scarce, offline data.We perform
extensive experiments across several benchmark environments and RL methods. The
consistent improvement of our approach, measured in terms of state dynamics
prediction and eventual reward, confirms the efficacy of our framework in
leveraging limited historical data to simultaneously learn personalized
policies across agents.
</p>
<a href="http://arxiv.org/abs/2102.06961" target="_blank">arXiv:2102.06961</a> [<a href="http://arxiv.org/pdf/2102.06961" target="_blank">pdf</a>]

<h2>Graph Convolution for Semi-Supervised Classification: Improved Linear Separability and Out-of-Distribution Generalization. (arXiv:2102.06966v1 [cs.LG])</h2>
<h3>Aseem Baranwal, Kimon Fountoulakis, Aukosh Jagannath</h3>
<p>Recently there has been increased interest in semi-supervised classification
in the presence of graphical information. A new class of learning models has
emerged that relies, at its most basic level, on classifying the data after
first applying a graph convolution. To understand the merits of this approach,
we study the classification of a mixture of Gaussians, where the data
corresponds to the node attributes of a stochastic block model. We show that
graph convolution extends the regime in which the data is linearly separable by
a factor of roughly $1/\sqrt{D}$, where $D$ is the expected degree of a node,
as compared to the mixture model data on its own. Furthermore, we find that the
linear classifier obtained by minimizing the cross-entropy loss after the graph
convolution generalizes to out-of-distribution data where the unseen data can
have different intra- and inter-class edge probabilities from the training
data.
</p>
<a href="http://arxiv.org/abs/2102.06966" target="_blank">arXiv:2102.06966</a> [<a href="http://arxiv.org/pdf/2102.06966" target="_blank">pdf</a>]

<h2>Discrete Cosine Transform in JPEG Compression. (arXiv:2102.06968v1 [cs.CV])</h2>
<h3>Jacob John</h3>
<p>Image Compression has become an absolute necessity in today's day and age.
With the advent of the Internet era, compressing files to share among other
users is quintessential. Several efforts have been made to reduce file sizes
while still maintain image quality in order to transmit files even on limited
bandwidth connections. This paper discusses the need for Discrete Cosine
Transform or DCT in the compression of images in Joint Photographic Experts
Group or JPEG file format. Via an intensive literature study, this paper first
introduces DCT and JPEG Compression. The section preceding it discusses how
JPEG compression is implemented by DCT. The last section concludes with further
real world applications of DCT in image processing.
</p>
<a href="http://arxiv.org/abs/2102.06968" target="_blank">arXiv:2102.06968</a> [<a href="http://arxiv.org/pdf/2102.06968" target="_blank">pdf</a>]

<h2>Normalized Convolution Upsampling for Refined Optical Flow Estimation. (arXiv:2102.06979v1 [cs.CV])</h2>
<h3>Abdelrahman Eldesokey, Michael Felsberg</h3>
<p>Optical flow is a regression task where convolutional neural networks (CNNs)
have led to major breakthroughs. However, this comes at major computational
demands due to the use of cost-volumes and pyramidal representations. This was
mitigated by producing flow predictions at quarter the resolution, which are
upsampled using bilinear interpolation during test time. Consequently, fine
details are usually lost and post-processing is needed to restore them. We
propose the Normalized Convolution UPsampler (NCUP), an efficient joint
upsampling approach to produce the full-resolution flow during the training of
optical flow CNNs. Our proposed approach formulates the upsampling task as a
sparse problem and employs the normalized convolutional neural networks to
solve it. We evaluate our upsampler against existing joint upsampling
approaches when trained end-to-end with a a coarse-to-fine optical flow CNN
(PWCNet) and we show that it outperforms all other approaches on the
FlyingChairs dataset while having at least one order fewer parameters.
Moreover, we test our upsampler with a recurrent optical flow CNN (RAFT) and we
achieve state-of-the-art results on Sintel benchmark with ~6% error reduction,
and on-par on the KITTI dataset, while having 7.5% fewer parameters (see Figure
1). Finally, our upsampler shows better generalization capabilities than RAFT
when trained and evaluated on different datasets.
</p>
<a href="http://arxiv.org/abs/2102.06979" target="_blank">arXiv:2102.06979</a> [<a href="http://arxiv.org/pdf/2102.06979" target="_blank">pdf</a>]

<h2>DeepRA: Predicting Joint Damage From Radiographs Using CNN with Attention. (arXiv:2102.06982v1 [cs.CV])</h2>
<h3>Neelambuj Chaturvedi</h3>
<p>Joint damage in Rheumatoid Arthritis (RA) is assessed by manually inspecting
and grading radiographs of hands and feet. This is a tedious task which
requires trained experts whose subjective assessment leads to low inter-rater
agreement. An algorithm which can automatically predict the joint level damage
in hands and feet can help optimize this process, which will eventually aid the
doctors in better patient care and research. In this paper, we propose a
two-staged approach which amalgamates object detection and convolution neural
networks with attention which can efficiently and accurately predict the
overall and joint level narrowing and erosion from patients radiographs. This
approach has been evaluated on hands and feet radiographs of patients suffering
from RA and has achieved a weighted root mean squared error (RMSE) of 1.358 and
1.404 in predicting joint level narrowing and erosion Sharp van der Heijde
(SvH) scores which is 31% and 19% improvement with respect to the baseline SvH
scores, respectively. The proposed approach achieved a weighted absolute error
of 1.456 in predicting the overall damage in hands and feet radiographs for the
patients which is a 79% improvement as compared to the baseline. Our method
also provides an inherent capability to provide explanations for model
predictions using attention weights, which is essential given the black box
nature of deep learning models. The proposed approach was developed during the
RA2 Dream Challenge hosted by Dream Challenges and secured 4th and 8th position
in predicting overall and joint level narrowing and erosion SvH scores from
radiographs.
</p>
<a href="http://arxiv.org/abs/2102.06982" target="_blank">arXiv:2102.06982</a> [<a href="http://arxiv.org/pdf/2102.06982" target="_blank">pdf</a>]

<h2>How Framelets Enhance Graph Neural Networks. (arXiv:2102.06986v1 [cs.LG])</h2>
<h3>Xuebin Zheng, Bingxin Zhou, Junbin Gao, Yu Guang Wang, Pietro Lio, Ming Li, Guido Montufar</h3>
<p>This paper presents a new approach for assembling graph neural networks based
on framelet transforms. The latter provides a multi-scale representation for
graph-structured data. With the framelet system, we can decompose the graph
feature into low-pass and high-pass frequencies as extracted features for
network training, which then defines a framelet-based graph convolution. The
framelet decomposition naturally induces a graph pooling strategy by
aggregating the graph feature into low-pass and high-pass spectra, which
considers both the feature values and geometry of the graph data and conserves
the total information. The graph neural networks with the proposed framelet
convolution and pooling achieve state-of-the-art performance in many types of
node and graph prediction tasks. Moreover, we propose shrinkage as a new
activation for the framelet convolution, which thresholds the high-frequency
information at different scales. Compared to ReLU, shrinkage in framelet
convolution improves the graph neural network model in terms of denoising and
signal compression: noises in both node and structure can be significantly
reduced by accurately cutting off the high-pass coefficients from framelet
decomposition, and the signal can be compressed to less than half its original
size with the prediction performance well preserved.
</p>
<a href="http://arxiv.org/abs/2102.06986" target="_blank">arXiv:2102.06986</a> [<a href="http://arxiv.org/pdf/2102.06986" target="_blank">pdf</a>]

<h2>A Novel Bio-Inspired Texture Descriptor based on Biodiversity and Taxonomic Measures. (arXiv:2102.06997v1 [cs.CV])</h2>
<h3>Steve Tsham Mpinda Ataky, Alessandro Lameiras Koerich</h3>
<p>Texture can be defined as the change of image intensity that forms repetitive
patterns, resulting from physical properties of the object's roughness or
differences in a reflection on the surface. Considering that texture forms a
complex system of patterns in a non-deterministic way, biodiversity concepts
can help to its characterization. In this paper, we propose a novel approach
capable of quantifying such a complex system of diverse patterns through
species diversity and richness, and taxonomic distinctiveness. The proposed
approach considers each image channel as a species ecosystem and computes
species diversity and richness measures as well as taxonomic measures to
describe the texture. The proposed approach takes advantage of the invariance
characteristics of ecological patterns to build a permutation, rotation, and
translation invariant descriptor. Experimental results on three datasets of
natural texture images and two datasets of histopathological images have shown
that the proposed texture descriptor has advantages over several texture
descriptors and deep methods.
</p>
<a href="http://arxiv.org/abs/2102.06997" target="_blank">arXiv:2102.06997</a> [<a href="http://arxiv.org/pdf/2102.06997" target="_blank">pdf</a>]

<h2>On the Last Iterate Convergence of Momentum Methods. (arXiv:2102.07002v1 [cs.LG])</h2>
<h3>Xiaoyu Li, Mingrui Liu, Francesco Orabona</h3>
<p>SGD with Momentum (SGDM) is widely used for large scale optimization of
machine learning problems. Yet, the theoretical understanding of this algorithm
is not complete. In fact, even the most recent results require changes to the
algorithm like an averaging scheme and a projection onto a bounded domain,
which are never used in practice. Also, no lower bound is known for SGDM. In
this paper, we prove for the first time that for any constant momentum factor,
there exists a Lipschitz and convex function for which the last iterate of SGDM
suffers from an error $\Omega(\frac{\log T}{\sqrt{T}})$ after $T$ steps. Based
on this fact, we study a new class of (both adaptive and non-adaptive)
Follow-The-Regularized-Leader-based SGDM algorithms with \emph{increasing
momentum} and \emph{shrinking updates}. For these algorithms, we show that the
last iterate has optimal convergence $O (\frac{1}{\sqrt{T}})$ for unconstrained
convex optimization problems. Further, we show that in the interpolation
setting with convex and smooth functions, our new SGDM algorithm automatically
converges at a rate of $O(\frac{\log T}{T})$. Empirical results are shown as
well.
</p>
<a href="http://arxiv.org/abs/2102.07002" target="_blank">arXiv:2102.07002</a> [<a href="http://arxiv.org/pdf/2102.07002" target="_blank">pdf</a>]

<h2>On the convergence of group-sparse autoencoders. (arXiv:2102.07003v1 [cs.LG])</h2>
<h3>Emmanouil Theodosis, Bahareh Tolooshams, Pranay Tankala, Abiy Tasissa, Demba Ba</h3>
<p>Recent approaches in the theoretical analysis of model-based deep learning
architectures have studied the convergence of gradient descent in shallow ReLU
networks that arise from generative models whose hidden layers are sparse.
Motivated by the success of architectures that impose structured forms of
sparsity, we introduce and study a group-sparse autoencoder that accounts for a
variety of generative models, and utilizes a group-sparse ReLU activation
function to force the non-zero units at a given layer to occur in blocks. For
clustering models, inputs that result in the same group of active units belong
to the same cluster. We proceed to analyze the gradient dynamics of a shallow
instance of the proposed autoencoder, trained with data adhering to a
group-sparse generative model. In this setting, we theoretically prove the
convergence of the network parameters to a neighborhood of the generating
matrix. We validate our model through numerical analysis and highlight the
superior performance of networks with a group-sparse ReLU compared to networks
that utilize traditional ReLUs, both in sparse coding and in parameter recovery
tasks. We also provide real data experiments to corroborate the simulated
results, and emphasize the clustering capabilities of structured sparsity
models.
</p>
<a href="http://arxiv.org/abs/2102.07003" target="_blank">arXiv:2102.07003</a> [<a href="http://arxiv.org/pdf/2102.07003" target="_blank">pdf</a>]

<h2>Weight Initialization Techniques for Deep Learning Algorithms in Remote Sensing: Recent Trends and Future Perspectives. (arXiv:2102.07004v1 [cs.LG])</h2>
<h3>Wadii Boulila, Maha Driss, Mohamed Al-Sarem, Faisal Saeed, Moez Krichen</h3>
<p>During the last decade, several research works have focused on providing
novel deep learning methods in many application fields. However, few of them
have investigated the weight initialization process for deep learning, although
its importance is revealed in improving deep learning performance. This can be
justified by the technical difficulties in proposing new techniques for this
promising research field. In this paper, a survey related to weight
initialization techniques for deep algorithms in remote sensing is conducted.
This survey will help practitioners to drive further research in this promising
field. To the best of our knowledge, this paper constitutes the first survey
focusing on weight initialization for deep learning models.
</p>
<a href="http://arxiv.org/abs/2102.07004" target="_blank">arXiv:2102.07004</a> [<a href="http://arxiv.org/pdf/2102.07004" target="_blank">pdf</a>]

<h2>Clustering Left-Censored Multivariate Time-Series. (arXiv:2102.07005v1 [stat.ML])</h2>
<h3>Irene Y. Chen, Rahul G. Krishnan, David Sontag</h3>
<p>Unsupervised learning seeks to uncover patterns in data. However, different
kinds of noise may impede the discovery of useful substructure from real-world
time-series data. In this work, we focus on mitigating the interference of
left-censorship in the task of clustering. We provide conditions under which
clusters and left-censorship may be identified; motivated by this result, we
develop a deep generative, continuous-time model of time-series data that
clusters while correcting for censorship time. We demonstrate accurate, stable,
and interpretable results on synthetic data that outperform several benchmarks.
To showcase the utility of our framework on real-world problems, we study how
left-censorship can adversely affect the task of disease phenotyping, resulting
in the often incorrect assumption that longitudinal patient data are aligned by
disease stage. In reality, patients at the time of diagnosis are at different
stages of the disease -- both late and early due to differences in when
patients seek medical care and such discrepancy can confound unsupervised
learning algorithms. On two clinical datasets, our model corrects for this form
of censorship and recovers known clinical subtypes.
</p>
<a href="http://arxiv.org/abs/2102.07005" target="_blank">arXiv:2102.07005</a> [<a href="http://arxiv.org/pdf/2102.07005" target="_blank">pdf</a>]

<h2>Asymmetric Heavy Tails and Implicit Bias in Gaussian Noise Injections. (arXiv:2102.07006v1 [stat.ML])</h2>
<h3>Alexander Camuto, Xiaoyu Wang, Lingjiong Zhu, Chris Holmes, Mert G&#xfc;rb&#xfc;zbalaban, Umut &#x15e;im&#x15f;ekli</h3>
<p>Gaussian noise injections (GNIs) are a family of simple and widely-used
regularisation methods for training neural networks, where one injects additive
or multiplicative Gaussian noise to the network activations at every iteration
of the optimisation algorithm, which is typically chosen as stochastic gradient
descent (SGD). In this paper we focus on the so-called `implicit effect' of
GNIs, which is the effect of the injected noise on the dynamics of SGD. We show
that this effect induces an asymmetric heavy-tailed noise on SGD gradient
updates. In order to model this modified dynamics, we first develop a
Langevin-like stochastic differential equation that is driven by a general
family of asymmetric heavy-tailed noise. Using this model we then formally
prove that GNIs induce an `implicit bias', which varies depending on the
heaviness of the tails and the level of asymmetry. Our empirical results
confirm that different types of neural networks trained with GNIs are
well-modelled by the proposed dynamics and that the implicit effect of these
injections induces a bias that degrades the performance of networks.
</p>
<a href="http://arxiv.org/abs/2102.07006" target="_blank">arXiv:2102.07006</a> [<a href="http://arxiv.org/pdf/2102.07006" target="_blank">pdf</a>]

<h2>Bridging Graph Neural Networks and Statistical Relational Learning: Relational One-Class GCN. (arXiv:2102.07007v1 [cs.LG])</h2>
<h3>Devendra Singh Dhami (1), Siwen Yan (2), Sriraam Natarajan (2) ((1) TU Darmstadt, (2) The University of Texas at Dallas)</h3>
<p>We consider the problem of learning Graph Convolutional Networks (GCNs) for
relational data. Specifically, we consider the classic link prediction and node
classification problems as relational modeling tasks and develop a relational
extension to GCNs. Our method constructs a secondary graph using relational
density estimation techniques where vertices correspond to the target triples.
We emphasize the importance of learning features using the secondary graph and
the advantages of employing a distance matrix over the typically used adjacency
matrix. Our comprehensive empirical evaluation demonstrates the superiority of
our approach over $\mathbf{12}$ different GCN models, relational embedding
techniques, rule learning techniques and relational models.
</p>
<a href="http://arxiv.org/abs/2102.07007" target="_blank">arXiv:2102.07007</a> [<a href="http://arxiv.org/pdf/2102.07007" target="_blank">pdf</a>]

<h2>Mitigating Negative Side Effects via Environment Shaping. (arXiv:2102.07017v1 [cs.AI])</h2>
<h3>Sandhya Saisubramanian, Shlomo Zilberstein</h3>
<p>Agents operating in unstructured environments often produce negative side
effects (NSE), which are difficult to identify at design time. While the agent
can learn to mitigate the side effects from human feedback, such feedback is
often expensive and the rate of learning is sensitive to the agent's state
representation. We examine how humans can assist an agent, beyond providing
feedback, and exploit their broader scope of knowledge to mitigate the impacts
of NSE. We formulate this problem as a human-agent team with decoupled
objectives. The agent optimizes its assigned task, during which its actions may
produce NSE. The human shapes the environment through minor reconfiguration
actions so as to mitigate the impacts of the agent's side effects, without
affecting the agent's ability to complete its assigned task. We present an
algorithm to solve this problem and analyze its theoretical properties. Through
experiments with human subjects, we assess the willingness of users to perform
minor environment modifications to mitigate the impacts of NSE. Empirical
evaluation of our approach shows that the proposed framework can successfully
mitigate NSE, without affecting the agent's ability to complete its assigned
task.
</p>
<a href="http://arxiv.org/abs/2102.07017" target="_blank">arXiv:2102.07017</a> [<a href="http://arxiv.org/pdf/2102.07017" target="_blank">pdf</a>]

<h2>ThetA -- fast and robust clustering via a distance parameter. (arXiv:2102.07028v1 [cs.LG])</h2>
<h3>Eleftherios Garyfallidis, Shreyas Fadnavis, Jong Sung Park, Bramsh Qamar Chandio, Javier Guaje, Serge Koudoro, Nasim Anousheh</h3>
<p>Clustering is a fundamental problem in machine learning where distance-based
approaches have dominated the field for many decades. This set of problems is
often tackled by partitioning the data into K clusters where the number of
clusters is chosen apriori. While significant progress has been made on these
lines over the years, it is well established that as the number of clusters or
dimensions increase, current approaches dwell in local minima resulting in
suboptimal solutions. In this work, we propose a new set of distance threshold
methods called Theta-based Algorithms (ThetA). Via experimental comparisons and
complexity analyses we show that our proposed approach outperforms existing
approaches in: a) clustering accuracy and b) time complexity. Additionally, we
show that for a large class of problems, learning the optimal threshold is
straightforward in comparison to learning K. Moreover, we show how ThetA can
infer the sparsity of datasets in higher dimensions.
</p>
<a href="http://arxiv.org/abs/2102.07028" target="_blank">arXiv:2102.07028</a> [<a href="http://arxiv.org/pdf/2102.07028" target="_blank">pdf</a>]

<h2>Diffusion Approximations for a Class of Sequential Testing Problems. (arXiv:2102.07030v1 [stat.ML])</h2>
<h3>Victor F. Araman, Rene Caldentey</h3>
<p>We consider a decision maker who must choose an action in order to maximize a
reward function that depends also on an unknown parameter {\Theta}. The
decision maker can delay taking the action in order to experiment and gather
additional information on {\Theta}. We model the decision maker's problem using
a Bayesian sequential experimentation framework and use dynamic programming and
diffusion-asymptotic analysis to solve it. For that, we scale our problem in a
way that both the average number of experiments that is conducted per unit of
time is large and the informativeness of each individual experiment is low.
Under such regime, we derive a diffusion approximation for the sequential
experimentation problem, which provides a number of important insights about
the nature of the problem and its solution. Our solution method also shows that
the complexity of the problem grows only quadratically with the cardinality of
the set of actions from which the decision maker can choose. We illustrate our
methodology and results using a concrete application in the context of
assortment selection and new product introduction. Specifically, we study the
problem of a seller who wants to select an optimal assortment of products to
launch into the marketplace and is uncertain about consumers' preferences.
Motivated by emerging practices in e-commerce, we assume that the seller is
able to use a crowdvoting system to learn these preferences before a final
assortment decision is made. In this context, we undertake an extensive
numerical analysis to assess the value of learning and demonstrate the
effectiveness and robustness of the heuristics derived from the diffusion
approximation.
</p>
<a href="http://arxiv.org/abs/2102.07030" target="_blank">arXiv:2102.07030</a> [<a href="http://arxiv.org/pdf/2102.07030" target="_blank">pdf</a>]

<h2>Model-free Representation Learning and Exploration in Low-rank MDPs. (arXiv:2102.07035v1 [cs.LG])</h2>
<h3>Aditya Modi, Jinglin Chen, Akshay Krishnamurthy, Nan Jiang, Alekh Agarwal</h3>
<p>The low rank MDP has emerged as an important model for studying
representation learning and exploration in reinforcement learning. With a known
representation, several model-free exploration strategies exist. In contrast,
all algorithms for the unknown representation setting are model-based, thereby
requiring the ability to model the full dynamics. In this work, we present the
first model-free representation learning algorithms for low rank MDPs. The key
algorithmic contribution is a new minimax representation learning objective,
for which we provide variants with differing tradeoffs in their statistical and
computational properties. We interleave this representation learning step with
an exploration strategy to cover the state space in a reward-free manner. The
resulting algorithms are provably sample efficient and can accommodate general
function approximation to scale to complex environments.
</p>
<a href="http://arxiv.org/abs/2102.07035" target="_blank">arXiv:2102.07035</a> [<a href="http://arxiv.org/pdf/2102.07035" target="_blank">pdf</a>]

<h2>Robust Lane Detection via Expanded Self Attention. (arXiv:2102.07037v1 [cs.CV])</h2>
<h3>Minhyeok Lee, Junhyeop Lee, Dogyoon Lee, Woojin Kim, Sangwon Hwang, Sangyoun Lee</h3>
<p>The image-based lane detection algorithm is one of the key technologies in
autonomous vehicles. Modern deep learning methods achieve high performance in
lane detection, but it is still difficult to accurately detect lanes in
challenging situations such as congested roads and extreme lighting conditions.
To be robust on these challenging situations, it is important to extract global
contextual information even from limited visual cues. In this paper, we propose
a simple but powerful self-attention mechanism optimized for lane detection
called the Expanded Self Attention (ESA) module. Inspired by the simple
geometric structure of lanes, the proposed method predicts the confidence of a
lane along the vertical and horizontal directions in an image. The prediction
of the confidence enables estimating occluded locations by extracting global
contextual information. ESA module can be easily implemented and applied to any
encoder-decoder-based model without increasing the inference time. The
performance of our method is evaluated on three popular lane detection
benchmarks (TuSimple, CULane and BDD100K). We achieve state-of-the-art
performance in CULane and BDD100K and distinct improvement on TuSimple dataset.
The experimental results show that our approach is robust to occlusion and
extreme lighting conditions.
</p>
<a href="http://arxiv.org/abs/2102.07037" target="_blank">arXiv:2102.07037</a> [<a href="http://arxiv.org/pdf/2102.07037" target="_blank">pdf</a>]

<h2>FaSTrack: a Modular Framework for Real-Time Motion Planning and Guaranteed Safe Tracking. (arXiv:2102.07039v1 [cs.RO])</h2>
<h3>Mo Chen, Sylvia L. Herbert, Haimin Hu, Ye Pu, Jaime F. Fisac, Somil Bansal, SooJean Han, Claire J. Tomlin</h3>
<p>Real-time, guaranteed safe trajectory planning is vital for navigation in
unknown environments. However, real-time navigation algorithms typically
sacrifice robustness for computation speed. Alternatively, provably safe
trajectory planning tends to be too computationally intensive for real-time
replanning. We propose FaSTrack, Fast and Safe Tracking, a framework that
achieves both real-time replanning and guaranteed safety. In this framework,
real-time computation is achieved by allowing any trajectory planner to use a
simplified \textit{planning model} of the system. The plan is tracked by the
system, represented by a more realistic, higher-dimensional \textit{tracking
model}. We precompute the tracking error bound (TEB) due to mismatch between
the two models and due to external disturbances. We also obtain the
corresponding tracking controller used to stay within the TEB. The
precomputation does not require prior knowledge of the environment. We
demonstrate FaSTrack using Hamilton-Jacobi reachability for precomputation and
three different real-time trajectory planners with three different
tracking-planning model pairs.
</p>
<a href="http://arxiv.org/abs/2102.07039" target="_blank">arXiv:2102.07039</a> [<a href="http://arxiv.org/pdf/2102.07039" target="_blank">pdf</a>]

<h2>Reasoning Over Virtual Knowledge Bases With Open Predicate Relations. (arXiv:2102.07043v1 [cs.AI])</h2>
<h3>Haitian Sun, Pat Verga, Bhuwan Dhingra, Ruslan Salakhutdinov, William W. Cohen</h3>
<p>We present the Open Predicate Query Language (OPQL); a method for
constructing a virtual KB (VKB) trained entirely from text. Large Knowledge
Bases (KBs) are indispensable for a wide-range of industry applications such as
question answering and recommendation. Typically, KBs encode world knowledge in
a structured, readily accessible form derived from laborious human annotation
efforts. Unfortunately, while they are extremely high precision, KBs are
inevitably highly incomplete and automated methods for enriching them are far
too inaccurate. Instead, OPQL constructs a VKB by encoding and indexing a set
of relation mentions in a way that naturally enables reasoning and can be
trained without any structured supervision. We demonstrate that OPQL
outperforms prior VKB methods on two different KB reasoning tasks and,
additionally, can be used as an external memory integrated into a language
model (OPQL-LM) leading to improvements on two open-domain question answering
tasks.
</p>
<a href="http://arxiv.org/abs/2102.07043" target="_blank">arXiv:2102.07043</a> [<a href="http://arxiv.org/pdf/2102.07043" target="_blank">pdf</a>]

<h2>Connecting Interpretability and Robustness in Decision Trees through Separation. (arXiv:2102.07048v1 [cs.LG])</h2>
<h3>Michal Moshkovitz, Yao-Yuan Yang, Kamalika Chaudhuri</h3>
<p>Recent research has recognized interpretability and robustness as essential
properties of trustworthy classification. Curiously, a connection between
robustness and interpretability was empirically observed, but the theoretical
reasoning behind it remained elusive. In this paper, we rigorously investigate
this connection. Specifically, we focus on interpretation using decision trees
and robustness to $l_{\infty}$-perturbation. Previous works defined the notion
of $r$-separation as a sufficient condition for robustness. We prove upper and
lower bounds on the tree size in case the data is $r$-separated. We then show
that a tighter bound on the size is possible when the data is linearly
separated. We provide the first algorithm with provable guarantees both on
robustness, interpretability, and accuracy in the context of decision trees.
Experiments confirm that our algorithm yields classifiers that are both
interpretable and robust and have high accuracy. The code for the experiments
is available at https://github.com/yangarbiter/interpretable-robust-trees .
</p>
<a href="http://arxiv.org/abs/2102.07048" target="_blank">arXiv:2102.07048</a> [<a href="http://arxiv.org/pdf/2102.07048" target="_blank">pdf</a>]

<h2>Achieving Linear Convergence in Federated Learning under Objective and Systems Heterogeneity. (arXiv:2102.07053v1 [cs.LG])</h2>
<h3>Aritra Mitra, Rayana Jaafar, George J. Pappas, Hamed Hassani</h3>
<p>We consider a standard federated learning architecture where a group of
clients periodically coordinate with a central server to train a statistical
model. We tackle two major challenges in federated learning: (i) objective
heterogeneity, which stems from differences in the clients' local loss
functions, and (ii) systems heterogeneity, which leads to slow and straggling
client devices. Due to such client heterogeneity, we show that existing
federated learning algorithms suffer from a fundamental speed-accuracy
conflict: they either guarantee linear convergence but to an incorrect point,
or convergence to the global minimum but at a sub-linear rate, i.e., fast
convergence comes at the expense of accuracy.

To address the above limitation, we propose FedLin - a simple, new algorithm
that exploits past gradients and employs client-specific learning rates. When
the clients' local loss functions are smooth and strongly convex, we show that
FedLin guarantees linear convergence to the global minimum. We then establish
matching upper and lower bounds on the convergence rate of FedLin that
highlight the trade-offs associated with infrequent, periodic communication.
Notably, FedLin is the only approach that is able to match centralized
convergence rates (up to constants) for smooth strongly convex, convex, and
non-convex loss functions despite arbitrary objective and systems
heterogeneity. We further show that FedLin preserves linear convergence rates
under aggressive gradient sparsification, and quantify the effect of the
compression level on the convergence rate.
</p>
<a href="http://arxiv.org/abs/2102.07053" target="_blank">arXiv:2102.07053</a> [<a href="http://arxiv.org/pdf/2102.07053" target="_blank">pdf</a>]

<h2>Achieving Efficiency in Black Box Simulation of Distribution Tails with Self-structuring Importance Samplers. (arXiv:2102.07060v1 [stat.ML])</h2>
<h3>Anand Deo, Karthyek Murthy</h3>
<p>Motivated by the increasing adoption of models which facilitate greater
automation in risk management and decision-making, this paper presents a novel
Importance Sampling (IS) scheme for measuring distribution tails of objectives
modelled with enabling tools such as feature-based decision rules, mixed
integer linear programs, deep neural networks, etc. Conventional efficient IS
approaches suffer from feasibility and scalability concerns due to the need to
intricately tailor the sampler to the underlying probability distribution and
the objective. This challenge is overcome in the proposed black-box scheme by
automating the selection of an effective IS distribution with a transformation
that implicitly learns and replicates the concentration properties observed in
less rare samples. This novel approach is guided by a large deviations
principle that brings out the phenomenon of self-similarity of optimal IS
distributions. The proposed sampler is the first to attain asymptotically
optimal variance reduction across a spectrum of multivariate distributions
despite being oblivious to the underlying structure. The large deviations
principle additionally results in new distribution tail asymptotics capable of
yielding operational insights. The applicability is illustrated by considering
product distribution networks and portfolio credit risk models informed by
neural networks as examples.
</p>
<a href="http://arxiv.org/abs/2102.07060" target="_blank">arXiv:2102.07060</a> [<a href="http://arxiv.org/pdf/2102.07060" target="_blank">pdf</a>]

<h2>NeRF$--$: Neural Radiance Fields Without Known Camera Parameters. (arXiv:2102.07064v1 [cs.CV])</h2>
<h3>Zirui Wang, Shangzhe Wu, Weidi Xie, Min Chen, Victor Adrian Prisacariu</h3>
<p>This paper tackles the problem of novel view synthesis (NVS) from 2D images
without known camera poses and intrinsics. Among various NVS techniques, Neural
Radiance Field (NeRF) has recently gained popularity due to its remarkable
synthesis quality. Existing NeRF-based approaches assume that the camera
parameters associated with each input image are either directly accessible at
training, or can be accurately estimated with conventional techniques based on
correspondences, such as Structure-from-Motion. In this work, we propose an
end-to-end framework, termed NeRF--, for training NeRF models given only RGB
images, without pre-computed camera parameters. Specifically, we show that the
camera parameters, including both intrinsics and extrinsics, can be
automatically discovered via joint optimisation during the training of the NeRF
model. On the standard LLFF benchmark, our model achieves comparable novel view
synthesis results compared to the baseline trained with COLMAP pre-computed
camera parameters. We also conduct extensive analyses to understand the model
behaviour under different camera trajectories, and show that in scenarios where
COLMAP fails, our model still produces robust results.
</p>
<a href="http://arxiv.org/abs/2102.07064" target="_blank">arXiv:2102.07064</a> [<a href="http://arxiv.org/pdf/2102.07064" target="_blank">pdf</a>]

<h2>FastHand: Fast Hand Pose Estimation From A Monocular Camera. (arXiv:2102.07067v1 [cs.RO])</h2>
<h3>Shan An, Xiajie Zhang, Dong Wei, Haogang Zhu, Jianyu Yang, Konstantinos A. Tsintotas</h3>
<p>Hand gesture recognition constitutes the initial step in most methods related
to human-robot interaction. There are two key challenges in this task. The
first one corresponds to the difficulty of achieving stable and accurate hand
landmark predictions in real-world scenarios, while the second to the decreased
time of forward inference. In this paper, we propose a fast and accurate
framework for hand pose estimation, dubbed as "FastHand". Using a lightweight
encoder-decoder network architecture, we achieve to fulfil the requirements of
practical applications running on embedded devices. The encoder consists of
deep layers with a small number of parameters, while the decoder makes use of
spatial location information to obtain more accurate results. The evaluation
took place on two publicly available datasets demonstrating the improved
performance of the proposed pipeline compared to other state-of-the-art
approaches. FastHand offers high accuracy scores while reaching a speed of 25
frames per second on an NVIDIA Jetson TX2 graphics processing unit.
</p>
<a href="http://arxiv.org/abs/2102.07067" target="_blank">arXiv:2102.07067</a> [<a href="http://arxiv.org/pdf/2102.07067" target="_blank">pdf</a>]

<h2>A Forward Backward Greedy approach for Sparse Multiscale Learning. (arXiv:2102.07068v1 [cs.LG])</h2>
<h3>Prashant Shekhar, Abani Patra</h3>
<p>Multiscale Models are known to be successful in uncovering and analyzing the
structures in data at different resolutions. In the current work we propose a
feature driven Reproducing Kernel Hilbert space (RKHS), for which the
associated kernel has a weighted multiscale structure. For generating
approximations in this space, we provide a practical forward-backward algorithm
that is shown to greedily construct a set of basis functions having a
multiscale structure, while also creating sparse representations from the given
data set, making representations and predictions very efficient. We provide a
detailed analysis of the algorithm including recommendations for selecting
algorithmic hyper-parameters and estimating probabilistic rates of convergence
at individual scales. Then we extend this analysis to multiscale setting,
studying the effects of finite scale truncation and quality of solution in the
inherent RKHS. In the last section, we analyze the performance of the approach
on a variety of simulation and real data sets, thereby justifying the
efficiency claims in terms of model quality and data reduction.
</p>
<a href="http://arxiv.org/abs/2102.07068" target="_blank">arXiv:2102.07068</a> [<a href="http://arxiv.org/pdf/2102.07068" target="_blank">pdf</a>]

<h2>Doping: A technique for efficient compression of LSTM models using sparse structured additive matrices. (arXiv:2102.07071v1 [cs.LG])</h2>
<h3>Urmish Thakker, Paul N. Whatmough, Zhigang Liu, Matthew Mattina, Jesse Beu</h3>
<p>Structured matrices, such as those derived from Kronecker products (KP), are
effective at compressing neural networks, but can lead to unacceptable accuracy
loss when applied to large models. In this paper, we propose the notion of
doping -- addition of an extremely sparse matrix to a structured matrix. Doping
facilitates additional degrees of freedom for a small number of parameters,
allowing them to independently diverge from the fixed structure. To train LSTMs
with doped structured matrices, we introduce the additional parameter matrix
while slowly annealing its sparsity level. However, we find that performance
degrades as we slowly sparsify the doping matrix, due to co-matrix adaptation
(CMA) between the structured and the sparse matrices. We address this over
dependence on the sparse matrix using a co-matrix dropout regularization (CMR)
scheme. We provide empirical evidence to show that doping, CMA and CMR are
concepts generally applicable to multiple structured matrices (Kronecker
Product, LMF, Hybrid Matrix Decomposition). Additionally, results with doped
kronecker product matrices demonstrate state-of-the-art accuracy at large
compression factors (10 - 25x) across 4 natural language processing
applications with minor loss in accuracy. Doped KP compression technique
outperforms previous state-of-the art compression results by achieving 1.3 -
2.4x higher compression factor at a similar accuracy, while also beating strong
alternatives like pruning and low-rank methods by a large margin (8% or more).
Additionally, we show that doped KP can be deployed on commodity hardware using
the current software stack and achieve 2.5 - 5.5x inference run-time speed-up
over baseline.
</p>
<a href="http://arxiv.org/abs/2102.07071" target="_blank">arXiv:2102.07071</a> [<a href="http://arxiv.org/pdf/2102.07071" target="_blank">pdf</a>]

<h2>Costly Features Classification using Monte Carlo Tree Search. (arXiv:2102.07073v1 [cs.LG])</h2>
<h3>Ziheng Chen, Jin Huang, Hongshik Ahn, Xin Ning</h3>
<p>We consider the problem of costly feature classification, where we
sequentially select the subset of features to make a balance between the
classification error and the feature cost. In this paper, we first cast the
task into a MDP problem and use Advantage Actor Critic algorithm to solve it.
In order to further improve the agent's performance and make the policy
explainable, we employ the Monte Carlo Tree Search to update the policy
iteratively. During the procedure, we also consider its performance on the
unbalanced dataset and its sensitivity to the missing value. We evaluate our
model on multiple datasets and find it outperforms other methods.
</p>
<a href="http://arxiv.org/abs/2102.07073" target="_blank">arXiv:2102.07073</a> [<a href="http://arxiv.org/pdf/2102.07073" target="_blank">pdf</a>]

<h2>TransGAN: Two Transformers Can Make One Strong GAN. (arXiv:2102.07074v1 [cs.CV])</h2>
<h3>Yifan Jiang, Shiyu Chang, Zhangyang Wang</h3>
<p>The recent explosive interest on transformers has suggested their potential
to become powerful "universal" models for computer vision tasks, such as
classification, detection, and segmentation. However, how further transformers
can go - are they ready to take some more notoriously difficult vision tasks,
e.g., generative adversarial networks (GANs)? Driven by that curiosity, we
conduct the first pilot study in building a GAN \textbf{completely free of
convolutions}, using only pure transformer-based architectures. Our vanilla GAN
architecture, dubbed \textbf{TransGAN}, consists of a memory-friendly
transformer-based generator that progressively increases feature resolution
while decreasing embedding dimension, and a patch-level discriminator that is
also transformer-based. We then demonstrate TransGAN to notably benefit from
data augmentations (more than standard GANs), a multi-task co-training strategy
for the generator, and a locally initialized self-attention that emphasizes the
neighborhood smoothness of natural images. Equipped with those findings,
TransGAN can effectively scale up with bigger models and high-resolution image
datasets. Specifically, our best architecture achieves highly competitive
performance compared to current state-of-the-art GANs based on convolutional
backbones. Specifically, TransGAN sets \textbf{new state-of-the-art} IS score
of 10.10 and FID score of 25.32 on STL-10. It also reaches competitive 8.64 IS
score and 11.89 FID score on Cifar-10, and 12.23 FID score on CelebA
$64\times64$, respectively. We also conclude with a discussion of the current
limitations and future potential of TransGAN. The code is available at
\url{https://github.com/VITA-Group/TransGAN}.
</p>
<a href="http://arxiv.org/abs/2102.07074" target="_blank">arXiv:2102.07074</a> [<a href="http://arxiv.org/pdf/2102.07074" target="_blank">pdf</a>]

<h2>Tight lower bounds for Dynamic Time Warping. (arXiv:2102.07076v1 [cs.LG])</h2>
<h3>Geoffrey I. Webb, Francois Petitjean</h3>
<p>Dynamic Time Warping (DTW) is a popular similarity measure for aligning and
comparing time series. Due to DTW's high computation time, lower bounds are
often employed to screen poor matches. Many alternative lower bounds have been
proposed, providing a range of different trade-offs between tightness and
computational efficiency. LB Keogh provides a useful trade-off in many
applications. Two recent lower bounds, LB Improved and LB Enhanced, are
substantially tighter than LB Keogh. All three have the same worst case
computational complexity - linear with respect to series length and constant
with respect to window size. We present four new DTW lower bounds in the same
complexity class. LB Petitjean is substantially tighter than LB Improved, with
only modest additional computational overhead. LB Webb is more efficient than
LB Improved, while often providing a tighter bound. LB Webb is always tighter
than LB Keogh. The parameter free LB Webb is usually tighter than LB Enhanced.
A parameterized variant, LB Webb Enhanced, is always tighter than LB Enhanced.
A further variant, LB Webb*, is useful for some constrained distance functions.
In extensive experiments, LB Webb proves to be very effective for nearest
neighbor search.
</p>
<a href="http://arxiv.org/abs/2102.07076" target="_blank">arXiv:2102.07076</a> [<a href="http://arxiv.org/pdf/2102.07076" target="_blank">pdf</a>]

<h2>Model-Agnostic Graph Regularization for Few-Shot Learning. (arXiv:2102.07077v1 [cs.LG])</h2>
<h3>Ethan Shen, Maria Brbic, Nicholas Monath, Jiaqi Zhai, Manzil Zaheer, Jure Leskovec</h3>
<p>In many domains, relationships between categories are encoded in the
knowledge graph. Recently, promising results have been achieved by
incorporating knowledge graph as side information in hard classification tasks
with severely limited data. However, prior models consist of highly complex
architectures with many sub-components that all seem to impact performance. In
this paper, we present a comprehensive empirical study on graph embedded
few-shot learning. We introduce a graph regularization approach that allows a
deeper understanding of the impact of incorporating graph information between
labels. Our proposed regularization is widely applicable and model-agnostic,
and boosts the performance of any few-shot learning model, including
fine-tuning, metric-based, and optimization-based meta-learning. Our approach
improves the performance of strong base learners by up to 2% on Mini-ImageNet
and 6.7% on ImageNet-FS, outperforming state-of-the-art graph embedded methods.
Additional analyses reveal that graph regularizing models result in a lower
loss for more difficult tasks, such as those with fewer shots and less
informative support examples.
</p>
<a href="http://arxiv.org/abs/2102.07077" target="_blank">arXiv:2102.07077</a> [<a href="http://arxiv.org/pdf/2102.07077" target="_blank">pdf</a>]

<h2>Exploiting Shared Representations for Personalized Federated Learning. (arXiv:2102.07078v1 [cs.LG])</h2>
<h3>Liam Collins, Hamed Hassani, Aryan Mokhtari, Sanjay Shakkottai</h3>
<p>Deep neural networks have shown the ability to extract universal feature
representations from data such as images and text that have been useful for a
variety of learning tasks. However, the fruits of representation learning have
yet to be fully-realized in federated settings. Although data in federated
settings is often non-i.i.d. across clients, the success of centralized deep
learning suggests that data often shares a global feature representation, while
the statistical heterogeneity across clients or tasks is concentrated in the
labels. Based on this intuition, we propose a novel federated learning
framework and algorithm for learning a shared data representation across
clients and unique local heads for each client. Our algorithm harnesses the
distributed computational power across clients to perform many local-updates
with respect to the low-dimensional local parameters for every update of the
representation. We prove that this method obtains linear convergence to the
ground-truth representation with near-optimal sample complexity in a linear
setting, demonstrating that it can efficiently reduce the problem dimension for
each client. Further, we provide extensive experimental results demonstrating
the improvement of our method over alternative personalized federated learning
approaches in heterogeneous settings.
</p>
<a href="http://arxiv.org/abs/2102.07078" target="_blank">arXiv:2102.07078</a> [<a href="http://arxiv.org/pdf/2102.07078" target="_blank">pdf</a>]

<h2>New methods for metastimuli: architecture, embeddings, and neural network optimization. (arXiv:2102.07090v1 [cs.AI])</h2>
<h3>Rico A.R. Picone, Dane Webb, Finbarr Obierefu, Jotham Lentz</h3>
<p>Six significant new methodological developments of the previously-presented
"metastimuli architecture" for human learning through machine learning of
spatially correlated structural position within a user's personal information
management system (PIMS), providing the basis for haptic metastimuli, are
presented. These include architectural innovation, recurrent (RNN) artificial
neural network (ANN) application, a variety of atom embedding techniques
(including a novel technique we call "nabla" embedding inspired by
linguistics), ANN hyper-parameter (one that affects the network but is not
trained, e.g. the learning rate) optimization, and meta-parameter (one that
determines the system performance but is not trained and not a hyper-parameter,
e.g. the atom embedding technique) optimization for exploring the large design
space. A technique for using the system for automatic atom categorization in a
user's PIMS is outlined. ANN training and hyper- and meta-parameter
optimization results are presented and discussed in service of methodological
recommendations.
</p>
<a href="http://arxiv.org/abs/2102.07090" target="_blank">arXiv:2102.07090</a> [<a href="http://arxiv.org/pdf/2102.07090" target="_blank">pdf</a>]

<h2>Learning Self-Similarity in Space and Time as Generalized Motion for Action Recognition. (arXiv:2102.07092v1 [cs.CV])</h2>
<h3>Heeseung Kwon, Manjin Kim, Suha Kwak, Minsu Cho</h3>
<p>Spatio-temporal convolution often fails to learn motion dynamics in videos
and thus an effective motion representation is required for video understanding
in the wild. In this paper, we propose a rich and robust motion representation
based on spatio-temporal self-similarity (STSS). Given a sequence of frames,
STSS represents each local region as similarities to its neighbors in space and
time. By converting appearance features into relational values, it enables the
learner to better recognize structural patterns in space and time. We leverage
the whole volume of STSS and let our model learn to extract an effective motion
representation from it. The proposed neural block, dubbed SELFY, can be easily
inserted into neural architectures and trained end-to-end without additional
supervision. With a sufficient volume of the neighborhood in space and time, it
effectively captures long-term interaction and fast motion in the video,
leading to robust action recognition. Our experimental analysis demonstrates
its superiority over previous methods for motion modeling as well as its
complementarity to spatio-temporal features from direct convolution. On the
standard action recognition benchmarks, Something-Something-V1 &amp; V2, Diving-48,
and FineGym, the proposed method achieves the state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/2102.07092" target="_blank">arXiv:2102.07092</a> [<a href="http://arxiv.org/pdf/2102.07092" target="_blank">pdf</a>]

<h2>Domain Adversarial Reinforcement Learning. (arXiv:2102.07097v1 [cs.LG])</h2>
<h3>Bonnie Li, Vincent Fran&#xe7;ois-Lavet, Thang Doan, Joelle Pineau</h3>
<p>We consider the problem of generalization in reinforcement learning where
visual aspects of the observations might differ, e.g. when there are different
backgrounds or change in contrast, brightness, etc. We assume that our agent
has access to only a few of the MDPs from the MDP distribution during training.
The performance of the agent is then reported on new unknown test domains drawn
from the distribution (e.g. unseen backgrounds). For this "zero-shot RL" task,
we enforce invariance of the learned representations to visual domains via a
domain adversarial optimization process. We empirically show that this approach
allows achieving a significant generalization improvement to new unseen
domains.
</p>
<a href="http://arxiv.org/abs/2102.07097" target="_blank">arXiv:2102.07097</a> [<a href="http://arxiv.org/pdf/2102.07097" target="_blank">pdf</a>]

<h2>Healing Products of Gaussian Processes. (arXiv:2102.07106v1 [stat.ML])</h2>
<h3>Samuel Cohen, Rendani Mbuvha, Tshilidzi Marwala, Marc Peter Deisenroth</h3>
<p>Gaussian processes (GPs) are nonparametric Bayesian models that have been
applied to regression and classification problems. One of the approaches to
alleviate their cubic training cost is the use of local GP experts trained on
subsets of the data. In particular, product-of-expert models combine the
predictive distributions of local experts through a tractable product
operation. While these expert models allow for massively distributed
computation, their predictions typically suffer from erratic behaviour of the
mean or uncalibrated uncertainty quantification. By calibrating predictions via
a tempered softmax weighting, we provide a solution to these problems for
multiple product-of-expert models, including the generalised product of experts
and the robust Bayesian committee machine. Furthermore, we leverage the optimal
transport literature and propose a new product-of-expert model that combines
predictions of local experts by computing their Wasserstein barycenter, which
can be applied to both regression and classification.
</p>
<a href="http://arxiv.org/abs/2102.07106" target="_blank">arXiv:2102.07106</a> [<a href="http://arxiv.org/pdf/2102.07106" target="_blank">pdf</a>]

<h2>Distributed Estimation, Control and Coordination of Quadcopter Swarm Robots. (arXiv:2102.07107v1 [cs.RO])</h2>
<h3>Zheng Jia, Michael Hamer, Raffaello D&#x27;Andrea</h3>
<p>In this thesis we are interested in applying distributed estimation, control
and optimization techniques to enable a group of quadcopters to fly through
openings. The quadcopters are assumed to be equipped with a simulated bearing
and distance sensor for localization. Some quadcopters are designated as
leaders who carry global position sensors. We assume quadcopters can
communicate information with each other.
</p>
<a href="http://arxiv.org/abs/2102.07107" target="_blank">arXiv:2102.07107</a> [<a href="http://arxiv.org/pdf/2102.07107" target="_blank">pdf</a>]

<h2>CATE: Computation-aware Neural Architecture Encoding with Transformers. (arXiv:2102.07108v1 [cs.LG])</h2>
<h3>Shen Yan, Kaiqiang Song, Fei Liu, Mi Zhang</h3>
<p>Recent works (White et al., 2020a; Yan et al., 2020) demonstrate the
importance of architecture encodings in Neural Architecture Search (NAS). These
encodings encode either structure or computation information of the neural
architectures. Compared to structure-aware encodings, computation-aware
encodings map architectures with similar accuracies to the same region, which
improves the downstream architecture search performance (Zhang et al., 2019;
White et al., 2020a). In this work, we introduce a Computation-Aware
Transformer-based Encoding method called CATE. Different from existing
computation-aware encodings based on fixed transformation (e.g. path encoding),
CATE employs a pairwise pre-training scheme to learn computation-aware
encodings using Transformers with cross-attention. Such learned encodings
contain dense and contextualized computation information of neural
architectures. We compare CATE with eleven encodings under three major
encoding-dependent NAS subroutines in both small and large search spaces. Our
experiments show that CATE is beneficial to the downstream search, especially
in the large search space. Moreover, the outside search space experiment shows
its superior generalization ability beyond the search space on which it was
trained.
</p>
<a href="http://arxiv.org/abs/2102.07108" target="_blank">arXiv:2102.07108</a> [<a href="http://arxiv.org/pdf/2102.07108" target="_blank">pdf</a>]

<h2>Machine Learning Methods for the Design and Operation of Liquid Rocket Engines -- Research Activities at the DLR Institute of Space Propulsion. (arXiv:2102.07109v1 [cs.LG])</h2>
<h3>G&#xfc;nther Waxenegger-Wilfing, Kai Dresia, Jan Deeken, Michael Oschwald</h3>
<p>The last years have witnessed an enormous interest in the use of artificial
intelligence methods, especially machine learning algorithms. This also has a
major impact on aerospace engineering in general, and the design and operation
of liquid rocket engines in particular, and research in this area is growing
rapidly. The paper describes current machine learning applications at the DLR
Institute of Space Propulsion. Not only applications in the field of modeling
are presented, but also convincing results that prove the capabilities of
machine learning methods for control and condition monitoring are described in
detail. Furthermore, the advantages and disadvantages of the presented methods
as well as current and future research directions are discussed.
</p>
<a href="http://arxiv.org/abs/2102.07109" target="_blank">arXiv:2102.07109</a> [<a href="http://arxiv.org/pdf/2102.07109" target="_blank">pdf</a>]

<h2>Point-line-based RGB-D SLAM and Bundle Adjustment Uncertainty Analysis. (arXiv:2102.07110v1 [cs.RO])</h2>
<h3>Xin Ma, Xinwu Liang</h3>
<p>Most of the state-of-the-art indirect visual SLAM methods are based on the
sparse point features. However, it is hard to find enough reliable point
features for state estimation in the case of low-textured scenes. Line features
are abundant in urban and indoor scenes. Recent studies have shown that the
combination of point and line features can provide better accuracy despite the
decrease in computational efficiency. In this paper, measurements of point and
line features are extracted from RGB-D data to create map features, and points
on a line are treated as keypoints. We propose an extended approach to make
more use of line observation information. And we prove that, in the local
bundle adjustment, the estimation uncertainty of keyframe poses can be reduced
when considering more landmarks with independent measurements in the
optimization process. Experimental results on two public RGB-D datasets
demonstrate that the proposed method has better robustness and accuracy in
challenging environments.
</p>
<a href="http://arxiv.org/abs/2102.07110" target="_blank">arXiv:2102.07110</a> [<a href="http://arxiv.org/pdf/2102.07110" target="_blank">pdf</a>]

<h2>A New Algorithm for Hidden Markov Models Learning Problem. (arXiv:2102.07112v1 [cs.LG])</h2>
<h3>Taha Mansouri, Mohamadreza Sadeghimoghadam, Iman Ghasemian Sahebi</h3>
<p>This research focuses on the algorithms and approaches for learning Hidden
Markov Models (HMMs) and compares HMM learning methods and algorithms. HMM is a
statistical Markov model in which the system being modeled is assumed to be a
Markov process. One of the essential characteristics of HMMs is their learning
capabilities. Learning algorithms are introduced to overcome this
inconvenience. One of the main problems of the newly proposed algorithms is
their validation. This research aims by using the theoretical and experimental
analysis to 1) compare HMMs learning algorithms proposed in the literature, 2)
provide a validation tool for new HMM learning algorithms, and 3) present a new
algorithm called Asexual Reproduction Optimization (ARO) with one of its
extensions - Modified ARO (MARO) - as a novel HMM learning algorithm to use the
validation tool proposed. According to the literature findings, it seems that
populationbased algorithms perform better among HMMs learning approaches than
other algorithms. Also, the testing was done in nine benchmark datasets. The
results show that MARO outperforms different algorithms in objective functions
in terms of accuracy and robustness.
</p>
<a href="http://arxiv.org/abs/2102.07112" target="_blank">arXiv:2102.07112</a> [<a href="http://arxiv.org/pdf/2102.07112" target="_blank">pdf</a>]

<h2>Comprehensive Comparative Study of Multi-Label Classification Methods. (arXiv:2102.07113v1 [cs.LG])</h2>
<h3>Jasmin Bogatinovski, Ljup&#x10d;o Todorovski, Sa&#x161;o D&#x17e;eroski, Dragi Kocev</h3>
<p>Multi-label classification (MLC) has recently received increasing interest
from the machine learning community. Several studies provide reviews of methods
and datasets for MLC and a few provide empirical comparisons of MLC methods.
However, they are limited in the number of methods and datasets considered.
This work provides a comprehensive empirical study of a wide range of MLC
methods on a plethora of datasets from various domains. More specifically, our
study evaluates 26 methods on 42 benchmark datasets using 20 evaluation
measures. The adopted evaluation methodology adheres to the highest literature
standards for designing and executing large scale, time-budgeted experimental
studies. First, the methods are selected based on their usage by the community,
assuring representation of methods across the MLC taxonomy of methods and
different base learners. Second, the datasets cover a wide range of complexity
and domains of application. The selected evaluation measures assess the
predictive performance and the efficiency of the methods. The results of the
analysis identify RFPCT, RFDTBR, ECCJ48, EBRJ48 and AdaBoost.MH as best
performing methods across the spectrum of performance measures. Whenever a new
method is introduced, it should be compared to different subsets of MLC
methods, determined on the basis of the different evaluation criteria.
</p>
<a href="http://arxiv.org/abs/2102.07113" target="_blank">arXiv:2102.07113</a> [<a href="http://arxiv.org/pdf/2102.07113" target="_blank">pdf</a>]

<h2>Sliced Multi-Marginal Optimal Transport. (arXiv:2102.07115v1 [stat.ML])</h2>
<h3>Samuel Cohen, K S Sesh Kumar, Marc Peter Deisenroth</h3>
<p>We study multi-marginal optimal transport, a generalization of optimal
transport that allows us to define discrepancies between multiple measures. It
provides a framework to solve multi-task learning problems and to perform
barycentric averaging. However, multi-marginal distances between multiple
measures are typically challenging to compute because they require estimating a
transport plan with $N^P$ variables. In this paper, we address this issue in
the following way: 1) we efficiently solve the one-dimensional multi-marginal
Monge-Wasserstein problem for a classical cost function in closed form, and 2)
we propose a higher-dimensional multi-marginal discrepancy via slicing and
study its generalized metric properties. We show that computing the sliced
multi-marginal discrepancy is massively scalable for a large number of
probability measures with support as large as $10^7$ samples. Our approach can
be applied to solving problems such as barycentric averaging, multi-task
density estimation and multi-task reinforcement learning.
</p>
<a href="http://arxiv.org/abs/2102.07115" target="_blank">arXiv:2102.07115</a> [<a href="http://arxiv.org/pdf/2102.07115" target="_blank">pdf</a>]

<h2>State-Visitation Fairness in Average-Reward MDPs. (arXiv:2102.07120v1 [cs.AI])</h2>
<h3>Ganesh Ghalme, Vineet Nair, Vishakha Patil, Yilun Zhou</h3>
<p>Fairness has emerged as an important concern in automated decision-making in
recent years, especially when these decisions affect human welfare. In this
work, we study fairness in temporally extended decision-making settings,
specifically those formulated as Markov Decision Processes (MDPs). Our proposed
notion of fairness ensures that each state's long-term visitation frequency is
more than a specified fraction. In an average-reward MDP (AMDP) setting, we
formulate the problem as a bilinear saddle point program and, for a generative
model, solve it using a Stochastic Mirror Descent (SMD) based algorithm. The
proposed solution guarantees a simultaneous approximation on the expected
average-reward and the long-term state-visitation frequency. We validate our
theoretical results with experiments on synthetic data.
</p>
<a href="http://arxiv.org/abs/2102.07120" target="_blank">arXiv:2102.07120</a> [<a href="http://arxiv.org/pdf/2102.07120" target="_blank">pdf</a>]

<h2>Multi-Objective Meta Learning. (arXiv:2102.07121v1 [cs.LG])</h2>
<h3>Feiyang Ye, Baijiong Lin, Zhixiong Yue, Pengxin Guo, Qiao Xiao, Yu Zhang</h3>
<p>Meta learning with multiple objectives can be formulated as a Multi-Objective
Bi-Level optimization Problem (MOBLP) where the upper-level subproblem is to
solve several possible conflicting targets for the meta learner. However,
existing studies either apply an inefficient evolutionary algorithm or linearly
combine multiple objectives as a single-objective problem with the need to tune
combination weights. In this paper, we propose a unified gradient-based
Multi-Objective Meta Learning (MOML) framework and devise the first
gradient-based optimization algorithm to solve the MOBLP by alternatively
solving the lower-level and upper-level subproblems via the gradient descent
method and the gradient-based multi-objective optimization method,
respectively. Theoretically, we prove the convergence properties of the
proposed gradient-based optimization algorithm. Empirically, we show the
effectiveness of the proposed MOML framework in several meta learning problems,
including few-shot learning, neural architecture search, domain adaptation, and
multi-task learning.
</p>
<a href="http://arxiv.org/abs/2102.07121" target="_blank">arXiv:2102.07121</a> [<a href="http://arxiv.org/pdf/2102.07121" target="_blank">pdf</a>]

<h2>Self Regulated Learning Mechanism for Data Efficient Knowledge Distillation. (arXiv:2102.07125v1 [cs.LG])</h2>
<h3>Sourav Mishra, Suresh Sundaram</h3>
<p>Existing methods for distillation use the conventional training approach
where all samples participate equally in the process and are thus highly
inefficient in terms of data utilization. In this paper, a novel data-efficient
approach to transfer the knowledge from a teacher model to a student model is
presented. Here, the teacher model uses self-regulation to select appropriate
samples for training and identifies their significance in the process. During
distillation, the significance information can be used along with the
soft-targets to supervise the students. Depending on the use of self-regulation
and sample significance information in supervising the knowledge transfer
process, three types of distillations are proposed - significance-based,
regulated, and hybrid, respectively. Experiments on benchmark datasets show
that the proposed methods achieve similar performance as other state-of-the-art
methods for knowledge distillation while utilizing a significantly less number
of samples.
</p>
<a href="http://arxiv.org/abs/2102.07125" target="_blank">arXiv:2102.07125</a> [<a href="http://arxiv.org/pdf/2102.07125" target="_blank">pdf</a>]

<h2>Perceptually Constrained Adversarial Attacks. (arXiv:2102.07140v1 [cs.LG])</h2>
<h3>Muhammad Zaid Hameed, Andras Gyorgy</h3>
<p>Motivated by previous observations that the usually applied $L_p$ norms
($p=1,2,\infty$) do not capture the perceptual quality of adversarial examples
in image classification, we propose to replace these norms with the structural
similarity index (SSIM) measure, which was developed originally to measure the
perceptual similarity of images. Through extensive experiments with
adversarially trained classifiers for MNIST and CIFAR-10, we demonstrate that
our SSIM-constrained adversarial attacks can break state-of-the-art
adversarially trained classifiers and achieve similar or larger success rate
than the elastic net attack, while consistently providing adversarial images of
better perceptual quality. Utilizing SSIM to automatically identify and
disallow adversarial images of low quality, we evaluate the performance of
several defense schemes in a perceptually much more meaningful way than was
done previously in the literature.
</p>
<a href="http://arxiv.org/abs/2102.07140" target="_blank">arXiv:2102.07140</a> [<a href="http://arxiv.org/pdf/2102.07140" target="_blank">pdf</a>]

<h2>Manifold Density Estimation via Generalized Dequantization. (arXiv:2102.07143v1 [stat.ML])</h2>
<h3>James A. Brofos, Marcus A. Brubaker, Roy R. Lederman</h3>
<p>Density estimation is an important technique for characterizing distributions
given observations. Much existing research on density estimation has focused on
cases wherein the data lies in a Euclidean space. However, some kinds of data
are not well-modeled by supposing that their underlying geometry is Euclidean.
Instead, it can be useful to model such data as lying on a {\it manifold} with
some known structure. For instance, some kinds of data may be known to lie on
the surface of a sphere. We study the problem of estimating densities on
manifolds. We propose a method, inspired by the literature on "dequantization,"
which we interpret through the lens of a coordinate transformation of an
ambient Euclidean space and a smooth manifold of interest. Using methods from
normalizing flows, we apply this method to the dequantization of smooth
manifold structures in order to model densities on the sphere, tori, and the
orthogonal group.
</p>
<a href="http://arxiv.org/abs/2102.07143" target="_blank">arXiv:2102.07143</a> [<a href="http://arxiv.org/pdf/2102.07143" target="_blank">pdf</a>]

<h2>FedU: A Unified Framework for Federated Multi-Task Learning with Laplacian Regularization. (arXiv:2102.07148v1 [cs.LG])</h2>
<h3>Canh T. Dinh, Tung T. Vu, Nguyen H. Tran, Minh N. Dao, Hongyu Zhang</h3>
<p>Federated multi-task learning (FMTL) has emerged as a natural choice to
capture the statistical diversity among the clients in federated learning. To
unleash the potential of FMTL beyond statistical diversity, we formulate a new
FMTL problem FedU using Laplacian regularization, which can explicitly leverage
relationships among the clients for multi-task learning. We first show that
FedU provides a unified framework covering a wide range of problems such as
conventional federated learning, personalized federated learning, few-shot
learning, and stratified model learning. We then propose algorithms including
both communication-centralized and decentralized schemes to learn optimal
models of FedU. Theoretically, we show that the convergence rates of both
FedU's algorithms achieve linear speedup for strongly convex and sublinear
speedup of order $1/2$ for nonconvex objectives. While the analysis of FedU is
applicable to both strongly convex and nonconvex loss functions, the
conventional FMTL algorithm MOCHA, which is based on CoCoA framework, is only
applicable to convex case. Experimentally, we verify that FedU outperforms the
vanilla FedAvg, MOCHA, as well as pFedMe and Per-FedAvg in personalized
federated learning.
</p>
<a href="http://arxiv.org/abs/2102.07148" target="_blank">arXiv:2102.07148</a> [<a href="http://arxiv.org/pdf/2102.07148" target="_blank">pdf</a>]

<h2>ChipNet: Budget-Aware Pruning with Heaviside Continuous Approximations. (arXiv:2102.07156v1 [cs.CV])</h2>
<h3>Rishabh Tiwari, Udbhav Bamba, Arnav Chavan, Deepak K. Gupta</h3>
<p>Structured pruning methods are among the effective strategies for extracting
small resource-efficient convolutional neural networks from their dense
counterparts with minimal loss in accuracy. However, most existing methods
still suffer from one or more limitations, that include 1) the need for
training the dense model from scratch with pruning-related parameters embedded
in the architecture, 2) requiring model-specific hyperparameter settings, 3)
inability to include budget-related constraint in the training process, and 4)
instability under scenarios of extreme pruning. In this paper, we present
ChipNet, a deterministic pruning strategy that employs continuous Heaviside
function and a novel crispness loss to identify a highly sparse network out of
an existing dense network. Our choice of continuous Heaviside function is
inspired by the field of design optimization, where the material distribution
task is posed as a continuous optimization problem, but only discrete values (0
or 1) are practically feasible and expected as final outcomes. Our approach's
flexible design facilitates its use with different choices of budget
constraints while maintaining stability for very low target budgets.
Experimental results show that ChipNet outperforms state-of-the-art structured
pruning methods by remarkable margins of up to 16.1% in terms of accuracy.
Further, we show that the masks obtained with ChipNet are transferable across
datasets. For certain cases, it was observed that masks transferred from a
model trained on feature-rich teacher dataset provide better performance on the
student dataset than those obtained by directly pruning on the student data
itself.
</p>
<a href="http://arxiv.org/abs/2102.07156" target="_blank">arXiv:2102.07156</a> [<a href="http://arxiv.org/pdf/2102.07156" target="_blank">pdf</a>]

<h2>Distributed Second Order Methods with Fast Rates and Compressed Communication. (arXiv:2102.07158v1 [cs.LG])</h2>
<h3>Rustem Islamov, Xun Qian, Peter Richt&#xe1;rik</h3>
<p>We develop several new communication-efficient second-order methods for
distributed optimization. Our first method, NEWTON-STAR, is a variant of
Newton's method from which it inherits its fast local quadratic rate. However,
unlike Newton's method, NEWTON-STAR enjoys the same per iteration communication
cost as gradient descent. While this method is impractical as it relies on the
use of certain unknown parameters characterizing the Hessian of the objective
function at the optimum, it serves as the starting point which enables us
design practical variants thereof with strong theoretical guarantees. In
particular, we design a stochastic sparsification strategy for learning the
unknown parameters in an iterative fashion in a communication efficient manner.
Applying this strategy to NEWTON-STAR leads to our next method, NEWTON-LEARN,
for which we prove local linear and superlinear rates independent of the
condition number. When applicable, this method can have dramatically superior
convergence behavior when compared to state-of-the-art methods. Finally, we
develop a globalization strategy using cubic regularization which leads to our
next method, CUBIC-NEWTON-LEARN, for which we prove global sublinear and linear
convergence rates, and a fast superlinear rate. Our results are supported with
experimental results on real datasets, and show several orders of magnitude
improvement on baseline and state-of-the-art methods in terms of communication
complexity.
</p>
<a href="http://arxiv.org/abs/2102.07158" target="_blank">arXiv:2102.07158</a> [<a href="http://arxiv.org/pdf/2102.07158" target="_blank">pdf</a>]

<h2>Adversarial Attack on Network Embeddings via Supervised Network Poisoning. (arXiv:2102.07164v1 [cs.LG])</h2>
<h3>Viresh Gupta, Tanmoy Chakraborty</h3>
<p>Learning low-level node embeddings using techniques from network
representation learning is useful for solving downstream tasks such as node
classification and link prediction. An important consideration in such
applications is the robustness of the embedding algorithms against adversarial
attacks, which can be examined by performing perturbation on the original
network. An efficient perturbation technique can degrade the performance of
network embeddings on downstream tasks. In this paper, we study network
embedding algorithms from an adversarial point of view and observe the effect
of poisoning the network on downstream tasks. We propose VIKING, a supervised
network poisoning strategy that outperforms the state-of-the-art poisoning
methods by upto 18% on the original network structure. We also extend VIKING to
a semi-supervised attack setting and show that it is comparable to its
supervised counterpart.
</p>
<a href="http://arxiv.org/abs/2102.07164" target="_blank">arXiv:2102.07164</a> [<a href="http://arxiv.org/pdf/2102.07164" target="_blank">pdf</a>]

<h2>Corrective Shared Autonomy for Addressing Task Variability. (arXiv:2102.07165v1 [cs.RO])</h2>
<h3>Michael Hagenow, Emmanuel Senft, Robert Radwin, Michael Gleicher, Bilge Mutlu, Michael Zinn</h3>
<p>Many tasks, particularly those involving interaction with the environment,
are characterized by high variability, making robotic autonomy difficult. One
flexible solution is to introduce the input of a human with superior experience
and cognitive abilities as part of a shared autonomy policy. However, current
methods for shared autonomy are not designed to address the wide range of
necessary corrections (e.g., positions, forces, execution rate, etc.) that the
user may need to provide to address task variability. In this paper, we present
corrective shared autonomy, where users provide corrections to key robot state
variables on top of an otherwise autonomous task model. We provide an
instantiation of this shared autonomy paradigm and demonstrate its viability
and benefits such as low user effort and physical demand via a system-level
user study on three tasks involving variability situated in aircraft
manufacturing.
</p>
<a href="http://arxiv.org/abs/2102.07165" target="_blank">arXiv:2102.07165</a> [<a href="http://arxiv.org/pdf/2102.07165" target="_blank">pdf</a>]

<h2>The Predictive Normalized Maximum Likelihood for Over-parameterized Linear Regression with Norm Constraint: Regret and Double Descent. (arXiv:2102.07181v1 [cs.LG])</h2>
<h3>Koby Bibas, Meir Feder</h3>
<p>A fundamental tenet of learning theory is that a trade-off exists between the
complexity of a prediction rule and its ability to generalize. The
double-decent phenomenon shows that modern machine learning models do not obey
this paradigm: beyond the interpolation limit, the test error declines as model
complexity increases. We investigate over-parameterization in linear regression
using the recently proposed predictive normalized maximum likelihood (pNML)
learner which is the min-max regret solution for individual data. We derive an
upper bound of its regret and show that if the test sample lies mostly in a
subspace spanned by the eigenvectors associated with the large eigenvalues of
the empirical correlation matrix of the training data, the model generalizes
despite its over-parameterized nature. We demonstrate the use of the pNML
regret as a point-wise learnability measure on synthetic data and that it can
successfully predict the double-decent phenomenon using the UCI dataset.
</p>
<a href="http://arxiv.org/abs/2102.07181" target="_blank">arXiv:2102.07181</a> [<a href="http://arxiv.org/pdf/2102.07181" target="_blank">pdf</a>]

<h2>Relation-aware Graph Attention Model With Adaptive Self-adversarial Training. (arXiv:2102.07186v1 [cs.LG])</h2>
<h3>Xiao Qin, Nasrullah Sheikh, Berthold Reinwald, Lingfei Wu</h3>
<p>This paper describes an end-to-end solution for the relationship prediction
task in heterogeneous, multi-relational graphs. We particularly address two
building blocks in the pipeline, namely heterogeneous graph representation
learning and negative sampling. Existing message passing-based graph neural
networks use edges either for graph traversal and/or selection of message
encoding functions. Ignoring the edge semantics could have severe repercussions
on the quality of embeddings, especially when dealing with two nodes having
multiple relations. Furthermore, the expressivity of the learned representation
depends on the quality of negative samples used during training. Although
existing hard negative sampling techniques can identify challenging negative
relationships for optimization, new techniques are required to control false
negatives during training as false negatives could corrupt the learning
process. To address these issues, first, we propose RelGNN -- a message
passing-based heterogeneous graph attention model. In particular, RelGNN
generates the states of different relations and leverages them along with the
node states to weigh the messages. RelGNN also adopts a self-attention
mechanism to balance the importance of attribute features and topological
features for generating the final entity embeddings. Second, we introduce a
parameter-free negative sampling technique -- adaptive self-adversarial (ASA)
negative sampling. ASA reduces the false-negative rate by leveraging positive
relationships to effectively guide the identification of true negative samples.
Our experimental evaluation demonstrates that RelGNN optimized by ASA for
relationship prediction improves state-of-the-art performance across
established benchmarks as well as on a real industrial dataset.
</p>
<a href="http://arxiv.org/abs/2102.07186" target="_blank">arXiv:2102.07186</a> [<a href="http://arxiv.org/pdf/2102.07186" target="_blank">pdf</a>]

<h2>Think Global and Act Local: Bayesian Optimisation over High-Dimensional Categorical and Mixed Search Spaces. (arXiv:2102.07188v1 [stat.ML])</h2>
<h3>Xingchen Wan, Vu Nguyen, Huong Ha, Binxin Ru, Cong Lu, Michael A. Osborne</h3>
<p>High-dimensional black-box optimisation remains an important yet notoriously
challenging problem. Despite the success of Bayesian optimisation methods on
continuous domains, domains that are categorical, or that mix continuous and
categorical variables, remain challenging. We propose a novel solution -- we
combine local optimisation with a tailored kernel design, effectively handling
high-dimensional categorical and mixed search spaces, whilst retaining sample
efficiency. We further derive convergence guarantee for the proposed approach.
Finally, we demonstrate empirically that our method outperforms the current
baselines on a variety of synthetic and real-world tasks in terms of
performance, computational costs, or both.
</p>
<a href="http://arxiv.org/abs/2102.07188" target="_blank">arXiv:2102.07188</a> [<a href="http://arxiv.org/pdf/2102.07188" target="_blank">pdf</a>]

<h2>Improved Bengali Image Captioning via deep convolutional neural network based encoder-decoder model. (arXiv:2102.07192v1 [cs.CV])</h2>
<h3>Mohammad Faiyaz Khan, S.M. Sadiq-Ur-Rahman Shifath, Md. Saiful Islam</h3>
<p>Image Captioning is an arduous task of producing syntactically and
semantically correct textual descriptions of an image in natural language with
context related to the image. Existing notable pieces of research in Bengali
Image Captioning (BIC) are based on encoder-decoder architecture. This paper
presents an end-to-end image captioning system utilizing a multimodal
architecture by combining a one-dimensional convolutional neural network (CNN)
to encode sequence information with a pre-trained ResNet-50 model image encoder
for extracting region-based visual features. We investigate our approach's
performance on the BanglaLekhaImageCaptions dataset using the existing
evaluation metrics and perform a human evaluation for qualitative analysis.
Experiments show that our approach's language encoder captures the fine-grained
information in the caption, and combined with the image features, it generates
accurate and diversified caption. Our work outperforms all the existing BIC
works and achieves a new state-of-the-art (SOTA) performance by scoring 0.651
on BLUE-1, 0.572 on CIDEr, 0.297 on METEOR, 0.434 on ROUGE, and 0.357 on SPICE.
</p>
<a href="http://arxiv.org/abs/2102.07192" target="_blank">arXiv:2102.07192</a> [<a href="http://arxiv.org/pdf/2102.07192" target="_blank">pdf</a>]

<h2>Human-Robot Handshaking: A Review. (arXiv:2102.07193v1 [cs.RO])</h2>
<h3>Vignesh Prasad, Ruth Stock-Homburg, Jan Peters</h3>
<p>For some years now, the use of social, anthropomorphic robots in various
situations has been on the rise. These are robots developed to interact with
humans and are equipped with corresponding extremities. They already support
human users in various industries, such as retail, gastronomy, hotels,
education and healthcare. During such Human-Robot Interaction (HRI) scenarios,
physical touch plays a central role in the various applications of social
robots as interactive non-verbal behaviour is a key factor in making the
interaction more natural. Shaking hands is a simple, natural interaction used
commonly in many social contexts and is seen as a symbol of greeting, farewell
and congratulations. In this paper, we take a look at the existing state of
Human-Robot Handshaking research, categorise the works based on their focus
areas, draw out the major findings of these areas while analysing their
pitfalls. We mainly see that some form of synchronisation exists during the
different phases of the interaction. In addition to this, we also find that
additional factors like gaze, voice facial expressions etc. can affect the
perception of a robotic handshake and that internal factors like personality
and mood can affect the way in which handshaking behaviours are executed by
humans. Based on the findings and insights, we finally discuss possible ways
forward for research on such physically interactive behaviours.
</p>
<a href="http://arxiv.org/abs/2102.07193" target="_blank">arXiv:2102.07193</a> [<a href="http://arxiv.org/pdf/2102.07193" target="_blank">pdf</a>]

<h2>Knowledge Graph Embedding using Graph Convolutional Networks with Relation-Aware Attention. (arXiv:2102.07200v1 [cs.LG])</h2>
<h3>Nasrullah Sheikh, Xiao Qin, Berthold Reinwald, Christoph Miksovic, Thomas Gschwind, Paolo Scotton</h3>
<p>Knowledge graph embedding methods learn embeddings of entities and relations
in a low dimensional space which can be used for various downstream machine
learning tasks such as link prediction and entity matching. Various graph
convolutional network methods have been proposed which use different types of
information to learn the features of entities and relations. However, these
methods assign the same weight (importance) to the neighbors when aggregating
the information, ignoring the role of different relations with the neighboring
entities. To this end, we propose a relation-aware graph attention model that
leverages relation information to compute different weights to the neighboring
nodes for learning embeddings of entities and relations. We evaluate our
proposed approach on link prediction and entity matching tasks. Our
experimental results on link prediction on three datasets (one proprietary and
two public) and results on unsupervised entity matching on one proprietary
dataset demonstrate the effectiveness of the relation-aware attention.
</p>
<a href="http://arxiv.org/abs/2102.07200" target="_blank">arXiv:2102.07200</a> [<a href="http://arxiv.org/pdf/2102.07200" target="_blank">pdf</a>]

<h2>Sample Efficient Subspace-based Representations for Nonlinear Meta-Learning. (arXiv:2102.07206v1 [cs.LG])</h2>
<h3>Halil Ibrahim Gulluk, Yue Sun, Samet Oymak, Maryam Fazel</h3>
<p>Constructing good representations is critical for learning complex tasks in a
sample efficient manner. In the context of meta-learning, representations can
be constructed from common patterns of previously seen tasks so that a future
task can be learned quickly. While recent works show the benefit of
subspace-based representations, such results are limited to linear-regression
tasks. This work explores a more general class of nonlinear tasks with
applications ranging from binary classification, generalized linear models and
neural nets. We prove that subspace-based representations can be learned in a
sample-efficient manner and provably benefit future tasks in terms of sample
complexity. Numerical results verify the theoretical predictions in
classification and neural-network regression tasks.
</p>
<a href="http://arxiv.org/abs/2102.07206" target="_blank">arXiv:2102.07206</a> [<a href="http://arxiv.org/pdf/2102.07206" target="_blank">pdf</a>]

<h2>Reversible Action Design for Combinatorial Optimization with Reinforcement Learning. (arXiv:2102.07210v1 [cs.LG])</h2>
<h3>Fan Yao, Renqin Cai, Hongning Wang</h3>
<p>Combinatorial optimization problem (COP) over graphs is a fundamental
challenge in optimization. Reinforcement learning (RL) has recently emerged as
a new framework to tackle these problems and has demonstrated promising
results. However, most RL solutions employ a greedy manner to construct the
solution incrementally, thus inevitably pose unnecessary dependency on action
sequences and need a lot of problem-specific designs. We propose a general RL
framework that not only exhibits state-of-the-art empirical performance but
also generalizes to a variety class of COPs. Specifically, we define state as a
solution to a problem instance and action as a perturbation to this solution.
We utilize graph neural networks (GNN) to extract latent representations for
given problem instances for state-action encoding, and then apply deep
Q-learning to obtain a policy that gradually refines the solution by flipping
or swapping vertex labels. Experiments are conducted on Maximum $k$-Cut and
Traveling Salesman Problem and performance improvement is achieved against a
set of learning-based and heuristic baselines.
</p>
<a href="http://arxiv.org/abs/2102.07210" target="_blank">arXiv:2102.07210</a> [<a href="http://arxiv.org/pdf/2102.07210" target="_blank">pdf</a>]

<h2>Efficient Designs of SLOPE Penalty Sequences in Finite Dimension. (arXiv:2102.07211v1 [stat.ML])</h2>
<h3>Yiliang Zhang, Zhiqi Bu</h3>
<p>In linear regression, SLOPE is a new convex analysis method that generalizes
the Lasso via the sorted L1 penalty: larger fitted coefficients are penalized
more heavily. This magnitude-dependent regularization requires an input of
penalty sequence $\lambda$, instead of a scalar penalty as in the Lasso case,
thus making the design extremely expensive in computation. In this paper, we
propose two efficient algorithms to design the possibly high-dimensional SLOPE
penalty, in order to minimize the mean squared error. For Gaussian data
matrices, we propose a first order Projected Gradient Descent (PGD) under the
Approximate Message Passing regime. For general data matrices, we present a
zero-th order Coordinate Descent (CD) to design a sub-class of SLOPE, referred
to as the k-level SLOPE. Our CD allows a useful trade-off between the accuracy
and the computation speed. We demonstrate the performance of SLOPE with our
designs via extensive experiments on synthetic data and real-world datasets.
</p>
<a href="http://arxiv.org/abs/2102.07211" target="_blank">arXiv:2102.07211</a> [<a href="http://arxiv.org/pdf/2102.07211" target="_blank">pdf</a>]

<h2>Why Talking about ethics is not enough: a proposal for Fintech's AI ethics. (arXiv:2102.07213v1 [cs.AI])</h2>
<h3>Cristina Godoy Bernardo de Oliveira, Evandro Eduardo Seron Ruiz</h3>
<p>As the potential applications of Artificial Intelligence (AI) in the
financial sector increases, ethical issues become gradually latent. The
distrust of individuals, social groups, and governments about the risks arising
from Fintech's activities is growing. Due to this scenario, the preparation of
recommendations and Ethics Guidelines is increasing and the risks of being
chosen the principles and ethical values most appropriate to companies are
high. Thus, this exploratory research aims to analyze the benefits of the
application of the stakeholder theory and the idea of Social License to build
an environment of trust and for the realization of ethical principles by
Fintech. The formation of a Fintech association for the creation of a Social
License will allow early-stage Fintech to participate from the beginning of its
activities in the elaboration of a dynamic ethical code and with the
participation of stakeholders.
</p>
<a href="http://arxiv.org/abs/2102.07213" target="_blank">arXiv:2102.07213</a> [<a href="http://arxiv.org/pdf/2102.07213" target="_blank">pdf</a>]

<h2>Large-Scale Meta-Learning with Continual Trajectory Shifting. (arXiv:2102.07215v1 [cs.LG])</h2>
<h3>Jaewoong Shin, Hae Beom Lee, Boqing Gong, Sung Ju Hwang</h3>
<p>Meta-learning of shared initialization parameters has shown to be highly
effective in solving few-shot learning tasks. However, extending the framework
to many-shot scenarios, which may further enhance its practicality, has been
relatively overlooked due to the technical difficulties of meta-learning over
long chains of inner-gradient steps. In this paper, we first show that allowing
the meta-learners to take a larger number of inner gradient steps better
captures the structure of heterogeneous and large-scale task distributions,
thus results in obtaining better initialization points. Further, in order to
increase the frequency of meta-updates even with the excessively long
inner-optimization trajectories, we propose to estimate the required shift of
the task-specific parameters with respect to the change of the initialization
parameters. By doing so, we can arbitrarily increase the frequency of
meta-updates and thus greatly improve the meta-level convergence as well as the
quality of the learned initializations. We validate our method on a
heterogeneous set of large-scale tasks and show that the algorithm largely
outperforms the previous first-order meta-learning methods in terms of both
generalization performance and convergence, as well as multi-task learning and
fine-tuning baselines.
</p>
<a href="http://arxiv.org/abs/2102.07215" target="_blank">arXiv:2102.07215</a> [<a href="http://arxiv.org/pdf/2102.07215" target="_blank">pdf</a>]

<h2>Urban Metric Maps for Small Unmanned Aircraft Systems Motion Planning. (arXiv:2102.07218v1 [cs.RO])</h2>
<h3>Cosme A. Ochoa, Ella M. Atkins</h3>
<p>Low-altitude urban flight planning for small Unmanned Aircraft Systems (UAS)
requires accurate vehicle, environment maps, and risk models to assure flight
plans consider the urban landscape as well as airspace constraints. This paper
presents a suite of motion planning metrics designed for small UAS urban
flight. We define map-based and path-based metrics to holistically characterize
motion plan quality. Proposed metrics are examined in the context of
representative geometric, graph-based, and sampling-based motion planners
applied to a multicopter small UAS. A novel multi-objective heuristic is
proposed and applied for graph-based and sampling motion planners at four urban
UAS flight altitude layers. Monte Carlo case studies in a New York City urban
environment illustrate metric map properties and planner performance. Motion
plans are evaluated as a function of planning algorithm, location, range, and
flight altitude.
</p>
<a href="http://arxiv.org/abs/2102.07218" target="_blank">arXiv:2102.07218</a> [<a href="http://arxiv.org/pdf/2102.07218" target="_blank">pdf</a>]

<h2>Double-descent curves in neural networks: a new perspective using Gaussian processes. (arXiv:2102.07238v1 [stat.ML])</h2>
<h3>Ouns El Harzli, Guillermo Valle-P&#xe9;rez, Ard A. Louis</h3>
<p>Double-descent curves in neural networks describe the phenomenon that the
generalisation error initially descends with increasing parameters, then grows
after reaching an optimal number of parameters which is less than the number of
data points, but then descends again in the overparameterised regime. Here we
use a neural network Gaussian process (NNGP) which maps exactly to a fully
connected network (FCN) in the infinite width limit, combined with techniques
from random matrix theory, to calculate this generalisation behaviour, with a
particular focus on the overparameterised regime. We verify our predictions
with numerical simulations of the corresponding Gaussian process regressions.
An advantage of our NNGP approach is that the analytical calculations are
easier to interpret. We argue that neural network generalization performance
improves in the overparameterised regime precisely because that is where they
converge to their equivalent Gaussian process.
</p>
<a href="http://arxiv.org/abs/2102.07238" target="_blank">arXiv:2102.07238</a> [<a href="http://arxiv.org/pdf/2102.07238" target="_blank">pdf</a>]

<h2>Naturalizing Neuromorphic Vision Event Streams Using GANs. (arXiv:2102.07243v1 [cs.CV])</h2>
<h3>Dennis Robey, Wesley Thio, Herbert Iu, Jason Eshraghian</h3>
<p>Dynamic vision sensors are able to operate at high temporal resolutions
within resource constrained environments, though at the expense of capturing
static content. The sparse nature of event streams enables efficient downstream
processing tasks as they are suited for power-efficient spiking neural
networks. One of the challenges associated with neuromorphic vision is the lack
of interpretability of event streams. While most application use-cases do not
intend for the event stream to be visually interpreted by anything other than a
classification network, there is a lost opportunity to integrating these
sensors in spaces that conventional high-speed CMOS sensors cannot go. For
example, biologically invasive sensors such as endoscopes must fit within
stringent power budgets, which do not allow MHz-speeds of image integration.
While dynamic vision sensing can fill this void, the interpretation challenge
remains and will degrade confidence in clinical diagnostics. The use of
generative adversarial networks presents a possible solution to overcoming and
compensating for a vision chip's poor spatial resolution and lack of
interpretability. In this paper, we methodically apply the Pix2Pix network to
naturalize the event stream from spike-converted CIFAR-10 and Linnaeus 5
datasets. The quality of the network is benchmarked by performing image
classification of naturalized event streams, which converges to within 2.81% of
equivalent raw images, and an associated improvement over unprocessed event
streams by 13.19% for the CIFAR-10 and Linnaeus 5 datasets.
</p>
<a href="http://arxiv.org/abs/2102.07243" target="_blank">arXiv:2102.07243</a> [<a href="http://arxiv.org/pdf/2102.07243" target="_blank">pdf</a>]

<h2>Smoothness Matrices Beat Smoothness Constants: Better Communication Compression Techniques for Distributed Optimization. (arXiv:2102.07245v1 [cs.LG])</h2>
<h3>Mher Safaryan, Filip Hanzely, Peter Richt&#xe1;rik</h3>
<p>Large scale distributed optimization has become the default tool for the
training of supervised machine learning models with a large number of
parameters and training data. Recent advancements in the field provide several
mechanisms for speeding up the training, including {\em compressed
communication}, {\em variance reduction} and {\em acceleration}. However, none
of these methods is capable of exploiting the inherently rich data-dependent
smoothness structure of the local losses beyond standard smoothness constants.
In this paper, we argue that when training supervised models, {\em smoothness
matrices} -- information-rich generalizations of the ubiquitous smoothness
constants -- can and should be exploited for further dramatic gains, both in
theory and practice. In order to further alleviate the communication burden
inherent in distributed optimization, we propose a novel communication
sparsification strategy that can take full advantage of the smoothness matrices
associated with local losses. To showcase the power of this tool, we describe
how our sparsification technique can be adapted to three distributed
optimization algorithms -- DCGD, DIANA and ADIANA -- yielding significant
savings in terms of communication complexity. The new methods always outperform
the baselines, often dramatically so.
</p>
<a href="http://arxiv.org/abs/2102.07245" target="_blank">arXiv:2102.07245</a> [<a href="http://arxiv.org/pdf/2102.07245" target="_blank">pdf</a>]

<h2>Responsibility Management through Responsibility Networks. (arXiv:2102.07246v1 [cs.AI])</h2>
<h3>Ruijun Chen, Jiong Qiu, Xuejiao Tang</h3>
<p>The safety management is critically important in the workplace.
Unfortunately, responsibility issues therein such as inefficient supervision,
poor evaluation and inadequate perception have not been properly addressed. To
this end, in this paper, we deploy the Internet of Responsibilities (IoR) for
responsibility management. Through the building of IoR framework, hierarchical
responsibility management, automated responsibility evaluation at all level and
efficient responsibility perception are achieved. The practical deployment of
IoR system showed its effective responsibility management capability in various
workplaces.
</p>
<a href="http://arxiv.org/abs/2102.07246" target="_blank">arXiv:2102.07246</a> [<a href="http://arxiv.org/pdf/2102.07246" target="_blank">pdf</a>]

<h2>Reinforcement Learning for IoT Security: A Comprehensive Survey. (arXiv:2102.07247v1 [cs.LG])</h2>
<h3>Aashma Uprety, Danda B. Rawat</h3>
<p>The number of connected smart devices has been increasing exponentially for
different Internet-of-Things (IoT) applications. Security has been a long run
challenge in the IoT systems which has many attack vectors, security flaws and
vulnerabilities. Securing billions of B connected devices in IoT is a must task
to realize the full potential of IoT applications. Recently, researchers have
proposed many security solutions for IoT. Machine learning has been proposed as
one of the emerging solutions for IoT security and Reinforcement learning is
gaining more popularity for securing IoT systems. Reinforcement learning,
unlike other machine learning techniques, can learn the environment by having
minimum information about the parameters to be learned. It solves the
optimization problem by interacting with the environment adapting the
parameters on the fly. In this paper, we present an comprehensive survey of
different types of cyber-attacks against different IoT systems and then we
present reinforcement learning and deep reinforcement learning based security
solutions to combat those different types of attacks in different IoT systems.
Furthermore, we present the Reinforcement learning for securing CPS systems
(i.e., IoT with feedback and control) such as smart grid and smart
transportation system. The recent important attacks and countermeasures using
reinforcement learning B in IoT are also summarized in the form of tables. With
this paper, readers can have a more thorough understanding of IoT security
attacks and countermeasures using Reinforcement Learning, as well as research
trends in this area.
</p>
<a href="http://arxiv.org/abs/2102.07247" target="_blank">arXiv:2102.07247</a> [<a href="http://arxiv.org/pdf/2102.07247" target="_blank">pdf</a>]

<h2>Asymptotically Optimal Strategies For Combinatorial Semi-Bandits in Polynomial Time. (arXiv:2102.07254v1 [stat.ML])</h2>
<h3>Thibaut Cuvelier, Richard Combes, Eric Gourdin</h3>
<p>We consider combinatorial semi-bandits with uncorrelated Gaussian rewards. In
this article, we propose the first method, to the best of our knowledge, that
enables to compute the solution of the Graves-Lai optimization problem in
polynomial time for many combinatorial structures of interest. In turn, this
immediately yields the first known approach to implement asymptotically optimal
algorithms in polynomial time for combinatorial semi-bandits.
</p>
<a href="http://arxiv.org/abs/2102.07254" target="_blank">arXiv:2102.07254</a> [<a href="http://arxiv.org/pdf/2102.07254" target="_blank">pdf</a>]

<h2>Learning-Driven Decision Mechanisms in Physical Layer: Facts, Challenges, and Remedies. (arXiv:2102.07258v1 [cs.LG])</h2>
<h3>Selen Gecgel, Caner Goztepe, Gunes Karabulut Kurt, Halim Yanikomeroglu</h3>
<p>Future communication systems must include extensive capabilities as they will
embrace a vast diversity of devices and applications. Conventional physical
layer decision mechanisms may not meet these requirements due to the frequent
use of impracticable and oversimplifying assumptions that lead to a trade-off
between complexity and efficiency. By utilizing past experiences,
learning-driven designs are promising solutions to present a resilient decision
mechanism and provide a quick response even under exceptional circumstances.
The corresponding design solutions should evolve following the learning-driven
paradigms that offer increased autonomy and robustness. This evolution must
take place by considering the facts of real-world systems without restraining
assumptions. This paper introduces the common assumptions in the physical layer
to highlight their discrepancies with practical systems. As a solution,
learning algorithms are examined by considering implementation steps and
challenges. Additionally, these issues are discussed through a real-time case
study that uses software-defined radio nodes, demonstrating the potential
performance improvement. A remedial perspective is presented to guide future
studies.
</p>
<a href="http://arxiv.org/abs/2102.07258" target="_blank">arXiv:2102.07258</a> [<a href="http://arxiv.org/pdf/2102.07258" target="_blank">pdf</a>]

<h2>Exploring Adversarial Robustness of Deep Metric Learning. (arXiv:2102.07265v1 [cs.LG])</h2>
<h3>Thomas Kobber Panum, Zi Wang, Pengyu Kan, Earlence Fernandes, Somesh Jha</h3>
<p>Deep Metric Learning (DML), a widely-used technique, involves learning a
distance metric between pairs of samples. DML uses deep neural architectures to
learn semantic embeddings of the input, where the distance between similar
examples is small while dissimilar ones are far apart. Although the underlying
neural networks produce good accuracy on naturally occurring samples, they are
vulnerable to adversarially-perturbed samples that reduce performance. We take
a first step towards training robust DML models and tackle the primary
challenge of the metric losses being dependent on the samples in a mini-batch,
unlike standard losses that only depend on the specific input-output pair. We
analyze this dependence effect and contribute a robust optimization
formulation. Using experiments on three commonly-used DML datasets, we
demonstrate 5-76 fold increases in adversarial accuracy, and outperform an
existing DML model that sought out to be robust.
</p>
<a href="http://arxiv.org/abs/2102.07265" target="_blank">arXiv:2102.07265</a> [<a href="http://arxiv.org/pdf/2102.07265" target="_blank">pdf</a>]

<h2>Sparse Attention Guided Dynamic Value Estimation for Single-Task Multi-Scene Reinforcement Learning. (arXiv:2102.07266v1 [cs.LG])</h2>
<h3>Jaskirat Singh, Liang Zheng</h3>
<p>Training deep reinforcement learning agents on environments with multiple
levels / scenes from the same task, has become essential for many applications
aiming to achieve generalization and domain transfer from simulation to the
real world. While such a strategy is helpful with generalization, the use of
multiple scenes significantly increases the variance of samples collected for
policy gradient computations. Current methods, effectively continue to view
this collection of scenes as a single Markov decision process (MDP), and thus
learn a scene-generic value function V(s). However, we argue that the sample
variance for a multi-scene environment is best minimized by treating each scene
as a distinct MDP, and then learning a joint value function V(s,M) dependent on
both state s and MDP M. We further demonstrate that the true joint value
function for a multi-scene environment, follows a multi-modal distribution
which is not captured by traditional CNN / LSTM based critic networks. To this
end, we propose a dynamic value estimation (DVE) technique, which approximates
the true joint value function through a sparse attention mechanism over
multiple value function hypothesis / modes. The resulting agent not only shows
significant improvements in the final reward score across a range of OpenAI
ProcGen environments, but also exhibits enhanced navigation efficiency and
provides an implicit mechanism for unsupervised state-space skill
decomposition.
</p>
<a href="http://arxiv.org/abs/2102.07266" target="_blank">arXiv:2102.07266</a> [<a href="http://arxiv.org/pdf/2102.07266" target="_blank">pdf</a>]

<h2>3D Fully Convolutional Neural Networks with Intersection Over Union Loss for Crop Mapping from Multi-Temporal Satellite Images. (arXiv:2102.07280v1 [cs.CV])</h2>
<h3>Sina Mohammadi, Mariana Belgiu, Alfred Stein</h3>
<p>Information on cultivated crops is relevant for a large number of food
security studies. Different scientific efforts are dedicated to generate this
information from remote sensing images by means of machine learning methods.
Unfortunately, these methods do not account for the spatial-temporal
relationships inherent in remote sensing images. In our paper, we explore the
capability of a 3D Fully Convolutional Neural Network (FCN) to map crop types
from multi-temporal images. In addition, we propose the Intersection Over Union
(IOU) loss function for increasing the overlap between the predicted classes
and ground truth data. The proposed method was applied to identify soybean and
corn from a study area situated in the US corn belt using multi-temporal
Landsat images. The study shows that our method outperforms related methods,
obtaining a Kappa coefficient of 90.8%. We conclude that using the IOU Loss
function provides a superior choice to learn individual crop types.
</p>
<a href="http://arxiv.org/abs/2102.07280" target="_blank">arXiv:2102.07280</a> [<a href="http://arxiv.org/pdf/2102.07280" target="_blank">pdf</a>]

<h2>Robust Classification using Hidden Markov Models and Mixtures of Normalizing Flows. (arXiv:2102.07284v1 [cs.LG])</h2>
<h3>Anubhab Ghosh, Antoine Honor&#xe9;, Dong Liu, Gustav Eje Henter, Saikat Chatterjee</h3>
<p>We test the robustness of a maximum-likelihood (ML) based classifier where
sequential data as observation is corrupted by noise. The hypothesis is that a
generative model, that combines the state transitions of a hidden Markov model
(HMM) and the neural network based probability distributions for the hidden
states of the HMM, can provide a robust classification performance. The
combined model is called normalizing-flow mixture model based HMM (NMM-HMM). It
can be trained using a combination of expectation-maximization (EM) and
backpropagation. We verify the improved robustness of NMM-HMM classifiers in an
application to speech recognition.
</p>
<a href="http://arxiv.org/abs/2102.07284" target="_blank">arXiv:2102.07284</a> [<a href="http://arxiv.org/pdf/2102.07284" target="_blank">pdf</a>]

<h2>A Deep Adversarial Model for Suffix and Remaining Time Prediction of Event Sequences. (arXiv:2102.07298v1 [cs.LG])</h2>
<h3>Farbod Taymouri, Marcello La Rosa, Sarah M. Erfani</h3>
<p>Event suffix and remaining time prediction are sequence to sequence learning
tasks. They have wide applications in different areas such as economics,
digital health, business process management and IT infrastructure monitoring.
Timestamped event sequences contain ordered events which carry at least two
attributes: the event's label and its timestamp. Suffix and remaining time
prediction are about obtaining the most likely continuation of event labels and
the remaining time until the sequence finishes, respectively. Recent deep
learning-based works for such predictions are prone to potentially large
prediction errors because of closed-loop training (i.e., the next event is
conditioned on the ground truth of previous events) and open-loop inference
(i.e., the next event is conditioned on previously predicted events). In this
work, we propose an encoder-decoder architecture for open-loop training to
advance the suffix and remaining time prediction of event sequences. To capture
the joint temporal dynamics of events, we harness the power of adversarial
learning techniques to boost prediction performance. We consider four real-life
datasets and three baselines in our experiments. The results show improvements
up to four times compared to the state of the art in suffix and remaining time
prediction of event sequences, specifically in the realm of business process
executions. We also show that the obtained improvements of adversarial training
are superior compared to standard training under the same experimental setup.
</p>
<a href="http://arxiv.org/abs/2102.07298" target="_blank">arXiv:2102.07298</a> [<a href="http://arxiv.org/pdf/2102.07298" target="_blank">pdf</a>]

<h2>Nearly Minimax Optimal Regret for Learning Infinite-horizon Average-reward MDPs with Linear Function Approximation. (arXiv:2102.07301v1 [cs.LG])</h2>
<h3>Yue Wu, Dongruo Zhou, Quanquan Gu</h3>
<p>We study reinforcement learning in an infinite-horizon average-reward setting
with linear function approximation, where the transition probability function
of the underlying Markov Decision Process (MDP) admits a linear form over a
feature mapping of the current state, action, and next state. We propose a new
algorithm UCRL2-VTR, which can be seen as an extension of the UCRL2 algorithm
with linear function approximation. We show that UCRL2-VTR with Bernstein-type
bonus can achieve a regret of $\tilde{O}(d\sqrt{DT})$, where $d$ is the
dimension of the feature mapping, $T$ is the horizon, and $\sqrt{D}$ is the
diameter of the MDP. We also prove a matching lower bound
$\tilde{\Omega}(d\sqrt{DT})$, which suggests that the proposed UCRL2-VTR is
minimax optimal up to logarithmic factors. To the best of our knowledge, our
algorithm is the first nearly minimax optimal RL algorithm with function
approximation in the infinite-horizon average-reward setting.
</p>
<a href="http://arxiv.org/abs/2102.07301" target="_blank">arXiv:2102.07301</a> [<a href="http://arxiv.org/pdf/2102.07301" target="_blank">pdf</a>]

<h2>CAP-GAN: Towards_Adversarial_Robustness_with_Cycle-consistent_Attentional_Purification. (arXiv:2102.07304v1 [cs.LG])</h2>
<h3>Mingu Kang, Trung Quang Tran, Seungju Cho, Daeyoung Kim</h3>
<p>Adversarial attack is aimed at fooling the target classifier with
imperceptible perturbation. Adversarial examples, which are carefully crafted
with a malicious purpose, can lead to erroneous predictions, resulting in
catastrophic accidents. To mitigate the effects of adversarial attacks, we
propose a novel purification model called CAP-GAN. CAP-GAN takes account of the
idea of pixel-level and feature-level consistency to achieve reasonable
purification under cycle-consistent learning. Specifically, we utilize the
guided attention module and knowledge distillation to convey meaningful
information to the purification model. Once a model is fully trained, inputs
would be projected into the purification model and transformed into clean-like
images. We vary the capacity of the adversary to argue the robustness against
various types of attack strategies. On the CIFAR-10 dataset, CAP-GAN
outperforms other pre-processing based defenses under both black-box and
white-box settings.
</p>
<a href="http://arxiv.org/abs/2102.07304" target="_blank">arXiv:2102.07304</a> [<a href="http://arxiv.org/pdf/2102.07304" target="_blank">pdf</a>]

<h2>Field Evaluations of A Deep Learning-based Intelligent Spraying Robot with Flow Control for Pear Orchards. (arXiv:2102.07313v1 [cs.RO])</h2>
<h3>Jaehwi Seol, Jeongeun Kim, Hyoung Il Son</h3>
<p>This paper proposes a variable flow control system in real time with deep
learning using the segmentation of fruit trees in a pear orchard. The flow rate
control in real time, undesired pressure fluctuation and theoretical modeling
may differ from those in the real world. Therefore, two types of preliminary
experiments were designed to examine the linear relationship of the flow rate
modeling. Through a preliminary experiment, the parameters of the pulse width
modulation (PWM) controller were optimized, and an actual field experiment was
conducted to confirm the performance of the variable flow rate control system.
As a result of the field experiment, the performance of the proposed system was
satisfactory, as it showed that it could reduce pesticide use and the risk of
pesticide exposure. Especially, since the field experiment was conducted in an
unstructured environment, the proposed variable flow control system is expected
to be sufficiently applicable to other orchards.
</p>
<a href="http://arxiv.org/abs/2102.07313" target="_blank">arXiv:2102.07313</a> [<a href="http://arxiv.org/pdf/2102.07313" target="_blank">pdf</a>]

<h2>The Role of Momentum Parameters in the Optimal Convergence of Adaptive Polyak's Heavy-ball Methods. (arXiv:2102.07314v1 [cs.LG])</h2>
<h3>Wei Tao, Sheng Long, Gaowei Wu, Qing Tao</h3>
<p>The adaptive stochastic gradient descent (SGD) with momentum has been widely
adopted in deep learning as well as convex optimization. In practice, the last
iterate is commonly used as the final solution to make decisions. However, the
available regret analysis and the setting of constant momentum parameters only
guarantee the optimal convergence of the averaged solution. In this paper, we
fill this theory-practice gap by investigating the convergence of the last
iterate (referred to as individual convergence), which is a more difficult task
than convergence analysis of the averaged solution. Specifically, in the
constrained convex cases, we prove that the adaptive Polyak's Heavy-ball (HB)
method, in which only the step size is updated using the exponential moving
average strategy, attains an optimal individual convergence rate of
$O(\frac{1}{\sqrt{t}})$, as opposed to the optimality of $O(\frac{\log t}{\sqrt
{t}})$ of SGD, where $t$ is the number of iterations. Our new analysis not only
shows how the HB momentum and its time-varying weight help us to achieve the
acceleration in convex optimization but also gives valuable hints how the
momentum parameters should be scheduled in deep learning. Empirical results on
optimizing convex functions and training deep networks validate the correctness
of our convergence analysis and demonstrate the improved performance of the
adaptive HB methods.
</p>
<a href="http://arxiv.org/abs/2102.07314" target="_blank">arXiv:2102.07314</a> [<a href="http://arxiv.org/pdf/2102.07314" target="_blank">pdf</a>]

<h2>A Global to Local Double Embedding Method for Multi-person Pose Estimation. (arXiv:2102.07318v1 [cs.CV])</h2>
<h3>Yiming Xu, Jiaxin Li, Yiheng Peng, Yan Ding, Hua-Liang Wei</h3>
<p>Multi-person pose estimation is a fundamental and challenging problem to many
computer vision tasks. Most existing methods can be broadly categorized into
two classes: top-down and bottom-up methods. Both of the two types of methods
involve two stages, namely, person detection and joints detection.
Conventionally, the two stages are implemented separately without considering
their interactions between them, and this may inevitably cause some issue
intrinsically. In this paper, we present a novel method to simplify the
pipeline by implementing person detection and joints detection simultaneously.
We propose a Double Embedding (DE) method to complete the multi-person pose
estimation task in a global-to-local way. DE consists of Global Embedding (GE)
and Local Embedding (LE). GE encodes different person instances and processes
information covering the whole image and LE encodes the local limbs
information. GE functions for the person detection in top-down strategy while
LE connects the rest joints sequentially which functions for joint grouping and
information processing in A bottom-up strategy. Based on LE, we design the
Mutual Refine Machine (MRM) to reduce the prediction difficulty in complex
scenarios. MRM can effectively realize the information communicating between
keypoints and further improve the accuracy. We achieve the competitive results
on benchmarks MSCOCO, MPII and CrowdPose, demonstrating the effectiveness and
generalization ability of our method.
</p>
<a href="http://arxiv.org/abs/2102.07318" target="_blank">arXiv:2102.07318</a> [<a href="http://arxiv.org/pdf/2102.07318" target="_blank">pdf</a>]

<h2>Regulating Greed Over Time in Multi-Armed Bandits. (arXiv:1505.05629v4 [stat.ML] UPDATED)</h2>
<h3>Stefano Trac&#xe0;, Cynthia Rudin, Weiyu Yan</h3>
<p>In retail, there are predictable yet dramatic time-dependent patterns in
customer behavior, such as periodic changes in the number of visitors, or
increases in customers just before major holidays. The current paradigm of
multi-armed bandit analysis does not take these known patterns into account.
This means that for applications in retail, where prices are fixed for periods
of time, current bandit algorithms will not suffice. This work provides a
remedy that takes the time-dependent patterns into account, and we show how
this remedy is implemented for the UCB, $\varepsilon$-greedy, and UCB-L
algorithms, and also through a new policy called the variable arm pool
algorithm. In the corrected methods, exploitation (greed) is regulated over
time, so that more exploitation occurs during higher reward periods, and more
exploration occurs in periods of low reward. In order to understand why regret
is reduced with the corrected methods, we present a set of bounds that provide
insight into why we would want to exploit during periods of high reward, and
discuss the impact on regret. Our proposed methods perform well in experiments,
and were inspired by a high-scoring entry in the Exploration and Exploitation 3
contest using data from Yahoo$!$ Front Page. That entry heavily used
time-series methods to regulate greed over time, which was substantially more
effective than other contextual bandit methods.
</p>
<a href="http://arxiv.org/abs/1505.05629" target="_blank">arXiv:1505.05629</a> [<a href="http://arxiv.org/pdf/1505.05629" target="_blank">pdf</a>]

<h2>FaSTrack: a Modular Framework for Fast and Guaranteed Safe Motion Planning. (arXiv:1703.07373v2 [cs.RO] UPDATED)</h2>
<h3>Sylvia L. Herbert, Mo Chen, SooJean Han, Somil Bansal, Jaime F. Fisac, Claire J. Tomlin</h3>
<p>Fast and safe navigation of dynamical systems through a priori unknown
cluttered environments is vital to many applications of autonomous systems.
However, trajectory planning for autonomous systems is computationally
intensive, often requiring simplified dynamics that sacrifice safety and
dynamic feasibility in order to plan efficiently. Conversely, safe trajectories
can be computed using more sophisticated dynamic models, but this is typically
too slow to be used for real-time planning. We propose a new algorithm
FaSTrack: Fast and Safe Tracking for High Dimensional systems. A path or
trajectory planner using simplified dynamics to plan quickly can be
incorporated into the FaSTrack framework, which provides a safety controller
for the vehicle along with a guaranteed tracking error bound. This bound
captures all possible deviations due to high dimensional dynamics and external
disturbances. Note that FaSTrack is modular and can be used with most current
path or trajectory planners. We demonstrate this framework using a 10D
nonlinear quadrotor model tracking a 3D path obtained from an RRT planner.
</p>
<a href="http://arxiv.org/abs/1703.07373" target="_blank">arXiv:1703.07373</a> [<a href="http://arxiv.org/pdf/1703.07373" target="_blank">pdf</a>]

<h2>Planning and Learning with Stochastic Action Sets. (arXiv:1805.02363v2 [cs.AI] UPDATED)</h2>
<h3>Craig Boutilier, Alon Cohen, Amit Daniely, Avinatan Hassidim, Yishay Mansour, Ofer Meshi, Martin Mladenov, Dale Schuurmans</h3>
<p>In many practical uses of reinforcement learning (RL) the set of actions
available at a given state is a random variable, with realizations governed by
an exogenous stochastic process. Somewhat surprisingly, the foundations for
such sequential decision processes have been unaddressed. In this work, we
formalize and investigate MDPs with stochastic action sets (SAS-MDPs) to
provide these foundations. We show that optimal policies and value functions in
this model have a structure that admits a compact representation. From an RL
perspective, we show that Q-learning with sampled action sets is sound. In
model-based settings, we consider two important special cases: when individual
actions are available with independent probabilities; and a sampling-based
model for unknown distributions. We develop poly-time value and policy
iteration methods for both cases; and in the first, we offer a poly-time linear
programming solution.
</p>
<a href="http://arxiv.org/abs/1805.02363" target="_blank">arXiv:1805.02363</a> [<a href="http://arxiv.org/pdf/1805.02363" target="_blank">pdf</a>]

<h2>Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees. (arXiv:1807.03858v5 [cs.LG] UPDATED)</h2>
<h3>Yuping Luo, Huazhe Xu, Yuanzhi Li, Yuandong Tian, Trevor Darrell, Tengyu Ma</h3>
<p>Model-based reinforcement learning (RL) is considered to be a promising
approach to reduce the sample complexity that hinders model-free RL. However,
the theoretical understanding of such methods has been rather limited. This
paper introduces a novel algorithmic framework for designing and analyzing
model-based RL algorithms with theoretical guarantees. We design a
meta-algorithm with a theoretical guarantee of monotone improvement to a local
maximum of the expected reward. The meta-algorithm iteratively builds a lower
bound of the expected reward based on the estimated dynamical model and sample
trajectories, and then maximizes the lower bound jointly over the policy and
the model. The framework extends the optimism-in-face-of-uncertainty principle
to non-linear dynamical models in a way that requires \textit{no explicit}
uncertainty quantification. Instantiating our framework with simplification
gives a variant of model-based RL algorithms Stochastic Lower Bounds
Optimization (SLBO). Experiments demonstrate that SLBO achieves
state-of-the-art performance when only one million or fewer samples are
permitted on a range of continuous control benchmark tasks.
</p>
<a href="http://arxiv.org/abs/1807.03858" target="_blank">arXiv:1807.03858</a> [<a href="http://arxiv.org/pdf/1807.03858" target="_blank">pdf</a>]

<h2>NEU: A Meta-Algorithm for Universal UAP-Invariant Feature Representation. (arXiv:1809.00082v3 [stat.ML] UPDATED)</h2>
<h3>Anastasis Kratsios, Cody Hyndman</h3>
<p>Effective feature representation is key to the predictive performance of any
algorithm. This paper introduces a meta-procedure, called Non-Euclidean
Upgrading (NEU), which learns feature maps that are expressive enough to embed
the universal approximation property (UAP) into most model classes while only
outputting feature maps that preserve any model class's UAP. We show that NEU
can learn any feature map with these two properties if that feature map is
asymptotically deformable into the identity. We also find that the
feature-representations learned by NEU are always submanifolds of the feature
space. NEU's properties are derived from a new deep neural model that is
universal amongst all orientation-preserving homeomorphisms on the input space.
We derive qualitative and quantitative approximation guarantees for this
architecture. We quantify the number of parameters required for this new
architecture to memorize any set of input-output pairs while simultaneously
fixing every point of the input space lying outside some compact set, and we
quantify the size of this set as a function of our model's depth. Moreover, we
show that no deep feed-forward network with commonly used activation function
has all these properties. NEU's performance is evaluated against competing
machine learning methods on various regression and dimension reduction tasks
both with financial and simulated data.
</p>
<a href="http://arxiv.org/abs/1809.00082" target="_blank">arXiv:1809.00082</a> [<a href="http://arxiv.org/pdf/1809.00082" target="_blank">pdf</a>]

<h2>General-Domain Truth Discovery via Average Proximity. (arXiv:1905.00629v3 [cs.AI] UPDATED)</h2>
<h3>Reshef Meir, Ofra Amir, Omer Ben-Porat, Tsviel Ben-Shabat, Gal Cohensius, Lirong Xia</h3>
<p>Truth discovery is a general name for a broad range of statistical methods
aimed to extract the correct answers to questions, based on multiple answers
coming from noisy sources. For example, workers in a crowdsourcing platform. In
this paper, we suggest a simple heuristic for estimating workers' competence
using average proximity to other workers. We prove that this estimates well the
actual competence level and enables separating high and low quality workers in
a wide spectrum of domains and statistical models.

We then design a simple proximity-based truth discovery algorithm (\PTD) that
weighs workers according to their average proximity. The answers for questions
may be of different forms such as real-valued, categorical, rankings, or other
complex labels, and \PTD can be combined with any existing aggregation function
or voting rule to improve their accuracy.

We demonstrate through an extensive empirical study on real and synthetic
data that \PTD and its iterative variants outperform other heuristics and
state-of-the-art truth discovery methods in the above domains.
</p>
<a href="http://arxiv.org/abs/1905.00629" target="_blank">arXiv:1905.00629</a> [<a href="http://arxiv.org/pdf/1905.00629" target="_blank">pdf</a>]

<h2>Occlusion-Robust MVO: Multimotion Estimation Through Occlusion Via Motion Closure. (arXiv:1905.05121v3 [cs.RO] UPDATED)</h2>
<h3>Kevin M. Judd, Jonathan D. Gammell</h3>
<p>Visual motion estimation is an integral and well-studied challenge in
autonomous navigation. Recent work has focused on addressing multimotion
estimation, which is especially challenging in highly dynamic environments.
Such environments not only comprise multiple, complex motions but also tend to
exhibit significant occlusion.

Previous work in object tracking focuses on maintaining the integrity of
object tracks but usually relies on specific appearance-based descriptors or
constrained motion models. These approaches are very effective in specific
applications but do not generalize to the full multimotion estimation problem.

This paper presents a pipeline for estimating multiple motions, including the
camera egomotion, in the presence of occlusions. This approach uses an
expressive motion prior to estimate the SE (3) trajectory of every motion in
the scene, even during temporary occlusions, and identify the reappearance of
motions through motion closure. The performance of this occlusion-robust
multimotion visual odometry (MVO) pipeline is evaluated on real-world data and
the Oxford Multimotion Dataset.
</p>
<a href="http://arxiv.org/abs/1905.05121" target="_blank">arXiv:1905.05121</a> [<a href="http://arxiv.org/pdf/1905.05121" target="_blank">pdf</a>]

<h2>On The Radon-Nikodym Spectral Approach With Optimal Clustering. (arXiv:1906.00460v14 [cs.LG] UPDATED)</h2>
<h3>Vladislav Gennadievich Malyshkin</h3>
<p>Problems of interpolation, classification, and clustering are considered. In
the tenets of Radon--Nikodym approach $\langle f(\mathbf{x})\psi^2 \rangle /
\langle\psi^2\rangle$, where the $\psi(\mathbf{x})$ is a linear function on
input attributes, all the answers are obtained from a generalized eigenproblem
$|f|\psi^{[i]}\rangle = \lambda^{[i]} |\psi^{[i]}\rangle$. The solution to the
interpolation problem is a regular Radon-Nikodym derivative. The solution to
the classification problem requires prior and posterior probabilities that are
obtained using the Lebesgue quadrature[1] technique. Whereas in a Bayesian
approach new observations change only outcome probabilities, in the
Radon-Nikodym approach not only outcome probabilities but also the probability
space $|\psi^{[i]}\rangle$ change with new observations. This is a remarkable
feature of the approach: both the probabilities and the probability space are
constructed from the data. The Lebesgue quadrature technique can be also
applied to the optimal clustering problem. The problem is solved by
constructing a Gaussian quadrature on the Lebesgue measure. A distinguishing
feature of the Radon-Nikodym approach is the knowledge of the invariant group:
all the answers are invariant relatively any non-degenerated linear transform
of input vector $\mathbf{x}$ components. A software product implementing the
algorithms of interpolation, classification, and optimal clustering is
available from the authors.
</p>
<a href="http://arxiv.org/abs/1906.00460" target="_blank">arXiv:1906.00460</a> [<a href="http://arxiv.org/pdf/1906.00460" target="_blank">pdf</a>]

<h2>Evolutionary Trigger Set Generation for DNN Black-Box Watermarking. (arXiv:1906.04411v2 [cs.LG] UPDATED)</h2>
<h3>Jia Guo, Miodrag Potkonjak</h3>
<p>The commercialization of deep learning creates a compelling need for
intellectual property (IP) protection. Deep neural network (DNN) watermarking
has been proposed as a promising tool to help model owners prove ownership and
fight piracy. A popular approach of watermarking is to train a DNN to recognize
images with certain \textit{trigger} patterns. In this paper, we propose a
novel evolutionary algorithm-based method to generate and optimize trigger
patterns. Our method brings a siginificant reduction in false positive rates,
leading to compelling proof of ownership. At the same time, it maintains the
robustness of the watermark against attacks. We compare our method with the
prior art and demonstrate its effectiveness on popular models and datasets.
</p>
<a href="http://arxiv.org/abs/1906.04411" target="_blank">arXiv:1906.04411</a> [<a href="http://arxiv.org/pdf/1906.04411" target="_blank">pdf</a>]

<h2>Memory Based Trajectory-conditioned Policies for Learning from Sparse Rewards. (arXiv:1907.10247v3 [cs.LG] UPDATED)</h2>
<h3>Yijie Guo, Jongwook Choi, Marcin Moczulski, Shengyu Feng, Samy Bengio, Mohammad Norouzi, Honglak Lee</h3>
<p>Reinforcement learning with sparse rewards is challenging because an agent
can rarely obtain non-zero rewards and hence, gradient-based optimization of
parameterized policies can be incremental and slow. Recent work demonstrated
that using a memory buffer of previous successful trajectories can result in
more effective policies. However, existing methods may overly exploit past
successful experiences, which can encourage the agent to adopt sub-optimal and
myopic behaviors. In this work, instead of focusing on good experiences with
limited diversity, we propose to learn a trajectory-conditioned policy to
follow and expand diverse past trajectories from a memory buffer. Our method
allows the agent to reach diverse regions in the state space and improve upon
the past trajectories to reach new states. We empirically show that our
approach significantly outperforms count-based exploration methods (parametric
approach) and self-imitation learning (parametric approach with non-parametric
memory) on various complex tasks with local optima. In particular, without
using expert demonstrations or resetting to arbitrary states, we achieve the
state-of-the-art scores under five billion number of frames, on challenging
Atari games such as Montezuma's Revenge and Pitfall.
</p>
<a href="http://arxiv.org/abs/1907.10247" target="_blank">arXiv:1907.10247</a> [<a href="http://arxiv.org/pdf/1907.10247" target="_blank">pdf</a>]

<h2>LiDARTag: A Real-Time Fiducial Tag System for Point Clouds. (arXiv:1908.10349v3 [cs.RO] UPDATED)</h2>
<h3>Jiunn-Kai Huang, Shoutian Wang, Maani Ghaffari, Jessy W. Grizzle</h3>
<p>Image-based fiducial markers are useful in problems such as object tracking
in cluttered or textureless environments, camera (and multi-sensor) calibration
tasks, and vision-based simultaneous localization and mapping (SLAM). The
state-of-the-art fiducial marker detection algorithms rely on the consistency
of the ambient lighting. This paper introduces LiDARTag, a novel fiducial tag
design and detection algorithm suitable for light detection and ranging (LiDAR)
point clouds. The proposed method runs in real-time and can process data at 100
Hz, which is faster than the currently available LiDAR sensor frequencies.
Because of the LiDAR sensors' nature, rapidly changing ambient lighting will
not affect the detection of a LiDARTag; hence, the proposed fiducial marker can
operate in a completely dark environment. In addition, the LiDARTag nicely
complements and is compatible with existing visual fiducial markers, such as
AprilTags, allowing for efficient multi-sensor fusion and calibration tasks. We
further propose a concept of minimizing a fitting error between a point cloud
and the marker's template to estimate the marker's pose. The proposed method
achieves millimeter error in translation and a few degrees in rotation. Due to
LiDAR returns' sparsity, the point cloud is lifted to a continuous function in
a reproducing kernel Hilbert space where the inner product can be used to
determine a marker's ID. The experimental results, verified by a motion capture
system, confirm that the proposed method can reliably provide a tag's pose and
unique ID code. The rejection of false positives is validated on the Google
Cartographer indoor dataset and the Honda H3D outdoor dataset. All
implementations are coded in C++ and are available at:
https://github.com/UMich-BipedLab/LiDARTag.
</p>
<a href="http://arxiv.org/abs/1908.10349" target="_blank">arXiv:1908.10349</a> [<a href="http://arxiv.org/pdf/1908.10349" target="_blank">pdf</a>]

<h2>Beating humans in a penny-matching game by leveraging cognitive hierarchy theory and Bayesian learning. (arXiv:1909.12701v3 [cs.AI] UPDATED)</h2>
<h3>Ran Tian, Nan Li, Ilya Kolmanovsky, Anouck Girard</h3>
<p>It is a long-standing goal of artificial intelligence (AI) to be superior to
human beings in decision making. Games are suitable for testing AI capabilities
of making good decisions in non-numerical tasks. In this paper, we develop a
new AI algorithm to play the penny-matching game considered in Shannon's
"mind-reading machine" (1953) against human players. In particular, we exploit
cognitive hierarchy theory and Bayesian learning techniques to continually
evolve a model for predicting human player decisions, and let the AI player
make decisions according to the model predictions to pursue the best chance of
winning. Experimental results show that our AI algorithm beats 27 out of 30
volunteer human players.
</p>
<a href="http://arxiv.org/abs/1909.12701" target="_blank">arXiv:1909.12701</a> [<a href="http://arxiv.org/pdf/1909.12701" target="_blank">pdf</a>]

<h2>Model Fusion via Optimal Transport. (arXiv:1910.05653v5 [cs.LG] UPDATED)</h2>
<h3>Sidak Pal Singh, Martin Jaggi</h3>
<p>Combining different models is a widely used paradigm in machine learning
applications. While the most common approach is to form an ensemble of models
and average their individual predictions, this approach is often rendered
infeasible by given resource constraints in terms of memory and computation,
which grow linearly with the number of models. We present a layer-wise model
fusion algorithm for neural networks that utilizes optimal transport to (soft-)
align neurons across the models before averaging their associated parameters.

We show that this can successfully yield "one-shot" knowledge transfer (i.e,
without requiring any retraining) between neural networks trained on
heterogeneous non-i.i.d. data. In both i.i.d. and non-i.i.d. settings , we
illustrate that our approach significantly outperforms vanilla averaging, as
well as how it can serve as an efficient replacement for the ensemble with
moderate fine-tuning, for standard convolutional networks (like VGG11),
residual networks (like ResNet18), and multi-layer perceptrons on CIFAR10,
CIFAR100, and MNIST. Finally, our approach also provides a principled way to
combine the parameters of neural networks with different widths, and we explore
its application for model compression. The code is available at the following
link, https://github.com/sidak/otfusion.
</p>
<a href="http://arxiv.org/abs/1910.05653" target="_blank">arXiv:1910.05653</a> [<a href="http://arxiv.org/pdf/1910.05653" target="_blank">pdf</a>]

<h2>Reducing Domain Gap by Reducing Style Bias. (arXiv:1910.11645v3 [cs.CV] UPDATED)</h2>
<h3>Hyeonseob Nam, HyunJae Lee, Jongchan Park, Wonjun Yoon, Donggeun Yoo</h3>
<p>Convolutional Neural Networks (CNNs) often fail to maintain their performance
when they confront new test domains, which is known as the problem of domain
shift. Recent studies suggest that one of the main causes of this problem is
CNNs' strong inductive bias towards image styles (i.e. textures) which are
sensitive to domain changes, rather than contents (i.e. shapes). Inspired by
this, we propose to reduce the intrinsic style bias of CNNs to close the gap
between domains. Our Style-Agnostic Networks (SagNets) disentangle style
encodings from class categories to prevent style biased predictions and focus
more on the contents. Extensive experiments show that our method effectively
reduces the style bias and makes the model more robust under the domain shift.
It achieves remarkable performance improvements in a wide range of cross-domain
tasks including domain generalization, unsupervised domain adaptation, and
semi-supervised domain adaptation on multiple datasets.
</p>
<a href="http://arxiv.org/abs/1910.11645" target="_blank">arXiv:1910.11645</a> [<a href="http://arxiv.org/pdf/1910.11645" target="_blank">pdf</a>]

<h2>Mitigating the Effects of Non-Identifiability on Inference for Bayesian Neural Networks with Latent Variables. (arXiv:1911.00569v2 [cs.LG] UPDATED)</h2>
<h3>Yaniv Yacoby, Weiwei Pan, Finale Doshi-Velez</h3>
<p>Bayesian Neural Networks with Latent Variables (BNN+LVs) provide
uncertainties in prediction estimates by explicitly modeling model uncertainty
(via priors on network weights) and environmental stochasticity (via a latent
input noise variable). In this work, we first show that BNN+LV suffers from a
serious form of non-identifiability: explanatory power can be transferred
between model parameters and input noise while fitting the data equally well.
We demonstrate that as a result, the posterior mode over the network weights
and latent variables is asymptotically biased away from the ground truth, and
as a result, traditional inference methods may yield parameters that generalize
poorly and mis-estimate uncertainty. Next, we develop a novel inference
procedure that explicitly mitigates the effects of likelihood
non-identifiability during training and yields high quality predictions as well
as uncertainty estimates. We demonstrate that our inference method improves
upon benchmark methods across a range of synthetic and real data sets.
</p>
<a href="http://arxiv.org/abs/1911.00569" target="_blank">arXiv:1911.00569</a> [<a href="http://arxiv.org/pdf/1911.00569" target="_blank">pdf</a>]

<h2>Confidence Intervals for Policy Evaluation in Adaptive Experiments. (arXiv:1911.02768v4 [stat.ML] UPDATED)</h2>
<h3>Vitor Hadad, David A. Hirshberg, Ruohan Zhan, Stefan Wager, Susan Athey</h3>
<p>Adaptive experiment designs can dramatically improve statistical efficiency
in randomized trials, but they also complicate statistical inference. For
example, it is now well known that the sample mean is biased in adaptive
trials. Inferential challenges are exacerbated when our parameter of interest
differs from the parameter the trial was designed to target, such as when we
are interested in estimating the value of a sub-optimal treatment after running
a trial to determine the optimal treatment using a stochastic bandit design. In
this context, typical estimators that use inverse propensity weighting to
eliminate sampling bias can be problematic: their distributions become skewed
and heavy-tailed as the propensity scores decay to zero. In this paper, we
present a class of estimators that overcome these issues. Our approach is to
adaptively reweight the terms of an augmented inverse propensity weighting
estimator to control the contribution of each term to the estimator's variance.
This adaptive weighting scheme prevents estimates from becoming heavy-tailed,
ensuring asymptotically correct coverage. It also reduces variance, allowing us
to test hypotheses with greater power - especially hypotheses that were not
targeted by the experimental design. We validate the accuracy of the resulting
estimates and their confidence intervals in numerical experiments and show our
methods compare favorably to existing alternatives in terms of RMSE and
coverage.
</p>
<a href="http://arxiv.org/abs/1911.02768" target="_blank">arXiv:1911.02768</a> [<a href="http://arxiv.org/pdf/1911.02768" target="_blank">pdf</a>]

<h2>Take an Emotion Walk: Perceiving Emotions from Gaits Using Hierarchical Attention Pooling and Affective Mapping. (arXiv:1911.08708v3 [cs.CV] UPDATED)</h2>
<h3>Uttaran Bhattacharya, Christian Roncal, Trisha Mittal, Rohan Chandra, Kyra Kapsaskis, Kurt Gray, Aniket Bera, Dinesh Manocha</h3>
<p>We present an autoencoder-based semi-supervised approach to classify
perceived human emotions from walking styles obtained from videos or
motion-captured data and represented as sequences of 3D poses. Given the motion
on each joint in the pose at each time step extracted from 3D pose sequences,
we hierarchically pool these joint motions in a bottom-up manner in the
encoder, following the kinematic chains in the human body. We also constrain
the latent embeddings of the encoder to contain the space of
psychologically-motivated affective features underlying the gaits. We train the
decoder to reconstruct the motions per joint per time step in a top-down manner
from the latent embeddings. For the annotated data, we also train a classifier
to map the latent embeddings to emotion labels. Our semi-supervised approach
achieves a mean average precision of 0.84 on the Emotion-Gait benchmark
dataset, which contains both labeled and unlabeled gaits collected from
multiple sources. We outperform current state-of-art algorithms for both
emotion recognition and action recognition from 3D gaits by 7%--23% on the
absolute. More importantly, we improve the average precision by 10%--50% on the
absolute on classes that each makes up less than 25% of the labeled part of the
Emotion-Gait benchmark dataset.
</p>
<a href="http://arxiv.org/abs/1911.08708" target="_blank">arXiv:1911.08708</a> [<a href="http://arxiv.org/pdf/1911.08708" target="_blank">pdf</a>]

<h2>Instance-Invariant Domain Adaptive Object Detection via Progressive Disentanglement. (arXiv:1911.08712v4 [cs.CV] UPDATED)</h2>
<h3>Aming Wu, Yahong Han, Linchao Zhu, Yi Yang</h3>
<p>Most state-of-the-art methods of object detection suffer from poor
generalization ability when the training and test data are from different
domains, e.g., with different styles. To address this problem, previous methods
mainly use holistic representations to align feature-level and pixel-level
distributions of different domains, which may neglect the instance-level
characteristics of objects in images. Besides, when transferring detection
ability across different domains, it is important to obtain the instance-level
features that are domain-invariant, instead of the styles that are
domain-specific. Therefore, in order to extract instance-invariant features, we
should disentangle the domain-invariant features from the domain-specific
features. To this end, a progressive disentangled framework is first proposed
to solve domain adaptive object detection. Particularly, base on disentangled
learning used for feature decomposition, we devise two disentangled layers to
decompose domain-invariant and domain-specific features. And the
instance-invariant features are extracted based on the domain-invariant
features. Finally, to enhance the disentanglement, a three-stage training
mechanism including multiple loss functions is devised to optimize our model.
In the experiment, we verify the effectiveness of our method on three
domain-shift scenes. Our method is separately 2.3\%, 3.6\%, and 4.0\% higher
than the baseline method \cite{saito2019strong}.
</p>
<a href="http://arxiv.org/abs/1911.08712" target="_blank">arXiv:1911.08712</a> [<a href="http://arxiv.org/pdf/1911.08712" target="_blank">pdf</a>]

<h2>Universal adversarial examples in speech command classification. (arXiv:1911.10182v4 [cs.LG] UPDATED)</h2>
<h3>Jon Vadillo, Roberto Santana</h3>
<p>Adversarial examples are inputs intentionally perturbed with the aim of
forcing a machine learning model to produce a wrong prediction, while the
changes are not easily detectable by a human. Although this topic has been
intensively studied in the image domain, classification tasks in the audio
domain have received less attention. In this paper we address the existence of
universal perturbations for speech command classification. We provide evidence
that universal attacks can be generated for speech command classification
tasks, which are able to generalize across different models to a significant
extent. Additionally, a novel analytical framework is proposed for the
evaluation of universal perturbations under different levels of universality,
demonstrating that the feasibility of generating effective perturbations
decreases as the universality level increases. Finally, we propose a more
detailed and rigorous framework to measure the amount of distortion introduced
by the perturbations, demonstrating that the methods employed by convention are
not realistic in audio-based problems.
</p>
<a href="http://arxiv.org/abs/1911.10182" target="_blank">arXiv:1911.10182</a> [<a href="http://arxiv.org/pdf/1911.10182" target="_blank">pdf</a>]

<h2>Grid-GCN for Fast and Scalable Point Cloud Learning. (arXiv:1912.02984v4 [cs.CV] UPDATED)</h2>
<h3>Qiangeng Xu, Xudong Sun, Cho-Ying Wu, Panqu Wang, Ulrich Neumann</h3>
<p>Due to the sparsity and irregularity of the point cloud data, methods that
directly consume points have become popular. Among all point-based models,
graph convolutional networks (GCN) lead to notable performance by fully
preserving the data granularity and exploiting point interrelation. However,
point-based networks spend a significant amount of time on data structuring
(e.g., Farthest Point Sampling (FPS) and neighbor points querying), which limit
the speed and scalability. In this paper, we present a method, named Grid-GCN,
for fast and scalable point cloud learning. Grid-GCN uses a novel data
structuring strategy, Coverage-Aware Grid Query (CAGQ). By leveraging the
efficiency of grid space, CAGQ improves spatial coverage while reducing the
theoretical time complexity. Compared with popular sampling methods such as
Farthest Point Sampling (FPS) and Ball Query, CAGQ achieves up to 50X speed-up.
With a Grid Context Aggregation (GCA) module, Grid-GCN achieves
state-of-the-art performance on major point cloud classification and
segmentation benchmarks with significantly faster runtime than previous
studies. Remarkably, Grid-GCN achieves the inference speed of 50fps on ScanNet
using 81920 points per scene as input.
</p>
<a href="http://arxiv.org/abs/1912.02984" target="_blank">arXiv:1912.02984</a> [<a href="http://arxiv.org/pdf/1912.02984" target="_blank">pdf</a>]

<h2>A Transferable Adaptive Domain Adversarial Neural Network for Virtual Reality Augmented EMG-Based Gesture Recognition. (arXiv:1912.09380v2 [cs.LG] UPDATED)</h2>
<h3>Ulysse C&#xf4;t&#xe9;-Allard, Gabriel Gagnon-Turcotte, Angkoon Phinyomark, Kyrre Glette, Erik Scheme, Fran&#xe7;ois Laviolette, Benoit Gosselin</h3>
<p>Within the field of electromyography-based (EMG) gesture recognition,
disparities exist between the offline accuracy reported in the literature and
the real-time usability of a classifier. This gap mainly stems from two
factors: 1) The absence of a controller, making the data collected dissimilar
to actual control. 2) The difficulty of including the four main dynamic factors
(gesture intensity, limb position, electrode shift, and transient changes in
the signal), as including their permutations drastically increases the amount
of data to be recorded. Contrarily, online datasets are limited to the exact
EMG-based controller used to record them, necessitating the recording of a new
dataset for each control method or variant to be tested. Consequently, this
paper proposes a new type of dataset to serve as an intermediate between
offline and online datasets, by recording the data using a real-time
experimental protocol. The protocol, performed in virtual reality, includes the
four main dynamic factors and uses an EMG-independent controller to guide
movements. This EMG-independent feedback ensures that the user is in-the-loop
during recording, while enabling the resulting dynamic dataset to be used as an
EMG-based benchmark. The dataset is comprised of 20 able-bodied participants
completing three to four sessions over a period of 14 to 21 days. The ability
of the dynamic dataset to serve as a benchmark is leveraged to evaluate the
impact of different recalibration techniques for long-term (across-day) gesture
recognition, including a novel algorithm, named TADANN. TADANN consistently and
significantly (p&lt;0.05) outperforms using fine-tuning as the recalibration
technique.
</p>
<a href="http://arxiv.org/abs/1912.09380" target="_blank">arXiv:1912.09380</a> [<a href="http://arxiv.org/pdf/1912.09380" target="_blank">pdf</a>]

<h2>AutoScale: Learning to Scale for Crowd Counting and Localization. (arXiv:1912.09632v3 [cs.CV] UPDATED)</h2>
<h3>Chenfeng Xu, Dingkang Liang, Yongchao Xu, Song Bai, Wei Zhan, Xiang Bai, Masayoshi Tomizuka</h3>
<p>Recent works on crowd counting mainly leverage Convolutional Neural Networks
(CNNs) to count by regressing density maps, and have achieved great progress.
In the density map, each person is represented by a Gaussian blob, and the
final count is obtained from the integration of the whole map. However, it is
difficult to accurately predict the density map on dense regions. A major issue
is that the density map on dense regions usually accumulates density values
from a number of nearby Gaussian blobs, yielding different large density values
on a small set of pixels. This makes the density map present a long-tailed
distribution of pixel-wise density values. In this paper, we aim to address
this long-tailed distribution issue in the density map. Specifically, we
propose a simple yet effective Learning to Scale (L2S) module, which
automatically scales dense regions into reasonable density levels. It
dynamically separates the overlapped blobs, decomposes the accumulated values
in the ground-truth density map, and thus alleviates the long-tailed
distribution of density values, which helps the model to better learn the
density map. We also explore the effectiveness of L2S in localizing people by
finding the local minima of the quantized distance (w.r.t. person location
map), which has a similar issue as density map regression. To the best of our
knowledge, such localization method is also novel in localization-based crowd
counting. We further introduce a customized dynamic cross-entropy loss,
significantly improving the localization-based model optimization. Extensive
experiments demonstrate that the proposed framework termed AutoScale improves
upon some state-of-the-art methods in both regression and localization
benchmarks on three crowded datasets and achieves very competitive performance
on two sparse datasets.
</p>
<a href="http://arxiv.org/abs/1912.09632" target="_blank">arXiv:1912.09632</a> [<a href="http://arxiv.org/pdf/1912.09632" target="_blank">pdf</a>]

<h2>Linearly Constrained Gaussian Processes with Boundary Conditions. (arXiv:2002.00818v3 [cs.LG] UPDATED)</h2>
<h3>Markus Lange-Hegermann</h3>
<p>One goal in Bayesian machine learning is to encode prior knowledge into prior
distributions, to model data efficiently. We consider prior knowledge from
systems of linear partial differential equations together with their boundary
conditions. We construct multi-output Gaussian process priors with realizations
in the solution set of such systems, in particular only such solutions can be
represented by Gaussian process regression. The construction is fully
algorithmic via Gr\"obner bases and it does not employ any approximation. It
builds these priors combining two parametrizations via a pullback: the first
parametrizes the solutions for the system of differential equations and the
second parametrizes all functions adhering to the boundary conditions.
</p>
<a href="http://arxiv.org/abs/2002.00818" target="_blank">arXiv:2002.00818</a> [<a href="http://arxiv.org/pdf/2002.00818" target="_blank">pdf</a>]

<h2>A Difference-of-Convex Programming Approach With Parallel Branch-and-Bound For Sentence Compression Via A Hybrid Extractive Model. (arXiv:2002.01352v2 [cs.AI] UPDATED)</h2>
<h3>Yi-Shuai Niu, Yu You, Wenxu Xu, Wentao Ding, Junpeng Hu, Songquan Yao</h3>
<p>Sentence compression is an important problem in natural language processing
with wide applications in text summarization, search engine and human-AI
interaction system etc. In this paper, we design a hybrid extractive sentence
compression model combining a probability language model and a parse tree
language model for compressing sentences by guaranteeing the syntax correctness
of the compression results. Our compression model is formulated as an integer
linear programming problem, which can be rewritten as a Difference-of-Convex
(DC) programming problem based on the exact penalty technique. We use a
well-known efficient DC algorithm -- DCA to handle the penalized problem for
local optimal solutions. Then a hybrid global optimization algorithm combining
DCA with a parallel branch-and-bound framework, namely PDCABB, is used for
finding global optimal solutions. Numerical results demonstrate that our
sentence compression model can provide excellent compression results evaluated
by F-score, and indicate that PDCABB is a promising algorithm for solving our
sentence compression model.
</p>
<a href="http://arxiv.org/abs/2002.01352" target="_blank">arXiv:2002.01352</a> [<a href="http://arxiv.org/pdf/2002.01352" target="_blank">pdf</a>]

<h2>Contradictory Structure Learning for Semi-supervised Domain Adaptation. (arXiv:2002.02545v2 [cs.CV] UPDATED)</h2>
<h3>Can Qin, Lichen Wang, Qianqian Ma, Yu Yin, Huan Wang, Yun Fu</h3>
<p>Current adversarial adaptation methods attempt to align the cross-domain
features, whereas two challenges remain unsolved: 1) the conditional
distribution mismatch and 2) the bias of the decision boundary towards the
source domain. To solve these challenges, we propose a novel framework for
semi-supervised domain adaptation by unifying the learning of opposite
structures (UODA). UODA consists of a generator and two classifiers (i.e., the
source-scattering classifier and the target-clustering classifier), which are
trained for contradictory purposes. The target-clustering classifier attempts
to cluster the target features to improve intra-class density and enlarge
inter-class divergence. Meanwhile, the source-scattering classifier is designed
to scatter the source features to enhance the decision boundary's smoothness.
Through the alternation of source-feature expansion and target-feature
clustering procedures, the target features are well-enclosed within the dilated
boundary of the corresponding source features. This strategy can make the
cross-domain features to be precisely aligned against the source bias
simultaneously. Moreover, to overcome the model collapse through training, we
progressively update the measurement of feature's distance and their
representation via an adversarial training paradigm. Extensive experiments on
the benchmarks of DomainNet and Office-home datasets demonstrate the
superiority of our approach over the state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2002.02545" target="_blank">arXiv:2002.02545</a> [<a href="http://arxiv.org/pdf/2002.02545" target="_blank">pdf</a>]

<h2>Un-Mix: Rethinking Image Mixtures for Unsupervised Visual Representation Learning. (arXiv:2003.05438v2 [cs.CV] UPDATED)</h2>
<h3>Zhiqiang Shen, Zechun Liu, Zhuang Liu, Marios Savvides, Trevor Darrell, Eric Xing</h3>
<p>In supervised learning, smoothing label or prediction distribution in neural
network training has been proven useful in preventing the model from being
over-confident, and is crucial for learning more robust visual representations.
This observation motivates us to explore ways to make predictions flattened in
unsupervised learning. Considering that human-annotated labels are not adopted
in unsupervised learning, we introduce a straightforward approach to perturb
input image space in order to soften the output prediction space indirectly,
meanwhile, assigning new label values in the unsupervised frameworks
accordingly. Despite its conceptual simplicity, we show empirically that with
the simple solution -- Unsupervised image mixtures (Un-Mix), we can learn more
robust visual representations from the transformed input. Extensive experiments
are conducted on CIFAR-10, CIFAR-100, STL-10, Tiny ImageNet and standard
ImageNet with popular unsupervised methods SimCLR, BYOL, MoCo V1&amp;V2, etc. Our
proposed image mixture and label assignment strategy can obtain consistent
improvement by 1~3% following exactly the same hyperparameters and training
procedures of the base methods.
</p>
<a href="http://arxiv.org/abs/2003.05438" target="_blank">arXiv:2003.05438</a> [<a href="http://arxiv.org/pdf/2003.05438" target="_blank">pdf</a>]

<h2>Visual Navigation Among Humans with Optimal Control as a Supervisor. (arXiv:2003.09354v2 [cs.RO] UPDATED)</h2>
<h3>Varun Tolani, Somil Bansal, Aleksandra Faust, Claire Tomlin</h3>
<p>Real world visual navigation requires robots to operate in unfamiliar,
human-occupied dynamic environments. Navigation around humans is especially
difficult because it requires anticipating their future motion, which can be
quite challenging. We propose an approach that combines learning-based
perception with model-based optimal control to navigate among humans based only
on monocular, first-person RGB images. Our approach is enabled by our novel
data-generation tool, HumANav that allows for photorealistic renderings of
indoor environment scenes with humans in them, which are then used to train the
perception module entirely in simulation. Through simulations and experiments
on a mobile robot, we demonstrate that the learned navigation policies can
anticipate and react to humans without explicitly predicting future human
motion, generalize to previously unseen environments and human behaviors, and
transfer directly from simulation to reality. Videos describing our approach
and experiments, as well as a demo of HumANav are available on the project
website.
</p>
<a href="http://arxiv.org/abs/2003.09354" target="_blank">arXiv:2003.09354</a> [<a href="http://arxiv.org/pdf/2003.09354" target="_blank">pdf</a>]

<h2>Multi-Scale Thermal to Visible Face Verification via Attribute Guided Synthesis. (arXiv:2004.09502v2 [cs.CV] UPDATED)</h2>
<h3>Xing Di, Benjamin S. Riggan, Shuowen Hu, Nathaniel J. Short, Vishal M. Patel</h3>
<p>Thermal-to-visible face verification is a challenging problem due to the
large domain discrepancy between the modalities. Existing approaches either
attempt to synthesize visible faces from thermal faces or learn
domain-invariant robust features from these modalities for cross-modal
matching. In this paper, we use attributes extracted from visible images to
synthesize attribute-preserved visible images from thermal imagery for
cross-modal matching. A pre-trained attribute predictor network is used to
extract the attributes from the visible image. Then, a novel multi-scale
generator is proposed to synthesize the visible image from the thermal image
guided by the extracted attributes. Finally, a pre-trained VGG-Face network is
leveraged to extract features from the synthesized image and the input visible
image for verification. Extensive experiments evaluated on three datasets (ARL
Face Database, Visible and Thermal Paired Face Database, and Tufts Face
Database) demonstrate that the proposed method achieves state-of-the-art
performance. In particular, it achieves around 2.41\%, 2.85\% and 1.77\%
improvements in Equal Error Rate (EER) over the state-of-the-art methods on the
ARL Face Database, Visible and Thermal Paired Face Database, and Tufts Face
Database, respectively. An extended dataset (ARL Face Dataset volume III)
consisting of polarimetric thermal faces of 121 subjects is also introduced in
this paper. Furthermore, an ablation study is conducted to demonstrate the
effectiveness of different modules in the proposed method.
</p>
<a href="http://arxiv.org/abs/2004.09502" target="_blank">arXiv:2004.09502</a> [<a href="http://arxiv.org/pdf/2004.09502" target="_blank">pdf</a>]

<h2>Fractional moment-preserving initialization schemes for training deep neural networks. (arXiv:2005.11878v5 [cs.LG] UPDATED)</h2>
<h3>Mert Gurbuzbalaban, Yuanhan Hu</h3>
<p>A traditional approach to initialization in deep neural networks (DNNs) is to
sample the network weights randomly for preserving the variance of
pre-activations. On the other hand, several studies show that during the
training process, the distribution of stochastic gradients can be heavy-tailed
especially for small batch sizes. In this case, weights and therefore
pre-activations can be modeled with a heavy-tailed distribution that has an
infinite variance but has a finite (non-integer) fractional moment of order $s$
with $s&lt;2$. Motivated by this fact, we develop initialization schemes for fully
connected feed-forward networks that can provably preserve any given moment of
order $s \in (0, 2]$ over the layers for a class of activations including ReLU,
Leaky ReLU, Randomized Leaky ReLU, and linear activations. These generalized
schemes recover traditional initialization schemes in the limit $s \to 2$ and
serve as part of a principled theory for initialization. For all these schemes,
we show that the network output admits a finite almost sure limit as the number
of layers grows, and the limit is heavy-tailed in some settings. This sheds
further light into the origins of heavy tail during signal propagation in DNNs.
We prove that the logarithm of the norm of the network outputs, if properly
scaled, will converge to a Gaussian distribution with an explicit mean and
variance we can compute depending on the activation used, the value of s chosen
and the network width. We also prove that our initialization scheme avoids
small network output values more frequently compared to traditional approaches.
Furthermore, the proposed initialization strategy does not have an extra cost
during the training procedure. We show through numerical experiments that our
initialization can improve the training and test performance.
</p>
<a href="http://arxiv.org/abs/2005.11878" target="_blank">arXiv:2005.11878</a> [<a href="http://arxiv.org/pdf/2005.11878" target="_blank">pdf</a>]

<h2>Fuzzy c-Means Clustering for Persistence Diagrams. (arXiv:2006.02796v5 [cs.LG] UPDATED)</h2>
<h3>Thomas Davies, Jack Aspinall, Bryan Wilder, Long Tran-Thanh</h3>
<p>Persistence diagrams concisely represent the topology of a point cloud whilst
having strong theoretical guarantees, but the question of how to best integrate
this information into machine learning workflows remains open. In this paper we
extend the ubiquitous Fuzzy c-Means (FCM) clustering algorithm to the space of
persistence diagrams, enabling unsupervised learning that automatically
captures the topological structure of data without the topological prior
knowledge or additional processing of persistence diagrams that many other
techniques require. We give theoretical convergence guarantees that correspond
to the Euclidean case, and empirically demonstrate the capability of our
algorithm to capture topological information via the fuzzy RAND index. We end
with experiments on two datasets that utilise both the topological and fuzzy
nature of our algorithm: pre-trained model selection in machine learning and
lattices structures from materials science. As pre-trained models can perform
well on multiple tasks, selecting the best model is a naturally fuzzy problem;
we show that fuzzy clustering persistence diagrams allows for model selection
using the topology of decision boundaries. In materials science, we classify
transformed lattice structure datasets for the first time, whilst the
probabilistic membership values let us rank candidate lattices in a scenario
where further investigation requires expensive laboratory time and expertise.
</p>
<a href="http://arxiv.org/abs/2006.02796" target="_blank">arXiv:2006.02796</a> [<a href="http://arxiv.org/pdf/2006.02796" target="_blank">pdf</a>]

<h2>Wasserstein Random Forests and Applications in Heterogeneous Treatment Effects. (arXiv:2006.04709v3 [stat.ML] UPDATED)</h2>
<h3>Qiming Du, G&#xe9;rard Biau, Fran&#xe7;ois Petit, Rapha&#xeb;l Porcher</h3>
<p>We present new insights into causal inference in the context of Heterogeneous
Treatment Effects by proposing natural variants of Random Forests to estimate
the key conditional distributions. To achieve this, we recast Breiman's
original splitting criterion in terms of Wasserstein distances between
empirical measures. This reformulation indicates that Random Forests are well
adapted to estimate conditional distributions and provides a natural extension
of the algorithm to multivariate outputs. Following the philosophy of Breiman's
construction, we propose some variants of the splitting rule that are
well-suited to the conditional distribution estimation problem. Some
preliminary theoretical connections are established along with various
numerical experiments, which show how our approach may help to conduct more
transparent causal inference in complex situations.
</p>
<a href="http://arxiv.org/abs/2006.04709" target="_blank">arXiv:2006.04709</a> [<a href="http://arxiv.org/pdf/2006.04709" target="_blank">pdf</a>]

<h2>Optimal Transport Graph Neural Networks. (arXiv:2006.04804v5 [stat.ML] UPDATED)</h2>
<h3>Gary B&#xe9;cigneul, Octavian-Eugen Ganea, Benson Chen, Regina Barzilay, Tommi Jaakkola</h3>
<p>Current graph neural network (GNN) architectures naively average or sum node
embeddings into an aggregated graph representation -- potentially losing
structural or semantic information. We here introduce OT-GNN, a model that
computes graph embeddings using parametric prototypes that highlight key facets
of different graph aspects. Towards this goal, we are (to our knowledge) the
first to successfully combine optimal transport (OT) with parametric graph
models. Graph representations are obtained from Wasserstein distances between
the set of GNN node embeddings and "prototype" point clouds as free parameters.
We theoretically prove that, unlike traditional sum aggregation, our function
class on point clouds satisfies a fundamental universal approximation theorem.
Empirically, we address an inherent collapse optimization issue by proposing a
noise contrastive regularizer to steer the model towards truly exploiting the
optimal transport geometry. Finally, we consistently report better
generalization performance on several molecular property prediction tasks,
while exhibiting smoother graph representations.
</p>
<a href="http://arxiv.org/abs/2006.04804" target="_blank">arXiv:2006.04804</a> [<a href="http://arxiv.org/pdf/2006.04804" target="_blank">pdf</a>]

<h2>A General Framework for Survival Analysis and Multi-State Modelling. (arXiv:2006.04893v2 [stat.ML] UPDATED)</h2>
<h3>Stefan Groha, Sebastian M Schmon, Alexander Gusev</h3>
<p>Survival models are a popular tool for the analysis of time to event data
with applications in medicine, engineering, economics, and many more. Advances
like the Cox proportional hazard model have enabled researchers to better
describe hazard rates for the occurrence of single fatal events, but are unable
to accurately model competing events and transitions. Common phenomena are
often better described through multiple states, for example: the progress of a
disease modeled as healthy, sick and dead instead of healthy and dead, where
the competing nature of death and disease has to be taken into account.
Moreover, Cox models are limited by modeling assumptions, like proportionality
of hazard rates and linear effects. Individual characteristics can vary
significantly between observational units, like patients, resulting in
idiosyncratic hazard rates and different disease trajectories. These
considerations require flexible modeling assumptions. To overcome these issues,
we propose the use of neural ordinary differential equations as a flexible and
general method for estimating multi-state survival models by directly solving
the Kolmogorov forward equations. To quantify the uncertainty in the resulting
individual cause-specific hazard rates, we further introduce a variational
latent variable model and show that this enables meaningful clustering with
respect to multi-state outcomes as well as interpretability regarding covariate
values. We show that our model exhibits state-of-the-art performance on popular
survival data sets and demonstrate its efficacy in a multi-state setting
</p>
<a href="http://arxiv.org/abs/2006.04893" target="_blank">arXiv:2006.04893</a> [<a href="http://arxiv.org/pdf/2006.04893" target="_blank">pdf</a>]

<h2>Self-Imitation Learning via Generalized Lower Bound Q-learning. (arXiv:2006.07442v3 [cs.LG] UPDATED)</h2>
<h3>Yunhao Tang</h3>
<p>Self-imitation learning motivated by lower-bound Q-learning is a novel and
effective approach for off-policy learning. In this work, we propose a n-step
lower bound which generalizes the original return-based lower-bound Q-learning,
and introduce a new family of self-imitation learning algorithms. To provide a
formal motivation for the potential performance gains provided by
self-imitation learning, we show that n-step lower bound Q-learning achieves a
trade-off between fixed point bias and contraction rate, drawing close
connections to the popular uncorrected n-step Q-learning. We finally show that
n-step lower bound Q-learning is a more robust alternative to return-based
self-imitation learning and uncorrected n-step, over a wide range of continuous
control benchmark tasks.
</p>
<a href="http://arxiv.org/abs/2006.07442" target="_blank">arXiv:2006.07442</a> [<a href="http://arxiv.org/pdf/2006.07442" target="_blank">pdf</a>]

<h2>Mitigating Gender Bias in Captioning Systems. (arXiv:2006.08315v6 [cs.CV] UPDATED)</h2>
<h3>Ruixiang Tang, Mengnan Du, Yuening Li, Zirui Liu, Na Zou, Xia Hu</h3>
<p>Image captioning has made substantial progress with huge supporting image
collections sourced from the web. However, recent studies have pointed out that
captioning datasets, such as COCO, contain gender bias found in web corpora. As
a result, learning models could heavily rely on the learned priors and image
context for gender identification, leading to incorrect or even offensive
errors. To encourage models to learn correct gender features, we reorganize the
COCO dataset and present two new splits COCO-GB V1 and V2 datasets where the
train and test sets have different gender-context joint distribution. Models
relying on contextual cues will suffer from huge gender prediction errors on
the anti-stereotypical test data. Benchmarking experiments reveal that most
captioning models learn gender bias, leading to high gender prediction errors,
especially for women. To alleviate the unwanted bias, we propose a new Guided
Attention Image Captioning model (GAIC) which provides self-guidance on visual
attention to encourage the model to capture correct gender visual evidence.
Experimental results validate that GAIC can significantly reduce gender
prediction errors with a competitive caption quality. Our codes and the
designed benchmark datasets are available at
https://github.com/datamllab/Mitigating_Gender_Bias_In_Captioning_System.
</p>
<a href="http://arxiv.org/abs/2006.08315" target="_blank">arXiv:2006.08315</a> [<a href="http://arxiv.org/pdf/2006.08315" target="_blank">pdf</a>]

<h2>GANs with First-Order Greedy Discriminators. (arXiv:2006.12376v4 [cs.LG] UPDATED)</h2>
<h3>Vijay Keswani, Oren Mangoubi, Sushant Sachdeva, Nisheeth K. Vishnoi</h3>
<p>We propose a variant of the standard min-max framework for GANs to learn a
distribution, where the discriminator can update its strategy in a greedy
manner until it reaches a first-order stationary point. We give an algorithm to
train such a GAN and show that it provably converges from any initial point to
an approximate local equilibrium for this framework. Our algorithm runs in time
polynomial in the smoothness parameters of the loss function and independent of
the dimension, and allows for loss functions that can be nonconvex and
nonconcave in the parameters of the generator and discriminator. Empirically,
GANs trained using our algorithm consistently learn a greater number of modes
than gradient descent-ascent (GDA), optimistic mirror descent (OMD), and
unrolled GANs when applied to a synthetic Gaussian mixture dataset. Moreover,
they perform significantly better on CIFAR-10 than OMD and GDA when comparing
the mean and standard deviation of the Inception Score respectively.
</p>
<a href="http://arxiv.org/abs/2006.12376" target="_blank">arXiv:2006.12376</a> [<a href="http://arxiv.org/pdf/2006.12376" target="_blank">pdf</a>]

<h2>Rescaling Egocentric Vision. (arXiv:2006.13256v3 [cs.CV] UPDATED)</h2>
<h3>Dima Damen, Hazel Doughty, Giovanni Maria Farinella, Antonino Furnari, Evangelos Kazakos, Jian Ma, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, Michael Wray</h3>
<p>This paper introduces the pipeline to scale the largest dataset in egocentric
vision EPIC-KITCHENS. The effort culminates in EPIC-KITCHENS-100, a collection
of 100~hours, 20M frames, 90K actions in 700 variable-length videos, capturing
long-term unscripted activities in 45 environments, using head-mounted cameras.
Compared to its previous version, EPIC-KITCHENS-100 has been annotated using a
novel pipeline that allows denser (54\% more actions per minute) and more
complete annotations of fine-grained actions (+128\% more action segments).
This collection also enables evaluating the "test of time" - i.e. whether
models trained on data collected in 2018 can generalise to new footage
collected under the same hypotheses albeit "two years on".

The dataset is aligned with 6 challenges: action recognition (full and weak
supervision), action detection, action anticipation, cross-modal retrieval
(from captions), as well as unsupervised domain adaptation for action
recognition. For each challenge, we define the task, provide baselines and
evaluation metrics.
</p>
<a href="http://arxiv.org/abs/2006.13256" target="_blank">arXiv:2006.13256</a> [<a href="http://arxiv.org/pdf/2006.13256" target="_blank">pdf</a>]

<h2>On Multivariate Singular Spectrum Analysis and its Variants. (arXiv:2006.13448v3 [cs.LG] UPDATED)</h2>
<h3>Anish Agarwal, Abdullah Alomar, Devavrat Shah</h3>
<p>We introduce and analyze a simpler and practical variant of multivariate
singular spectrum analysis (mSSA), a known time series method to impute and
forecast multivariate time series. Towards this, we introduce a spatio-temporal
factor model to analyze mSSA. We establish that given $N$ time series and $T$
observations per time series, the in-sample prediction error for both
imputation and forecasting under mSSA scales as $1/\sqrt{\min(N, T) T}$. This
is an improvement over: (i) the $1/\sqrt{T}$ error scaling one gets for SSA,
which is the restriction of mSSA to a univariate time series; (ii) the
${1}/{\min(N, T)}$ error scaling one gets for Temporal Regularized Matrix
Factorized (TRMF), a matrix factorization based method for time series
prediction. That is, mSSA exploits both the `temporal' and `spatial' structure
in a multivariate time series. Our experimental results using various benchmark
datasets confirm the characteristics of the spatio-temporal factor model as
well as our theoretical findings -- the variant of mSSA we introduce
empirically performs as well or better compared to popular neural network based
time series methods, LSTM and DeepAR. We discuss various extensions of mSSA we
introduce: (i) a variant of mSSA to estimate the time-varying variance of a
time series; (ii) a tensor variant of mSSA we call tSSA to further exploit the
`temporal' and `spatial' structure in a multivariate time series. The
spatio-temporal model considered in our work includes the usual components used
to model dynamics in time series analysis such as trends (low order
polynomials), seasonality (finite sum of harmonics) and linear time-invariant
systems. An important representation result of this work, which might be of
interest more broadly, is the `calculus' for such models that we introduce:
specifically, instances of the spatio-temporal factor model are closed under
addition and multiplication.
</p>
<a href="http://arxiv.org/abs/2006.13448" target="_blank">arXiv:2006.13448</a> [<a href="http://arxiv.org/pdf/2006.13448" target="_blank">pdf</a>]

<h2>Traditional and accelerated gradient descent for neural architecture search. (arXiv:2006.15218v3 [cs.LG] UPDATED)</h2>
<h3>Nicolas Garcia Trillos, Felix Morales, Javier Morales</h3>
<p>In this paper we introduce two algorithms for neural architecture search
(NASGD and NASAGD) following the theoretical work by two of the authors [5]
which used the geometric structure of optimal transport to introduce the
conceptual basis for new notions of traditional and accelerated gradient
descent algorithms for the optimization of a function on a semi-discrete space.
Our algorithms, which use the network morphism framework introduced in [2] as a
baseline, can analyze forty times as many architectures as the hill climbing
methods [2, 14] while using the same computational resources and time and
achieving comparable levels of accuracy. For example, using NASGD on CIFAR-10,
our method designs and trains networks with an error rate of 4.06 in only 12
hours on a single GPU.
</p>
<a href="http://arxiv.org/abs/2006.15218" target="_blank">arXiv:2006.15218</a> [<a href="http://arxiv.org/pdf/2006.15218" target="_blank">pdf</a>]

<h2>Robustifying the Deployment of tinyML Models for Autonomous mini-vehicles. (arXiv:2007.00302v2 [cs.CV] UPDATED)</h2>
<h3>Miguel de Prado, Manuele Rusci, Romain Donze, Alessandro Capotondi, Serge Monnerat, Luca Benini and, Nuria Pazos</h3>
<p>Standard-size autonomous navigation vehicles have rapidly improved thanks to
the breakthroughs of deep learning. However, scaling autonomous driving to
low-power systems deployed on dynamic environments poses several challenges
that prevent their adoption. To address them, we propose a closed-loop learning
flow for autonomous driving mini-vehicles that includes the target environment
in-the-loop. We leverage a family of compact and high-throughput tinyCNNs to
control the mini-vehicle, which learn in the target environment by imitating a
computer vision algorithm, i.e., the expert. Thus, the tinyCNNs, having only
access to an on-board fast-rate linear camera, gain robustness to lighting
conditions and improve over time. Further, we leverage GAP8, a parallel
ultra-low-power RISC-V SoC, to meet the inference requirements. When running
the family of CNNs, our GAP8's solution outperforms any other implementation on
the STM32L4 and NXP k64f (Cortex-M4), reducing the latency by over 13x and the
energy consummation by 92%.
</p>
<a href="http://arxiv.org/abs/2007.00302" target="_blank">arXiv:2007.00302</a> [<a href="http://arxiv.org/pdf/2007.00302" target="_blank">pdf</a>]

<h2>Adaptive Cascade Submodular Maximization. (arXiv:2007.03592v2 [cs.LG] UPDATED)</h2>
<h3>Shaojie Tang, Jing Yuan</h3>
<p>In this paper, we propose and study the cascade submodular maximization
problem under the adaptive setting. The input of our problem is a set of items,
each item is in a particular state (i.e., the marginal contribution of an item)
which is drawn from a known probability distribution. However, we can not know
its actual state before selecting it. As compared with existing studies on
stochastic submodular maximization, one unique setting of our problem is that
each item is associated with a continuation probability which represents the
probability that one is allowed to continue to select the next item after
selecting the current one. Intuitively, this term captures the externality of
selecting one item to all its subsequent items in terms of the opportunity of
being selected. Therefore, the actual set of items that can be selected by a
policy depends on the specific ordering it adopts to select items, this makes
our problem fundamentally different from classical submodular set optimization
problems. Our objective is to identify the best sequence of selecting items so
as to maximize the expected utility of the selected items. We propose a class
of stochastic utility functions, \emph{adaptive cascade submodular functions},
and show that the objective functions in many practical application domains
satisfy adaptive cascade submodularity. Then we develop a $0.12$ approximation
algorithm to the adaptive cascade submodular maximization problem.
</p>
<a href="http://arxiv.org/abs/2007.03592" target="_blank">arXiv:2007.03592</a> [<a href="http://arxiv.org/pdf/2007.03592" target="_blank">pdf</a>]

<h2>AMITE: A Novel Polynomial Expansion for Analyzing Neural Network Nonlinearities. (arXiv:2007.06226v3 [cs.LG] UPDATED)</h2>
<h3>Mauro J. Sanchirico III, Xun Jiao, C. Nataraj</h3>
<p>Polynomial expansions are an important technique in the analysis and study of
neural network nonlinearities. Recently, expansions have been applied to neural
networks addressing well known difficulties in the verifiable, explainable and
secure deployment thereof. Existing approaches span classical Taylor and
Chebyshev methods, asymptotics, and many numerical and algorithmic approaches.
We find that while existing approaches individually have useful properties such
as exact error formulas, monic form, adjustable domain, and robustness to
undefined derivatives, there are no approaches that provide a consistent method
yielding an expansion with all these properties. To address this gap, we
develop an analytically modified integral transform expansion referred to as
AMITE, which is a novel expansion via integral transforms modified using
derived criteria for convergence. We apply AMITE to the nonlinear activation
functions of neural networks including hyperbolic tangent and rectified linear
units. Compared with existing state-of-the-art expansion techniques such as
Chebyshev, Taylor series, and numerical approximations, AMITE is the first
polynomial expansion that can provide six previously mutually exclusive desired
expansion properties such as exact formulas for the coefficients and exact
expansion errors (Table II). Using an MLP as a case study, we demonstrate the
effectiveness of AMITE in the equivalence testing problem of MLP where a
black-box network under test is stimulated, and a replicated multivariate
polynomial form is efficiently extracted from a noisy response to enable
comparison against an original network. AMITE presents a new dimension of
expansion methods that are suitable for analysis/approximation of
nonlinearities in neural networks, which opens up new directions and
opportunities for the theoretical analysis and systematic testing of neural
networks.
</p>
<a href="http://arxiv.org/abs/2007.06226" target="_blank">arXiv:2007.06226</a> [<a href="http://arxiv.org/pdf/2007.06226" target="_blank">pdf</a>]

<h2>Estimating Barycenters of Measures in High Dimensions. (arXiv:2007.07105v2 [stat.ML] UPDATED)</h2>
<h3>Samuel Cohen, Michael Arbel, Marc Peter Deisenroth</h3>
<p>Barycentric averaging is a principled way of summarizing populations of
measures. Existing algorithms for estimating barycenters typically parametrize
them as weighted sums of Diracs and optimize their weights and/or locations.
However, these approaches do not scale to high-dimensional settings due to the
curse of dimensionality. In this paper, we propose a scalable and general
algorithm for estimating barycenters of measures in high dimensions. The key
idea is to turn the optimization over measures into an optimization over
generative models, introducing inductive biases that allow the method to scale
while still accurately estimating barycenters. We prove local convergence under
mild assumptions on the discrepancy showing that the approach is well-posed. We
demonstrate that our method is fast, achieves good performance on
low-dimensional problems, and scales to high-dimensional settings. In
particular, our approach is the first to be used to estimate barycenters in
thousands of dimensions.
</p>
<a href="http://arxiv.org/abs/2007.07105" target="_blank">arXiv:2007.07105</a> [<a href="http://arxiv.org/pdf/2007.07105" target="_blank">pdf</a>]

<h2>Upper Counterfactual Confidence Bounds: a New Optimism Principle for Contextual Bandits. (arXiv:2007.07876v3 [cs.LG] UPDATED)</h2>
<h3>Yunbei Xu, Assaf Zeevi</h3>
<p>The principle of optimism in the face of uncertainty is one of the most
widely used and successful ideas in multi-armed bandits and reinforcement
learning. However, existing optimistic algorithms (primarily UCB and its
variants) are often unable to deal with large context spaces. Essentially all
existing well performing algorithms for general contextual bandit problems rely
on weighted action allocation schemes; and theoretical guarantees for
optimism-based algorithms are only known for restricted formulations. In this
paper we study general contextual bandits under the realizability condition,
and propose a simple generic principle to design optimistic algorithms, dubbed
"Upper Counterfactual Confidence Bounds" (UCCB). We show that these algorithms
are provably optimal and efficient in the presence of large context spaces. Key
components of UCCB include: 1) a systematic analysis of confidence bounds in
policy space rather than in action space; and 2) the potential function
perspective that is used to express the power of optimism in the contextual
setting. We further show how the UCCB principle can be extended to infinite
action spaces, by constructing confidence bounds via the newly introduced
notion of "counterfactual action divergence."
</p>
<a href="http://arxiv.org/abs/2007.07876" target="_blank">arXiv:2007.07876</a> [<a href="http://arxiv.org/pdf/2007.07876" target="_blank">pdf</a>]

<h2>Improving Generalization in Meta-learning via Task Augmentation. (arXiv:2007.13040v2 [cs.LG] UPDATED)</h2>
<h3>Huaxiu Yao, Longkai Huang, Linjun Zhang, Ying Wei, Li Tian, James Zou, Junzhou Huang, Zhenhui Li</h3>
<p>Meta-learning has proven to be a powerful paradigm for transferring the
knowledge from previous tasks to facilitate the learning of a novel task.
Current dominant algorithms train a well-generalized model initialization which
is adapted to each task via the support set. The crux lies in optimizing the
generalization capability of the initialization, which is measured by the
performance of the adapted model on the query set of each task. Unfortunately,
this generalization measure, evidenced by empirical results, pushes the
initialization to overfit the meta-training tasks, which significantly impairs
the generalization and adaptation to novel tasks. To address this issue, we
actively augment a meta-training task with "more data" when evaluating the
generalization. Concretely, we propose two task augmentation methods, including
MetaMix and Channel Shuffle. MetaMix linearly combines features and labels of
samples from both the support and query sets. For each class of samples,
Channel Shuffle randomly replaces a subset of their channels with the
corresponding ones from a different class. Theoretical studies show how task
augmentation improves the generalization of meta-learning. Moreover, both
MetaMix and Channel Shuffle outperform state-of-the-art results by a large
margin across many datasets and are compatible with existing meta-learning
algorithms.
</p>
<a href="http://arxiv.org/abs/2007.13040" target="_blank">arXiv:2007.13040</a> [<a href="http://arxiv.org/pdf/2007.13040" target="_blank">pdf</a>]

<h2>Deep Learning Models for Early Detection and Prediction of the spread of Novel Coronavirus (COVID-19). (arXiv:2008.01170v2 [cs.LG] UPDATED)</h2>
<h3>Devante Ayris, Kye Horbury, Blake Williams, Mitchell Blackney, Celine Shi Hui See, Maleeha Imtiaz, Syed Afaq Ali Shah</h3>
<p>SARS-CoV2, which causes coronavirus disease (COVID-19) is continuing to
spread globally and has become a pandemic. People have lost their lives due to
the virus and the lack of counter measures in place. Given the increasing
caseload and uncertainty of spread, there is an urgent need to develop machine
learning techniques to predict the spread of COVID-19. Prediction of the spread
can allow counter measures and actions to be implemented to mitigate the spread
of COVID-19. In this paper, we propose a deep learning technique, called Deep
Sequential Prediction Model (DSPM) and machine learning based Non-parametric
Regression Model (NRM) to predict the spread of COVID-19. Our proposed models
were trained and tested on novel coronavirus 2019 dataset, which contains 19.53
Million confirmed cases of COVID-19. Our proposed models were evaluated by
using Mean Absolute Error and compared with baseline method. Our experimental
results, both quantitative and qualitative, demonstrate the superior prediction
performance of the proposed models.
</p>
<a href="http://arxiv.org/abs/2008.01170" target="_blank">arXiv:2008.01170</a> [<a href="http://arxiv.org/pdf/2008.01170" target="_blank">pdf</a>]

<h2>Learning Off-Policy with Online Planning. (arXiv:2008.10066v2 [cs.LG] UPDATED)</h2>
<h3>Harshit Sikchi, Wenxuan Zhou, David Held</h3>
<p>We propose Learning Off-Policy with Online Planning (LOOP), an efficient
reinforcement learning framework, combining the benefits of model-based local
trajectory optimization and off-policy algorithms. The agent learns a dynamics
model and then uses trajectory optimization with the learned model to select
actions. To sidestep the myopic effect of fixed-horizon trajectory
optimization, a value function learned through an off-policy algorithm is
attached to the end of the planning horizon. We investigate various
instantiations of this framework and demonstrate its benefit in three settings:
online reinforcement learning, offline reinforcement learning, and safe
learning. We show that this method significantly improves the underlying
model-based and model-free algorithms and achieves state-of-the-art performance
in a variety of settings.
</p>
<a href="http://arxiv.org/abs/2008.10066" target="_blank">arXiv:2008.10066</a> [<a href="http://arxiv.org/pdf/2008.10066" target="_blank">pdf</a>]

<h2>Learning Personalized Models of Human Behavior in Chess. (arXiv:2008.10086v2 [cs.AI] UPDATED)</h2>
<h3>Reid McIlroy-Young, Russell Wang, Siddhartha Sen, Jon Kleinberg, Ashton Anderson</h3>
<p>Even when machine learning systems surpass human ability in a domain, there
are many reasons why AI systems that capture human-like behavior would be
desirable: humans may want to learn from them, they may need to collaborate
with them, or they may expect them to serve as partners in an extended
interaction. Motivated by this goal of human-like AI systems, the problem of
predicting human actions -- as opposed to predicting optimal actions -- has
become an increasingly useful task. We extend this line of work by developing
highly accurate personalized models of human behavior in the context of chess.
Chess is a rich domain for exploring these questions, since it combines a set
of appealing features: AI systems have achieved superhuman performance but
still interact closely with human chess players both as opponents and
preparation tools, and there is an enormous amount of recorded data on
individual players. Starting with an open-source version of AlphaZero trained
on a population of human players, we demonstrate that we can significantly
improve prediction of a particular player's moves by applying a series of
fine-tuning adjustments. Furthermore, we can accurately perform stylometry --
predicting who made a given set of actions -- indicating that our personalized
models capture human decision-making at an individual level.
</p>
<a href="http://arxiv.org/abs/2008.10086" target="_blank">arXiv:2008.10086</a> [<a href="http://arxiv.org/pdf/2008.10086" target="_blank">pdf</a>]

<h2>Bounded Risk-Sensitive Markov Games: Forward Policy Design and Inverse Reward Learning with Iterative Reasoning and Cumulative Prospect Theory. (arXiv:2009.01495v6 [cs.LG] UPDATED)</h2>
<h3>Ran Tian, Liting Sun, Masayoshi Tomizuka</h3>
<p>Classical game-theoretic approaches for multi-agent systems in both the
forward policy design problem and the inverse reward learning problem often
make strong rationality assumptions: agents perfectly maximize expected
utilities under uncertainties. Such assumptions, however, substantially
mismatch with observed humans' behaviors such as satisficing with sub-optimal,
risk-seeking, and loss-aversion decisions. In this paper, we investigate the
problem of bounded risk-sensitive Markov Game (BRSMG) and its inverse reward
learning problem for modeling human realistic behaviors and learning human
behavioral models. Drawing on iterative reasoning models and cumulative
prospect theory, we embrace that humans have bounded intelligence and maximize
risk-sensitive utilities in BRSMGs. Convergence analysis for both the forward
policy design and the inverse reward learning problems are established under
the BRSMG framework. We validate the proposed forward policy design and inverse
reward learning algorithms in a navigation scenario. The results show that the
behaviors of agents demonstrate both risk-averse and risk-seeking
characteristics. Moreover, in the inverse reward learning task, the proposed
bounded risk-sensitive inverse learning algorithm outperforms a baseline
risk-neutral inverse learning algorithm by effectively recovering not only more
accurate reward values but also the intelligence levels and the risk-measure
parameters given demonstrations of agents' interactive behaviors.
</p>
<a href="http://arxiv.org/abs/2009.01495" target="_blank">arXiv:2009.01495</a> [<a href="http://arxiv.org/pdf/2009.01495" target="_blank">pdf</a>]

<h2>Online Disease Self-diagnosis with Inductive Heterogeneous Graph Convolutional Networks. (arXiv:2009.02625v2 [cs.LG] UPDATED)</h2>
<h3>Zifeng Wang, Rui Wen, Xi Chen, Shilei Cao, Shao-Lun Huang, Buyue Qian, Yefeng Zheng</h3>
<p>We propose a Healthcare Graph Convolutional Network (HealGCN) to offer
disease self-diagnosis service for online users based on Electronic Healthcare
Records (EHRs). Two main challenges are focused in this paper for online
disease diagnosis: (1) serving cold-start users via graph convolutional
networks and (2) handling scarce clinical description via a symptom retrieval
system. To this end, we first organize the EHR data into a heterogeneous graph
that is capable of modeling complex interactions among users, symptoms and
diseases, and tailor the graph representation learning towards disease
diagnosis with an inductive learning paradigm. Then, we build a disease
self-diagnosis system with a corresponding EHR Graph-based Symptom Retrieval
System (GraphRet) that can search and provide a list of relevant alternative
symptoms by tracing the predefined meta-paths. GraphRet helps enrich the seed
symptom set through the EHR graph when confronting users with scarce
descriptions, hence yield better diagnosis accuracy. At last, we validate the
superiority of our model on a large-scale EHR dataset.
</p>
<a href="http://arxiv.org/abs/2009.02625" target="_blank">arXiv:2009.02625</a> [<a href="http://arxiv.org/pdf/2009.02625" target="_blank">pdf</a>]

<h2>Quantifying the Preferential Direction of the Model Gradient in Adversarial Training With Projected Gradient Descent. (arXiv:2009.04709v2 [stat.ML] UPDATED)</h2>
<h3>Ricardo Bigolin Lanfredi, Joyce D. Schroeder, Tolga Tasdizen</h3>
<p>Adversarial training, especially projected gradient descent (PGD), has been
the most successful approach for improving robustness against adversarial
attacks. After adversarial training, gradients of models with respect to their
inputs have a preferential direction. However, the direction of alignment is
not mathematically well established, making it difficult to evaluate
quantitatively. We propose a novel definition of this direction as the
direction of the vector pointing toward the closest point of the support of the
closest inaccurate class in decision space. To evaluate the alignment with this
direction after adversarial training, we apply a metric that uses generative
adversarial networks to produce the smallest residual needed to change the
class present in the image. We show that PGD-trained models have a higher
alignment than the baseline according to our definition, that our metric
presents higher alignment values than a competing metric formulation, and that
enforcing this alignment increases the robustness of models.
</p>
<a href="http://arxiv.org/abs/2009.04709" target="_blank">arXiv:2009.04709</a> [<a href="http://arxiv.org/pdf/2009.04709" target="_blank">pdf</a>]

<h2>DANCE: Differentiable Accelerator/Network Co-Exploration. (arXiv:2009.06237v2 [cs.LG] UPDATED)</h2>
<h3>Kanghyun Choi, Deokki Hong, Hojae Yoon, Joonsang Yu, Youngsok Kim, Jinho Lee</h3>
<p>To cope with the ever-increasing computational demand of the DNN execution,
recent neural architecture search (NAS) algorithms consider hardware cost
metrics into account, such as GPU latency. To further pursue a fast, efficient
execution, DNN-specialized hardware accelerators are being designed for
multiple purposes, which far-exceeds the efficiency of the GPUs. However, those
hardware-related metrics have been proven to exhibit non-linear relationships
with the network architectures. Therefore it became a chicken-and-egg problem
to optimize the network against the accelerator, or to optimize the accelerator
against the network. In such circumstances, this work presents DANCE, a
differentiable approach towards the co-exploration of the hardware accelerator
and network architecture design. At the heart of DANCE is a differentiable
evaluator network. By modeling the hardware evaluation software with a neural
network, the relation between the accelerator architecture and the hardware
metrics becomes differentiable, allowing the search to be performed with
backpropagation. Compared to the naive existing approaches, our method performs
co-exploration in a significantly shorter time, while achieving superior
accuracy and hardware cost metrics.
</p>
<a href="http://arxiv.org/abs/2009.06237" target="_blank">arXiv:2009.06237</a> [<a href="http://arxiv.org/pdf/2009.06237" target="_blank">pdf</a>]

<h2>RaLL: End-to-end Radar Localization on Lidar Map Using Differentiable Measurement Model. (arXiv:2009.07061v2 [cs.RO] UPDATED)</h2>
<h3>Huan Yin, Yue Wang, Runjian Chen, Rong Xiong</h3>
<p>Compared to the onboard camera and laser scanner, radar sensor provides
lighting and weather invariant sensing, which is naturally suitable for
long-term localization under adverse conditions. However, radar data is sparse
and noisy, resulting in challenges for radar mapping. On the other hand, the
most popular available map currently is built by lidar. In this paper, we
propose an end-to-end deep learning framework for Radar Localization on Lidar
Map (RaLL) to bridge the gap, which not only achieves the robust radar
localization but also exploits the mature lidar mapping technique, thus
reducing the cost of radar mapping. We first embed both sensor modals into a
common feature space by a neural network. Then multiple offsets are added to
the map modal for exhaustive similarity evaluation against the current radar
modal, yielding the regression of the current pose. Finally, we apply this
differentiable measurement model to a Kalman Filter (KF) to learn the whole
sequential localization process in an end-to-end manner. \textit{The whole
learning system is differentiable with the network based measurement model at
the front-end and KF at the back-end.} To validate the feasibility and
effectiveness, we employ multi-session multi-scene datasets collected from the
real world, and the results demonstrate that our proposed system achieves
superior performance over $90km$ driving, even in generalization scenarios
where the model training is in UK, while testing in South Korea. We also
release the source code publicly.
</p>
<a href="http://arxiv.org/abs/2009.07061" target="_blank">arXiv:2009.07061</a> [<a href="http://arxiv.org/pdf/2009.07061" target="_blank">pdf</a>]

<h2>MSTREAM: Fast Anomaly Detection in Multi-Aspect Streams. (arXiv:2009.08451v3 [cs.LG] UPDATED)</h2>
<h3>Siddharth Bhatia, Arjit Jain, Pan Li, Ritesh Kumar, Bryan Hooi</h3>
<p>Given a stream of entries in a multi-aspect data setting i.e., entries having
multiple dimensions, how can we detect anomalous activities in an unsupervised
manner? For example, in the intrusion detection setting, existing work seeks to
detect anomalous events or edges in dynamic graph streams, but this does not
allow us to take into account additional attributes of each entry. Our work
aims to define a streaming multi-aspect data anomaly detection framework,
termed MSTREAM which can detect unusual group anomalies as they occur, in a
dynamic manner. MSTREAM has the following properties: (a) it detects anomalies
in multi-aspect data including both categorical and numeric attributes; (b) it
is online, thus processing each record in constant time and constant memory;
(c) it can capture the correlation between multiple aspects of the data.
MSTREAM is evaluated over the KDDCUP99, CICIDS-DoS, UNSW-NB 15 and CICIDS-DDoS
datasets, and outperforms state-of-the-art baselines.
</p>
<a href="http://arxiv.org/abs/2009.08451" target="_blank">arXiv:2009.08451</a> [<a href="http://arxiv.org/pdf/2009.08451" target="_blank">pdf</a>]

<h2>Reconstructing Actions To Explain Deep Reinforcement Learning. (arXiv:2009.08507v3 [cs.AI] UPDATED)</h2>
<h3>Xuan Chen, Zifan Wang, Yucai Fan, Bonan Jin, Piotr Mardziel, Carlee Joe-Wong, Anupam Datta</h3>
<p>Feature attribution has been a foundational building block for explaining the
input feature importance in supervised learning with Deep Neural Network
(DNNs), but face new challenges when applied to deep Reinforcement Learning
(RL).We propose a new approach to explaining deep RL actions by defining a
class of \emph{action reconstruction} functions that mimic the behavior of a
network in deep RL. This approach allows us to answer more complex
explainability questions than direct application of DNN attribution methods,
which we adapt to \emph{behavior-level attributions} in building our action
reconstructions. It also allows us to define \emph{agreement}, a metric for
quantitatively evaluating the explainability of our methods. Our experiments on
a variety of Atari games suggest that perturbation-based attribution methods
are significantly more suitable in reconstructing actions to explain the deep
RL agent than alternative attribution methods, and show greater
\emph{agreement} than existing explainability work utilizing attention. We
further show that action reconstruction allows us to demonstrate how a deep
agent learns to play Pac-Man game.
</p>
<a href="http://arxiv.org/abs/2009.08507" target="_blank">arXiv:2009.08507</a> [<a href="http://arxiv.org/pdf/2009.08507" target="_blank">pdf</a>]

<h2>2D-3D Geometric Fusion Network using Multi-Neighbourhood Graph Convolution for RGB-D Indoor Scene Classification. (arXiv:2009.11154v2 [cs.CV] UPDATED)</h2>
<h3>Albert Mosella-Montoro, Javier Ruiz-Hidalgo</h3>
<p>Multi-modal fusion has been proved to help enhance the performance of scene
classification tasks. This paper presents a 2D-3D Fusion stage that combines 3D
Geometric Features with 2D Texture Features obtained by 2D Convolutional Neural
Networks. To get a robust 3D Geometric embedding, a network that uses two novel
layers is proposed. The first layer, Multi-Neighbourhood Graph Convolution,
aims to learn a more robust geometric descriptor of the scene combining two
different neighbourhoods: one in the Euclidean space and the other in the
Feature space. The second proposed layer, Nearest Voxel Pooling, improves the
performance of the well-known Voxel Pooling. Experimental results, using
NYU-Depth-V2 and SUN RGB-D datasets, show that the proposed method outperforms
the current state-of-the-art in RGB-D indoor scene classification task.
</p>
<a href="http://arxiv.org/abs/2009.11154" target="_blank">arXiv:2009.11154</a> [<a href="http://arxiv.org/pdf/2009.11154" target="_blank">pdf</a>]

<h2>Geometric Disentanglement by Random Convex Polytopes. (arXiv:2009.13987v2 [cs.LG] UPDATED)</h2>
<h3>Michael Joswig, Marek Kaluba, Lukas Ruff</h3>
<p>We propose a new geometric method for measuring the quality of
representations obtained from deep learning. Our approach, called Random
Polytope Descriptor, provides an efficient description of data points based on
the construction of random convex polytopes. We demonstrate the use of our
technique by qualitatively comparing the behavior of classic and regularized
autoencoders. This reveals that applying regularization to autoencoder networks
may decrease the out-of-distribution detection performance in latent space.
While our technique is similar in spirit to $k$-means clustering, we achieve
significantly better false positive/negative balance in clustering tasks on
autoencoded datasets.
</p>
<a href="http://arxiv.org/abs/2009.13987" target="_blank">arXiv:2009.13987</a> [<a href="http://arxiv.org/pdf/2009.13987" target="_blank">pdf</a>]

<h2>Efficient texture-aware multi-GAN for image inpainting. (arXiv:2009.14721v2 [cs.CV] UPDATED)</h2>
<h3>Mohamed Abbas Hedjazi, Yakup Genc</h3>
<p>Recent GAN-based (Generative adversarial networks) inpainting methods show
remarkable improvements and generate plausible images using multi-stage
networks or Contextual Attention Modules (CAM). However, these techniques
increase the model complexity limiting their application in low-resource
environments. Furthermore, they fail in generating high-resolution images with
realistic texture details due to the GAN stability problem. Motivated by these
observations, we propose a multi-GAN architecture improving both the
performance and rendering efficiency. Our training schema optimizes the
parameters of four progressive efficient generators and discriminators in an
end-to-end manner. Filling in low-resolution images is less challenging for
GANs due to the small dimensional space. Meanwhile, it guides higher resolution
generators to learn the global structure consistency of the image. To constrain
the inpainting task and ensure fine-grained textures, we adopt an LBP-based
loss function to minimize the difference between the generated and the ground
truth textures. We conduct our experiments on Places2 and CelebHQ datasets.
Qualitative and quantitative results show that the proposed method not only
performs favorably against state-of-the-art algorithms but also speeds up the
inference time.
</p>
<a href="http://arxiv.org/abs/2009.14721" target="_blank">arXiv:2009.14721</a> [<a href="http://arxiv.org/pdf/2009.14721" target="_blank">pdf</a>]

<h2>Agnostic Learning of Halfspaces with Gradient Descent via Soft Margins. (arXiv:2010.00539v2 [cs.LG] UPDATED)</h2>
<h3>Spencer Frei, Yuan Cao, Quanquan Gu</h3>
<p>We analyze the properties of gradient descent on convex surrogates for the
zero-one loss for the agnostic learning of linear halfspaces. If $\mathsf{OPT}$
is the best classification error achieved by a halfspace, by appealing to the
notion of soft margins we are able to show that gradient descent finds
halfspaces with classification error $\tilde O(\mathsf{OPT}^{1/2}) +
\varepsilon$ in $\mathrm{poly}(d,1/\varepsilon)$ time and sample complexity for
a broad class of distributions that includes log-concave isotropic
distributions as a subclass. Along the way we answer a question recently posed
by Ji et al. (2020) on how the tail behavior of a loss function can affect
sample complexity and runtime guarantees for gradient descent.
</p>
<a href="http://arxiv.org/abs/2010.00539" target="_blank">arXiv:2010.00539</a> [<a href="http://arxiv.org/pdf/2010.00539" target="_blank">pdf</a>]

<h2>Understanding Self-supervised Learning with Dual Deep Networks. (arXiv:2010.00578v6 [cs.LG] UPDATED)</h2>
<h3>Yuandong Tian, Lantao Yu, Xinlei Chen, Surya Ganguli</h3>
<p>We propose a novel theoretical framework to understand contrastive
self-supervised learning (SSL) methods that employ dual pairs of deep ReLU
networks (e.g., SimCLR). First, we prove that in each SGD update of SimCLR with
various loss functions, including simple contrastive loss, soft Triplet loss
and InfoNCE loss, the weights at each layer are updated by a \emph{covariance
operator} that specifically amplifies initial random selectivities that vary
across data samples but survive averages over data augmentations. To further
study what role the covariance operator plays and which features are learned in
such a process, we model data generation and augmentation processes through a
\emph{hierarchical latent tree model} (HLTM) and prove that the hidden neurons
of deep ReLU networks can learn the latent variables in HLTM, despite the fact
that the network receives \emph{no direct supervision} from these unobserved
latent variables. This leads to a provable emergence of hierarchical features
through the amplification of initially random selectivities through contrastive
SSL. Extensive numerical studies justify our theoretical findings. Code is
released in https://github.com/facebookresearch/luckmatters/tree/master/ssl.
</p>
<a href="http://arxiv.org/abs/2010.00578" target="_blank">arXiv:2010.00578</a> [<a href="http://arxiv.org/pdf/2010.00578" target="_blank">pdf</a>]

<h2>Quickly Finding a Benign Region via Heavy Ball Momentum in Non-Convex Optimization. (arXiv:2010.01449v2 [cs.LG] UPDATED)</h2>
<h3>Jun-Kun Wang, Jacob Abernethy</h3>
<p>The Heavy Ball Method, proposed by Polyak over five decades ago, is a
first-order method for optimizing continuous functions. While its stochastic
counterpart has proven extremely popular in training deep networks, there are
almost no known functions where deterministic Heavy Ball is provably faster
than the simple and classical gradient descent algorithm in non-convex
optimization. The success of Heavy Ball has thus far eluded theoretical
understanding. Our goal is to address this gap, and in the present work we
identify two non-convex problems where we provably show that the Heavy Ball
momentum helps the iterate to enter a benign region that contains a global
optimal point faster. We show that Heavy Ball exhibits simple dynamics that
clearly reveal the benefit of using a larger value of momentum parameter for
the problems. The first of these optimization problems is the phase retrieval
problem, which has useful applications in physical science. The second of these
optimization problems is the cubic-regularized minimization, a critical
subroutine required by Nesterov-Polyak cubic-regularized method to find
second-order stationary points in general smooth non-convex problems.
</p>
<a href="http://arxiv.org/abs/2010.01449" target="_blank">arXiv:2010.01449</a> [<a href="http://arxiv.org/pdf/2010.01449" target="_blank">pdf</a>]

<h2>A Modular Analysis of Provable Acceleration via Polyak's Momentum: Training a Wide ReLU Network and a Deep Linear Network. (arXiv:2010.01618v2 [cs.LG] UPDATED)</h2>
<h3>Jun-Kun Wang, Chi-Heng Lin, Jacob Abernethy</h3>
<p>Incorporating a so-called "momentum" dynamic in gradient descent methods is
widely used in neural net training as it has been broadly observed that, at
least empirically, it often leads to significantly faster convergence. At the
same time, there are very few theoretical guarantees in the literature to
explain this apparent acceleration effect. Even for the classical strongly
convex quadratic problems, several existing results only show Polyak's momentum
has an accelerated linear rate asymptotically. In this paper, we first revisit
the quadratic problems and show a non-asymptotic accelerated linear rate of
Polyak's momentum. Then, we provably show that Polyak's momentum achieves
acceleration for training a one-layer wide ReLU network and a deep linear
network, which are perhaps the two most popular canonical models for studying
optimization and deep learning in the literature. Prior work Du at al. 2019 and
Wu et al. 2019 showed that using vanilla gradient descent, and with an use of
over-parameterization, the error decays as $(1- \Theta(\frac{1}{ \kappa'}))^t$
after $t$ iterations, where $\kappa'$ is the condition number of a Gram Matrix.
Our result shows that with the appropriate choice of parameters Polyak's
momentum has a rate of $(1-\Theta(\frac{1}{\sqrt{\kappa'}}))^t$. For the deep
linear network, prior work Hu et al. 2020 showed that vanilla gradient descent
has a rate of $(1-\Theta(\frac{1}{\kappa}))^t$, where $\kappa$ is the condition
number of a data matrix. Our result shows an acceleration rate $(1-
\Theta(\frac{1}{\sqrt{\kappa}}))^t$ is achievable by Polyak's momentum. All the
results in this work are obtained from a modular analysis, which can be of
independent interest. This work establishes that momentum does indeed speed up
neural net training.
</p>
<a href="http://arxiv.org/abs/2010.01618" target="_blank">arXiv:2010.01618</a> [<a href="http://arxiv.org/pdf/2010.01618" target="_blank">pdf</a>]

<h2>Towards Better Understanding Meta-learning Methods through Multi-task Representation Learning Theory. (arXiv:2010.01992v2 [cs.LG] UPDATED)</h2>
<h3>Quentin Bouniot, Ievgen Redko, Romaric Audigier, Ang&#xe9;lique Loesch, Yevhenii Zotkin, Amaury Habrard</h3>
<p>In this paper, we consider the framework of multi-task representation (MTR)
learning where the goal is to use source tasks to learn a representation that
reduces the sample complexity of solving a target task. We start by reviewing
recent advances in MTR theory and show that they can provide novel insights for
popular meta-learning algorithms when analyzed within this framework. In
particular, we highlight a fundamental difference between gradient-based and
metric-based algorithms and put forward a theoretical analysis to explain it.
Finally, we use the derived insights to improve the generalization capacity of
meta-learning methods via a new spectral-based regularization term and confirm
its efficiency through experimental studies on classic few-shot classification
and continual learning benchmarks. To the best of our knowledge, this is the
first contribution that puts the most recent learning bounds of MTR theory into
practice of training popular meta-learning methods.
</p>
<a href="http://arxiv.org/abs/2010.01992" target="_blank">arXiv:2010.01992</a> [<a href="http://arxiv.org/pdf/2010.01992" target="_blank">pdf</a>]

<h2>Provable Hierarchical Imitation Learning via EM. (arXiv:2010.03133v2 [cs.LG] UPDATED)</h2>
<h3>Zhiyu Zhang, Ioannis Paschalidis</h3>
<p>Due to recent empirical successes, the options framework for hierarchical
reinforcement learning is gaining increasing popularity. Rather than learning
from rewards which suffers from the curse of dimensionality, we consider
learning an options-type hierarchical policy from expert demonstrations. Such a
problem is referred to as hierarchical imitation learning. Converting this
problem to parameter inference in a latent variable model, we theoretically
characterize the EM approach proposed by Daniel et al. (2016). The population
level algorithm is analyzed as an intermediate step, which is nontrivial due to
the samples being correlated. If the expert policy can be parameterized by a
variant of the options framework, then under regularity conditions, we prove
that the proposed algorithm converges with high probability to a norm ball
around the true parameter. To our knowledge, this is the first performance
guarantee for an hierarchical imitation learning algorithm that only observes
primitive state-action pairs.
</p>
<a href="http://arxiv.org/abs/2010.03133" target="_blank">arXiv:2010.03133</a> [<a href="http://arxiv.org/pdf/2010.03133" target="_blank">pdf</a>]

<h2>Controllable Pareto Multi-Task Learning. (arXiv:2010.06313v2 [cs.LG] UPDATED)</h2>
<h3>Xi Lin, Zhiyuan Yang, Qingfu Zhang, Sam Kwong</h3>
<p>A multi-task learning (MTL) system aims at solving multiple related tasks at
the same time. With a fixed model capacity, the tasks would be conflicted with
each other, and the system usually has to make a trade-off among learning all
of them together. For many real-world applications where the trade-off has to
be made online, multiple models with different preferences over tasks have to
be trained and stored. This work proposes a novel controllable Pareto
multi-task learning framework, to enable the system to make real-time trade-off
control among different tasks with a single model. To be specific, we formulate
the MTL as a preference-conditioned multiobjective optimization problem, with a
parametric mapping from preferences to the corresponding trade-off solutions. A
single hypernetwork-based multi-task neural network is built to learn all tasks
with different trade-off preferences among them, where the hypernetwork
generates the model parameters conditioned on the preference. For inference,
MTL practitioners can easily control the model performance based on different
trade-off preferences in real-time. Experiments on different applications
demonstrate that the proposed model is efficient for solving various MTL
problems.
</p>
<a href="http://arxiv.org/abs/2010.06313" target="_blank">arXiv:2010.06313</a> [<a href="http://arxiv.org/pdf/2010.06313" target="_blank">pdf</a>]

<h2>Deep Learning from Small Amount of Medical Data with Noisy Labels: A Meta-Learning Approach. (arXiv:2010.06939v2 [cs.CV] UPDATED)</h2>
<h3>G&#xf6;rkem Algan, Ilkay Ulusoy, &#x15e;aban G&#xf6;n&#xfc;l, Banu Turgut, Berker Bakbak</h3>
<p>Computer vision systems recently made a big leap thanks to deep neural
networks. However, these systems require correctly labeled large datasets in
order to be trained properly, which is very difficult to obtain for medical
applications. Two main reasons for label noise in medical applications are the
high complexity of the data and conflicting opinions of experts. Moreover,
medical imaging datasets are commonly tiny, which makes each data very
important in learning. As a result, if not handled properly, label noise
significantly degrades the performance. Therefore, a label-noise-robust
learning algorithm that makes use of the meta-learning paradigm is proposed in
this article. The proposed solution is tested on retinopathy of prematurity
(ROP) dataset with a very high label noise of 68%. Results show that the
proposed algorithm significantly improves the classification algorithm's
performance in the presence of noisy labels.
</p>
<a href="http://arxiv.org/abs/2010.06939" target="_blank">arXiv:2010.06939</a> [<a href="http://arxiv.org/pdf/2010.06939" target="_blank">pdf</a>]

<h2>Maximum Moment Restriction for Instrumental Variable Regression. (arXiv:2010.07684v3 [cs.LG] UPDATED)</h2>
<h3>Rui Zhang, Masaaki Imaizumi, Bernhard Sch&#xf6;lkopf, Krikamol Muandet</h3>
<p>We propose a simple framework for nonlinear instrumental variable (IV)
regression based on a kernelized conditional moment restriction (CMR) known as
a maximum moment restriction (MMR). The MMR is formulated by maximizing the
interaction between the residual and the instruments belonging to a unit ball
in a reproducing kernel Hilbert space (RKHS). The MMR allows us to reformulate
the IV regression as a single-step empirical risk minimization problem, where
the risk depends on the reproducing kernel on the instrument and can be
estimated by a U-statistic or V-statistic. This simplification not only eases
the proofs of consistency and asymptotic normality in both parametric and
non-parametric settings, but also results in easy-to-use algorithms with an
efficient hyper-parameter selection procedure. We demonstrate the advantages of
our framework over existing ones using experiments on both synthetic and
real-world data.
</p>
<a href="http://arxiv.org/abs/2010.07684" target="_blank">arXiv:2010.07684</a> [<a href="http://arxiv.org/pdf/2010.07684" target="_blank">pdf</a>]

<h2>Deep Conditional Transformation Models. (arXiv:2010.07860v2 [cs.LG] UPDATED)</h2>
<h3>Philipp F.M. Baumann, Torsten Hothorn, David R&#xfc;gamer</h3>
<p>Learning the cumulative distribution function (CDF) of an outcome variable
conditional on a set of features remains challenging, especially in
high-dimensional settings. Conditional transformation models provide a
semi-parametric approach that allows to model a large class of conditional CDFs
without an explicit parametric distribution assumption and with only a few
parameters. Existing estimation approaches within this class are, however,
either limited in their complexity and applicability to unstructured data
sources such as images or text, lack interpretability, or are restricted to
certain types of outcomes. We close this gap by introducing the class of deep
conditional transformation models which unifies existing approaches and allows
to learn both interpretable (non-)linear model terms and more complex neural
network predictors in one holistic framework. To this end we propose a novel
network architecture, provide details on different model definitions and derive
suitable constraints as well as network regularization terms. We demonstrate
the efficacy of our approach through numerical experiments and applications.
</p>
<a href="http://arxiv.org/abs/2010.07860" target="_blank">arXiv:2010.07860</a> [<a href="http://arxiv.org/pdf/2010.07860" target="_blank">pdf</a>]

<h2>Graph Neural Network for Large-Scale Network Localization. (arXiv:2010.11653v2 [cs.LG] UPDATED)</h2>
<h3>Wenzhong Yan, Di Jin, Zhidi Lin, Feng Yin</h3>
<p>Graph neural networks (GNNs) are popular to use for classifying structured
data in the context of machine learning. But surprisingly, they are rarely
applied to regression problems. In this work, we adopt GNN for a classic but
challenging nonlinear regression problem, namely the network localization. Our
main findings are in order. First, GNN is potentially the best solution to
large-scale network localization in terms of accuracy, robustness and
computational time. Second, proper thresholding of the communication range is
essential to its superior performance. Simulation results corroborate that the
proposed GNN based method outperforms all state-of-the-art benchmarks by far.
Such inspiring results are theoretically justified in terms of data
aggregation, non-line-of-sight (NLOS) noise removal and low-pass filtering
effect, all affected by the threshold for neighbor selection. Code is available
at https://github.com/Yanzongzi/GNN-For-localization.
</p>
<a href="http://arxiv.org/abs/2010.11653" target="_blank">arXiv:2010.11653</a> [<a href="http://arxiv.org/pdf/2010.11653" target="_blank">pdf</a>]

<h2>On the Equivalence of Decoupled Graph Convolution Network and Label Propagation. (arXiv:2010.12408v2 [cs.LG] UPDATED)</h2>
<h3>Hande Dong, Jiawei Chen, Fuli Feng, Xiangnan He, Shuxian Bi, Zhaolin Ding, Peng Cui</h3>
<p>The original design of Graph Convolution Network (GCN) couples feature
transformation and neighborhood aggregation for node representation learning.
Recently, some work shows that coupling is inferior to decoupling, which
supports deep graph propagation better and has become the latest paradigm of
GCN (e.g., APPNP and SGCN). Despite effectiveness, the working mechanisms of
the decoupled GCN are not well understood. In this paper, we explore the
decoupled GCN for semi-supervised node classification from a novel and
fundamental perspective -- label propagation. We conduct thorough theoretical
analyses, proving that the decoupled GCN is essentially the same as the
two-step label propagation: first, propagating the known labels along the graph
to generate pseudo-labels for the unlabeled nodes, and second, training normal
neural network classifiers on the augmented pseudo-labeled data. More
interestingly, we reveal the effectiveness of decoupled GCN: going beyond the
conventional label propagation, it could automatically assign structure- and
model- aware weights to the pseudo-label data. This explains why the decoupled
GCN is relatively robust to the structure noise and over-smoothing, but
sensitive to the label noise and model initialization. Based on this insight,
we propose a new label propagation method named Propagation then Training
Adaptively (PTA), which overcomes the flaws of the decoupled GCN with a dynamic
and adaptive weighting strategy. Our PTA is simple yet more effective and
robust than decoupled GCN. We empirically validate our findings on four
benchmark datasets, demonstrating the advantages of our method. The code is
available at https://github.com/DongHande/PT_propagation_then_training.
</p>
<a href="http://arxiv.org/abs/2010.12408" target="_blank">arXiv:2010.12408</a> [<a href="http://arxiv.org/pdf/2010.12408" target="_blank">pdf</a>]

<h2>Graph Contrastive Learning with Adaptive Augmentation. (arXiv:2010.14945v2 [cs.LG] UPDATED)</h2>
<h3>Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, Liang Wang</h3>
<p>Recently, contrastive learning (CL) has emerged as a successful method for
unsupervised graph representation learning. Most graph CL methods first perform
stochastic augmentation on the input graph to obtain two graph views and
maximize the agreement of representations in the two views. Despite the
prosperous development of graph CL methods, the design of graph augmentation
schemes -- a crucial component in CL -- remains rarely explored. We argue that
the data augmentation schemes should preserve intrinsic structures and
attributes of graphs, which will force the model to learn representations that
are insensitive to perturbation on unimportant nodes and edges. However, most
existing methods adopt uniform data augmentation schemes, like uniformly
dropping edges and uniformly shuffling features, leading to suboptimal
performance. In this paper, we propose a novel graph contrastive representation
learning method with adaptive augmentation that incorporates various priors for
topological and semantic aspects of the graph. Specifically, on the topology
level, we design augmentation schemes based on node centrality measures to
highlight important connective structures. On the node attribute level, we
corrupt node features by adding more noise to unimportant node features, to
enforce the model to recognize underlying semantic information. We perform
extensive experiments of node classification on a variety of real-world
datasets. Experimental results demonstrate that our proposed method
consistently outperforms existing state-of-the-art baselines and even surpasses
some supervised counterparts, which validates the effectiveness of the proposed
contrastive framework with adaptive augmentation.
</p>
<a href="http://arxiv.org/abs/2010.14945" target="_blank">arXiv:2010.14945</a> [<a href="http://arxiv.org/pdf/2010.14945" target="_blank">pdf</a>]

<h2>Revisiting Graph Neural Networks for Link Prediction. (arXiv:2010.16103v2 [cs.LG] UPDATED)</h2>
<h3>Muhan Zhang, Pan Li, Yinglong Xia, Kai Wang, Long Jin</h3>
<p>Graph neural networks (GNNs) have achieved great success in recent years.
Three most common applications include node classification, link prediction,
and graph classification. While there is rich literature on node classification
and graph classification, GNN for link prediction is relatively less studied
and less understood. One common practice in previous works is to first compute
node representations through a GNN, and then directly aggregate two node
representations as a link representation. In this paper, we show the
limitations of such an approach, and propose a labeling trick to make GNNs
learn better link representations. Labeling trick assigns labels to nodes as
their additional features according to nodes' relationships with the target
link. We show theoretically that GNNs applied to such labeled graphs can learn
most expressive link representations. We also show that one state-of-the-art
link prediction model, SEAL, exactly uses a labeling trick. Labeling trick
brings up to 195% performance gains over plain GNNs, achieving 3 first places
on the OGB link prediction leaderboard.
</p>
<a href="http://arxiv.org/abs/2010.16103" target="_blank">arXiv:2010.16103</a> [<a href="http://arxiv.org/pdf/2010.16103" target="_blank">pdf</a>]

<h2>SapAugment: Learning A Sample Adaptive Policy for Data Augmentation. (arXiv:2011.01156v2 [cs.LG] UPDATED)</h2>
<h3>Ting-Yao Hu, Ashish Shrivastava, Jen-Hao Rick Chang, Hema Koppula, Stefan Braun, Kyuyeon Hwang, Ozlem Kalinli, Oncel Tuzel</h3>
<p>Data augmentation methods usually apply the same augmentation (or a mix of
them) to all the training samples. For example, to perturb data with noise, the
noise is sampled from a Normal distribution with a fixed standard deviation,
for all samples. We hypothesize that a hard sample with high training loss
already provides strong training signal to update the model parameters and
should be perturbed with mild or no augmentation. Perturbing a hard sample with
a strong augmentation may also make it too hard to learn from. Furthermore, a
sample with low training loss should be perturbed by a stronger augmentation to
provide more robustness to a variety of conditions. To formalize these
intuitions, we propose a novel method to learn a Sample-Adaptive Policy for
Augmentation -- SapAugment. Our policy adapts the augmentation parameters based
on the training loss of the data samples. In the example of Gaussian noise, a
hard sample will be perturbed with a low variance noise and an easy sample with
a high variance noise. Furthermore, the proposed method combines multiple
augmentation methods into a methodical policy learning framework and obviates
hand-crafting augmentation parameters by trial-and-error. We apply our method
on an automatic speech recognition (ASR) task, and combine existing and novel
augmentations using the proposed framework. We show substantial improvement, up
to 21% relative reduction in word error rate on LibriSpeech dataset, over the
state-of-the-art speech augmentation method.
</p>
<a href="http://arxiv.org/abs/2011.01156" target="_blank">arXiv:2011.01156</a> [<a href="http://arxiv.org/pdf/2011.01156" target="_blank">pdf</a>]

<h2>An HVS-Oriented Saliency Map Prediction Model. (arXiv:2011.04076v6 [cs.CV] UPDATED)</h2>
<h3>Qiang Li</h3>
<p>Visual attention is one of the most significant characteristics for selecting
and understanding the outside redundancy world. The nature complex scenes,
including larger redundancy and human vision, cannot be processing all
information simultaneously because of the information bottleneck. The human
visual system mainly focuses on dominant parts of the scenes to reduce the
input visual redundancy information. It is commonly known as visual attention
prediction or visual saliency map. This paper proposes a new saliency
prediction architecture WECSF which inspired by human low-level visual cortex
function. The model consists of opponent color channels, wavelet transform,
wavelet energy map, and contrast sensitivity function for extracting low-level
image features and maximum approximation to the human visual system. The
proposed model is evaluated several datasets, including MIT1003, MIT300,
TORONTO, SID4VAM and UCF Sports dataset to explain its efficiency. The proposed
model results are quantitatively and qualitatively compared to other
state-of-the-art salience prediction models. Compared with the baseline model,
our model achieved very good performance. Secondly, we also confirmed
Fourier/Spectral inspired saliency prediction models has the best prediction
scores compared to other start-of-the-art non-neural network and even deep
neural network models on the simple image features saliency prediction.
Finally, the model also can be applied to spatial-temporal saliency prediction
and got better performance.
</p>
<a href="http://arxiv.org/abs/2011.04076" target="_blank">arXiv:2011.04076</a> [<a href="http://arxiv.org/pdf/2011.04076" target="_blank">pdf</a>]

<h2>Adaptive Learning of Rank-One Models for Efficient Pairwise Sequence Alignment. (arXiv:2011.04832v2 [cs.LG] UPDATED)</h2>
<h3>Govinda M. Kamath, Tavor Z. Baharav, Ilan Shomorony</h3>
<p>Pairwise alignment of DNA sequencing data is a ubiquitous task in
bioinformatics and typically represents a heavy computational burden.
State-of-the-art approaches to speed up this task use hashing to identify short
segments (k-mers) that are shared by pairs of reads, which can then be used to
estimate alignment scores. However, when the number of reads is large,
accurately estimating alignment scores for all pairs is still very costly.
Moreover, in practice, one is only interested in identifying pairs of reads
with large alignment scores. In this work, we propose a new approach to
pairwise alignment estimation based on two key new ingredients. The first
ingredient is to cast the problem of pairwise alignment estimation under a
general framework of rank-one crowdsourcing models, where the workers'
responses correspond to k-mer hash collisions. These models can be accurately
solved via a spectral decomposition of the response matrix. The second
ingredient is to utilise a multi-armed bandit algorithm to adaptively refine
this spectral estimator only for read pairs that are likely to have large
alignments. The resulting algorithm iteratively performs a spectral
decomposition of the response matrix for adaptively chosen subsets of the read
pairs.
</p>
<a href="http://arxiv.org/abs/2011.04832" target="_blank">arXiv:2011.04832</a> [<a href="http://arxiv.org/pdf/2011.04832" target="_blank">pdf</a>]

<h2>Efficient and Transferable Adversarial Examples from Bayesian Neural Networks. (arXiv:2011.05074v2 [cs.LG] UPDATED)</h2>
<h3>Martin Gubri, Maxime Cordy, Mike Papadakis, Yves Le Traon</h3>
<p>An established way to improve the transferability of black-box evasion
attacks is to craft the adversarial examples on a surrogate ensemble model.
Unfortunately, such methods involve heavy computation costs to train the models
forming the ensemble. Based on a state-of-the-art Bayesian Neural Network
technique, we propose a new method to efficiently build such surrogates by
sampling from the posterior distribution of neural network weights during a
single training process. Our experiments on ImageNet and CIFAR-10 show that our
approach improves the transfer rates of four state-of-the-art attacks
significantly (between 2.5 and 44.4 percentage points), in both
intra-architecture and inter-architecture cases. On ImageNet, our approach can
reach 94% of transfer rate while reducing training time from 387 to 136 hours
on our infrastructure, compared to an ensemble of independently trained DNNs.
Furthermore, our approach can be combined with test-time techniques improving
transferability, further increasing their effectiveness by up to 25.1
percentage points.
</p>
<a href="http://arxiv.org/abs/2011.05074" target="_blank">arXiv:2011.05074</a> [<a href="http://arxiv.org/pdf/2011.05074" target="_blank">pdf</a>]

<h2>Two-stage Training of Graph Neural Networks for Graph Classification. (arXiv:2011.05097v3 [cs.LG] UPDATED)</h2>
<h3>Manh Tuan Do, Noseong Park, Kijung Shin</h3>
<p>Graph neural networks (GNNs) have received massive attention in the field of
machine learning on graphs. Inspired by the success of neural networks, a line
of research has been conducted to train GNNs to deal with various tasks, such
as node classification, graph classification, and link prediction. In this
work, our task of interest is graph classification. Several GNN models have
been proposed and shown great accuracy in this task. However, the question is
whether usual training methods fully realize the capacity of the GNN models.

In this work, we propose a two-stage training framework based on triplet
loss. In the first stage, GNN is trained to map each graph to a Euclidean-space
vector so that graphs of the same class are close while those of different
classes are mapped far apart. Once graphs are well-separated based on labels, a
classifier is trained to distinguish between different classes. This method is
generic in the sense that it is compatible with any GNN model. By adapting five
GNN models to our method, we demonstrate the consistent improvement in accuracy
and utilization of each GNN's allocated capacity over the original training
method of each model up to 5.4\% points in 12 datasets.
</p>
<a href="http://arxiv.org/abs/2011.05097" target="_blank">arXiv:2011.05097</a> [<a href="http://arxiv.org/pdf/2011.05097" target="_blank">pdf</a>]

<h2>Rebounding Bandits for Modeling Satiation Effects. (arXiv:2011.06741v2 [cs.LG] UPDATED)</h2>
<h3>Liu Leqi, Fatma Kilinc-Karzan, Zachary C. Lipton, Alan L. Montgomery</h3>
<p>A large body of psychological research shows that enjoyment of many goods is
subject to satiation, with short-term satisfaction declining after repeated
exposures to the same item. Nevertheless, proposed algorithms for powering
recommender systems seldom model these dynamics, instead proceeding as though
user preferences were fixed in time. In this work, we adopt a multi-armed
bandit setup, modeling satiation dynamics as a time-invariant linear dynamical
system. In our model, the expected rewards for each arm decline monotonically
with consecutive exposures to the same item and rebound towards the initial
reward whenever that arm is not pulled. We analyze this model, showing that
when the arms exhibit identical deterministic dynamics, our problem is
equivalent to a specific instance of Max K-Cut. In this case, a greedy policy,
which plays the arms in a cyclic order, is optimal. To handle the case when the
parameters governing the satiation dynamics can vary across arms, we propose a
lookahead policy that generalizes the greedy policy. When the satiation
dynamics are stochastic and governed by different (unknown) parameters, we
propose an algorithm that first uses offline data to identify an affine
dynamical system specified by the reward model and then plans using the
lookahead policy.
</p>
<a href="http://arxiv.org/abs/2011.06741" target="_blank">arXiv:2011.06741</a> [<a href="http://arxiv.org/pdf/2011.06741" target="_blank">pdf</a>]

<h2>HAWQV3: Dyadic Neural Network Quantization. (arXiv:2011.10680v2 [cs.CV] UPDATED)</h2>
<h3>Zhewei Yao, Zhen Dong, Zhangcheng Zheng, Amir Gholami, Jiali Yu, Eric Tan, Leyuan Wang, Qijing Huang, Yida Wang, Michael W. Mahoney, Kurt Keutzer</h3>
<p>Quantization is one of the key techniques used to make Neural Networks (NNs)
faster and more energy efficient. However, current low precision quantization
algorithms often have the hidden cost of conversion back and forth from
floating point to quantized integer values. This hidden cost limits the latency
improvement realized by quantizing NNs. To address this, we present HAWQV3, a
novel dyadic quantization framework. The contributions of HAWQV3 are the
following. (i) The entire inference process consists of only integer
multiplication, addition, and bit shifting in INT4/8 mixed precision, without
any floating point operations/casting or even integer division. (ii) We pose
the mixed-precision quantization as an integer linear programming problem,
where the bit precision setting is computed to minimize model perturbation,
while observing application specific constraints on memory footprint, latency,
and BOPS. (iii) To verify our approach, we develop the first open source 4-bit
mixed-precision quantization in TVM, and we directly deploy the quantized
models to T4 GPUs using only the Turing Tensor Cores. We observe an average
speed up of $1.45\times$ for uniform 4-bit, as compared to uniform 8-bit,
precision for ResNet50. (iv) We extensively test the proposed dyadic
quantization approach on multiple different NNs, including ResNet18/50 and
InceptionV3, for various model compression levels with/without mixed precision.
For instance, we achieve an accuracy of $78.50\%$ with dyadic INT8
quantization, which is more than $4\%$ higher than prior integer-only work for
InceptionV3. Furthermore, we show that mixed-precision INT4/8 quantization can
be used to achieve higher speed ups, as compared to INT8 inference, with
minimal impact on accuracy. For example, for ResNet50 we can reduce INT8
latency by $23\%$ with mixed precision and still achieve $76.73\%$ accuracy.
</p>
<a href="http://arxiv.org/abs/2011.10680" target="_blank">arXiv:2011.10680</a> [<a href="http://arxiv.org/pdf/2011.10680" target="_blank">pdf</a>]

<h2>Tensor Kernel Recovery for Spatio-Temporal Hawkes Processes. (arXiv:2011.12151v2 [stat.ML] UPDATED)</h2>
<h3>Heejune Sheen, Xiaonan Zhu, Yao Xie</h3>
<p>We estimate the general influence functions for spatio-temporal Hawkes
processes using a tensor recovery approach by formulating the location
dependent influence function that captures the influence of historical events
as a tensor kernel. We assume a low-rank structure for the tensor kernel and
cast the estimation problem as a convex optimization problem using the Fourier
transformed nuclear norm (TNN). We provide theoretical performance guarantees
for our approach and present an algorithm to solve the optimization problem.
Moreover, we demonstrate the efficiency of our estimation with numerical
simulations.
</p>
<a href="http://arxiv.org/abs/2011.12151" target="_blank">arXiv:2011.12151</a> [<a href="http://arxiv.org/pdf/2011.12151" target="_blank">pdf</a>]

<h2>Equivariant Learning of Stochastic Fields: Gaussian Processes and Steerable Conditional Neural Processes. (arXiv:2011.12916v2 [cs.LG] UPDATED)</h2>
<h3>Peter Holderrieth, Michael Hutchinson, Yee Whye Teh</h3>
<p>Motivated by objects such as electric fields or fluid streams, we study the
problem of learning stochastic fields, i.e. stochastic processes whose samples
are fields like those occurring in physics and engineering. Considering general
transformations such as rotations and reflections, we show that spatial
invariance of stochastic fields requires an inference model to be equivariant.
Leveraging recent advances from the equivariance literature, we study
equivariance in two classes of models. Firstly, we fully characterise
equivariant Gaussian processes. Secondly, we introduce Steerable Conditional
Neural Processes (SteerCNPs), a new, fully equivariant member of the Neural
Process family. In experiments with Gaussian process vector fields, images, and
real-world weather data, we observe that SteerCNPs significantly improve the
performance of previous models and equivariance leads to improvements in
transfer learning tasks.
</p>
<a href="http://arxiv.org/abs/2011.12916" target="_blank">arXiv:2011.12916</a> [<a href="http://arxiv.org/pdf/2011.12916" target="_blank">pdf</a>]

<h2>Rethinking Generalization in American Sign Language Prediction for Edge Devices with Extremely Low Memory Footprint. (arXiv:2011.13741v2 [cs.LG] UPDATED)</h2>
<h3>Aditya Jyoti Paul, Puranjay Mohan, Stuti Sehgal</h3>
<p>Due to the boom in technical compute in the last few years, the world has
seen massive advances in artificially intelligent systems solving diverse
real-world problems. But a major roadblock in the ubiquitous acceptance of
these models is their enormous computational complexity and memory footprint.
Hence efficient architectures and training techniques are required for
deployment on extremely low resource inference endpoints. This paper proposes
an architecture for detection of alphabets in American Sign Language on an ARM
Cortex-M7 microcontroller having just 496 KB of framebuffer RAM. Leveraging
parameter quantization is a common technique that might cause varying drops in
test accuracy. This paper proposes using interpolation as augmentation amongst
other techniques as an efficient method of reducing this drop, which also helps
the model generalize well to previously unseen noisy data. The proposed model
is about 185 KB post-quantization and inference speed is 20 frames per second.
</p>
<a href="http://arxiv.org/abs/2011.13741" target="_blank">arXiv:2011.13741</a> [<a href="http://arxiv.org/pdf/2011.13741" target="_blank">pdf</a>]

<h2>Optimizing the Neural Architecture of Reinforcement Learning Agents. (arXiv:2011.14632v2 [cs.LG] UPDATED)</h2>
<h3>N. Mazyavkina, S. Moustafa, I. Trofimov, E. Burnaev</h3>
<p>Reinforcement learning (RL) enjoyed significant progress over the last years.
One of the most important steps forward was the wide application of neural
networks. However, architectures of these neural networks are typically
constructed manually. In this work, we study recently proposed neural
architecture search (NAS) methods for optimizing the architecture of RL agents.
We carry out experiments on the Atari benchmark and conclude that modern NAS
methods find architectures of RL agents outperforming a manually selected one.
</p>
<a href="http://arxiv.org/abs/2011.14632" target="_blank">arXiv:2011.14632</a> [<a href="http://arxiv.org/pdf/2011.14632" target="_blank">pdf</a>]

<h2>Improving KernelSHAP: Practical Shapley Value Estimation via Linear Regression. (arXiv:2012.01536v2 [cs.LG] UPDATED)</h2>
<h3>Ian Covert, Su-In Lee</h3>
<p>The Shapley value concept from cooperative game theory has become a popular
technique for interpreting ML models, but efficiently estimating these values
remains challenging, particularly in the model-agnostic setting. Here, we
revisit the idea of estimating Shapley values via linear regression to
understand and improve upon this approach. By analyzing the original KernelSHAP
alongside a newly proposed unbiased version, we develop techniques to detect
its convergence and calculate uncertainty estimates. We also find that the
original version incurs a negligible increase in bias in exchange for
significantly lower variance, and we propose a variance reduction technique
that further accelerates the convergence of both estimators. Finally, we
develop a version of KernelSHAP for stochastic cooperative games that yields
fast new estimators for two global explanation methods.
</p>
<a href="http://arxiv.org/abs/2012.01536" target="_blank">arXiv:2012.01536</a> [<a href="http://arxiv.org/pdf/2012.01536" target="_blank">pdf</a>]

<h2>MOLTR: Multiple Object Localisation, Tracking, and Reconstruction from Monocular RGB Videos. (arXiv:2012.05360v2 [cs.CV] UPDATED)</h2>
<h3>Kejie Li, Hamid Rezatofighi, Ian Reid</h3>
<p>Semantic aware reconstruction is more advantageous than geometric-only
reconstruction for future robotic and AR/VR applications because it represents
not only where things are, but also what things are. Object-centric mapping is
a task to build an object-level reconstruction where objects are separate and
meaningful entities that convey both geometry and semantic information. In this
paper, we present MOLTR, a solution to object-centric mapping using only
monocular image sequences and camera poses. It is able to localise, track, and
reconstruct multiple objects in an online fashion when an RGB camera captures a
video of the surrounding. Given a new RGB frame, MOLTR firstly applies a
monocular 3D detector to localise objects of interest and extract their shape
codes that represent the object shapes in a learned embedding space. Detections
are then merged to existing objects in the map after data association. Motion
state (i.e. kinematics and the motion status) of each object is tracked by a
multiple model Bayesian filter and object shape is progressively refined by
fusing multiple shape code. We evaluate localisation, tracking, and
reconstruction on benchmarking datasets for indoor and outdoor scenes, and show
superior performance over previous approaches.
</p>
<a href="http://arxiv.org/abs/2012.05360" target="_blank">arXiv:2012.05360</a> [<a href="http://arxiv.org/pdf/2012.05360" target="_blank">pdf</a>]

<h2>Learning from Survey Propagation: a Neural Network for MAX-E-$3$-SAT. (arXiv:2012.06344v2 [cs.AI] UPDATED)</h2>
<h3>Raffaele Marino</h3>
<p>Many natural optimization problems are NP-hard, which implies that they are
probably hard to solve exactly in the worst-case. However, it suffices to get
reasonably good solutions for all (or even most) instances in practice. This
paper presents a new algorithm for computing approximate solutions in
${\Theta(N})$ for the Maximum Exact 3-Satisfiability (MAX-E-$3$-SAT) problem by
using deep learning methodology. This methodology allows us to create a
learning algorithm able to fix Boolean variables by using local information
obtained by the Survey Propagation algorithm. By performing an accurate
analysis, on random CNF instances of the MAX-E-$3$-SAT with several Boolean
variables, we show that this new algorithm, avoiding any decimation strategy,
can build assignments better than a random one, even if the convergence of the
messages is not found. Although this algorithm is not competitive with
state-of-the-art Maximum Satisfiability (MAX-SAT) solvers, it can solve
substantially larger and more complicated problems than it ever saw during
training.
</p>
<a href="http://arxiv.org/abs/2012.06344" target="_blank">arXiv:2012.06344</a> [<a href="http://arxiv.org/pdf/2012.06344" target="_blank">pdf</a>]

<h2>Bandit Learning in Decentralized Matching Markets. (arXiv:2012.07348v3 [cs.LG] UPDATED)</h2>
<h3>Lydia T. Liu, Feng Ruan, Horia Mania, Michael I. Jordan</h3>
<p>We study two-sided matching markets in which one side of the market (the
players) does not have a priori knowledge about its preferences for the other
side (the arms) and is required to learn its preferences from experience. Also,
we assume the players have no direct means of communication. This model extends
the standard stochastic multi-armed bandit framework to a decentralized
multiple player setting with competition. We introduce a new algorithm for this
setting that, over a time horizon $T$, attains $\mathcal{O}(\log(T))$ stable
regret when preferences of the arms over players are shared, and
$\mathcal{O}(\log(T)^2)$ regret when there are no assumptions on the
preferences on either side. Moreover, in the setting where a single player may
deviate, we show that the algorithm is incentive compatible whenever the arms'
preferences are shared, but not necessarily so when preferences are fully
general.
</p>
<a href="http://arxiv.org/abs/2012.07348" target="_blank">arXiv:2012.07348</a> [<a href="http://arxiv.org/pdf/2012.07348" target="_blank">pdf</a>]

<h2>A Perturbation Resilient Framework for Unsupervised Learning. (arXiv:2012.07399v2 [cs.LG] UPDATED)</h2>
<h3>Andreas Maurer, Daniela A. Parletta, Andrea Paudice, Massimiliano Pontil</h3>
<p>Designing learning algorithms that are resistant to perturbations of the
underlying data distribution is a problem of wide practical and theoretical
importance. We present a general approach to this problem focusing on
unsupervised learning. The key assumption is that the perturbing distribution
is characterized by larger losses relative to a given class of admissible
models. This is exploited by a general descent algorithm which minimizes an
$L$-statistic criterion over the model class, weighting more small losses. We
characterize the robustness of the method in terms of bounds on the
reconstruction error for the assumed unperturbed distribution. Numerical
experiments with \textsc{kmeans} clustering and principal subspace analysis
demonstrate the effectiveness of our method.
</p>
<a href="http://arxiv.org/abs/2012.07399" target="_blank">arXiv:2012.07399</a> [<a href="http://arxiv.org/pdf/2012.07399" target="_blank">pdf</a>]

<h2>Image-based Intraluminal Contact Force Monitoring in Robotic Vascular Navigation. (arXiv:2012.10762v2 [cs.RO] UPDATED)</h2>
<h3>Masoud Razban, Javad Dargahi, Benoit Boulet</h3>
<p>Embolization, stroke, ischaemic lesion, and perforation remain significant
concerns in endovascular interventions. Intravascular sensing of tool
interaction with the arteries is advantageous to minimize such complications
and enhance navigation safety. Intraluminal information is currently limited
due to the lack of intravascular contact sensing technologies. We present
monitoring of the intraluminal tool interaction with the arterial wall using an
image-based estimation approach within vascular robotic navigation. The
proposed image-based method employs continuous finite element simulation of the
tool using imaging data to estimate multi-point forces along tool-vessel wall
interaction. We implemented imaging algorithms to detect and track contacts,
and compute pose measurements. The model is constructed based on the nonlinear
beam element and flexural rigidity profile over the tool length. During remote
cannulation of aortic arteries, intraluminal monitoring achieved tracking local
contact forces, building a contour map of force on the arterial wall and
estimating tool structural stress. Results suggest that high risk intraluminal
forces may happen even with low insertion force. The presented online
monitoring system delivers insight into the intraluminal behavior of
endovascular tools and is well suited for intraoperative visual guidance for
the clinician, robotic control of vascular procedures and research on
interventional device design.
</p>
<a href="http://arxiv.org/abs/2012.10762" target="_blank">arXiv:2012.10762</a> [<a href="http://arxiv.org/pdf/2012.10762" target="_blank">pdf</a>]

<h2>Self-Supervised Hyperboloid Representations from Logical Queries over Knowledge Graphs. (arXiv:2012.13023v2 [cs.LG] UPDATED)</h2>
<h3>Nurendra Choudhary, Nikhil Rao, Sumeet Katariya, Karthik Subbian, Chandan K. Reddy</h3>
<p>Knowledge Graphs (KGs) are ubiquitous structures for information storagein
several real-world applications such as web search, e-commerce, social
networks, and biology. Querying KGs remains a foundational and challenging
problem due to their size and complexity. Promising approaches to tackle this
problem include embedding the KG units (e.g., entities and relations) in a
Euclidean space such that the query embedding contains the information relevant
to its results. These approaches, however, fail to capture the hierarchical
nature and semantic information of the entities present in the graph.
Additionally, most of these approaches only utilize multi-hop queries (that can
be modeled by simple translation operations) to learn embeddings and ignore
more complex operations such as intersection and union of simpler queries. To
tackle such complex operations, in this paper, we formulate KG representation
learning as a self-supervised logical query reasoning problem that utilizes
translation, intersection and union queries over KGs. We propose Hyperboloid
Embeddings (HypE), a novel self-supervised dynamic reasoning framework, that
utilizes positive first-order existential queries on a KG to learn
representations of its entities and relations as hyperboloids in a Poincar\'e
ball. HypE models the positive first-order queries as geometrical translation,
intersection, and union. For the problem of KG reasoning in real-world
datasets, the proposed HypE model significantly outperforms the state-of-the
art results. We also apply HypE to an anomaly detection task on a popular
e-commerce website product taxonomy as well as hierarchically organized web
articles and demonstrate significant performance improvements compared to
existing baseline methods. Finally, we also visualize the learned HypE
embeddings in a Poincar\'e ball to clearly interpret and comprehend the
representation space.
</p>
<a href="http://arxiv.org/abs/2012.13023" target="_blank">arXiv:2012.13023</a> [<a href="http://arxiv.org/pdf/2012.13023" target="_blank">pdf</a>]

<h2>Generative Partial Visual-Tactile Fused Object Clustering. (arXiv:2012.14070v2 [cs.RO] UPDATED)</h2>
<h3>Tao Zhang, Yang Cong, Gan Sun, Jiahua Dong, Yuyang Liu, Zhengming Ding</h3>
<p>Visual-tactile fused sensing for object clustering has achieved significant
progresses recently, since the involvement of tactile modality can effectively
improve clustering performance. However, the missing data (i.e., partial data)
issues always happen due to occlusion and noises during the data collecting
process. This issue is not well solved by most existing partial multi-view
clustering methods for the heterogeneous modality challenge. Naively employing
these methods would inevitably induce a negative effect and further hurt the
performance. To solve the mentioned challenges, we propose a Generative Partial
Visual-Tactile Fused (i.e., GPVTF) framework for object clustering. More
specifically, we first do partial visual and tactile features extraction from
the partial visual and tactile data, respectively, and encode the extracted
features in modality-specific feature subspaces. A conditional cross-modal
clustering generative adversarial network is then developed to synthesize one
modality conditioning on the other modality, which can compensate missing
samples and align the visual and tactile modalities naturally by adversarial
learning. To the end, two pseudo-label based KL-divergence losses are employed
to update the corresponding modality-specific encoders. Extensive comparative
experiments on three public visual-tactile datasets prove the effectiveness of
our method.
</p>
<a href="http://arxiv.org/abs/2012.14070" target="_blank">arXiv:2012.14070</a> [<a href="http://arxiv.org/pdf/2012.14070" target="_blank">pdf</a>]

<h2>A CNN Approach to Simultaneously Count Plants and Detect Plantation-Rows from UAV Imagery. (arXiv:2012.15827v3 [cs.CV] UPDATED)</h2>
<h3>Lucas Prado Osco, Mauro dos Santos de Arruda, Diogo Nunes Gon&#xe7;alves, Alexandre Dias, Juliana Batistoti, Mauricio de Souza, Felipe David Georges Gomes, Ana Paula Marques Ramos, L&#xfa;cio Andr&#xe9; de Castro Jorge, Veraldo Liesenberg, Jonathan Li, Lingfei Ma, Jos&#xe9; Marcato Junior, Wesley Nunes Gon&#xe7;alves</h3>
<p>In this paper, we propose a novel deep learning method based on a
Convolutional Neural Network (CNN) that simultaneously detects and geolocates
plantation-rows while counting its plants considering highly-dense plantation
configurations. The experimental setup was evaluated in a cornfield with
different growth stages and in a Citrus orchard. Both datasets characterize
different plant density scenarios, locations, types of crops, sensors, and
dates. A two-branch architecture was implemented in our CNN method, where the
information obtained within the plantation-row is updated into the plant
detection branch and retro-feed to the row branch; which are then refined by a
Multi-Stage Refinement method. In the corn plantation datasets (with both
growth phases, young and mature), our approach returned a mean absolute error
(MAE) of 6.224 plants per image patch, a mean relative error (MRE) of 0.1038,
precision and recall values of 0.856, and 0.905, respectively, and an F-measure
equal to 0.876. These results were superior to the results from other deep
networks (HRNet, Faster R-CNN, and RetinaNet) evaluated with the same task and
dataset. For the plantation-row detection, our approach returned precision,
recall, and F-measure scores of 0.913, 0.941, and 0.925, respectively. To test
the robustness of our model with a different type of agriculture, we performed
the same task in the citrus orchard dataset. It returned an MAE equal to 1.409
citrus-trees per patch, MRE of 0.0615, precision of 0.922, recall of 0.911, and
F-measure of 0.965. For citrus plantation-row detection, our approach resulted
in precision, recall, and F-measure scores equal to 0.965, 0.970, and 0.964,
respectively. The proposed method achieved state-of-the-art performance for
counting and geolocating plants and plant-rows in UAV images from different
types of crops.
</p>
<a href="http://arxiv.org/abs/2012.15827" target="_blank">arXiv:2012.15827</a> [<a href="http://arxiv.org/pdf/2012.15827" target="_blank">pdf</a>]

<h2>Adaptive Surgical Robotic Training Using Real-Time Stylistic Behavior Feedback Through Haptic Cues. (arXiv:2101.00097v2 [cs.RO] UPDATED)</h2>
<h3>Marzieh Ershad, Robert Rege, Ann Majewicz Fey</h3>
<p>Surgical skill directly affects surgical procedure outcomes; thus, effective
training is needed to ensure satisfactory results. Many objective assessment
metrics have been developed and some are widely used in surgical training
simulators. These objective metrics provide the trainee with descriptive
feedback about their performance however, often lack feedback on how to proceed
to improve performance. The most effective training method is one that is
intuitive, easy to understand, personalized to the user and provided in a
timely manner. We propose a framework to enable user-adaptive training using
near-real-time detection of performance, based on intuitive styles of surgical
movements (e.g., fluidity, smoothness, crispness, etc.), and propose a haptic
feedback framework to assist with correcting styles of movement. We evaluate
the ability of three types of force feedback (spring, damping, and spring plus
damping feedback), computed based on prior user positions, to improve different
stylistic behaviors of the user during kinematically constrained reaching
movement tasks. The results indicate that four out of the six styles studied
here were statistically significantly improved (p&lt;0.05) using spring guidance
force feedback and a significant reduction in task time was also found using
spring feedback. The path straightness and targeting error in the task were
other task performance metrics studied which were improved significantly using
the spring-damping feedback. This study presents a groundwork for adaptive
training in robotic surgery based on near-real-time human-centric models of
surgical behavior.
</p>
<a href="http://arxiv.org/abs/2101.00097" target="_blank">arXiv:2101.00097</a> [<a href="http://arxiv.org/pdf/2101.00097" target="_blank">pdf</a>]

<h2>Provable Generalization of SGD-trained Neural Networks of Any Width in the Presence of Adversarial Label Noise. (arXiv:2101.01152v3 [cs.LG] UPDATED)</h2>
<h3>Spencer Frei, Yuan Cao, Quanquan Gu</h3>
<p>We consider a one-hidden-layer leaky ReLU network of arbitrary width trained
by stochastic gradient descent (SGD) following an arbitrary initialization. We
prove that SGD produces neural networks that have classification accuracy
competitive with that of the best halfspace over the distribution for a broad
class of distributions that includes log-concave isotropic and hard margin
distributions. Equivalently, such networks can generalize when the data
distribution is linearly separable but corrupted with adversarial label noise,
despite the capacity to overfit. To the best of our knowledge, this is the
first work to show that overparameterized neural networks trained by SGD can
generalize when the data is corrupted with adversarial label noise.
</p>
<a href="http://arxiv.org/abs/2101.01152" target="_blank">arXiv:2101.01152</a> [<a href="http://arxiv.org/pdf/2101.01152" target="_blank">pdf</a>]

<h2>Convergence and finite sample approximations of entropic regularized Wasserstein distances in Gaussian and RKHS settings. (arXiv:2101.01429v2 [stat.ML] UPDATED)</h2>
<h3>Minh Ha Quang</h3>
<p>This work studies the convergence and finite sample approximations of
entropic regularized Wasserstein distances in the Hilbert space setting. Our
first main result is that for Gaussian measures on an infinite-dimensional
Hilbert space, convergence in the 2-Sinkhorn divergence is {\it strictly
weaker} than convergence in the exact 2-Wasserstein distance. Specifically, a
sequence of centered Gaussian measures converges in the 2-Sinkhorn divergence
if the corresponding covariance operators converge in the Hilbert-Schmidt norm.
This is in contrast to the previous known result that a sequence of centered
Gaussian measures converges in the exact 2-Wasserstein distance if and only if
the covariance operators converge in the trace class norm. In the reproducing
kernel Hilbert space (RKHS) setting, the {\it kernel Gaussian-Sinkhorn
divergence}, which is the Sinkhorn divergence between Gaussian measures defined
on an RKHS, defines a semi-metric on the set of Borel probability measures on a
Polish space, given a characteristic kernel on that space. With the
Hilbert-Schmidt norm convergence, we obtain {\it dimension-independent}
convergence rates for finite sample approximations of the kernel
Gaussian-Sinkhorn divergence, with the same order as the Maximum Mean
Discrepancy. These convergence rates apply in particular to Sinkhorn divergence
between Gaussian measures on Euclidean and infinite-dimensional Hilbert spaces.
The sample complexity for the 2-Wasserstein distance between Gaussian measures
on Euclidean space, while dimension-dependent and larger than that of the
Sinkhorn divergence, is exponentially faster than the worst case scenario in
the literature.
</p>
<a href="http://arxiv.org/abs/2101.01429" target="_blank">arXiv:2101.01429</a> [<a href="http://arxiv.org/pdf/2101.01429" target="_blank">pdf</a>]

<h2>On the price of explainability for some clustering problems. (arXiv:2101.01576v2 [cs.LG] UPDATED)</h2>
<h3>Eduardo Laber, Lucas Murtinho</h3>
<p>The price of explainability for a clustering task can be defined as the
unavoidable loss,in terms of the objective function, if we force the final
partition to be explainable.

Here, we study this price for the following clustering problems: $k$-means,
$k$-medians, $k$-centers and maximum-spacing. We provide upper and lower bounds
for a natural model where explainability is achieved via decision trees. For
the $k$-means and $k$-medians problems our upper bounds improve those obtained
by [Moshkovitz et. al, ICML 20] for low dimensions.

Another contribution is a simple and efficient algorithm for building
explainable clusterings for the $k$-means problem. We provide empirical
evidence that its performance is better than the current state of the art for
decision-tree based explainable clustering.
</p>
<a href="http://arxiv.org/abs/2101.01576" target="_blank">arXiv:2101.01576</a> [<a href="http://arxiv.org/pdf/2101.01576" target="_blank">pdf</a>]

<h2>Learning from Synthetic Shadows for Shadow Detection and Removal. (arXiv:2101.01713v2 [cs.CV] UPDATED)</h2>
<h3>Naoto Inoue, Toshihiko Yamasaki</h3>
<p>Shadow removal is an essential task in computer vision and computer graphics.
Recent shadow removal approaches all train convolutional neural networks (CNN)
on real paired shadow/shadow-free or shadow/shadow-free/mask image datasets.
However, obtaining a large-scale, diverse, and accurate dataset has been a big
challenge, and it limits the performance of the learned models on shadow images
with unseen shapes/intensities. To overcome this challenge, we present
SynShadow, a novel large-scale synthetic shadow/shadow-free/matte image
triplets dataset and a pipeline to synthesize it. We extend a
physically-grounded shadow illumination model and synthesize a shadow image
given an arbitrary combination of a shadow-free image, a matte image, and
shadow attenuation parameters. Owing to the diversity, quantity, and quality of
SynShadow, we demonstrate that shadow removal models trained on SynShadow
perform well in removing shadows with diverse shapes and intensities on some
challenging benchmarks. Furthermore, we show that merely fine-tuning from a
SynShadow-pre-trained model improves existing shadow detection and removal
models. Codes are publicly available at https://github.com/naoto0804/SynShadow.
</p>
<a href="http://arxiv.org/abs/2101.01713" target="_blank">arXiv:2101.01713</a> [<a href="http://arxiv.org/pdf/2101.01713" target="_blank">pdf</a>]

<h2>Max-Affine Spline Insights Into Deep Network Pruning. (arXiv:2101.02338v2 [cs.LG] UPDATED)</h2>
<h3>Randall Balestriero, Haoran You, Zhihan Lu, Yutong Kou, Huihong Shi, Yingyan Lin, Richard Baraniuk</h3>
<p>In this paper, we study the importance of pruning in Deep Networks (DNs) and
the yin &amp; yang relationship between (1) pruning highly overparametrized DNs
that have been trained from random initialization and (2) training small DNs
that have been "cleverly" initialized. As in most cases practitioners can only
resort to random initialization, there is a strong need to develop a grounded
understanding of DN pruning. Current literature remains largely empirical,
lacking a theoretical understanding of how pruning affects DNs' decision
boundary, how to interpret pruning, and how to design corresponding principled
pruning techniques. To tackle those questions, we propose to employ recent
advances in the theoretical analysis of Continuous Piecewise Affine (CPA) DNs.
From this perspective, we will be able to detect the early-bird (EB) ticket
phenomenon, provide interpretability into current pruning techniques, and
develop a principled pruning strategy. In each step of our study, we conduct
extensive experiments supporting our claims and results; while our main goal is
to enhance the current understanding towards DN pruning instead of developing a
new pruning method, our spline pruning criteria in terms of layerwise and
global pruning is on par with or even outperforms state-of-the-art pruning
methods.
</p>
<a href="http://arxiv.org/abs/2101.02338" target="_blank">arXiv:2101.02338</a> [<a href="http://arxiv.org/pdf/2101.02338" target="_blank">pdf</a>]

<h2>Argument Schemes and Dialogue for Explainable Planning. (arXiv:2101.02648v2 [cs.AI] UPDATED)</h2>
<h3>Quratul-ain Mahesar, Simon Parsons</h3>
<p>Artificial Intelligence (AI) is being increasingly deployed in practical
applications. However, there is a major concern whether AI systems will be
trusted by humans. In order to establish trust in AI systems, there is a need
for users to understand the reasoning behind their solutions. Therefore,
systems should be able to explain and justify their output. In this paper, we
propose an argument scheme-based approach to provide explanations in the domain
of AI planning. We present novel argument schemes to create arguments that
explain a plan and its key elements; and a set of critical questions that allow
interaction between the arguments and enable the user to obtain further
information regarding the key elements of the plan. Furthermore, we present a
novel dialogue system using the argument schemes and critical questions for
providing interactive dialectical explanations.
</p>
<a href="http://arxiv.org/abs/2101.02648" target="_blank">arXiv:2101.02648</a> [<a href="http://arxiv.org/pdf/2101.02648" target="_blank">pdf</a>]

<h2>An automated machine learning-genetic algorithm (AutoML-GA) approach for efficient simulation-driven engine design optimization. (arXiv:2101.02653v2 [cs.LG] UPDATED)</h2>
<h3>Opeoluwa Owoyele, Pinaki Pal, Alvaro Vidal Torreira, Daniel Probst, Matthew Shaxted, Michael Wilde, Peter Kelly Senecal</h3>
<p>In recent years, the use of machine learning techniques as surrogate models
for computational fluid dynamics (CFD) simulations has emerged as a promising
method for reducing the computational cost associated with engine design
optimization. However, such methods still suffer from drawbacks. One main
disadvantage of such methods is that the default machine learning
hyperparameters are often severely suboptimal for a given problem. This has
often been addressed by manually trying out different hyperparameter settings,
but this solution is ineffective in a high-dimensional hyperparameter space.
Besides this problem, the amount of data needed for training is also not known
a priori. In response to these issues which need to be addressed, this work
describes and validates an automated active learning approach for
surrogate-based optimization of internal combustion engines, AutoML-GA. In this
approach, a Bayesian optimization technique is used to find the best machine
learning hyperparameters based on an initial dataset obtained from a small
number of CFD simulations. Subsequently, a genetic algorithm is employed to
locate the design optimum on the surrogate surface trained with the optimal
hyperparameters. In the vicinity of the design optimum, the solution is refined
by repeatedly running CFD simulations at the projected optimum and adding the
newly obtained data to the training dataset. It is shown that this approach
leads to a better optimum with a lower number of CFD simulations, compared to
the use of default hyperparameters. The developed approach offers the advantage
of being a more hands-off approach that can be easily applied by researchers
and engineers in industry who do not have a machine learning background.
</p>
<a href="http://arxiv.org/abs/2101.02653" target="_blank">arXiv:2101.02653</a> [<a href="http://arxiv.org/pdf/2101.02653" target="_blank">pdf</a>]

<h2>LBS: Loss-aware Bit Sharing for Automatic Model Compression. (arXiv:2101.04935v2 [cs.CV] UPDATED)</h2>
<h3>Jing Liu, Bohan Zhuang, Peng Chen, Yong Guo, Chunhua Shen, Jianfei Cai, Mingkui Tan</h3>
<p>Low-bitwidth model compression is an effective method to reduce the model
size and computational overhead. Existing compression methods rely on some
compression configurations (such as pruning rates, and/or bitwidths), which are
often determined manually and not optimal. Some attempts have been made to
search them automatically, but the optimization process is often very
expensive. To alleviate this, we devise a simple yet effective method named
Loss-aware Bit Sharing (LBS) to automatically search for optimal model
compression configurations. To this end, we propose a novel single-path model
to encode all candidate compression configurations, where a high bitwidth
quantized value can be decomposed into the sum of the lowest bitwidth quantized
value and a series of re-assignment offsets. We then introduce learnable binary
gates to encode the choice of bitwidth, including filter-wise 0-bit for filter
pruning. By jointly training the binary gates in conjunction with network
parameters, the compression configurations of each layer can be automatically
determined. Extensive experiments on both CIFAR-100 and ImageNet show that LBS
is able to significantly reduce computational cost while preserving promising
performance.
</p>
<a href="http://arxiv.org/abs/2101.04935" target="_blank">arXiv:2101.04935</a> [<a href="http://arxiv.org/pdf/2101.04935" target="_blank">pdf</a>]

<h2>Knowledge-Preserving Incremental Social Event Detection via Heterogeneous GNNs. (arXiv:2101.08747v2 [cs.LG] UPDATED)</h2>
<h3>Yuwei Cao, Hao Peng, Jia Wu, Yingtong Dou, Jianxin Li, Philip S. Yu</h3>
<p>Social events provide valuable insights into group social behaviors and
public concerns and therefore have many applications in fields such as product
recommendation and crisis management. The complexity and streaming nature of
social messages make it appealing to address social event detection in an
incremental learning setting, where acquiring, preserving, and extending
knowledge are major concerns. Most existing methods, including those based on
incremental clustering and community detection, learn limited amounts of
knowledge as they ignore the rich semantics and structural information
contained in social data. Moreover, they cannot memorize previously acquired
knowledge. In this paper, we propose a novel Knowledge-Preserving Incremental
Heterogeneous Graph Neural Network (KPGNN) for incremental social event
detection. To acquire more knowledge, KPGNN models complex social messages into
unified social graphs to facilitate data utilization and explores the
expressive power of GNNs for knowledge extraction. To continuously adapt to the
incoming data, KPGNN adopts contrastive loss terms that cope with a changing
number of event classes. It also leverages the inductive learning ability of
GNNs to efficiently detect events and extends its knowledge from previously
unseen data. To deal with large social streams, KPGNN adopts a mini-batch
subgraph sampling strategy for scalable training, and periodically removes
obsolete data to maintain a dynamic embedding space. KPGNN requires no feature
engineering and has few hyperparameters to tune. Extensive experiment results
demonstrate the superiority of KPGNN over various baselines.
</p>
<a href="http://arxiv.org/abs/2101.08747" target="_blank">arXiv:2101.08747</a> [<a href="http://arxiv.org/pdf/2101.08747" target="_blank">pdf</a>]

<h2>Fighting deepfakes by detecting GAN DCT anomalies. (arXiv:2101.09781v3 [cs.CV] UPDATED)</h2>
<h3>Oliver Giudice (1), Luca Guarnera (1 and 2), Sebastiano Battiato (1 and 2) ((1) University of Catania, (2) iCTLab s.r.l. - Spin-off of University of Catania)</h3>
<p>Synthetic multimedia contents created through AI technologies, such as
Generative Adversarial Networks (GAN), applied to human faces can have serious
social and political consequences. State-of-the-art algorithms employ deep
neural networks to detect fake contents but, unfortunately, almost all
approaches appear to be neither generalizable nor explainable. In this paper, a
new fast detection method able to discriminate Deepfake images with high
precision is proposed. By employing Discrete Cosine Transform (DCT), anomalous
frequencies in real and Deepfake image datasets were analyzed. The \beta
statistics inferred by the distribution of AC coefficients have been the key to
recognize GAN-engine generated images. The proposed technique has been
validated on pristine high quality images of faces synthesized by different GAN
architectures. Experiments carried out show that the method is innovative,
exceeds the state-of-the-art and also gives many insights in terms of
explainability.
</p>
<a href="http://arxiv.org/abs/2101.09781" target="_blank">arXiv:2101.09781</a> [<a href="http://arxiv.org/pdf/2101.09781" target="_blank">pdf</a>]

<h2>Spatio-temporal Data Augmentation for Visual Surveillance. (arXiv:2101.09895v3 [cs.CV] UPDATED)</h2>
<h3>Jae-Yeul Kim, Jong-Eun Ha</h3>
<p>Visual surveillance aims to stably detect a foreground object using a
continuous image acquired from a fixed camera. Recent deep learning methods
based on supervised learning show superior performance compared to classical
background subtraction algorithms. However, there is still a room for
improvement in static foreground, dynamic background, hard shadow, illumination
changes, camouflage, etc. In addition, most of the deep learning-based methods
operates well on environments similar to training. If the testing environments
are different from training ones, their performance degrades. As a result,
additional training on those operating environments is required to ensure a
good performance. Our previous work which uses spatio-temporal input data
consisted of a number of past images, background images and current image
showed promising results in different environments from training, although it
uses a simple U-NET structure. In this paper, we propose a data augmentation
technique suitable for visual surveillance for additional performance
improvement using the same network used in our previous work. In deep learning,
most data augmentation techniques deal with spatial-level data augmentation
techniques for use in image classification and object detection. In this paper,
we propose a new method of data augmentation in the spatio-temporal dimension
suitable for our previous work. Two data augmentation methods of adjusting
background model images and past images are proposed. Through this, it is shown
that performance can be improved in difficult areas such as static foreground
and ghost objects, compared to previous studies. Through quantitative and
qualitative evaluation using SBI, LASIESTA, and our own dataset, we show that
it gives superior performance compared to deep learning-based algorithms and
background subtraction algorithms.
</p>
<a href="http://arxiv.org/abs/2101.09895" target="_blank">arXiv:2101.09895</a> [<a href="http://arxiv.org/pdf/2101.09895" target="_blank">pdf</a>]

<h2>Graph Neural Network for Traffic Forecasting: A Survey. (arXiv:2101.11174v2 [cs.LG] UPDATED)</h2>
<h3>Weiwei Jiang, Jiayun Luo</h3>
<p>Traffic forecasting is important for the success of intelligent
transportation systems. Deep learning models, including convolution neural
networks and recurrent neural networks, have been extensively applied in
traffic forecasting problems to model spatial and temporal dependencies. In
recent years, to model the graph structures in transportation systems as well
as contextual information, graph neural networks have been introduced and have
achieved state-of-the-art performance in a series of traffic forecasting
problems. In this survey, we review the rapidly growing body of research using
different graph neural networks, e.g. graph convolutional and graph attention
networks, in various traffic forecasting problems, e.g. road traffic flow and
speed forecasting, passenger flow forecasting in urban rail transit systems,
and demand forecasting in ride-hailing platforms. We also present a
comprehensive list of open data and source resources for each problem and
identify future research directions. To the best of our knowledge, this paper
is the first comprehensive survey that explores the application of graph neural
networks for traffic forecasting problems. We have also created a public GitHub
repository where the latest papers, open data, and source resources will be
updated.
</p>
<a href="http://arxiv.org/abs/2101.11174" target="_blank">arXiv:2101.11174</a> [<a href="http://arxiv.org/pdf/2101.11174" target="_blank">pdf</a>]

<h2>A Hybrid 2-stage Neural Optimization for Pareto Front Extraction. (arXiv:2101.11684v2 [cs.LG] UPDATED)</h2>
<h3>Gurpreet Singh, Soumyajit Gupta, Matthew Lease, Clint Dawson</h3>
<p>Classification, recommendation, and ranking problems often involve competing
goals with additional constraints (e.g., to satisfy fairness or diversity
criteria). Such optimization problems are quite challenging, often involving
non-convex functions along with considerations of user preferences in balancing
trade-offs. Pareto solutions represent optimal frontiers for jointly optimizing
multiple competing objectives. A major obstacle for frequently used
linear-scalarization strategies is that the resulting optimization problem
might not always converge to a global optimum. Furthermore, such methods only
return one solution point per run. A Pareto solution set is a subset of all
such global optima over multiple runs for different trade-off choices.
Therefore, a Pareto front can only be guaranteed with multiple runs of the
linear-scalarization problem, where all runs converge to their respective
global optima. Consequently, extracting a Pareto front for practical problems
is computationally intractable with substantial computational overheads,
limited scalability, and reduced accuracy. We propose a robust, low cost,
two-stage, hybrid neural Pareto optimization approach that is accurate and
scales (compute space and time) with data dimensions, as well as number of
functions and constraints. The first stage (neural network) efficiently
extracts a weak Pareto front, using Fritz-John conditions as the discriminator,
with no assumptions of convexity on the objectives or constraints. The second
stage (efficient Pareto filter) extracts the strong Pareto optimal subset given
the weak front from stage 1. Fritz-John conditions provide us with theoretical
bounds on approximation error between the true and network extracted weak
Pareto front. Numerical experiments demonstrates the accuracy and efficiency on
a canonical set of benchmark problems and a fairness optimization task from
prior works.
</p>
<a href="http://arxiv.org/abs/2101.11684" target="_blank">arXiv:2101.11684</a> [<a href="http://arxiv.org/pdf/2101.11684" target="_blank">pdf</a>]

<h2>Hadamard Extensions and the Identification of Mixtures of Product Distributions. (arXiv:2101.11688v2 [cs.LG] UPDATED)</h2>
<h3>Spencer L. Gordon, Leonard J. Schulman</h3>
<p>The Hadamard Extension of a matrix is the matrix consisting of all Hadamard
products of subsets of its rows. This construction arises in the context of
identifying a mixture of product distributions on binary random variables: full
column rank of such extensions is a necessary ingredient of identification
algorithms. We provide several results concerning when a Hadamard Extension has
full column rank.
</p>
<a href="http://arxiv.org/abs/2101.11688" target="_blank">arXiv:2101.11688</a> [<a href="http://arxiv.org/pdf/2101.11688" target="_blank">pdf</a>]

<h2>DOC2PPT: Automatic Presentation Slides Generation from Scientific Documents. (arXiv:2101.11796v2 [cs.CV] UPDATED)</h2>
<h3>Tsu-Jui Fu, William Yang Wang, Daniel McDuff, Yale Song</h3>
<p>Creating presentation materials requires complex multimodal reasoning skills
to summarize key concepts and arrange them in a logical and visually pleasing
manner. Can machines learn to emulate this laborious process? We present a
novel task and approach for document-to-slide generation. Solving this involves
document summarization, image and text retrieval, slide structure and layout
prediction to arrange key elements in a form suitable for presentation. We
propose a hierarchical sequence-to-sequence approach to tackle our task in an
end-to-end manner. Our approach exploits the inherent structures within
documents and slides and incorporates paraphrasing and layout prediction
modules to generate slides. To help accelerate research in this domain, we
release a dataset about 6K paired documents and slide decks used in our
experiments. We show that our approach outperforms strong baselines and
produces slides with rich content and aligned imagery.
</p>
<a href="http://arxiv.org/abs/2101.11796" target="_blank">arXiv:2101.11796</a> [<a href="http://arxiv.org/pdf/2101.11796" target="_blank">pdf</a>]

<h2>Optimistic Policy Iteration for MDPs with Acyclic Transient State Structure. (arXiv:2102.00030v2 [cs.LG] UPDATED)</h2>
<h3>Joseph Lubars, Anna Winnicki, Michael Livesay, R. Srikant</h3>
<p>We consider Markov Decision Processes (MDPs) in which every stationary policy
induces the same graph structure for the underlying Markov chain and further,
the graph has the following property: if we replace each recurrent class by a
node, then the resulting graph is acyclic. For such MDPs, we prove the
convergence of the stochastic dynamics associated with a version of optimistic
policy iteration (OPI), suggested in Tsitsiklis (2002), in which the values
associated with all the nodes visited during each iteration of the OPI are
updated.
</p>
<a href="http://arxiv.org/abs/2102.00030" target="_blank">arXiv:2102.00030</a> [<a href="http://arxiv.org/pdf/2102.00030" target="_blank">pdf</a>]

<h2>Learning Interaction Kernels for Agent Systems on Riemannian Manifolds. (arXiv:2102.00327v2 [cs.LG] UPDATED)</h2>
<h3>Mauro Maggioni, Jason Miller, Hongda Qui, Ming Zhong</h3>
<p>Interacting agent and particle systems are extensively used to model complex
phenomena in science and engineering. We consider the problem of learning
interaction kernels in these dynamical systems constrained to evolve on
Riemannian manifolds from given trajectory data. The models we consider are
based on interaction kernels depending on pairwise Riemannian distances between
agents, with agents interacting locally along the direction of the shortest
geodesic connecting them. We show that our estimators converge at a rate that
is independent of the dimension of the state space, and derive bounds on the
trajectory estimation error, on the manifold, between the observed and
estimated dynamics. We demonstrate the performance of our estimator on two
classical first order interacting systems: Opinion Dynamics and a
Predator-Swarm system, with each system constrained on two prototypical
manifolds, the $2$-dimensional sphere and the Poincar\'e disk model of
hyperbolic space.
</p>
<a href="http://arxiv.org/abs/2102.00327" target="_blank">arXiv:2102.00327</a> [<a href="http://arxiv.org/pdf/2102.00327" target="_blank">pdf</a>]

<h2>Ivy: Templated Deep Learning for Inter-Framework Portability. (arXiv:2102.02886v2 [cs.LG] UPDATED)</h2>
<h3>Daniel Lenton, Fabio Pardo, Fabian Falck, Stephen James, Ronald Clark</h3>
<p>We introduce Ivy, a templated Deep Learning (DL) framework which abstracts
existing DL frameworks such that their core functions all exhibit consistent
call signatures, syntax and input-output behaviour. Ivy allows high-level
framework-agnostic functions to be implemented through the use of framework
templates. The framework templates act as placeholders for the specific
framework at development time, which are then determined at runtime. The
portability of Ivy functions enables their use in projects of any supported
framework. Ivy currently supports TensorFlow, PyTorch, MXNet, Jax and NumPy.
Alongside Ivy, we release four pure-Ivy libraries for mechanics, 3D vision,
robotics, and differentiable environments. Through our evaluations, we show
that Ivy can significantly reduce lines of code with a runtime overhead of less
than 1% in most cases. We welcome developers to join the Ivy community by
writing their own functions, layers and libraries in Ivy, maximizing their
audience and helping to accelerate DL research through the creation of lifelong
inter-framework codebases. More information can be found at https://ivy-dl.org.
</p>
<a href="http://arxiv.org/abs/2102.02886" target="_blank">arXiv:2102.02886</a> [<a href="http://arxiv.org/pdf/2102.02886" target="_blank">pdf</a>]

<h2>Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training. (arXiv:2102.02887v2 [cs.LG] UPDATED)</h2>
<h3>Shiwei Liu, Lu Yin, Decebal Constantin Mocanu, Mykola Pechenizkiy</h3>
<p>In this paper, we introduce a new perspective on training deep neural
networks capable of state-of-the-art performance without the need for the
expensive over-parameterization by proposing the concept of In-Time
Over-Parameterization (ITOP) in sparse training. By starting from a random
sparse network and continuously exploring sparse connectivities during
training, we can perform an Over-Parameterization in the space-time manifold,
closing the gap in the expressibility between sparse training and dense
training. We further use ITOP to understand the underlying mechanism of Dynamic
Sparse Training (DST) and indicate that the benefits of DST come from its
ability to consider across time all possible parameters when searching for the
optimal sparse connectivity. As long as there are sufficient parameters that
have been reliably explored during training, DST can outperform the dense
neural network by a large margin. We present a series of experiments to support
our conjecture and achieve the state-of-the-art sparse training performance
with ResNet-50 on ImageNet. More impressively, our method achieves dominant
performance over the overparameterization-based sparse methods at extreme
sparsity levels. When trained on CIFAR-100, our method can match the
performance of the dense model even at an extreme sparsity (98%).
</p>
<a href="http://arxiv.org/abs/2102.02887" target="_blank">arXiv:2102.02887</a> [<a href="http://arxiv.org/pdf/2102.02887" target="_blank">pdf</a>]

<h2>Understanding Emails and Drafting Responses -- An Approach Using GPT-3. (arXiv:2102.03062v3 [cs.AI] UPDATED)</h2>
<h3>Jonas Thiergart, Stefan Huber, Thomas &#xdc;bellacker</h3>
<p>Providing computer systems with the ability to understand and generate
natural language has long been a challenge of engineers. Recent progress in
natural language processing (NLP), like the GPT-3 language model released by
OpenAI, has made both possible to an extent. In this paper, we explore the
possibility of rationalising email communication using GPT-3. First, we
demonstrate the technical feasibility of understanding incoming emails and
generating responses, drawing on literature from the disciplines of software
engineering as well as data science. Second, we apply knowledge from both
business studies and, again, software engineering to identify ways to tackle
challenges we encountered. Third, we argue for the economic viability of such a
solution by analysing costs and market demand. We conclude that applying GPT-3
to rationalising email communication is feasible both technically and
economically.
</p>
<a href="http://arxiv.org/abs/2102.03062" target="_blank">arXiv:2102.03062</a> [<a href="http://arxiv.org/pdf/2102.03062" target="_blank">pdf</a>]

<h2>Learning Audio-Visual Correlations from Variational Cross-Modal Generation. (arXiv:2102.03424v2 [cs.CV] UPDATED)</h2>
<h3>Ye Zhu, Yu Wu, Hugo Latapie, Yi Yang, Yan Yan</h3>
<p>People can easily imagine the potential sound while seeing an event. This
natural synchronization between audio and visual signals reveals their
intrinsic correlations. To this end, we propose to learn the audio-visual
correlations from the perspective of cross-modal generation in a
self-supervised manner, the learned correlations can be then readily applied in
multiple downstream tasks such as the audio-visual cross-modal localization and
retrieval. We introduce a novel Variational AutoEncoder (VAE) framework that
consists of Multiple encoders and a Shared decoder (MS-VAE) with an additional
Wasserstein distance constraint to tackle the problem. Extensive experiments
demonstrate that the optimized latent representation of the proposed MS-VAE can
effectively learn the audio-visual correlations and can be readily applied in
multiple audio-visual downstream tasks to achieve competitive performance even
without any given label information during training.
</p>
<a href="http://arxiv.org/abs/2102.03424" target="_blank">arXiv:2102.03424</a> [<a href="http://arxiv.org/pdf/2102.03424" target="_blank">pdf</a>]

<h2>Tilting the playing field: Dynamical loss functions for machine learning. (arXiv:2102.03793v2 [cs.LG] UPDATED)</h2>
<h3>Miguel Ruiz-Garcia, Ge Zhang, Samuel S. Schoenholz, Andrea J. Liu</h3>
<p>We show that learning can be improved by using loss functions that evolve
cyclically during training to emphasize one class at a time. In
underparameterized networks, such dynamical loss functions can lead to
successful training for networks that fail to find a deep minima of the
standard cross-entropy loss. In overparameterized networks, dynamical loss
functions can lead to better generalization. Improvement arises from the
interplay of the changing loss landscape with the dynamics of the system as it
evolves to minimize the loss. In particular, as the loss function oscillates,
instabilities develop in the form of bifurcation cascades, which we study using
the Hessian and Neural Tangent Kernel. Valleys in the landscape widen and
deepen, and then narrow and rise as the loss landscape changes during a cycle.
As the landscape narrows, the learning rate becomes too large and the network
becomes unstable and bounces around the valley. This process ultimately pushes
the system into deeper and wider regions of the loss landscape and is
characterized by decreasing eigenvalues of the Hessian. This results in better
regularized models with improved generalization performance.
</p>
<a href="http://arxiv.org/abs/2102.03793" target="_blank">arXiv:2102.03793</a> [<a href="http://arxiv.org/pdf/2102.03793" target="_blank">pdf</a>]

<h2>Exploiting epistemic uncertainty of the deep learning models to generate adversarial samples. (arXiv:2102.04150v2 [cs.LG] UPDATED)</h2>
<h3>Omer Faruk Tuna, Ferhat Ozgur Catak, M. Taner Eskil</h3>
<p>Deep neural network architectures are considered to be robust to random
perturbations. Nevertheless, it was shown that they could be severely
vulnerable to slight but carefully crafted perturbations of the input, termed
as adversarial samples. In recent years, numerous studies have been conducted
in this new area called "Adversarial Machine Learning" to devise new
adversarial attacks and to defend against these attacks with more robust DNN
architectures. However, almost all the research work so far has been
concentrated on utilising model loss function to craft adversarial examples or
create robust models. This study explores the usage of quantified epistemic
uncertainty obtained from Monte-Carlo Dropout Sampling for adversarial attack
purposes by which we perturb the input to the areas where the model has not
seen before. We proposed new attack ideas based on the epistemic uncertainty of
the model. Our results show that our proposed hybrid attack approach increases
the attack success rates from 82.59% to 85.40%, 82.86% to 89.92% and 88.06% to
90.03% on MNIST Digit, MNIST Fashion and CIFAR-10 datasets, respectively.
</p>
<a href="http://arxiv.org/abs/2102.04150" target="_blank">arXiv:2102.04150</a> [<a href="http://arxiv.org/pdf/2102.04150" target="_blank">pdf</a>]

<h2>Diverse Single Image Generation with Controllable Global Structure through Self-Attention. (arXiv:2102.04780v2 [cs.CV] UPDATED)</h2>
<h3>Sutharsan Mahendren, Chamira Edussooriya, Ranga Rodrigo</h3>
<p>Image generation from a single image using generative adversarial networks is
quite interesting due to the realism of generated images. However, recent
approaches need improvement for such realistic and diverse image generation,
when the global context of the image is important such as in face, animal, and
architectural image generation. This is mainly due to the use of fewer
convolutional layers for mainly capturing the patch statistics and, thereby,
not being able to capture global statistics very well. We solve this problem by
using attention blocks at selected scales and feeding a random Gaussian blurred
image to the discriminator for training. Our results are visually better than
the state-of-the-art particularly in generating images that require global
context. The diversity of our image generation, measured using the average
standard deviation of pixels, is also better.
</p>
<a href="http://arxiv.org/abs/2102.04780" target="_blank">arXiv:2102.04780</a> [<a href="http://arxiv.org/pdf/2102.04780" target="_blank">pdf</a>]

<h2>Domain Invariant Representation Learning with Domain Density Transformations. (arXiv:2102.05082v2 [cs.LG] UPDATED)</h2>
<h3>A. Tuan Nguyen, Toan Tran, Yarin Gal, At&#x131;l&#x131;m G&#xfc;ne&#x15f; Baydin</h3>
<p>Domain generalization refers to the problem where we aim to train a model on
data from a set of source domains so that the model can generalize to unseen
target domains. Naively training a model on the aggregate set of data (pooled
from all source domains) has been shown to perform suboptimally, since the
information learned by that model might be domain-specific and generalize
imperfectly to target domains. To tackle this problem, a predominant approach
is to find and learn some domain-invariant information in order to use it for
the prediction task. In this paper, we propose a theoretically grounded method
to learn a domain-invariant representation by enforcing the representation
network to be invariant under all transformation functions among domains. We
also show how to use generative adversarial networks to learn such domain
transformations to implement our method in practice. We demonstrate the
effectiveness of our method on several widely used datasets for the domain
generalization problem, on all of which we achieve competitive results with
state-of-the-art models.
</p>
<a href="http://arxiv.org/abs/2102.05082" target="_blank">arXiv:2102.05082</a> [<a href="http://arxiv.org/pdf/2102.05082" target="_blank">pdf</a>]

<h2>Detecting Localized Adversarial Examples: A Generic Approach using Critical Region Analysis. (arXiv:2102.05241v2 [cs.CV] UPDATED)</h2>
<h3>Fengting Li, Xuankai Liu, Xiaoli Zhang, Qi Li, Kun Sun, Kang Li</h3>
<p>Deep neural networks (DNNs) have been applied in a wide range of
applications,e.g.,face recognition and image classification; however,they are
vulnerable to adversarial examples. By adding a small amount of imperceptible
perturbations,an attacker can easily manipulate the outputs of a DNN.
Particularly,the localized adversarial examples only perturb a small and
contiguous region of the target object,so that they are robust and effective in
both digital and physical worlds. Although the localized adversarial examples
have more severe real-world impacts than traditional pixel attacks,they have
not been well addressed in the literature. In this paper,we propose a generic
defense system called TaintRadar to accurately detect localized adversarial
examples via analyzing critical regions that have been manipulated by
attackers. The main idea is that when removing critical regions from input
images,the ranking changes of adversarial labels will be larger than those of
benign labels. Compared with existing defense solutions,TaintRadar can
effectively capture sophisticated localized partial attacks, e.g.,the
eye-glasses attack,while not requiring additional training or fine-tuning of
the original model's structure. Comprehensive experiments have been conducted
in both digital and physical worlds to verify the effectiveness and robustness
of our defense.
</p>
<a href="http://arxiv.org/abs/2102.05241" target="_blank">arXiv:2102.05241</a> [<a href="http://arxiv.org/pdf/2102.05241" target="_blank">pdf</a>]

<h2>SCA-Net: A Self-Correcting Two-Layer Autoencoder for Hyper-spectral Unmixing. (arXiv:2102.05713v2 [cs.LG] UPDATED)</h2>
<h3>Gurpreet Singh, Soumyajit Gupta, Matthew Lease, Clint Dawson</h3>
<p>Linear Mixture Model for hyperspectral datasets involves separating a mixed
pixel as a linear combination of its constituent endmembers and corresponding
fractional abundances. Both optimization and neural methods have attempted to
tackle this problem, with the current state of the art results achieved by
neural models on benchmark datasets. However, our review of these neural models
show that these networks are severely over-parameterized and consequently the
invariant endmember spectra extracted as decoder weights has a high variance
over multiple runs. All of these approaches require substantial post-processing
to satisfy LMM constraints. Furthermore, they also require an exact
specification of the number of endmembers and specialized initialization of
weights from other algorithms like VCA. Our work shows for the first time that
a two-layer autoencoder (SCA-Net), with $2FK$ parameters ($F$ features, $K$
endmembers), achieves error metrics that are scales apart ($10^{-5})$ from
previously reported values $(10^{-2})$. SCA-Net converges to this low error
solution starting from a random initialization of weights. We also show that
SCA-Net, based upon a bi-orthogonal representation, performs a self-correction
when the the number of endmembers are over-specified. We show that our network
formulation extracts a low-rank representation that is bounded below by a
tail-energy and can be computationally verified. Our numerical experiments on
Samson, Jasper, and Urban datasets demonstrate that SCA-Net outperforms
previously reported error metrics for all the cases while being robust to noise
and outliers.
</p>
<a href="http://arxiv.org/abs/2102.05713" target="_blank">arXiv:2102.05713</a> [<a href="http://arxiv.org/pdf/2102.05713" target="_blank">pdf</a>]

<h2>EventScore: An Automated Real-time Early Warning Score for Clinical Events. (arXiv:2102.05958v2 [cs.LG] UPDATED)</h2>
<h3>Ibrahim Hammoud, Prateek Prasanna, IV Ramakrishnan, Adam Singer, Mark Henry, Henry Thode</h3>
<p>Early prediction of patients at risk of clinical deterioration can help
physicians intervene and alter their clinical course towards better outcomes.
In addition to the accuracy requirement, early warning systems must make the
predictions early enough to give physicians enough time to intervene.
Interpretability is also one of the challenges when building such systems since
being able to justify the reasoning behind model decisions is desirable in
clinical practice. In this work, we built an interpretable model for the early
prediction of various adverse clinical events indicative of clinical
deterioration. The model is evaluated on two datasets and four clinical events.
The first dataset is collected in a predominantly COVID-19 positive population
at Stony Brook Hospital. The second dataset is the MIMIC III dataset. The model
was trained to provide early warning scores for ventilation, ICU transfer, and
mortality prediction tasks on the Stony Brook Hospital dataset and to predict
mortality and the need for vasopressors on the MIMIC III dataset. Our model
first separates each feature into multiple ranges and then uses logistic
regression with lasso penalization to select the subset of ranges for each
feature. The model training is completely automated and doesn't require expert
knowledge like other early warning scores. We compare our model to the Modified
Early Warning Score (MEWS) and quick SOFA (qSOFA), commonly used in hospitals.
We show that our model outperforms these models in the area under the receiver
operating characteristic curve (AUROC) while having a similar or better median
detection time on all clinical events, even when using fewer features. Unlike
MEWS and qSOFA, our model can be entirely automated without requiring any
manually recorded features. We also show that discretization improves model
performance by comparing our model to a baseline logistic regression model.
</p>
<a href="http://arxiv.org/abs/2102.05958" target="_blank">arXiv:2102.05958</a> [<a href="http://arxiv.org/pdf/2102.05958" target="_blank">pdf</a>]

<h2>Neural Re-rendering for Full-frame Video Stabilization. (arXiv:2102.06205v2 [cs.CV] UPDATED)</h2>
<h3>Yu-Lun Liu, Wei-Sheng Lai, Ming-Hsuan Yang, Yung-Yu Chuang, Jia-Bin Huang</h3>
<p>Existing video stabilization methods either require aggressive cropping of
frame boundaries or generate distortion artifacts on the stabilized frames. In
this work, we present an algorithm for full-frame video stabilization by first
estimating dense warp fields. Full-frame stabilized frames can then be
synthesized by fusing warped contents from neighboring frames. The core
technical novelty lies in our learning-based hybrid-space fusion that
alleviates artifacts caused by optical flow inaccuracy and fast-moving objects.
We validate the effectiveness of our method on the NUS and selfie video
datasets. Extensive experiment results demonstrate the merits of our approach
over prior video stabilization methods.
</p>
<a href="http://arxiv.org/abs/2102.06205" target="_blank">arXiv:2102.06205</a> [<a href="http://arxiv.org/pdf/2102.06205" target="_blank">pdf</a>]

<h2>Speculative Path Planning. (arXiv:2102.06261v2 [cs.RO] UPDATED)</h2>
<h3>Mohammad Bakhshalipour, Mohamad Qadri, Dominic Guri</h3>
<p>Parallelization of A* path planning is mostly limited by the number of
possible motions, which is far less than the level of parallelism that modern
processors support. In this paper, we go beyond the limitations of traditional
parallelism of A* and propose Speculative Path Planning to accelerate the
search when there are abundant idle resources. The key idea of our approach is
predicting future state expansions relying on patterns among expansions and
aggressively parallelize the computations of prospective states (i.e.
pre-evaluate the expensive collision checking operation of prospective nodes).
This method allows us to maintain the same search order as of vanilla A* and
safeguard any optimality guarantees. We evaluate our method on various
configurations and show that on a machine with 32 physical cores, our method
improves the performance around 11x and 10x on average over counterpart
single-threaded and multi-threaded implementations respectively. The code to
our paper can be found here:
https://github.com/bakhshalipour/speculative-path-planning.
</p>
<a href="http://arxiv.org/abs/2102.06261" target="_blank">arXiv:2102.06261</a> [<a href="http://arxiv.org/pdf/2102.06261" target="_blank">pdf</a>]

<h2>Projected Wasserstein gradient descent for high-dimensional Bayesian inference. (arXiv:2102.06350v2 [cs.LG] UPDATED)</h2>
<h3>Yifei Wang, Peng Chen, Wuchen Li</h3>
<p>We propose a projected Wasserstein gradient descent method (pWGD) for
high-dimensional Bayesian inference problems. The underlying density function
of a particle system of WGD is approximated by kernel density estimation (KDE),
which faces the long-standing curse of dimensionality. We overcome this
challenge by exploiting the intrinsic low-rank structure in the difference
between the posterior and prior distributions. The parameters are projected
into a low-dimensional subspace to alleviate the approximation error of KDE in
high dimensions. We formulate a projected Wasserstein gradient flow and analyze
its convergence property under mild assumptions. Several numerical experiments
illustrate the accuracy, convergence, and complexity scalability of pWGD with
respect to parameter dimension, sample size, and processor cores.
</p>
<a href="http://arxiv.org/abs/2102.06350" target="_blank">arXiv:2102.06350</a> [<a href="http://arxiv.org/pdf/2102.06350" target="_blank">pdf</a>]

<h2>DeepGLEAM: a hybrid mechanistic and deep learning model for COVID-19 forecasting. (arXiv:2102.06684v2 [cs.LG] UPDATED)</h2>
<h3>Dongxia Wu, Liyao Gao, Xinyue Xiong, Matteo Chinazzi, Alessandro Vespignani, Yian Ma, Rose Yu</h3>
<p>We introduce DeepGLEAM, a hybrid model for COVID-19 forecasting. DeepGLEAM
combines a mechanistic stochastic simulation model GLEAM with deep learning. It
uses deep learning to learn the correction terms from GLEAM, which leads to
improved performance. We further integrate various uncertainty quantification
methods to generate confidence intervals. We demonstrate DeepGLEAM on
real-world COVID-19 mortality forecasting tasks.
</p>
<a href="http://arxiv.org/abs/2102.06684" target="_blank">arXiv:2102.06684</a> [<a href="http://arxiv.org/pdf/2102.06684" target="_blank">pdf</a>]

<h2>Enterprise domain ontology learning from web-based corpus. (arXiv:2102.01498v1 [cs.AI] CROSS LISTED)</h2>
<h3>Andrei Vasilateanu, Nicolae Goga, Elena-Alice Tanase, Iuliana Marin</h3>
<p>Enterprise knowledge is a key asset in the competing and fast-changing
corporate landscape. The ability to learn, store and distribute implicit and
explicit knowledge can be the difference between success and failure. While
enterprise knowledge management is a well-defined research domain, current
implementations lack orientation towards small and medium enterprise. We
propose a semantic search engine for relevant documents in an enterprise, based
on automatic generated domain ontologies. In this paper we focus on the
component for ontology learning and population.
</p>
<a href="http://arxiv.org/abs/2102.01498" target="_blank">arXiv:2102.01498</a> [<a href="http://arxiv.org/pdf/2102.01498" target="_blank">pdf</a>]

<h2>A Simple Deep Equilibrium Model Converges to Global Optima with Weight Tying. (arXiv:2102.07346v1 [cs.LG])</h2>
<h3>Kenji Kawaguchi</h3>
<p>A deep equilibrium linear model is implicitly defined through an equilibrium
point of an infinite sequence of computation. It avoids any explicit
computation of the infinite sequence by finding an equilibrium point directly
via root-finding and by computing gradients via implicit differentiation. It is
a simple deep equilibrium model with nonlinear activations on weight matrices.
In this paper, we analyze the gradient dynamics of this simple deep equilibrium
model with non-convex objective functions for a general class of losses used in
regression and classification. Despite non-convexity, convergence to global
optimum at a linear rate is guaranteed without any assumption on the width of
the models, allowing the width to be smaller than the output dimension and the
number of data points. Moreover, we prove a relation between the gradient
dynamics of the simple deep equilibrium model and the dynamics of trust region
Newton method of a shallow model. This mathematically proven relation along
with our numerical observation suggests the importance of understanding
implicit bias and a possible open problem on the topic. Our proofs deal with
nonlinearity and weight tying, and differ from those in the related literature.
</p>
<a href="http://arxiv.org/abs/2102.07346" target="_blank">arXiv:2102.07346</a> [<a href="http://arxiv.org/pdf/2102.07346" target="_blank">pdf</a>]

<h2>Almost Optimal Algorithms for Two-player Markov Games with Linear Function Approximation. (arXiv:2102.07404v1 [cs.LG])</h2>
<h3>Zixiang Chen, Dongruo Zhou, Quanquan Gu</h3>
<p>We study reinforcement learning for two-player zero-sum Markov games with
simultaneous moves in the finite-horizon setting, where the transition kernel
of the underlying Markov games can be parameterized by a linear function over
the current state, both players' actions and the next state. In particular, we
assume that we can control both players and aim to find the Nash Equilibrium by
minimizing the duality gap. We propose an algorithm Nash-UCRL-VTR based on the
principle "Optimism-in-Face-of-Uncertainty". Our algorithm only needs to find a
Coarse Correlated Equilibrium (CCE), which is computationally very efficient.
Specifically, we show that Nash-UCRL-VTR can provably achieve an
$\tilde{O}(dH\sqrt{T})$ regret, where $d$ is the linear function dimension, $H$
is the length of the game and $T$ is the total number of steps in the game. To
access the optimality of our algorithm, we also prove an $\tilde{\Omega}(
dH\sqrt{T})$ lower bound on the regret. Our upper bound matches the lower bound
up to logarithmic factors, which suggests the optimality of our algorithm.
</p>
<a href="http://arxiv.org/abs/2102.07404" target="_blank">arXiv:2102.07404</a> [<a href="http://arxiv.org/pdf/2102.07404" target="_blank">pdf</a>]

<h2>Tractable structured natural gradient descent using local parameterizations. (arXiv:2102.07405v1 [stat.ML])</h2>
<h3>Wu Lin, Frank Nielsen, Mohammad Emtiyaz Khan, Mark Schmidt</h3>
<p>Natural-gradient descent on structured parameter spaces (e.g., low-rank
covariances) is computationally challenging due to complicated inverse
Fisher-matrix computations. We address this issue for optimization, inference,
and search problems by using \emph{local-parameter coordinates}. Our method
generalizes an existing evolutionary-strategy method, recovers Newton and
Riemannian-gradient methods as special cases, and also yields new tractable
natural-gradient algorithms for learning flexible covariance structures of
Gaussian and Wishart-based distributions. We show results on a range of
applications on deep learning, variational inference, and evolution strategies.
Our work opens a new direction for scalable structured geometric methods via
local parameterizations.
</p>
<a href="http://arxiv.org/abs/2102.07405" target="_blank">arXiv:2102.07405</a> [<a href="http://arxiv.org/pdf/2102.07405" target="_blank">pdf</a>]

<h2>Fast and accurate optimization on the orthogonal manifold without retraction. (arXiv:2102.07432v1 [stat.ML])</h2>
<h3>Pierre Ablin, Gabriel Peyr&#xe9;</h3>
<p>We consider the problem of minimizing a function over the manifold of
orthogonal matrices. The majority of algorithms for this problem compute a
direction in the tangent space, and then use a retraction to move in that
direction while staying on the manifold. Unfortunately, the numerical
computation of retractions on the orthogonal manifold always involves some
expensive linear algebra operation, such as matrix inversion or matrix
square-root. These operations quickly become expensive as the dimension of the
matrices grows. To bypass this limitation, we propose the landing algorithm
which does not involve retractions. The algorithm is not constrained to stay on
the manifold but its evolution is driven by a potential energy which
progressively attracts it towards the manifold. One iteration of the landing
algorithm only involves matrix multiplications, which makes it cheap compared
to its retraction counterparts. We provide an analysis of the convergence of
the algorithm, and demonstrate its promises on large-scale problems, where it
is faster and less prone to numerical errors than retraction-based methods.
</p>
<a href="http://arxiv.org/abs/2102.07432" target="_blank">arXiv:2102.07432</a> [<a href="http://arxiv.org/pdf/2102.07432" target="_blank">pdf</a>]

<h2>Annealed Flow Transport Monte Carlo. (arXiv:2102.07501v1 [stat.ML])</h2>
<h3>Michael Arbel, Alexander G. D. G. Matthews, Arnaud Doucet</h3>
<p>Annealed Importance Sampling (AIS) and its Sequential Monte Carlo (SMC)
extensions are state-of-the-art methods for estimating normalizing constants of
probability distributions. We propose here a novel Monte Carlo algorithm,
Annealed Flow Transport (AFT), that builds upon AIS and SMC and combines them
with normalizing flows (NF) for improved performance. This method transports a
set of particles using not only importance sampling (IS), Markov chain Monte
Carlo (MCMC) and resampling steps - as in SMC, but also relies on NF which are
learned sequentially to push particles towards the successive annealed targets.
We provide limit theorems for the resulting Monte Carlo estimates of the
normalizing constant and expectations with respect to the target distribution.
Additionally, we show that a continuous-time scaling limit of the population
version of AFT is given by a Feynman--Kac measure which simplifies to the law
of a controlled diffusion for expressive NF. We demonstrate experimentally the
benefits and limitations of our methodology on a variety of applications.
</p>
<a href="http://arxiv.org/abs/2102.07501" target="_blank">arXiv:2102.07501</a> [<a href="http://arxiv.org/pdf/2102.07501" target="_blank">pdf</a>]

<h2>Distributed Online Learning for Joint Regret with Communication Constraints. (arXiv:2102.07521v1 [cs.LG])</h2>
<h3>Dirk van der Hoeven, H&#xe9;di Hadiji, Tim van Erven</h3>
<p>In this paper we consider a distributed online learning

setting for joint regret with communication constraints. This is a
multi-agent setting in which in each round $t$ an adversary activates an agent,
which has to issue a prediction. A subset of all the agents may then
communicate a $b$-bit message to their neighbors in a graph. All agents
cooperate to control the joint regret, which is the sum of the losses of the
agents minus the losses evaluated at the best fixed common comparator
parameters $\pmb{u}$. We provide a comparator-adaptive algorithm for this
setting, which means that the joint regret scales with the norm of the
comparator $\|\pmb{u}\|$. To address communication constraints we provide
deterministic and stochastic gradient compression schemes and show that with
these compression schemes our algorithm has worst-case optimal regret for the
case that all agents communicate in every round. Additionally, we exploit the
comparator-adaptive property of our algorithm to learn the best partition from
a set of candidate partitions, which allows different subsets of agents to
learn a different comparator.
</p>
<a href="http://arxiv.org/abs/2102.07521" target="_blank">arXiv:2102.07521</a> [<a href="http://arxiv.org/pdf/2102.07521" target="_blank">pdf</a>]

<h2>Certifiably Robust Variational Autoencoders. (arXiv:2102.07559v1 [stat.ML])</h2>
<h3>Ben Barrett, Alexander Camuto, Matthew Willetts, Tom Rainforth</h3>
<p>We introduce an approach for training Variational Autoencoders (VAEs) that
are certifiably robust to adversarial attack. Specifically, we first derive
actionable bounds on the minimal size of an input perturbation required to
change a VAE's reconstruction by more than an allowed amount, with these bounds
depending on certain key parameters such as the Lipschitz constants of the
encoder and decoder. We then show how these parameters can be controlled,
thereby providing a mechanism to ensure a priori that a VAE will attain a
desired level of robustness. Moreover, we extend this to a complete practical
approach for training such VAEs to ensure our criteria are met. Critically, our
method allows one to specify a desired level of robustness upfront and then
train a VAE that is guaranteed to achieve this robustness. We further
demonstrate that these Lipschitz--constrained VAEs are more robust to attack
than standard VAEs in practice.
</p>
<a href="http://arxiv.org/abs/2102.07559" target="_blank">arXiv:2102.07559</a> [<a href="http://arxiv.org/pdf/2102.07559" target="_blank">pdf</a>]

<h2>On Riemannian Stochastic Approximation Schemes with Fixed Step-Size. (arXiv:2102.07586v1 [stat.ML])</h2>
<h3>Alain Durmus, Pablo Jim&#xe9;nez, &#xc9;ric Moulines, Salem Said</h3>
<p>This paper studies fixed step-size stochastic approximation (SA) schemes,
including stochastic gradient schemes, in a Riemannian framework. It is
motivated by several applications, where geodesics can be computed explicitly,
and their use accelerates crude Euclidean methods. A fixed step-size scheme
defines a family of time-homogeneous Markov chains, parametrized by the
step-size. Here, using this formulation, non-asymptotic performance bounds are
derived, under Lyapunov conditions. Then, for any step-size, the corresponding
Markov chain is proved to admit a unique stationary distribution, and to be
geometrically ergodic. This result gives rise to a family of stationary
distributions indexed by the step-size, which is further shown to converge to a
Dirac measure, concentrated at the solution of the problem at hand, as the
step-size goes to 0. Finally, the asymptotic rate of this convergence is
established, through an asymptotic expansion of the bias, and a central limit
theorem.
</p>
<a href="http://arxiv.org/abs/2102.07586" target="_blank">arXiv:2102.07586</a> [<a href="http://arxiv.org/pdf/2102.07586" target="_blank">pdf</a>]

<h2>A generalized quadratic loss for SVM and Deep Neural Networks. (arXiv:2102.07606v1 [cs.LG])</h2>
<h3>Filippo Portera</h3>
<p>We consider some supervised binary classification tasks and a regression
task, whereas SVM and Deep Learning, at present, exhibit the best
generalization performances. We extend the work [3] on a generalized quadratic
loss for learning problems that examines pattern correlations in order to
concentrate the learning problem into input space regions where patterns are
more densely distributed. From a shallow methods point of view (e.g.: SVM),
since the following mathematical derivation of problem (9) in [3] is incorrect,
we restart from problem (8) in [3] and we try to solve it with one procedure
that iterates over the dual variables until the primal and dual objective
functions converge. In addition we propose another algorithm that tries to
solve the classification problem directly from the primal problem formulation.
We make also use of Multiple Kernel Learning to improve generalization
performances. Moreover, we introduce for the first time a custom loss that
takes in consideration pattern correlation for a shallow and a Deep Learning
task. We propose some pattern selection criteria and the results on 4 UCI
data-sets for the SVM method. We also report the results on a larger binary
classification data-set based on Twitter, again drawn from UCI, combined with
shallow Learning Neural Networks, with and without the generalized quadratic
loss. At last, we test our loss with a Deep Neural Network within a larger
regression task taken from UCI. We compare the results of our optimizers with
the well known solver SVMlight and with Keras Multi-Layers Neural Networks with
standard losses and with a parameterized generalized quadratic loss, and we
obtain comparable results.
</p>
<a href="http://arxiv.org/abs/2102.07606" target="_blank">arXiv:2102.07606</a> [<a href="http://arxiv.org/pdf/2102.07606" target="_blank">pdf</a>]

<h2>Causal Markov Decision Processes: Learning Good Interventions Efficiently. (arXiv:2102.07663v1 [stat.ML])</h2>
<h3>Yangyi Lu, Amirhossein Meisami, Ambuj Tewari</h3>
<p>We introduce causal Markov Decision Processes (C-MDPs), a new formalism for
sequential decision making which combines the standard MDP formulation with
causal structures over state transition and reward functions. Many contemporary
and emerging application areas such as digital healthcare and digital marketing
can benefit from modeling with C-MDPs due to the causal mechanisms underlying
the relationship between interventions and states/rewards. We propose the
causal upper confidence bound value iteration (C-UCBVI) algorithm that exploits
the causal structure in C-MDPs and improves the performance of standard
reinforcement learning algorithms that do not take causal knowledge into
account. We prove that C-UCBVI satisfies an $\tilde{O}(HS\sqrt{ZT})$ regret
bound, where $T$ is the the total time steps, $H$ is the episodic horizon, and
$S$ is the cardinality of the state space. Notably, our regret bound does not
scale with the size of actions/interventions ($A$), but only scales with a
causal graph dependent quantity $Z$ which can be exponentially smaller than
$A$. By extending C-UCBVI to the factored MDP setting, we propose the causal
factored UCBVI (CF-UCBVI) algorithm, which further reduces the regret
exponentially in terms of $S$. Furthermore, we show that RL algorithms for
linear MDP problems can also be incorporated in C-MDPs. We empirically show the
benefit of our causal approaches in various settings to validate our algorithms
and theoretical results.
</p>
<a href="http://arxiv.org/abs/2102.07663" target="_blank">arXiv:2102.07663</a> [<a href="http://arxiv.org/pdf/2102.07663" target="_blank">pdf</a>]

<h2>Does Standard Backpropagation Forget Less Catastrophically Than Adam?. (arXiv:2102.07686v1 [cs.LG])</h2>
<h3>Dylan R. Ashley, Sina Ghiassian, Richard S. Sutton</h3>
<p>Catastrophic forgetting remains a severe hindrance to the broad application
of artificial neural networks (ANNs), however, it continues to be a poorly
understood phenomenon. Despite the extensive amount of work on catastrophic
forgetting, we argue that it is still unclear how exactly the phenomenon should
be quantified, and, moreover, to what degree all of the choices we make when
designing learning systems affect the amount of catastrophic forgetting. We use
various testbeds from the reinforcement learning and supervised learning
literature to (1) provide evidence that the choice of which modern
gradient-based optimization algorithm is used to train an ANN has a significant
impact on the amount of catastrophic forgetting and show that--surprisingly--in
many instances classical algorithms such as vanilla SGD experience less
catastrophic forgetting than the more modern algorithms such as Adam. We
empirically compare four different existing metrics for quantifying
catastrophic forgetting and (2) show that the degree to which the learning
systems experience catastrophic forgetting is sufficiently sensitive to the
metric used that a change from one principled metric to another is enough to
change the conclusions of a study dramatically. Our results suggest that a much
more rigorous experimental methodology is required when looking at catastrophic
forgetting. Based on our results, we recommend inter-task forgetting in
supervised learning must be measured with both retention and relearning metrics
concurrently, and intra-task forgetting in reinforcement learning must--at the
very least--be measured with pairwise interference.
</p>
<a href="http://arxiv.org/abs/2102.07686" target="_blank">arXiv:2102.07686</a> [<a href="http://arxiv.org/pdf/2102.07686" target="_blank">pdf</a>]

<h2>Scalable nonparametric Bayesian learning for heterogeneous and dynamic velocity fields. (arXiv:2102.07695v1 [stat.ML])</h2>
<h3>Sunrit Chakraborty, Aritra Guha, Rayleigh Lei, XuanLong Nguyen</h3>
<p>Analysis of heterogeneous patterns in complex spatio-temporal data finds
usage across various domains in applied science and engineering, including
training autonomous vehicles to navigate in complex traffic scenarios.
Motivated by applications arising in the transportation domain, in this paper
we develop a model for learning heterogeneous and dynamic patterns of velocity
field data. We draw from basic nonparameric Bayesian modeling elements such as
hierarchical Dirichlet process and infinite hidden Markov model, while the
smoothness of each homogeneous velocity field element is captured with a
Gaussian process prior. Of particular focus is a scalable approximate inference
method for the proposed model; this is achieved by employing sequential MAP
estimates from the infinite HMM model and an efficient sequential GP posterior
computation technique, which is shown to work effectively on simulated data
sets. Finally, we demonstrate the effectiveness of our techniques to the NGSIM
dataset of complex multi-vehicle interactions.
</p>
<a href="http://arxiv.org/abs/2102.07695" target="_blank">arXiv:2102.07695</a> [<a href="http://arxiv.org/pdf/2102.07695" target="_blank">pdf</a>]

<h2>How to Learn when Data Reacts to Your Model: Performative Gradient Descent. (arXiv:2102.07698v1 [cs.LG])</h2>
<h3>Zachary Izzo, Lexing Ying, James Zou</h3>
<p>Performative distribution shift captures the setting where the choice of
which ML model is deployed changes the data distribution. For example, a bank
which uses the number of open credit lines to determine a customer's risk of
default on a loan may induce customers to open more credit lines in order to
improve their chances of being approved. Because of the interactions between
the model and data distribution, finding the optimal model parameters is
challenging. Works in this area have focused on finding stable points, which
can be far from optimal. Here we introduce performative gradient descent
(PerfGD), which is the first algorithm which provably converges to the
performatively optimal point. PerfGD explicitly captures how changes in the
model affects the data distribution and is simple to use. We support our
findings with theory and experiments.
</p>
<a href="http://arxiv.org/abs/2102.07698" target="_blank">arXiv:2102.07698</a> [<a href="http://arxiv.org/pdf/2102.07698" target="_blank">pdf</a>]

<h2>Secure-UCB: Saving Stochastic Bandits from Poisoning Attacks via Limited Data Verification. (arXiv:2102.07711v1 [cs.LG])</h2>
<h3>Anshuka Rangi, Long Tran-Thanh, Haifeng Xu, Massimo Franceschetti</h3>
<p>This paper studies bandit algorithms under data poisoning attacks in a
bounded reward setting. We consider a strong attacker model in which the
attacker can observe both the selected actions and their corresponding rewards,
and can contaminate the rewards with additive noise. We show that \emph{any}
bandit algorithm with regret $O(\log T)$ can be forced to suffer a regret
$\Omega(T)$ with an expected amount of contamination $O(\log T)$. This amount
of contamination is also necessary, as we prove that there exists an $O(\log
T)$ regret bandit algorithm, specifically the classical UCB, that requires
$\Omega(\log T)$ amount of contamination to suffer regret $\Omega(T)$. To
combat such poising attacks, our second main contribution is to propose a novel
algorithm, Secure-UCB, which uses limited \emph{verification} to access a
limited number of uncontaminated rewards. We show that with $O(\log T)$
expected number of verifications, Secure-UCB can restore the order optimal
$O(\log T)$ regret \emph{irrespective of the amount of contamination} used by
the attacker. Finally, we prove that for any bandit algorithm, this number of
verifications $O(\log T)$ is necessary to recover the order-optimal regret. We
can then conclude that Secure-UCB is order-optimal in terms of both the
expected regret and the expected number of verifications, and can save
stochastic bandits from any data poisoning attack.
</p>
<a href="http://arxiv.org/abs/2102.07711" target="_blank">arXiv:2102.07711</a> [<a href="http://arxiv.org/pdf/2102.07711" target="_blank">pdf</a>]

