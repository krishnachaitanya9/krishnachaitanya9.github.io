---
title: Latest Deep Learning Papers
date: 2021-02-16 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (198 Articles)</h1>
<h2>Variable importance scores. (arXiv:2102.07765v1 [cs.LG])</h2>
<h3>Wei-Yin Loh, Peigen Zhou</h3>
<p>Scoring of variables for importance in predicting a response is an
ill-defined concept. Several methods have been proposed but little is known of
their performance. This paper fills the gap with a comparative evaluation of
eleven methods and an updated one based on the GUIDE algorithm. For data
without missing values, eight of the methods are shown to be biased in that
they give higher or lower scores to different types of variables, even when all
are independent of the response. Of the remaining four methods, only two are
applicable to data with missing values, with GUIDE the only unbiased one. GUIDE
achieves unbiasedness by using a self-calibrating step that is applicable to
other methods for score de-biasing. GUIDE also yields a threshold for
distinguishing important from unimportant variables at 95 and 99 percent
confidence levels; the technique is applicable to other methods as well.
Finally, the paper studies the relationship of the scores to predictive power
in three data sets. It is found that the scores of many methods are more
consistent with marginal predictive power than conditional predictive power.
</p>
<a href="http://arxiv.org/abs/2102.07765" target="_blank">arXiv:2102.07765</a> [<a href="http://arxiv.org/pdf/2102.07765" target="_blank">pdf</a>]

<h2>Communication-Efficient Distributed Cooperative Learning with Compressed Beliefs. (arXiv:2102.07767v1 [cs.LG])</h2>
<h3>Mohammad Taha Toghani, Cesar A. Uribe</h3>
<p>We study the problem of distributed cooperative learning, where a group of
agents seek to agree on a set of hypotheses that best describes a sequence of
private observations. In the scenario where the set of hypotheses is large, we
propose a belief update rule where agents share compressed (either sparse or
quantized) beliefs with an arbitrary positive compression rate. Our algorithm
leverages a unified and straightforward communication rule that enables agents
to access wide-ranging compression operators as black-box modules. We prove the
almost sure asymptotic exponential convergence of beliefs around the set of
optimal hypotheses. Additionally, we show a non-asymptotic, explicit, and
linear concentration rate in probability of the beliefs on the optimal
hypothesis set. We provide numerical experiments to illustrate the
communication benefits of our method. The simulation results show that the
number of transmitted bits can be reduced to 5-10% of the non-compressed method
in the studied scenarios.
</p>
<a href="http://arxiv.org/abs/2102.07767" target="_blank">arXiv:2102.07767</a> [<a href="http://arxiv.org/pdf/2102.07767" target="_blank">pdf</a>]

<h2>Posterior-Aided Regularization for Likelihood-Free Inference. (arXiv:2102.07770v1 [cs.LG])</h2>
<h3>Dongjun Kim, Kyungwoo Song, Seungjae Shin, Wanmo Kang, Il-Chul Moon</h3>
<p>The recent development of likelihood-free inference aims training a flexible
density estimator for the target posterior with a set of input-output pairs
from simulation. Given the diversity of simulation structures, it is difficult
to find a single unified inference method for each simulation model. This paper
proposes a universally applicable regularization technique, called
Posterior-Aided Regularization (PAR), which is applicable to learning the
density estimator, regardless of the model structure. Particularly, PAR solves
the mode collapse problem that arises as the output dimension of the simulation
increases. PAR resolves this posterior mode degeneracy through a mixture of 1)
the reverse KL divergence with the mode seeking property; and 2) the mutual
information for the high quality representation on likelihood. Because of the
estimation intractability of PAR, we provide a unified estimation method of PAR
to estimate both reverse KL term and mutual information term with a single
neural network. Afterwards, we theoretically prove the asymptotic convergence
of the regularized optimal solution to the unregularized optimal solution as
the regularization magnitude converges to zero. Additionally, we empirically
show that past sequential neural likelihood inferences in conjunction with PAR
present the statistically significant gains on diverse simulation tasks.
</p>
<a href="http://arxiv.org/abs/2102.07770" target="_blank">arXiv:2102.07770</a> [<a href="http://arxiv.org/pdf/2102.07770" target="_blank">pdf</a>]

<h2>Online learning of Riemannian hidden Markov models in homogeneous Hadamard spaces. (arXiv:2102.07771v1 [cs.LG])</h2>
<h3>Quinten Tupker, Salem Said, Cyrus Mostajeran</h3>
<p>Hidden Markov models with observations in a Euclidean space play an important
role in signal and image processing. Previous work extending to models where
observations lie in Riemannian manifolds based on the Baum-Welch algorithm
suffered from high memory usage and slow speed. Here we present an algorithm
that is online, more accurate, and offers dramatic improvements in speed and
efficiency.
</p>
<a href="http://arxiv.org/abs/2102.07771" target="_blank">arXiv:2102.07771</a> [<a href="http://arxiv.org/pdf/2102.07771" target="_blank">pdf</a>]

<h2>Ada-SISE: Adaptive Semantic Input Sampling for Efficient Explanation of Convolutional Neural Networks. (arXiv:2102.07799v1 [cs.CV])</h2>
<h3>Mahesh Sudhakar, Sam Sattarzadeh, Konstantinos N. Plataniotis, Jongseong Jang, Yeonjeong Jeong, Hyunwoo Kim</h3>
<p>Explainable AI (XAI) is an active research area to interpret a neural
network's decision by ensuring transparency and trust in the task-specified
learned models. Recently, perturbation-based model analysis has shown better
interpretation, but backpropagation techniques are still prevailing because of
their computational efficiency. In this work, we combine both approaches as a
hybrid visual explanation algorithm and propose an efficient interpretation
method for convolutional neural networks. Our method adaptively selects the
most critical features that mainly contribute towards a prediction to probe the
model by finding the activated features. Experimental results show that the
proposed method can reduce the execution time up to 30% while enhancing
competitive interpretability without compromising the quality of explanation
generated.
</p>
<a href="http://arxiv.org/abs/2102.07799" target="_blank">arXiv:2102.07799</a> [<a href="http://arxiv.org/pdf/2102.07799" target="_blank">pdf</a>]

<h2>Top-$k$ eXtreme Contextual Bandits with Arm Hierarchy. (arXiv:2102.07800v1 [stat.ML])</h2>
<h3>Rajat Sen, Alexander Rakhlin, Lexing Ying, Rahul Kidambi, Dean Foster, Daniel Hill, Inderjit Dhillon</h3>
<p>Motivated by modern applications, such as online advertisement and
recommender systems, we study the top-$k$ extreme contextual bandits problem,
where the total number of arms can be enormous, and the learner is allowed to
select $k$ arms and observe all or some of the rewards for the chosen arms. We
first propose an algorithm for the non-extreme realizable setting, utilizing
the Inverse Gap Weighting strategy for selecting multiple arms. We show that
our algorithm has a regret guarantee of $O(k\sqrt{(A-k+1)T \log
(|\mathcal{F}|T)})$, where $A$ is the total number of arms and $\mathcal{F}$ is
the class containing the regression function, while only requiring
$\tilde{O}(A)$ computation per time step. In the extreme setting, where the
total number of arms can be in the millions, we propose a practically-motivated
arm hierarchy model that induces a certain structure in mean rewards to ensure
statistical and computational efficiency. The hierarchical structure allows for
an exponential reduction in the number of relevant arms for each context, thus
resulting in a regret guarantee of $O(k\sqrt{(\log A-k+1)T \log
(|\mathcal{F}|T)})$. Finally, we implement our algorithm using a hierarchical
linear function class and show superior performance with respect to well-known
benchmarks on simulated bandit feedback experiments using extreme multi-label
classification datasets. On a dataset with three million arms, our reduction
scheme has an average inference time of only 7.9 milliseconds, which is a 100x
improvement.
</p>
<a href="http://arxiv.org/abs/2102.07800" target="_blank">arXiv:2102.07800</a> [<a href="http://arxiv.org/pdf/2102.07800" target="_blank">pdf</a>]

<h2>Efficient Learning with Arbitrary Covariate Shift. (arXiv:2102.07802v1 [cs.LG])</h2>
<h3>Adam Kalai, Varun Kanade</h3>
<p>We give an efficient algorithm for learning a binary function in a given
class C of bounded VC dimension, with training data distributed according to P
and test data according to Q, where P and Q may be arbitrary distributions over
X. This is the generic form of what is called covariate shift, which is
impossible in general as arbitrary P and Q may not even overlap. However,
recently guarantees were given in a model called PQ-learning (Goldwasser et
al., 2020) where the learner has: (a) access to unlabeled test examples from Q
(in addition to labeled samples from P, i.e., semi-supervised learning); and
(b) the option to reject any example and abstain from classifying it (i.e.,
selective classification). The algorithm of Goldwasser et al. (2020) requires
an (agnostic) noise tolerant learner for C. The present work gives a
polynomial-time PQ-learning algorithm that uses an oracle to a "reliable"
learner for C, where reliable learning (Kalai et al., 2012) is a model of
learning with one-sided noise. Furthermore, our reduction is optimal in the
sense that we show the equivalence of reliable and PQ learning.
</p>
<a href="http://arxiv.org/abs/2102.07802" target="_blank">arXiv:2102.07802</a> [<a href="http://arxiv.org/pdf/2102.07802" target="_blank">pdf</a>]

<h2>Scaling Up Exact Neural Network Compression by ReLU Stability. (arXiv:2102.07804v1 [cs.LG])</h2>
<h3>Thiago Serra, Abhinav Kumar, Srikumar Ramalingam</h3>
<p>We can compress a neural network while exactly preserving its underlying
functionality with respect to a given input domain if some of its neurons are
stable. However, current approaches to determine the stability of neurons in
networks with Rectified Linear Unit (ReLU) activations require solving or
finding a good approximation to multiple discrete optimization problems. In
this work, we introduce an algorithm based on solving a single optimization
problem to identify all stable neurons. Our approach is on median 21 times
faster than the state-of-art method, which allows us to explore exact
compression on deeper (5 x 100) and wider (2 x 800) networks within minutes.
For classifiers trained under an amount of L1 regularization that does not
worsen accuracy, we can remove up to 40% of the connections.
</p>
<a href="http://arxiv.org/abs/2102.07804" target="_blank">arXiv:2102.07804</a> [<a href="http://arxiv.org/pdf/2102.07804" target="_blank">pdf</a>]

<h2>Integrated Grad-CAM: Sensitivity-Aware Visual Explanation of Deep Convolutional Networks via Integrated Gradient-Based Scoring. (arXiv:2102.07805v1 [cs.CV])</h2>
<h3>Sam Sattarzadeh, Mahesh Sudhakar, Konstantinos N. Plataniotis, Jongseong Jang, Yeonjeong Jeong, Hyunwoo Kim</h3>
<p>Visualizing the features captured by Convolutional Neural Networks (CNNs) is
one of the conventional approaches to interpret the predictions made by these
models in numerous image recognition applications. Grad-CAM is a popular
solution that provides such a visualization by combining the activation maps
obtained from the model. However, the average gradient-based terms deployed in
this method underestimates the contribution of the representations discovered
by the model to its predictions. Addressing this problem, we introduce a
solution to tackle this issue by computing the path integral of the
gradient-based terms in Grad-CAM. We conduct a thorough analysis to demonstrate
the improvement achieved by our method in measuring the importance of the
extracted representations for the CNN's predictions, which yields to our
method's administration in object localization and model interpretation.
</p>
<a href="http://arxiv.org/abs/2102.07805" target="_blank">arXiv:2102.07805</a> [<a href="http://arxiv.org/pdf/2102.07805" target="_blank">pdf</a>]

<h2>HDMI: High-order Deep Multiplex Infomax. (arXiv:2102.07810v1 [cs.LG])</h2>
<h3>Baoyu Jing, Chanyoung Park, Hanghang Tong</h3>
<p>Networks have been widely used to represent the relations between objects
such as academic networks and social networks, and learning embedding for
networks has thus garnered plenty of research attention. Self-supervised
network representation learning aims at extracting node embedding without
external supervision. Recently, maximizing the mutual information between the
local node embedding and the global summary (e.g. Deep Graph Infomax, or DGI
for short) has shown promising results on many downstream tasks such as node
classification. However, there are two major limitations of DGI. Firstly, DGI
merely considers the extrinsic supervision signal (i.e., the mutual information
between node embedding and global summary) while ignores the intrinsic signal
(i.e., the mutual dependence between node embedding and node attributes).
Secondly, nodes in a real-world network are usually connected by multiple edges
with different relations, while DGI does not fully explore the various
relations among nodes. To address the above-mentioned problems, we propose a
novel framework, called High-order Deep Multiplex Infomax (HDMI), for learning
node embedding on multiplex networks in a self-supervised way. To be more
specific, we first design a joint supervision signal containing both extrinsic
and intrinsic mutual information by high-order mutual information, and we
propose a High-order Deep Infomax (HDI) to optimize the proposed supervision
signal. Then we propose an attention based fusion module to combine node
embedding from different layers of the multiplex network. Finally, we evaluate
the proposed HDMI on various downstream tasks such as unsupervised clustering
and supervised classification. The experimental results show that HDMI achieves
state-of-the-art performance on these tasks.
</p>
<a href="http://arxiv.org/abs/2102.07810" target="_blank">arXiv:2102.07810</a> [<a href="http://arxiv.org/pdf/2102.07810" target="_blank">pdf</a>]

<h2>Graph-based Motion Planning for Automated Vehicles using Multi-model Branching and Admissible Heuristics. (arXiv:2102.07812v1 [cs.RO])</h2>
<h3>Oliver Speidel, Jona Ruof, Klaus Dietmayer</h3>
<p>Automated driving in urban scenarios requires efficient planning algorithms
able to handle complex situations in real-time. A popular approach is to use
graph-based planning methods in order to obtain a rough trajectory which is
subsequently optimized. A key aspect is the generation of trajectories
implementing comfortable and safe behavior already during graph-search while
keeping computation times low. To capture this aspect, on the one hand, a
branching strategy is presented in this work that leads to better performance
in terms of quality of resulting trajectories and runtime. On the other hand,
admissible heuristics are shown which guide the graph-search efficiently, where
the solution remains optimal.
</p>
<a href="http://arxiv.org/abs/2102.07812" target="_blank">arXiv:2102.07812</a> [<a href="http://arxiv.org/pdf/2102.07812" target="_blank">pdf</a>]

<h2>Online hyperparameter optimization by real-time recurrent learning. (arXiv:2102.07813v1 [cs.LG])</h2>
<h3>Daniel Jiwoong Im, Cristina Savin, Kyunghyun Cho</h3>
<p>Conventional hyperparameter optimization methods are computationally
intensive and hard to generalize to scenarios that require dynamically adapting
hyperparameters, such as life-long learning. Here, we propose an online
hyperparameter optimization algorithm that is asymptotically exact and
computationally tractable, both theoretically and practically. Our framework
takes advantage of the analogy between hyperparameter optimization and
parameter learning in recurrent neural networks (RNNs). It adapts a
well-studied family of online learning algorithms for RNNs to tune
hyperparameters and network parameters simultaneously, without repeatedly
rolling out iterative optimization. This procedure yields systematically better
generalization performance compared to standard methods, at a fraction of
wallclock time.
</p>
<a href="http://arxiv.org/abs/2102.07813" target="_blank">arXiv:2102.07813</a> [<a href="http://arxiv.org/pdf/2102.07813" target="_blank">pdf</a>]

<h2>What Do We Want From Explainable Artificial Intelligence (XAI)? -- A Stakeholder Perspective on XAI and a Conceptual Model Guiding Interdisciplinary XAI Research. (arXiv:2102.07817v1 [cs.AI])</h2>
<h3>Markus Langer, Daniel Oster, Timo Speith, Holger Hermanns, Lena K&#xe4;stner, Eva Schmidt, Andreas Sesing, Kevin Baum</h3>
<p>Previous research in Explainable Artificial Intelligence (XAI) suggests that
a main aim of explainability approaches is to satisfy specific interests,
goals, expectations, needs, and demands regarding artificial systems (we call
these stakeholders' desiderata) in a variety of contexts. However, the
literature on XAI is vast, spreads out across multiple largely disconnected
disciplines, and it often remains unclear how explainability approaches are
supposed to achieve the goal of satisfying stakeholders' desiderata. This paper
discusses the main classes of stakeholders calling for explainability of
artificial systems and reviews their desiderata. We provide a model that
explicitly spells out the main concepts and relations necessary to consider and
investigate when evaluating, adjusting, choosing, and developing explainability
approaches that aim to satisfy stakeholders' desiderata. This model can serve
researchers from the variety of different disciplines involved in XAI as a
common ground. It emphasizes where there is interdisciplinary potential in the
evaluation and the development of explainability approaches.
</p>
<a href="http://arxiv.org/abs/2102.07817" target="_blank">arXiv:2102.07817</a> [<a href="http://arxiv.org/pdf/2102.07817" target="_blank">pdf</a>]

<h2>Certified Robustness to Programmable Transformations in LSTMs. (arXiv:2102.07818v1 [cs.LG])</h2>
<h3>Yuhao Zhang, Aws Albarghouthi, Loris D&#x27;Antoni</h3>
<p>Deep neural networks for natural language processing are fragile in the face
of adversarial examples--small input perturbations, like synonym substitution
or word duplication, which cause a neural network to change its prediction. We
present an approach to certifying the robustness of LSTMs (and extensions of
LSTMs) and training models that can be efficiently certified. Our approach can
certify robustness to intractably large perturbation spaces defined
programmatically in a language of string transformations.

The key insight of our approach is an application of abstract interpretation
that exploits recursive LSTM structure to incrementally propagate symbolic sets
of inputs, compactly representing a large perturbation space. Our evaluation
shows that (1) our approach can train models that are more robust to
combinations of string transformations than those produced using existing
techniques; (2) our approach can show high certification accuracy of the
resulting models.
</p>
<a href="http://arxiv.org/abs/2102.07818" target="_blank">arXiv:2102.07818</a> [<a href="http://arxiv.org/pdf/2102.07818" target="_blank">pdf</a>]

<h2>Using Data Assimilation to Train a Hybrid Forecast System that Combines Machine-Learning and Knowledge-Based Components. (arXiv:2102.07819v1 [cs.LG])</h2>
<h3>Alexander Wikner, Jaideep Pathak, Brian R. Hunt, Istvan Szunyogh, Michelle Girvan, Edward Ott</h3>
<p>We consider the problem of data-assisted forecasting of chaotic dynamical
systems when the available data is in the form of noisy partial measurements of
the past and present state of the dynamical system. Recently there have been
several promising data-driven approaches to forecasting of chaotic dynamical
systems using machine learning. Particularly promising among these are hybrid
approaches that combine machine learning with a knowledge-based model, where a
machine-learning technique is used to correct the imperfections in the
knowledge-based model. Such imperfections may be due to incomplete
understanding and/or limited resolution of the physical processes in the
underlying dynamical system, e.g., the atmosphere or the ocean. Previously
proposed data-driven forecasting approaches tend to require, for training,
measurements of all the variables that are intended to be forecast. We describe
a way to relax this assumption by combining data assimilation with machine
learning. We demonstrate this technique using the Ensemble Transform Kalman
Filter (ETKF) to assimilate synthetic data for the 3-variable Lorenz system and
for the Kuramoto-Sivashinsky system, simulating model error in each case by a
misspecified parameter value. We show that by using partial measurements of the
state of the dynamical system, we can train a machine learning model to improve
predictions made by an imperfect knowledge-based model.
</p>
<a href="http://arxiv.org/abs/2102.07819" target="_blank">arXiv:2102.07819</a> [<a href="http://arxiv.org/pdf/2102.07819" target="_blank">pdf</a>]

<h2>A Koopman Approach to Understanding Sequence Neural Models. (arXiv:2102.07824v1 [cs.LG])</h2>
<h3>Ilan Naiman, Omri Azencot</h3>
<p>We introduce a new approach to understanding trained sequence neural models:
the Koopman Analysis of Neural Networks (KANN) method. Motivated by the
relation between time-series models and self-maps, we compute approximate
Koopman operators that encode well the latent dynamics. Unlike other existing
methods whose applicability is limited, our framework is global, and it has
only weak constraints over the inputs. Moreover, the Koopman operator is
linear, and it is related to a rich mathematical theory. Thus, we can use tools
and insights from linear analysis and Koopman Theory in our study. For
instance, we show that the operator eigendecomposition is instrumental in
exploring the dominant features of the network. Our results extend across tasks
and architectures as we demonstrate for the copy problem, and ECG
classification and sentiment analysis tasks.
</p>
<a href="http://arxiv.org/abs/2102.07824" target="_blank">arXiv:2102.07824</a> [<a href="http://arxiv.org/pdf/2102.07824" target="_blank">pdf</a>]

<h2>Phase-Modulated Radar Waveform Classification Using Deep Networks. (arXiv:2102.07827v1 [cs.LG])</h2>
<h3>Michael Wharton, Anne M. Pavy, Philip Schniter</h3>
<p>We consider the problem of classifying noisy, phase-modulated radar
waveforms. While traditionally this has been accomplished by applying classical
machine-learning algorithms on hand-crafted features, it has recently been
shown that better performance can be attained by training deep neural networks
(DNNs) to classify raw I/Q waveforms. However, existing DNNs assume
time-synchronized waveforms and do not exploit complex-valued signal structure,
and many aspects of the their DNN design and training are suboptimal. We
demonstrate that, with an improved DNN architecture and training procedure, it
is possible to reduce classification error from 18% to 0.14% on asynchronous
waveforms from the SIDLE dataset. Unlike past work, we furthermore demonstrate
that accurate classification of multiple overlapping waveforms is also
possible, by achieving 4.0% error with 4 asynchronous SIDLE waveforms.
</p>
<a href="http://arxiv.org/abs/2102.07827" target="_blank">arXiv:2102.07827</a> [<a href="http://arxiv.org/pdf/2102.07827" target="_blank">pdf</a>]

<h2>One Line To Rule Them All: Generating LO-Shot Soft-Label Prototypes. (arXiv:2102.07834v1 [cs.LG])</h2>
<h3>Ilia Sucholutsky, Nam-Hwui Kim, Ryan P. Browne, Matthias Schonlau</h3>
<p>Increasingly large datasets are rapidly driving up the computational costs of
machine learning. Prototype generation methods aim to create a small set of
synthetic observations that accurately represent a training dataset but greatly
reduce the computational cost of learning from it. Assigning soft labels to
prototypes can allow increasingly small sets of prototypes to accurately
represent the original training dataset. Although foundational work on `less
than one'-shot learning has proven the theoretical plausibility of learning
with fewer than one observation per class, developing practical algorithms for
generating such prototypes remains an unexplored territory. We propose a novel,
modular method for generating soft-label prototypical lines that still
maintains representational accuracy even when there are fewer prototypes than
the number of classes in the data. In addition, we propose the Hierarchical
Soft-Label Prototype k-Nearest Neighbor classification algorithm based on these
prototypical lines. We show that our method maintains high classification
accuracy while greatly reducing the number of prototypes required to represent
a dataset, even when working with severely imbalanced and difficult data. Our
code is available at https://github.com/ilia10000/SLkNN.
</p>
<a href="http://arxiv.org/abs/2102.07834" target="_blank">arXiv:2102.07834</a> [<a href="http://arxiv.org/pdf/2102.07834" target="_blank">pdf</a>]

<h2>Topological Graph Neural Networks. (arXiv:2102.07835v1 [cs.LG])</h2>
<h3>Max Horn, Edward De Brouwer, Michael Moor, Yves Moreau, Bastian Rieck, Karsten Borgwardt</h3>
<p>Graph neural networks (GNNs) are a powerful architecture for tackling graph
learning tasks, yet have been shown to be oblivious to eminent substructures,
such as cycles. We present TOGL, a novel layer that incorporates global
topological information of a graph using persistent homology. TOGL can be
easily integrated into any type of GNN and is strictly more expressive in terms
of the Weisfeiler--Lehman test of isomorphism. Augmenting GNNs with our layer
leads to beneficial predictive performance, both on synthetic data sets, which
can be trivially classified by humans but not by ordinary GNNs, and on
real-world data.
</p>
<a href="http://arxiv.org/abs/2102.07835" target="_blank">arXiv:2102.07835</a> [<a href="http://arxiv.org/pdf/2102.07835" target="_blank">pdf</a>]

<h2>Quartile-based Prediction of Event Types and Event Time in Business Processes using Deep Learning. (arXiv:2102.07838v1 [cs.LG])</h2>
<h3>Ishwar Venugopal</h3>
<p>Deep learning models are now being increasingly used for predictive process
mining tasks in business processes. Modern approaches have been successful in
achieving better performance for different predictive tasks, as compared to
traditional approaches. In this work, five different variants of a model
involving a Graph Convolutional Layer and linear layers have been tested for
the task of predicting the nature and timestamp of the next activity in a given
process instance. We have introduced a new method for representing feature
vectors for any individual event in a given process instance, taking into
consideration the structure of Directly-follows process graphs generated from
the corresponding datasets. The adjacency matrix of the process graphs
generated has been used as input to a Graph Convolutional Network (GCN).
Different model variants make use of variations in the representation of the
adjacency matrix. The performance of all the model variants have been tested at
different stages of a process, determined by quartiles estimated based on the
number of events and the case duration. The results obtained from the
experiments, significantly improves over the previously reported results for
most of the individual tasks. Interestingly, it was observed that a linear
Multi-Layer Perceptron (MLP) with dropout was able to outperform the GCN
variants in both the prediction tasks. Using a quartile-based analysis, it was
further observed that the other variants were able to perform better than MLP
at individual quartiles in some of the tasks where the MLP had the best overall
performance.
</p>
<a href="http://arxiv.org/abs/2102.07838" target="_blank">arXiv:2102.07838</a> [<a href="http://arxiv.org/pdf/2102.07838" target="_blank">pdf</a>]

<h2>MARINA: Faster Non-Convex Distributed Learning with Compression. (arXiv:2102.07845v1 [cs.LG])</h2>
<h3>Eduard Gorbunov, Konstantin Burlachenko, Zhize Li, Peter Richt&#xe1;rik</h3>
<p>We develop and analyze MARINA: a new communication efficient method for
non-convex distributed learning over heterogeneous datasets. MARINA employs a
novel communication compression strategy based on the compression of gradient
differences which is reminiscent of but different from the strategy employed in
the DIANA method of Mishchenko et al (2019). Unlike virtually all competing
distributed first-order methods, including DIANA, ours is based on a carefully
designed biased gradient estimator, which is the key to its superior
theoretical and practical performance. To the best of our knowledge, the
communication complexity bounds we prove for MARINA are strictly superior to
those of all previous first order methods. Further, we develop and analyze two
variants of MARINA: VR-MARINA and PP-MARINA. The first method is designed for
the case when the local loss functions owned by clients are either of a finite
sum or of an expectation form, and the second method allows for partial
participation of clients -- a feature important in federated learning. All our
methods are superior to previous state-of-the-art methods in terms of the
oracle/communication complexity. Finally, we provide convergence analysis of
all methods for problems satisfying the Polyak-Lojasiewicz condition.
</p>
<a href="http://arxiv.org/abs/2102.07845" target="_blank">arXiv:2102.07845</a> [<a href="http://arxiv.org/pdf/2102.07845" target="_blank">pdf</a>]

<h2>Self-Supervised Features Improve Open-World Learning. (arXiv:2102.07848v1 [cs.CV])</h2>
<h3>Akshay Raj Dhamija, Touqeer Ahmad, Jonathan Schwan, Mohsen Jafarzadeh, Chunchun Li, Terrance E. Boult</h3>
<p>This is a position paper that addresses the problem of Open-World learning
while proposing for the underlying feature representation to be learnt using
self-supervision. We also present an unifying open-world framework combining
three individual research dimensions which have been explored independently \ie
Incremental Learning, Out-of-Distribution detection and Open-World learning. We
observe that the supervised feature representations are limited and degenerate
for the Open-World setting and unsupervised feature representation is native to
each of these three problem domains. Under an unsupervised feature
representation, we categorize the problem of detecting unknowns as either
Out-of-Label-space or Out-of-Distribution detection, depending on the data used
during system training versus system testing. The incremental learning
component of our pipeline is a zero-exemplar online model which performs
comparatively against state-of-the-art on ImageNet-100 protocol and does not
require any back-propagation or retraining of the underlying deep-network. It
further outperforms the current state-of-the-art by simply using the same
number of exemplars as its counterparts. To evaluate our approach for
Open-World learning, we propose a new comprehensive protocol and evaluate its
performance in both Out-of-Label and Out-of-Distribution settings for each
incremental stage. We also demonstrate the adaptability of our approach by
showing how it can work as a plug-in with any of the recently proposed
self-supervised feature representation methods.
</p>
<a href="http://arxiv.org/abs/2102.07848" target="_blank">arXiv:2102.07848</a> [<a href="http://arxiv.org/pdf/2102.07848" target="_blank">pdf</a>]

<h2>Identifying Misinformation from Website Screenshots. (arXiv:2102.07849v1 [cs.LG])</h2>
<h3>Sara Abdali, Rutuja Gurav, Siddharth Menon, Daniel Fonseca, Negin Entezari, Neil Shah, Evangelos E. Papalexakis</h3>
<p>Can the look and the feel of a website give information about the
trustworthiness of an article? In this paper, we propose to use a promising,
yet neglected aspect in detecting the misinformativeness: the overall look of
the domain webpage. To capture this overall look, we take screenshots of news
articles served by either misinformative or trustworthy web domains and
leverage a tensor decomposition based semi-supervised classification technique.
The proposed approach i.e., VizFake is insensitive to a number of image
transformations such as converting the image to grayscale, vectorizing the
image and losing some parts of the screenshots. VizFake leverages a very small
amount of known labels, mirroring realistic and practical scenarios, where
labels (especially for known misinformative articles), are scarce and quickly
become dated. The F1 score of VizFake on a dataset of 50k screenshots of news
articles spanning more than 500 domains is roughly 85% using only 5% of ground
truth labels. Furthermore, tensor representations of VizFake, obtained in an
unsupervised manner, allow for exploratory analysis of the data that provides
valuable insights into the problem. Finally, we compare VizFake with deep
transfer learning, since it is a very popular black-box approach for image
classification and also well-known text text-based methods. VizFake achieves
competitive accuracy with deep transfer learning models while being two orders
of magnitude faster and not requiring laborious hyper-parameter tuning.
</p>
<a href="http://arxiv.org/abs/2102.07849" target="_blank">arXiv:2102.07849</a> [<a href="http://arxiv.org/pdf/2102.07849" target="_blank">pdf</a>]

<h2>Differentiable Particle Filtering via Entropy-Regularized Optimal Transport. (arXiv:2102.07850v1 [stat.ML])</h2>
<h3>Adrien Corenflos, James Thornton, Arnaud Doucet, George Deligiannidis</h3>
<p>Particle Filtering (PF) methods are an established class of procedures for
performing inference in non-linear state-space models. Resampling is a key
ingredient of PF, necessary to obtain low variance likelihood and states
estimates. However, traditional resampling methods result in PF-based loss
functions being non-differentiable with respect to model and PF parameters. In
a variational inference context, resampling also yields high variance gradient
estimates of the PF-based evidence lower bound. By leveraging optimal transport
ideas, we introduce a principled differentiable particle filter and provide
convergence results. We demonstrate this novel method on a variety of
applications.
</p>
<a href="http://arxiv.org/abs/2102.07850" target="_blank">arXiv:2102.07850</a> [<a href="http://arxiv.org/pdf/2102.07850" target="_blank">pdf</a>]

<h2>Don't Just Blame Over-parametrization for Over-confidence: Theoretical Analysis of Calibration in Binary Classification. (arXiv:2102.07856v1 [cs.LG])</h2>
<h3>Yu Bai, Song Mei, Huan Wang, Caiming Xiong</h3>
<p>Modern machine learning models with high accuracy are often miscalibrated --
the predicted top probability does not reflect the actual accuracy, and tends
to be over-confident. It is commonly believed that such over-confidence is
mainly due to over-parametrization, in particular when the model is large
enough to memorize the training data and maximize the confidence.

In this paper, we show theoretically that over-parametrization is not the
only reason for over-confidence. We prove that logistic regression is
inherently over-confident, in the realizable, under-parametrized setting where
the data is generated from the logistic model, and the sample size is much
larger than the number of parameters. Further, this over-confidence happens for
general well-specified binary classification problems as long as the activation
is symmetric and concave on the positive part. Perhaps surprisingly, we also
show that over-confidence is not always the case -- there exists another
activation function (and a suitable loss function) under which the learned
classifier is under-confident at some probability values. Overall, our theory
provides a precise characterization of calibration in realizable binary
classification, which we verify on simulations and real data experiments.
</p>
<a href="http://arxiv.org/abs/2102.07856" target="_blank">arXiv:2102.07856</a> [<a href="http://arxiv.org/pdf/2102.07856" target="_blank">pdf</a>]

<h2>KNH: Multi-View Modeling with K-Nearest Hyperplanes Graph for Misinformation Detection. (arXiv:2102.07857v1 [cs.LG])</h2>
<h3>Sara Abdali, Neil Shah, Evangelos E. Papalexakis</h3>
<p>Graphs are one of the most efficacious structures for representing datapoints
and their relations, and they have been largely exploited for different
applications. Previously, the higher-order relations between the nodes have
been modeled by a generalization of graphs known as hypergraphs. In
hypergraphs, the edges are defined by a set of nodes i.e., hyperedges to
demonstrate the higher order relationships between the data. However, there is
no explicit higher-order generalization for nodes themselves. In this work, we
introduce a novel generalization of graphs i.e., K-Nearest Hyperplanes graph
(KNH) where the nodes are defined by higher order Euclidean subspaces for
multi-view modeling of the nodes. In fact, in KNH, nodes are hyperplanes or
more precisely m-flats instead of datapoints. We experimentally evaluate the
KNH graph on two multi-aspect datasets for misinformation detection. The
experimental results suggest that multi-view modeling of articles using KNH
graph outperforms the classic KNN graph in terms of classification performance.
</p>
<a href="http://arxiv.org/abs/2102.07857" target="_blank">arXiv:2102.07857</a> [<a href="http://arxiv.org/pdf/2102.07857" target="_blank">pdf</a>]

<h2>Low Curvature Activations Reduce Overfitting in Adversarial Training. (arXiv:2102.07861v1 [cs.LG])</h2>
<h3>Vasu Singla, Sahil Singla, David Jacobs, Soheil Feizi</h3>
<p>Adversarial training is one of the most effective defenses against
adversarial attacks. Previous works suggest that overfitting is a dominant
phenomenon in adversarial training leading to a large generalization gap
between test and train accuracy in neural networks. In this work, we show that
the observed generalization gap is closely related to the choice of the
activation function. In particular, we show that using activation functions
with low (exact or approximate) curvature values has a regularization effect
that significantly reduces both the standard and robust generalization gaps in
adversarial training. We observe this effect for both differentiable/smooth
activations such as Swish as well as non-differentiable/non-smooth activations
such as LeakyReLU. In the latter case, the approximate curvature of the
activation is low. Finally, we show that for activation functions with low
curvature, the double descent phenomenon for adversarially trained models does
not occur.
</p>
<a href="http://arxiv.org/abs/2102.07861" target="_blank">arXiv:2102.07861</a> [<a href="http://arxiv.org/pdf/2102.07861" target="_blank">pdf</a>]

<h2>Unified Shapley Framework to Explain Prediction Drift. (arXiv:2102.07862v1 [cs.LG])</h2>
<h3>Aalok Shanbhag, Avijit Ghosh, Josh Rubin</h3>
<p>Predictions are the currency of a machine learning model, and to understand
the model's behavior over segments of a dataset, or over time, is an important
problem in machine learning research and practice. There currently is no
systematic framework to understand this drift in prediction distributions over
time or between two semantically meaningful slices of data, in terms of the
input features and points. We propose GroupShapley and GroupIG (Integrated
Gradients), as axiomatically justified methods to tackle this problem. In doing
so, we re-frame all current feature/data importance measures based on the
Shapley value as essentially problems of distributional comparisons, and unify
them under a common umbrella. We axiomatize certain desirable properties of
distributional difference, and study the implications of choosing them
empirically.
</p>
<a href="http://arxiv.org/abs/2102.07862" target="_blank">arXiv:2102.07862</a> [<a href="http://arxiv.org/pdf/2102.07862" target="_blank">pdf</a>]

<h2>GP-Tree: A Gaussian Process Classifier for Few-Shot Incremental Learning. (arXiv:2102.07868v1 [cs.LG])</h2>
<h3>Idan Achituve, Aviv Navon, Yochai Yemini, Gal Chechik, Ethan Fetaya</h3>
<p>Gaussian processes (GPs) are non-parametric, flexible, models that work well
in many tasks. Combining GPs with deep learning methods via deep kernel
learning is especially compelling due to the strong expressive power induced by
the network. However, inference in GPs, whether with or without deep kernel
learning, can be computationally challenging on large datasets. Here, we
propose GP-Tree, a novel method for multi-class classification with Gaussian
processes and deep kernel learning. We develop a tree-based hierarchical model
in which each internal node of the tree fits a GP to the data using the
Polya-Gamma augmentation scheme. As a result, our method scales well with both
the number of classes and data size. We demonstrate our method effectiveness
against other Gaussian process training baselines, and we show how our general
GP approach is easily applied to incremental few-shot learning and reaches
state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2102.07868" target="_blank">arXiv:2102.07868</a> [<a href="http://arxiv.org/pdf/2102.07868" target="_blank">pdf</a>]

<h2>Momentum Residual Neural Networks. (arXiv:2102.07870v1 [cs.LG])</h2>
<h3>Michael E. Sander, Pierre Ablin, Mathieu Blondel, Gabriel Peyr&#xe9;</h3>
<p>The training of deep residual neural networks (ResNets) with backpropagation
has a memory cost that increases linearly with respect to the depth of the
network. A simple way to circumvent this issue is to use reversible
architectures. In this paper, we propose to change the forward rule of a ResNet
by adding a momentum term. The resulting networks, momentum residual neural
networks (MomentumNets), are invertible. Unlike previous invertible
architectures, they can be used as a drop-in replacement for any existing
ResNet block. We show that MomentumNets can be interpreted in the infinitesimal
step size regime as second-order ordinary differential equations (ODEs) and
exactly characterize how adding momentum progressively increases the
representation capabilities of MomentumNets. Our analysis reveals that
MomentumNets can learn any linear mapping up to a multiplicative factor, while
ResNets cannot. In a learning to optimize setting, where convergence to a fixed
point is required, we show theoretically and empirically that our method
succeeds while existing invertible architectures fail. We show on CIFAR and
ImageNet that MomentumNets have the same accuracy as ResNets, while having a
much smaller memory footprint, and show that pre-trained MomentumNets are
promising for fine-tuning models.
</p>
<a href="http://arxiv.org/abs/2102.07870" target="_blank">arXiv:2102.07870</a> [<a href="http://arxiv.org/pdf/2102.07870" target="_blank">pdf</a>]

<h2>PSA-Net: Deep Learning based Physician Style-Aware Segmentation Network for Post-Operative Prostate Cancer Clinical Target Volume. (arXiv:2102.07880v1 [cs.CV])</h2>
<h3>Anjali Balagopal, Howard Morgan, Michael Dohopoloski, Ramsey Timmerman, Jie Shan, Daniel F. Heitjan, Wei Liu, Dan Nguyen, Raquibul Hannan, Aurelie Garant, Neil Desai, Steve Jiang</h3>
<p>Automatic segmentation of medical images with DL algorithms has proven to be
highly successful. With most of these algorithms, inter-observer variation is
an acknowledged problem, leading to sub-optimal results. This problem is even
more significant in post-operative clinical target volume (post-op CTV)
segmentation due to the absence of macroscopic visual tumor in the image. This
study, using post-op CTV segmentation as the test bed, tries to determine if
physician styles are consistent and learnable, if there is an impact of
physician styles on treatment outcome and toxicity; and how to explicitly deal
with physician styles in DL algorithms to facilitate its clinical acceptance. A
classifier is trained to identify which physician has contoured the CTV from
just the contour and corresponding CT scan, to determine if physician styles
are consistent and learnable. Next, we evaluate if adapting automatic
segmentation to physician styles would be clinically feasible based on a lack
of difference between outcomes. For modeling different physician styles of CTV
segmentation, a concept called physician style-aware (PSA) segmentation is
proposed which is an encoder-multidecoder network trained with perceptual loss.
With the proposed physician style-aware network (PSA-Net), Dice similarity
coefficient (DSC) accuracy increases on an average of 3.4% for all physicians
from a general model that is not style adapted. We show that stylistic
contouring variations also exist between institutions that follow the same
segmentation guidelines and show the effectiveness of the proposed method in
adapting to new institutional styles. We observed an accuracy improvement of 5%
in terms of DSC when adapting to the style of a separate institution.
</p>
<a href="http://arxiv.org/abs/2102.07880" target="_blank">arXiv:2102.07880</a> [<a href="http://arxiv.org/pdf/2102.07880" target="_blank">pdf</a>]

<h2>VA-RED$^2$: Video Adaptive Redundancy Reduction. (arXiv:2102.07887v1 [cs.CV])</h2>
<h3>Bowen Pan, Rameswar Panda, Camilo Fosco, Chung-Ching Lin, Alex Andonian, Yue Meng, Kate Saenko, Aude Oliva, Rogerio Feris</h3>
<p>Performing inference on deep learning models for videos remains a challenge
due to the large amount of computational resources required to achieve robust
recognition. An inherent property of real-world videos is the high correlation
of information across frames which can translate into redundancy in either
temporal or spatial feature maps of the models, or both. The type of redundant
features depends on the dynamics and type of events in the video: static videos
have more temporal redundancy while videos focusing on objects tend to have
more channel redundancy. Here we present a redundancy reduction framework,
termed VA-RED$^2$, which is input-dependent. Specifically, our VA-RED$^2$
framework uses an input-dependent policy to decide how many features need to be
computed for temporal and channel dimensions. To keep the capacity of the
original model, after fully computing the necessary features, we reconstruct
the remaining redundant features from those using cheap linear operations. We
learn the adaptive policy jointly with the network weights in a differentiable
way with a shared-weight mechanism, making it highly efficient. Extensive
experiments on multiple video datasets and different visual tasks show that our
framework achieves $20\% - 40\%$ reduction in computation (FLOPs) when compared
to state-of-the-art methods without any performance loss. Project page:
this http URL
</p>
<a href="http://arxiv.org/abs/2102.07887" target="_blank">arXiv:2102.07887</a> [<a href="http://arxiv.org/pdf/2102.07887" target="_blank">pdf</a>]

<h2>Distributionally-Constrained Policy Optimization via Unbalanced Optimal Transport. (arXiv:2102.07889v1 [cs.LG])</h2>
<h3>Arash Givchi, Pei Wang, Junqi Wang, Patrick Shafto</h3>
<p>We consider constrained policy optimization in Reinforcement Learning, where
the constraints are in form of marginals on state visitations and global action
executions. Given these distributions, we formulate policy optimization as
unbalanced optimal transport over the space of occupancy measures. We propose a
general purpose RL objective based on Bregman divergence and optimize it using
Dykstra's algorithm. The approach admits an actor-critic algorithm for when the
state or action space is large, and only samples from the marginals are
available. We discuss applications of our approach and provide demonstrations
to show the effectiveness of our algorithm.
</p>
<a href="http://arxiv.org/abs/2102.07889" target="_blank">arXiv:2102.07889</a> [<a href="http://arxiv.org/pdf/2102.07889" target="_blank">pdf</a>]

<h2>Improving the Accuracy Of MEPDG Climate Modeling Using Radial Basis Function. (arXiv:2102.07890v1 [cs.LG])</h2>
<h3>Amirehsan Ghasemi, Kelvin J Msechu, Arash Ghasemi, Mbakisya A. Onyango, Ignatius Fomunung, Joseph Owino</h3>
<p>In this paper, the accuracy of two mesh-free approximation approaches, the
Gravity model and Radial Basis Function, are compared. The two schemes'
convergence behaviors prove that RBF is faster and more accurate than the
Gravity model. As a case study, the interpolation of temperature at different
locations in Tennesse, USA, are compared. Delaunay mesh generation is used to
create random points inside and on the border, which data can be incorporated
in these locations. 49 MERRA weather stations as used as data sources to
provide the temperature at a specific day and hour. The contours of
interpolated temperatures provided in the result section assert RBF is a more
accurate method than the Gravity model by showing a smoother and broader range
of interpolated data.
</p>
<a href="http://arxiv.org/abs/2102.07890" target="_blank">arXiv:2102.07890</a> [<a href="http://arxiv.org/pdf/2102.07890" target="_blank">pdf</a>]

<h2>Engineering Education in the Age of Autonomous Machines. (arXiv:2102.07900v1 [cs.AI])</h2>
<h3>Shaoshan Liu, Jean-Luc Gaudiot, Hironori Kasahara</h3>
<p>In the past few years, we have observed a huge supply-demand gap for
autonomous driving engineers. The core problem is that autonomous driving is
not one single technology but rather a complex system integrating many
technologies, and no one single academic department can provide comprehensive
education in this field. We advocate to create a cross-disciplinary program to
expose students with technical background in computer science, computer
engineering, electrical engineering, as well as mechanical engineering. On top
of the cross-disciplinary technical foundation, a capstone project that
provides students with hands-on experiences of working with a real autonomous
vehicle is required to consolidate the technical foundation.
</p>
<a href="http://arxiv.org/abs/2102.07900" target="_blank">arXiv:2102.07900</a> [<a href="http://arxiv.org/pdf/2102.07900" target="_blank">pdf</a>]

<h2>MITNet: GAN Enhanced Magnetic Induction Tomography Based on Complex CNN. (arXiv:2102.07911v1 [cs.CV])</h2>
<h3>Zuohui Chen, Qing Yuan, Xujie Song, Cheng Chen, Dan Zhang, Yun Xiang, Ruigang Liu, Qi Xuan</h3>
<p>Magnetic induction tomography (MIT) is an efficient solution for long-term
brain disease monitoring, which focuses on reconstructing bio-impedance
distribution inside the human brain using non-intrusive electromagnetic fields.
However, high-quality brain image reconstruction remains challenging since
reconstructing images from the measured weak signals is a highly non-linear and
ill-conditioned problem. In this work, we propose a generative adversarial
network (GAN) enhanced MIT technique, named MITNet, based on a complex
convolutional neural network (CNN). The experimental results on the real-world
dataset validate the performance of our technique, which outperforms the
state-of-art method by 25.27%.
</p>
<a href="http://arxiv.org/abs/2102.07911" target="_blank">arXiv:2102.07911</a> [<a href="http://arxiv.org/pdf/2102.07911" target="_blank">pdf</a>]

<h2>Few-Shot Graph Learning for Molecular Property Prediction. (arXiv:2102.07916v1 [cs.LG])</h2>
<h3>Zhichun Guo, Chuxu Zhang, Wenhao Yu, John Herr, Olaf Wiest, Meng Jiang, Nitesh V. Chawla</h3>
<p>The recent success of graph neural networks has significantly boosted
molecular property prediction, advancing activities such as drug discovery. The
existing deep neural network methods usually require large training dataset for
each property, impairing their performances in cases (especially for new
molecular properties) with a limited amount of experimental data, which are
common in real situations. To this end, we propose Meta-MGNN, a novel model for
few-shot molecular property prediction. Meta-MGNN applies molecular graph
neural network to learn molecular representation and builds a meta-learning
framework for model optimization. To exploit unlabeled molecular information
and address task heterogeneity of different molecular properties, Meta-MGNN
further incorporates molecular structure, attribute based self-supervised
modules and self-attentive task weights into the former framework,
strengthening the whole learning model. Extensive experiments on two public
multi-property datasets demonstrate that Meta-MGNN outperforms a variety of
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.07916" target="_blank">arXiv:2102.07916</a> [<a href="http://arxiv.org/pdf/2102.07916" target="_blank">pdf</a>]

<h2>Information Ranking Using Optimum-Path Forest. (arXiv:2102.07917v1 [cs.AI])</h2>
<h3>Nathalia Q. Ascen&#xe7;&#xe3;o, Luis C. S. Afonso, Danilo Colombo, Luciano Oliveira, Jo&#xe3;o P. Papa</h3>
<p>The task of learning to rank has been widely studied by the machine learning
community, mainly due to its use and great importance in information retrieval,
data mining, and natural language processing. Therefore, ranking accurately and
learning to rank are crucial tasks. Context-Based Information Retrieval systems
have been of great importance to reduce the effort of finding relevant data.
Such systems have evolved by using machine learning techniques to improve their
results, but they are mainly dependent on user feedback. Although information
retrieval has been addressed in different works along with classifiers based on
Optimum-Path Forest (OPF), these have so far not been applied to the learning
to rank task. Therefore, the main contribution of this work is to evaluate
classifiers based on Optimum-Path Forest, in such a context. Experiments were
performed considering the image retrieval and ranking scenarios, and the
performance of OPF-based approaches was compared to the well-known SVM-Rank
pairwise technique and a baseline based on distance calculation. The
experiments showed competitive results concerning precision and outperformed
traditional techniques in terms of computational load.
</p>
<a href="http://arxiv.org/abs/2102.07917" target="_blank">arXiv:2102.07917</a> [<a href="http://arxiv.org/pdf/2102.07917" target="_blank">pdf</a>]

<h2>Training Larger Networks for Deep Reinforcement Learning. (arXiv:2102.07920v1 [cs.LG])</h2>
<h3>Kei Ota, Devesh K. Jha, Asako Kanezaki</h3>
<p>The success of deep learning in the computer vision and natural language
processing communities can be attributed to training of very deep neural
networks with millions or billions of parameters which can then be trained with
massive amounts of data. However, similar trend has largely eluded training of
deep reinforcement learning (RL) algorithms where larger networks do not lead
to performance improvement. Previous work has shown that this is mostly due to
instability during training of deep RL agents when using larger networks. In
this paper, we make an attempt to understand and address training of larger
networks for deep RL. We first show that naively increasing network capacity
does not improve performance. Then, we propose a novel method that consists of
1) wider networks with DenseNet connection, 2) decoupling representation
learning from training of RL, 3) a distributed training method to mitigate
overfitting problems. Using this three-fold technique, we show that we can
train very large networks that result in significant performance gains. We
present several ablation studies to demonstrate the efficacy of the proposed
method and some intuitive understanding of the reasons for performance gain. We
show that our proposed method outperforms other baseline algorithms on several
challenging locomotion tasks.
</p>
<a href="http://arxiv.org/abs/2102.07920" target="_blank">arXiv:2102.07920</a> [<a href="http://arxiv.org/pdf/2102.07920" target="_blank">pdf</a>]

<h2>Darboux-Frame-Based Parametrization for a Spin-Rolling Sphere on a Plane: A Nonlinear Transformation of Underactuated System to Fully-Actuated Model. (arXiv:2102.07923v1 [cs.RO])</h2>
<h3>Seyed Amir Tafrishi, Mikhail Svinin, Motoji Yamamoto</h3>
<p>This paper presents a new kinematic model based on the Darboux-frame for
motion control and planning. In this work, we show that an underactuated system
as a spin-rolling sphere on a plane with three inputs and five states can be
transformed into a fully-actuated model by the given Darboux-frame
transformation. This nonlinear state transformation is a geometric model that
is different from conventional state-space models. First, a kinematic model of
the Darboux frame at the contact point of a rotating object i.e., the sphere,
is established. Next, we propose a virtual surface that is trapped between
sphere and plane surfaces. This virtual surface generates arc-length-based
inputs for controlling the trajectories on the sphere and plane. Finally, we
discuss the controllability of this new system after our introduced
transformation. In the future, we will design a proper geometric path planning
method for the obtained kinematic model.
</p>
<a href="http://arxiv.org/abs/2102.07923" target="_blank">arXiv:2102.07923</a> [<a href="http://arxiv.org/pdf/2102.07923" target="_blank">pdf</a>]

<h2>Reciprocal Distance Transform Maps for Crowd Counting and People Localization in Dense Crowd. (arXiv:2102.07925v1 [cs.CV])</h2>
<h3>Dingkang Liang, Wei Xu, Yingying Zhu, Yu Zhou</h3>
<p>In this paper, we propose a novel map for dense crowd counting and people
localization. Most crowd counting methods utilize convolution neural networks
(CNN) to regress a density map, achieving significant progress recently.
However, these regression-based methods are often unable to provide a precise
location for each people, attributed to two crucial reasons: 1) the density map
consists of a series of blurry Gaussian blobs, 2) severe overlaps exist in the
dense region of the density map. To tackle this issue, we propose a novel
Reciprocal Distance Transform (R-DT) map for crowd counting. Compared with the
density maps, the R-DT maps accurately describe the people location, without
overlap between nearby heads in dense regions. We simultaneously implement
crowd counting and people localization with a simple network by replacing
density maps with R-DT maps. Extensive experiments demonstrate that the
proposed method outperforms state-of-the-art localization-based methods in
crowd counting and people localization tasks, achieving very competitive
performance compared with the regression-based methods in counting tasks. In
addition, the proposed method achieves a good generalization performance under
cross dataset validation, which further verifies the effectiveness of the R-DT
map. The code and models are available at https://github.com/dk-liang/RDTM.
</p>
<a href="http://arxiv.org/abs/2102.07925" target="_blank">arXiv:2102.07925</a> [<a href="http://arxiv.org/pdf/2102.07925" target="_blank">pdf</a>]

<h2>Improving Bayesian Inference in Deep Neural Networks with Variational Structured Dropout. (arXiv:2102.07927v1 [cs.LG])</h2>
<h3>Son Nguyen, Duong Nguyen, Khai Nguyen, Nhat Ho, Khoat Than, Hung Bui</h3>
<p>Approximate inference in deep Bayesian networks exhibits a dilemma of how to
yield high fidelity posterior approximations while maintaining computational
efficiency and scalability. We tackle this challenge by introducing a new
variational structured approximation inspired by the interpretation of Dropout
training as approximate inference in Bayesian probabilistic models. Concretely,
we focus on restrictions of the factorized structure of Dropout posterior which
is inflexible to capture rich correlations among weight parameters of the true
posterior, and we then propose a novel method called Variational Structured
Dropout (VSD) to overcome this limitation. VSD employs an orthogonal
transformation to learn a structured representation on the variational Dropout
noise and consequently induces statistical dependencies in the approximate
posterior. We further gain expressive Bayesian modeling for VSD via proposing a
hierarchical Dropout procedure that corresponds to the joint inference in a
Bayesian network. Moreover, we can scale up VSD to modern deep convolutional
networks in a direct way with a low computational cost. Finally, we conduct
extensive experiments on standard benchmarks to demonstrate the effectiveness
of VSD over state-of-the-art methods on both predictive accuracy and
uncertainty estimation.
</p>
<a href="http://arxiv.org/abs/2102.07927" target="_blank">arXiv:2102.07927</a> [<a href="http://arxiv.org/pdf/2102.07927" target="_blank">pdf</a>]

<h2>Optimal Algorithms for Private Online Learning in a Stochastic Environment. (arXiv:2102.07929v1 [cs.LG])</h2>
<h3>Bingshan Hu, Zhiming Huang, Nishant A. Mehta</h3>
<p>We consider two variants of private stochastic online learning. The first
variant is differentially private stochastic bandits. Previously, Sajed and
Sheffet (2019) devised the DP Successive Elimination (DP-SE) algorithm that
achieves the optimal $ O \biggl(\sum\limits_{1\le j \le K: \Delta_j &gt;0} \frac{
\log T}{ \Delta_j} + \frac{ K\log T}{\epsilon} \biggr)$ problem-dependent
regret bound, where $K$ is the number of arms, $\Delta_j$ is the mean reward
gap of arm $j$, $T$ is the time horizon, and $\epsilon$ is the required privacy
parameter. However, like other elimination style algorithms, it is not an
anytime algorithm. Until now, it was not known whether UCB-based algorithms
could achieve this optimal regret bound. We present an anytime, UCB-based
algorithm that achieves optimality. Our experiments show that the UCB-based
algorithm is competitive with DP-SE. The second variant is the full information
version of private stochastic online learning. Specifically, for the problems
of decision-theoretic online learning with stochastic rewards, we present the
first algorithm that achieves an $ O \left( \frac{ \log K}{ \Delta_{\min}} +
\frac{ \log K}{\epsilon} \right)$ regret bound, where $\Delta_{\min}$ is the
minimum mean reward gap. The key idea behind our good theoretical guarantees in
both settings is the forgetfulness, i.e., decisions are made based on a certain
amount of newly obtained observations instead of all the observations obtained
from the very beginning.
</p>
<a href="http://arxiv.org/abs/2102.07929" target="_blank">arXiv:2102.07929</a> [<a href="http://arxiv.org/pdf/2102.07929" target="_blank">pdf</a>]

<h2>GraphGallery: A Platform for Fast Benchmarking and Easy Development of Graph Neural Networks Based Intelligent Software. (arXiv:2102.07933v1 [cs.AI])</h2>
<h3>Jintang Li, Kun Xu, Liang Chen, Zibin Zheng, Xiao Liu</h3>
<p>Graph Neural Networks (GNNs) have recently shown to be powerful tools for
representing and analyzing graph data. So far GNNs is becoming an increasingly
critical role in software engineering including program analysis, type
inference, and code representation. In this paper, we introduce GraphGallery, a
platform for fast benchmarking and easy development of GNNs based software.
GraphGallery is an easy-to-use platform that allows developers to automatically
deploy GNNs even with less domain-specific knowledge. It offers a set of
implementations of common GNN models based on mainstream deep learning
frameworks. In addition, existing GNNs toolboxes such as PyG and DGL can be
easily incorporated into the platform. Experiments demonstrate the reliability
of implementations and superiority in fast coding. The official source code of
GraphGallery is available at https://github.com/EdisonLeeeee/GraphGallery and a
demo video can be found at https://youtu.be/mv7Zs1YeaYo.
</p>
<a href="http://arxiv.org/abs/2102.07933" target="_blank">arXiv:2102.07933</a> [<a href="http://arxiv.org/pdf/2102.07933" target="_blank">pdf</a>]

<h2>Inverse Reinforcement Learning in the Continuous Setting with Formal Guarantees. (arXiv:2102.07937v1 [cs.LG])</h2>
<h3>Gregory Dexter, Kevin Bello, Jean Honorio</h3>
<p>Inverse Reinforcement Learning (IRL) is the problem of finding a reward
function which describes observed/known expert behavior. IRL is useful for
automated control in situations where the reward function is difficult to
specify manually, which impedes reinforcement learning. We provide a new IRL
algorithm for the continuous state space setting with unknown transition
dynamics by modeling the system using a basis of orthonormal functions. We
provide a proof of correctness and formal guarantees on the sample and time
complexity of our algorithm.
</p>
<a href="http://arxiv.org/abs/2102.07937" target="_blank">arXiv:2102.07937</a> [<a href="http://arxiv.org/pdf/2102.07937" target="_blank">pdf</a>]

<h2>Structured Graph Learning for Scalable Subspace Clustering: From Single-view to Multi-view. (arXiv:2102.07943v1 [cs.LG])</h2>
<h3>Zhao Kang, Zhiping Lin, Xiaofeng Zhu, Wenbo Xu</h3>
<p>Graph-based subspace clustering methods have exhibited promising performance.
However, they still suffer some of these drawbacks: encounter the expensive
time overhead, fail in exploring the explicit clusters, and cannot generalize
to unseen data points. In this work, we propose a scalable graph learning
framework, seeking to address the above three challenges simultaneously.
Specifically, it is based on the ideas of anchor points and bipartite graph.
Rather than building a $n\times n$ graph, where $n$ is the number of samples,
we construct a bipartite graph to depict the relationship between samples and
anchor points. Meanwhile, a connectivity constraint is employed to ensure that
the connected components indicate clusters directly. We further establish the
connection between our method and the K-means clustering. Moreover, a model to
process multi-view data is also proposed, which is linear scaled with respect
to $n$. Extensive experiments demonstrate the efficiency and effectiveness of
our approach with respect to many state-of-the-art clustering methods.
</p>
<a href="http://arxiv.org/abs/2102.07943" target="_blank">arXiv:2102.07943</a> [<a href="http://arxiv.org/pdf/2102.07943" target="_blank">pdf</a>]

<h2>Local Hyper-flow Diffusion. (arXiv:2102.07945v1 [cs.LG])</h2>
<h3>Kimon Fountoulakis, Pan Li, Shenghao Yang</h3>
<p>A plethora of real-world problems require utilization of hypergraphs and
diffusion algorithms. Examples include recommendation systems, node ranking in
food networks and community detection in social networks to mention a few. Due
to the increased size and complexity of real hypergraphs, local and accurate
diffusion algorithms that work with the most complex hypergraphs are in need.
We propose the first local diffusion method that works on higher-order
relations with only a submodularity assumption. Our method is based on a
primal-dual optimization formulation where the primal problem has a natural
network flow interpretation, and the dual problem has a cut-based
interpretation using the $\ell_2$-norm penalty for general submodular
cut-costs. We prove that the proposed formulation achieves quadratic
approximation error for the problem of local hypergraph clustering. We
demonstrate that the new technique is significantly better than
state-of-the-art methods over a range of real datasets for the local hypergraph
clustering and node ranking problems.
</p>
<a href="http://arxiv.org/abs/2102.07945" target="_blank">arXiv:2102.07945</a> [<a href="http://arxiv.org/pdf/2102.07945" target="_blank">pdf</a>]

<h2>ResNet-LDDMM: Advancing the LDDMM Framework Using Deep Residual Networks. (arXiv:2102.07951v1 [cs.AI])</h2>
<h3>Boulbaba Ben Amor, Sylvain Arguill&#xe8;re, Ling Shao</h3>
<p>In deformable registration, the geometric framework - large deformation
diffeomorphic metric mapping or LDDMM, in short - has inspired numerous
techniques for comparing, deforming, averaging and analyzing shapes or images.
Grounded in flows, which are akin to the equations of motion used in fluid
dynamics, LDDMM algorithms solve the flow equation in the space of plausible
deformations, i.e. diffeomorphisms. In this work, we make use of deep residual
neural networks to solve the non-stationary ODE (flow equation) based on a
Euler's discretization scheme. The central idea is to represent time-dependent
velocity fields as fully connected ReLU neural networks (building blocks) and
derive optimal weights by minimizing a regularized loss function. Computing
minimizing paths between deformations, thus between shapes, turns to find
optimal network parameters by back-propagating over the intermediate building
blocks. Geometrically, at each time step, ResNet-LDDMM searches for an optimal
partition of the space into multiple polytopes, and then computes optimal
velocity vectors as affine transformations on each of these polytopes. As a
result, different parts of the shape, even if they are close (such as two
fingers of a hand), can be made to belong to different polytopes, and therefore
be moved in different directions without costing too much energy. Importantly,
we show how diffeomorphic transformations, or more precisely bilipshitz
transformations, are predicted by our algorithm. We illustrate these ideas on
diverse registration problems of 3D shapes under complex topology-preserving
transformations. We thus provide essential foundations for more advanced shape
variability analysis under a novel joint geometric-neural networks
Riemannian-like framework, i.e. ResNet-LDDMM.
</p>
<a href="http://arxiv.org/abs/2102.07951" target="_blank">arXiv:2102.07951</a> [<a href="http://arxiv.org/pdf/2102.07951" target="_blank">pdf</a>]

<h2>A Survey of Machine Learning for Computer Architecture and Systems. (arXiv:2102.07952v1 [cs.LG])</h2>
<h3>Nan Wu, Yuan Xie</h3>
<p>It has been a long time that computer architecture and systems are optimized
to enable efficient execution of machine learning (ML) algorithms or models.
Now, it is time to reconsider the relationship between ML and systems, and let
ML transform the way that computer architecture and systems are designed. This
embraces a twofold meaning: the improvement of designers' productivity, and the
completion of the virtuous cycle. In this paper, we present a comprehensive
review of work that applies ML for system design, which can be grouped into two
major categories, ML-based modelling that involves predictions of performance
metrics or some other criteria of interest, and ML-based design methodology
that directly leverages ML as the design tool. For ML-based modelling, we
discuss existing studies based on their target level of system, ranging from
the circuit level to the architecture/system level. For ML-based design
methodology, we follow a bottom-up path to review current work, with a scope of
(micro-)architecture design (memory, branch prediction, NoC), coordination
between architecture/system and workload (resource allocation and management,
data center management, and security), compiler, and design automation. We
further provide a future vision of opportunities and potential directions, and
envision that applying ML for computer architecture and systems would thrive in
the community.
</p>
<a href="http://arxiv.org/abs/2102.07952" target="_blank">arXiv:2102.07952</a> [<a href="http://arxiv.org/pdf/2102.07952" target="_blank">pdf</a>]

<h2>AlphaNet: Improved Training of Supernet with Alpha-Divergence. (arXiv:2102.07954v1 [cs.CV])</h2>
<h3>Dilin Wang, Chengyue Gong, Meng Li, Qiang Liu, Vikas Chandra</h3>
<p>Weight-sharing neural architecture search (NAS) is an effective technique for
automating efficient neural architecture design. Weight-sharing NAS builds a
supernet that assembles all the architectures as its sub-networks and jointly
trains the supernet with the sub-networks. The success of weight-sharing NAS
heavily relies on distilling the knowledge of the supernet to the sub-networks.
However, we find that the widely used distillation divergence, i.e., KL
divergence, may lead to student sub-networks that over-estimate or
under-estimate the uncertainty of the teacher supernet, leading to inferior
performance of the sub-networks. In this work, we propose to improve the
supernet training with a more generalized alpha-divergence. By adaptively
selecting the alpha-divergence, we simultaneously prevent the over-estimation
or under-estimation of the uncertainty of the teacher model. We apply the
proposed alpha-divergence based supernet training to both slimmable neural
networks and weight-sharing NAS, and demonstrate significant improvements.
Specifically, our discovered model family, AlphaNet, outperforms prior-art
models on a wide range of FLOPs regimes, including BigNAS, Once-for-All
networks, FBNetV3, and AttentiveNAS. We achieve ImageNet top-1 accuracy of
80.0% with only 444 MFLOPs.
</p>
<a href="http://arxiv.org/abs/2102.07954" target="_blank">arXiv:2102.07954</a> [<a href="http://arxiv.org/pdf/2102.07954" target="_blank">pdf</a>]

<h2>Music Harmony Generation, through Deep Learning and Using a Multi-Objective Evolutionary Algorithm. (arXiv:2102.07960v1 [cs.AI])</h2>
<h3>Maryam Majidi, Rahil Mahdian Toroghi</h3>
<p>Automatic music generation has become an epicenter research topic for many
scientists in artificial intelligence, who are also interested in the music
industry. Being a balanced combination of math and art, music in collaboration
with A.I. can simplify the generation process for new musical pieces, and ease
the interpretation of it to a tangible level. On the other hand, the artistic
nature of music and its mingling with the senses and feelings of the composer
makes the artificial generation and mathematical modeling of it infeasible. In
fact, there are no clear evaluation measures that can combine the objective
music grammar and structure with the subjective audience satisfaction goal.
Also, original music contains different elements that it is inevitable to put
together. Therefore, in this paper, a method based on a genetic multi-objective
evolutionary optimization algorithm for the generation of polyphonic music
(melody with rhythm and harmony or appropriate chords) is introduced in which
three specific goals determine the qualifications of the music generated. One
of the goals is the rules and regulations of music, which, along with the other
two goals, including the scores of music experts and ordinary listeners, fits
the cycle of evolution to get the most optimal response. The scoring of experts
and listeners separately is modeled using a Bi-LSTM neural network and has been
incorporated in the fitness function of the algorithm. The results show that
the proposed method is able to generate difficult and pleasant pieces with
desired styles and lengths, along with harmonic sounds that follow the grammar
while attracting the listener, at the same time.
</p>
<a href="http://arxiv.org/abs/2102.07960" target="_blank">arXiv:2102.07960</a> [<a href="http://arxiv.org/pdf/2102.07960" target="_blank">pdf</a>]

<h2>Multi-Attribute Enhancement Network for Person Search. (arXiv:2102.07968v1 [cs.CV])</h2>
<h3>Lequan Chen, Wei Xie, Zhigang Tu, Yaping Tao, Xinming Wang</h3>
<p>Person Search is designed to jointly solve the problems of Person Detection
and Person Re-identification (Re-ID), in which the target person will be
located in a large number of uncut images. Over the past few years, Person
Search based on deep learning has made great progress. Visual character
attributes play a key role in retrieving the query person, which has been
explored in Re-ID but has been ignored in Person Search. So, we introduce
attribute learning into the model, allowing the use of attribute features for
retrieval task. Specifically, we propose a simple and effective model called
Multi-Attribute Enhancement (MAE) which introduces attribute tags to learn
local features. In addition to learning the global representation of
pedestrians, it also learns the local representation, and combines the two
aspects to learn robust features to promote the search performance.
Additionally, we verify the effectiveness of our module on the existing
benchmark dataset, CUHK-SYSU and PRW. Ultimately, our model achieves
state-of-the-art among end-to-end methods, especially reaching 91.8% of mAP and
93.0% of rank-1 on CUHK-SYSU. Codes and models are available at
https://github.com/chenlq123/MAE.
</p>
<a href="http://arxiv.org/abs/2102.07968" target="_blank">arXiv:2102.07968</a> [<a href="http://arxiv.org/pdf/2102.07968" target="_blank">pdf</a>]

<h2>Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation. (arXiv:2102.07970v1 [cs.LG])</h2>
<h3>Justin Fu, Sergey Levine</h3>
<p>In this work we consider data-driven optimization problems where one must
maximize a function given only queries at a fixed set of points. This problem
setting emerges in many domains where function evaluation is a complex and
expensive process, such as in the design of materials, vehicles, or neural
network architectures. Because the available data typically only covers a small
manifold of the possible space of inputs, a principal challenge is to be able
to construct algorithms that can reason about uncertainty and
out-of-distribution values, since a naive optimizer can easily exploit an
estimated model to return adversarial inputs. We propose to tackle this problem
by leveraging the normalized maximum-likelihood (NML) estimator, which provides
a principled approach to handling uncertainty and out-of-distribution inputs.
While in the standard formulation NML is intractable, we propose a tractable
approximation that allows us to scale our method to high-capacity neural
network models. We demonstrate that our method can effectively optimize
high-dimensional design problems in a variety of disciplines such as chemistry,
biology, and materials engineering.
</p>
<a href="http://arxiv.org/abs/2102.07970" target="_blank">arXiv:2102.07970</a> [<a href="http://arxiv.org/pdf/2102.07970" target="_blank">pdf</a>]

<h2>A Sub-band Approach to Deep Denoising Wavelet Networks and a Frequency-adaptive Loss for Perceptual Quality. (arXiv:2102.07973v1 [cs.LG])</h2>
<h3>Caglar Aytekin, Sakari Alenius, Dmytro Paliy, Juuso Gren</h3>
<p>In this paper, we propose two contributions to neural network based
denoising. First, we propose applying separate convolutional layers to each
sub-band of discrete wavelet transform (DWT) as opposed to the common usage of
DWT which concatenates all sub-bands and applies a single convolution layer. We
show that our approach to using DWT in neural networks improves the accuracy
notably, due to keeping the sub-band order uncorrupted prior to inverse DWT.
Our second contribution is a denoising loss based on top k-percent of errors in
frequency domain. A neural network trained with this loss, adaptively focuses
on frequencies that it fails to recover the most in each iteration. We show
that this loss results into better perceptual quality by providing an image
that is more balanced in terms of the errors in frequency components.
</p>
<a href="http://arxiv.org/abs/2102.07973" target="_blank">arXiv:2102.07973</a> [<a href="http://arxiv.org/pdf/2102.07973" target="_blank">pdf</a>]

<h2>Twin Augmented Architectures for Robust Classification of COVID-19 Chest X-Ray Images. (arXiv:2102.07975v1 [cs.CV])</h2>
<h3>Kartikeya Badola, Sameer Ambekar, Himanshu Pant, Sumit Soman, Anuradha Sural, Rajiv Narang, Suresh Chandra, Jayadeva</h3>
<p>The gold standard for COVID-19 is RT-PCR, testing facilities for which are
limited and not always optimally distributed. Test results are delayed, which
impacts treatment. Expert radiologists, one of whom is a co-author, are able to
diagnose COVID-19 positivity from Chest X-Rays (CXR) and CT scans, that can
facilitate timely treatment. Such diagnosis is particularly valuable in
locations lacking radiologists with sufficient expertise and familiarity with
COVID-19 patients. This paper has two contributions. One, we analyse literature
on CXR based COVID-19 diagnosis. We show that popular choices of dataset
selection suffer from data homogeneity, leading to misleading results. We
compile and analyse a viable benchmark dataset from multiple existing
heterogeneous sources. Such a benchmark is important for realistically testing
models. Our second contribution relates to learning from imbalanced data.
Datasets for COVID X-Ray classification face severe class imbalance, since most
subjects are COVID -ve. Twin Support Vector Machines (Twin SVM) and Twin Neural
Networks (Twin NN) have, in recent years, emerged as effective ways of handling
skewed data. We introduce a state-of-the-art technique, termed as Twin
Augmentation, for modifying popular pre-trained deep learning models. Twin
Augmentation boosts the performance of a pre-trained deep neural network
without requiring re-training. Experiments show, that across a multitude of
classifiers, Twin Augmentation is very effective in boosting the performance of
given pre-trained model for classification in imbalanced settings.
</p>
<a href="http://arxiv.org/abs/2102.07975" target="_blank">arXiv:2102.07975</a> [<a href="http://arxiv.org/pdf/2102.07975" target="_blank">pdf</a>]

<h2>A Generic Descent Aggregation Framework for Gradient-based Bi-level Optimization. (arXiv:2102.07976v1 [cs.LG])</h2>
<h3>Risheng Liu, Pan Mu, Xiaoming Yuan, Shangzhi Zeng, Jin Zhang</h3>
<p>In recent years, gradient-based methods for solving bi-level optimization
tasks have drawn a great deal of interest from the machine learning community.
However, to calculate the gradient of the best response, existing research
always relies on the singleton of the lower-level solution set (a.k.a.,
Lower-Level Singleton, LLS). In this work, by formulating bi-level models from
an optimistic bi-level viewpoint, we first establish a novel Bi-level Descent
Aggregation (BDA) framework, which aggregates hierarchical objectives of both
upper level and lower level. The flexibility of our framework benefits from the
embedded replaceable task-tailored iteration dynamics modules, thereby
capturing a wide range of bi-level learning tasks. Theoretically, we derive a
new methodology to prove the convergence of BDA framework without the LLS
restriction. Besides, the new proof recipe we propose is also engaged to
improve the convergence results of conventional gradient-based bi-level methods
under the LLS simplification. Furthermore, we employ a one-stage technique to
accelerate the back-propagation calculation in a numerical manner. Extensive
experiments justify our theoretical results and demonstrate the superiority of
the proposed algorithm for hyper-parameter optimization and meta-learning
tasks.
</p>
<a href="http://arxiv.org/abs/2102.07976" target="_blank">arXiv:2102.07976</a> [<a href="http://arxiv.org/pdf/2102.07976" target="_blank">pdf</a>]

<h2>A Benchmark of Ocular Disease Intelligent Recognition: One Shot for Multi-disease Detection. (arXiv:2102.07978v1 [cs.CV])</h2>
<h3>Ning Li, Tao Li, Chunyu Hu, Kai Wang, Hong Kang</h3>
<p>In ophthalmology, early fundus screening is an economic and effective way to
prevent blindness caused by ophthalmic diseases. Clinically, due to the lack of
medical resources, manual diagnosis is time-consuming and may delay the
condition. With the development of deep learning, some researches on ophthalmic
diseases have achieved good results, however, most of them are just based on
one disease. During fundus screening, ophthalmologists usually give diagnoses
of multi-disease on binocular fundus image, so we release a dataset with 8
diseases to meet the real medical scene, which contains 10,000 fundus images
from both eyes of 5,000 patients. We did some benchmark experiments on it
through some state-of-the-art deep neural networks. We found simply increasing
the scale of network cannot bring good results for multi-disease
classification, and a well-structured feature fusion method combines
characteristics of multi-disease is needed. Through this work, we hope to
advance the research of related fields.
</p>
<a href="http://arxiv.org/abs/2102.07978" target="_blank">arXiv:2102.07978</a> [<a href="http://arxiv.org/pdf/2102.07978" target="_blank">pdf</a>]

<h2>SiMaN: Sign-to-Magnitude Network Binarization. (arXiv:2102.07981v1 [cs.CV])</h2>
<h3>Mingbao Lin, Rongrong Ji, Zihan Xu, Baochang Zhang, Fei Chao, Mingliang Xu, Chia-Wen Lin, Ling Shao</h3>
<p>Binary neural networks (BNNs) have attracted broad research interest due to
their efficient storage and computational ability. Nevertheless, a significant
challenge of BNNs lies in handling discrete constraints while ensuring bit
entropy maximization, which typically makes their weight optimization very
difficult. Existing methods relax the learning using the sign function, which
simply encodes positive weights into +1s, and -1s otherwise. Alternatively, we
formulate an angle alignment objective to constrain the weight binarization to
{0,+1} to solve the challenge. In this paper, we show that our weight
binarization provides an analytical solution by encoding high-magnitude weights
into +1s, and 0s otherwise. Therefore, a high-quality discrete solution is
established in a computationally efficient manner without the sign function. We
prove that the learned weights of binarized networks roughly follow a Laplacian
distribution that does not allow entropy maximization, and further demonstrate
that it can be effectively solved by simply removing the $\ell_2$
regularization during network training. Our method, dubbed sign-to-magnitude
network binarization (SiMaN), is evaluated on CIFAR-10 and ImageNet,
demonstrating its superiority over the sign-based state-of-the-arts. Code is at
https://github.com/lmbxmu/SiMaN.
</p>
<a href="http://arxiv.org/abs/2102.07981" target="_blank">arXiv:2102.07981</a> [<a href="http://arxiv.org/pdf/2102.07981" target="_blank">pdf</a>]

<h2>The Randomized Elliptical Potential Lemma with an Application to Linear Thompson Sampling. (arXiv:2102.07987v1 [stat.ML])</h2>
<h3>Nima Hamidi, Mohsen Bayati</h3>
<p>In this note, we introduce a randomized version of the well-known elliptical
potential lemma that is widely used in the analysis of algorithms in sequential
learning and decision-making problems such as stochastic linear bandits. Our
randomized elliptical potential lemma relaxes the Gaussian assumption on the
observation noise and on the prior distribution of the problem parameters. We
then use this generalization to prove an improved Bayesian regret bound for
Thompson sampling for the linear stochastic bandits with changing action sets
where prior and noise distributions are general. This bound is minimax optimal
up to constants.
</p>
<a href="http://arxiv.org/abs/2102.07987" target="_blank">arXiv:2102.07987</a> [<a href="http://arxiv.org/pdf/2102.07987" target="_blank">pdf</a>]

<h2>TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models. (arXiv:2102.07988v1 [cs.LG])</h2>
<h3>Zhuohan Li, Siyuan Zhuang, Shiyuan Guo, Danyang Zhuo, Hao Zhang, Dawn Song, Ion Stoica</h3>
<p>Model parallelism has become a necessity for training modern large-scale deep
language models. In this work, we identify a new and orthogonal dimension from
existing model parallel approaches: it is possible to perform pipeline
parallelism within a single training sequence for Transformer-based language
models thanks to its autoregressive property. This enables a more fine-grained
pipeline compared with previous work. With this key idea, we design TeraPipe, a
high-performance token-level pipeline parallel algorithm for synchronous
model-parallel training of Transformer-based language models. We develop a
novel dynamic programming-based algorithm to calculate the optimal pipelining
execution scheme given a specific model and cluster configuration. We show that
TeraPipe can speed up the training by 5.0x for the largest GPT-3 model with 175
billion parameters on an AWS cluster with 48 p3.16xlarge instances compared
with state-of-the-art model-parallel methods.
</p>
<a href="http://arxiv.org/abs/2102.07988" target="_blank">arXiv:2102.07988</a> [<a href="http://arxiv.org/pdf/2102.07988" target="_blank">pdf</a>]

<h2>LEAD: LiDAR Extender for Autonomous Driving. (arXiv:2102.07989v1 [cs.CV])</h2>
<h3>Jianing Zhang, Wei Li, Honggang Gou, Lu Fang, Ruigang Yang</h3>
<p>3D perception using sensors under vehicle industrial standard is the rigid
demand in autonomous driving. MEMS LiDAR emerges with irresistible trend due to
its lower cost, more robust, and meeting the mass-production standards.
However, it suffers small field of view (FoV), slowing down the step of its
population. In this paper, we propose LEAD, i.e., LiDAR Extender for Autonomous
Driving, to extend the MEMS LiDAR by coupled image w.r.t both FoV and range. We
propose a multi-stage propagation strategy based on depth distributions and
uncertainty map, which shows effective propagation ability. Moreover, our depth
outpainting/propagation network follows a teacher-student training fashion,
which transfers depth estimation ability to depth completion network without
any scale error passed. To validate the LiDAR extension quality, we utilize a
high-precise laser scanner to generate a ground-truth dataset. Quantitative and
qualitative evaluations show that our scheme outperforms SOTAs with a large
margin. We believe the proposed LEAD along with the dataset would benefit the
community w.r.t depth researches.
</p>
<a href="http://arxiv.org/abs/2102.07989" target="_blank">arXiv:2102.07989</a> [<a href="http://arxiv.org/pdf/2102.07989" target="_blank">pdf</a>]

<h2>Feature Pyramid Network with Multi-Head Attention for Se-mantic Segmentation of Fine-Resolution Remotely Sensed Im-ages. (arXiv:2102.07997v1 [cs.CV])</h2>
<h3>Rui Li, Shunyi Zheng, Chenxi Duan</h3>
<p>Semantic segmentation from fine-resolution remotely sensed images is an
urgent issue in satellite imagery processing. Due to the complicated
environment, automatic categorization and segmen-tation is a challenging matter
especially for images with a fine resolution. Solving it can help to surmount a
wide varied range of obstacles in urban planning, environmental protection, and
natural landscape monitoring, which paves the way for complete scene
understanding. However, the existing frequently-used encoder-decoder structure
is unable to effectively combine the extracted spatial and contextual features.
Therefore, in this paper, we introduce the Feature Pyramid Net-work (FPN) to
bridge the gap between the low-level and high-level features. Moreover, we
enhance the contextual information with the elaborate Multi-Head Attention
module and propose the Feature Pyramid Network with Multi-Head Attention
(FPN-MHA) for semantic segmentation of fine-resolution remotely sensed images.
Extensive experiments conducted on the ISPRS Potsdam and Vaihingen datasets
demonstrate the effectiveness of our FPN-MHA. Code is available at
https://github.com/lironui/FPN-MHA.
</p>
<a href="http://arxiv.org/abs/2102.07997" target="_blank">arXiv:2102.07997</a> [<a href="http://arxiv.org/pdf/2102.07997" target="_blank">pdf</a>]

<h2>TransFuse: Fusing Transformers and CNNs for Medical Image Segmentation. (arXiv:2102.08005v1 [cs.CV])</h2>
<h3>Yundong Zhang, Huiye Liu, Qiang Hu</h3>
<p>U-Net based convolutional neural networks with deep feature representation
and skip-connections have significantly boosted the performance of medical
image segmentation. In this paper, we study the more challenging problem of
improving efficiency in modeling global contexts without losing localization
ability for low-level details. TransFuse, a novel two-branch architecture is
proposed, which combines Transformers and CNNs in a parallel style. With
TransFuse, both global dependency and low-level spatial details can be
efficiently captured in a much shallower manner. Besides, a novel fusion
technique - BiFusion module is proposed to fuse the multi-level features from
each branch. TransFuse achieves the newest state-of-the-arts on polyp
segmentation task, with 20\% fewer parameters and the fastest inference speed
at about 98.7 FPS.
</p>
<a href="http://arxiv.org/abs/2102.08005" target="_blank">arXiv:2102.08005</a> [<a href="http://arxiv.org/pdf/2102.08005" target="_blank">pdf</a>]

<h2>EfficientLPS: Efficient LiDAR Panoptic Segmentation. (arXiv:2102.08009v1 [cs.CV])</h2>
<h3>Kshitij Sirohi, Rohit Mohan, Daniel B&#xfc;scher, Wolfram Burgard, Abhinav Valada</h3>
<p>Panoptic segmentation of point clouds is a crucial task that enables
autonomous vehicles to comprehend their vicinity using their highly accurate
and reliable LiDAR sensors. Existing top-down approaches tackle this problem by
either combining independent task-specific networks or translating methods from
the image domain ignoring the intricacies of LiDAR data and thus often
resulting in sub-optimal performance. In this paper, we present the novel
top-down Efficient LiDAR Panoptic Segmentation (EfficientLPS) architecture that
addresses multiple challenges in segmenting LiDAR point clouds including
distance-dependent sparsity, severe occlusions, large scale-variations, and
re-projection errors. EfficientLPS comprises of a novel shared backbone that
encodes with strengthened geometric transformation modeling capacity and
aggregates semantically rich range-aware multi-scale features. It incorporates
new scale-invariant semantic and instance segmentation heads along with the
panoptic fusion module which is supervised by our proposed panoptic periphery
loss function. Additionally, we formulate a regularized pseudo labeling
framework to further improve the performance of EfficientLPS by training on
unlabelled data. We benchmark our proposed model on two large-scale LiDAR
datasets: nuScenes, for which we also provide ground truth annotations, and
SemanticKITTI. Notably, EfficientLPS sets the new state-of-the-art on both
these datasets.
</p>
<a href="http://arxiv.org/abs/2102.08009" target="_blank">arXiv:2102.08009</a> [<a href="http://arxiv.org/pdf/2102.08009" target="_blank">pdf</a>]

<h2>Training Stacked Denoising Autoencoders for Representation Learning. (arXiv:2102.08012v1 [cs.LG])</h2>
<h3>Jason Liang, Keith Kelly</h3>
<p>We implement stacked denoising autoencoders, a class of neural networks that
are capable of learning powerful representations of high dimensional data. We
describe stochastic gradient descent for unsupervised training of autoencoders,
as well as a novel genetic algorithm based approach that makes use of gradient
information. We analyze the performance of both optimization algorithms and
also the representation learning ability of the autoencoder when it is trained
on standard image classification datasets.
</p>
<a href="http://arxiv.org/abs/2102.08012" target="_blank">arXiv:2102.08012</a> [<a href="http://arxiv.org/pdf/2102.08012" target="_blank">pdf</a>]

<h2>Enhancing Hierarchical Information by Using Metric Cones for Graph Embedding. (arXiv:2102.08014v1 [cs.AI])</h2>
<h3>Daisuke Takehara, Kei Kobayashi</h3>
<p>Graph embedding is becoming an important method with applications in various
areas, including social networks and knowledge graph completion. In particular,
Poincar\'e embedding has been proposed to capture the hierarchical structure of
graphs, and its effectiveness has been reported. However, most of the existing
methods have isometric mappings in the embedding space, and the choice of the
origin point can be arbitrary. This fact is not desirable when the distance
from the origin is used as an indicator of hierarchy, as in the case of
Poincar\'e embedding. In this paper, we propose graph embedding in a metric
cone to solve such a problem, and we gain further benefits: 1) we provide an
indicator of hierarchical information that is both geometrically and
intuitively natural to interpret, 2) we can extract the hierarchical structure
from a graph embedding output of other methods by learning additional
one-dimensional parameters, and 3) we can change the curvature of the embedding
space via a hyperparameter.
</p>
<a href="http://arxiv.org/abs/2102.08014" target="_blank">arXiv:2102.08014</a> [<a href="http://arxiv.org/pdf/2102.08014" target="_blank">pdf</a>]

<h2>A Thorough View of Exact Inference in Graphs from the Degree-4 Sum-of-Squares Hierarchy. (arXiv:2102.08019v1 [cs.LG])</h2>
<h3>Kevin Bello, Chuyang Ke, Jean Honorio</h3>
<p>Performing inference in graphs is a common task within several machine
learning problems, e.g., image segmentation, community detection, among others.
For a given undirected connected graph, we tackle the statistical problem of
exactly recovering an unknown ground-truth binary labeling of the nodes from a
single corrupted observation of each edge. Such problem can be formulated as a
quadratic combinatorial optimization problem over the boolean hypercube, where
it has been shown before that one can (with high probability and in polynomial
time) exactly recover the ground-truth labeling of graphs that have an
isoperimetric number that grows with respect to the number of nodes (e.g.,
complete graphs, regular expanders). In this work, we apply a powerful
hierarchy of relaxations, known as the sum-of-squares (SoS) hierarchy, to the
combinatorial problem. Motivated by empirical evidence on the improvement in
exact recoverability, we center our attention on the degree-4 SoS relaxation
and set out to understand the origin of such improvement from a graph
theoretical perspective. We show that the solution of the dual of the relaxed
problem is related to finding edge weights of the Johnson and Kneser graphs,
where the weights fulfill the SoS constraints and intuitively allow the input
graph to increase its algebraic connectivity. Finally, as byproduct of our
analysis, we derive a novel Cheeger-type lower bound for the algebraic
connectivity of graphs with signed edge weights.
</p>
<a href="http://arxiv.org/abs/2102.08019" target="_blank">arXiv:2102.08019</a> [<a href="http://arxiv.org/pdf/2102.08019" target="_blank">pdf</a>]

<h2>Uncertainty-based method for improving poorly labeled segmentation datasets. (arXiv:2102.08021v1 [cs.CV])</h2>
<h3>Ekaterina Redekop, Alexey Chernyavskiy</h3>
<p>The success of modern deep learning algorithms for image segmentation heavily
depends on the availability of large datasets with clean pixel-level
annotations (masks), where the objects of interest are accurately delineated.
Lack of time and expertise during data annotation leads to incorrect boundaries
and label noise. It is known that deep convolutional neural networks (DCNNs)
can memorize even completely random labels, resulting in poor accuracy. We
propose a framework to train binary segmentation DCNNs using sets of unreliable
pixel-level annotations. Erroneously labeled pixels are identified based on the
estimated aleatoric uncertainty of the segmentation and are relabeled to the
true value.
</p>
<a href="http://arxiv.org/abs/2102.08021" target="_blank">arXiv:2102.08021</a> [<a href="http://arxiv.org/pdf/2102.08021" target="_blank">pdf</a>]

<h2>Joint self-supervised blind denoising and noise estimation. (arXiv:2102.08023v1 [cs.LG])</h2>
<h3>Jean Ollion, Charles Ollion (CMAP), Elisabeth Gassiat (LMO), Luc Leh&#xe9;ricy (JAD), Sylvain Le Corff (IP Paris, TIPIC-SAMOVAR, SAMOVAR)</h3>
<p>We propose a novel self-supervised image blind denoising approach in which
two neural networks jointly predict the clean signal and infer the noise
distribution. Assuming that the noisy observations are independent
conditionally to the signal, the networks can be jointly trained without clean
training data. Therefore, our approach is particularly relevant for biomedical
image denoising where the noise is difficult to model precisely and clean
training data are usually unavailable. Our method significantly outperforms
current state-of-the-art self-supervised blind denoising algorithms, on six
publicly available biomedical image datasets. We also show empirically with
synthetic noisy data that our model captures the noise distribution
efficiently. Finally, the described framework is simple, lightweight and
computationally efficient, making it useful in practical cases.
</p>
<a href="http://arxiv.org/abs/2102.08023" target="_blank">arXiv:2102.08023</a> [<a href="http://arxiv.org/pdf/2102.08023" target="_blank">pdf</a>]

<h2>EDITH :ECG biometrics aided by Deep learning for reliable Individual auTHentication. (arXiv:2102.08026v1 [cs.LG])</h2>
<h3>Nabil Ibtehaz, Muhammad E. H. Chowdhury, Amith Khandakar, Serkan Kiranyaz, M. Sohel Rahman, Anas Tahir, Yazan Qiblawey, Tawsifur Rahman</h3>
<p>In recent years, physiological signal based authentication has shown great
promises,for its inherent robustness against forgery. Electrocardiogram (ECG)
signal, being the most widely studied biosignal, has also received the highest
level of attention in this regard. It has been proven with numerous studies
that by analyzing ECG signals from different persons, it is possible to
identify them, with acceptable accuracy. In this work, we present, EDITH, a
deep learning-based framework for ECG biometrics authentication system.
Moreover, we hypothesize and demonstrate that Siamese architectures can be used
over typical distance metrics for improved performance. We have evaluated EDITH
using 4 commonly used datasets and outperformed the prior works using less
number of beats. EDITH performs competitively using just a single heartbeat
(96-99.75% accuracy) and can be further enhanced by fusing multiple beats (100%
accuracy from 3 to 6 beats). Furthermore, the proposed Siamese architecture
manages to reduce the identity verification Equal Error Rate (EER) to 1.29%. A
limited case study of EDITH with real-world experimental data also suggests its
potential as a practical authentication system.
</p>
<a href="http://arxiv.org/abs/2102.08026" target="_blank">arXiv:2102.08026</a> [<a href="http://arxiv.org/pdf/2102.08026" target="_blank">pdf</a>]

<h2>Transferring Domain Knowledge with an Adviser in Continuous Tasks. (arXiv:2102.08029v1 [cs.AI])</h2>
<h3>Rukshan Wijesinghe, Kasun Vithanage, Dumindu Tissera, Alex Xavier, Subha Fernando, Jayathu Samarawickrama</h3>
<p>Recent advances in Reinforcement Learning (RL) have surpassed human-level
performance in many simulated environments. However, existing reinforcement
learning techniques are incapable of explicitly incorporating already known
domain-specific knowledge into the learning process. Therefore, the agents have
to explore and learn the domain knowledge independently through a trial and
error approach, which consumes both time and resources to make valid responses.
Hence, we adapt the Deep Deterministic Policy Gradient (DDPG) algorithm to
incorporate an adviser, which allows integrating domain knowledge in the form
of pre-learned policies or pre-defined relationships to enhance the agent's
learning process. Our experiments on OpenAi Gym benchmark tasks show that
integrating domain knowledge through advisers expedites the learning and
improves the policy towards better optima.
</p>
<a href="http://arxiv.org/abs/2102.08029" target="_blank">arXiv:2102.08029</a> [<a href="http://arxiv.org/pdf/2102.08029" target="_blank">pdf</a>]

<h2>Design a Technology Based on the Fusion of Genetic Algorithm, Neural network and Fuzzy logic. (arXiv:2102.08035v1 [cs.AI])</h2>
<h3>Raid R. Al-Nima, Fawaz S. Abdullah, Ali N. Hamoodi</h3>
<p>This paper describes the design and development of a prototype technique for
artificial intelligence based on the fusion of genetic algorithm, neural
network and fuzzy logic. It starts by establishing a relationship between the
neural network and fuzzy logic. Then, it combines the genetic algorithm with
them. Information fusions are at the confidence level, where matching scores
can be reported and discussed. The technique is called the Genetic Neuro-Fuzzy
(GNF). It can be used for high accuracy real-time environments.
</p>
<a href="http://arxiv.org/abs/2102.08035" target="_blank">arXiv:2102.08035</a> [<a href="http://arxiv.org/pdf/2102.08035" target="_blank">pdf</a>]

<h2>A Multiscale Graph Convolutional Network for Change Detection in Homogeneous and Heterogeneous Remote Sensing Images. (arXiv:2102.08041v1 [cs.CV])</h2>
<h3>Junzheng Wu, Biao Li, Yao Qin, Weiping Ni, Han Zhang, Yuli Sun</h3>
<p>Change detection (CD) in remote sensing images has been an ever-expanding
area of research. To date, although many methods have been proposed using
various techniques, accurately identifying changes is still a great challenge,
especially in the high resolution or heterogeneous situations, due to the
difficulties in effectively modeling the features from ground objects with
different patterns. In this paper, a novel CD method based on the graph
convolutional network (GCN) and multiscale object-based technique is proposed
for both homogeneous and heterogeneous images. First, the object-wise high
level features are obtained through a pre-trained U-net and the multiscale
segmentations. Treating each parcel as a node, the graph representations can be
formed and then, fed into the proposed multiscale graph convolutional network
with each channel corresponding to one scale. The multiscale GCN propagates the
label information from a small number of labeled nodes to the other ones which
are unlabeled. Further, to comprehensively incorporate the information from the
output channels of multiscale GCN, a fusion strategy is designed using the
father-child relationships between scales. Extensive Experiments on optical,
SAR and heterogeneous optical/SAR data sets demonstrate that the proposed
method outperforms some state-of the-art methods in both qualitative and
quantitative evaluations. Besides, the Influences of some factors are also
discussed.
</p>
<a href="http://arxiv.org/abs/2102.08041" target="_blank">arXiv:2102.08041</a> [<a href="http://arxiv.org/pdf/2102.08041" target="_blank">pdf</a>]

<h2>Zero-Shot Adaptation for mmWave Beam-Tracking on Overhead Messenger Wires through Robust Adversarial Reinforcement Learning. (arXiv:2102.08055v1 [cs.LG])</h2>
<h3>Masao Shinzaki, Yusuke Koda, Koji Yamamoto, Takayuki Nishio, Masahiro Morikura, Yushi Shirato, Daisei Uchida, Naoki Kita</h3>
<p>This paper discusses the opportunity of bringing the concept of zero-shot
adaptation into learning-based millimeter-wave (mmWave) communication systems,
particularly in environments with unstable urban infrastructures. Here,
zero-shot adaptation implies that a learning agent adapts to unseen scenarios
during training without any adaptive fine-tuning. By considering learning-based
beam-tracking of a mmWave node placed on an overhead messenger wire, we first
discuss the importance of zero-shot adaptation. More specifically, we confirm
that the gap between the values of wire tension and total wire mass in training
and test scenarios deteriorates the beam-tracking performance in terms of the
received power. Motivated by this discussion, we propose a robust beam-tracking
method to adapt to a broad range of test scenarios in a zero-shot manner, i.e.,
without requiring any retraining to adapt the scenarios. The key idea is to
leverage a recent, robust adversarial reinforcement learning technique, where
such training and test gaps are regarded as disturbances from adversaries. In
our case, a beam-tracking agent performs training competitively bases on an
intelligent adversary who causes beam misalignments. Numerical evaluations
confirm the feasibility of zero-shot adaptation by showing that the on-wire
node achieves feasible beam-tracking performance without any adaptive
fine-tuning in unseen scenarios.
</p>
<a href="http://arxiv.org/abs/2102.08055" target="_blank">arXiv:2102.08055</a> [<a href="http://arxiv.org/pdf/2102.08055" target="_blank">pdf</a>]

<h2>Learning to Recognize Actions on Objects in Egocentric Video with Attention Dictionaries. (arXiv:2102.08065v1 [cs.CV])</h2>
<h3>Swathikiran Sudhakaran, Sergio Escalera, Oswald Lanz</h3>
<p>We present EgoACO, a deep neural architecture for video action recognition
that learns to pool action-context-object descriptors from frame level features
by leveraging the verb-noun structure of action labels in egocentric video
datasets. The core component of EgoACO is class activation pooling (CAP), a
differentiable pooling operation that combines ideas from bilinear pooling for
fine-grained recognition and from feature learning for discriminative
localization. CAP uses self-attention with a dictionary of learnable weights to
pool from the most relevant feature regions. Through CAP, EgoACO learns to
decode object and scene context descriptors from video frame features. For
temporal modeling in EgoACO, we design a recurrent version of class activation
pooling termed Long Short-Term Attention (LSTA). LSTA extends convolutional
gated LSTM with built-in spatial attention and a re-designed output gate.
Action, object and context descriptors are fused by a multi-head prediction
that accounts for the inter-dependencies between noun-verb-action structured
labels in egocentric video datasets. EgoACO features built-in visual
explanations, helping learning and interpretation. Results on the two largest
egocentric action recognition datasets currently available, EPIC-KITCHENS and
EGTEA, show that by explicitly decoding action-context-object descriptors,
EgoACO achieves state-of-the-art recognition performance.
</p>
<a href="http://arxiv.org/abs/2102.08065" target="_blank">arXiv:2102.08065</a> [<a href="http://arxiv.org/pdf/2102.08065" target="_blank">pdf</a>]

<h2>A comparative study on movement feature in different directions for micro-expression recognition. (arXiv:2102.08068v1 [cs.CV])</h2>
<h3>Jinsheng Wei, Guanming Lu, Jingjie Yan</h3>
<p>Micro-expression can reflect people's real emotions. Recognizing
micro-expressions is difficult because they are small motions and have a short
duration. As the research is deepening into micro-expression recognition, many
effective features and methods have been proposed. To determine which direction
of movement feature is easier for distinguishing micro-expressions, this paper
selects 18 directions (including three types of horizontal, vertical and
oblique movements) and proposes a new low-dimensional feature called the
Histogram of Single Direction Gradient (HSDG) to study this topic. In this
paper, HSDG in every direction is concatenated with LBP-TOP to obtain the LBP
with Single Direction Gradient (LBP-SDG) and analyze which direction of
movement feature is more discriminative for micro-expression recognition. As
with some existing work, Euler Video Magnification (EVM) is employed as a
preprocessing step. The experiments on the CASME II and SMIC-HS databases
summarize the effective and optimal directions and demonstrate that HSDG in an
optimal direction is discriminative, and the corresponding LBP-SDG achieves
state-of-the-art performance using EVM.
</p>
<a href="http://arxiv.org/abs/2102.08068" target="_blank">arXiv:2102.08068</a> [<a href="http://arxiv.org/pdf/2102.08068" target="_blank">pdf</a>]

<h2>Steadily Learn to Drive with Virtual Memory. (arXiv:2102.08072v1 [cs.LG])</h2>
<h3>Yuhang Zhang, Yao Mu, Yujie Yang, Yang Guan, Shengbo Eben Li, Qi Sun, Jianyu Chen</h3>
<p>Reinforcement learning has shown great potential in developing high-level
autonomous driving. However, for high-dimensional tasks, current RL methods
suffer from low data efficiency and oscillation in the training process. This
paper proposes an algorithm called Learn to drive with Virtual Memory (LVM) to
overcome these problems. LVM compresses the high-dimensional information into
compact latent states and learns a latent dynamic model to summarize the
agent's experience. Various imagined latent trajectories are generated as
virtual memory by the latent dynamic model. The policy is learned by
propagating gradient through the learned latent model with the imagined latent
trajectories and thus leads to high data efficiency. Furthermore, a double
critic structure is designed to reduce the oscillation during the training
process. The effectiveness of LVM is demonstrated by an image-input autonomous
driving task, in which LVM outperforms the existing method in terms of data
efficiency, learning stability, and control performance.
</p>
<a href="http://arxiv.org/abs/2102.08072" target="_blank">arXiv:2102.08072</a> [<a href="http://arxiv.org/pdf/2102.08072" target="_blank">pdf</a>]

<h2>Restore from Restored: Single-image Inpainting. (arXiv:2102.08078v1 [cs.CV])</h2>
<h3>Eun Hye Lee, Jeong Mu Kim, Ji Su Kim, Tae Hyun Kim</h3>
<p>Recent image inpainting methods show promising results due to the power of
deep learning, which can explore external information available from a large
training dataset. However, many state-of-the-art inpainting networks are still
limited in exploiting internal information available in the given input image
at test time. To mitigate this problem, we present a novel and efficient
self-supervised fine-tuning algorithm that can adapt the parameters of fully
pretrained inpainting networks without using ground-truth clean image in this
work. We upgrade the parameters of the pretrained networks by utilizing
existing self-similar patches within the given input image without changing
network architectures. Qualitative and quantitative experimental results
demonstrate the superiority of the proposed algorithm and we achieve
state-of-the-art inpainting results on publicly available numerous benchmark
datasets.
</p>
<a href="http://arxiv.org/abs/2102.08078" target="_blank">arXiv:2102.08078</a> [<a href="http://arxiv.org/pdf/2102.08078" target="_blank">pdf</a>]

<h2>Just Noticeable Difference for Machine Perception and Generation of Regularized Adversarial Images with Minimal Perturbation. (arXiv:2102.08079v1 [cs.CV])</h2>
<h3>Adil Kaan Akan, Emre Akbas, Fatos T. Yarman Vural</h3>
<p>In this study, we introduce a measure for machine perception, inspired by the
concept of Just Noticeable Difference (JND) of human perception. Based on this
measure, we suggest an adversarial image generation algorithm, which
iteratively distorts an image by an additive noise until the machine learning
model detects the change in the image by outputting a false label. The amount
of noise added to the original image is defined as the gradient of the cost
function of the machine learning model. This cost function explicitly minimizes
the amount of perturbation applied on the input image and it is regularized by
bounded range and total variation functions to assure perceptual similarity of
the adversarial image to the input. We evaluate the adversarial images
generated by our algorithm both qualitatively and quantitatively on CIFAR10,
ImageNet, and MS COCO datasets. Our experiments on image classification and
object detection tasks show that adversarial images generated by our method are
both more successful in deceiving the recognition/detection model and less
perturbed compared to the images generated by the state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.08079" target="_blank">arXiv:2102.08079</a> [<a href="http://arxiv.org/pdf/2102.08079" target="_blank">pdf</a>]

<h2>Learning the Noise of Failure: Intelligent System Tests for Robots. (arXiv:2102.08080v1 [cs.RO])</h2>
<h3>Felix Sygulla, Daniel Rixen</h3>
<p>Roboticists usually test new control software in simulation environments
before evaluating its functionality on real-world robots. Simulations reduce
the risk of damaging the hardware and can significantly increase the
development process's efficiency in the form of automated system tests.

However, many flaws in the software remain undetected in simulation data,
revealing their harmful effects on the system only in time-consuming
experiments. In reality, such irregularities are often easily recognized solely
by the robot's airborne noise during operation. We propose a simulated noise
estimate for the detection of failures in automated system tests of robots. The
classification of flaws uses classical machine learning - a support vector
machine - to identify different failure classes from the scalar noise estimate.

The methodology is evaluated on simulation data from the humanoid robot LOLA.
The approach yields high failure detection accuracy with a low false-positive
rate, enabling its use for stricter automated system tests. Results indicate
that a single trained model may work for different robots. The proposed
technique is provided to the community in the form of the open-source tool
NoisyTest, making it easy to test data from any robot. In a broader scope, the
technique may empower real-world automated system tests without human
evaluation of success or failure.
</p>
<a href="http://arxiv.org/abs/2102.08080" target="_blank">arXiv:2102.08080</a> [<a href="http://arxiv.org/pdf/2102.08080" target="_blank">pdf</a>]

<h2>Orthogonal Features-based EEG Signal Denoising using Fractionally Compressed AutoEncoder. (arXiv:2102.08083v1 [cs.LG])</h2>
<h3>Subham Nagar, Ahlad Kumar, M.N.S. Swamy</h3>
<p>A fractional-based compressed auto-encoder architecture has been introduced
to solve the problem of denoising electroencephalogram (EEG) signals. The
architecture makes use of fractional calculus to calculate the gradients during
the backpropagation process, as a result of which a new hyper-parameter in the
form of fractional order ($\alpha$) has been introduced which can be tuned to
get the best denoising performance. Additionally, to avoid substantial use of
memory resources, the model makes use of orthogonal features in the form of
Tchebichef moments as input. The orthogonal features have been used in
achieving compression at the input stage. Considering the growing use of low
energy devices, compression of neural networks becomes imperative. Here, the
auto-encoder's weights are compressed using the randomized singular value
decomposition (RSVD) algorithm during training while evaluation is performed
using various compression ratios. The experimental results show that the
proposed fractionally compressed architecture provides improved denoising
results on the standard datasets when compared with the existing methods.
</p>
<a href="http://arxiv.org/abs/2102.08083" target="_blank">arXiv:2102.08083</a> [<a href="http://arxiv.org/pdf/2102.08083" target="_blank">pdf</a>]

<h2>Boosting Deep Transfer Learning for COVID-19 Classification. (arXiv:2102.08085v1 [cs.CV])</h2>
<h3>Fouzia Altaf, Syed M.S. Islam, Naeem K. Janjua, Naveed Akhtar</h3>
<p>COVID-19 classification using chest Computed Tomography (CT) has been found
pragmatically useful by several studies. Due to the lack of annotated samples,
these studies recommend transfer learning and explore the choices of
pre-trained models and data augmentation. However, it is still unknown if there
are better strategies than vanilla transfer learning for more accurate COVID-19
classification with limited CT data. This paper provides an affirmative answer,
devising a novel `model' augmentation technique that allows a considerable
performance boost to transfer learning for the task. Our method systematically
reduces the distributional shift between the source and target domains and
considers augmenting deep learning with complementary representation learning
techniques. We establish the efficacy of our method with publicly available
datasets and models, along with identifying contrasting observations in the
previous studies.
</p>
<a href="http://arxiv.org/abs/2102.08085" target="_blank">arXiv:2102.08085</a> [<a href="http://arxiv.org/pdf/2102.08085" target="_blank">pdf</a>]

<h2>Making the most of your day: online learning for optimal allocation of time. (arXiv:2102.08087v1 [stat.ML])</h2>
<h3>Etienne Boursier, Tristan Garrec, Vianney Perchet, Marco Scarsini</h3>
<p>We study online learning for optimal allocation when the resource to be
allocated is time. Examples of possible applications include a driver filling a
day with rides, a landlord renting an estate, etc. Following our initial
motivation, a driver receives ride proposals sequentially according to a
Poisson process and can either accept or reject a proposed ride. If she accepts
the proposal, she is busy for the duration of the ride and obtains a reward
that depends on the ride duration. If she rejects it, she remains on hold until
a new ride proposal arrives. We study the regret incurred by the driver first
when she knows her reward function but does not know the distribution of the
ride duration, and then when she does not know her reward function, either.
Faster rates are finally obtained by adding structural assumptions on the
distribution of rides or on the reward function. This natural setting bears
similarities with contextual (one-armed) bandits, but with the crucial
difference that the normalized reward associated to a context depends on the
whole distribution of contexts.
</p>
<a href="http://arxiv.org/abs/2102.08087" target="_blank">arXiv:2102.08087</a> [<a href="http://arxiv.org/pdf/2102.08087" target="_blank">pdf</a>]

<h2>An AutoML-based Approach to Multimodal Image Sentiment Analysis. (arXiv:2102.08092v1 [cs.LG])</h2>
<h3>Vasco Lopes, Ant&#xf3;nio Gaspar, Lu&#xed;s A. Alexandre, Jo&#xe3;o Cordeiro</h3>
<p>Sentiment analysis is a research topic focused on analysing data to extract
information related to the sentiment that it causes. Applications of sentiment
analysis are wide, ranging from recommendation systems, and marketing to
customer satisfaction. Recent approaches evaluate textual content using Machine
Learning techniques that are trained over large corpora. However, as social
media grown, other data types emerged in large quantities, such as images.
Sentiment analysis in images has shown to be a valuable complement to textual
data since it enables the inference of the underlying message polarity by
creating context and connections. Multimodal sentiment analysis approaches
intend to leverage information of both textual and image content to perform an
evaluation. Despite recent advances, current solutions still flounder in
combining both image and textual information to classify social media data,
mainly due to subjectivity, inter-class homogeneity and fusion data
differences. In this paper, we propose a method that combines both textual and
image individual sentiment analysis into a final fused classification based on
AutoML, that performs a random search to find the best model. Our method
achieved state-of-the-art performance in the B-T4SA dataset, with 95.19%
accuracy.
</p>
<a href="http://arxiv.org/abs/2102.08092" target="_blank">arXiv:2102.08092</a> [<a href="http://arxiv.org/pdf/2102.08092" target="_blank">pdf</a>]

<h2>A Law of Robustness for Weight-bounded Neural Networks. (arXiv:2102.08093v1 [stat.ML])</h2>
<h3>Hisham Husain, Borja Balle</h3>
<p>Robustness of deep neural networks against adversarial perturbations is a
pressing concern motivated by recent findings showing the pervasive nature of
such vulnerabilities. One method of characterizing the robustness of a neural
network model is through its Lipschitz constant, which forms a robustness
certificate. A natural question to ask is, for a fixed model class (such as
neural networks) and a dataset of size $n$, what is the smallest achievable
Lipschitz constant among all models that fit the dataset? Recently, (Bubeck et
al., 2020) conjectured that when using two-layer networks with $k$ neurons to
fit a generic dataset, the smallest Lipschitz constant is
$\Omega(\sqrt{\frac{n}{k}})$. This implies that one would require one neuron
per data point to robustly fit the data. In this work we derive a lower bound
on the Lipschitz constant for any arbitrary model class with bounded Rademacher
complexity. Our result coincides with that conjectured in (Bubeck et al., 2020)
for two-layer networks under the assumption of bounded weights. However, due to
our result's generality, we also derive bounds for multi-layer neural networks,
discovering that one requires $\log n$ constant-sized layers to robustly fit
the data. Thus, our work establishes a law of robustness for weight bounded
neural networks and provides formal evidence on the necessity of
over-parametrization in deep learning.
</p>
<a href="http://arxiv.org/abs/2102.08093" target="_blank">arXiv:2102.08093</a> [<a href="http://arxiv.org/pdf/2102.08093" target="_blank">pdf</a>]

<h2>Composing Pick-and-Place Tasks By Grounding Language. (arXiv:2102.08094v1 [cs.RO])</h2>
<h3>Oier Mees, Wolfram Burgard</h3>
<p>Controlling robots to perform tasks via natural language is one of the most
challenging topics in human-robot interaction. In this work, we present a robot
system that follows unconstrained language instructions to pick and place
arbitrary objects and effectively resolves ambiguities through dialogues. Our
approach infers objects and their relationships from input images and language
expressions and can place objects in accordance with the spatial relations
expressed by the user. Unlike previous approaches, we consider grounding not
only for the picking but also for the placement of everyday objects from
language. Specifically, by grounding objects and their spatial relations, we
allow specification of complex placement instructions, e.g. "place it behind
the middle red bowl". Our results obtained using a real-world PR2 robot
demonstrate the effectiveness of our method in understanding pick-and-place
language instructions and sequentially composing them to solve tabletop
manipulation tasks. Videos are available at
this http URL
</p>
<a href="http://arxiv.org/abs/2102.08094" target="_blank">arXiv:2102.08094</a> [<a href="http://arxiv.org/pdf/2102.08094" target="_blank">pdf</a>]

<h2>Supervised Training of Dense Object Nets using Optimal Descriptors for Industrial Robotic Applications. (arXiv:2102.08096v1 [cs.RO])</h2>
<h3>Andras Kupcsik, Markus Spies, Alexander Klein, Marco Todescato, Nicolai Waniek, Philipp Schillinger, Mathias Buerger</h3>
<p>Dense Object Nets (DONs) by Florence, Manuelli and Tedrake (2018) introduced
dense object descriptors as a novel visual object representation for the
robotics community. It is suitable for many applications including object
grasping, policy learning, etc. DONs map an RGB image depicting an object into
a descriptor space image, which implicitly encodes key features of an object
invariant to the relative camera pose. Impressively, the self-supervised
training of DONs can be applied to arbitrary objects and can be evaluated and
deployed within hours. However, the training approach relies on accurate depth
images and faces challenges with small, reflective objects, typical for
industrial settings, when using consumer grade depth cameras. In this paper we
show that given a 3D model of an object, we can generate its descriptor space
image, which allows for supervised training of DONs. We rely on Laplacian
Eigenmaps (LE) to embed the 3D model of an object into an optimally generated
space. While our approach uses more domain knowledge, it can be efficiently
applied even for smaller and reflective objects, as it does not rely on depth
information. We compare the training methods on generating 6D grasps for
industrial objects and show that our novel supervised training approach
improves the pick-and-place performance in industry-relevant tasks.
</p>
<a href="http://arxiv.org/abs/2102.08096" target="_blank">arXiv:2102.08096</a> [<a href="http://arxiv.org/pdf/2102.08096" target="_blank">pdf</a>]

<h2>GradInit: Learning to Initialize Neural Networks for Stable and Efficient Training. (arXiv:2102.08098v1 [cs.LG])</h2>
<h3>Chen Zhu, Renkun Ni, Zheng Xu, Kezhi Kong, W. Ronny Huang, Tom Goldstein</h3>
<p>Changes in neural architectures have fostered significant breakthroughs in
language modeling and computer vision. Unfortunately, novel architectures often
require re-thinking the choice of hyperparameters (e.g., learning rate, warmup
schedule, and momentum coefficients) to maintain stability of the optimizer.
This optimizer instability is often the result of poor parameter
initialization, and can be avoided by architecture-specific initialization
schemes. In this paper, we present GradInit, an automated and architecture
agnostic method for initializing neural networks. GradInit is based on a simple
heuristic; the variance of each network layer is adjusted so that a single step
of SGD or Adam results in the smallest possible loss value. This adjustment is
done by introducing a scalar multiplier variable in front of each parameter
block, and then optimizing these variables using a simple numerical scheme.
GradInit accelerates the convergence and test performance of many convolutional
architectures, both with or without skip connections, and even without
normalization layers. It also enables training the original Post-LN Transformer
for machine translation without learning rate warmup under a wide range of
learning rates and momentum coefficients. Code is available at
https://github.com/zhuchen03/gradinit.
</p>
<a href="http://arxiv.org/abs/2102.08098" target="_blank">arXiv:2102.08098</a> [<a href="http://arxiv.org/pdf/2102.08098" target="_blank">pdf</a>]

<h2>EPE-NAS: Efficient Performance Estimation Without Training for Neural Architecture Search. (arXiv:2102.08099v1 [cs.LG])</h2>
<h3>Vasco Lopes, Saeid Alirezazadeh, Lu&#xed;s A. Alexandre</h3>
<p>Neural Architecture Search (NAS) has shown excellent results in designing
architectures for computer vision problems. NAS alleviates the need for
human-defined settings by automating architecture design and engineering.
However, NAS methods tend to be slow, as they require large amounts of GPU
computation. This bottleneck is mainly due to the performance estimation
strategy, which requires the evaluation of the generated architectures, mainly
by training them, to update the sampler method. In this paper, we propose
EPE-NAS, an efficient performance estimation strategy, that mitigates the
problem of evaluating networks, by scoring untrained networks and creating a
correlation with their trained performance. We perform this process by looking
at intra and inter-class correlations of an untrained network. We show that
EPE-NAS can produce a robust correlation and that by incorporating it into a
simple random sampling strategy, we are able to search for competitive
networks, without requiring any training, in a matter of seconds using a single
GPU. Moreover, EPE-NAS is agnostic to the search method, since it focuses on
the evaluation of untrained networks, making it easy to integrate into almost
any NAS method.
</p>
<a href="http://arxiv.org/abs/2102.08099" target="_blank">arXiv:2102.08099</a> [<a href="http://arxiv.org/pdf/2102.08099" target="_blank">pdf</a>]

<h2>Chickenpox Cases in Hungary: a Benchmark Dataset for Spatiotemporal Signal Processing with Graph Neural Networks. (arXiv:2102.08100v1 [cs.LG])</h2>
<h3>Benedek Rozemberczki, Paul Scherer, Oliver Kiss, Rik Sarkar, Tamas Ferenci</h3>
<p>Recurrent graph convolutional neural networks are highly effective machine
learning techniques for spatiotemporal signal processing. Newly proposed graph
neural network architectures are repetitively evaluated on standard tasks such
as traffic or weather forecasting. In this paper, we propose the Chickenpox
Cases in Hungary dataset as a new dataset for comparing graph neural network
architectures. Our time series analysis and forecasting experiments demonstrate
that the Chickenpox Cases in Hungary dataset is adequate for comparing the
predictive performance and forecasting capabilities of novel recurrent graph
neural network architectures.
</p>
<a href="http://arxiv.org/abs/2102.08100" target="_blank">arXiv:2102.08100</a> [<a href="http://arxiv.org/pdf/2102.08100" target="_blank">pdf</a>]

<h2>Message Passing Descent for Efficient Machine Learning. (arXiv:2102.08110v1 [cs.LG])</h2>
<h3>Francesco Concetti, Michael Chertkov</h3>
<p>We propose a new iterative optimization method for the {\bf Data-Fitting}
(DF) problem in Machine Learning, e.g. Neural Network (NN) training. The
approach relies on {\bf Graphical Model} (GM) representation of the DF problem,
where variables are fitting parameters and factors are associated with the
Input-Output (IO) data. The GM results in the {\bf Belief Propagation}
Equations considered in the {\bf Large Deviation Limit} corresponding to the
practically important case when the number of the IO samples is much larger
than the number of the fitting parameters. We suggest the {\bf Message Passage
Descent} algorithm which relies on the piece-wise-polynomial representation of
the model DF function. In contrast with the popular gradient descent and
related algorithms our MPD algorithm rely on analytic (not automatic)
differentiation, while also (and most importantly) it descents through the
rugged DF landscape by \emph{making non local updates of the parameters} at
each iteration. The non-locality guarantees that the MPD is not trapped in the
local-minima, therefore resulting in better performance than locally-updated
algorithms of the gradient-descent type. We illustrate superior performance of
the algorithm on a Feed-Forward NN with a single hidden layer and a
piece-wise-linear activation function.
</p>
<a href="http://arxiv.org/abs/2102.08110" target="_blank">arXiv:2102.08110</a> [<a href="http://arxiv.org/pdf/2102.08110" target="_blank">pdf</a>]

<h2>Dynamic Virtual Graph Significance Networks for Predicting Influenza. (arXiv:2102.08122v1 [cs.AI])</h2>
<h3>Jie Zhang, Pengfei Zhou, Hongyan Wu</h3>
<p>Graph-structured data and their related algorithms have attracted significant
attention in many fields, such as influenza prediction in public health.
However, the variable influenza seasonality, occasional pandemics, and domain
knowledge pose great challenges to construct an appropriate graph, which could
impair the strength of the current popular graph-based algorithms to perform
data analysis. In this study, we develop a novel method, Dynamic Virtual Graph
Significance Networks (DVGSN), which can supervisedly and dynamically learn
from similar "infection situations" in historical timepoints. Representation
learning on the dynamic virtual graph can tackle the varied seasonality and
pandemics, and therefore improve the performance. The extensive experiments on
real-world influenza data demonstrate that DVGSN significantly outperforms the
current state-of-the-art methods. To the best of our knowledge, this is the
first attempt to supervisedly learn a dynamic virtual graph for time-series
prediction tasks. Moreover, the proposed method needs less domain knowledge to
build a graph in advance and has rich interpretability, which makes the method
more acceptable in the fields of public health, life sciences, and so on.
</p>
<a href="http://arxiv.org/abs/2102.08122" target="_blank">arXiv:2102.08122</a> [<a href="http://arxiv.org/pdf/2102.08122" target="_blank">pdf</a>]

<h2>Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N:M Transposable Masks. (arXiv:2102.08124v1 [cs.AI])</h2>
<h3>Itay Hubara, Brian Chmiel, Moshe Island, Ron Banner, Seffi Naor, Daniel Soudry</h3>
<p>Recently, researchers proposed pruning deep neural network weights (DNNs)
using an $N:M$ fine-grained block sparsity mask. In this mask, for each block
of $M$ weights, we have at least $N$ zeros. In contrast to unstructured
sparsity, $N:M$ fine-grained block sparsity allows acceleration in actual
modern hardware. So far, this was used for DNN acceleration at the inference
phase. First, we suggest a method to convert a pretrained model with
unstructured sparsity to a $N:M$ fine-grained block sparsity model, with little
to no training. Then, to also allow such acceleration in the training phase, we
suggest a novel transposable-fine-grained sparsity mask where the same mask can
be used for both forward and backward passes. Our transposable mask ensures
that both the weight matrix and its transpose follow the same sparsity pattern;
thus the matrix multiplication required for passing the error backward can also
be accelerated. We discuss the transposable constraint and devise a new measure
for mask constraints, called mask-diversity (MD), which correlates with their
expected accuracy. Then, we formulate the problem of finding the optimal
transposable mask as a minimum-cost-flow problem and suggest a fast linear
approximation that can be used when the masks dynamically change while
training. Our experiments suggest 2x speed-up with no accuracy degradation over
vision and language models. A reference implementation can be found at
https://github.com/papers-submission/structured_transposable_masks.
</p>
<a href="http://arxiv.org/abs/2102.08124" target="_blank">arXiv:2102.08124</a> [<a href="http://arxiv.org/pdf/2102.08124" target="_blank">pdf</a>]

<h2>Capturing the learning curves of generic features maps for realistic data sets with a teacher-student model. (arXiv:2102.08127v1 [stat.ML])</h2>
<h3>Bruno Loureiro, C&#xe9;dric Gerbelot, Hugo Cui, Sebastian Goldt, Florent Krzakala, Marc M&#xe9;zard, Lenka Zdeborov&#xe1;</h3>
<p>Teacher-student models provide a powerful framework in which the typical case
performance of high-dimensional supervised learning tasks can be studied in
closed form. In this setting, labels are assigned to data - often taken to be
Gaussian i.i.d. - by a teacher model, and the goal is to characterise the
typical performance of the student model in recovering the parameters that
generated the labels. In this manuscript we discuss a generalisation of this
setting where the teacher and student can act on different spaces, generated
with fixed, but generic feature maps. This is achieved via the rigorous study
of a high-dimensional Gaussian covariate model. Our contribution is two-fold:
First, we prove a rigorous formula for the asymptotic training loss and
generalisation error achieved by empirical risk minimization for this model.
Second, we present a number of situations where the learning curve of the model
captures the one of a \emph{realistic data set} learned with kernel regression
and classification, with out-of-the-box feature maps such as random projections
or scattering transforms, or with pre-learned ones - such as the features
learned by training multi-layer neural networks. We discuss both the power and
the limitations of the Gaussian teacher-student framework as a typical case
analysis capturing learning curves as encountered in practice on real data
sets.
</p>
<a href="http://arxiv.org/abs/2102.08127" target="_blank">arXiv:2102.08127</a> [<a href="http://arxiv.org/pdf/2102.08127" target="_blank">pdf</a>]

<h2>Hough2Map -- Iterative Event-based Hough Transform for High-Speed Railway Mapping. (arXiv:2102.08145v1 [cs.RO])</h2>
<h3>Florian Tschopp, Cornelius von Einem, Andrei Cramariuc, David Hug, Andrew William Palmer, Roland Siegwart, Margarita Chli, Juan Nieto</h3>
<p>To cope with the growing demand for transportation on the railway system,
accurate, robust, and high-frequency positioning is required to enable a safe
and efficient utilization of the existing railway infrastructure. As a basis
for a localization system, we propose a complete on-board mapping pipeline able
to map robust meaningful landmarks, such as poles from power lines, in the
vicinity of the vehicle. Such poles are good candidates for reliable and long
term landmarks even through difficult weather conditions or seasonal changes.
To address the challenges of motion blur and illumination changes in railway
scenarios we employ a Dynamic Vision Sensor, a novel event-based camera. Using
a sideways oriented on-board camera, poles appear as vertical lines. To map
such lines in a real-time event stream, we introduce HoughCeption, a novel
consecutive iterative event-based Hough transform framework capable of
detecting, tracking, and triangulating close-by structures. We demonstrate the
mapping reliability and accuracy of HoughCeption on real-world data in typical
usage scenarios and evaluate using surveyed infrastructure ground truth maps.
HoughCeption achieves a detection reliability of up to 92% and a mapping root
mean square error accuracy of 1.1518 m.
</p>
<a href="http://arxiv.org/abs/2102.08145" target="_blank">arXiv:2102.08145</a> [<a href="http://arxiv.org/pdf/2102.08145" target="_blank">pdf</a>]

<h2>Nominal Unification and Matching of Higher Order Expressions with Recursive Let. (arXiv:2102.08146v1 [cs.AI])</h2>
<h3>Manfred Schmidt-Schau&#xdf;, Temur Kutsia, Jordi Levy, Mateu Villaret, Yunus Kutz</h3>
<p>A sound and complete algorithm for nominal unification of higher-order
expressions with a recursive let is described, and shown to run in
nondeterministic polynomial time. We also explore specializations like nominal
letrec-matching for expressions, for DAGs, and for garbage-free expressions and
determine their complexity. Finally, we also provide a nominal unification
algorithm for higher-order expressions with recursive let and atom-variables,
where we show that it also runs in nondeterministic polynomial time.
</p>
<a href="http://arxiv.org/abs/2102.08146" target="_blank">arXiv:2102.08146</a> [<a href="http://arxiv.org/pdf/2102.08146" target="_blank">pdf</a>]

<h2>Flow-Mixup: Classifying Multi-labeled Medical Images with Corrupted Labels. (arXiv:2102.08148v1 [cs.CV])</h2>
<h3>Jintai Chen, Hongyun Yu, Ruiwei Feng, Danny Z. Chen, Jian Wu</h3>
<p>In clinical practice, medical image interpretation often involves
multi-labeled classification, since the affected parts of a patient tend to
present multiple symptoms or comorbidities. Recently, deep learning based
frameworks have attained expert-level performance on medical image
interpretation, which can be attributed partially to large amounts of accurate
annotations. However, manually annotating massive amounts of medical images is
impractical, while automatic annotation is fast but imprecise (possibly
introducing corrupted labels). In this work, we propose a new regularization
approach, called Flow-Mixup, for multi-labeled medical image classification
with corrupted labels. Flow-Mixup guides the models to capture robust features
for each abnormality, thus helping handle corrupted labels effectively and
making it possible to apply automatic annotation. Specifically, Flow-Mixup
decouples the extracted features by adding constraints to the hidden states of
the models. Also, Flow-Mixup is more stable and effective comparing to other
known regularization methods, as shown by theoretical and empirical analyses.
Experiments on two electrocardiogram datasets and a chest X-ray dataset
containing corrupted labels verify that Flow-Mixup is effective and insensitive
to corrupted labels.
</p>
<a href="http://arxiv.org/abs/2102.08148" target="_blank">arXiv:2102.08148</a> [<a href="http://arxiv.org/pdf/2102.08148" target="_blank">pdf</a>]

<h2>Differentiating Surgeon Expertise Solely by Eye Movement Features. (arXiv:2102.08155v1 [cs.CV])</h2>
<h3>Benedikt Hosp, Myat Su Yin, Peter Haddawy, Paphon Sa-Ngasoongsong, Enkelejda Kasneci</h3>
<p>Developments in computer science in recent years are moving into hospitals.
Surgeons are faced with ever new technical challenges. Visual perception plays
a key role in most of these. Diagnostic and training models are needed to
optimize the training of young surgeons. In this study, we present a model for
classifying experts, 4th-year residents and 3rd-year residents, using only eye
movements. We show a model that uses a minimal set of features and still
achieve a robust accuracy of 76.46 % to classify eye movements into the correct
class. Likewise, in this study, we address the evolutionary steps of visual
perception between three expertise classes, forming a first step towards a
diagnostic model for expertise.
</p>
<a href="http://arxiv.org/abs/2102.08155" target="_blank">arXiv:2102.08155</a> [<a href="http://arxiv.org/pdf/2102.08155" target="_blank">pdf</a>]

<h2>RMIX: Learning Risk-Sensitive Policies for Cooperative Reinforcement Learning Agents. (arXiv:2102.08159v1 [cs.LG])</h2>
<h3>Wei Qiu, Xinrun Wang, Runsheng Yu, Xu He, Rundong Wang, Bo An, Svetlana Obraztsova, Zinovi Rabinovich</h3>
<p>Current value-based multi-agent reinforcement learning methods optimize
individual Q values to guide individuals' behaviours via centralized training
with decentralized execution (CTDE). However, such expected, i.e.,
risk-neutral, Q value is not sufficient even with CTDE due to the randomness of
rewards and the uncertainty in environments, which causes the failure of these
methods to train coordinating agents in complex environments. To address these
issues, we propose RMIX, a novel cooperative MARL method with the Conditional
Value at Risk (CVaR) measure over the learned distributions of individuals' Q
values. Specifically, we first learn the return distributions of individuals to
analytically calculate CVaR for decentralized execution. Then, to handle the
temporal nature of the stochastic outcomes during executions, we propose a
dynamic risk level predictor for risk level tuning. Finally, we optimize the
CVaR policies with CVaR values used to estimate the target in TD error during
centralized training and the CVaR values are used as auxiliary local rewards to
update the local distribution via Quantile Regression loss. Empirically, we
show that our method significantly outperforms state-of-the-art methods on
challenging StarCraft II tasks, demonstrating enhanced coordination and
improved sample efficiency.
</p>
<a href="http://arxiv.org/abs/2102.08159" target="_blank">arXiv:2102.08159</a> [<a href="http://arxiv.org/pdf/2102.08159" target="_blank">pdf</a>]

<h2>Integrating Floor Plans into Hedonic Models for Rent Price Appraisal. (arXiv:2102.08162v1 [cs.LG])</h2>
<h3>Kirill Solovev, Nicolas Pr&#xf6;llochs</h3>
<p>Online real estate platforms have become significant marketplaces
facilitating users' search for an apartment or a house. Yet it remains
challenging to accurately appraise a property's value. Prior works have
primarily studied real estate valuation based on hedonic price models that take
structured data into account while accompanying unstructured data is typically
ignored. In this study, we investigate to what extent an automated visual
analysis of apartment floor plans on online real estate platforms can enhance
hedonic rent price appraisal. We propose a tailored two-staged deep learning
approach to learn price-relevant designs of floor plans from historical price
data. Subsequently, we integrate the floor plan predictions into hedonic rent
price models that account for both structural and locational characteristics of
an apartment. Our empirical analysis based on a unique dataset of 9174 real
estate listings suggests that current hedonic models underutilize the available
data. We find that (1) the visual design of floor plans has significant
explanatory power regarding rent prices - even after controlling for structural
and locational apartment characteristics, and (2) harnessing floor plans
results in an up to 10.56% lower out-of-sample prediction error. We further
find that floor plans yield a particularly high gain in prediction performance
for older and smaller apartments. Altogether, our empirical findings contribute
to the existing research body by establishing the link between the visual
design of floor plans and real estate prices. Moreover, our approach has
important implications for online real estate platforms, which can use our
findings to enhance user experience in their real estate listings.
</p>
<a href="http://arxiv.org/abs/2102.08162" target="_blank">arXiv:2102.08162</a> [<a href="http://arxiv.org/pdf/2102.08162" target="_blank">pdf</a>]

<h2>Differential Privacy and Byzantine Resilience in SGD: Do They Add Up?. (arXiv:2102.08166v1 [cs.LG])</h2>
<h3>Rachid Guerraoui, Nirupam Gupta, Rafa&#xeb;l Pinot, S&#xe9;bastien Rouault, John Stephan</h3>
<p>This paper addresses the problem of combining Byzantine resilience with
privacy in machine learning (ML). Specifically, we study whether a distributed
implementation of the renowned Stochastic Gradient Descent (SGD) learning
algorithm is feasible with both differential privacy (DP) and
$(\alpha,f)$-Byzantine resilience. To the best of our knowledge, this is the
first work to tackle this problem from a theoretical point of view. A key
finding of our analyses is that the classical approaches to these two
(seemingly) orthogonal issues are incompatible. More precisely, we show that a
direct composition of these techniques makes the guarantees of the resulting
SGD algorithm depend unfavourably upon the number of parameters in the ML
model, making the training of large models practically infeasible. We validate
our theoretical results through numerical experiments on publicly-available
datasets; showing that it is impractical to ensure DP and Byzantine resilience
simultaneously.
</p>
<a href="http://arxiv.org/abs/2102.08166" target="_blank">arXiv:2102.08166</a> [<a href="http://arxiv.org/pdf/2102.08166" target="_blank">pdf</a>]

<h2>Does deep machine vision have just noticeable difference (JND)?. (arXiv:2102.08168v1 [cs.CV])</h2>
<h3>Jian Jin, Xingxing Zhang, Xin Fu, Huan Zhang, Weisi Lin, Jian Lou, Yao Zhao</h3>
<p>As an important perceptual characteristic of the Human Visual System (HVS),
the Just Noticeable Difference (JND) has been studied for decades with
image/video processing (e.g., perceptual image/video coding). However, there is
little exploration on the existence of JND for AI, like Deep Machine Vision
(DMV), although the DMV has made great strides in many machine vision tasks. In
this paper, we take an initial attempt, and demonstrate that DMV does have the
JND, termed as DMVJND. Besides, we propose a JND model for the classification
task in DMV. It has been discovered that DMV can tolerate distorted images with
average PSNR of only 9.56dB (the lower the better), by generating JND via
unsupervised learning with our DMVJND-NET. In particular, a semantic-guided
redundancy assessment strategy is designed to constrain the magnitude and
spatial distribution of the JND. Experimental results on classification tasks
demonstrate that we successfully find and model the JND for deep machine
vision. Meanwhile, our DMV-JND paves a possible direction for DMV oriented
image/video compression, watermarking, quality assessment, deep neural network
security, and so on.
</p>
<a href="http://arxiv.org/abs/2102.08168" target="_blank">arXiv:2102.08168</a> [<a href="http://arxiv.org/pdf/2102.08168" target="_blank">pdf</a>]

<h2>Accurate and Clear Precipitation Nowcasting with Consecutive Attention and Rain-map Discrimination. (arXiv:2102.08175v1 [cs.CV])</h2>
<h3>Ashesh, Buo-Fu Chen, Treng-Shi Huang, Boyo Chen, Chia-Tung Chang, Hsuan-Tien Lin</h3>
<p>Precipitation nowcasting is an important task for weather forecasting. Many
recent works aim to predict the high rainfall events more accurately with the
help of deep learning techniques, but such events are relatively rare. The
rarity is often addressed by formulations that re-weight the rare events.
Somehow such a formulation carries a side effect of making "blurry" predictions
in low rainfall regions and cannot convince meteorologists to trust its
practical usability. We fix the trust issue by introducing a discriminator that
encourages the prediction model to generate realistic rain-maps without
sacrificing predictive accuracy. Furthermore, we extend the nowcasting time
frame from one hour to three hours to further address the needs from
meteorologists. The extension is based on consecutive attentions across
different hours. We propose a new deep learning model for precipitation
nowcasting that includes both the discrimination and attention techniques. The
model is examined on a newly-built benchmark dataset that contains both radar
data and actual rain data. The benchmark, which will be publicly released, not
only establishes the superiority of the proposed model, but also is expected to
encourage future research on precipitation nowcasting.
</p>
<a href="http://arxiv.org/abs/2102.08175" target="_blank">arXiv:2102.08175</a> [<a href="http://arxiv.org/pdf/2102.08175" target="_blank">pdf</a>]

<h2>Value of Information for Argumentation based Intelligence Analysis. (arXiv:2102.08180v1 [cs.AI])</h2>
<h3>Todd Robinson</h3>
<p>Argumentation provides a representation of arguments and attacks between
these arguments. Argumentation can be used to represent a reasoning process
over evidence to reach conclusions. Within such a reasoning process,
understanding the value of information can improve the quality of decision
making based on the output of the reasoning process. The value of an item of
information is inherently dependent on the available evidence and the question
being answered by the reasoning. In this paper we introduce a value of
information on argument frameworks to identify the most valuable arguments
within the finite set of arguments in the framework, and the arguments and
attacks which could be added to change the output of an evaluation. We
demonstrate the value of information within an argument framework representing
an intelligence analysis in the maritime domain. Understanding the value of
information in an intelligence analysis will allow analysts to balance the
value against the costs and risks of collection, to effectively request further
collection of intelligence to increase the confidence in the analysis of
hypotheses.
</p>
<a href="http://arxiv.org/abs/2102.08180" target="_blank">arXiv:2102.08180</a> [<a href="http://arxiv.org/pdf/2102.08180" target="_blank">pdf</a>]

<h2>Constructing Multiclass Classifiers using Binary Classifiers Under Log-Loss. (arXiv:2102.08184v1 [cs.LG])</h2>
<h3>Assaf Ben-Yishai, Or Ordentlich</h3>
<p>The construction of multiclass classifiers from binary classifiers is studied
in this paper, and performance is quantified by the regret, defined with
respect to the Bayes optimal log-loss. We start by proving that the regret of
the well known One vs. All (OVA) method is upper bounded by the sum of the
regrets of its constituent binary classifiers. We then present a new method
called Conditional OVA (COVA), and prove that its regret is given by the
weighted sum of the regrets corresponding to the constituent binary
classifiers. Lastly, we present a method termed Leveraged COVA (LCOVA),
designated to reduce the regret of a multiclass classifier by breaking it down
to independently optimized binary classifiers.
</p>
<a href="http://arxiv.org/abs/2102.08184" target="_blank">arXiv:2102.08184</a> [<a href="http://arxiv.org/pdf/2102.08184" target="_blank">pdf</a>]

<h2>Improper Learning with Gradient-based Policy Optimization. (arXiv:2102.08201v1 [cs.LG])</h2>
<h3>Mohammadi Zaki, Avinash Mohan, Aditya Gopalan, Shie Mannor</h3>
<p>We consider an improper reinforcement learning setting where the learner is
given M base controllers for an unknown Markov Decision Process, and wishes to
combine them optimally to produce a potentially new controller that can
outperform each of the base ones. We propose a gradient-based approach that
operates over a class of improper mixtures of the controllers. The value
function of the mixture and its gradient may not be available in closed-form;
however, we show that we can employ rollouts and simultaneous perturbation
stochastic approximation (SPSA) for explicit gradient descent optimization. We
derive convergence and convergence rate guarantees for the approach assuming
access to a gradient oracle. Numerical results on a challenging constrained
queueing task show that our improper policy optimization algorithm can
stabilize the system even when each constituent policy at its disposal is
unstable.
</p>
<a href="http://arxiv.org/abs/2102.08201" target="_blank">arXiv:2102.08201</a> [<a href="http://arxiv.org/pdf/2102.08201" target="_blank">pdf</a>]

<h2>Conditional Distributional Treatment Effect with Kernel Conditional Mean Embeddings and U-Statistic Regression. (arXiv:2102.08208v1 [stat.ML])</h2>
<h3>Junhyung Park, Uri Shalit, Bernhard Sch&#xf6;lkopf, Krikamol Muandet</h3>
<p>We propose to analyse the conditional distributional treatment effect
(CoDiTE), which, in contrast to the more common conditional average treatment
effect (CATE), is designed to encode a treatment's distributional aspects
beyond the mean. We first introduce a formal definition of the CoDiTE
associated with a distance function between probability measures. Then we
discuss the CoDiTE associated with the maximum mean discrepancy via kernel
conditional mean embeddings, which, coupled with a hypothesis test, tells us
whether there is any conditional distributional effect of the treatment.
Finally, we investigate what kind of conditional distributional effect the
treatment has, both in an exploratory manner via the conditional witness
function, and in a quantitative manner via U-statistic regression, generalising
the CATE to higher-order moments. Experiments on synthetic, semi-synthetic and
real datasets demonstrate the merits of our approach.
</p>
<a href="http://arxiv.org/abs/2102.08208" target="_blank">arXiv:2102.08208</a> [<a href="http://arxiv.org/pdf/2102.08208" target="_blank">pdf</a>]

<h2>The Yin-Yang dataset. (arXiv:2102.08211v1 [cs.AI])</h2>
<h3>Laura Kriener, Julian G&#xf6;ltz, Mihai A. Petrovici</h3>
<p>The Yin-Yang dataset was developed for research on biologically plausible
error backpropagation and deep learning in spiking neural networks. It serves
as an alternative to classic deep learning datasets, especially in algorithm-
and model-prototyping scenarios, by providing several advantages. First, it is
smaller and therefore faster to learn, thereby being better suited for the
deployment on neuromorphic chips with limited network sizes. Second, it
exhibits a very clear gap between the accuracies achievable using shallow as
compared to deep neural networks.
</p>
<a href="http://arxiv.org/abs/2102.08211" target="_blank">arXiv:2102.08211</a> [<a href="http://arxiv.org/pdf/2102.08211" target="_blank">pdf</a>]

<h2>Unifying Lower Bounds on Prediction Dimension of Consistent Convex Surrogates. (arXiv:2102.08218v1 [cs.LG])</h2>
<h3>Jessie Finocchiaro, Rafael Frongillo, Bo Waggoner</h3>
<p>Given a prediction task, understanding when one can and cannot design a
consistent convex surrogate loss, particularly a low-dimensional one, is an
important and active area of machine learning research. The prediction task may
be given as a target loss, as in classification and structured prediction, or
simply as a (conditional) statistic of the data, as in risk measure estimation.
These two scenarios typically involve different techniques for designing and
analyzing surrogate losses. We unify these settings using tools from property
elicitation, and give a general lower bound on prediction dimension. Our lower
bound tightens existing results in the case of discrete predictions, showing
that previous calibration-based bounds can largely be recovered via property
elicitation. For continuous estimation, our lower bound resolves on open
problem on estimating measures of risk and uncertainty.
</p>
<a href="http://arxiv.org/abs/2102.08218" target="_blank">arXiv:2102.08218</a> [<a href="http://arxiv.org/pdf/2102.08218" target="_blank">pdf</a>]

<h2>Differentially Private Quantiles. (arXiv:2102.08244v1 [cs.LG])</h2>
<h3>Jennifer Gillenwater, Matthew Joseph, Alex Kulesza</h3>
<p>Quantiles are often used for summarizing and understanding data. If that data
is sensitive, it may be necessary to compute quantiles in a way that is
differentially private, providing theoretical guarantees that the result does
not reveal private information. However, in the common case where multiple
quantiles are needed, existing differentially private algorithms scale poorly:
they compute each quantile individually, splitting their privacy budget and
thus decreasing accuracy. In this work we propose an instance of the
exponential mechanism that simultaneously estimates $m$ quantiles from $n$ data
points while guaranteeing differential privacy. The utility function is
carefully structured to allow for an efficient implementation that avoids
exponential dependence on $m$ and returns estimates of all $m$ quantiles in
time $O(mn^2 + m^2n)$. Experiments show that our method significantly
outperforms the current state of the art on both real and synthetic data while
remaining efficient enough to be practical.
</p>
<a href="http://arxiv.org/abs/2102.08244" target="_blank">arXiv:2102.08244</a> [<a href="http://arxiv.org/pdf/2102.08244" target="_blank">pdf</a>]

<h2>Classification of multivariate weakly-labelled time-series with attention. (arXiv:2102.08245v1 [cs.LG])</h2>
<h3>Surayez Rahman, Chang Wei Tan</h3>
<p>This research identifies a gap in weakly-labelled multivariate time-series
classification (TSC), where state-of-the-art TSC models do not per-form well.
Weakly labelled time-series are time-series containing noise and significant
redundancies. In response to this gap, this paper proposes an approach of
exploiting context relevance of subsequences from previous subsequences to
improve classification accuracy. To achieve this, state-of-the-art Attention
algorithms are experimented in combination with the top CNN models for TSC (FCN
and ResNet), in an CNN-LSTM architecture. Attention is a popular strategy for
context extraction with exceptional performance in modern sequence-to-sequence
tasks. This paper shows how attention algorithms can be used for improved
weakly labelledTSC by evaluating models on a multivariate EEG time-series
dataset obtained using a commercial Emotiv headsets from participants
performing various activities while driving. These time-series are segmented
into sub-sequences and labelled to allow supervised TSC.
</p>
<a href="http://arxiv.org/abs/2102.08245" target="_blank">arXiv:2102.08245</a> [<a href="http://arxiv.org/pdf/2102.08245" target="_blank">pdf</a>]

<h2>Probabilistic Localization of Insect-Scale Drones on Floating-Gate Inverter Arrays. (arXiv:2102.08247v1 [cs.RO])</h2>
<h3>Priyesh Shukla, Ankith Muralidhar, Nick Iliev, Theja Tulabandhula, Sawyer B. Fuller, Amit Ranjan Trivedi</h3>
<p>We propose a novel compute-in-memory (CIM)-based ultra-low-power framework
for probabilistic localization of insect-scale drones. The conventional
probabilistic localization approaches rely on the three-dimensional (3D)
Gaussian Mixture Model (GMM)-based representation of a 3D map. A GMM model with
hundreds of mixture functions is typically needed to adequately learn and
represent the intricacies of the map. Meanwhile, localization using complex GMM
map models is computationally intensive. Since insect-scale drones operate
under extremely limited area/power budget, continuous localization using GMM
models entails much higher operating energy -- thereby, limiting flying
duration and/or size of the drone due to a larger battery. Addressing the
computational challenges of localization in an insect-scale drone using a CIM
approach, we propose a novel framework of 3D map representation using a
harmonic mean of "Gaussian-like" mixture (HMGM) model. The likelihood function
useful for drone localization can be efficiently implemented by connecting many
multi-input inverters in parallel, each programmed with the parameters of the
3D map model represented as HMGM. When the depth measurements are projected to
the input of the implementation, the summed current of the inverters emulates
the likelihood of the measurement. We have characterized our approach on an
RGB-D indoor localization dataset. The average localization error in our
approach is $\sim$0.1125 m which is only slightly degraded than software-based
evaluation ($\sim$0.08 m). Meanwhile, our localization framework is
ultra-low-power, consuming as little as $\sim$17 $\mu$W power while processing
a depth frame in 1.33 ms over hundred pose hypotheses in the particle-filtering
(PF) algorithm used to localize the drone.
</p>
<a href="http://arxiv.org/abs/2102.08247" target="_blank">arXiv:2102.08247</a> [<a href="http://arxiv.org/pdf/2102.08247" target="_blank">pdf</a>]

<h2>Hierarchical VAEs Know What They Don't Know. (arXiv:2102.08248v1 [cs.LG])</h2>
<h3>Jakob D. Havtorn, Jes Frellsen, S&#xf8;ren Hauberg, Lars Maal&#xf8;e</h3>
<p>Deep generative models have shown themselves to be state-of-the-art density
estimators. Yet, recent work has found that they often assign a higher
likelihood to data from outside the training distribution. This seemingly
paradoxical behavior has caused concerns over the quality of the attained
density estimates. In the context of hierarchical variational autoencoders, we
provide evidence to explain this behavior by out-of-distribution data having
in-distribution low-level features. We argue that this is both expected and
desirable behavior. With this insight in hand, we develop a fast, scalable and
fully unsupervised likelihood-ratio score for OOD detection that requires data
to be in-distribution across all feature-levels. We benchmark the method on a
vast set of data and model combinations and achieve state-of-the-art results on
out-of-distribution detection.
</p>
<a href="http://arxiv.org/abs/2102.08248" target="_blank">arXiv:2102.08248</a> [<a href="http://arxiv.org/pdf/2102.08248" target="_blank">pdf</a>]

<h2>Reinforced Contact Tracing and Epidemic Intervention. (arXiv:2102.08251v1 [cs.AI])</h2>
<h3>Tao Feng, Sirui Song, Tong Xia, Yong Li</h3>
<p>The recent outbreak of COVID-19 poses a serious threat to people's lives.
Epidemic control strategies have also caused damage to the economy by cutting
off humans' daily commute. In this paper, we develop an Individual-based
Reinforcement Learning Epidemic Control Agent (IDRLECA) to search for smart
epidemic control strategies that can simultaneously minimize infections and the
cost of mobility intervention. IDRLECA first hires an infection probability
model to calculate the current infection probability of each individual. Then,
the infection probabilities together with individuals' health status and
movement information are fed to a novel GNN to estimate the spread of the virus
through human contacts. The estimated risks are used to further support an RL
agent to select individual-level epidemic-control actions. The training of
IDRLECA is guided by a specially designed reward function considering both the
cost of mobility intervention and the effectiveness of epidemic control.
Moreover, we design a constraint for control-action selection that eases its
difficulty and further improve exploring efficiency. Extensive experimental
results demonstrate that IDRLECA can suppress infections at a very low level
and retain more than 95% of human mobility.
</p>
<a href="http://arxiv.org/abs/2102.08251" target="_blank">arXiv:2102.08251</a> [<a href="http://arxiv.org/pdf/2102.08251" target="_blank">pdf</a>]

<h2>Dataset Condensation with Differentiable Siamese Augmentation. (arXiv:2102.08259v1 [cs.LG])</h2>
<h3>Bo Zhao, Hakan Bilen</h3>
<p>In many machine learning problems, large-scale datasets have become the
de-facto standard to train state-of-the-art deep networks at the price of heavy
computation load. In this paper, we focus on condensing large training sets
into significantly smaller synthetic sets which can be used to train deep
neural networks from scratch with minimum drop in performance. Inspired from
the recent training set synthesis methods, we propose Differentiable Siamese
Augmentation that enables effective use of data augmentation to synthesize more
informative synthetic images and thus achieves better performance when training
networks with augmentations. Experiments on multiple image classification
benchmarks demonstrate that the proposed method obtains substantial gains over
the state-of-the-art, 7% improvements on CIFAR10 and CIFAR100 datasets. We show
with only less than 1% data that our method achieves 99.6%, 94.9%, 88.5%, 71.5%
relative performance on MNIST, FashionMNIST, SVHN, CIFAR10 respectively.
</p>
<a href="http://arxiv.org/abs/2102.08259" target="_blank">arXiv:2102.08259</a> [<a href="http://arxiv.org/pdf/2102.08259" target="_blank">pdf</a>]

<h2>Optimal Mixed Discrete-Continuous Planningfor Linear Hybrid Systems. (arXiv:2102.08261v1 [cs.RO])</h2>
<h3>Jingkai Chen, Brian Williams, Chuchu Fan</h3>
<p>Planning in hybrid systems with both discrete and continuous control
variables is important for dealing with real-world applications such as
extra-planetary exploration and multi-vehicle transportation systems.
Meanwhile, generating high-quality solutions given certain hybrid planning
specifications is crucial to building high-performance hybrid systems. However,
since hybrid planning is challenging in general, most methods use greedy search
that is guided by various heuristics, which is neither complete nor optimal and
often falls into blind search towards an infinite-action plan. In this paper,
we present a hybrid automaton planning formalism and propose an optimal
approach that encodes this planning problem as a Mixed Integer Linear Program
(MILP) by fixing the action number of automaton runs. We also show an extension
of our approach for reasoning over temporally concurrent goals. By leveraging
an efficient MILP optimizer, our method is able to generate provably optimal
solutions for complex mixed discrete-continuous planning problems within a
reasonable time. We use several case studies to demonstrate the extraordinary
performance of our hybrid planning method and show that it outperforms a
state-of-the-art hybrid planner, Scotty, in both efficiency and solution
qualities.
</p>
<a href="http://arxiv.org/abs/2102.08261" target="_blank">arXiv:2102.08261</a> [<a href="http://arxiv.org/pdf/2102.08261" target="_blank">pdf</a>]

<h2>Model-based Meta Reinforcement Learning using Graph Structured Surrogate Models. (arXiv:2102.08291v1 [cs.LG])</h2>
<h3>Qi Wang, Herke van Hoof</h3>
<p>Reinforcement learning is a promising paradigm for solving sequential
decision-making problems, but low data efficiency and weak generalization
across tasks are bottlenecks in real-world applications. Model-based meta
reinforcement learning addresses these issues by learning dynamics and
leveraging knowledge from prior experience. In this paper, we take a closer
look at this framework, and propose a new Thompson-sampling based approach that
consists of a new model to identify task dynamics together with an amortized
policy optimization step. We show that our model, called a graph structured
surrogate model (GSSM), outperforms state-of-the-art methods in predicting
environment dynamics. Additionally, our approach is able to obtain high
returns, while allowing fast execution during deployment by avoiding test time
policy gradient optimization.
</p>
<a href="http://arxiv.org/abs/2102.08291" target="_blank">arXiv:2102.08291</a> [<a href="http://arxiv.org/pdf/2102.08291" target="_blank">pdf</a>]

<h2>Design Iterations for Passive Aerial Manipulator. (arXiv:2102.08306v1 [cs.RO])</h2>
<h3>Vidyadhara B V, Lima Agnel Tony, Mohitvishnu S. Gadde, Shuvrangshu Jana, Varun V. P., Aashay Anil Bhise, Suresh Sundaram, Debasish Ghose</h3>
<p>Grabbing a manoeuvring target using drones is a challenging problem. This
paper presents the design, development, and prototyping of a novel aerial
manipulator for target interception. It is a single Degree of Freedom (DoF)
manipulator with passive basket-type end-effector. The proposed design is
energy efficient, light weight and suitable for aerial grabbing applications.
The detailed design of the proposed manipulation mechanism and a novel
in-flight extending propeller guard, is reported in this paper.
</p>
<a href="http://arxiv.org/abs/2102.08306" target="_blank">arXiv:2102.08306</a> [<a href="http://arxiv.org/pdf/2102.08306" target="_blank">pdf</a>]

<h2>Dynamic neighbourhood optimisation for task allocation using multi-agent. (arXiv:2102.08307v1 [cs.AI])</h2>
<h3>Niall Creech, Natalia Criado Pacheco, Simon Miles</h3>
<p>In large-scale systems there are fundamental challenges when centralised
techniques are used for task allocation. The number of interactions is limited
by resource constraints such as on computation, storage, and network
communication. We can increase scalability by implementing the system as a
distributed task-allocation system, sharing tasks across many agents. However,
this also increases the resource cost of communications and synchronisation,
and is difficult to scale.

In this paper we present four algorithms to solve these problems. The
combination of these algorithms enable each agent to improve their task
allocation strategy through reinforcement learning, while changing how much
they explore the system in response to how optimal they believe their current
strategy is, given their past experience. We focus on distributed agent systems
where the agents' behaviours are constrained by resource usage limits, limiting
agents to local rather than system-wide knowledge. We evaluate these algorithms
in a simulated environment where agents are given a task composed of multiple
subtasks that must be allocated to other agents with differing capabilities, to
then carry out those tasks. We also simulate real-life system effects such as
networking instability. Our solution is shown to solve the task allocation
problem to 6.7% of the theoretical optimal within the system configurations
considered. It provides 5x better performance recovery over no-knowledge
retention approaches when system connectivity is impacted, and is tested
against systems up to 100 agents with less than a 9% impact on the algorithms'
performance.
</p>
<a href="http://arxiv.org/abs/2102.08307" target="_blank">arXiv:2102.08307</a> [<a href="http://arxiv.org/pdf/2102.08307" target="_blank">pdf</a>]

<h2>Adaptive Weighting Scheme for Automatic Time-Series Data Augmentation. (arXiv:2102.08310v1 [cs.LG])</h2>
<h3>Elizabeth Fons, Paula Dawson, Xiao-jun Zeng, John Keane, Alexandros Iosifidis</h3>
<p>Data augmentation methods have been shown to be a fundamental technique to
improve generalization in tasks such as image, text and audio classification.
Recently, automated augmentation methods have led to further improvements on
image classification and object detection leading to state-of-the-art
performances. Nevertheless, little work has been done on time-series data, an
area that could greatly benefit from automated data augmentation given the
usually limited size of the datasets. We present two sample-adaptive automatic
weighting schemes for data augmentation: the first learns to weight the
contribution of the augmented samples to the loss, and the second method
selects a subset of transformations based on the ranking of the predicted
training loss. We validate our proposed methods on a large, noisy financial
dataset and on time-series datasets from the UCR archive. On the financial
dataset, we show that the methods in combination with a trading strategy lead
to improvements in annualized returns of over 50$\%$, and on the time-series
data we outperform state-of-the-art models on over half of the datasets, and
achieve similar performance in accuracy on the others.
</p>
<a href="http://arxiv.org/abs/2102.08310" target="_blank">arXiv:2102.08310</a> [<a href="http://arxiv.org/pdf/2102.08310" target="_blank">pdf</a>]

<h2>Tighter Bounds on the Log Marginal Likelihood of Gaussian Process Regression Using Conjugate Gradients. (arXiv:2102.08314v1 [stat.ML])</h2>
<h3>Artem Artemev, David R. Burt, Mark van der Wilk</h3>
<p>We propose a lower bound on the log marginal likelihood of Gaussian process
regression models that can be computed without matrix factorisation of the full
kernel matrix. We show that approximate maximum likelihood learning of model
parameters by maximising our lower bound retains many of the sparse variational
approach benefits while reducing the bias introduced into parameter learning.
The basis of our bound is a more careful analysis of the log-determinant term
appearing in the log marginal likelihood, as well as using the method of
conjugate gradients to derive tight lower bounds on the term involving a
quadratic form. Our approach is a step forward in unifying methods relying on
lower bound maximisation (e.g. variational methods) and iterative approaches
based on conjugate gradients for training Gaussian processes. In experiments,
we show improved predictive performance with our model for a comparable amount
of training time compared to other conjugate gradient based approaches.
</p>
<a href="http://arxiv.org/abs/2102.08314" target="_blank">arXiv:2102.08314</a> [<a href="http://arxiv.org/pdf/2102.08314" target="_blank">pdf</a>]

<h2>Resource allocation in dynamic multiagent systems. (arXiv:2102.08317v1 [cs.AI])</h2>
<h3>Niall Creech, Natalia Criado Pacheco, Simon Miles</h3>
<p>Resource allocation and task prioritisation are key problem domains in the
fields of autonomous vehicles, networking, and cloud computing. The challenge
in developing efficient and robust algorithms comes from the dynamic nature of
these systems, with many components communicating and interacting in complex
ways. The multi-group resource allocation optimisation (MG-RAO) algorithm we
present uses multiple function approximations of resource demand over time,
alongside reinforcement learning techniques, to develop a novel method of
optimising resource allocation in these multi-agent systems. This method is
applicable where there are competing demands for shared resources, or in task
prioritisation problems. Evaluation is carried out in a simulated environment
containing multiple competing agents. We compare the new algorithm to an
approach where child agents distribute their resources uniformly across all the
tasks they can be allocated. We also contrast the performance of the algorithm
where resource allocation is modelled separately for groups of agents, as to
being modelled jointly over all agents. The MG-RAO algorithm shows a 23 - 28%
improvement over fixed resource allocation in the simulated environments.
Results also show that, in a volatile system, using the MG-RAO algorithm
configured so that child agents model resource allocation for all agents as a
whole has 46.5% of the performance of when it is set to model multiple groups
of agents. These results demonstrate the ability of the algorithm to solve
resource allocation problems in multi-agent systems and to perform well in
dynamic environments.
</p>
<a href="http://arxiv.org/abs/2102.08317" target="_blank">arXiv:2102.08317</a> [<a href="http://arxiv.org/pdf/2102.08317" target="_blank">pdf</a>]

<h2>Instance Localization for Self-supervised Detection Pretraining. (arXiv:2102.08318v1 [cs.CV])</h2>
<h3>Ceyuan Yang, Zhirong Wu, Bolei Zhou, Stephen Lin</h3>
<p>Prior research on self-supervised learning has led to considerable progress
on image classification, but often with degraded transfer performance on object
detection. The objective of this paper is to advance self-supervised pretrained
models specifically for object detection. Based on the inherent difference
between classification and detection, we propose a new self-supervised pretext
task, called instance localization. Image instances are pasted at various
locations and scales onto background images. The pretext task is to predict the
instance category given the composited images as well as the foreground
bounding boxes. We show that integration of bounding boxes into pretraining
promotes better task alignment and architecture alignment for transfer
learning. In addition, we propose an augmentation method on the bounding boxes
to further enhance the feature alignment. As a result, our model becomes weaker
at Imagenet semantic classification but stronger at image patch localization,
with an overall stronger pretrained model for object detection. Experimental
results demonstrate that our approach yields state-of-the-art transfer learning
results for object detection on PASCAL VOC and MSCOCO.
</p>
<a href="http://arxiv.org/abs/2102.08318" target="_blank">arXiv:2102.08318</a> [<a href="http://arxiv.org/pdf/2102.08318" target="_blank">pdf</a>]

<h2>A Cooperative Memory Network for Personalized Task-oriented Dialogue Systems with Incomplete User Profiles. (arXiv:2102.08322v1 [cs.AI])</h2>
<h3>Jiahuan Pei, Pengjie Ren, Maarten de Rijke</h3>
<p>There is increasing interest in developing personalized Task-oriented
Dialogue Systems (TDSs). Previous work on personalized TDSs often assumes that
complete user profiles are available for most or even all users. This is
unrealistic because (1) not everyone is willing to expose their profiles due to
privacy concerns; and (2) rich user profiles may involve a large number of
attributes (e.g., gender, age, tastes, . . .). In this paper, we study
personalized TDSs without assuming that user profiles are complete. We propose
a Cooperative Memory Network (CoMemNN) that has a novel mechanism to gradually
enrich user profiles as dialogues progress and to simultaneously improve
response selection based on the enriched profiles. CoMemNN consists of two core
modules: User Profile Enrichment (UPE) and Dialogue Response Selection (DRS).
The former enriches incomplete user profiles by utilizing collaborative
information from neighbor users as well as current dialogues. The latter uses
the enriched profiles to update the current user query so as to encode more
useful information, based on which a personalized response to a user request is
selected.

We conduct extensive experiments on the personalized bAbI dialogue benchmark
datasets. We find that CoMemNN is able to enrich user profiles effectively,
which results in an improvement of 3.06% in terms of response selection
accuracy compared to state-of-the-art methods. We also test the robustness of
CoMemNN against incompleteness of user profiles by randomly discarding
attribute values from user profiles. Even when discarding 50% of the attribute
values, CoMemNN is able to match the performance of the best performing
baseline without discarding user profiles, showing the robustness of CoMemNN.
</p>
<a href="http://arxiv.org/abs/2102.08322" target="_blank">arXiv:2102.08322</a> [<a href="http://arxiv.org/pdf/2102.08322" target="_blank">pdf</a>]

<h2>Successive Pruning for Model Compression via Rate Distortion Theory. (arXiv:2102.08329v1 [cs.LG])</h2>
<h3>Berivan Isik, Albert No, Tsachy Weissman</h3>
<p>Neural network (NN) compression has become essential to enable deploying
over-parameterized NN models on resource-constrained devices. As a simple and
easy-to-implement method, pruning is one of the most established NN compression
techniques. Although it is a mature method with more than 30 years of history,
there is still a lack of good understanding and systematic analysis of why
pruning works well even with aggressive compression ratios. In this work, we
answer this question by studying NN compression from an information-theoretic
approach and show that rate distortion theory suggests pruning to achieve the
theoretical limits of NN compression. Our derivation also provides an
end-to-end compression pipeline involving a novel pruning strategy. That is, in
addition to pruning the model, we also find a minimum-length binary
representation of it via entropy coding. Our method consistently outperforms
the existing pruning strategies and reduces the pruned model's size by 2.5
times. We evaluate the efficacy of our strategy on MNIST, CIFAR-10 and ImageNet
datasets using 5 distinct architectures.
</p>
<a href="http://arxiv.org/abs/2102.08329" target="_blank">arXiv:2102.08329</a> [<a href="http://arxiv.org/pdf/2102.08329" target="_blank">pdf</a>]

<h2>Learning Invariant Representations using Inverse Contrastive Loss. (arXiv:2102.08343v1 [cs.LG])</h2>
<h3>Aditya Kumar Akash, Vishnu Suresh Lokhande, Sathya N. Ravi, Vikas Singh</h3>
<p>Learning invariant representations is a critical first step in a number of
machine learning tasks. A common approach corresponds to the so-called
information bottleneck principle in which an application dependent function of
mutual information is carefully chosen and optimized. Unfortunately, in
practice, these functions are not suitable for optimization purposes since
these losses are agnostic of the metric structure of the parameters of the
model. We introduce a class of losses for learning representations that are
invariant to some extraneous variable of interest by inverting the class of
contrastive losses, i.e., inverse contrastive loss (ICL). We show that if the
extraneous variable is binary, then optimizing ICL is equivalent to optimizing
a regularized MMD divergence. More generally, we also show that if we are
provided a metric on the sample space, our formulation of ICL can be decomposed
into a sum of convex functions of the given distance metric. Our experimental
results indicate that models obtained by optimizing ICL achieve significantly
better invariance to the extraneous variable for a fixed desired level of
accuracy. In a variety of experimental settings, we show applicability of ICL
for learning invariant representations for both continuous and discrete
extraneous variables.
</p>
<a href="http://arxiv.org/abs/2102.08343" target="_blank">arXiv:2102.08343</a> [<a href="http://arxiv.org/pdf/2102.08343" target="_blank">pdf</a>]

<h2>Topological Deep Learning: Classification Neural Networks. (arXiv:2102.08354v1 [cs.LG])</h2>
<h3>Mustafa Hajij, Kyle Istvan</h3>
<p>Topological deep learning is a formalism that is aimed at introducing
topological language to deep learning for the purpose of utilizing the minimal
mathematical structures to formalize problems that arise in a generic deep
learning problem. This is the first of a sequence of articles with the purpose
of introducing and studying this formalism. In this article, we define and
study the classification problem in machine learning in a topological setting.
Using this topological framework, we show when the classification problem is
possible or not possible in the context of neural networks. Finally, we
demonstrate how our topological setting immediately illuminates aspects of this
problem that are not as readily apparent using traditional tools.
</p>
<a href="http://arxiv.org/abs/2102.08354" target="_blank">arXiv:2102.08354</a> [<a href="http://arxiv.org/pdf/2102.08354" target="_blank">pdf</a>]

<h2>Adversarial Targeted Forgetting in Regularization and Generative Based Continual Learning Models. (arXiv:2102.08355v1 [cs.LG])</h2>
<h3>Muhammad Umer, Robi Polikar</h3>
<p>Continual (or "incremental") learning approaches are employed when additional
knowledge or tasks need to be learned from subsequent batches or from streaming
data. However these approaches are typically adversary agnostic, i.e., they do
not consider the possibility of a malicious attack. In our prior work, we
explored the vulnerabilities of Elastic Weight Consolidation (EWC) to the
perceptible misinformation. We now explore the vulnerabilities of other
regularization-based as well as generative replay-based continual learning
algorithms, and also extend the attack to imperceptible misinformation. We show
that an intelligent adversary can take advantage of a continual learning
algorithm's capabilities of retaining existing knowledge over time, and force
it to learn and retain deliberately introduced misinformation. To demonstrate
this vulnerability, we inject backdoor attack samples into the training data.
These attack samples constitute the misinformation, allowing the attacker to
capture control of the model at test time. We evaluate the extent of this
vulnerability on both rotated and split benchmark variants of the MNIST dataset
under two important domain and class incremental learning scenarios. We show
that the adversary can create a "false memory" about any task by inserting
carefully-designed backdoor samples to the test instances of that task thereby
controlling the amount of forgetting of any task of its choosing. Perhaps most
importantly, we show this vulnerability to be very acute and damaging: the
model memory can be easily compromised with the addition of backdoor samples
into as little as 1\% of the training data, even when the misinformation is
imperceptible to human eye.
</p>
<a href="http://arxiv.org/abs/2102.08355" target="_blank">arXiv:2102.08355</a> [<a href="http://arxiv.org/pdf/2102.08355" target="_blank">pdf</a>]

<h2>Efficient Competitions and Online Learning with Strategic Forecasters. (arXiv:2102.08358v1 [cs.LG])</h2>
<h3>Rafael Frongillo, Robert Gomez, Anish Thilagar, Bo Waggoner</h3>
<p>Winner-take-all competitions in forecasting and machine-learning suffer from
distorted incentives. Witkowskiet al. identified this problem and proposed ELF,
a truthful mechanism to select a winner. We show that, from a pool of $n$
forecasters, ELF requires $\Theta(n\log n)$ events or test data points to
select a near-optimal forecaster with high probability. We then show that
standard online learning algorithms select an $\epsilon$-optimal forecaster
using only $O(\log(n) / \epsilon^2)$ events, by way of a strong
approximate-truthfulness guarantee. This bound matches the best possible even
in the nonstrategic setting. We then apply these mechanisms to obtain the first
no-regret guarantee for non-myopic strategic experts.
</p>
<a href="http://arxiv.org/abs/2102.08358" target="_blank">arXiv:2102.08358</a> [<a href="http://arxiv.org/pdf/2102.08358" target="_blank">pdf</a>]

<h2>Interpretable COVID-19 Chest X-Ray Classification via Orthogonality Constraint. (arXiv:2102.08360v1 [cs.LG])</h2>
<h3>Ella Y. Wang, Anirudh Som, Ankita Shukla, Hongjun Choi, Pavan Turaga</h3>
<p>Deep neural networks have increasingly been used as an auxiliary tool in
healthcare applications, due to their ability to improve performance of several
diagnosis tasks. However, these methods are not widely adopted in clinical
settings due to the practical limitations in the reliability, generalizability,
and interpretability of deep learning based systems. As a result, methods have
been developed that impose additional constraints during network training to
gain more control as well as improve interpretabilty, facilitating their
acceptance in healthcare community. In this work, we investigate the benefit of
using Orthogonal Spheres (OS) constraint for classification of COVID-19 cases
from chest X-ray images. The OS constraint can be written as a simple
orthonormality term which is used in conjunction with the standard
cross-entropy loss during classification network training. Previous studies
have demonstrated significant benefits in applying such constraints to deep
learning models. Our findings corroborate these observations, indicating that
the orthonormality loss function effectively produces improved semantic
localization via GradCAM visualizations, enhanced classification performance,
and reduced model calibration error. Our approach achieves an improvement in
accuracy of 1.6% and 4.8% for two- and three-class classification,
respectively; similar results are found for models with data augmentation
applied. In addition to these findings, our work also presents a new
application of the OS regularizer in healthcare, increasing the post-hoc
interpretability and performance of deep learning models for COVID-19
classification to facilitate adoption of these methods in clinical settings. We
also identify the limitations of our strategy that can be explored for further
research in future.
</p>
<a href="http://arxiv.org/abs/2102.08360" target="_blank">arXiv:2102.08360</a> [<a href="http://arxiv.org/pdf/2102.08360" target="_blank">pdf</a>]

<h2>A Multi-disciplinary Ensemble Algorithm for Clustering Heterogeneous Datasets. (arXiv:2102.08361v1 [cs.LG])</h2>
<h3>Bryar A. Hassan, Tarik A. Rashid</h3>
<p>Clustering is a commonly used method for exploring and analysing data where
the primary objective is to categorise observations into similar clusters. In
recent decades, several algorithms and methods have been developed for
analysing clustered data. We notice that most of these techniques
deterministically define a cluster based on the value of the attributes,
distance, and density of homogenous and single-featured datasets. However,
these definitions are not successful in adding clear semantic meaning to the
clusters produced. Evolutionary operators and statistical and
multi-disciplinary techniques may help in generating meaningful clusters. Based
on this premise, we propose a new evolutionary clustering algorithm (ECAStar)
based on social class ranking and meta-heuristic algorithms for stochastically
analysing heterogeneous and multiple-featured datasets. The ECAStar is
integrated with recombinational evolutionary operators, Levy flight
optimisation, and some statistical techniques, such as quartiles and
percentiles, as well as the Euclidean distance of the K-means algorithm.
Experiments are conducted to evaluate the ECAStar against five conventional
approaches: K-means (KM), K-meansPlusPlus (KMPlusPlus), expectation
maximisation (EM), learning vector quantisation (LVQ), and the genetic
algorithm for clusteringPlusPlus (GENCLUSTPlusPlus).
</p>
<a href="http://arxiv.org/abs/2102.08361" target="_blank">arXiv:2102.08361</a> [<a href="http://arxiv.org/pdf/2102.08361" target="_blank">pdf</a>]

<h2>A Hybrid Approach for Reinforcement Learning Using Virtual Policy Gradient for Balancing an Inverted Pendulum. (arXiv:2102.08362v1 [cs.LG])</h2>
<h3>Dylan Bates</h3>
<p>Using the policy gradient algorithm, we train a single-hidden-layer neural
network to balance a physically accurate simulation of a single inverted
pendulum. The trained weights and biases can then be transferred to a physical
agent, where they are robust enough to to balance a real inverted pendulum.
This hybrid approach of training a simulation allows thousands of trial runs to
be completed orders of magnitude faster than would be possible in the real
world, resulting in greatly reduced training time and more iterations,
producing a more robust model. When compared with existing reinforcement
learning methods, the resulting control is smoother, learned faster, and able
to withstand forced disturbances.
</p>
<a href="http://arxiv.org/abs/2102.08362" target="_blank">arXiv:2102.08362</a> [<a href="http://arxiv.org/pdf/2102.08362" target="_blank">pdf</a>]

<h2>COMBO: Conservative Offline Model-Based Policy Optimization. (arXiv:2102.08363v1 [cs.LG])</h2>
<h3>Tianhe Yu, Aviral Kumar, Rafael Rafailov, Aravind Rajeswaran, Sergey Levine, Chelsea Finn</h3>
<p>Model-based algorithms, which learn a dynamics model from logged experience
and perform some sort of pessimistic planning under the learned model, have
emerged as a promising paradigm for offline reinforcement learning (offline
RL). However, practical variants of such model-based algorithms rely on
explicit uncertainty quantification for incorporating pessimism. Uncertainty
estimation with complex models, such as deep neural networks, can be difficult
and unreliable. We overcome this limitation by developing a new model-based
offline RL algorithm, COMBO, that regularizes the value function on
out-of-support state-action tuples generated via rollouts under the learned
model. This results in a conservative estimate of the value function for
out-of-support state-action tuples, without requiring explicit uncertainty
estimation. We theoretically show that our method optimizes a lower bound on
the true policy value, that this bound is tighter than that of prior methods,
and our approach satisfies a policy improvement guarantee in the offline
setting. Through experiments, we find that COMBO consistently performs as well
or better as compared to prior offline model-free and model-based methods on
widely studied offline RL benchmarks, including image-based tasks.
</p>
<a href="http://arxiv.org/abs/2102.08363" target="_blank">arXiv:2102.08363</a> [<a href="http://arxiv.org/pdf/2102.08363" target="_blank">pdf</a>]

<h2>CTAB-GAN: Effective Table Data Synthesizing. (arXiv:2102.08369v1 [cs.LG])</h2>
<h3>Zilong Zhao, Aditya Kunar, Hiek Van der Scheer, Robert Birke, Lydia Y. Chen</h3>
<p>While data sharing is crucial for knowledge development, privacy concerns and
strict regulation (e.g., European General Data Protection Regulation (GDPR))
unfortunately limit its full effectiveness. Synthetic tabular data emerges as
an alternative to enable data sharing while fulfilling regulatory and privacy
constraints. The state-of-the-art tabular data synthesizers draw methodologies
from generative Adversarial Networks (GAN) and address two main data types in
the industry, i.e., continuous and categorical. In this paper, we develop
CTAB-GAN, a novel conditional table GAN architecture that can effectively model
diverse data types, including a mix of continuous and categorical variables.
Moreover, we address data imbalance and long-tail issues, i.e., certain
variables have drastic frequency differences across large values. To achieve
those aims, we first introduce the information loss and classification loss to
the conditional GAN. Secondly, we design a novel conditional vector, which
efficiently encodes the mixed data type and skewed distribution of data
variable. We extensively evaluate CTAB-GAN with the state of the art GANs that
generate synthetic tables, in terms of data similarity and analysis utility.
The results on five datasets show that the synthetic data of CTAB-GAN
remarkably resembles the real data for all three types of variables and results
into higher accuracy for five machine learning algorithms, by up to 17%.
</p>
<a href="http://arxiv.org/abs/2102.08369" target="_blank">arXiv:2102.08369</a> [<a href="http://arxiv.org/pdf/2102.08369" target="_blank">pdf</a>]

<h2>Analysis of feature learning in weight-tied autoencoders via the mean field lens. (arXiv:2102.08373v1 [cs.LG])</h2>
<h3>Phan-Minh Nguyen</h3>
<p>Autoencoders are among the earliest introduced nonlinear models for
unsupervised learning. Although they are widely adopted beyond research, it has
been a longstanding open problem to understand mathematically the feature
extraction mechanism that trained nonlinear autoencoders provide.

In this work, we make progress in this problem by analyzing a class of
two-layer weight-tied nonlinear autoencoders in the mean field framework. Upon
a suitable scaling, in the regime of a large number of neurons, the models
trained with stochastic gradient descent are shown to admit a mean field
limiting dynamics. This limiting description reveals an asymptotically precise
picture of feature learning by these models: their training dynamics exhibit
different phases that correspond to the learning of different principal
subspaces of the data, with varying degrees of nonlinear shrinkage dependent on
the $\ell_{2}$-regularization and stopping time. While we prove these results
under an idealized assumption of (correlated) Gaussian data, experiments on
real-life data demonstrate an interesting match with the theory.

The autoencoder setup of interests poses a nontrivial mathematical challenge
to proving these results. In this setup, the "Lipschitz" constants of the
models grow with the data dimension $d$. Consequently an adaptation of previous
analyses requires a number of neurons $N$ that is at least exponential in $d$.
Our main technical contribution is a new argument which proves that the
required $N$ is only polynomial in $d$. We conjecture that $N\gg d$ is
sufficient and that $N$ is necessarily larger than a data-dependent intrinsic
dimension, a behavior that is fundamentally different from previously studied
setups.
</p>
<a href="http://arxiv.org/abs/2102.08373" target="_blank">arXiv:2102.08373</a> [<a href="http://arxiv.org/pdf/2102.08373" target="_blank">pdf</a>]

<h2>IntSGD: Floatless Compression of Stochastic Gradients. (arXiv:2102.08374v1 [cs.LG])</h2>
<h3>Konstantin Mishchenko, Bokun Wang, Dmitry Kovalev, Peter Richt&#xe1;rik</h3>
<p>We propose a family of lossy integer compressions for Stochastic Gradient
Descent (SGD) that do not communicate a single float. This is achieved by
multiplying floating-point vectors with a number known to every device and then
rounding to an integer number. Our theory shows that the iteration complexity
of SGD does not change up to constant factors when the vectors are scaled
properly. Moreover, this holds for both convex and non-convex functions, with
and without overparameterization. In contrast to other compression-based
algorithms, ours preserves the convergence rate of SGD even on non-smooth
problems. Finally, we show that when the data is significantly heterogeneous,
it may become increasingly hard to keep the integers bounded and propose an
alternative algorithm, IntDIANA, to solve this type of problems.
</p>
<a href="http://arxiv.org/abs/2102.08374" target="_blank">arXiv:2102.08374</a> [<a href="http://arxiv.org/pdf/2102.08374" target="_blank">pdf</a>]

<h2>Counterfactual Mean Embeddings. (arXiv:1805.08845v3 [stat.ML] UPDATED)</h2>
<h3>Krikamol Muandet, Motonobu Kanagawa, Sorawit Saengkyongam, Sanparith Marukatat</h3>
<p>Counterfactual inference has become a ubiquitous tool in online
advertisement, recommendation systems, medical diagnosis, and econometrics.
Accurate modeling of outcome distributions associated with different
interventions -- known as counterfactual distributions -- is crucial for the
success of these applications. In this work, we propose to model counterfactual
distributions using a novel Hilbert space representation called counterfactual
mean embedding (CME). The CME embeds the associated counterfactual distribution
into a reproducing kernel Hilbert space (RKHS) endowed with a positive definite
kernel, which allows us to perform causal inference over the entire landscape
of the counterfactual distribution. Based on this representation, we propose a
distributional treatment effect (DTE) that can quantify the causal effect over
entire outcome distributions. Our approach is nonparametric as the CME can be
estimated under the unconfoundedness assumption from observational data without
requiring any parametric assumption about the underlying distributions. We also
establish a rate of convergence of the proposed estimator which depends on the
smoothness of the conditional mean and the Radon-Nikodym derivative of the
underlying marginal distributions. Furthermore, our framework allows for more
complex outcomes such as images, sequences, and graphs. Our experimental
results on synthetic data and off-policy evaluation tasks demonstrate the
advantages of the proposed estimator.
</p>
<a href="http://arxiv.org/abs/1805.08845" target="_blank">arXiv:1805.08845</a> [<a href="http://arxiv.org/pdf/1805.08845" target="_blank">pdf</a>]

<h2>Confident Learning: Estimating Uncertainty in Dataset Labels. (arXiv:1911.00068v4 [stat.ML] UPDATED)</h2>
<h3>Curtis G. Northcutt, Lu Jiang, Isaac L. Chuang</h3>
<p>Learning exists in the context of data, yet notions of \emph{confidence}
typically focus on model predictions, not label quality. Confident learning
(CL) is an alternative approach which focuses instead on label quality by
characterizing and identifying label errors in datasets, based on the
principles of pruning noisy data, counting with probabilistic thresholds to
estimate noise, and ranking examples to train with confidence. Whereas numerous
studies have developed these principles independently, here, we combine them,
building on the assumption of a classification noise process to directly
estimate the joint distribution between noisy (given) labels and uncorrupted
(unknown) labels. This results in a generalized CL which is provably consistent
and experimentally performant. We present sufficient conditions where CL
exactly finds label errors, and show CL performance exceeds seven
state-of-the-art approaches for learning with noisy labels on the CIFAR
dataset. The CL framework is \emph{not} coupled to a specific data modality or
model: we use CL to find errors in the presumed error-free MNIST dataset and
improve sentiment classification on text data in Amazon Reviews. We also employ
CL on ImageNet to quantify ontological class overlap (e.g. finding
approximately 645 \emph{missile} images are mislabeled as their parent class
\emph{projectile}), and moderately increase model accuracy (e.g. for ResNet) by
cleaning data prior to training. These results are replicable using the
open-source \texttt{cleanlab} release.
</p>
<a href="http://arxiv.org/abs/1911.00068" target="_blank">arXiv:1911.00068</a> [<a href="http://arxiv.org/pdf/1911.00068" target="_blank">pdf</a>]

<h2>Crypto-Oriented Neural Architecture Design. (arXiv:1911.12322v3 [cs.LG] UPDATED)</h2>
<h3>Avital Shafran, Gil Segev, Shmuel Peleg, Yedid Hoshen</h3>
<p>As neural networks revolutionize many applications, significant privacy
conflicts between model users and providers emerge. The cryptography community
developed a variety of techniques for secure computation to address such
privacy issues. As generic techniques for secure computation are typically
prohibitively ineffective, many efforts focus on optimizing their underlying
cryptographic tools. Differently, we propose to optimize the initial design of
crypto-oriented neural architectures and provide a novel Partial Activation
layer. The proposed layer is much faster for secure computation. Evaluating our
method on three state-of-the-art architectures (SqueezeNet, ShuffleNetV2, and
MobileNetV2) demonstrates significant improvement to the efficiency of secure
inference on common evaluation metrics.
</p>
<a href="http://arxiv.org/abs/1911.12322" target="_blank">arXiv:1911.12322</a> [<a href="http://arxiv.org/pdf/1911.12322" target="_blank">pdf</a>]

<h2>The gap between theory and practice in function approximation with deep neural networks. (arXiv:2001.07523v3 [cs.LG] UPDATED)</h2>
<h3>Ben Adcock, Nick Dexter</h3>
<p>Deep learning (DL) is transforming industry as decision-making processes are
being automated by deep neural networks (DNNs) trained on real-world data.
Driven partly by rapidly-expanding literature on DNN approximation theory
showing they can approximate a rich variety of functions, such tools are
increasingly being considered for problems in scientific computing. Yet, unlike
traditional algorithms in this field, little is known about DNNs from the
principles of numerical analysis, e.g., stability, accuracy, computational
efficiency and sample complexity. In this paper we introduce a computational
framework for examining DNNs in practice, and use it to study empirical
performance with regard to these issues. We study performance of DNNs of
different widths &amp; depths on test functions in various dimensions, including
smooth and piecewise smooth functions. We also compare DL against best-in-class
methods for smooth function approx. based on compressed sensing (CS). Our main
conclusion from these experiments is that there is a crucial gap between the
approximation theory of DNNs and their practical performance, with trained DNNs
performing relatively poorly on functions for which there are strong
approximation results (e.g. smooth functions), yet performing well in
comparison to best-in-class methods for other functions. To analyze this gap
further, we provide some theoretical insights. We establish a practical
existence theorem, asserting existence of a DNN architecture and training
procedure that offers the same performance as CS. This establishes a key
theoretical benchmark, showing the gap can be closed, albeit via a strategy
guaranteed to perform as well as, but no better than, current best-in-class
schemes. Nevertheless, it demonstrates the promise of practical DNN approx., by
highlighting potential for better schemes through careful design of DNN
architectures and training strategies.
</p>
<a href="http://arxiv.org/abs/2001.07523" target="_blank">arXiv:2001.07523</a> [<a href="http://arxiv.org/pdf/2001.07523" target="_blank">pdf</a>]

<h2>Improving Sampling Accuracy of Stochastic Gradient MCMC Methods via Non-uniform Subsampling of Gradients. (arXiv:2002.08949v2 [cs.LG] UPDATED)</h2>
<h3>Ruilin Li, Xin Wang, Hongyuan Zha, Molei Tao</h3>
<p>Stochastic Gradient (SG-)MCMC methods for sampling statistical distributions
approximate gradients by stochastic ones, commonly via uniformly subsampled
data points. We propose a non-uniform subsampling scheme to improve the
sampling accuracy. The proposed exponentially weighted stochastic gradient
(EWSG) is designed so that a non-uniform-SG-MCMC method mimics the statistical
behavior of a batch-gradient-MCMC method, and hence the inaccuracy due to SG
approximation is reduced. EWSG differs from Variance Reduction (VR) techniques
as it focuses on the entire distribution instead of just the variance;
nevertheless, its reduced local variance is also proved. EWSG can also be
viewed as an extension of the importance sampling idea, successful for SG-based
optimizations, to sampling tasks. In our practical implementation of EWSG, the
non-uniform subsampling is performed efficiently via a Metropolis-Hasting chain
on the data index, which is coupled to the MCMC algorithm. Numerical
experiments are provided, not only to demonstrate EWSG's effectiveness, but
also to guide hyperparameter choices, and validate our \emph{non-asymptotic
global error bound} despite of approximations in the implementation. Notably,
while statistical accuracy is improved, convergence speed can be comparable to
the uniform version, which renders EWSG a practical alternative to VR (but EWSG
and VR can be combined too).
</p>
<a href="http://arxiv.org/abs/2002.08949" target="_blank">arXiv:2002.08949</a> [<a href="http://arxiv.org/pdf/2002.08949" target="_blank">pdf</a>]

<h2>Revealing the Structure of Deep Neural Networks via Convex Duality. (arXiv:2002.09773v3 [cs.LG] UPDATED)</h2>
<h3>Tolga Ergen, Mert Pilanci</h3>
<p>We study regularized deep neural networks (DNNs) and introduce a convex
analytic framework to characterize the structure of the hidden layers. We show
that a set of optimal hidden layer weights for a norm regularized DNN training
problem can be explicitly found as the extreme points of a convex set. For the
special case of deep linear networks with $K$ outputs, we prove that each
optimal weight matrix is rank-$K$ and aligns with the previous layers via
duality. More importantly, we apply the same characterization to deep ReLU
networks with whitened data and prove the same weight alignment holds. As a
corollary, we also prove that norm regularized deep ReLU networks yield spline
interpolation for one-dimensional datasets which was previously known only for
two-layer networks. Furthermore, we provide closed-form solutions for the
optimal layer weights when data is rank-one or whitened. The same results also
apply to architectures with batch normalization even for arbitrary data,
therefore, we obtain a complete explanation for a recent empirical observation
termed Neural Collapse where class means collapse to the vertices of a simplex
equiangular tight frame.
</p>
<a href="http://arxiv.org/abs/2002.09773" target="_blank">arXiv:2002.09773</a> [<a href="http://arxiv.org/pdf/2002.09773" target="_blank">pdf</a>]

<h2>Modeling of Spatio-Temporal Hawkes Processes with Randomized Kernels. (arXiv:2003.03671v2 [cs.LG] UPDATED)</h2>
<h3>Fatih Ilhan, Suleyman Serdar Kozat</h3>
<p>We investigate spatio-temporal event analysis using point processes.
Inferring the dynamics of event sequences spatiotemporally has many practical
applications including crime prediction, social media analysis, and traffic
forecasting. In particular, we focus on spatio-temporal Hawkes processes that
are commonly used due to their capability to capture excitations between event
occurrences. We introduce a novel inference framework based on randomized
transformations and gradient descent to learn the process. We replace the
spatial kernel calculations by randomized Fourier feature-based
transformations. The introduced randomization by this representation provides
flexibility while modeling the spatial excitation between events. Moreover, the
system described by the process is expressed within closed-form in terms of
scalable matrix operations. During the optimization, we use maximum likelihood
estimation approach and gradient descent while properly handling positivity and
orthonormality constraints. The experiment results show the improvements
achieved by the introduced method in terms of fitting capability in synthetic
and real datasets with respect to the conventional inference methods in the
spatio-temporal Hawkes process literature. We also analyze the triggering
interactions between event types and how their dynamics change in space and
time through the interpretation of learned parameters.
</p>
<a href="http://arxiv.org/abs/2003.03671" target="_blank">arXiv:2003.03671</a> [<a href="http://arxiv.org/pdf/2003.03671" target="_blank">pdf</a>]

<h2>Handling new target classes in semantic segmentation with domain adaptation. (arXiv:2004.01130v2 [cs.CV] UPDATED)</h2>
<h3>Maxime Bucher, Tuan-Hung Vu, Matthieu Cord, Patrick P&#xe9;rez</h3>
<p>In this work, we define and address a novel domain adaptation (DA) problem in
semantic scene segmentation, where the target domain not only exhibits a data
distribution shift w.r.t. the source domain, but also includes novel classes
that do not exist in the latter. Different to "open-set" and "universal domain
adaptation", which both regard all objects from new classes as "unknown", we
aim at explicit test-time prediction for these new classes. To reach this goal,
we propose a framework that leverages domain adaptation and zero-shot learning
techniques to enable "boundless" adaptation in the target domain. It relies on
a novel architecture, along with a dedicated learning scheme, to bridge the
source-target domain gap while learning how to map new classes' labels to
relevant visual representations. The performance is further improved using
self-training on target-domain pseudo-labels. For validation, we consider
different domain adaptation set-ups, namely synthetic-2-real, country-2-country
and dataset-2-dataset. Our framework outperforms the baselines by significant
margins, setting competitive standards on all benchmarks for the new task. Code
and models are available at https://github.com/valeoai/buda.
</p>
<a href="http://arxiv.org/abs/2004.01130" target="_blank">arXiv:2004.01130</a> [<a href="http://arxiv.org/pdf/2004.01130" target="_blank">pdf</a>]

<h2>CWY Parametrization: a Solution for Parallelized Optimization of Orthogonal and Stiefel Matrices. (arXiv:2004.08675v3 [cs.LG] UPDATED)</h2>
<h3>Valerii Likhosherstov, Jared Davis, Krzysztof Choromanski, Adrian Weller</h3>
<p>We introduce an efficient approach for optimization over orthogonal groups on
highly parallel computation units such as GPUs or TPUs. As in earlier work, we
parametrize an orthogonal matrix as a product of Householder reflections.
However, to overcome low parallelization capabilities of computing Householder
reflections sequentially, we propose employing an accumulation scheme called
the compact WY (or CWY) transform -- a compact parallelization-friendly matrix
representation for the series of Householder reflections. We further develop a
novel Truncated CWY (or T-CWY) approach for Stiefel manifold parametrization
which has a competitive complexity and, again, yields benefits when computed on
GPUs and TPUs. We prove that our CWY and T-CWY methods lead to convergence to a
stationary point of the training objective when coupled with stochastic
gradient descent. We apply our methods to train recurrent neural network
architectures in the tasks of neural machine translation and video prediction.
</p>
<a href="http://arxiv.org/abs/2004.08675" target="_blank">arXiv:2004.08675</a> [<a href="http://arxiv.org/pdf/2004.08675" target="_blank">pdf</a>]

<h2>Graph-based State Representation for Deep Reinforcement Learning. (arXiv:2004.13965v3 [cs.LG] UPDATED)</h2>
<h3>Vikram Waradpande, Daniel Kudenko, Megha Khosla</h3>
<p>Deep RL approaches build much of their success on the ability of the deep
neural network to generate useful internal representations. Nevertheless, they
suffer from a high sample-complexity and starting with a good input
representation can have a significant impact on the performance. In this paper,
we exploit the fact that the underlying Markov decision process (MDP)
represents a graph, which enables us to incorporate the topological information
for effective state representation learning.

Motivated by the recent success of node representations for several graph
analytical tasks we specifically investigate the capability of node
representation learning methods to effectively encode the topology of the
underlying MDP in Deep RL. To this end we perform a comparative analysis of
several models chosen from 4 different classes of representation learning
algorithms for policy learning in grid-world navigation tasks, which are
representative of a large class of RL problems. We find that all embedding
methods outperform the commonly used matrix representation of grid-world
environments in all of the studied cases. Moreoever, graph convolution based
methods are outperformed by simpler random walk based methods and graph linear
autoencoders.
</p>
<a href="http://arxiv.org/abs/2004.13965" target="_blank">arXiv:2004.13965</a> [<a href="http://arxiv.org/pdf/2004.13965" target="_blank">pdf</a>]

<h2>Explaining the Behavior of Black-Box Prediction Algorithms with Causal Learning. (arXiv:2006.02482v2 [cs.LG] UPDATED)</h2>
<h3>Numair Sani, Daniel Malinsky, Ilya Shpitser</h3>
<p>We propose to explain the behavior of black-box prediction methods (e.g.,
deep neural networks trained on image pixel data) using causal graphical
models. Specifically, we explore learning the structure of a causal graph where
the nodes represent prediction outcomes along with a set of macro-level
"interpretable" features, while allowing for arbitrary unmeasured confounding
among these variables. The resulting graph may indicate which of the
interpretable features, if any, are possible causes of the prediction outcome
and which may be merely associated with prediction outcomes due to confounding.
The approach is motivated by a counterfactual theory of causal explanation
wherein good explanations point to factors which are "difference-makers" in an
interventionist sense. The resulting analysis may be useful in algorithm
auditing and evaluation, by identifying features which make a causal difference
to the algorithm's output.
</p>
<a href="http://arxiv.org/abs/2006.02482" target="_blank">arXiv:2006.02482</a> [<a href="http://arxiv.org/pdf/2006.02482" target="_blank">pdf</a>]

<h2>Fair Classification with Noisy Protected Attributes: A Framework with Provable Guarantees. (arXiv:2006.04778v3 [cs.LG] UPDATED)</h2>
<h3>L. Elisa Celis, Lingxiao Huang, Vijay Keswani, Nisheeth K. Vishnoi</h3>
<p>We present an optimization framework for learning a fair classifier in the
presence of noisy perturbations in the protected attributes. Compared to prior
work, our framework can be employed with a very general class of linear and
linear-fractional fairness constraints, can handle multiple, non-binary
protected attributes, and outputs a classifier that comes with provable
guarantees on both accuracy and fairness. Empirically, we show that our
framework can be used to attain either statistical rate or false positive rate
fairness guarantees with a minimal loss in accuracy, even when the noise is
large, in two real-world datasets.
</p>
<a href="http://arxiv.org/abs/2006.04778" target="_blank">arXiv:2006.04778</a> [<a href="http://arxiv.org/pdf/2006.04778" target="_blank">pdf</a>]

<h2>Emergent Properties of Foveated Perceptual Systems. (arXiv:2006.07991v2 [cs.CV] UPDATED)</h2>
<h3>Arturo Deza, Talia Konkle</h3>
<p>The goal of this work is to characterize the representational impact that
foveation operations have for machine vision systems, inspired by the foveated
human visual system, which has higher acuity at the center of gaze and a
texture-like encoding mechanism in the periphery. To do so, we introduce models
consisting of a first-stage \textit{fixed} image transform followed by a
second-stage \textit{learnable} convolutional neural network, and we varied the
first stage component. The primary model has a foveated-textural input stage,
which we compare to a model with foveated-blurred input and a model with
spatially-uniform blurred input (both matched for perceptual compression), and
a final reference model with minimal input-based compression. We find that the
model with foveated texture-based input -- most akin to the human visual system
-- shows similar scene classification accuracy as the reference model despite
its compressed input, with greater i.i.d. generalization than the other models.
Second, the foveated-texture model maintains sensitivity to high-spatial
frequency information and greater robustness to occlusion properties, similar
to the reference, and unlike the comparison models. Finally, both the foveated
systems, either texture or blur-based, show a stronger center image-bias
relative to the spatially-uniform systems. These results demonstrate that
foveation with peripheral texture-based computations yields an efficient,
distinct, and robust representational format of scene information, and provides
computational insight into the representational consequences that texture-based
peripheral encoding may have for processing in the human visual system.
</p>
<a href="http://arxiv.org/abs/2006.07991" target="_blank">arXiv:2006.07991</a> [<a href="http://arxiv.org/pdf/2006.07991" target="_blank">pdf</a>]

<h2>Domain Adaptation with Joint Learning for Generic, Optical Car Part Recognition and Detection Systems (Go-CaRD). (arXiv:2006.08521v2 [cs.CV] UPDATED)</h2>
<h3>Lukas Stappen, Xinchen Du, Vincent Karas, Stefan M&#xfc;ller, Bj&#xf6;rn W. Schuller</h3>
<p>Systems for the automatic recognition and detection of automotive parts are
crucial in several emerging research areas in the development of intelligent
vehicles. They enable, for example, the detection and modelling of interactions
between human and the vehicle. In this paper, we quantitatively and
qualitatively explore the efficacy of deep learning architectures for the
classification and localisation of 29 interior and exterior vehicle regions on
three novel datasets. Furthermore, we experiment with joint and transfer
learning approaches across datasets and point out potential applications of our
systems. Our best network architecture achieves an F1 score of 93.67 % for
recognition, while our best localisation approach utilising state-of-the-art
backbone networks achieve a mAP of 63.01 % for detection. The MuSe-CAR-Part
dataset, which is based on a large variety of human-car interactions in videos,
the weights of the best models, and the code is publicly available to academic
parties for benchmarking and future research.
</p>
<a href="http://arxiv.org/abs/2006.08521" target="_blank">arXiv:2006.08521</a> [<a href="http://arxiv.org/pdf/2006.08521" target="_blank">pdf</a>]

<h2>The Reflectron: Exploiting geometry for learning generalized linear models. (arXiv:2006.08575v3 [cs.LG] UPDATED)</h2>
<h3>Nicholas M. Boffi, Stephen Tu, Jean-Jacques E. Slotine</h3>
<p>We present the Reflectron, a family of pseudogradient methods for learning
generalized linear models inspired by mirror descent. Despite nonconvexity of
the underlying optimization problem, we prove that the Reflectron is both
statistically and computationally efficient. By analogy to standard mirror
descent, we show that the methods can be tailored to the $\textit{problem
geometry}$ through choice of a potential function that defines the
$\textit{optimization geometry}$. We provide guarantees in both the stochastic
and full-batch settings, and our analysis recovers gradient descent and the
GLM-tron of Kakade et al. (2011) as special cases. Via a natural
continuous-time limit, we provide simple and intuitive derivations of the
statistical, convergence, and implicit bias properties of the algorithms. We
subsequently discretize the flow to arrive at an iteration with matching
guarantees. Experimentally, the extra flexibility afforded by the Reflectron
allows it to outperform the GLM-tron on sparse vector and low-rank matrix
recovery problems.
</p>
<a href="http://arxiv.org/abs/2006.08575" target="_blank">arXiv:2006.08575</a> [<a href="http://arxiv.org/pdf/2006.08575" target="_blank">pdf</a>]

<h2>OMBA: User-Guided Product Representations for Online Market Basket Analysis. (arXiv:2006.10396v2 [cs.LG] UPDATED)</h2>
<h3>Amila Silva, Ling Luo, Shanika Karunasekera, Christopher Leckie</h3>
<p>Market Basket Analysis (MBA) is a popular technique to identify associations
between products, which is crucial for business decision making. Previous
studies typically adopt conventional frequent itemset mining algorithms to
perform MBA. However, they generally fail to uncover rarely occurring
associations among the products at their most granular level. Also, they have
limited ability to capture temporal dynamics in associations between products.
Hence, we propose OMBA, a novel representation learning technique for Online
Market Basket Analysis. OMBA jointly learns representations for products and
users such that they preserve the temporal dynamics of product-to-product and
user-to-product associations. Subsequently, OMBA proposes a scalable yet
effective online method to generate products' associations using their
representations. Our extensive experiments on three real-world datasets show
that OMBA outperforms state-of-the-art methods by as much as 21%, while
emphasizing rarely occurring strong associations and effectively capturing
temporal changes in associations.
</p>
<a href="http://arxiv.org/abs/2006.10396" target="_blank">arXiv:2006.10396</a> [<a href="http://arxiv.org/pdf/2006.10396" target="_blank">pdf</a>]

<h2>Graph Backdoor. (arXiv:2006.11890v3 [cs.LG] UPDATED)</h2>
<h3>Zhaohan Xi, Ren Pang, Shouling Ji, Ting Wang</h3>
<p>One intriguing property of deep neural networks (DNNs) is their inherent
vulnerability to backdoor attacks -- a trojaned model responds to
trigger-embedded inputs in a highly predictable manner while functioning
normally otherwise. Surprisingly, despite the plethora of prior work on DNNs
for continuous data (e.g., images), little is known about the vulnerability of
graph neural networks (GNNs) for discrete-structured data (e.g., graphs), which
is highly concerning given their increasing use in security-sensitive domains.

To bridge this gap, we present GTA, the first backdoor attack on GNNs.
Compared with prior work, GTA departs in significant ways: graph-oriented -- it
defines triggers as specific subgraphs, including both topological structures
and descriptive features, entailing a large design spectrum for the adversary;
input-tailored -- it dynamically adapts triggers to individual graphs, thereby
optimizing both attack effectiveness and evasiveness; downstream model-agnostic
-- it can be readily launched without knowledge regarding downstream models or
fine-tuning strategies; and attack-extensible -- it can be instantiated for
both transductive (e.g., node classification) and inductive (e.g., graph
classification) tasks, constituting severe threats for a range of
security-critical applications (e.g., toxic chemical classification). Through
extensive evaluation using benchmark datasets and state-of-the-art models, we
demonstrate the effectiveness of GTA: for instance, on pre-trained,
off-the-shelf GNNs, GTA attains over 99.2% attack success rate with less than
0.3% accuracy drop. We further provide analytical justification for its
effectiveness and discuss potential countermeasures, pointing to several
promising research directions.
</p>
<a href="http://arxiv.org/abs/2006.11890" target="_blank">arXiv:2006.11890</a> [<a href="http://arxiv.org/pdf/2006.11890" target="_blank">pdf</a>]

<h2>Convex Regularization in Monte-Carlo Tree Search. (arXiv:2007.00391v3 [cs.LG] UPDATED)</h2>
<h3>Tuan Dam, Carlo D&#x27;Eramo, Jan Peters, Joni Pajarinen</h3>
<p>Monte-Carlo planning and Reinforcement Learning (RL) are essential to
sequential decision making. The recent AlphaGo and AlphaZero algorithms have
shown how to successfully combine these two paradigms in order to solve large
scale sequential decision problems. These methodologies exploit a variant of
the well-known UCT algorithm to trade off exploitation of good actions and
exploration of unvisited states, but their empirical success comes at the cost
of poor sample-efficiency and high computation time. In this paper, we overcome
these limitations by considering convex regularization in Monte-Carlo Tree
Search (MCTS), which has been successfully used in RL to efficiently drive
exploration. First, we introduce a unifying theory on the use of generic convex
regularizers in MCTS, deriving the regret analysis and providing guarantees of
exponential convergence rate. Second, we exploit our theoretical framework to
introduce novel regularized backup operators for MCTS, based on the relative
entropy of the policy update, and on the Tsallis entropy of the policy.
Finally, we empirically evaluate the proposed operators in AlphaGo and
AlphaZero on problems of increasing dimensionality and branching factor, from a
toy problem to several Atari games, showing their superiority w.r.t.
representative baselines.
</p>
<a href="http://arxiv.org/abs/2007.00391" target="_blank">arXiv:2007.00391</a> [<a href="http://arxiv.org/pdf/2007.00391" target="_blank">pdf</a>]

<h2>Adaptive Gradient Methods for Constrained Convex Optimization and Variational Inequalities. (arXiv:2007.08840v3 [cs.LG] UPDATED)</h2>
<h3>Alina Ene, Huy L. Nguyen, Adrian Vladu</h3>
<p>We provide new adaptive first-order methods for constrained convex
optimization. Our main algorithms AdaACSA and AdaAGD+ are accelerated methods,
which are universal in the sense that they achieve nearly-optimal convergence
rates for both smooth and non-smooth functions, even when they only have access
to stochastic gradients. In addition, they do not require any prior knowledge
on how the objective function is parametrized, since they automatically adjust
their per-coordinate learning rate. These can be seen as truly accelerated
Adagrad methods for constrained optimization.

We complement them with a simpler algorithm AdaGrad+ which enjoys the same
features, and achieves the standard non-accelerated convergence rate. We also
present a set of new results involving adaptive methods for unconstrained
optimization and monotone operators.
</p>
<a href="http://arxiv.org/abs/2007.08840" target="_blank">arXiv:2007.08840</a> [<a href="http://arxiv.org/pdf/2007.08840" target="_blank">pdf</a>]

<h2>Monocular Instance Motion Segmentation for Autonomous Driving: KITTI InstanceMotSeg Dataset and Multi-task Baseline. (arXiv:2008.07008v3 [cs.CV] UPDATED)</h2>
<h3>Eslam Mohamed, Mahmoud Ewaisha, Mennatullah Siam, Hazem Rashed, Senthil Yogamani, Waleed Hamdy, Muhammad Helmi, Ahmad El-Sallab</h3>
<p>Moving object segmentation is a crucial task for autonomous vehicles as it
can be used to segment objects in a class agnostic manner based on their motion
cues. It enables the detection of unseen objects during training (e.g., moose
or a construction truck) based on their motion and independent of their
appearance. Although pixel-wise motion segmentation has been studied in
autonomous driving literature, it has been rarely addressed at the instance
level, which would help separate connected segments of moving objects leading
to better trajectory planning. As the main issue is the lack of large public
datasets, we create a new InstanceMotSeg dataset comprising of 12.9K samples
improving upon our KITTIMoSeg dataset. In addition to providing instance level
annotations, we have added 4 additional classes which is crucial for studying
class agnostic motion segmentation. We adapt YOLACT and implement a
motion-based class agnostic instance segmentation model which would act as a
baseline for the dataset. We also extend it to an efficient multi-task model
which additionally provides semantic instance segmentation sharing the encoder.
The model then learns separate prototype coefficients within the class agnostic
and semantic heads providing two independent paths of object detection for
redundant safety. To obtain real-time performance, we study different efficient
encoders and obtain 39 fps on a Titan Xp GPU using MobileNetV2 with an
improvement of 10% mAP relative to the baseline. Our model improves the
previous state of the art motion segmentation method by 3.3%. The dataset and
qualitative results video are shared in our website at
https://sites.google.com/view/instancemotseg/.
</p>
<a href="http://arxiv.org/abs/2008.07008" target="_blank">arXiv:2008.07008</a> [<a href="http://arxiv.org/pdf/2008.07008" target="_blank">pdf</a>]

<h2>Generative Design by Reinforcement Learning: Enhancing the Diversity of Topology Optimization Designs. (arXiv:2008.07119v2 [cs.CV] UPDATED)</h2>
<h3>Seowoo Jang, Soyoung Yoo, Namwoo Kang</h3>
<p>Generative design refers to computational design methods that can
automatically conduct design exploration under constraints defined by
designers. Among many approaches, topology optimization-based generative
designs aim to explore diverse topology designs, which cannot be represented by
conventional parametric design approaches. Recently, data-driven topology
optimization research has started to exploit artificial intelligence, such as
deep learning or machine learning, to improve the capability of design
exploration. This study proposes a reinforcement learning (RL) based generative
design process, with reward functions maximizing the diversity of topology
designs. We formulate generative design as a sequential problem of finding
optimal design parameter combinations in accordance with a given reference
design. Proximal Policy Optimization is used as the learning framework, which
is demonstrated in the case study of an automotive wheel design problem. To
reduce the heavy computational burden of the wheel topology optimization
process required by our RL formulation, we approximate the optimization process
with neural networks. With efficient data preprocessing/augmentation and neural
architecture, the neural networks achieve a generalized performance and
symmetricity-reserving characteristics. We show that RL-based generative design
produces a large number of diverse designs within a short inference time by
exploiting GPU in a fully automated manner. It is different from the previous
approach using CPU which takes much more processing time and involving human
intervention.
</p>
<a href="http://arxiv.org/abs/2008.07119" target="_blank">arXiv:2008.07119</a> [<a href="http://arxiv.org/pdf/2008.07119" target="_blank">pdf</a>]

<h2>Variational Deep Learning for the Identification and Reconstruction of Chaotic and Stochastic Dynamical Systems from Noisy and Partial Observations. (arXiv:2009.02296v6 [cs.LG] UPDATED)</h2>
<h3>Duong Nguyen, Said Ouala, Lucas Drumetz, Ronan Fablet</h3>
<p>The data-driven recovery of the unknown governing equations of dynamical
systems has recently received an increasing interest. However, the
identification of governing equations remains challenging when dealing with
noisy and partial observations. Here, we address this challenge and investigate
variational deep learning schemes. Within the proposed framework, we jointly
learn an inference model to reconstruct the true states of the system and the
governing laws of these states from series of noisy and partial data. In doing
so, this framework bridges classical data assimilation and state-of-the-art
machine learning techniques. We also demonstrate that it generalises
state-of-the-art methods. Importantly, both the inference model and the
governing model embed stochastic components to account for stochastic
variabilities, model errors, and reconstruction uncertainties. Various
experiments on chaotic and stochastic dynamical systems support the relevance
of our scheme w.r.t. state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2009.02296" target="_blank">arXiv:2009.02296</a> [<a href="http://arxiv.org/pdf/2009.02296" target="_blank">pdf</a>]

<h2>GraphNorm: A Principled Approach to Accelerating Graph Neural Network Training. (arXiv:2009.03294v2 [cs.LG] UPDATED)</h2>
<h3>Tianle Cai, Shengjie Luo, Keyulu Xu, Di He, Tie-Yan Liu, Liwei Wang</h3>
<p>Normalization is known to help the optimization of deep neural networks.
Curiously, different architectures require specialized normalization methods.
In this paper, we study what normalization is effective for Graph Neural
Networks (GNNs). First, we adapt and evaluate the existing methods from other
domains to GNNs. Faster convergence is achieved with InstanceNorm compared to
BatchNorm and LayerNorm. We provide an explanation by showing that InstanceNorm
serves as a preconditioner for GNNs, but such preconditioning effect is weaker
with BatchNorm due to the heavy batch noise in graph datasets. Second, we show
that the shift operation in InstanceNorm results in an expressiveness
degradation of GNNs for highly regular graphs. We address this issue by
proposing GraphNorm with a learnable shift. Empirically, GNNs with GraphNorm
converge faster compared to GNNs using other normalization. GraphNorm also
improves the generalization of GNNs, achieving better performance on graph
classification benchmarks.
</p>
<a href="http://arxiv.org/abs/2009.03294" target="_blank">arXiv:2009.03294</a> [<a href="http://arxiv.org/pdf/2009.03294" target="_blank">pdf</a>]

<h2>DANCE: Differentiable Accelerator/Network Co-Exploration. (arXiv:2009.06237v3 [cs.LG] UPDATED)</h2>
<h3>Kanghyun Choi, Deokki Hong, Hojae Yoon, Joonsang Yu, Youngsok Kim, Jinho Lee</h3>
<p>To cope with the ever-increasing computational demand of the DNN execution,
recent neural architecture search (NAS) algorithms consider hardware cost
metrics into account, such as GPU latency. To further pursue a fast, efficient
execution, DNN-specialized hardware accelerators are being designed for
multiple purposes, which far-exceeds the efficiency of the GPUs. However, those
hardware-related metrics have been proven to exhibit non-linear relationships
with the network architectures. Therefore it became a chicken-and-egg problem
to optimize the network against the accelerator, or to optimize the accelerator
against the network. In such circumstances, this work presents DANCE, a
differentiable approach towards the co-exploration of the hardware accelerator
and network architecture design. At the heart of DANCE is a differentiable
evaluator network. By modeling the hardware evaluation software with a neural
network, the relation between the accelerator architecture and the hardware
metrics becomes differentiable, allowing the search to be performed with
backpropagation. Compared to the naive existing approaches, our method performs
co-exploration in a significantly shorter time, while achieving superior
accuracy and hardware cost metrics.
</p>
<a href="http://arxiv.org/abs/2009.06237" target="_blank">arXiv:2009.06237</a> [<a href="http://arxiv.org/pdf/2009.06237" target="_blank">pdf</a>]

<h2>Agent Environment Cycle Games. (arXiv:2009.13051v2 [cs.LG] UPDATED)</h2>
<h3>Justin K Terry, Nathaniel Grammel, Benjamin Black, Ananth Hari, Caroline Horsch, Luis Santos</h3>
<p>Partially Observable Stochastic Games (POSGs) are the most general and common
model of games used in Multi-Agent Reinforcement Learning (MARL). We argue that
the POSG model is conceptually ill suited to software MARL environments, and
offer case studies from the literature where this mismatch has led to severely
unexpected behavior. In response to this, we introduce the Agent Environment
Cycle Games (AEC Games) model, which is more representative of software
implementation. We then prove it's as an equivalent model to POSGs. The AEC
games model is also uniquely useful in that it can elegantly represent both all
forms of MARL environments, whereas for example POSGs cannot elegantly
represent strictly turn based games like chess.
</p>
<a href="http://arxiv.org/abs/2009.13051" target="_blank">arXiv:2009.13051</a> [<a href="http://arxiv.org/pdf/2009.13051" target="_blank">pdf</a>]

<h2>Exponential Lower Bounds for Planning in MDPs With Linearly-Realizable Optimal Action-Value Functions. (arXiv:2010.01374v2 [cs.LG] UPDATED)</h2>
<h3>Gell&#xe9;rt Weisz, Philip Amortila, Csaba Szepesv&#xe1;ri</h3>
<p>We consider the problem of local planning in fixed-horizon and discounted
Markov Decision Processes (MDPs) with linear function approximation and a
generative model under the assumption that the optimal action-value function
lies in the span of a feature map that is available to the planner. Previous
work has left open the question of whether there exist sound planners that need
only poly(H,d) queries regardless of the MDP, where H is the horizon and d is
the dimensionality of the features. We answer this question in the negative: we
show that any sound planner must query at least $\min(\exp({\Omega}(d)),
{\Omega}(2^H))$ samples in the fized-horizon setting and $\exp({\Omega}(d))$
samples in the discounted setting. We also show that for any ${\delta}&gt;0$, the
least-squares value iteration algorithm with $O(H^5d^{H+1}/{\delta}^2)$ queries
can compute a ${\delta}$-optimal policy in the fixed-horizon setting. We
discuss implications and remaining open questions.
</p>
<a href="http://arxiv.org/abs/2010.01374" target="_blank">arXiv:2010.01374</a> [<a href="http://arxiv.org/pdf/2010.01374" target="_blank">pdf</a>]

<h2>Voting-based Approaches For Differentially Private Federated Learning. (arXiv:2010.04851v2 [cs.LG] UPDATED)</h2>
<h3>Yuqing Zhu, Xiang Yu, Yi-Hsuan Tsai, Francesco Pittaluga, Masoud Faraki, Manmohan chandraker, Yu-Xiang Wang</h3>
<p>Differentially Private Federated Learning (DPFL) is an emerging field with
many applications. Gradient averaging based DPFL methods require costly
communication rounds and hardly work with large-capacity models, due to the
explicit dimension dependence in its added noise. In this work, inspired by
knowledge transfer non-federated privacy learning from Papernot et al.(2017;
2018), we design two new DPFL schemes, by voting among the data labels returned
from each local model, instead of averaging the gradients, which avoids the
dimension dependence and significantly reduces the communication cost.
Theoretically, by applying secure multi-party computation, we could
exponentially amplify the (data-dependent) privacy guarantees when the margin
of the voting scores are large. Extensive experiments show that our approaches
significantly improve the privacy-utility trade-off over the state-of-the-arts
in DPFL.
</p>
<a href="http://arxiv.org/abs/2010.04851" target="_blank">arXiv:2010.04851</a> [<a href="http://arxiv.org/pdf/2010.04851" target="_blank">pdf</a>]

<h2>Correlation Filter for UAV-Based Aerial Tracking: A Review and Experimental Evaluation. (arXiv:2010.06255v4 [cs.CV] UPDATED)</h2>
<h3>Changhong Fu, Bowen Li, Fangqiang Ding, Fuling Lin, Geng Lu</h3>
<p>Aerial tracking, which has exhibited its omnipresent dedication and splendid
performance, is one of the most active applications in the remote sensing
field. Especially, unmanned aerial vehicle (UAV)-based remote sensing system,
equipped with a visual tracking approach, has been widely used in aviation,
navigation, agriculture,transportation, and public security, etc. As is
mentioned above, the UAV-based aerial tracking platform has been gradually
developed from research to practical application stage, reaching one of the
main aerial remote sensing technologies in the future. However, due to the
real-world onerous situations, e.g., harsh external challenges, the vibration
of the UAV mechanical structure (especially under strong wind conditions), the
maneuvering flight in complex environment, and the limited computation
resources onboard, accuracy, robustness, and high efficiency are all crucial
for the onboard tracking methods. Recently, the discriminative correlation
filter (DCF)-based trackers have stood out for their high computational
efficiency and appealing robustness on a single CPU, and have flourished in the
UAV visual tracking community. In this work, the basic framework of the
DCF-based trackers is firstly generalized, based on which, 23 state-of-the-art
DCF-based trackers are orderly summarized according to their innovations for
solving various issues. Besides, exhaustive and quantitative experiments have
been extended on various prevailing UAV tracking benchmarks, i.e., UAV123,
UAV123@10fps, UAV20L, UAVDT, DTB70, and VisDrone2019-SOT, which contain 371,903
frames in total. The experiments show the performance, verify the feasibility,
and demonstrate the current challenges of DCF-based trackers onboard UAV
tracking.
</p>
<a href="http://arxiv.org/abs/2010.06255" target="_blank">arXiv:2010.06255</a> [<a href="http://arxiv.org/pdf/2010.06255" target="_blank">pdf</a>]

<h2>Cross-Domain Few-Shot Learning by Representation Fusion. (arXiv:2010.06498v2 [cs.LG] UPDATED)</h2>
<h3>Thomas Adler, Johannes Brandstetter, Michael Widrich, Andreas Mayr, David Kreil, Michael Kopp, G&#xfc;nter Klambauer, Sepp Hochreiter</h3>
<p>In order to quickly adapt to new data, few-shot learning aims at learning
from few examples, often by using already acquired knowledge. The new data
often differs from the previously seen data due to a domain shift, that is, a
change of the input-target distribution. While several methods perform well on
small domain shifts like new target classes with similar inputs, larger domain
shifts are still challenging. Large domain shifts may result in high-level
concepts that are not shared between the original and the new domain, whereas
low-level concepts like edges in images might still be shared and useful. For
cross-domain few-shot learning, we suggest representation fusion to unify
different abstraction levels of a deep neural network into one representation.
We propose Cross-domain Hebbian Ensemble Few-shot learning (CHEF), which
achieves representation fusion by an ensemble of Hebbian learners acting on
different layers of a deep neural network. Ablation studies show that
representation fusion is a decisive factor to boost cross-domain few-shot
learning. On the few-shot datasets miniImagenet and tieredImagenet with small
domain shifts, CHEF is competitive with state-of-the-art methods. On
cross-domain few-shot benchmark challenges with larger domain shifts, CHEF
establishes novel state-of-the-art results in all categories. We further apply
CHEF on a real-world cross-domain application in drug discovery. We consider a
domain shift from bioactive molecules to environmental chemicals and drugs with
twelve associated toxicity prediction tasks. On these tasks, that are highly
relevant for computational drug discovery, CHEF significantly outperforms all
its competitors. Github: https://github.com/ml-jku/chef
</p>
<a href="http://arxiv.org/abs/2010.06498" target="_blank">arXiv:2010.06498</a> [<a href="http://arxiv.org/pdf/2010.06498" target="_blank">pdf</a>]

<h2>Local SGD for Saddle-Point Problems. (arXiv:2010.13112v2 [cs.LG] UPDATED)</h2>
<h3>Aleksandr Beznosikov, Valentin Samokhin, Alexander Gasnikov</h3>
<p>GAN is one of the most popular and commonly used neural network models. When
the model is large and there is a lot of data, the learning process can be
delayed. The standard way out is to use multiple devices. Therefore, the
methods of distributed and federated training for GANs are an important
question. But from an optimization point of view, GANs are nothing more than a
classical saddle-point problem: $\min_x \max_y f(x,y)$. Therefore, this paper
focuses on the distributed optimization of the smooth stochastic saddle-point
problems using Local SGD. We present a new algorithm specifically for our
problem -- Extra Step Local SGD. The obtained theoretical bounds of
communication rounds are $\Omega(K^{2/3} M^{1/3})$ in
strongly-convex-strongly-concave case and $\Omega(K^{8/9} M^{4/9})$ in
convex-concave (here $M$ -- number of functions (nodes) and $K$ - number of
iterations).
</p>
<a href="http://arxiv.org/abs/2010.13112" target="_blank">arXiv:2010.13112</a> [<a href="http://arxiv.org/pdf/2010.13112" target="_blank">pdf</a>]

<h2>Semi-Supervised Speech Recognition via Graph-based Temporal Classification. (arXiv:2010.15653v2 [cs.LG] UPDATED)</h2>
<h3>Niko Moritz, Takaaki Hori, Jonathan Le Roux</h3>
<p>Semi-supervised learning has demonstrated promising results in automatic
speech recognition (ASR) by self-training using a seed ASR model with
pseudo-labels generated for unlabeled data. The effectiveness of this approach
largely relies on the pseudo-label accuracy, for which typically only the
1-best ASR hypothesis is used. However, alternative ASR hypotheses of an N-best
list can provide more accurate labels for an unlabeled speech utterance and
also reflect uncertainties of the seed ASR model. In this paper, we propose a
generalized form of the connectionist temporal classification (CTC) objective
that accepts a graph representation of the training labels. The newly proposed
graph-based temporal classification (GTC) objective is applied for
self-training with WFST-based supervision, which is generated from an N-best
list of pseudo-labels. In this setup, GTC is used to learn not only a temporal
alignment, similarly to CTC, but also a label alignment to obtain the optimal
pseudo-label sequence from the weighted graph. Results show that this approach
can effectively exploit an N-best list of pseudo-labels with associated scores,
considerably outperforming standard pseudo-labeling, with ASR results
approaching an oracle experiment in which the best hypotheses of the N-best
lists are selected manually.
</p>
<a href="http://arxiv.org/abs/2010.15653" target="_blank">arXiv:2010.15653</a> [<a href="http://arxiv.org/pdf/2010.15653" target="_blank">pdf</a>]

<h2>Hybrid Federated and Centralized Learning. (arXiv:2011.06892v2 [cs.LG] UPDATED)</h2>
<h3>Ahmet M. Elbir, Sinem Coleri, Kumar Vijay Mishra</h3>
<p>Many of the machine learning (ML) tasks are focused on centralized learning
(CL), which requires the transmission of local datasets from the clients to a
parameter server (PS) leading to a huge communication overhead. Federated
learning (FL) overcomes this issue by allowing the clients to send only the
model updates to the PS instead of the whole dataset. In this way, FL brings
the learning to edge level, wherein powerful computational resources are
required on the client side. This requirement may not always be satisfied
because of diverse computational capabilities of edge devices. We address this
through a novel hybrid federated and centralized learning (HFCL) framework to
effectively train a learning model by exploiting the computational capability
of the clients. In HFCL, only the clients who have sufficient resources employ
FL; the remaining clients resort to CL by transmitting their local dataset to
PS. This allows all the clients to collaborate on the learning process
regardless of their computational resources. We also propose a sequential data
transmission approach with HFCL (HFCL-SDT) to reduce the training duration. The
proposed HFCL frameworks outperform previously proposed non-hybrid FL (CL)
based schemes in terms of learning accuracy (communication overhead) since all
the clients collaborate on the learning process with their datasets regardless
of their computational resources.
</p>
<a href="http://arxiv.org/abs/2011.06892" target="_blank">arXiv:2011.06892</a> [<a href="http://arxiv.org/pdf/2011.06892" target="_blank">pdf</a>]

<h2>Data-Efficient Learning for Complex and Real-Time Physical Problem Solving using Augmented Simulation. (arXiv:2011.07193v2 [cs.LG] UPDATED)</h2>
<h3>Kei Ota, Devesh K. Jha, Diego Romeres, Jeroen van Baar, Kevin A. Smith, Takayuki Semitsu, Tomoaki Oiki, Alan Sullivan, Daniel Nikovski, Joshua B. Tenenbaum</h3>
<p>Humans quickly solve tasks in novel systems with complex dynamics, without
requiring much interaction. While deep reinforcement learning algorithms have
achieved tremendous success in many complex tasks, these algorithms need a
large number of samples to learn meaningful policies. In this paper, we present
a task for navigating a marble to the center of a circular maze. While this
system is very intuitive and easy for humans to solve, it can be very difficult
and inefficient for standard reinforcement learning algorithms to learn
meaningful policies. We present a model that learns to move a marble in the
complex environment within minutes of interacting with the real system.
Learning consists of initializing a physics engine with parameters estimated
using data from the real system. The error in the physics engine is then
corrected using Gaussian process regression, which is used to model the
residual between real observations and physics engine simulations. The physics
engine augmented with the residual model is then used to control the marble in
the maze environment using a model-predictive feedback over a receding horizon.
To the best of our knowledge, this is the first time that a hybrid model
consisting of a full physics engine along with a statistical function
approximator has been used to control a complex physical system in real-time
using nonlinear model-predictive control (NMPC).
</p>
<a href="http://arxiv.org/abs/2011.07193" target="_blank">arXiv:2011.07193</a> [<a href="http://arxiv.org/pdf/2011.07193" target="_blank">pdf</a>]

<h2>Close Category Generalization for Out-of-Distribution Classification. (arXiv:2011.08485v2 [cs.LG] UPDATED)</h2>
<h3>Yao-Yuan Yang, Cyrus Rashtchian, Ruslan Salakhutdinov, Kamalika Chaudhuri</h3>
<p>Out-of-distribution generalization is a core challenge in machine learning.
We introduce and propose a solution to a new type of out-of-distribution
evaluation, which we call close category generalization. This task specifies
how a classifier should extrapolate to unseen classes by considering a
bi-criteria objective: (i) on in-distribution examples, output the correct
label, and (ii) on out-of-distribution examples, output the label of the
nearest neighbor in the training set. In addition to formalizing this problem,
we present a new training algorithm to improve the close category
generalization of neural networks. We compare to many baselines, including
robust algorithms and out-of-distribution detection methods, and we show that
our method has better or comparable close category generalization. Then, we
investigate a related representation learning task, and we find that performing
well on close category generalization correlates with learning a good
representation of an unseen class and with finding a good initialization for
few-shot learning. The code is available at
https://github.com/yangarbiter/close-category-generalization
</p>
<a href="http://arxiv.org/abs/2011.08485" target="_blank">arXiv:2011.08485</a> [<a href="http://arxiv.org/pdf/2011.08485" target="_blank">pdf</a>]

<h2>Aerial Height Prediction and Refinement Neural Networks with Semantic and Geometric Guidance. (arXiv:2011.10697v2 [cs.CV] UPDATED)</h2>
<h3>Elhousni Mahdi, Huang Xinming, Zhang Ziming</h3>
<p>Deep learning provides a powerful new approach to many computer vision tasks.
Height prediction from aerial images is one of those tasks that benefited
greatly from the deployment of deep learning which replaced old multi-view
geometry techniques. This letter proposes a two-stage approach, where first a
multi-task neural network is used to predict the height map resulting from a
single RGB aerial input image. We also include a second refinement step, where
a denoising autoencoder is used to produce higher quality height maps.
Experiments on two publicly available datasets show that our method is capable
of producing state-of-the-art results
</p>
<a href="http://arxiv.org/abs/2011.10697" target="_blank">arXiv:2011.10697</a> [<a href="http://arxiv.org/pdf/2011.10697" target="_blank">pdf</a>]

<h2>Vision-based Drone Flocking in Outdoor Environments. (arXiv:2012.01245v2 [cs.RO] UPDATED)</h2>
<h3>Fabian Schilling, Fabrizio Schiano, Dario Floreano</h3>
<p>Decentralized deployment of drone swarms usually relies on inter-agent
communication or visual markers that are mounted on the vehicles to simplify
their mutual detection. This letter proposes a vision-based detection and
tracking algorithm that enables groups of drones to navigate without
communication or visual markers. We employ a convolutional neural network to
detect and localize nearby agents onboard the quadcopters in real-time. Rather
than manually labeling a dataset, we automatically annotate images to train the
neural network using background subtraction by systematically flying a
quadcopter in front of a static camera. We use a multi-agent state tracker to
estimate the relative positions and velocities of nearby agents, which are
subsequently fed to a flocking algorithm for high-level control. The drones are
equipped with multiple cameras to provide omnidirectional visual inputs. The
camera setup ensures the safety of the flock by avoiding blind spots regardless
of the agent configuration. We evaluate the approach with a group of three real
quadcopters that are controlled using the proposed vision-based flocking
algorithm. The results show that the drones can safely navigate in an outdoor
environment despite substantial background clutter and difficult lighting
conditions. The source code, image dataset, and trained detection model are
available at https://github.com/lis-epfl/vswarm.
</p>
<a href="http://arxiv.org/abs/2012.01245" target="_blank">arXiv:2012.01245</a> [<a href="http://arxiv.org/pdf/2012.01245" target="_blank">pdf</a>]

<h2>PAC-Learning for Strategic Classification. (arXiv:2012.03310v3 [cs.LG] UPDATED)</h2>
<h3>Ravi Sundaram, Anil Vullikanti, Haifeng Xu, Fan Yao</h3>
<p>The study of strategic or adversarial manipulation of testing data to fool a
classifier has attracted much recent attention. Most previous works have
focused on two extreme situations where any testing data point either is
completely adversarial or always equally prefers the positive label. In this
paper, we generalize both of these through a unified framework for strategic
classification, and introduce the notion of strategic VC-dimension (SVC) to
capture the PAC-learnability in our general strategic setup. SVC provably
generalizes the recent concept of adversarial VC-dimension (AVC) introduced by
Cullina et al. arXiv:1806.01471. We instantiate our framework for the
fundamental strategic linear classification problem. We fully characterize: (1)
the statistical learnability of linear classifiers by pinning down its SVC; (2)
its computational tractability by pinning down the complexity of the empirical
risk minimization problem. Interestingly, the SVC of linear classifiers is
always upper bounded by its standard VC-dimension. This characterization also
strictly generalizes the AVC bound for linear classifiers in arXiv:1806.01471.
</p>
<a href="http://arxiv.org/abs/2012.03310" target="_blank">arXiv:2012.03310</a> [<a href="http://arxiv.org/pdf/2012.03310" target="_blank">pdf</a>]

<h2>String Tightening as a Self-Organizing Phenomenon: Computation of Shortest Homotopic Path, Smooth Path, and Convex Hull. (arXiv:2012.06513v2 [cs.AI] UPDATED)</h2>
<h3>Bonny Banerjee</h3>
<p>The phenomenon of self-organization has been of special interest to the
neural network community for decades. In this paper, we study a variant of the
Self-Organizing Map (SOM) that models the phenomenon of self-organization of
the particles forming a string when the string is tightened from one or both
ends. The proposed variant, called the String Tightening Self-Organizing Neural
Network (STON), can be used to solve certain practical problems, such as
computation of shortest homotopic paths, smoothing paths to avoid sharp turns,
and computation of convex hull. These problems are of considerable interest in
computational geometry, robotics path planning, AI (diagrammatic reasoning),
VLSI routing, and geographical information systems. Given a set of obstacles
and a string with two fixed terminal points in a two dimensional space, the
STON model continuously tightens the given string until the unique shortest
configuration in terms of the Euclidean metric is reached. The STON minimizes
the total length of a string on convergence by dynamically creating and
selecting feature vectors in a competitive manner. Proof of correctness of this
anytime algorithm and experimental results obtained by its deployment are
presented in the paper.
</p>
<a href="http://arxiv.org/abs/2012.06513" target="_blank">arXiv:2012.06513</a> [<a href="http://arxiv.org/pdf/2012.06513" target="_blank">pdf</a>]

<h2>Proofs and additional experiments on Second order techniques for learning time-series with structural breaks. (arXiv:2012.08037v2 [cs.LG] UPDATED)</h2>
<h3>Takayuki Osogami</h3>
<p>We provide complete proofs of the lemmas about the properties of the
regularized loss function that is used in the second order techniques for
learning time-series with structural breaks in Osogami (2021). In addition, we
show experimental results that support the validity of the techniques.
</p>
<a href="http://arxiv.org/abs/2012.08037" target="_blank">arXiv:2012.08037</a> [<a href="http://arxiv.org/pdf/2012.08037" target="_blank">pdf</a>]

<h2>SpaceML: Distributed Open-source Research with Citizen Scientists for the Advancement of Space Technology for NASA. (arXiv:2012.10610v3 [cs.CV] UPDATED)</h2>
<h3>Anirudh Koul, Siddha Ganju, Meher Kasam, James Parr</h3>
<p>Traditionally, academic labs conduct open-ended research with the primary
focus on discoveries with long-term value, rather than direct products that can
be deployed in the real world. On the other hand, research in the industry is
driven by its expected commercial return on investment, and hence focuses on a
real world product with short-term timelines. In both cases, opportunity is
selective, often available to researchers with advanced educational
backgrounds. Research often happens behind closed doors and may be kept
confidential until either its publication or product release, exacerbating the
problem of AI reproducibility and slowing down future research by others in the
field. As many research organizations tend to exclusively focus on specific
areas, opportunities for interdisciplinary research reduce. Undertaking
long-term bold research in unexplored fields with non-commercial yet great
public value is hard due to factors including the high upfront risk, budgetary
constraints, and a lack of availability of data and experts in niche fields.
Only a few companies or well-funded research labs can afford to do such
long-term research. With research organizations focused on an exploding array
of fields and resources spread thin, opportunities for the maturation of
interdisciplinary research reduce. Apart from these exigencies, there is also a
need to engage citizen scientists through open-source contributors to play an
active part in the research dialogue. We present a short case study of SpaceML,
an extension of the Frontier Development Lab, an AI accelerator for NASA.
SpaceML distributes open-source research and invites volunteer citizen
scientists to partake in development and deployment of high social value
products at the intersection of space and AI.
</p>
<a href="http://arxiv.org/abs/2012.10610" target="_blank">arXiv:2012.10610</a> [<a href="http://arxiv.org/pdf/2012.10610" target="_blank">pdf</a>]

<h2>CAMTA: Causal Attention Model for Multi-touch Attribution. (arXiv:2012.11403v2 [cs.LG] UPDATED)</h2>
<h3>Sachin Kumar, Garima Gupta, Ranjitha Prasad, Arnab Chatterjee, Lovekesh Vig, Gautam Shroff</h3>
<p>Advertising channels have evolved from conventional print media, billboards
and radio advertising to online digital advertising (ad), where the users are
exposed to a sequence of ad campaigns via social networks, display ads, search
etc. While advertisers revisit the design of ad campaigns to concurrently serve
the requirements emerging out of new ad channels, it is also critical for
advertisers to estimate the contribution from touch-points (view, clicks,
converts) on different channels, based on the sequence of customer actions.
This process of contribution measurement is often referred to as multi-touch
attribution (MTA). In this work, we propose CAMTA, a novel deep recurrent
neural network architecture which is a casual attribution mechanism for
user-personalised MTA in the context of observational data. CAMTA minimizes the
selection bias in channel assignment across time-steps and touchpoints.
Furthermore, it utilizes the users' pre-conversion actions in a principled way
in order to predict pre-channel attribution. To quantitatively benchmark the
proposed MTA model, we employ the real world Criteo dataset and demonstrate the
superior performance of CAMTA with respect to prediction accuracy as compared
to several baselines. In addition, we provide results for budget allocation and
user-behaviour modelling on the predicted channel attribution.
</p>
<a href="http://arxiv.org/abs/2012.11403" target="_blank">arXiv:2012.11403</a> [<a href="http://arxiv.org/pdf/2012.11403" target="_blank">pdf</a>]

<h2>Meta Learning Backpropagation And Improving It. (arXiv:2012.14905v2 [cs.LG] UPDATED)</h2>
<h3>Louis Kirsch, J&#xfc;rgen Schmidhuber</h3>
<p>Many concepts have been proposed for meta learning with neural networks
(NNs), e.g., NNs that learn to control fast weights, hyper networks, learned
learning rules, and meta recurrent NNs. Our Variable Shared Meta Learning
(VS-ML) unifies the above and demonstrates that simple weight-sharing and
sparsity in an NN is sufficient to express powerful learning algorithms (LAs)
in a reusable fashion. A simple implementation of VS-ML called VS-ML RNN allows
for implementing the backpropagation LA solely by running an RNN in
forward-mode. It can even meta-learn new LAs that improve upon backpropagation
and generalize to datasets outside of the meta training distribution without
explicit gradient calculation. Introspection reveals that our meta-learned LAs
learn qualitatively different from gradient descent through fast association.
</p>
<a href="http://arxiv.org/abs/2012.14905" target="_blank">arXiv:2012.14905</a> [<a href="http://arxiv.org/pdf/2012.14905" target="_blank">pdf</a>]

<h2>Knowledge Distillation with Adaptive Asymmetric Label Sharpening for Semi-supervised Fracture Detection in Chest X-rays. (arXiv:2012.15359v2 [cs.CV] UPDATED)</h2>
<h3>Yirui Wang, Kang Zheng, Chi-Tung Chang, Xiao-Yun Zhou, Zhilin Zheng, Lingyun Huang, Jing Xiao, Le Lu, Chien-Hung Liao, Shun Miao</h3>
<p>Exploiting available medical records to train high performance computer-aided
diagnosis (CAD) models via the semi-supervised learning (SSL) setting is
emerging to tackle the prohibitively high labor costs involved in large-scale
medical image annotations. Despite the extensive attentions received on SSL,
previous methods failed to 1) account for the low disease prevalence in medical
records and 2) utilize the image-level diagnosis indicated from the medical
records. Both issues are unique to SSL for CAD models. In this work, we propose
a new knowledge distillation method that effectively exploits large-scale
image-level labels extracted from the medical records, augmented with limited
expert annotated region-level labels, to train a rib and clavicle fracture CAD
model for chest X-ray (CXR). Our method leverages the teacher-student model
paradigm and features a novel adaptive asymmetric label sharpening (AALS)
algorithm to address the label imbalance problem that specially exists in
medical domain. Our approach is extensively evaluated on all CXR (N = 65,845)
from the trauma registry of anonymous hospital over a period of 9 years
(2008-2016), on the most common rib and clavicle fractures. The experiment
results demonstrate that our method achieves the state-of-the-art fracture
detection performance, i.e., an area under receiver operating characteristic
curve (AUROC) of 0.9318 and a free-response receiver operating characteristic
(FROC) score of 0.8914 on the rib fractures, significantly outperforming
previous approaches by an AUROC gap of 1.63% and an FROC improvement by 3.74%.
Consistent performance gains are also observed for clavicle fracture detection.
</p>
<a href="http://arxiv.org/abs/2012.15359" target="_blank">arXiv:2012.15359</a> [<a href="http://arxiv.org/pdf/2012.15359" target="_blank">pdf</a>]

<h2>Action Priors for Large Action Spaces in Robotics. (arXiv:2101.04178v2 [cs.RO] UPDATED)</h2>
<h3>Ondrej Biza, Dian Wang, Robert Platt, Jan-Willem van de Meent, Lawson L. S. Wong</h3>
<p>In robotics, it is often not possible to learn useful policies using pure
model-free reinforcement learning without significant reward shaping or
curriculum learning. As a consequence, many researchers rely on expert
demonstrations to guide learning. However, acquiring expert demonstrations can
be expensive. This paper proposes an alternative approach where the solutions
of previously solved tasks are used to produce an action prior that can
facilitate exploration in future tasks. The action prior is a probability
distribution over actions that summarizes the set of policies found solving
previous tasks. Our results indicate that this approach can be used to solve
robotic manipulation problems that would otherwise be infeasible without expert
demonstrations. Source code is available at
\url{https://github.com/ondrejba/action_priors}.
</p>
<a href="http://arxiv.org/abs/2101.04178" target="_blank">arXiv:2101.04178</a> [<a href="http://arxiv.org/pdf/2101.04178" target="_blank">pdf</a>]

<h2>CobBO: Coordinate Backoff Bayesian Optimization. (arXiv:2101.05147v2 [cs.LG] UPDATED)</h2>
<h3>Jian Tan, Niv Nayman, Mengchang Wang, Feifei Li, Rong Jin</h3>
<p>Bayesian optimization is a popular method for optimizing expensive black-box
functions. The objective functions of hard real world problems are oftentimes
characterized by a fluctuated landscape of many local optima. Bayesian
optimization risks in over-exploiting such traps, remaining with insufficient
query budget for exploring the global landscape. We introduce Coordinate
Backoff Bayesian Optimization (CobBO) to alleviate those challenges. CobBO
captures a smooth approximation of the global landscape by interpolating the
values of queried points projected to randomly selected promising subspaces.
Thus also a smaller query budget is required for the Gaussian process
regressions applied over the lower dimensional subspaces. This approach can be
viewed as a variant of coordinate ascent, tailored for Bayesian optimization,
using a stopping rule for backing off from a certain subspace and switching to
another coordinate subset. Extensive evaluations show that CobBO finds
solutions comparable to or better than other state-of-the-art methods for
dimensions ranging from tens to hundreds, while reducing the trial complexity.
</p>
<a href="http://arxiv.org/abs/2101.05147" target="_blank">arXiv:2101.05147</a> [<a href="http://arxiv.org/pdf/2101.05147" target="_blank">pdf</a>]

<h2>Discrete Graph Structure Learning for Forecasting Multiple Time Series. (arXiv:2101.06861v2 [cs.LG] UPDATED)</h2>
<h3>Chao Shang, Jie Chen, Jinbo Bi</h3>
<p>Time series forecasting is an extensively studied subject in statistics,
economics, and computer science. Exploration of the correlation and causation
among the variables in a multivariate time series shows promise in enhancing
the performance of a time series model. When using deep neural networks as
forecasting models, we hypothesize that exploiting the pairwise information
among multiple (multivariate) time series also improves their forecast. If an
explicit graph structure is known, graph neural networks (GNNs) have been
demonstrated as powerful tools to exploit the structure. In this work, we
propose learning the structure simultaneously with the GNN if the graph is
unknown. We cast the problem as learning a probabilistic graph model through
optimizing the mean performance over the graph distribution. The distribution
is parameterized by a neural network so that discrete graphs can be sampled
differentiably through reparameterization. Empirical evaluations show that our
method is simpler, more efficient, and better performing than a recently
proposed bilevel learning approach for graph structure learning, as well as a
broad array of forecasting models, either deep or non-deep learning based, and
graph or non-graph based.
</p>
<a href="http://arxiv.org/abs/2101.06861" target="_blank">arXiv:2101.06861</a> [<a href="http://arxiv.org/pdf/2101.06861" target="_blank">pdf</a>]

<h2>Anchor Distance for 3D Multi-Object Distance Estimation from 2D Single Shot. (arXiv:2101.10399v2 [cs.CV] UPDATED)</h2>
<h3>Hyeonwoo Yu, Jean Oh</h3>
<p>Visual perception of the objects in a 3D environment is a key to successful
performance in autonomous driving and simultaneous localization and mapping
(SLAM). In this paper, we present a real time approach for estimating the
distances to multiple objects in a scene using only a single-shot image. Given
a 2D Bounding Box (BBox) and object parameters, a 3D distance to the object can
be calculated directly using 3D reprojection; however, such methods are prone
to significant errors because an error from the 2D detection can be amplified
in 3D. In addition, it is also challenging to apply such methods to a real-time
system due to the computational burden. In the case of the traditional
multi-object detection methods, %they mostly pay attention to existing works
have been developed for specific tasks such as object segmentation or 2D BBox
regression. These methods introduce the concept of anchor BBox for elaborate 2D
BBox estimation, and predictors are specialized and trained for specific 2D
BBoxes. In order to estimate the distances to the 3D objects from a single 2D
image, we introduce the notion of \textit{anchor distance} based on an object's
location and propose a method that applies the anchor distance to the
multi-object detector structure. We let the predictors catch the distance prior
using anchor distance and train the network based on the distance. The
predictors can be characterized to the objects located in a specific distance
range. By propagating the distance prior using a distance anchor to the
predictors, it is feasible to perform the precise distance estimation and
real-time execution simultaneously. The proposed method achieves about 30 FPS
speed, and shows the lowest RMSE compared to the existing methods.
</p>
<a href="http://arxiv.org/abs/2101.10399" target="_blank">arXiv:2101.10399</a> [<a href="http://arxiv.org/pdf/2101.10399" target="_blank">pdf</a>]

<h2>Meta-learning on Spectral Images of Electroencephalogram of Schizophenics. (arXiv:2101.12208v2 [cs.LG] UPDATED)</h2>
<h3>Maritza Tynes, Mahboobeh Parsapoor</h3>
<p>Schizophrenia is a complex psychiatric disorder involving changes in thought
patterns, perception, mood, and behavior. The diagnosis of schizophrenia is
challenging and requires that patients show two or more positive symptoms for
at least one month. Delays in identifying this debilitating disorder can impede
a patient ability to receive much needed treatment. Advances in neuroimaging
and machine learning algorithms can facilitate the diagnosis of schizophrenia
and help clinicians to provide an accurate diagnosis of the disease. This paper
presents a methodology for analyzing spectral images of Electroencephalography
collected from patients with schizophrenia using convolutional neural networks.
It also explains how we have developed accurate classifiers employing
Model-Agnostic Meta-Learning and prototypical networks. Such classifiers have
the capacity to distinguish people with schizophrenia from healthy controls
based on their brain activity.
</p>
<a href="http://arxiv.org/abs/2101.12208" target="_blank">arXiv:2101.12208</a> [<a href="http://arxiv.org/pdf/2101.12208" target="_blank">pdf</a>]

<h2>Layer-Peeled Model: Toward Understanding Well-Trained Deep Neural Networks. (arXiv:2101.12699v2 [cs.LG] UPDATED)</h2>
<h3>Cong Fang, Hangfeng He, Qi Long, Weijie J. Su</h3>
<p>In this paper, we introduce the Layer-Peeled Model, a nonconvex yet
analytically tractable optimization program, in a quest to better understand
deep neural networks that are trained for a sufficiently long time. As the name
suggests, this new model is derived by isolating the topmost layer from the
remainder of the neural network, followed by imposing certain constraints
separately on the two parts. We demonstrate that the Layer-Peeled Model, albeit
simple, inherits many characteristics of well-trained neural networks, thereby
offering an effective tool for explaining and predicting common empirical
patterns of deep learning training. First, when working on class-balanced
datasets, we prove that any solution to this model forms a simplex equiangular
tight frame, which in part explains the recently discovered phenomenon of
neural collapse in deep learning training [PHD20]. Moreover, when moving to the
imbalanced case, our analysis of the Layer-Peeled Model reveals a hitherto
unknown phenomenon that we term Minority Collapse, which fundamentally limits
the performance of deep learning models on the minority classes. In addition,
we use the Layer-Peeled Model to gain insights into how to mitigate Minority
Collapse. Interestingly, this phenomenon is first predicted by the Layer-Peeled
Model before its confirmation by our computational experiments.
</p>
<a href="http://arxiv.org/abs/2101.12699" target="_blank">arXiv:2101.12699</a> [<a href="http://arxiv.org/pdf/2101.12699" target="_blank">pdf</a>]

<h2>Recurrent Submodular Welfare and Matroid Blocking Bandits. (arXiv:2102.00321v2 [cs.LG] UPDATED)</h2>
<h3>Orestis Papadigenopoulos, Constantine Caramanis</h3>
<p>A recent line of research focuses on the study of the stochastic multi-armed
bandits problem (MAB), in the case where temporal correlations of specific
structure are imposed between the player's actions and the reward distributions
of the arms (Kleinberg and Immorlica [FOCS18], Basu et al. [NeurIPS19]). As
opposed to the standard MAB setting, where the optimal solution in hindsight
can be trivially characterized, these correlations lead to (sub-)optimal
solutions that exhibit interesting dynamical patterns -- a phenomenon that
yields new challenges both from an algorithmic as well as a learning
perspective. In this work, we extend the above direction to a combinatorial
bandit setting and study a variant of stochastic MAB, where arms are subject to
matroid constraints and each arm becomes unavailable (blocked) for a fixed
number of rounds after each play. A natural common generalization of the
state-of-the-art for blocking bandits, and that for matroid bandits, yields a
$(1-\frac{1}{e})$-approximation for partition matroids, yet it only guarantees
a $\frac{1}{2}$-approximation for general matroids. In this paper we develop
new algorithmic ideas that allow us to obtain a polynomial-time $(1 -
\frac{1}{e})$-approximation algorithm (asymptotically and in expectation) for
any matroid, and thus to control the $(1-\frac{1}{e})$-approximate regret. A
key ingredient is the technique of correlated (interleaved) scheduling. Along
the way, we discover an interesting connection to a variant of Submodular
Welfare Maximization, for which we provide (asymptotically) matching upper and
lower approximability bounds.
</p>
<a href="http://arxiv.org/abs/2102.00321" target="_blank">arXiv:2102.00321</a> [<a href="http://arxiv.org/pdf/2102.00321" target="_blank">pdf</a>]

<h2>SCA-Net: A Self-Correcting Two-Layer Autoencoder for Hyper-spectral Unmixing. (arXiv:2102.05713v3 [cs.LG] UPDATED)</h2>
<h3>Gurpreet Singh, Soumyajit Gupta, Matthew Lease, Clint Dawson</h3>
<p>Linear Mixture Model for hyperspectral datasets involves separating a mixed
pixel as a linear combination of its constituent endmembers and corresponding
fractional abundances. Both optimization and neural methods have attempted to
tackle this problem, with the current state of the art results achieved by
neural models on benchmark datasets. However, our review of these neural models
show that these networks are severely over-parameterized and consequently the
invariant endmember spectra extracted as decoder weights has a high variance
over multiple runs. All of these approaches require substantial post-processing
to satisfy LMM constraints. Furthermore, they also require an exact
specification of the number of endmembers and specialized initialization of
weights from other algorithms like VCA. Our work shows for the first time that
a two-layer autoencoder (SCA-Net), with $2FK$ parameters ($F$ features, $K$
endmembers), achieves error metrics that are scales apart ($10^{-5})$ from
previously reported values $(10^{-2})$. SCA-Net converges to this low error
solution starting from a random initialization of weights. We also show that
SCA-Net, based upon a bi-orthogonal representation, performs a self-correction
when the the number of endmembers are over-specified. We show that our network
formulation extracts a low-rank representation that is bounded below by a
tail-energy and can be computationally verified. Our numerical experiments on
Samson, Jasper, and Urban datasets demonstrate that SCA-Net outperforms
previously reported error metrics for all the cases while being robust to noise
and outliers.
</p>
<a href="http://arxiv.org/abs/2102.05713" target="_blank">arXiv:2102.05713</a> [<a href="http://arxiv.org/pdf/2102.05713" target="_blank">pdf</a>]

<h2>Robust Policy Gradient against Strong Data Corruption. (arXiv:2102.05800v2 [cs.LG] UPDATED)</h2>
<h3>Xuezhou Zhang, Yiding Chen, Xiaojin Zhu, Wen Sun</h3>
<p>We study the problem of robust reinforcement learning under adversarial
corruption on both rewards and transitions. Our attack model assumes an
\textit{adaptive} adversary who can arbitrarily corrupt the reward and
transition at every step within an episode, for at most $\epsilon$-fraction of
the learning episodes. Our attack model is strictly stronger than those
considered in prior works. Our first result shows that no algorithm can find a
better than $O(\epsilon)$-optimal policy under our attack model. Next, we show
that surprisingly the natural policy gradient (NPG) method retains a natural
robustness property if the reward corruption is bounded, and can find an
$O(\sqrt{\epsilon})$-optimal policy. Consequently, we develop a Filtered Policy
Gradient (FPG) algorithm that can tolerate even unbounded reward corruption and
can find an $O(\epsilon^{1/4})$-optimal policy. We emphasize that FPG is the
first that can achieve a meaningful learning guarantee when a constant fraction
of episodes are corrupted. Complimentary to the theoretical results, we show
that a neural implementation of FPG achieves strong robust learning performance
on the MuJoCo continuous control benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.05800" target="_blank">arXiv:2102.05800</a> [<a href="http://arxiv.org/pdf/2102.05800" target="_blank">pdf</a>]

<h2>NeRF--: Neural Radiance Fields Without Known Camera Parameters. (arXiv:2102.07064v2 [cs.CV] UPDATED)</h2>
<h3>Zirui Wang, Shangzhe Wu, Weidi Xie, Min Chen, Victor Adrian Prisacariu</h3>
<p>This paper tackles the problem of novel view synthesis (NVS) from 2D images
without known camera poses and intrinsics. Among various NVS techniques, Neural
Radiance Field (NeRF) has recently gained popularity due to its remarkable
synthesis quality. Existing NeRF-based approaches assume that the camera
parameters associated with each input image are either directly accessible at
training, or can be accurately estimated with conventional techniques based on
correspondences, such as Structure-from-Motion. In this work, we propose an
end-to-end framework, termed NeRF--, for training NeRF models given only RGB
images, without pre-computed camera parameters. Specifically, we show that the
camera parameters, including both intrinsics and extrinsics, can be
automatically discovered via joint optimisation during the training of the NeRF
model. On the standard LLFF benchmark, our model achieves comparable novel view
synthesis results compared to the baseline trained with COLMAP pre-computed
camera parameters. We also conduct extensive analyses to understand the model
behaviour under different camera trajectories, and show that in scenarios where
COLMAP fails, our model still produces robust results.
</p>
<a href="http://arxiv.org/abs/2102.07064" target="_blank">arXiv:2102.07064</a> [<a href="http://arxiv.org/pdf/2102.07064" target="_blank">pdf</a>]

<h2>TransGAN: Two Transformers Can Make One Strong GAN. (arXiv:2102.07074v2 [cs.CV] UPDATED)</h2>
<h3>Yifan Jiang, Shiyu Chang, Zhangyang Wang</h3>
<p>The recent explosive interest on transformers has suggested their potential
to become powerful "universal" models for computer vision tasks, such as
classification, detection, and segmentation. However, how further transformers
can go - are they ready to take some more notoriously difficult vision tasks,
e.g., generative adversarial networks (GANs)? Driven by that curiosity, we
conduct the first pilot study in building a GAN \textbf{completely free of
convolutions}, using only pure transformer-based architectures. Our vanilla GAN
architecture, dubbed \textbf{TransGAN}, consists of a memory-friendly
transformer-based generator that progressively increases feature resolution
while decreasing embedding dimension, and a patch-level discriminator that is
also transformer-based. We then demonstrate TransGAN to notably benefit from
data augmentations (more than standard GANs), a multi-task co-training strategy
for the generator, and a locally initialized self-attention that emphasizes the
neighborhood smoothness of natural images. Equipped with those findings,
TransGAN can effectively scale up with bigger models and high-resolution image
datasets. Specifically, our best architecture achieves highly competitive
performance compared to current state-of-the-art GANs based on convolutional
backbones. Specifically, TransGAN sets \textbf{new state-of-the-art} IS score
of 10.10 and FID score of 25.32 on STL-10. It also reaches competitive 8.64 IS
score and 11.89 FID score on Cifar-10, and 12.23 FID score on CelebA
$64\times64$, respectively. We also conclude with a discussion of the current
limitations and future potential of TransGAN. The code is available at
\url{https://github.com/VITA-Group/TransGAN}.
</p>
<a href="http://arxiv.org/abs/2102.07074" target="_blank">arXiv:2102.07074</a> [<a href="http://arxiv.org/pdf/2102.07074" target="_blank">pdf</a>]

<h2>Comprehensive Comparative Study of Multi-Label Classification Methods. (arXiv:2102.07113v2 [cs.LG] UPDATED)</h2>
<h3>Jasmin Bogatinovski, Ljup&#x10d;o Todorovski, Sa&#x161;o D&#x17e;eroski, Dragi Kocev</h3>
<p>Multi-label classification (MLC) has recently received increasing interest
from the machine learning community. Several studies provide reviews of methods
and datasets for MLC and a few provide empirical comparisons of MLC methods.
However, they are limited in the number of methods and datasets considered.
This work provides a comprehensive empirical study of a wide range of MLC
methods on a plethora of datasets from various domains. More specifically, our
study evaluates 26 methods on 42 benchmark datasets using 20 evaluation
measures. The adopted evaluation methodology adheres to the highest literature
standards for designing and executing large scale, time-budgeted experimental
studies. First, the methods are selected based on their usage by the community,
assuring representation of methods across the MLC taxonomy of methods and
different base learners. Second, the datasets cover a wide range of complexity
and domains of application. The selected evaluation measures assess the
predictive performance and the efficiency of the methods. The results of the
analysis identify RFPCT, RFDTBR, ECCJ48, EBRJ48 and AdaBoostMH as best
performing methods across the spectrum of performance measures. Whenever a new
method is introduced, it should be compared to different subsets of MLC
methods, determined on the basis of the different evaluation criteria.
</p>
<a href="http://arxiv.org/abs/2102.07113" target="_blank">arXiv:2102.07113</a> [<a href="http://arxiv.org/pdf/2102.07113" target="_blank">pdf</a>]

<h2>Double-descent curves in neural networks: a new perspective using Gaussian processes. (arXiv:2102.07238v2 [stat.ML] UPDATED)</h2>
<h3>Ouns El Harzli, Guillermo Valle-P&#xe9;rez, Ard A. Louis</h3>
<p>Double-descent curves in neural networks describe the phenomenon that the
generalisation error initially descends with increasing parameters, then grows
after reaching an optimal number of parameters which is less than the number of
data points, but then descends again in the overparameterised regime. Here we
use a neural network Gaussian process (NNGP) which maps exactly to a fully
connected network (FCN) in the infinite width limit, combined with techniques
from random matrix theory, to calculate this generalisation behaviour, with a
particular focus on the overparameterised regime. We verify our predictions
with numerical simulations of the corresponding Gaussian process regressions.
An advantage of our NNGP approach is that the analytical calculations are
easier to interpret. We argue that neural network generalization performance
improves in the overparameterised regime precisely because that is where they
converge to their equivalent Gaussian process.
</p>
<a href="http://arxiv.org/abs/2102.07238" target="_blank">arXiv:2102.07238</a> [<a href="http://arxiv.org/pdf/2102.07238" target="_blank">pdf</a>]

<h2>A Global to Local Double Embedding Method for Multi-person Pose Estimation. (arXiv:2102.07318v2 [cs.CV] UPDATED)</h2>
<h3>Yiming Xu, Jiaxin Li, Yiheng Peng, Yan Ding, Hua-Liang Wei</h3>
<p>Multi-person pose estimation is a fundamental and challenging problem to many
computer vision tasks. Most existing methods can be broadly categorized into
two classes: top-down and bottom-up methods. Both of the two types of methods
involve two stages, namely, person detection and joints detection.
Conventionally, the two stages are implemented separately without considering
their interactions between them, and this may inevitably cause some issue
intrinsically. In this paper, we present a novel method to simplify the
pipeline by implementing person detection and joints detection simultaneously.
We propose a Double Embedding (DE) method to complete the multi-person pose
estimation task in a global-to-local way. DE consists of Global Embedding (GE)
and Local Embedding (LE). GE encodes different person instances and processes
information covering the whole image and LE encodes the local limbs
information. GE functions for the person detection in top-down strategy while
LE connects the rest joints sequentially which functions for joint grouping and
information processing in A bottom-up strategy. Based on LE, we design the
Mutual Refine Machine (MRM) to reduce the prediction difficulty in complex
scenarios. MRM can effectively realize the information communicating between
keypoints and further improve the accuracy. We achieve the competitive results
on benchmarks MSCOCO, MPII and CrowdPose, demonstrating the effectiveness and
generalization ability of our method.
</p>
<a href="http://arxiv.org/abs/2102.07318" target="_blank">arXiv:2102.07318</a> [<a href="http://arxiv.org/pdf/2102.07318" target="_blank">pdf</a>]

<h2>Maximizing Conditional Entropy for Batch-Mode Active Learning of Perceptual Metrics. (arXiv:2102.07365v2 [cs.LG] UPDATED)</h2>
<h3>Priyadarshini Kumari, Sidhdhartha Chaudhuri, Vivek Borkar, Subhasis Chaudhuri</h3>
<p>Active metric learning is the problem of incrementally selecting batches of
training data (typically, ordered triplets) to annotate, in order to
progressively improve a learned model of a metric over some input domain as
rapidly as possible. Standard approaches, which independently select each
triplet in a batch, are susceptible to highly correlated batches with many
redundant triplets and hence low overall utility. While there has been recent
work on selecting decorrelated batches for metric learning
\cite{kumari2020batch}, these methods rely on ad hoc heuristics to estimate the
correlation between two triplets at a time. We present a novel approach for
batch mode active metric learning using the Maximum Entropy Principle that
seeks to collectively select batches with maximum joint entropy, which captures
both the informativeness and the diversity of the triplets. The entropy is
derived from the second-order statistics estimated by dropout. We take
advantage of the monotonically increasing submodular entropy function to
construct an efficient greedy algorithm based on Gram-Schmidt orthogonalization
that is provably $\left( 1 - \frac{1}{e} \right)$-optimal. Our approach is the
first batch-mode active metric learning method to define a unified score that
balances informativeness and diversity for an entire batch of triplets.
Experiments with several real-world datasets demonstrate that our algorithm is
robust and consistently outperforms the state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2102.07365" target="_blank">arXiv:2102.07365</a> [<a href="http://arxiv.org/pdf/2102.07365" target="_blank">pdf</a>]

<h2>Learning Student-Friendly Teacher Networks for Knowledge Distillation. (arXiv:2102.07650v2 [cs.LG] UPDATED)</h2>
<h3>Dae Young Park, Moon-Hyun Cha, Changwook Jeong, Daesin Kim, Bohyung Han</h3>
<p>We propose a novel knowledge distillation approach to facilitate the transfer
of dark knowledge from a teacher to a student. Contrary to most of the existing
methods that rely on effective training of student models given pretrained
teachers, we aim to learn the teacher models that are friendly to students and,
consequently, more appropriate for knowledge transfer. In other words, even at
the time of optimizing a teacher model, the proposed algorithm learns the
student branches jointly to obtain student-friendly representations. Since the
main goal of our approach lies in training teacher models and the subsequent
knowledge distillation procedure is straightforward, most of the existing
knowledge distillation algorithms can adopt this technique to improve the
performance of the student models in terms of accuracy and convergence speed.
The proposed algorithm demonstrates outstanding accuracy in several well-known
knowledge distillation techniques with various combinations of teacher and
student architectures.
</p>
<a href="http://arxiv.org/abs/2102.07650" target="_blank">arXiv:2102.07650</a> [<a href="http://arxiv.org/pdf/2102.07650" target="_blank">pdf</a>]

<h2>Diverse Auto-Curriculum is Critical for Successful Real-World Multiagent Learning Systems. (arXiv:2102.07659v2 [cs.AI] UPDATED)</h2>
<h3>Yaodong Yang, Jun Luo, Ying Wen, Oliver Slumbers, Daniel Graves, Haitham Bou Ammar, Jun Wang, Matthew E. Taylor</h3>
<p>Multiagent reinforcement learning (MARL) has achieved a remarkable amount of
success in solving various types of video games. A cornerstone of this success
is the auto-curriculum framework, which shapes the learning process by
continually creating new challenging tasks for agents to adapt to, thereby
facilitating the acquisition of new skills. In order to extend MARL methods to
real-world domains outside of video games, we envision in this blue sky paper
that maintaining a diversity-aware auto-curriculum is critical for successful
MARL applications. Specifically, we argue that \emph{behavioural diversity} is
a pivotal, yet under-explored, component for real-world multiagent learning
systems, and that significant work remains in understanding how to design a
diversity-aware auto-curriculum. We list four open challenges for
auto-curriculum techniques, which we believe deserve more attention from this
community. Towards validating our vision, we recommend modelling realistic
interactive behaviours in autonomous driving as an important test bed, and
recommend the SMARTS/ULTRA benchmark.
</p>
<a href="http://arxiv.org/abs/2102.07659" target="_blank">arXiv:2102.07659</a> [<a href="http://arxiv.org/pdf/2102.07659" target="_blank">pdf</a>]

<h2>How to Learn when Data Reacts to Your Model: Performative Gradient Descent. (arXiv:2102.07698v2 [cs.LG] UPDATED)</h2>
<h3>Zachary Izzo, Lexing Ying, James Zou</h3>
<p>Performative distribution shift captures the setting where the choice of
which ML model is deployed changes the data distribution. For example, a bank
which uses the number of open credit lines to determine a customer's risk of
default on a loan may induce customers to open more credit lines in order to
improve their chances of being approved. Because of the interactions between
the model and data distribution, finding the optimal model parameters is
challenging. Works in this area have focused on finding stable points, which
can be far from optimal. Here we introduce performative gradient descent
(PerfGD), which is the first algorithm which provably converges to the
performatively optimal point. PerfGD explicitly captures how changes in the
model affects the data distribution and is simple to use. We support our
findings with theory and experiments.
</p>
<a href="http://arxiv.org/abs/2102.07698" target="_blank">arXiv:2102.07698</a> [<a href="http://arxiv.org/pdf/2102.07698" target="_blank">pdf</a>]

<h2>A Data Quality-Driven View of MLOps. (arXiv:2102.07750v1 [cs.LG] CROSS LISTED)</h2>
<h3>Cedric Renggli, Luka Rimanic, Nezihe Merve G&#xfc;rel, Bojan Karla&#x161;, Wentao Wu, Ce Zhang</h3>
<p>Developing machine learning models can be seen as a process similar to the
one established for traditional software development. A key difference between
the two lies in the strong dependency between the quality of a machine learning
model and the quality of the data used to train or perform evaluations. In this
work, we demonstrate how different aspects of data quality propagate through
various stages of machine learning development. By performing a joint analysis
of the impact of well-known data quality dimensions and the downstream machine
learning process, we show that different components of a typical MLOps pipeline
can be efficiently designed, providing both a technical and theoretical
perspective.
</p>
<a href="http://arxiv.org/abs/2102.07750" target="_blank">arXiv:2102.07750</a> [<a href="http://arxiv.org/pdf/2102.07750" target="_blank">pdf</a>]

