---
title: Latest Deep Learning Papers
date: 2021-01-14 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (144 Articles)</h1>
<h2>GAN Inversion: A Survey. (arXiv:2101.05278v1 [cs.CV])</h2>
<h3>Weihao Xia, Yulun Zhang, Yujiu Yang, Jing-Hao Xue, Bolei Zhou, Ming-Hsuan Yang</h3>
<p>GAN inversion aims to invert a given image back into the latent space of a
pretrained GAN model, for the image to be faithfully reconstructed from the
inverted code by the generator. As an emerging technique to bridge the real and
fake image domains, GAN inversion plays an essential role in enabling the
pretrained GAN models such as StyleGAN and BigGAN to be used for real image
editing applications. Meanwhile, GAN inversion also provides insights on the
interpretation of GAN's latent space and how the realistic images can be
generated. In this paper, we provide an overview of GAN inversion with a focus
on its recent algorithms and applications. We cover important techniques of GAN
inversion and their applications to image restoration and image manipulation.
We further elaborate on some trends and challenges for future directions.
</p>
<a href="http://arxiv.org/abs/2101.05278" target="_blank">arXiv:2101.05278</a> [<a href="http://arxiv.org/pdf/2101.05278" target="_blank">pdf</a>]

<h2>Understanding the Effect of Out-of-distribution Examples and Interactive Explanations on Human-AI Decision Making. (arXiv:2101.05303v1 [cs.AI])</h2>
<h3>Han Liu, Vivian Lai, Chenhao Tan</h3>
<p>Although AI holds promise for improving human decision making in societally
critical domains, it remains an open question how human-AI teams can reliably
outperform AI alone and human alone in challenging prediction tasks (also known
as complementary performance). We explore two directions to understand the gaps
in achieving complementary performance. First, we argue that the typical
experimental setup limits the potential of human-AI teams. To account for lower
AI performance out-of-distribution than in-distribution because of distribution
shift, we design experiments with different distribution types and investigate
human performance for both in-distribution and out-of-distribution examples.
Second, we develop novel interfaces to support interactive explanations so that
humans can actively engage with AI assistance. Using in-person user study and
large-scale randomized experiments across three tasks, we demonstrate a clear
difference between in-distribution and out-of-distribution, and observe mixed
results for interactive explanations: while interactive explanations improve
human perception of AI assistance's usefulness, they may magnify human biases
and lead to limited performance improvement. Overall, our work points out
critical challenges and future directions towards complementary performance.
</p>
<a href="http://arxiv.org/abs/2101.05303" target="_blank">arXiv:2101.05303</a> [<a href="http://arxiv.org/pdf/2101.05303" target="_blank">pdf</a>]

<h2>Spatial-Temporal Convolutional Network for Spread Prediction of COVID-19. (arXiv:2101.05304v1 [cs.LG])</h2>
<h3>Ravid Shwartz-Ziv, Itamar Ben Ari, Amitai Armon</h3>
<p>In this work we present a spatial-temporal convolutional neural network for
predicting future COVID-19 related symptoms severity among a population, per
region, given its past reported symptoms. This can help approximate the number
of future Covid-19 patients in each region, thus enabling a faster response,
e.g., preparing the local hospital or declaring a local lockdown where
necessary. Our model is based on a national symptom survey distributed in
Israel and can predict symptoms severity for different regions daily. The model
includes two main parts - (1) learned region-based survey responders profiles
used for aggregating questionnaires data into features (2) Spatial-Temporal 3D
convolutional neural network which uses the above features to predict symptoms
progression.
</p>
<a href="http://arxiv.org/abs/2101.05304" target="_blank">arXiv:2101.05304</a> [<a href="http://arxiv.org/pdf/2101.05304" target="_blank">pdf</a>]

<h2>Explainability of vision-based autonomous driving systems: Review and challenges. (arXiv:2101.05307v1 [cs.CV])</h2>
<h3>&#xc9;loi Zablocki, H&#xe9;di Ben-Younes, Patrick P&#xe9;rez, Matthieu Cord</h3>
<p>This survey reviews explainability methods for vision-based self-driving
systems. The concept of explainability has several facets and the need for
explainability is strong in driving, a safety-critical application. Gathering
contributions from several research fields, namely computer vision, deep
learning, autonomous driving, explainable AI (X-AI), this survey tackles
several points. First, it discusses definitions, context, and motivation for
gaining more interpretability and explainability from self-driving systems.
Second, major recent state-of-the-art approaches to develop self-driving
systems are quickly presented. Third, methods providing explanations to a
black-box self-driving system in a post-hoc fashion are comprehensively
organized and detailed. Fourth, approaches from the literature that aim at
building more interpretable self-driving systems by design are presented and
discussed in detail. Finally, remaining open-challenges and potential future
research directions are identified and examined.
</p>
<a href="http://arxiv.org/abs/2101.05307" target="_blank">arXiv:2101.05307</a> [<a href="http://arxiv.org/pdf/2101.05307" target="_blank">pdf</a>]

<h2>Learning and Fast Adaptation for Grid Emergency Control via Deep Meta Reinforcement Learning. (arXiv:2101.05317v1 [cs.LG])</h2>
<h3>Renke Huang, Yujiao Chen, Tianzhixi Yin, Qiuhua Huang, Jie Tan, Wenhao Yu, Xinya Li, Ang Li, Yan Du</h3>
<p>As power systems are undergoing a significant transformation with more
uncertainties, less inertia and closer to operation limits, there is increasing
risk of large outages. Thus, there is an imperative need to enhance grid
emergency control to maintain system reliability and security. Towards this
end, great progress has been made in developing deep reinforcement learning
(DRL) based grid control solutions in recent years. However, existing DRL-based
solutions have two main limitations: 1) they cannot handle well with a wide
range of grid operation conditions, system parameters, and contingencies; 2)
they generally lack the ability to fast adapt to new grid operation conditions,
system parameters, and contingencies, limiting their applicability for
real-world applications. In this paper, we mitigate these limitations by
developing a novel deep meta reinforcement learning (DMRL) algorithm. The DMRL
combines the meta strategy optimization together with DRL, and trains policies
modulated by a latent space that can quickly adapt to new scenarios. We test
the developed DMRL algorithm on the IEEE 300-bus system. We demonstrate fast
adaptation of the meta-trained DRL polices with latent variables to new
operating conditions and scenarios using the proposed method and achieve
superior performance compared to the state-of-the-art DRL and model predictive
control (MPC) methods.
</p>
<a href="http://arxiv.org/abs/2101.05317" target="_blank">arXiv:2101.05317</a> [<a href="http://arxiv.org/pdf/2101.05317" target="_blank">pdf</a>]

<h2>Multi-robot Symmetric Rendezvous Searchon the Line. (arXiv:2101.05324v1 [cs.RO])</h2>
<h3>Deniz Ozsoyeller, Pratap Tokekar</h3>
<p>We study the Symmetric Rendezvous Search Problem for a multi-robot system.
There are $n&gt;2$ robots arbitrarily located on a line. Their goal is to meet
somewhere on the line as quickly as possible. The robots do not know the
initial location of any of the other robots or their own positions on the line.
The symmetric version of the problem requires the robots to execute the same
search strategy to achieve rendezvous. Therefore, we solve the problem in an
online fashion with a randomized strategy. In this paper, we present a
symmetric rendezvous algorithm which achieves a constant competitive ratio for
the total distance traveled by the robots. We validate our theoretical results
through simulations.
</p>
<a href="http://arxiv.org/abs/2101.05324" target="_blank">arXiv:2101.05324</a> [<a href="http://arxiv.org/pdf/2101.05324" target="_blank">pdf</a>]

<h2>Learning Kinematic Feasibility for Mobile Manipulation through Deep Reinforcement Learning. (arXiv:2101.05325v1 [cs.RO])</h2>
<h3>Daniel Honerkamp, Tim Welschehold, Abhinav Valada</h3>
<p>Mobile manipulation tasks remain one of the critical challenges for the
widespread adoption of autonomous robots in both service and industrial
scenarios. While planning approaches are good at generating feasible whole-body
robot trajectories, they struggle with dynamic environments as well as the
incorporation of constraints given by the task and the environment. On the
other hand, dynamic motion models in the action space struggle with generating
kinematically feasible trajectories for mobile manipulation actions. We propose
a deep reinforcement learning approach to learn feasible dynamic motions for a
mobile base while the end-effector follows a trajectory in task space generated
by an arbitrary system to fulfill the task at hand. This modular formulation
has several benefits: it enables us to readily transform a broad range of
end-effector motions into mobile applications, it allows us to use the
kinematic feasibility of the end-effector trajectory as a dense reward signal
and its modular formulation allows it to generalise to unseen end-effector
motions at test time. We demonstrate the capabilities of our approach on
multiple mobile robot platforms with different kinematic abilities and
different types of wheeled platforms in extensive simulated as well as
real-world experiments.
</p>
<a href="http://arxiv.org/abs/2101.05325" target="_blank">arXiv:2101.05325</a> [<a href="http://arxiv.org/pdf/2101.05325" target="_blank">pdf</a>]

<h2>Uniform Error and Posterior Variance Bounds for Gaussian Process Regression with Application to Safe Control. (arXiv:2101.05328v1 [cs.LG])</h2>
<h3>Armin Lederer, Jonas Umlauft, Sandra Hirche</h3>
<p>In application areas where data generation is expensive, Gaussian processes
are a preferred supervised learning model due to their high data-efficiency.
Particularly in model-based control, Gaussian processes allow the derivation of
performance guarantees using probabilistic model error bounds. To make these
approaches applicable in practice, two open challenges must be solved i)
Existing error bounds rely on prior knowledge, which might not be available for
many real-world tasks. (ii) The relationship between training data and the
posterior variance, which mainly drives the error bound, is not well understood
and prevents the asymptotic analysis. This article addresses these issues by
presenting a novel uniform error bound using Lipschitz continuity and an
analysis of the posterior variance function for a large class of kernels.
Additionally, we show how these results can be used to guarantee safe control
of an unknown dynamical system and provide numerical illustration examples.
</p>
<a href="http://arxiv.org/abs/2101.05328" target="_blank">arXiv:2101.05328</a> [<a href="http://arxiv.org/pdf/2101.05328" target="_blank">pdf</a>]

<h2>A Survey on Simulators for Testing Self-Driving Cars. (arXiv:2101.05337v1 [cs.RO])</h2>
<h3>Prabhjot Kaur, Samira Taghavi, Zhaofeng Tian, Weisong Shi</h3>
<p>A rigorous and comprehensive testing plays a key role in training
self-driving cars to handle variety of situations that they are expected to see
on public roads.

The physical testing on public roads is unsafe, costly, and not always
reproducible. This is where testing in simulation helps fill the gap, however,
the problem with simulation testing is that it is only as good as the simulator
used for testing and how representative the simulated scenarios are of the real
environment. In this paper, we identify key requirements that a good simulator
must have. Further, we provide a comparison of commonly used simulators. Our
analysis shows that CARLA and LGSVL simulators are the current state-of-the-art
simulators for end to end testing of self-driving cars for the reasons
mentioned in this paper. Finally, we also present current challenges that
simulation testing continues to face as we march towards building fully
autonomous cars.
</p>
<a href="http://arxiv.org/abs/2101.05337" target="_blank">arXiv:2101.05337</a> [<a href="http://arxiv.org/pdf/2101.05337" target="_blank">pdf</a>]

<h2>X-CAL: Explicit Calibration for Survival Analysis. (arXiv:2101.05346v1 [cs.LG])</h2>
<h3>Mark Goldstein, Xintian Han, Aahlad Puli, Adler J. Perotte, Rajesh Ranganath</h3>
<p>Survival analysis models the distribution of time until an event of interest,
such as discharge from the hospital or admission to the ICU. When a model's
predicted number of events within any time interval is similar to the observed
number, it is called well-calibrated. A survival model's calibration can be
measured using, for instance, distributional calibration (D-CALIBRATION)
[Haider et al., 2020] which computes the squared difference between the
observed and predicted number of events within different time intervals.
Classically, calibration is addressed in post-training analysis. We develop
explicit calibration (X-CAL), which turns D-CALIBRATION into a differentiable
objective that can be used in survival modeling alongside maximum likelihood
estimation and other objectives. X-CAL allows practitioners to directly
optimize calibration and strike a desired balance between predictive power and
calibration. In our experiments, we fit a variety of shallow and deep models on
simulated data, a survival dataset based on MNIST, on length-of-stay prediction
using MIMIC-III data, and on brain cancer data from The Cancer Genome Atlas. We
show that the models we study can be miscalibrated. We give experimental
evidence on these datasets that X-CAL improves D-CALIBRATION without a large
decrease in concordance or likelihood.
</p>
<a href="http://arxiv.org/abs/2101.05346" target="_blank">arXiv:2101.05346</a> [<a href="http://arxiv.org/pdf/2101.05346" target="_blank">pdf</a>]

<h2>Gaussian Mixture Graphical Lasso with Application to Edge Detection in Brain Networks. (arXiv:2101.05348v1 [cs.LG])</h2>
<h3>Hang Yin, Xinyue Liu, Xiangnan Kong</h3>
<p>Sparse inverse covariance estimation (i.e., edge de-tection) is an important
research problem in recent years, wherethe goal is to discover the direct
connections between a set ofnodes in a networked system based upon the observed
nodeactivities. Existing works mainly focus on unimodal distributions,where it
is usually assumed that the observed activities aregenerated from
asingleGaussian distribution (i.e., one graph).However, this assumption is too
strong for many real-worldapplications. In many real-world applications (e.g.,
brain net-works), the node activities usually exhibit much more complexpatterns
that are difficult to be captured by one single Gaussiandistribution. In this
work, we are inspired by Latent DirichletAllocation (LDA) [4] and consider
modeling the edge detectionproblem as estimating a mixture ofmultipleGaussian
distribu-tions, where each corresponds to a separate sub-network. Toaddress
this problem, we propose a novel model called GaussianMixture Graphical Lasso
(MGL). It learns the proportionsof signals generated by each mixture component
and theirparameters iteratively via an EM framework. To obtain
moreinterpretable networks, MGL imposes a special regularization,called Mutual
Exclusivity Regularization (MER), to minimize theoverlap between different
sub-networks. MER also addresses thecommon issues in read-world data sets,i.e.,
noisy observationsand small sample size. Through the extensive experiments
onsynthetic and real brain data sets, the results demonstrate thatMGL can
effectively discover multiple connectivity structuresfrom the observed node
activities
</p>
<a href="http://arxiv.org/abs/2101.05348" target="_blank">arXiv:2101.05348</a> [<a href="http://arxiv.org/pdf/2101.05348" target="_blank">pdf</a>]

<h2>Practical Face Reconstruction via Differentiable Ray Tracing. (arXiv:2101.05356v1 [cs.CV])</h2>
<h3>Abdallah Dib, Gaurav Bharaj, Junghyun Ahn, C&#xe9;dric Th&#xe9;bault, Philippe-Henri Gosselin, Marco Romeo, Louis Chevallier</h3>
<p>We present a differentiable ray-tracing based novel face reconstruction
approach where scene attributes - 3D geometry, reflectance (diffuse, specular
and roughness), pose, camera parameters, and scene illumination - are estimated
from unconstrained monocular images. The proposed method models scene
illumination via a novel, parameterized virtual light stage, which
in-conjunction with differentiable ray-tracing, introduces a coarse-to-fine
optimization formulation for face reconstruction. Our method can not only
handle unconstrained illumination and self-shadows conditions, but also
estimates diffuse and specular albedos. To estimate the face attributes
consistently and with practical semantics, a two-stage optimization strategy
systematically uses a subset of parametric attributes, where subsequent
attribute estimations factor those previously estimated. For example,
self-shadows estimated during the first stage, later prevent its baking into
the personalized diffuse and specular albedos in the second stage. We show the
efficacy of our approach in several real-world scenarios, where face attributes
can be estimated even under extreme illumination conditions. Ablation studies,
analyses and comparisons against several recent state-of-the-art methods show
improved accuracy and versatility of our approach. With consistent face
attributes reconstruction, our method leads to several style -- illumination,
albedo, self-shadow -- edit and transfer applications, as discussed in the
paper.
</p>
<a href="http://arxiv.org/abs/2101.05356" target="_blank">arXiv:2101.05356</a> [<a href="http://arxiv.org/pdf/2101.05356" target="_blank">pdf</a>]

<h2>Towards Creating a Deployable Grasp Type Probability Estimator for a Prosthetic Hand. (arXiv:2101.05357v1 [cs.LG])</h2>
<h3>Mehrshad Zandigohar, Mo Han, Deniz Erdogmus, Gunar Schirner</h3>
<p>For lower arm amputees, prosthetic hands promise to restore most of physical
interaction capabilities. This requires to accurately predict hand gestures
capable of grabbing varying objects and execute them timely as intended by the
user. Current approaches often rely on physiological signal inputs such as
Electromyography (EMG) signal from residual limb muscles to infer the intended
motion. However, limited signal quality, user diversity and high variability
adversely affect the system robustness. Instead of solely relying on EMG
signals, our work enables augmenting EMG intent inference with physical state
probability through machine learning and computer vision method. To this end,
we: (1) study state-of-the-art deep neural network architectures to select a
performant source of knowledge transfer for the prosthetic hand, (2) use a
dataset containing object images and probability distribution of grasp types as
a new form of labeling where instead of using absolute values of zero and one
as the conventional classification labels, our labels are a set of
probabilities whose sum is 1. The proposed method generates probabilistic
predictions which could be fused with EMG prediction of probabilities over
grasps by using the visual information from the palm camera of a prosthetic
hand. Our results demonstrate that InceptionV3 achieves highest accuracy with
0.95 angular similarity followed by 1.4 MobileNetV2 with 0.93 at ~20% the
amount of operations.
</p>
<a href="http://arxiv.org/abs/2101.05357" target="_blank">arXiv:2101.05357</a> [<a href="http://arxiv.org/pdf/2101.05357" target="_blank">pdf</a>]

<h2>Preferential Mixture-of-Experts: Interpretable Models that Rely on Human Expertise as much as Possible. (arXiv:2101.05360v1 [cs.LG])</h2>
<h3>Melanie F. Pradier, Javier Zazo, Sonali Parbhoo, Roy H. Perlis, Maurizio Zazzi, Finale Doshi-Velez</h3>
<p>We propose Preferential MoE, a novel human-ML mixture-of-experts model that
augments human expertise in decision making with a data-based classifier only
when necessary for predictive performance. Our model exhibits an interpretable
gating function that provides information on when human rules should be
followed or avoided. The gating function is maximized for using human-based
rules, and classification errors are minimized. We propose solving a coupled
multi-objective problem with convex subproblems. We develop approximate
algorithms and study their performance and convergence. Finally, we demonstrate
the utility of Preferential MoE on two clinical applications for the treatment
of Human Immunodeficiency Virus (HIV) and management of Major Depressive
Disorder (MDD).
</p>
<a href="http://arxiv.org/abs/2101.05360" target="_blank">arXiv:2101.05360</a> [<a href="http://arxiv.org/pdf/2101.05360" target="_blank">pdf</a>]

<h2>Random Shadows and Highlights: A new data augmentation method for Extreme Lighting Conditions. (arXiv:2101.05361v1 [cs.CV])</h2>
<h3>Osama Mazhar, Jens Kober</h3>
<p>In this paper, we propose a new data augmentation method, Random Shadows and
Highlights (RSH) to acquire robustness against lighting perturbations. Our
method creates random shadows and highlights on images, thus challenging the
neural network during the learning process such that it acquires immunity
against such input corruptions in real world applications. It is a
parameter-learning free method which can be integrated into most vision related
learning applications effortlessly. With extensive experimentation, we
demonstrate that RSH not only increases the robustness of the models against
lighting perturbations, but also reduces over-fitting significantly. Thus RSH
should be considered essential for all vision related learning systems. Code is
available at: https://github.com/OsamaMazhar/Random-Shadows-Highlights.
</p>
<a href="http://arxiv.org/abs/2101.05361" target="_blank">arXiv:2101.05361</a> [<a href="http://arxiv.org/pdf/2101.05361" target="_blank">pdf</a>]

<h2>NetCut: Real-Time DNN Inference Using Layer Removal. (arXiv:2101.05363v1 [cs.LG])</h2>
<h3>Mehrshad Zandigohar, Deniz Erdogmus, Gunar Schirner</h3>
<p>Deep Learning plays a significant role in assisting humans in many aspects of
their lives. As these networks tend to get deeper over time, they extract more
features to increase accuracy at the cost of additional inference latency. This
accuracy-performance trade-off makes it more challenging for Embedded Systems,
as resource-constrained processors with strict deadlines, to deploy them
efficiently. This can lead to selection of networks that can prematurely meet a
specified deadline with excess slack time that could have potentially
contributed to increased accuracy.

In this work, we propose: (i) the concept of layer removal as a means of
constructing TRimmed Networks (TRNs) that are based on removing
problem-specific features of a pretrained network used in transfer learning,
and (ii) NetCut, a methodology based on an empirical or an analytical latency
estimator, which only proposes and retrains TRNs that can meet the
application's deadline, hence reducing the exploration time significantly.

We demonstrate that TRNs can expand the Pareto frontier that trades off
latency and accuracy to provide networks that can meet arbitrary deadlines with
potential accuracy improvement over off-the-shelf networks. Our experimental
results show that such utilization of TRNs, while transferring to a simpler
dataset, in combination with NetCut, can lead to the proposal of networks that
can achieve relative accuracy improvement of up to 10.43% among existing
off-the-shelf neural architectures while meeting a specific deadline, and 27x
speedup in exploration time.
</p>
<a href="http://arxiv.org/abs/2101.05363" target="_blank">arXiv:2101.05363</a> [<a href="http://arxiv.org/pdf/2101.05363" target="_blank">pdf</a>]

<h2>Anomaly Detection Support Using Process Classification. (arXiv:2101.05371v1 [cs.LG])</h2>
<h3>Sebastian Eresheim, Lukas Daniel Klausner, Patrick Kochberger</h3>
<p>Anomaly detection systems need to consider a lot of information when scanning
for anomalies. One example is the context of the process in which an anomaly
might occur, because anomalies for one process might not be anomalies for a
different one. Therefore data -- such as system events -- need to be assigned
to the program they originate from. This paper investigates whether it is
possible to infer from a list of system events the program whose behavior
caused the occurrence of these system events. To that end, we model transition
probabilities between non-equivalent events and apply the $k$-nearest neighbors
algorithm. This system is evaluated on non-malicious, real-world data using
four different evaluation scores. Our results suggest that the approach
proposed in this paper is capable of correctly inferring program names from
system events.
</p>
<a href="http://arxiv.org/abs/2101.05371" target="_blank">arXiv:2101.05371</a> [<a href="http://arxiv.org/pdf/2101.05371" target="_blank">pdf</a>]

<h2>Evaluating Soccer Player: from Live Camera to Deep Reinforcement Learning. (arXiv:2101.05388v1 [cs.LG])</h2>
<h3>Paul Garnier, Th&#xe9;ophane Gregoir</h3>
<p>Scientifically evaluating soccer players represents a challenging Machine
Learning problem. Unfortunately, most existing answers have very opaque
algorithm training procedures; relevant data are scarcely accessible and almost
impossible to generate. In this paper, we will introduce a two-part solution:
an open-source Player Tracking model and a new approach to evaluate these
players based solely on Deep Reinforcement Learning, without human data
training nor guidance. Our tracking model was trained in a supervised fashion
on datasets we will also release, and our Evaluation Model relies only on
simulations of virtual soccer games. Combining those two architectures allows
one to evaluate Soccer Players directly from a live camera without large
datasets constraints. We term our new approach Expected Discounted Goal (EDG),
as it represents the number of goals a team can score or concede from a
particular state. This approach leads to more meaningful results than the
existing ones that are based on real-world data, and could easily be extended
to other sports.
</p>
<a href="http://arxiv.org/abs/2101.05388" target="_blank">arXiv:2101.05388</a> [<a href="http://arxiv.org/pdf/2101.05388" target="_blank">pdf</a>]

<h2>Quantitative Rates and Fundamental Obstructions to Non-Euclidean Universal Approximation with Deep Narrow Feed-Forward Networks. (arXiv:2101.05390v1 [cs.LG])</h2>
<h3>Anastasis Kratsios, Leonie Papon</h3>
<p>By incorporating structured pairs of non-trainable input and output layers,
the universal approximation property of feed-forward have recently been
extended across a broad range of non-Euclidean input spaces X and output spaces
Y. We quantify the number of narrow layers required for these "deep geometric
feed-forward neural networks" (DGNs) to approximate any continuous function in
$C(X,Y)$, uniformly on compacts. The DGN architecture is then extended to
accommodate complete Riemannian manifolds, where the input and output layers
are only defined locally, and we obtain local analogs of our results. In this
case, we find that both the global and local universal approximation guarantees
can only coincide when approximating null-homotopic functions. Consequently, we
show that if Y is a compact Riemannian manifold, then there exists a function
that cannot be uniformly approximated on large compact subsets of X.
Nevertheless, we obtain lower-bounds of the maximum diameter of any geodesic
ball in X wherein our local universal approximation results hold. Applying our
results, we build universal approximators between spaces of non-degenerate
Gaussian measures. We also obtain a quantitative version of the universal
approximation theorem for classical deep narrow feed-forward networks with
general activation functions.
</p>
<a href="http://arxiv.org/abs/2101.05390" target="_blank">arXiv:2101.05390</a> [<a href="http://arxiv.org/pdf/2101.05390" target="_blank">pdf</a>]

<h2>Should Ensemble Members Be Calibrated?. (arXiv:2101.05397v1 [cs.LG])</h2>
<h3>Xixin Wu, Mark Gales</h3>
<p>Underlying the use of statistical approaches for a wide range of applications
is the assumption that the probabilities obtained from a statistical model are
representative of the "true" probability that event, or outcome, will occur.
Unfortunately, for modern deep neural networks this is not the case, they are
often observed to be poorly calibrated. Additionally, these deep learning
approaches make use of large numbers of model parameters, motivating the use of
Bayesian, or ensemble approximation, approaches to handle issues with parameter
estimation. This paper explores the application of calibration schemes to deep
ensembles from both a theoretical perspective and empirically on a standard
image classification task, CIFAR-100. The underlying theoretical requirements
for calibration, and associated calibration criteria, are first described. It
is shown that well calibrated ensemble members will not necessarily yield a
well calibrated ensemble prediction, and if the ensemble prediction is well
calibrated its performance cannot exceed that of the average performance of the
calibrated ensemble members. On CIFAR-100 the impact of calibration for
ensemble prediction, and associated calibration is evaluated. Additionally the
situation where multiple different topologies are combined together is
discussed.
</p>
<a href="http://arxiv.org/abs/2101.05397" target="_blank">arXiv:2101.05397</a> [<a href="http://arxiv.org/pdf/2101.05397" target="_blank">pdf</a>]

<h2>Image deblurring based on lightweight multi-information fusion network. (arXiv:2101.05403v1 [cs.CV])</h2>
<h3>Yanni Zhang, Yiming Liu, Qiang Li, Miao Qi, Dahong Xu, Jun Kong, Jianzhong Wang</h3>
<p>Recently, deep learning based image deblurring has been well developed.
However, exploiting the detailed image features in a deep learning framework
always requires a mass of parameters, which inevitably makes the network suffer
from high computational burden. To solve this problem, we propose a lightweight
multiinformation fusion network (LMFN) for image deblurring. The proposed LMFN
is designed as an encoder-decoder architecture. In the encoding stage, the
image feature is reduced to various smallscale spaces for multi-scale
information extraction and fusion without a large amount of information loss.
Then, a distillation network is used in the decoding stage, which allows the
network benefit the most from residual learning while remaining sufficiently
lightweight. Meanwhile, an information fusion strategy between distillation
modules and feature channels is also carried out by attention mechanism.
Through fusing different information in the proposed approach, our network can
achieve state-of-the-art image deblurring result with smaller number of
parameters and outperforms existing methods in model complexity.
</p>
<a href="http://arxiv.org/abs/2101.05403" target="_blank">arXiv:2101.05403</a> [<a href="http://arxiv.org/pdf/2101.05403" target="_blank">pdf</a>]

<h2>Enclosing the Sliding Surfaces of a Controlled Swing. (arXiv:2101.05418v1 [cs.RO])</h2>
<h3>Luc Jaulin (Robex, Lab-STICC), Beno&#xee;t Desrochers (DGA-TN)</h3>
<p>When implementing a non-continuous controller for a cyber-physical system, it
may happen that the evolution of the closed-loop system is not anymore
piecewise differentiable along the trajectory, mainly due to conditional
statements inside the controller. This may lead to some unwanted chattering
effects than may damage the system. This behavior is difficult to observe even
in simulation. In this paper, we propose an interval approach to characterize
the sliding surface which corresponds to the set of all states such that the
state trajectory may jump indefinitely between two distinct behaviors. We show
that the recent notion of thick sets will allows us to compute efficiently an
outer approximation of the sliding surface of a given class of hybrid system
taking into account all set-membership uncertainties. An application to the
verification of the controller of a child swing is considered to illustrate the
principle of the approach.
</p>
<a href="http://arxiv.org/abs/2101.05418" target="_blank">arXiv:2101.05418</a> [<a href="http://arxiv.org/pdf/2101.05418" target="_blank">pdf</a>]

<h2>DAIL: Dataset-Aware and Invariant Learning for Face Recognition. (arXiv:2101.05419v1 [cs.CV])</h2>
<h3>Gaoang Wang, Lin Chen, Tianqiang Liu, Mingwei He, Jiebo Luo</h3>
<p>To achieve good performance in face recognition, a large scale training
dataset is usually required. A simple yet effective way to improve recognition
performance is to use a dataset as large as possible by combining multiple
datasets in the training. However, it is problematic and troublesome to naively
combine different datasets due to two major issues. First, the same person can
possibly appear in different datasets, leading to an identity overlapping issue
between different datasets. Naively treating the same person as different
classes in different datasets during training will affect back-propagation and
generate non-representative embeddings. On the other hand, manually cleaning
labels may take formidable human efforts, especially when there are millions of
images and thousands of identities. Second, different datasets are collected in
different situations and thus will lead to different domain distributions.
Naively combining datasets will make it difficult to learn domain invariant
embeddings across different datasets. In this paper, we propose DAIL:
Dataset-Aware and Invariant Learning to resolve the above-mentioned issues. To
solve the first issue of identity overlapping, we propose a dataset-aware loss
for multi-dataset training by reducing the penalty when the same person appears
in multiple datasets. This can be readily achieved with a modified softmax loss
with a dataset-aware term. To solve the second issue, domain adaptation with
gradient reversal layers is employed for dataset invariant learning. The
proposed approach not only achieves state-of-the-art results on several
commonly used face recognition validation sets, including LFW, CFP-FP, and
AgeDB-30, but also shows great benefit for practical use.
</p>
<a href="http://arxiv.org/abs/2101.05419" target="_blank">arXiv:2101.05419</a> [<a href="http://arxiv.org/pdf/2101.05419" target="_blank">pdf</a>]

<h2>Federated Learning: Opportunities and Challenges. (arXiv:2101.05428v1 [cs.LG])</h2>
<h3>Priyanka Mary Mammen</h3>
<p>Federated Learning (FL) is a concept first introduced by Google in 2016, in
which multiple devices collaboratively learn a machine learning model without
sharing their private data under the supervision of a central server. This
offers ample opportunities in critical domains such as healthcare, finance etc,
where it is risky to share private user information to other organisations or
devices. While FL appears to be a promising Machine Learning (ML) technique to
keep the local data private, it is also vulnerable to attacks like other ML
models. Given the growing interest in the FL domain, this report discusses the
opportunities and challenges in federated learning.
</p>
<a href="http://arxiv.org/abs/2101.05428" target="_blank">arXiv:2101.05428</a> [<a href="http://arxiv.org/pdf/2101.05428" target="_blank">pdf</a>]

<h2>Interpreting and Predicting Tactile Signals for the SynTouch BioTac. (arXiv:2101.05452v1 [cs.RO])</h2>
<h3>Yashraj S. Narang, Balakumar Sundaralingam, Karl Van Wyk, Arsalan Mousavian, Dieter Fox</h3>
<p>In the human hand, high-density contact information provided by afferent
neurons is essential for many human grasping and manipulation capabilities. In
contrast, robotic tactile sensors, including the state-of-the-art SynTouch
BioTac, are typically used to provide low-density contact information, such as
contact location, center of pressure, and net force. Although useful, these
data do not convey or leverage the rich information content that some tactile
sensors naturally measure. This research extends robotic tactile sensing beyond
reduced-order models through 1) the automated creation of a precise
experimental tactile dataset for the BioTac over a diverse range of physical
interactions, 2) a 3D finite element (FE) model of the BioTac, which
complements the experimental dataset with high-density, distributed contact
data, 3) neural-network-based mappings from raw BioTac signals to not only
low-dimensional experimental data, but also high-density FE deformation fields,
and 4) mappings from the FE deformation fields to the raw signals themselves.
The high-density data streams can provide a far greater quantity of
interpretable information for grasping and manipulation algorithms than
previously accessible.
</p>
<a href="http://arxiv.org/abs/2101.05452" target="_blank">arXiv:2101.05452</a> [<a href="http://arxiv.org/pdf/2101.05452" target="_blank">pdf</a>]

<h2>On the quantization of recurrent neural networks. (arXiv:2101.05453v1 [cs.LG])</h2>
<h3>Jian Li, Raziel Alvarez</h3>
<p>Integer quantization of neural networks can be defined as the approximation
of the high precision computation of the canonical neural network formulation,
using reduced integer precision. It plays a significant role in the efficient
deployment and execution of machine learning (ML) systems, reducing memory
consumption and leveraging typically faster computations. In this work, we
present an integer-only quantization strategy for Long Short-Term Memory (LSTM)
neural network topologies, which themselves are the foundation of many
production ML systems. Our quantization strategy is accurate (e.g. works well
with quantization post-training), efficient and fast to execute (utilizing 8
bit integer weights and mostly 8 bit activations), and is able to target a
variety of hardware (by leveraging instructions sets available in common CPU
architectures, as well as available neural accelerators).
</p>
<a href="http://arxiv.org/abs/2101.05453" target="_blank">arXiv:2101.05453</a> [<a href="http://arxiv.org/pdf/2101.05453" target="_blank">pdf</a>]

<h2>Self-Supervised Learning for Segmentation. (arXiv:2101.05456v1 [cs.CV])</h2>
<h3>Abhinav Dhere, Jayanthi Sivaswamy</h3>
<p>Self-supervised learning is emerging as an effective substitute for transfer
learning from large datasets. In this work, we use kidney segmentation to
explore this idea. The anatomical asymmetry of kidneys is leveraged to define
an effective proxy task for kidney segmentation via self-supervised learning. A
siamese convolutional neural network (CNN) is used to classify a given pair of
kidney sections from CT volumes as being kidneys of the same or different
sides. This knowledge is then transferred for the segmentation of kidneys using
another deep CNN using one branch of the siamese CNN as the encoder for the
segmentation network. Evaluation results on a publicly available dataset
containing computed tomography (CT) scans of the abdominal region shows that a
boost in performance and fast convergence can be had relative to a network
trained conventionally from scratch. This is notable given that no additional
data/expensive annotations or augmentation were used in training.
</p>
<a href="http://arxiv.org/abs/2101.05456" target="_blank">arXiv:2101.05456</a> [<a href="http://arxiv.org/pdf/2101.05456" target="_blank">pdf</a>]

<h2>Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model. (arXiv:2101.05467v1 [cs.LG])</h2>
<h3>Qizhou Wang, Bo Han, Tongliang Liu, Gang Niu, Jian Yang, Chen Gong</h3>
<p>The drastic increase of data quantity often brings the severe decrease of
data quality, such as incorrect label annotations, which poses a great
challenge for robustly training Deep Neural Networks (DNNs). Existing learning
\mbox{methods} with label noise either employ ad-hoc heuristics or restrict to
specific noise assumptions. However, more general situations, such as
instance-dependent label noise, have not been fully explored, as scarce studies
focus on their label corruption process. By categorizing instances into
confusing and unconfusing instances, this paper proposes a simple yet universal
probabilistic model, which explicitly relates noisy labels to their instances.
The resultant model can be realized by DNNs, where the training procedure is
accomplished by employing an alternating optimization algorithm. Experiments on
datasets with both synthetic and real-world label noise verify that the
proposed method yields significant improvements on robustness over
state-of-the-art counterparts.
</p>
<a href="http://arxiv.org/abs/2101.05467" target="_blank">arXiv:2101.05467</a> [<a href="http://arxiv.org/pdf/2101.05467" target="_blank">pdf</a>]

<h2>OrigamiSet1.0: Two New Datasets for Origami Classification and Difficulty Estimation. (arXiv:2101.05470v1 [cs.CV])</h2>
<h3>Daniel Ma, Gerald Friedland, Mario Michael Krell</h3>
<p>Origami is becoming more and more relevant to research. However, there is no
public dataset yet available and there hasn't been any research on this topic
in machine learning. We constructed an origami dataset using images from the
multimedia commons and other databases. It consists of two subsets: one for
classification of origami images and the other for difficulty estimation. We
obtained 16000 images for classification (half origami, half other objects) and
1509 for difficulty estimation with $3$ different categories (easy: 764,
intermediate: 427, complex: 318). The data can be downloaded at:
https://github.com/multimedia-berkeley/OriSet. Finally, we provide machine
learning baselines.
</p>
<a href="http://arxiv.org/abs/2101.05470" target="_blank">arXiv:2101.05470</a> [<a href="http://arxiv.org/pdf/2101.05470" target="_blank">pdf</a>]

<h2>Towards Practical Adam: Non-Convexity, Convergence Theory, and Mini-Batch Acceleration. (arXiv:2101.05471v1 [cs.LG])</h2>
<h3>Congliang Chen, Li Shen, Fangyu Zou, Wei Liu</h3>
<p>Adam is one of the most influential adaptive stochastic algorithms for
training deep neural networks, which has been pointed out to be divergent even
in the simple convex setting via a few simple counterexamples. Many attempts,
such as decreasing an adaptive learning rate, adopting a big batch size,
incorporating a temporal decorrelation technique, seeking an analogous
surrogate, \textit{etc.}, have been tried to promote Adam-type algorithms to
converge. In contrast with existing approaches, we introduce an alternative
easy-to-check sufficient condition, which merely depends on the parameters of
the base learning rate and combinations of historical second-order moments, to
guarantee the global convergence of generic Adam for solving large-scale
non-convex stochastic optimization. This observation coupled with this
sufficient condition gives much deeper interpretations on the divergence of
Adam. On the other hand, in practice, mini-Adam and distributed-Adam are widely
used without theoretical guarantee, we further give an analysis on how will the
batch size or the number of nodes in the distributed system will affect the
convergence of Adam, which theoretically shows that mini-batch and distributed
Adam can be linearly accelerated by using a larger mini-batch size or more
number of nodes. At last, we apply the generic Adam and mini-batch Adam with a
sufficient condition for solving the counterexample and training several
different neural networks on various real-world datasets. Experimental results
are exactly in accord with our theoretical analysis.
</p>
<a href="http://arxiv.org/abs/2101.05471" target="_blank">arXiv:2101.05471</a> [<a href="http://arxiv.org/pdf/2101.05471" target="_blank">pdf</a>]

<h2>Understanding the Role of Scene Graphs in Visual Question Answering. (arXiv:2101.05479v1 [cs.CV])</h2>
<h3>Vinay Damodaran, Sharanya Chakravarthy, Akshay Kumar, Anjana Umapathy, Teruko Mitamura, Yuta Nakashima, Noa Garcia, Chenhui Chu</h3>
<p>Visual Question Answering (VQA) is of tremendous interest to the research
community with important applications such as aiding visually impaired users
and image-based search. In this work, we explore the use of scene graphs for
solving the VQA task. We conduct experiments on the GQA dataset which presents
a challenging set of questions requiring counting, compositionality and
advanced reasoning capability, and provides scene graphs for a large number of
images. We adopt image + question architectures for use with scene graphs,
evaluate various scene graph generation techniques for unseen images, propose a
training curriculum to leverage human-annotated and auto-generated scene
graphs, and build late fusion architectures to learn from multiple image
representations. We present a multi-faceted study into the use of scene graphs
for VQA, making this work the first of its kind.
</p>
<a href="http://arxiv.org/abs/2101.05479" target="_blank">arXiv:2101.05479</a> [<a href="http://arxiv.org/pdf/2101.05479" target="_blank">pdf</a>]

<h2>4D Attention-based Neural Network for EEG Emotion Recognition. (arXiv:2101.05484v1 [cs.LG])</h2>
<h3>Guowen Xiao, Mengwen Ye, Bowen Xu, Zhendi Chen, Quansheng Ren</h3>
<p>Electroencephalograph (EEG) emotion recognition is a significant task in the
brain-computer interface field. Although many deep learning methods are
proposed recently, it is still challenging to make full use of the information
contained in different domains of EEG signals. In this paper, we present a
novel method, called four-dimensional attention-based neural network (4D-aNN)
for EEG emotion recognition. First, raw EEG signals are transformed into 4D
spatial-spectral-temporal representations. Then, the proposed 4D-aNN adopts
spectral and spatial attention mechanisms to adaptively assign the weights of
different brain regions and frequency bands, and a convolutional neural network
(CNN) is utilized to deal with the spectral and spatial information of the 4D
representations. Moreover, a temporal attention mechanism is integrated into a
bidirectional Long Short-Term Memory (LSTM) to explore temporal dependencies of
the 4D representations. Our model achieves state-of-the-art performance on the
SEED dataset under intra-subject splitting. The experimental results have shown
the effectiveness of the attention mechanisms in different domains for EEG
emotion recognition.
</p>
<a href="http://arxiv.org/abs/2101.05484" target="_blank">arXiv:2101.05484</a> [<a href="http://arxiv.org/pdf/2101.05484" target="_blank">pdf</a>]

<h2>Label Contrastive Coding based Graph Neural Network for Graph Classification. (arXiv:2101.05486v1 [cs.LG])</h2>
<h3>Yuxiang Ren, Jiyang Bai, Jiawei Zhang</h3>
<p>Graph classification is a critical research problem in many applications from
different domains. In order to learn a graph classification model, the most
widely used supervision component is an output layer together with
classification loss (e.g.,cross-entropy loss together with softmax or margin
loss). In fact, the discriminative information among instances are more
fine-grained, which can benefit graph classification tasks. In this paper, we
propose the novel Label Contrastive Coding based Graph Neural Network (LCGNN)
to utilize label information more effectively and comprehensively. LCGNN still
uses the classification loss to ensure the discriminability of classes.
Meanwhile, LCGNN leverages the proposed Label Contrastive Loss derived from
self-supervised learning to encourage instance-level intra-class compactness
and inter-class separability. To power the contrastive learning, LCGNN
introduces a dynamic label memory bank and a momentum updated encoder. Our
extensive evaluations with eight benchmark graph datasets demonstrate that
LCGNN can outperform state-of-the-art graph classification models. Experimental
results also verify that LCGNN can achieve competitive performance with less
training data because LCGNN exploits label information comprehensively.
</p>
<a href="http://arxiv.org/abs/2101.05486" target="_blank">arXiv:2101.05486</a> [<a href="http://arxiv.org/pdf/2101.05486" target="_blank">pdf</a>]

<h2>Neural networks behave as hash encoders: An empirical study. (arXiv:2101.05490v1 [cs.LG])</h2>
<h3>Fengxiang He, Shiye Lei, Jianmin Ji, Dacheng Tao</h3>
<p>The input space of a neural network with ReLU-like activations is partitioned
into multiple linear regions, each corresponding to a specific activation
pattern of the included ReLU-like activations. We demonstrate that this
partition exhibits the following encoding properties across a variety of deep
learning models: (1) {\it determinism}: almost every linear region contains at
most one training example. We can therefore represent almost every training
example by a unique activation pattern, which is parameterized by a {\it neural
code}; and (2) {\it categorization}: according to the neural code, simple
algorithms, such as $K$-Means, $K$-NN, and logistic regression, can achieve
fairly good performance on both training and test data. These encoding
properties surprisingly suggest that {\it normal neural networks well-trained
for classification behave as hash encoders without any extra efforts.} In
addition, the encoding properties exhibit variability in different scenarios.
{Further experiments demonstrate that {\it model size}, {\it training time},
{\it training sample size}, {\it regularization}, and {\it label noise}
contribute in shaping the encoding properties, while the impacts of the first
three are dominant.} We then define an {\it activation hash phase chart} to
represent the space expanded by {model size}, training time, training sample
size, and the encoding properties, which is divided into three canonical
regions: {\it under-expressive regime}, {\it critically-expressive regime}, and
{\it sufficiently-expressive regime}. The source code package is available at
\url{https://github.com/LeavesLei/activation-code}.
</p>
<a href="http://arxiv.org/abs/2101.05490" target="_blank">arXiv:2101.05490</a> [<a href="http://arxiv.org/pdf/2101.05490" target="_blank">pdf</a>]

<h2>Joint Dimensionality Reduction for Separable Embedding Estimation. (arXiv:2101.05500v1 [cs.LG])</h2>
<h3>Yanjun Li, Bihan Wen, Hao Cheng, Yoram Bresler</h3>
<p>Low-dimensional embeddings for data from disparate sources play critical
roles in multi-modal machine learning, multimedia information retrieval, and
bioinformatics. In this paper, we propose a supervised dimensionality reduction
method that learns linear embeddings jointly for two feature vectors
representing data of different modalities or data from distinct types of
entities. We also propose an efficient feature selection method that
complements, and can be applied prior to, our joint dimensionality reduction
method. Assuming that there exist true linear embeddings for these features,
our analysis of the error in the learned linear embeddings provides theoretical
guarantees that the dimensionality reduction method accurately estimates the
true embeddings when certain technical conditions are satisfied and the number
of samples is sufficiently large. The derived sample complexity results are
echoed by numerical experiments. We apply the proposed dimensionality reduction
method to gene-disease association, and predict unknown associations using
kernel regression on the dimension-reduced feature vectors. Our approach
compares favorably against other dimensionality reduction methods, and against
a state-of-the-art method of bilinear regression for predicting gene-disease
associations.
</p>
<a href="http://arxiv.org/abs/2101.05500" target="_blank">arXiv:2101.05500</a> [<a href="http://arxiv.org/pdf/2101.05500" target="_blank">pdf</a>]

<h2>Reliability Check via Weight Similarity in Privacy-Preserving Multi-Party Machine Learning. (arXiv:2101.05504v1 [cs.LG])</h2>
<h3>Kennedy Edemacu, Beakcheol Jang, Jong Wook Kim</h3>
<p>Multi-party machine learning is a paradigm in which multiple participants
collaboratively train a machine learning model to achieve a common learning
objective without sharing their privately owned data. The paradigm has recently
received a lot of attention from the research community aimed at addressing its
associated privacy concerns. In this work, we focus on addressing the concerns
of data privacy, model privacy, and data quality associated with
privacy-preserving multi-party machine learning, i.e., we present a scheme for
privacy-preserving collaborative learning that checks the participants' data
quality while guaranteeing data and model privacy. In particular, we propose a
novel metric called weight similarity that is securely computed and used to
check whether a participant can be categorized as a reliable participant (holds
good quality data) or not. The problems of model and data privacy are tackled
by integrating homomorphic encryption in our scheme and uploading encrypted
weights, which prevent leakages to the server and malicious participants,
respectively. The analytical and experimental evaluations of our scheme
demonstrate that it is accurate and ensures data and model privacy.
</p>
<a href="http://arxiv.org/abs/2101.05504" target="_blank">arXiv:2101.05504</a> [<a href="http://arxiv.org/pdf/2101.05504" target="_blank">pdf</a>]

<h2>Evaluating the Robustness of Collaborative Agents. (arXiv:2101.05507v1 [cs.LG])</h2>
<h3>Paul Knott, Micah Carroll, Sam Devlin, Kamil Ciosek, Katja Hofmann, A. D. Dragan, Rohin Shah</h3>
<p>In order for agents trained by deep reinforcement learning to work alongside
humans in realistic settings, we will need to ensure that the agents are
\emph{robust}. Since the real world is very diverse, and human behavior often
changes in response to agent deployment, the agent will likely encounter novel
situations that have never been seen during training. This results in an
evaluation challenge: if we cannot rely on the average training or validation
reward as a metric, then how can we effectively evaluate robustness? We take
inspiration from the practice of \emph{unit testing} in software engineering.
Specifically, we suggest that when designing AI agents that collaborate with
humans, designers should search for potential edge cases in \emph{possible
partner behavior} and \emph{possible states encountered}, and write tests which
check that the behavior of the agent in these edge cases is reasonable. We
apply this methodology to build a suite of unit tests for the Overcooked-AI
environment, and use this test suite to evaluate three proposals for improving
robustness. We find that the test suite provides significant insight into the
effects of these proposals that were generally not revealed by looking solely
at the average validation reward.
</p>
<a href="http://arxiv.org/abs/2101.05507" target="_blank">arXiv:2101.05507</a> [<a href="http://arxiv.org/pdf/2101.05507" target="_blank">pdf</a>]

<h2>Entangled Kernels -- Beyond Separability. (arXiv:2101.05514v1 [cs.LG])</h2>
<h3>Riikka Huusari, Hachem Kadri</h3>
<p>We consider the problem of operator-valued kernel learning and investigate
the possibility of going beyond the well-known separable kernels. Borrowing
tools and concepts from the field of quantum computing, such as partial trace
and entanglement, we propose a new view on operator-valued kernels and define a
general family of kernels that encompasses previously known operator-valued
kernels, including separable and transformable kernels. Within this framework,
we introduce another novel class of operator-valued kernels called entangled
kernels that are not separable. We propose an efficient two-step algorithm for
this framework, where the entangled kernel is learned based on a novel
extension of kernel alignment to operator-valued kernels. We illustrate our
algorithm with an application to supervised dimensionality reduction, and
demonstrate its effectiveness with both artificial and real data for
multi-output regression.
</p>
<a href="http://arxiv.org/abs/2101.05514" target="_blank">arXiv:2101.05514</a> [<a href="http://arxiv.org/pdf/2101.05514" target="_blank">pdf</a>]

<h2>BiGCN: A Bi-directional Low-Pass Filtering Graph Neural Network. (arXiv:2101.05519v1 [cs.LG])</h2>
<h3>Zhixian Chen, Tengfei Ma, Zhihua Jin, Yangqiu Song, Yang Wang</h3>
<p>Graph convolutional networks have achieved great success on graph-structured
data. Many graph convolutional networks can be regarded as low-pass filters for
graph signals. In this paper, we propose a new model, BiGCN, which represents a
graph neural network as a bi-directional low-pass filter. Specifically, we not
only consider the original graph structure information but also the latent
correlation between features, thus BiGCN can filter the signals along with both
the original graph and a latent feature-connection graph. Our model outperforms
previous graph neural networks in the tasks of node classification and link
prediction on most of the benchmark datasets, especially when we add noise to
the node features.
</p>
<a href="http://arxiv.org/abs/2101.05519" target="_blank">arXiv:2101.05519</a> [<a href="http://arxiv.org/pdf/2101.05519" target="_blank">pdf</a>]

<h2>Scaling Equilibrium Propagation to Deep ConvNets by Drastically Reducing its Gradient Estimator Bias. (arXiv:2101.05536v1 [cs.LG])</h2>
<h3>Axel Laborieux, Maxence Ernoult, Benjamin Scellier, Yoshua Bengio, Julie Grollier, Damien Querlioz</h3>
<p>Equilibrium Propagation (EP) is a biologically-inspired counterpart of
Backpropagation Through Time (BPTT) which, owing to its strong theoretical
guarantees and the locality in space of its learning rule, fosters the design
of energy-efficient hardware dedicated to learning. In practice, however, EP
does not scale to visual tasks harder than MNIST. In this work, we show that a
bias in the gradient estimate of EP, inherent in the use of finite nudging, is
responsible for this phenomenon and that cancelling it allows training deep
ConvNets by EP, including architectures with distinct forward and backward
connections. These results highlight EP as a scalable approach to compute error
gradients in deep neural networks, thereby motivating its hardware
implementation.
</p>
<a href="http://arxiv.org/abs/2101.05536" target="_blank">arXiv:2101.05536</a> [<a href="http://arxiv.org/pdf/2101.05536" target="_blank">pdf</a>]

<h2>DICE: Diversity in Deep Ensembles via Conditional Redundancy Adversarial Estimation. (arXiv:2101.05544v1 [cs.LG])</h2>
<h3>Alexandre Rame, Matthieu Cord</h3>
<p>Deep ensembles perform better than a single network thanks to the diversity
among their members. Recent approaches regularize predictions to increase
diversity; however, they also drastically decrease individual members'
performances. In this paper, we argue that learning strategies for deep
ensembles need to tackle the trade-off between ensemble diversity and
individual accuracies. Motivated by arguments from information theory and
leveraging recent advances in neural estimation of conditional mutual
information, we introduce a novel training criterion called DICE: it increases
diversity by reducing spurious correlations among features. The main idea is
that features extracted from pairs of members should only share information
useful for target class prediction without being conditionally redundant.
Therefore, besides the classification loss with information bottleneck, we
adversarially prevent features from being conditionally predictable from each
other. We manage to reduce simultaneous errors while protecting class
information. We obtain state-of-the-art accuracy results on CIFAR-10/100: for
example, an ensemble of 5 networks trained with DICE matches an ensemble of 7
networks trained independently. We further analyze the consequences on
calibration, uncertainty estimation, out-of-distribution detection and online
co-distillation.
</p>
<a href="http://arxiv.org/abs/2101.05544" target="_blank">arXiv:2101.05544</a> [<a href="http://arxiv.org/pdf/2101.05544" target="_blank">pdf</a>]

<h2>FabricNet: A Fiber Recognition Architecture Using Ensemble ConvNets. (arXiv:2101.05564v1 [cs.CV])</h2>
<h3>Abu Quwsar Ohi, M. F. Mridha, Md. Abdul Hamid, Muhammad Mostafa Monowar, Faris A Kateb</h3>
<p>Fabric is a planar material composed of textile fibers. Textile fibers are
generated from many natural sources; including plants, animals, minerals, and
even, it can be synthetic. A particular fabric may contain different types of
fibers that pass through a complex production process. Fiber identification is
usually carried out through chemical tests and microscopic tests. However,
these testing processes are complicated as well as time-consuming. We propose
FabricNet, a pioneering approach for the image-based textile fiber recognition
system, which may have a revolutionary impact from individual to the industrial
fiber recognition process. The FabricNet can recognize a large scale of fibers
by only utilizing a surface image of fabric. The recognition system is
constructed using a distinct category of class-based ensemble convolutional
neural network (CNN) architecture. The experiment is conducted on recognizing
50 different types of textile fibers. This experiment includes a significantly
large number of unique textile fibers than previous research endeavors to the
best of our knowledge. We experiment with popular CNN architectures that
include Inception, ResNet, VGG, MobileNet, DenseNet, and Xception. Finally, the
experimental results demonstrate that FabricNet outperforms the
state-of-the-art popular CNN architectures by reaching an accuracy of 84% and
F1-score of 90%.
</p>
<a href="http://arxiv.org/abs/2101.05564" target="_blank">arXiv:2101.05564</a> [<a href="http://arxiv.org/pdf/2101.05564" target="_blank">pdf</a>]

<h2>TypeNet: Deep Learning Keystroke Biometrics. (arXiv:2101.05570v1 [cs.CV])</h2>
<h3>Alejandro Acien, Aythami Morales, John V. Monaco, Ruben Vera-Rodriguez, Julian Fierrez</h3>
<p>We study the performance of Long Short-Term Memory networks for keystroke
biometric authentication at large scale in free-text scenarios. For this we
introduce TypeNet, a Recurrent Neural Network (RNN) trained with a moderate
number of keystrokes per identity. We evaluate different learning approaches
depending on the loss function (softmax, contrastive, and triplet loss), number
of gallery samples, length of the keystroke sequences, and device type
(physical vs touchscreen keyboard). With 5 gallery sequences and test sequences
of length 50, TypeNet achieves state-of-the-art keystroke biometric
authentication performance with an Equal Error Rate of 2.2% and 9.2% for
physical and touchscreen keyboards, respectively, significantly outperforming
previous approaches. Our experiments demonstrate a moderate increase in error
with up to 100,000 subjects, demonstrating the potential of TypeNet to operate
at an Internet scale. We utilize two Aalto University keystroke databases, one
captured on physical keyboards and the second on mobile devices (touchscreen
keyboards). To the best of our knowledge, both databases are the largest
existing free-text keystroke databases available for research with more than
136 million keystrokes from 168,000 subjects in physical keyboards, and 60,000
subjects with more than 63 million keystrokes acquired on mobile touchscreens.
</p>
<a href="http://arxiv.org/abs/2101.05570" target="_blank">arXiv:2101.05570</a> [<a href="http://arxiv.org/pdf/2101.05570" target="_blank">pdf</a>]

<h2>A Physics-Informed Machine Learning Model for Porosity Analysis in Laser Powder Bed Fusion Additive Manufacturing. (arXiv:2101.05605v1 [cs.LG])</h2>
<h3>Rui Liu, Sen Liu, Xiaoli Zhang</h3>
<p>To control part quality, it is critical to analyze pore generation
mechanisms, laying theoretical foundation for future porosity control. Current
porosity analysis models use machine setting parameters, such as laser angle
and part pose. However, these setting-based models are machine dependent, hence
they often do not transfer to analysis of porosity for a different machine. To
address the first problem, a physics-informed, data-driven model (PIM), which
instead of directly using machine setting parameters to predict porosity levels
of printed parts, it first interprets machine settings into physical effects,
such as laser energy density and laser radiation pressure. Then, these
physical, machine independent effects are used to predict porosity levels
according to pass, flag, fail categories instead of focusing on quantitative
pore size prediction. With six learning methods evaluation, PIM proved to
achieve good performances with prediction error of 10$\sim$26%. Finally,
pore-encouraging influence and pore-suppressing influence were analyzed for
quality analysis.
</p>
<a href="http://arxiv.org/abs/2101.05605" target="_blank">arXiv:2101.05605</a> [<a href="http://arxiv.org/pdf/2101.05605" target="_blank">pdf</a>]

<h2>Deep Cellular Recurrent Network for Efficient Analysis of Time-Series Data with Spatial Information. (arXiv:2101.05608v1 [cs.LG])</h2>
<h3>Lasitha Vidyaratne, Mahbubul Alam, Alexander Glandon, Anna Shabalina, Christopher Tennant, Khan Iftekharuddin</h3>
<p>Efficient processing of large-scale time series data is an intricate problem
in machine learning. Conventional sensor signal processing pipelines with hand
engineered feature extraction often involve huge computational cost with high
dimensional data. Deep recurrent neural networks have shown promise in
automated feature learning for improved time-series processing. However,
generic deep recurrent models grow in scale and depth with increased complexity
of the data. This is particularly challenging in presence of high dimensional
data with temporal and spatial characteristics. Consequently, this work
proposes a novel deep cellular recurrent neural network (DCRNN) architecture to
efficiently process complex multi-dimensional time series data with spatial
information. The cellular recurrent architecture in the proposed model allows
for location-aware synchronous processing of time series data from spatially
distributed sensor signal sources. Extensive trainable parameter sharing due to
cellularity in the proposed architecture ensures efficiency in the use of
recurrent processing units with high-dimensional inputs. This study also
investigates the versatility of the proposed DCRNN model for classification of
multi-class time series data from different application domains. Consequently,
the proposed DCRNN architecture is evaluated using two time-series datasets: a
multichannel scalp EEG dataset for seizure detection, and a machine fault
detection dataset obtained in-house. The results suggest that the proposed
architecture achieves state-of-the-art performance while utilizing
substantially less trainable parameters when compared to comparable methods in
the literature.
</p>
<a href="http://arxiv.org/abs/2101.05608" target="_blank">arXiv:2101.05608</a> [<a href="http://arxiv.org/pdf/2101.05608" target="_blank">pdf</a>]

<h2>A SOM-based Gradient-Free Deep Learning Method with Convergence Analysis. (arXiv:2101.05612v1 [cs.LG])</h2>
<h3>Shaosheng Xu, Jinde Cao, Yichao Cao, Tong Wang</h3>
<p>As gradient descent method in deep learning causes a series of questions,
this paper proposes a novel gradient-free deep learning structure. By adding a
new module into traditional Self-Organizing Map and introducing residual into
the map, a Deep Valued Self-Organizing Map network is constructed. And analysis
about the convergence performance of such a deep Valued Self-Organizing Map
network is proved in this paper, which gives an inequality about the designed
parameters with the dimension of inputs and the loss of prediction.
</p>
<a href="http://arxiv.org/abs/2101.05612" target="_blank">arXiv:2101.05612</a> [<a href="http://arxiv.org/pdf/2101.05612" target="_blank">pdf</a>]

<h2>FBGEMM: Enabling High-Performance Low-Precision Deep Learning Inference. (arXiv:2101.05615v1 [cs.LG])</h2>
<h3>Daya Khudia, Jianyu Huang, Protonu Basu, Summer Deng, Haixin Liu, Jongsoo Park, Mikhail Smelyanskiy</h3>
<p>Deep learning models typically use single-precision (FP32) floating point
data types for representing activations and weights, but a slew of recent
research work has shown that computations with reduced-precision data types
(FP16, 16-bit integers, 8-bit integers or even 4- or 2-bit integers) are enough
to achieve same accuracy as FP32 and are much more efficient. Therefore, we
designed fbgemm, a high-performance kernel library, from ground up to perform
high-performance quantized inference on current generation CPUs. fbgemm
achieves efficiency by fusing common quantization operations with a
high-performance gemm implementation and by shape- and size-specific kernel
code generation at runtime. The library has been deployed at Facebook, where it
delivers greater than 2x performance gains with respect to our current
production baseline.
</p>
<a href="http://arxiv.org/abs/2101.05615" target="_blank">arXiv:2101.05615</a> [<a href="http://arxiv.org/pdf/2101.05615" target="_blank">pdf</a>]

<h2>Road Surface Translation Under Snow-covered and Semantic Segmentation for Snow Hazard Index. (arXiv:2101.05616v1 [cs.CV])</h2>
<h3>Yasuno Takato, Fujii Junichiro, Sugawara Hiroaki, Amakata Masazumi</h3>
<p>In 2020, record heavy snowfall have been occurred owing to climate change.
Actually, 2,000 vehicles on the highway could get stuck for three days. Due to
the freezing of the road surface, 10 vehicles could have a billiard accident.
Road managers are required to provide them immediately in order to alert
drivers to snow cover at hazardous location. This paper proposes a deep
learning application with CCTV image post-processing to automatically calculate
a snow hazard indicator. First, the road surface of hidden region under
snow-covered is translated using generative adversarial network, pix2pix.
Second, snow-covered and road surface classes are detected using semantic
segmentation, DeepLabv3+ under backbone MobileNet. Based on these trained
networks, we enable to automatically compute the road to snow rate hazard index
how much snow is covered on the road surface. We demonstrate the applied
results to 1,000 CCTV snow images on Hokkaido and North Tohoku area in Japan.
We mention the usefulness and the practical robustness.
</p>
<a href="http://arxiv.org/abs/2101.05616" target="_blank">arXiv:2101.05616</a> [<a href="http://arxiv.org/pdf/2101.05616" target="_blank">pdf</a>]

<h2>A Framework for Assurance of Medication Safety using Machine Learning. (arXiv:2101.05620v1 [cs.LG])</h2>
<h3>Yan Jia, Tom Lawton, John McDermid, Eric Rojas, Ibrahim Habli</h3>
<p>Medication errors continue to be the leading cause of avoidable patient harm
in hospitals. This paper sets out a framework to assure medication safety that
combines machine learning and safety engineering methods. It uses safety
analysis to proactively identify potential causes of medication error, based on
expert opinion. As healthcare is now data rich, it is possible to augment
safety analysis with machine learning to discover actual causes of medication
error from the data, and to identify where they deviate from what was predicted
in the safety analysis. Combining these two views has the potential to enable
the risk of medication errors to be managed proactively and dynamically. We
apply the framework to a case study involving thoracic surgery, e.g.
oesophagectomy, where errors in giving beta-blockers can be critical to control
atrial fibrillation. This case study combines a HAZOP-based safety analysis
method known as SHARD with Bayesian network structure learning and process
mining to produce the analysis results, showing the potential of the framework
for ensuring patient safety, and for transforming the way that safety is
managed in complex healthcare environments.
</p>
<a href="http://arxiv.org/abs/2101.05620" target="_blank">arXiv:2101.05620</a> [<a href="http://arxiv.org/pdf/2101.05620" target="_blank">pdf</a>]

<h2>Design of borehole resistivity measurement acquisition systems using deep learning. (arXiv:2101.05623v1 [cs.LG])</h2>
<h3>M. Shahriari, A. Hazra, D. Pardo</h3>
<p>Borehole resistivity measurements recorded with logging-while-drilling (LWD)
instruments are widely used for characterizing the earth's subsurface
properties. They facilitate the extraction of natural resources such as oil and
gas. LWD instruments require real-time inversions of electromagnetic
measurements to estimate the electrical properties of the earth's subsurface
near the well and possibly correct the well trajectory. Deep Neural Network
(DNN)-based methods are suitable for the rapid inversion of borehole
resistivity measurements as they approximate the forward and inverse problem
offline during the training phase and they only require a fraction of a second
for the evaluation (aka prediction). However, the inverse problem generally
admits multiple solutions. DNNs with traditional loss functions based on data
misfit are ill-equipped for solving an inverse problem. This can be partially
overcome by adding regularization terms to a loss function specifically
designed for encoder-decoder architectures. But adding regularization seriously
limits the number of possible solutions to a set of a priori desirable physical
solutions. To avoid this, we use a two-step loss function without any
regularization. In addition, to guarantee an inverse solution, we need a
carefully selected measurement acquisition system with a sufficient number of
measurements. In this work, we propose a DNN-based iterative algorithm for
designing such a measurement acquisition system. We illustrate our DNN-based
iterative algorithm via several synthetic examples. Numerical results show that
the obtained measurement acquisition system is sufficient to identify and
characterize both resistive and conductive layers above and below the logging
instrument. Numerical results are promising, although further improvements are
required to make our method amenable for industrial purposes.
</p>
<a href="http://arxiv.org/abs/2101.05623" target="_blank">arXiv:2101.05623</a> [<a href="http://arxiv.org/pdf/2101.05623" target="_blank">pdf</a>]

<h2>Adversarially robust and explainable model compression with on-device personalization for NLP applications. (arXiv:2101.05624v1 [cs.LG])</h2>
<h3>Yao Qiang, Supriya Tumkur Suresh Kumar, Marco Brocanelli, Dongxiao Zhu</h3>
<p>On-device Deep Neural Networks (DNNs) have recently gained more attention due
to the increasing computing power of the mobile devices and the number of
applications in Computer Vision (CV), Natural Language Processing (NLP), and
Internet of Things (IoTs). Unfortunately, the existing efficient convolutional
neural network (CNN) architectures designed for CV tasks are not directly
applicable to NLP tasks and the tiny Recurrent Neural Network (RNN)
architectures have been designed primarily for IoT applications. In NLP
applications, although model compression has seen initial success in on-device
text classification, there are at least three major challenges yet to be
addressed: adversarial robustness, explainability, and personalization. Here we
attempt to tackle these challenges by designing a new training scheme for model
compression and adversarial robustness, including the optimization of an
explainable feature mapping objective, a knowledge distillation objective, and
an adversarially robustness objective. The resulting compressed model is
personalized using on-device private training data via fine-tuning. We perform
extensive experiments to compare our approach with both compact RNN (e.g.,
FastGRNN) and compressed RNN (e.g., PRADO) architectures in both natural and
adversarial NLP test settings.
</p>
<a href="http://arxiv.org/abs/2101.05624" target="_blank">arXiv:2101.05624</a> [<a href="http://arxiv.org/pdf/2101.05624" target="_blank">pdf</a>]

<h2>Parkinson's Disease Diagnosis Using Deep Learning. (arXiv:2101.05631v1 [cs.LG])</h2>
<h3>Mohamad Alissa</h3>
<p>Parkinson's Disease (PD) is a chronic, degenerative disorder which leads to a
range of motor and cognitive symptoms. PD diagnosis is a challenging task since
its symptoms are very similar to other diseases such as normal ageing and
essential tremor. Much research has been applied to diagnosing this disease.
This project aims to automate the PD diagnosis process using deep learning,
Recursive Neural Networks (RNN) and Convolutional Neural Networks (CNN), to
differentiate between healthy and PD patients. Besides that, since different
datasets may capture different aspects of this disease, this project aims to
explore which PD test is more effective in the discrimination process by
analysing different imaging and movement datasets (notably cube and spiral
pentagon datasets). In addition, this project evaluates which dataset type,
imaging or time series, is more effective in diagnosing PD.
</p>
<a href="http://arxiv.org/abs/2101.05631" target="_blank">arXiv:2101.05631</a> [<a href="http://arxiv.org/pdf/2101.05631" target="_blank">pdf</a>]

<h2>Enhanced Audit Techniques Empowered by the Reinforcement Learning Pertaining to IFRS 16 Lease. (arXiv:2101.05633v1 [cs.LG])</h2>
<h3>Byungryul Choi</h3>
<p>The purpose of accounting audit is to have clear understanding on the
financial activities of a company, which can be enhanced by machine learning or
reinforcement learning as numeric analysis better than manual analysis can be
made. For the purpose of assessment on the relevance, completeness and accuracy
of the information produced by entity pertaining to the newly implemented
International Financial Reporting Standard 16 Lease (IFRS 16) is one of such
candidates as its characteristic of requiring the understanding on the nature
of contracts and its complete analysis from listing up without omission, which
can be enhanced by the digitalization of contracts for the purpose of creating
the lists, still leaving the need of auditing cash flows of companies for the
possible omission due to the potential error at the stage of data collection,
especially for entities with various short or middle term business sites and
related leases, such as construction entities.

The implementation of the reinforcement learning and its well-known code is
to be made for the purpose of drawing the possibility and utilizability of
interpreters from domain knowledge to numerical system, also can be called
'gamification interpreter' or 'numericalization interpreter' which can be
referred or compared to the extrapolation with nondimensional numbers, such as
Froude Number, in physics, which was a source of inspiration at this study.
Studies on the interpreters can be able to empower the utilizability of
artificial general intelligence in domain and commercial area.
</p>
<a href="http://arxiv.org/abs/2101.05633" target="_blank">arXiv:2101.05633</a> [<a href="http://arxiv.org/pdf/2101.05633" target="_blank">pdf</a>]

<h2>Untargeted, Targeted and Universal Adversarial Attacks and Defenses on Time Series. (arXiv:2101.05639v1 [cs.LG])</h2>
<h3>Pradeep Rathore, Arghya Basak, Sri Harsha Nistala, Venkataramana Runkana</h3>
<p>Deep learning based models are vulnerable to adversarial attacks. These
attacks can be much more harmful in case of targeted attacks, where an attacker
tries not only to fool the deep learning model, but also to misguide the model
to predict a specific class. Such targeted and untargeted attacks are
specifically tailored for an individual sample and require addition of an
imperceptible noise to the sample. In contrast, universal adversarial attack
calculates a special imperceptible noise which can be added to any sample of
the given dataset so that, the deep learning model is forced to predict a wrong
class. To the best of our knowledge these targeted and universal attacks on
time series data have not been studied in any of the previous works. In this
work, we have performed untargeted, targeted and universal adversarial attacks
on UCR time series datasets. Our results show that deep learning based time
series classification models are vulnerable to these attacks. We also show that
universal adversarial attacks have good generalization property as it need only
a fraction of the training data. We have also performed adversarial training
based adversarial defense. Our results show that models trained adversarially
using Fast gradient sign method (FGSM), a single step attack, are able to
defend against FGSM as well as Basic iterative method (BIM), a popular
iterative attack.
</p>
<a href="http://arxiv.org/abs/2101.05639" target="_blank">arXiv:2101.05639</a> [<a href="http://arxiv.org/pdf/2101.05639" target="_blank">pdf</a>]

<h2>Continuous Deep Q-Learning with Simulator for Stabilization of Uncertain Discrete-Time Systems. (arXiv:2101.05640v1 [cs.LG])</h2>
<h3>Junya Ikemoto, Toshimitsu Ushio</h3>
<p>Applications of reinforcement learning (RL) to stabilization problems of real
systems are restricted since an agent needs many experiences to learn an
optimal policy and may determine dangerous actions during its exploration. If
we know a mathematical model of a real system, a simulator is useful because it
predicates behaviors of the real system using the mathematical model with a
given system parameter vector. We can collect many experiences more efficiently
than interactions with the real system. However, it is difficult to identify
the system parameter vector accurately. If we have an identification error,
experiences obtained by the simulator may degrade the performance of the
learned policy. Thus, we propose a practical RL algorithm that consists of two
stages. At the first stage, we choose multiple system parameter vectors. Then,
we have a mathematical model for each system parameter vector, which is called
a virtual system. We obtain optimal Q-functions for multiple virtual systems
using the continuous deep Q-learning algorithm. At the second stage, we
represent a Q-function for the real system by a linear approximated function
whose basis functions are optimal Q-functions learned at the first stage. The
agent learns the Q-function through interactions with the real system online.
By numerical simulations, we show the usefulness of our proposed method.
</p>
<a href="http://arxiv.org/abs/2101.05640" target="_blank">arXiv:2101.05640</a> [<a href="http://arxiv.org/pdf/2101.05640" target="_blank">pdf</a>]

<h2>Ensemble of LSTMs and feature selection for human action prediction. (arXiv:2101.05645v1 [cs.RO])</h2>
<h3>Tomislav Petkovi&#x107;, Luka Petrovi&#x107;, Ivan Markovi&#x107;, Ivan Petrovi&#x107;</h3>
<p>As robots are becoming more and more ubiquitous in human environments, it
will be necessary for robotic systems to better understand and predict human
actions. However, this is not an easy task, at times not even for us humans,
but based on a relatively structured set of possible actions, appropriate cues,
and the right model, this problem can be computationally tackled. In this
paper, we propose to use an ensemble of long-short term memory (LSTM) networks
for human action prediction. To train and evaluate models, we used the MoGaze
dataset - currently the most comprehensive dataset capturing poses of human
joints and the human gaze. We have thoroughly analyzed the MoGaze dataset and
selected a reduced set of cues for this task. Our model can predict (i) which
of the labeled objects the human is going to grasp, and (ii) which of the macro
locations the human is going to visit (such as table or shelf). We have
exhaustively evaluated the proposed method and compared it to individual cue
baselines. The results suggest that our LSTM model slightly outperforms the
gaze baseline in single object picking accuracy, but achieves better accuracy
in macro object prediction. Furthermore, we have also analyzed the prediction
accuracy when the gaze is not used, and in this case, the LSTM model
considerably outperformed the best single cue baseline
</p>
<a href="http://arxiv.org/abs/2101.05645" target="_blank">arXiv:2101.05645</a> [<a href="http://arxiv.org/pdf/2101.05645" target="_blank">pdf</a>]

<h2>Rescaling CNN through Learnable Repetition of Network Parameters. (arXiv:2101.05650v1 [cs.CV])</h2>
<h3>Arnav Chavan, Udbhav Bamba, Rishabh Tiwari, Deepak Gupta</h3>
<p>Deeper and wider CNNs are known to provide improved performance for deep
learning tasks. However, most such networks have poor performance gain per
parameter increase. In this paper, we investigate whether the gain observed in
deeper models is purely due to the addition of more optimization parameters or
whether the physical size of the network as well plays a role. Further, we
present a novel rescaling strategy for CNNs based on learnable repetition of
its parameters. Based on this strategy, we rescale CNNs without changing their
parameter count, and show that learnable sharing of weights itself can provide
significant boost in the performance of any given model without changing its
parameter count. We show that small base networks when rescaled, can provide
performance comparable to deeper networks with as low as 6% of optimization
parameters of the deeper one.

The relevance of weight sharing is further highlighted through the example of
group-equivariant CNNs. We show that the significant improvements obtained with
group-equivariant CNNs over the regular CNNs on classification problems are
only partly due to the added equivariance property, and part of it comes from
the learnable repetition of network weights. For rot-MNIST dataset, we show
that up to 40% of the relative gain reported by state-of-the-art methods for
rotation equivariance could actually be due to just the learnt repetition of
weights.
</p>
<a href="http://arxiv.org/abs/2101.05650" target="_blank">arXiv:2101.05650</a> [<a href="http://arxiv.org/pdf/2101.05650" target="_blank">pdf</a>]

<h2>A Pipeline for Vision-Based On-Orbit Proximity Operations Using Deep Learning and Synthetic Imagery. (arXiv:2101.05661v1 [cs.LG])</h2>
<h3>Carson Schubert, Kevin Black, Daniel Fonseka, Abhimanyu Dhir, Jacob Deutsch, Nihal Dhamani, Gavin Martin, Maruthi Akella</h3>
<p>Deep learning has become the gold standard for image processing over the past
decade. Simultaneously, we have seen growing interest in orbital activities
such as satellite servicing and debris removal that depend on proximity
operations between spacecraft. However, two key challenges currently pose a
major barrier to the use of deep learning for vision-based on-orbit proximity
operations. Firstly, efficient implementation of these techniques relies on an
effective system for model development that streamlines data curation,
training, and evaluation. Secondly, a scarcity of labeled training data (images
of a target spacecraft) hinders creation of robust deep learning models. This
paper presents an open-source deep learning pipeline, developed specifically
for on-orbit visual navigation applications, that addresses these challenges.
The core of our work consists of two custom software tools built on top of a
cloud architecture that interconnects all stages of the model development
process. The first tool leverages Blender, an open-source 3D graphics toolset,
to generate labeled synthetic training data with configurable model poses
(positions and orientations), lighting conditions, backgrounds, and commonly
observed in-space image aberrations. The second tool is a plugin-based
framework for effective dataset curation and model training; it provides common
functionality like metadata generation and remote storage access to all
projects while giving complete independence to project-specific code.
Time-consuming, graphics-intensive processes such as synthetic image generation
and model training run on cloud-based computational resources which scale to
any scope and budget and allow development of even the largest datasets and
models from any machine. The presented system has been used in the Texas
Spacecraft Laboratory with marked benefits in development speed and quality.
</p>
<a href="http://arxiv.org/abs/2101.05661" target="_blank">arXiv:2101.05661</a> [<a href="http://arxiv.org/pdf/2101.05661" target="_blank">pdf</a>]

<h2>Analysis of hidden feedback loops in continuous machine learning systems. (arXiv:2101.05673v1 [cs.LG])</h2>
<h3>Anton Khritankov</h3>
<p>In this concept paper, we discuss intricacies of specifying and verifying the
quality of continuous and lifelong learning artificial intelligence systems as
they interact with and influence their environment causing a so-called concept
drift. We signify a problem of implicit feedback loops, demonstrate how they
intervene with user behavior on an exemplary housing prices prediction system.
Based on a preliminary model, we highlight conditions when such feedback loops
arise and discuss possible solution approaches.
</p>
<a href="http://arxiv.org/abs/2101.05673" target="_blank">arXiv:2101.05673</a> [<a href="http://arxiv.org/pdf/2101.05673" target="_blank">pdf</a>]

<h2>Convex Smoothed Autoencoder-Optimal Transport model. (arXiv:2101.05679v1 [stat.ML])</h2>
<h3>Aratrika Mustafi</h3>
<p>Generative modelling is a key tool in unsupervised machine learning which has
achieved stellar success in recent years. Despite this huge success, even the
best generative models such as Generative Adversarial Networks (GANs) and
Variational Autoencoders (VAEs) come with their own shortcomings, mode collapse
and mode mixture being the two most prominent problems. In this paper we
develop a new generative model capable of generating samples which resemble the
observed data, and is free from mode collapse and mode mixture. Our model is
inspired by the recently proposed Autoencoder-Optimal Transport (AE-OT) model
and tries to improve on it by addressing the problems faced by the AE-OT model
itself, specifically with respect to the sample generation algorithm.
Theoretical results concerning the bound on the error in approximating the
non-smooth Brenier potential by its smoothed estimate, and approximating the
discontinuous optimal transport map by a smoothed optimal transport map
estimate have also been established in this paper.
</p>
<a href="http://arxiv.org/abs/2101.05679" target="_blank">arXiv:2101.05679</a> [<a href="http://arxiv.org/pdf/2101.05679" target="_blank">pdf</a>]

<h2>AVGCN: Trajectory Prediction using Graph Convolutional Networks Guided by Human Attention. (arXiv:2101.05682v1 [cs.CV])</h2>
<h3>Congcong Liu, Yuying Chen, Ming Liu, Bertram E. Shi</h3>
<p>Pedestrian trajectory prediction is a critical yet challenging task,
especially for crowded scenes. We suggest that introducing an attention
mechanism to infer the importance of different neighbors is critical for
accurate trajectory prediction in scenes with varying crowd size. In this work,
we propose a novel method, AVGCN, for trajectory prediction utilizing graph
convolutional networks (GCN) based on human attention (A denotes attention, V
denotes visual field constraints). First, we train an attention network that
estimates the importance of neighboring pedestrians, using gaze data collected
as subjects perform a bird's eye view crowd navigation task. Then, we
incorporate the learned attention weights modulated by constraints on the
pedestrian's visual field into a trajectory prediction network that uses a GCN
to aggregate information from neighbors efficiently. AVGCN also considers the
stochastic nature of pedestrian trajectories by taking advantage of variational
trajectory prediction. Our approach achieves state-of-the-art performance on
several trajectory prediction benchmarks, and the lowest average prediction
error over all considered benchmarks.
</p>
<a href="http://arxiv.org/abs/2101.05682" target="_blank">arXiv:2101.05682</a> [<a href="http://arxiv.org/pdf/2101.05682" target="_blank">pdf</a>]

<h2>Generating coherent spontaneous speech and gesture from text. (arXiv:2101.05684v1 [cs.LG])</h2>
<h3>Simon Alexanderson, &#xc9;va Sz&#xe9;kely, Gustav Eje Henter, Taras Kucherenko, Jonas Beskow</h3>
<p>Embodied human communication encompasses both verbal (speech) and non-verbal
information (e.g., gesture and head movements). Recent advances in machine
learning have substantially improved the technologies for generating synthetic
versions of both of these types of data: On the speech side, text-to-speech
systems are now able to generate highly convincing, spontaneous-sounding speech
using unscripted speech audio as the source material. On the motion side,
probabilistic motion-generation methods can now synthesise vivid and lifelike
speech-driven 3D gesticulation. In this paper, we put these two
state-of-the-art technologies together in a coherent fashion for the first
time. Concretely, we demonstrate a proof-of-concept system trained on a
single-speaker audio and motion-capture dataset, that is able to generate both
speech and full-body gestures together from text input. In contrast to previous
approaches for joint speech-and-gesture generation, we generate full-body
gestures from speech synthesis trained on recordings of spontaneous speech from
the same person as the motion-capture data. We illustrate our results by
visualising gesture spaces and text-speech-gesture alignments, and through a
demonstration video at https://simonalexanderson.github.io/IVA2020 .
</p>
<a href="http://arxiv.org/abs/2101.05684" target="_blank">arXiv:2101.05684</a> [<a href="http://arxiv.org/pdf/2101.05684" target="_blank">pdf</a>]

<h2>Towards Accurate Camouflaged Object Detection with Mixture Convolution and Interactive Fusion. (arXiv:2101.05687v1 [cs.CV])</h2>
<h3>Bo Dong, Mingchen Zhuge, Yongxiong Wang, Hongbo Bi, Geng Chen</h3>
<p>Camouflaged object detection (COD), which aims to identify the objects that
conceal themselves into the surroundings, has recently drawn increasing
research efforts in the field of computer vision. In practice, the success of
deep learning based COD is mainly determined by two key factors, including (i)
A significantly large receptive field, which provides rich context information,
and (ii) An effective fusion strategy, which aggregates the rich multi-level
features for accurate COD. Motivated by these observations, in this paper, we
propose a novel deep learning based COD approach, which integrates the large
receptive field and effective feature fusion into a unified framework.
Specifically, we first extract multi-level features from a backbone network.
The resulting features are then fed to the proposed dual-branch mixture
convolution modules, each of which utilizes multiple asymmetric convolutional
layers and two dilated convolutional layers to extract rich context features
from a large receptive field. Finally, we fuse the features using
specially-designed multi-level interactive fusion modules, each of which
employs an attention mechanism along with feature interaction for effective
feature fusion. Our method detects camouflaged objects with an effective fusion
strategy, which aggregates the rich context information from a large receptive
field. All of these designs meet the requirements of COD well, allowing the
accurate detection of camouflaged objects. Extensive experiments on widely-used
benchmark datasets demonstrate that our method is capable of accurately
detecting camouflaged objects and outperforms the state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2101.05687" target="_blank">arXiv:2101.05687</a> [<a href="http://arxiv.org/pdf/2101.05687" target="_blank">pdf</a>]

<h2>Temporal Logic Task Allocation in Heterogeneous Multi-Robot Systems. (arXiv:2101.05694v1 [cs.RO])</h2>
<h3>Xusheng Luo, Michael M. Zavlanos</h3>
<p>In this paper, we consider the problem of optimally allocating tasks,
expressed as global Linear Temporal Logic (LTL) specifications, to teams of
heterogeneous mobile robots. The robots are classified in different types that
capture their different capabilities, and each task may require robots of
multiple types. The specific robots assigned to each task are immaterial, as
long as they are of the desired type. Given a discrete workspace, our goal is
to design paths, i.e., sequences of discrete states, for the robots so that the
LTL specification is satisfied. To obtain a scalable solution to this complex
temporal logic task allocation problem, we propose a hierarchical approach that
first allocates specific robots to tasks using the information about the tasks
contained in the Nondeterministic Buchi Automaton (NBA) that captures the LTL
specification, and then designs low-level executable plans for the robots that
respect the high-level assignment. Specifically, we first prune and relax the
NBA by removing all negative atomic propositions. This step is motivated by
"lazy collision checking" methods in robotics and allows to simplify the
planning problem by checking constraint satisfaction only when needed. Then, we
extract sequences of subtasks from the relaxed NBA along with their temporal
orders, and formulate a Mixed Integer Linear Program (MILP) to allocate these
subtasks to the robots. Finally, we define generalized multi-robot path
planning problems to obtain low-level executable robot plans that satisfy both
the high-level task allocation and the temporal constraints captured by the
negative atomic propositions in the original NBA. We provide theoretical
results showing completeness and soundness of our proposed method and present
numerical simulations demonstrating that our method can generate robot paths
with lower cost, considerably faster than existing methods.
</p>
<a href="http://arxiv.org/abs/2101.05694" target="_blank">arXiv:2101.05694</a> [<a href="http://arxiv.org/pdf/2101.05694" target="_blank">pdf</a>]

<h2>Spillover Algorithm: A Decentralized Coordination Approach for Multi-Robot Production Planning in Open Shared Factories. (arXiv:2101.05700v1 [cs.RO])</h2>
<h3>Marin Lujak, Alberto Fern&#xe1;ndez, Eva Onaindia</h3>
<p>Open and shared manufacturing factories typically dispose of a limited number
of robots that should be properly allocated to tasks in time and space for an
effective and efficient system performance. In particular, we deal with the
dynamic capacitated production planning problem with sequence independent setup
costs where quantities of products to manufacture and location of robots need
to be determined at consecutive periods within a given time horizon and
products can be anticipated or backordered related to the demand period. We
consider a decentralized multi-agent variant of this problem in an open factory
setting with multiple owners of robots as well as different owners of the items
to be produced, both considered self-interested and individually rational.
Existing solution approaches to the classic constrained lot-sizing problem are
centralized exact methods that require sharing of global knowledge of all the
participants' private and sensitive information and are not applicable in the
described multi-agent context. Therefore, we propose a computationally
efficient decentralized approach based on the spillover effect that solves this
NP-hard problem by distributing decisions in an intrinsically decentralized
multi-agent system environment while protecting private and sensitive
information. To the best of our knowledge, this is the first decentralized
algorithm for the solution of the studied problem in intrinsically
decentralized environments where production resources and/or products are owned
by multiple stakeholders with possibly conflicting objectives. To show its
efficiency, the performance of the Spillover Algorithm is benchmarked against
state-of-the-art commercial solver CPLEX 12.8.
</p>
<a href="http://arxiv.org/abs/2101.05700" target="_blank">arXiv:2101.05700</a> [<a href="http://arxiv.org/pdf/2101.05700" target="_blank">pdf</a>]

<h2>Rule-based Optimal Control for Autonomous Driving. (arXiv:2101.05709v1 [cs.RO])</h2>
<h3>Wei Xiao, Noushin Mehdipour, Anne Collin, Amitai Bin-Nun, Emilio Frazzoli, Radboud Duintjer Tebbens, Calin Belta</h3>
<p>We develop optimal control strategies for Autonomous Vehicles (AVs) that are
required to meet complex specifications imposed by traffic laws and cultural
expectations of reasonable driving behavior. We formulate these specifications
as rules, and specify their priorities by constructing a priority structure. We
propose a recursive framework, in which the satisfaction of the rules in the
priority structure are iteratively relaxed based on their priorities. Central
to this framework is an optimal control problem, where convergence to desired
states is achieved using Control Lyapunov Functions (CLFs), and safety is
enforced through Control Barrier Functions (CBFs). We also show how the
proposed framework can be used for after-the-fact, pass / fail evaluation of
trajectories - a given trajectory is rejected if we can find a controller
producing a trajectory that leads to less violation of the rule priority
structure. We present case studies with multiple driving scenarios to
demonstrate the effectiveness of the proposed framework.
</p>
<a href="http://arxiv.org/abs/2101.05709" target="_blank">arXiv:2101.05709</a> [<a href="http://arxiv.org/pdf/2101.05709" target="_blank">pdf</a>]

<h2>Stereo camera system calibration: the need of two sets of parameters. (arXiv:2101.05725v1 [cs.CV])</h2>
<h3>Riccardo Beschi, Xiao Feng, Stefania Melillo, Leonardo Parisi, Lorena Postiglione</h3>
<p>The reconstruction of a scene via a stereo-camera system is a two-steps
process, where at first images from different cameras are matched to identify
the set of point-to-point correspondences that then will actually be
reconstructed in the three dimensional real world. The performance of the
system strongly relies of the calibration procedure, which has to be carefully
designed to guarantee optimal results. We implemented three different
calibration methods and we compared their performance over 19 datasets. We
present the experimental evidence that, due to the image noise, a single set of
parameters is not sufficient to achieve high accuracy in the identification of
the correspondences and in the 3D reconstruction at the same time. We propose
to calibrate the system twice to estimate two different sets of parameters: the
one obtained by minimizing the reprojection error that will be used when
dealing with quantities defined in the 2D space of the cameras, and the one
obtained by minimizing the reconstruction error that will be used when dealing
with quantities defined in the real 3D world.
</p>
<a href="http://arxiv.org/abs/2101.05725" target="_blank">arXiv:2101.05725</a> [<a href="http://arxiv.org/pdf/2101.05725" target="_blank">pdf</a>]

<h2>$\text{O}^2$PF: Oversampling via Optimum-Path Forest for Breast Cancer Detection. (arXiv:2101.05775v1 [cs.LG])</h2>
<h3>Leandro Aparecido Passos, Danilo Samuel Jodas, Luiz C. F. Ribeiro, Thierry Pinheiro, Jo&#xe3;o P. Papa</h3>
<p>Breast cancer is among the most deadly diseases, distressing mostly women
worldwide. Although traditional methods for detection have presented themselves
as valid for the task, they still commonly present low accuracies and demand
considerable time and effort from professionals. Therefore, a computer-aided
diagnosis (CAD) system capable of providing early detection becomes hugely
desirable. In the last decade, machine learning-based techniques have been of
paramount importance in this context, since they are capable of extracting
essential information from data and reasoning about it. However, such
approaches still suffer from imbalanced data, specifically on medical issues,
where the number of healthy people samples is, in general, considerably higher
than the number of patients. Therefore this paper proposes the $\text{O}^2$PF,
a data oversampling method based on the unsupervised Optimum-Path Forest
Algorithm. Experiments conducted over the full oversampling scenario state the
robustness of the model, which is compared against three well-established
oversampling methods considering three breast cancer and three general-purpose
tasks for medical issues datasets.
</p>
<a href="http://arxiv.org/abs/2101.05775" target="_blank">arXiv:2101.05775</a> [<a href="http://arxiv.org/pdf/2101.05775" target="_blank">pdf</a>]

<h2>Topological Deep Learning. (arXiv:2101.05778v1 [cs.LG])</h2>
<h3>Ephy R. Love, Benjamin Filippenko, Vasileios Maroulas, Gunnar Carlsson</h3>
<p>This work introduces the Topological CNN (TCNN), which encompasses several
topologically defined convolutional methods. Manifolds with important
relationships to the natural image space are used to parameterize image filters
which are used as convolutional weights in a TCNN. These manifolds also
parameterize slices in layers of a TCNN across which the weights are localized.
We show evidence that TCNNs learn faster, on less data, with fewer learned
parameters, and with greater generalizability and interpretability than
conventional CNNs. We introduce and explore TCNN layers for both image and
video data. We propose extensions to 3D images and 3D video.
</p>
<a href="http://arxiv.org/abs/2101.05778" target="_blank">arXiv:2101.05778</a> [<a href="http://arxiv.org/pdf/2101.05778" target="_blank">pdf</a>]

<h2>Structured Prediction as Translation between Augmented Natural Languages. (arXiv:2101.05779v1 [cs.LG])</h2>
<h3>Giovanni Paolini, Ben Athiwaratkun, Jason Krone, Jie Ma, Alessandro Achille, Rishita Anubhai, Cicero Nogueira dos Santos, Bing Xiang, Stefano Soatto</h3>
<p>We propose a new framework, Translation between Augmented Natural Languages
(TANL), to solve many structured prediction language tasks including joint
entity and relation extraction, nested named entity recognition, relation
classification, semantic role labeling, event extraction, coreference
resolution, and dialogue state tracking. Instead of tackling the problem by
training task-specific discriminative classifiers, we frame it as a translation
task between augmented natural languages, from which the task-relevant
information can be easily extracted. Our approach can match or outperform
task-specific models on all tasks, and in particular, achieves new
state-of-the-art results on joint entity and relation extraction (CoNLL04, ADE,
NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and
semantic role labeling (CoNLL-2005 and CoNLL-2012). We accomplish this while
using the same architecture and hyperparameters for all tasks and even when
training a single model to solve all tasks at the same time (multi-task
learning). Finally, we show that our framework can also significantly improve
the performance in a low-resource regime, thanks to better use of label
semantics.
</p>
<a href="http://arxiv.org/abs/2101.05779" target="_blank">arXiv:2101.05779</a> [<a href="http://arxiv.org/pdf/2101.05779" target="_blank">pdf</a>]

<h2>U-Noise: Learnable Noise Masks for Interpretable Image Segmentation. (arXiv:2101.05791v1 [cs.CV])</h2>
<h3>Teddy Koker, Fatemehsadat Mireshghallah, Tom Titcombe, Georgios Kaissis</h3>
<p>Deep Neural Networks (DNNs) are widely used for decision making in a myriad
of critical applications, ranging from medical to societal and even judicial.
Given the importance of these decisions, it is crucial for us to be able to
interpret these models. We introduce a new method for interpreting image
segmentation models by learning regions of images in which noise can be applied
without hindering downstream model performance. We apply this method to
segmentation of the pancreas in CT scans, and qualitatively compare the quality
of the method to existing explainability techniques, such as Grad-CAM and
occlusion sensitivity. Additionally we show that, unlike other methods, our
interpretability model can be quantitatively evaluated based on the downstream
performance over obscured images.
</p>
<a href="http://arxiv.org/abs/2101.05791" target="_blank">arXiv:2101.05791</a> [<a href="http://arxiv.org/pdf/2101.05791" target="_blank">pdf</a>]

<h2>A Metaheuristic-Driven Approach to Fine-Tune Deep Boltzmann Machines. (arXiv:2101.05795v1 [cs.LG])</h2>
<h3>Leandro Aparecido Passos, Jo&#xe3;o Paulo Papa</h3>
<p>Deep learning techniques, such as Deep Boltzmann Machines (DBMs), have
received considerable attention over the past years due to the outstanding
results concerning a variable range of domains. One of the main shortcomings of
these techniques involves the choice of their hyperparameters, since they have
a significant impact on the final results. This work addresses the issue of
fine-tuning hyperparameters of Deep Boltzmann Machines using metaheuristic
optimization techniques with different backgrounds, such as swarm intelligence,
memory- and evolutionary-based approaches. Experiments conducted in three
public datasets for binary image reconstruction showed that metaheuristic
techniques can obtain reasonable results.
</p>
<a href="http://arxiv.org/abs/2101.05795" target="_blank">arXiv:2101.05795</a> [<a href="http://arxiv.org/pdf/2101.05795" target="_blank">pdf</a>]

<h2>DeFlow: Learning Complex Image Degradations from Unpaired Data with Conditional Flows. (arXiv:2101.05796v1 [cs.CV])</h2>
<h3>Valentin Wolf, Andreas Lugmayr, Martin Danelljan, Luc Van Gool, Radu Timofte</h3>
<p>The difficulty of obtaining paired data remains a major bottleneck for
learning image restoration and enhancement models for real-world applications.
Current strategies aim to synthesize realistic training data by modeling noise
and degradations that appear in real-world settings. We propose DeFlow, a
method for learning stochastic image degradations from unpaired data. Our
approach is based on a novel unpaired learning formulation for conditional
normalizing flows. We model the degradation process in the latent space of a
shared flow encoder-decoder network. This allows us to learn the conditional
distribution of a noisy image given the clean input by solely minimizing the
negative log-likelihood of the marginal distributions. We validate our DeFlow
formulation on the task of joint image restoration and super-resolution. The
models trained with the synthetic data generated by DeFlow outperform previous
learnable approaches on all three datasets.
</p>
<a href="http://arxiv.org/abs/2101.05796" target="_blank">arXiv:2101.05796</a> [<a href="http://arxiv.org/pdf/2101.05796" target="_blank">pdf</a>]

<h2>Kernels on Sample Sets via Nonparametric Divergence Estimates. (arXiv:1202.0302v3 [cs.LG] UPDATED)</h2>
<h3>Danica J. Sutherland, Liang Xiong, Barnab&#xe1;s P&#xf3;czos, Jeff Schneider</h3>
<p>Most machine learning algorithms, such as classification or regression, treat
the individual data point as the object of interest. Here we consider extending
machine learning algorithms to operate on groups of data points. We suggest
treating a group of data points as an i.i.d. sample set from an underlying
feature distribution for that group. Our approach employs kernel machines with
a kernel on i.i.d. sample sets of vectors. We define certain kernel functions
on pairs of distributions, and then use a nonparametric estimator to
consistently estimate those functions based on sample sets. The projection of
the estimated Gram matrix to the cone of symmetric positive semi-definite
matrices enables us to use kernel machines for classification, regression,
anomaly detection, and low-dimensional embedding in the space of distributions.
We present several numerical experiments both on real and simulated datasets to
demonstrate the advantages of our new approach.
</p>
<a href="http://arxiv.org/abs/1202.0302" target="_blank">arXiv:1202.0302</a> [<a href="http://arxiv.org/pdf/1202.0302" target="_blank">pdf</a>]

<h2>Linear-time Learning on Distributions with Approximate Kernel Embeddings. (arXiv:1509.07553v2 [stat.ML] UPDATED)</h2>
<h3>Danica J. Sutherland, Junier B. Oliva, Barnab&#xe1;s P&#xf3;czos, Jeff Schneider</h3>
<p>Many interesting machine learning problems are best posed by considering
instances that are distributions, or sample sets drawn from distributions.
Previous work devoted to machine learning tasks with distributional inputs has
done so through pairwise kernel evaluations between pdfs (or sample sets).
While such an approach is fine for smaller datasets, the computation of an $N
\times N$ Gram matrix is prohibitive in large datasets. Recent scalable
estimators that work over pdfs have done so only with kernels that use
Euclidean metrics, like the $L_2$ distance. However, there are a myriad of
other useful metrics available, such as total variation, Hellinger distance,
and the Jensen-Shannon divergence. This work develops the first random features
for pdfs whose dot product approximates kernels using these non-Euclidean
metrics, allowing estimators using such kernels to scale to large datasets by
working in a primal space, without computing large Gram matrices. We provide an
analysis of the approximation error in using our proposed random features and
show empirically the quality of our approximation both in estimating a Gram
matrix and in solving learning tasks in real-world and synthetic data.
</p>
<a href="http://arxiv.org/abs/1509.07553" target="_blank">arXiv:1509.07553</a> [<a href="http://arxiv.org/pdf/1509.07553" target="_blank">pdf</a>]

<h2>Deep Mean Maps. (arXiv:1511.04150v2 [stat.ML] UPDATED)</h2>
<h3>Junier B. Oliva, Danica J. Sutherland, Barnab&#xe1;s P&#xf3;czos, Jeff Schneider</h3>
<p>The use of distributions and high-level features from deep architecture has
become commonplace in modern computer vision. Both of these methodologies have
separately achieved a great deal of success in many computer vision tasks.
However, there has been little work attempting to leverage the power of these
to methodologies jointly. To this end, this paper presents the Deep Mean Maps
(DMMs) framework, a novel family of methods to non-parametrically represent
distributions of features in convolutional neural network models.

DMMs are able to both classify images using the distribution of top-level
features, and to tune the top-level features for performing this task. We show
how to implement DMMs using a special mean map layer composed of typical CNN
operations, making both forward and backward propagation simple.

We illustrate the efficacy of DMMs at analyzing distributional patterns in
image data in a synthetic data experiment. We also show that we extending
existing deep architectures with DMMs improves the performance of existing CNNs
on several challenging real-world datasets.
</p>
<a href="http://arxiv.org/abs/1511.04150" target="_blank">arXiv:1511.04150</a> [<a href="http://arxiv.org/pdf/1511.04150" target="_blank">pdf</a>]

<h2>Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy. (arXiv:1611.04488v6 [stat.ML] UPDATED)</h2>
<h3>Danica J. Sutherland, Hsiao-Yu Tung, Heiko Strathmann, Soumyajit De, Aaditya Ramdas, Alex Smola, Arthur Gretton</h3>
<p>We propose a method to optimize the representation and distinguishability of
samples from two probability distributions, by maximizing the estimated power
of a statistical test based on the maximum mean discrepancy (MMD). This
optimized MMD is applied to the setting of unsupervised learning by generative
adversarial networks (GAN), in which a model attempts to generate realistic
samples, and a discriminator attempts to tell these apart from data samples. In
this context, the MMD may be used in two roles: first, as a discriminator,
either directly on the samples, or on features of the samples. Second, the MMD
can be used to evaluate the performance of a generative model, by testing the
model's samples against a reference data set. In the latter role, the optimized
MMD is particularly helpful, as it gives an interpretable indication of how the
model and data distributions differ, even in cases where individual model
samples are not easily distinguished either by eye or by classifier.
</p>
<a href="http://arxiv.org/abs/1611.04488" target="_blank">arXiv:1611.04488</a> [<a href="http://arxiv.org/pdf/1611.04488" target="_blank">pdf</a>]

<h2>Fixing an error in Caponnetto and de Vito (2007). (arXiv:1702.02982v2 [stat.ML] UPDATED)</h2>
<h3>Danica J. Sutherland</h3>
<p>The seminal paper of Caponnetto and de Vito (2007) provides minimax-optimal
rates for kernel ridge regression in a very general setting. Its proof,
however, contains an error in its bound on the effective dimensionality. In
this note, we explain the mistake, provide a correct bound, and show that the
main theorem remains true.
</p>
<a href="http://arxiv.org/abs/1702.02982" target="_blank">arXiv:1702.02982</a> [<a href="http://arxiv.org/pdf/1702.02982" target="_blank">pdf</a>]

<h2>Efficient and principled score estimation with Nystr\"om kernel exponential families. (arXiv:1705.08360v6 [stat.ML] UPDATED)</h2>
<h3>Danica J. Sutherland, Heiko Strathmann, Michael Arbel, Arthur Gretton</h3>
<p>We propose a fast method with statistical guarantees for learning an
exponential family density model where the natural parameter is in a
reproducing kernel Hilbert space, and may be infinite-dimensional. The model is
learned by fitting the derivative of the log density, the score, thus avoiding
the need to compute a normalization constant. Our approach improves the
computational efficiency of an earlier solution by using a low-rank,
Nystr\"om-like solution. The new solution retains the consistency and
convergence rates of the full-rank solution (exactly in Fisher distance, and
nearly in other distances), with guarantees on the degree of cost and storage
reduction. We evaluate the method in experiments on density estimation and in
the construction of an adaptive Hamiltonian Monte Carlo sampler. Compared to an
existing score learning approach using a denoising autoencoder, our estimator
is empirically more data-efficient when estimating the score, runs faster, and
has fewer parameters (which can be tuned in a principled and interpretable
way), in addition to providing statistical guarantees.
</p>
<a href="http://arxiv.org/abs/1705.08360" target="_blank">arXiv:1705.08360</a> [<a href="http://arxiv.org/pdf/1705.08360" target="_blank">pdf</a>]

<h2>Demystifying MMD GANs. (arXiv:1801.01401v5 [stat.ML] UPDATED)</h2>
<h3>Miko&#x142;aj Bi&#x144;kowski, Danica J. Sutherland, Michael Arbel, Arthur Gretton</h3>
<p>We investigate the training and performance of generative adversarial
networks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs.
As our main theoretical contribution, we clarify the situation with bias in GAN
loss functions raised by recent work: we show that gradient estimators used in
the optimization process for both MMD GANs and Wasserstein GANs are unbiased,
but learning a discriminator based on samples leads to biased gradients for the
generator parameters. We also discuss the issue of kernel choice for the MMD
critic, and characterize the kernel corresponding to the energy distance used
for the Cramer GAN critic. Being an integral probability metric, the MMD
benefits from training strategies recently developed for Wasserstein GANs. In
experiments, the MMD GAN is able to employ a smaller critic network than the
Wasserstein GAN, resulting in a simpler and faster-training algorithm with
matching performance. We also propose an improved measure of GAN convergence,
the Kernel Inception Distance, and show how to use it to dynamically adapt
learning rates during GAN training.
</p>
<a href="http://arxiv.org/abs/1801.01401" target="_blank">arXiv:1801.01401</a> [<a href="http://arxiv.org/pdf/1801.01401" target="_blank">pdf</a>]

<h2>On gradient regularizers for MMD GANs. (arXiv:1805.11565v5 [stat.ML] UPDATED)</h2>
<h3>Michael Arbel, Danica J. Sutherland, Miko&#x142;aj Bi&#x144;kowski, Arthur Gretton</h3>
<p>We propose a principled method for gradient-based regularization of the
critic of GAN-like models trained by adversarially optimizing the kernel of a
Maximum Mean Discrepancy (MMD). We show that controlling the gradient of the
critic is vital to having a sensible loss function, and devise a method to
enforce exact, analytical gradient constraints at no additional cost compared
to existing approximate techniques based on additive regularizers. The new loss
function is provably continuous, and experiments show that it stabilizes and
accelerates training, giving image generation models that outperform
state-of-the art methods on $160 \times 160$ CelebA and $64 \times 64$
unconditional ImageNet.
</p>
<a href="http://arxiv.org/abs/1805.11565" target="_blank">arXiv:1805.11565</a> [<a href="http://arxiv.org/pdf/1805.11565" target="_blank">pdf</a>]

<h2>Learning deep kernels for exponential family densities. (arXiv:1811.08357v4 [stat.ML] UPDATED)</h2>
<h3>Li Wenliang, Danica J. Sutherland, Heiko Strathmann, Arthur Gretton</h3>
<p>The kernel exponential family is a rich class of distributions, which can be
fit efficiently and with statistical guarantees by score matching. Being
required to choose a priori a simple kernel such as the Gaussian, however,
limits its practical applicability. We provide a scheme for learning a kernel
parameterized by a deep network, which can find complex location-dependent
local features of the data geometry. This gives a very rich class of density
models, capable of fitting complex structures on moderate-dimensional problems.
Compared to deep density models fit via maximum likelihood, our approach
provides a complementary set of strengths and tradeoffs: in empirical studies,
the former can yield higher likelihoods, whereas the latter gives better
estimates of the gradient of the log density, the score, which describes the
distribution's shape.
</p>
<a href="http://arxiv.org/abs/1811.08357" target="_blank">arXiv:1811.08357</a> [<a href="http://arxiv.org/pdf/1811.08357" target="_blank">pdf</a>]

<h2>Deep Learning Model for Finding New Superconductors. (arXiv:1812.01995v4 [cs.LG] UPDATED)</h2>
<h3>Tomohiko Konno, Hodaka Kurokawa, Fuyuki Nabeshima, Yuki Sakishita, Ryo Ogawa, Iwao Hosako, Atsutaka Maeda</h3>
<p>Exploration of new superconductors still relies on the experience and
intuition of experts and is largely a process of experimental trial and error.
In one study, only 3% of the candidate materials showed superconductivity.
Here, we report the first deep learning model for finding new superconductors.
We introduced the method named "reading periodic table" which represented the
periodic table in a way that allows deep learning to learn to read the periodic
table and to learn the law of elements for the purpose of discovering novel
superconductors that are outside the training data. It is recognized that it is
difficult for deep learning to predict something outside the training data.
Although we used only the chemical composition of materials as information, we
obtained an $R^{2}$ value of 0.92 for predicting $T_\text{c}$ for materials in
a database of superconductors. We also introduced the method named "garbage-in"
to create synthetic data of non-superconductors that do not exist.
Non-superconductors are not reported, but the data must be required for deep
learning to distinguish between superconductors and non-superconductors. We
obtained three remarkable results. The deep learning can predict
superconductivity for a material with a precision of 62%, which shows the
usefulness of the model; it found the recently discovered superconductor CaBi2
and another one Hf0.5Nb0.2V2Zr0.3, neither of which is in the superconductor
database; and it found Fe-based high-temperature superconductors (discovered in
2008) from the training data before 2008. These results open the way for the
discovery of new high-temperature superconductor families. The candidate
materials list, data, and method are openly available from the link
https://github.com/tomo835g/Deep-Learning-to-find-Superconductors.
</p>
<a href="http://arxiv.org/abs/1812.01995" target="_blank">arXiv:1812.01995</a> [<a href="http://arxiv.org/pdf/1812.01995" target="_blank">pdf</a>]

<h2>Physics-Based Learning for Robotic Environmental Sensing. (arXiv:1812.03894v4 [cs.RO] UPDATED)</h2>
<h3>Reza Khodayi-mehr, Michael M. Zavlanos</h3>
<p>We propose a physics-based method to learn environmental fields (EFs) using a
mobile robot. Common purely data-driven methods require prohibitively many
measurements to accurately learn such complex EFs. Alternatively, physics-based
models provide global knowledge of EFs but require experimental validation,
depend on uncertain parameters, and are intractable for mobile robots. To
address these challenges, we propose a Bayesian framework to select the most
likely physics-based models of EFs in real-time, from a pool of numerical
solutions generated offline as a function of the uncertain parameters.
Specifically, we focus on turbulent flow fields and utilize Gaussian processes
(GPs) to construct statistical models for them, using the pool of numerical
solutions to inform their prior mean. To incorporate flow measurements into
these GPs, we control a custom-built mobile robot through a sequence of
waypoints that maximize the information content of the measurements. We
experimentally demonstrate that our proposed framework constructs a posterior
distribution of the flow field that better approximates the real flow compared
to the prior numerical solutions and purely data-driven methods.
</p>
<a href="http://arxiv.org/abs/1812.03894" target="_blank">arXiv:1812.03894</a> [<a href="http://arxiv.org/pdf/1812.03894" target="_blank">pdf</a>]

<h2>Benchmark and Survey of Automated Machine Learning Frameworks. (arXiv:1904.12054v4 [cs.LG] UPDATED)</h2>
<h3>Marc-Andr&#xe9; Z&#xf6;ller, Marco F. Huber</h3>
<p>Machine learning (ML) has become a vital part in many aspects of our daily
life. However, building well performing machine learning applications requires
highly specialized data scientists and domain experts. Automated machine
learning (AutoML) aims to reduce the demand for data scientists by enabling
domain experts to build machine learning applications automatically without
extensive knowledge of statistics and machine learning. This paper is a
combination of a survey on current AutoML methods and a benchmark of popular
AutoML frameworks on real data sets. Driven by the selected frameworks for
evaluation, we summarize and review important AutoML techniques and methods
concerning every step in building an ML pipeline. The selected AutoML
frameworks are evaluated on 137 data sets from established AutoML benchmark
suits.
</p>
<a href="http://arxiv.org/abs/1904.12054" target="_blank">arXiv:1904.12054</a> [<a href="http://arxiv.org/pdf/1904.12054" target="_blank">pdf</a>]

<h2>Unbiased estimators for the variance of MMD estimators. (arXiv:1906.02104v2 [stat.ML] UPDATED)</h2>
<h3>Danica J. Sutherland</h3>
<p>The maximum mean discrepancy (MMD) is a kernel-based distance between
probability distributions useful in many applications (Gretton et al. 2012),
bearing a simple estimator with pleasing computational and statistical
properties. Being able to efficiently estimate the variance of this estimator
is very helpful to various problems in two-sample testing. Towards this end,
Bounliphone et al. (2016) used the theory of U-statistics to derive estimators
for the variance of an MMD estimator, and differences between two such
estimators. Their estimator, however, drops lower-order terms, and is
unnecessarily biased. We show in this note - extending and correcting work of
Sutherland et al. (2017) - that we can find a truly unbiased estimator for the
actual variance of both the squared MMD estimator and the difference of two
correlated squared MMD estimators, at essentially no additional computational
cost.
</p>
<a href="http://arxiv.org/abs/1906.02104" target="_blank">arXiv:1906.02104</a> [<a href="http://arxiv.org/pdf/1906.02104" target="_blank">pdf</a>]

<h2>Reward Prediction Error as an Exploration Objective in Deep RL. (arXiv:1906.08189v5 [cs.LG] UPDATED)</h2>
<h3>Riley Simmons-Edler, Ben Eisner, Daniel Yang, Anthony Bisulco, Eric Mitchell, Sebastian Seung, Daniel Lee</h3>
<p>A major challenge in reinforcement learning is exploration, when local
dithering methods such as epsilon-greedy sampling are insufficient to solve a
given task. Many recent methods have proposed to intrinsically motivate an
agent to seek novel states, driving the agent to discover improved reward.
However, while state-novelty exploration methods are suitable for tasks where
novel observations correlate well with improved reward, they may not explore
more efficiently than epsilon-greedy approaches in environments where the two
are not well-correlated. In this paper, we distinguish between exploration
tasks in which seeking novel states aids in finding new reward, and those where
it does not, such as goal-conditioned tasks and escaping local reward maxima.
We propose a new exploration objective, maximizing the reward prediction error
(RPE) of a value function trained to predict extrinsic reward. We then propose
a deep reinforcement learning method, QXplore, which exploits the temporal
difference error of a Q-function to solve hard exploration tasks in
high-dimensional MDPs. We demonstrate the exploration behavior of QXplore on
several OpenAI Gym MuJoCo tasks and Atari games and observe that QXplore is
comparable to or better than a baseline state-novelty method in all cases,
outperforming the baseline on tasks where state novelty is not well-correlated
with improved reward.
</p>
<a href="http://arxiv.org/abs/1906.08189" target="_blank">arXiv:1906.08189</a> [<a href="http://arxiv.org/pdf/1906.08189" target="_blank">pdf</a>]

<h2>In Defense of LSTMs for Addressing Multiple Instance Learning Problems. (arXiv:1909.05690v5 [cs.CV] UPDATED)</h2>
<h3>Kaili Wang, Jose Oramas, Tinne Tuytelaars</h3>
<p>LSTMs have a proven track record in analyzing sequential data. But what about
unordered instance bags, as found under a Multiple Instance Learning (MIL)
setting? While not often used for this, we show LSTMs excell under this setting
too. In addition, we show thatLSTMs are capable of indirectly capturing
instance-level information us-ing only bag-level annotations. Thus, they can be
used to learn instance-level models in a weakly supervised manner. Our
empirical evaluation on both simplified (MNIST) and realistic (Lookbook and
Histopathology) datasets shows that LSTMs are competitive with or even surpass
state-of-the-art methods specially designed for handling specific MIL problems.
Moreover, we show that their performance on instance-level prediction is close
to that of fully-supervised methods.
</p>
<a href="http://arxiv.org/abs/1909.05690" target="_blank">arXiv:1909.05690</a> [<a href="http://arxiv.org/pdf/1909.05690" target="_blank">pdf</a>]

<h2>Lane Attention: Predicting Vehicles' Moving Trajectories by Learning Their Attention over Lanes. (arXiv:1909.13377v2 [cs.LG] UPDATED)</h2>
<h3>Jiacheng Pan, Hongyi Sun, Kecheng Xu, Yifei Jiang, Xiangquan Xiao, Jiangtao Hu, Jinghao Miao</h3>
<p>Accurately forecasting the future movements of surrounding vehicles is
essential for safe and efficient operations of autonomous driving cars. This
task is difficult because a vehicle's moving trajectory is greatly determined
by its driver's intention, which is often hard to estimate. By leveraging
attention mechanisms along with long short-term memory (LSTM) networks, this
work learns the relation between a driver's intention and the vehicle's
changing positions relative to road infrastructures, and uses it to guide the
prediction. Different from other state-of-the-art solutions, our work treats
the on-road lanes as non-Euclidean structures, unfolds the vehicle's moving
history to form a spatio-temporal graph, and uses methods from Graph Neural
Networks to solve the problem. Not only is our approach a pioneering attempt in
using non-Euclidean methods to process static environmental features around a
predicted object, our model also outperforms other state-of-the-art models in
several metrics. The practicability and interpretability analysis of the model
shows great potential for large-scale deployment in various autonomous driving
systems in addition to our own.
</p>
<a href="http://arxiv.org/abs/1909.13377" target="_blank">arXiv:1909.13377</a> [<a href="http://arxiv.org/pdf/1909.13377" target="_blank">pdf</a>]

<h2>IdBench: Evaluating Semantic Representations of Identifier Names in Source Code. (arXiv:1910.05177v2 [cs.LG] UPDATED)</h2>
<h3>Yaza Wainakh, Moiz Rauf, Michael Pradel</h3>
<p>Identifier names convey useful information about the intended semantics of
code. Name-based program analyses use this information, e.g., to detect bugs,
to predict types, and to improve the readability of code. At the core of
name-based analyses are semantic representations of identifiers, e.g., in the
form of learned embeddings. The high-level goal of such a representation is to
encode whether two identifiers, e.g., len and size, are semantically similar.
Unfortunately, it is currently unclear to what extent semantic representations
match the semantic relatedness and similarity perceived by developers. This
paper presents IdBench, the first benchmark for evaluating semantic
representations against a ground truth created from thousands of ratings by 500
software developers. We use IdBench to study state-of-the-art embedding
techniques proposed for natural language, an embedding technique specifically
designed for source code, and lexical string distance functions. Our results
show that the effectiveness of semantic representations varies significantly
and that the best available embeddings successfully represent semantic
relatedness. On the downside, no existing technique provides a satisfactory
representation of semantic similarities, among other reasons because
identifiers with opposing meanings are incorrectly considered to be similar,
which may lead to fatal mistakes, e.g., in a refactoring tool. Studying the
strengths and weaknesses of the different techniques shows that they complement
each other. As a first step toward exploiting this complementarity, we present
an ensemble model that combines existing techniques and that clearly
outperforms the best available semantic representation.
</p>
<a href="http://arxiv.org/abs/1910.05177" target="_blank">arXiv:1910.05177</a> [<a href="http://arxiv.org/pdf/1910.05177" target="_blank">pdf</a>]

<h2>Post-training Quantization with Multiple Points: Mixed Precision without Mixed Precision. (arXiv:2002.09049v3 [cs.LG] UPDATED)</h2>
<h3>Xingchao Liu, Mao Ye, Dengyong Zhou, Qiang Liu</h3>
<p>We consider the post-training quantization problem, which discretizes the
weights of pre-trained deep neural networks without re-training the model. We
propose multipoint quantization, a quantization method that approximates a
full-precision weight vector using a linear combination of multiple vectors of
low-bit numbers; this is in contrast to typical quantization methods that
approximate each weight using a single low precision number. Computationally,
we construct the multipoint quantization with an efficient greedy selection
procedure, and adaptively decides the number of low precision points on each
quantized weight vector based on the error of its output. This allows us to
achieve higher precision levels for important weights that greatly influence
the outputs, yielding an 'effect of mixed precision' but without physical mixed
precision implementations (which requires specialized hardware accelerators).
Empirically, our method can be implemented by common operands, bringing almost
no memory and computation overhead. We show that our method outperforms a range
of state-of-the-art methods on ImageNet classification and it can be
generalized to more challenging tasks like PASCAL VOC object detection.
</p>
<a href="http://arxiv.org/abs/2002.09049" target="_blank">arXiv:2002.09049</a> [<a href="http://arxiv.org/pdf/2002.09049" target="_blank">pdf</a>]

<h2>Learning Deep Kernels for Non-Parametric Two-Sample Tests. (arXiv:2002.09116v3 [stat.ML] UPDATED)</h2>
<h3>Feng Liu, Wenkai Xu, Jie Lu, Guangquan Zhang, Arthur Gretton, Danica J. Sutherland</h3>
<p>We propose a class of kernel-based two-sample tests, which aim to determine
whether two sets of samples are drawn from the same distribution. Our tests are
constructed from kernels parameterized by deep neural nets, trained to maximize
test power. These tests adapt to variations in distribution smoothness and
shape over space, and are especially suited to high dimensions and complex
data. By contrast, the simpler kernels used in prior kernel testing work are
spatially homogeneous, and adaptive only in lengthscale. We explain how this
scheme includes popular classifier-based two-sample tests as a special case,
but improves on them in general. We provide the first proof of consistency for
the proposed adaptation method, which applies both to kernels on deep features
and to simpler radial basis kernels or multiple kernel learning. In
experiments, we establish the superior performance of our deep kernels in
hypothesis testing on benchmark and real-world data. The code of our
deep-kernel-based two sample tests is available at
https://github.com/fengliu90/DK-for-TST.
</p>
<a href="http://arxiv.org/abs/2002.09116" target="_blank">arXiv:2002.09116</a> [<a href="http://arxiv.org/pdf/2002.09116" target="_blank">pdf</a>]

<h2>Tighter Bound Estimation of Sensitivity Analysis for Incremental and Decremental Data Modification. (arXiv:2003.03351v4 [cs.LG] UPDATED)</h2>
<h3>Kaichen Zhou, Shiji Song, Gao Huang, Wu Cheng, Quan Zhou</h3>
<p>In large-scale classification problems, the data set always be faced with
frequent updates when a part of the data is added to or removed from the
original data set. In this case, conventional incremental learning, which
updates an existing classifier by explicitly modeling the data modification, is
more efficient than retraining a new classifier from scratch. However,
sometimes, we are more interested in determining whether we should update the
classifier or performing some sensitivity analysis tasks. To deal with these
such tasks, we propose an algorithm to make rational inferences about the
updated linear classifier without exactly updating the classifier.
Specifically, the proposed algorithm can be used to estimate the upper and
lower bounds of the updated classifier's coefficient matrix with a low
computational complexity related to the size of the updated dataset. Both
theoretical analysis and experiment results show that the proposed approach is
superior to existing methods in terms of tightness of coefficients' bounds and
computational complexity.
</p>
<a href="http://arxiv.org/abs/2003.03351" target="_blank">arXiv:2003.03351</a> [<a href="http://arxiv.org/pdf/2003.03351" target="_blank">pdf</a>]

<h2>VMLoc: Variational Fusion For Learning-Based Multimodal Camera Localization. (arXiv:2003.07289v4 [cs.CV] UPDATED)</h2>
<h3>Kaichen Zhou, Changhao Chen, Bing Wang, Muhamad Risqi U. Saputra, Niki Trigoni, Andrew Markham</h3>
<p>Recent learning-based approaches have achieved impressive results in the
field of single-shot camera localization. However, how best to fuse multiple
modalities (e.g., image and depth) and to deal with degraded or missing input
are less well studied. In particular, we note that previous approaches towards
deep fusion do not perform significantly better than models employing a single
modality. We conjecture that this is because of the naive approaches to feature
space fusion through summation or concatenation which do not take into account
the different strengths of each modality. To address this, we propose an
end-to-end framework, termed VMLoc, to fuse different sensor inputs into a
common latent space through a variational Product-of-Experts (PoE) followed by
attention-based fusion. Unlike previous multimodal variational works directly
adapting the objective function of vanilla variational auto-encoder, we show
how camera localization can be accurately estimated through an unbiased
objective function based on importance weighting. Our model is extensively
evaluated on RGB-D datasets and the results prove the efficacy of our model.
The source code is available at https://github.com/Zalex97/VMLoc.
</p>
<a href="http://arxiv.org/abs/2003.07289" target="_blank">arXiv:2003.07289</a> [<a href="http://arxiv.org/pdf/2003.07289" target="_blank">pdf</a>]

<h2>Pose Augmentation: Class-agnostic Object Pose Transformation for Object Recognition. (arXiv:2003.08526v4 [cs.CV] UPDATED)</h2>
<h3>Yunhao Ge, Jiaping Zhao, Laurent Itti</h3>
<p>Object pose increases intraclass object variance which makes object
recognition from 2D images harder. To render a classifier robust to pose
variations, most deep neural networks try to eliminate the influence of pose by
using large datasets with many poses for each class. Here, we propose a
different approach: a class-agnostic object pose transformation network
(OPT-Net) can transform an image along 3D yaw and pitch axes to synthesize
additional poses continuously. Synthesized images lead to better training of an
object classifier. We design a novel eliminate-add structure to explicitly
disentangle pose from object identity: first eliminate pose information of the
input image and then add target pose information (regularized as continuous
variables) to synthesize any target pose. We trained OPT-Net on images of toy
vehicles shot on a turntable from the iLab-20M dataset. After training on
unbalanced discrete poses (5 classes with 6 poses per object instance, plus 5
classes with only 2 poses), we show that OPT-Net can synthesize balanced
continuous new poses along yaw and pitch axes with high quality. Training a
ResNet-18 classifier with original plus synthesized poses improves mAP accuracy
by 9% overtraining on original poses only. Further, the pre-trained OPT-Net can
generalize to new object classes, which we demonstrate on both iLab-20M and
RGB-D. We also show that the learned features can generalize to ImageNet.
</p>
<a href="http://arxiv.org/abs/2003.08526" target="_blank">arXiv:2003.08526</a> [<a href="http://arxiv.org/pdf/2003.08526" target="_blank">pdf</a>]

<h2>Neuron Linear Transformation: Modeling the Domain Shift for Crowd Counting. (arXiv:2004.02133v2 [cs.CV] UPDATED)</h2>
<h3>Qi Wang, Tao Han, Junyu Gao, Yuan Yuan</h3>
<p>Cross-domain crowd counting (CDCC) is a hot topic due to its importance in
public safety. The purpose of CDCC is to alleviate the domain shift between the
source and target domain. Recently, typical methods attempt to extract
domain-invariant features via image translation and adversarial learning. When
it comes to specific tasks, we find that the domain shifts are reflected on
model parameters' differences. To describe the domain gap directly at the
parameter-level, we propose a Neuron Linear Transformation (NLT) method,
exploiting domain factor and bias weights to learn the domain shift.
Specifically, for a specific neuron of a source model, NLT exploits few labeled
target data to learn domain shift parameters. Finally, the target neuron is
generated via a linear transformation. Extensive experiments and analysis on
six real-world datasets validate that NLT achieves top performance compared
with other domain adaptation methods. An ablation study also shows that the NLT
is robust and more effective than supervised and fine-tune training. Code is
available at: \url{https://github.com/taohan10200/NLT}.
</p>
<a href="http://arxiv.org/abs/2004.02133" target="_blank">arXiv:2004.02133</a> [<a href="http://arxiv.org/pdf/2004.02133" target="_blank">pdf</a>]

<h2>Telling BERT's full story: from Local Attention to Global Aggregation. (arXiv:2004.05916v2 [cs.LG] UPDATED)</h2>
<h3>Damian Pascual, Gino Brunner, Roger Wattenhofer</h3>
<p>We take a deep look into the behavior of self-attention heads in the
transformer architecture. In light of recent work discouraging the use of
attention distributions for explaining a model's behavior, we show that
attention distributions can nevertheless provide insights into the local
behavior of attention heads. This way, we propose a distinction between local
patterns revealed by attention and global patterns that refer back to the
input, and analyze BERT from both angles. We use gradient attribution to
analyze how the output of an attention attention head depends on the input
tokens, effectively extending the local attention-based analysis to account for
the mixing of information throughout the transformer layers. We find that there
is a significant discrepancy between attention and attribution distributions,
caused by the mixing of context inside the model. We quantify this discrepancy
and observe that interestingly, there are some patterns that persist across all
layers despite the mixing.
</p>
<a href="http://arxiv.org/abs/2004.05916" target="_blank">arXiv:2004.05916</a> [<a href="http://arxiv.org/pdf/2004.05916" target="_blank">pdf</a>]

<h2>LOCA: LOcal Conformal Autoencoder for standardized data coordinates. (arXiv:2004.07234v2 [cs.LG] UPDATED)</h2>
<h3>Erez Peterfreund, Ofir Lindenbaum, Felix Dietrich, Tom Bertalan, Matan Gavish, Ioannis G. Kevrekidis, Ronald R. Coifman</h3>
<p>We propose a deep-learning based method for obtaining standardized data
coordinates from scientific measurements.Data observations are modeled as
samples from an unknown, non-linear deformation of an underlying Riemannian
manifold, which is parametrized by a few normalized latent variables. By
leveraging a repeated measurement sampling strategy, we present a method for
learning an embedding in $\mathbb{R}^d$ that is isometric to the latent
variables of the manifold. These data coordinates, being invariant under smooth
changes of variables, enable matching between different instrumental
observations of the same phenomenon. Our embedding is obtained using a LOcal
Conformal Autoencoder (LOCA), an algorithm that constructs an embedding to
rectify deformations by using a local z-scoring procedure while preserving
relevant geometric information. We demonstrate the isometric embedding
properties of LOCA on various model settings and observe that it exhibits
promising interpolation and extrapolation capabilities. Finally, we apply LOCA
to single-site Wi-Fi localization data, and to $3$-dimensional curved surface
estimation based on a $2$-dimensional projection.
</p>
<a href="http://arxiv.org/abs/2004.07234" target="_blank">arXiv:2004.07234</a> [<a href="http://arxiv.org/pdf/2004.07234" target="_blank">pdf</a>]

<h2>OptiGAN: Generative Adversarial Networks for Goal Optimized Sequence Generation. (arXiv:2004.07534v10 [cs.LG] UPDATED)</h2>
<h3>Mahmoud Hossam, Trung Le, Viet Huynh, Michael Papasimeon, Dinh Phung</h3>
<p>One of the challenging problems in sequence generation tasks is the optimized
generation of sequences with specific desired goals. Current sequential
generative models mainly generate sequences to closely mimic the training data,
without direct optimization of desired goals or properties specific to the
task. We introduce OptiGAN, a generative model that incorporates both
Generative Adversarial Networks (GAN) and Reinforcement Learning (RL) to
optimize desired goal scores using policy gradients. We apply our model to text
and real-valued sequence generation, where our model is able to achieve higher
desired scores out-performing GAN and RL baselines, while not sacrificing
output sample diversity.
</p>
<a href="http://arxiv.org/abs/2004.07534" target="_blank">arXiv:2004.07534</a> [<a href="http://arxiv.org/pdf/2004.07534" target="_blank">pdf</a>]

<h2>Leveraging Planar Regularities for Point Line Visual-Inertial Odometry. (arXiv:2004.11969v2 [cs.CV] UPDATED)</h2>
<h3>Xin Li, Yijia He, Jinlong Lin, Xiao Liu</h3>
<p>With monocular Visual-Inertial Odometry (VIO) system, 3D point cloud and
camera motion can be estimated simultaneously. Because pure sparse 3D points
provide a structureless representation of the environment, generating 3D mesh
from sparse points can further model the environment topology and produce dense
mapping. To improve the accuracy of 3D mesh generation and localization, we
propose a tightly-coupled monocular VIO system, PLP-VIO, which exploits point
features and line features as well as plane regularities. The co-planarity
constraints are used to leverage additional structure information for the more
accurate estimation of 3D points and spatial lines in state estimator. To
detect plane and 3D mesh robustly, we combine both the line features with point
features in the detection method. The effectiveness of the proposed method is
verified on both synthetic data and public datasets and is compared with other
state-of-the-art algorithms.
</p>
<a href="http://arxiv.org/abs/2004.11969" target="_blank">arXiv:2004.11969</a> [<a href="http://arxiv.org/pdf/2004.11969" target="_blank">pdf</a>]

<h2>Neural Computing for Online Arabic Handwriting Character Recognition using Hard Stroke Features Mining. (arXiv:2005.02171v2 [cs.CV] UPDATED)</h2>
<h3>Amjad Rehman</h3>
<p>Online Arabic cursive character recognition is still a big challenge due to
the existing complexities including Arabic cursive script styles, writing
speed, writer mood and so forth. Due to these unavoidable constraints, the
accuracy of online Arabic character's recognition is still low and retain space
for improvement. In this research, an enhanced method of detecting the desired
critical points from vertical and horizontal direction-length of handwriting
stroke features of online Arabic script recognition is proposed. Each extracted
stroke feature divides every isolated character into some meaningful pattern
known as tokens. A minimum feature set is extracted from these tokens for
classification of characters using a multilayer perceptron with a
back-propagation learning algorithm and modified sigmoid function-based
activation function. In this work, two milestones are achieved; firstly, attain
a fixed number of tokens, secondly, minimize the number of the most repetitive
tokens. For experiments, handwritten Arabic characters are selected from the
OHASD benchmark dataset to test and evaluate the proposed method. The proposed
method achieves an average accuracy of 98.6% comparable in state of art
character recognition techniques.
</p>
<a href="http://arxiv.org/abs/2005.02171" target="_blank">arXiv:2005.02171</a> [<a href="http://arxiv.org/pdf/2005.02171" target="_blank">pdf</a>]

<h2>Physics-informed learning of governing equations from scarce data. (arXiv:2005.03448v3 [cs.LG] UPDATED)</h2>
<h3>Zhao Chen, Yang Liu, Hao Sun</h3>
<p>Harnessing data to discover the underlying governing laws or equations that
describe the behavior of complex physical systems can significantly advance our
modeling, simulation and understanding of such systems in various science and
engineering disciplines. This work introduces a novel physics-informed deep
learning framework to discover governing partial differential equations (PDEs)
from scarce and noisy data for nonlinear spatiotemporal systems. In particular,
this approach seamlessly integrates the strengths of deep neural networks for
rich representation learning, physics embedding, automatic differentiation and
sparse regression to (1) approximate the solution of system variables, (2)
compute essential derivatives, as well as (3) identify the key derivative terms
and parameters that form the structure and explicit expression of the PDEs. The
efficacy and robustness of this method are demonstrated, both numerically and
experimentally, on discovering a variety of PDE systems with different levels
of data scarcity and noise accounting for different initial/boundary
conditions. The resulting computational framework shows the potential for
closed-form model discovery in practical applications where large and accurate
datasets are intractable to capture.
</p>
<a href="http://arxiv.org/abs/2005.03448" target="_blank">arXiv:2005.03448</a> [<a href="http://arxiv.org/pdf/2005.03448" target="_blank">pdf</a>]

<h2>CARPe Posterum: A Convolutional Approach for Real-time Pedestrian Path Prediction. (arXiv:2005.12469v2 [cs.CV] UPDATED)</h2>
<h3>Mat&#xed;as Mendieta, Hamed Tabkhi</h3>
<p>Pedestrian path prediction is an essential topic in computer vision and video
understanding. Having insight into the movement of pedestrians is crucial for
ensuring safe operation in a variety of applications including autonomous
vehicles, social robots, and environmental monitoring. Current works in this
area utilize complex generative or recurrent methods to capture many possible
futures. However, despite the inherent real-time nature of predicting future
paths, little work has been done to explore accurate and computationally
efficient approaches for this task. To this end, we propose a convolutional
approach for real-time pedestrian path prediction, \method. It utilizes a
variation of Graph Isomorphism Networks in combination with an agile
convolutional neural network design to form a fast and accurate path prediction
approach. Notable results in both inference speed and prediction accuracy are
achieved, improving FPS considerably in comparison to current state-of-the-art
methods while delivering competitive accuracy on well-known path prediction
datasets.
</p>
<a href="http://arxiv.org/abs/2005.12469" target="_blank">arXiv:2005.12469</a> [<a href="http://arxiv.org/pdf/2005.12469" target="_blank">pdf</a>]

<h2>Evaluating the Disentanglement of Deep Generative Models through Manifold Topology. (arXiv:2006.03680v4 [stat.ML] UPDATED)</h2>
<h3>Sharon Zhou, Eric Zelikman, Fred Lu, Andrew Y. Ng, Gunnar Carlsson, Stefano Ermon</h3>
<p>Learning disentangled representations is regarded as a fundamental task for
improving the generalization, robustness, and interpretability of generative
models. However, measuring disentanglement has been challenging and
inconsistent, often dependent on an ad-hoc external model or specific to a
certain dataset. To address this, we present a method for quantifying
disentanglement that only uses the generative model, by measuring the
topological similarity of conditional submanifolds in the learned
representation. This method showcases both unsupervised and supervised
variants. To illustrate the effectiveness and applicability of our method, we
empirically evaluate several state-of-the-art models across multiple datasets.
We find that our method ranks models similarly to existing methods. We make
ourcode publicly available at
https://github.com/stanfordmlgroup/disentanglement.
</p>
<a href="http://arxiv.org/abs/2006.03680" target="_blank">arXiv:2006.03680</a> [<a href="http://arxiv.org/pdf/2006.03680" target="_blank">pdf</a>]

<h2>Motion Prediction using Trajectory Sets and Self-Driving Domain Knowledge. (arXiv:2006.04767v2 [cs.LG] UPDATED)</h2>
<h3>Freddy A. Boulton, Elena Corina Grigore, Eric M. Wolff</h3>
<p>Predicting the future motion of vehicles has been studied using various
techniques, including stochastic policies, generative models, and regression.
Recent work has shown that classification over a trajectory set, which
approximates possible motions, achieves state-of-the-art performance and avoids
issues like mode collapse. However, map information and the physical
relationships between nearby trajectories is not fully exploited in this
formulation. We build on classification-based approaches to motion prediction
by adding an auxiliary loss that penalizes off-road predictions. This auxiliary
loss can easily be pretrained using only map information (e.g., off-road area),
which significantly improves performance on small datasets. We also investigate
weighted cross-entropy losses to capture spatial-temporal relationships among
trajectories. Our final contribution is a detailed comparison of classification
and ordinal regression on two public self-driving datasets.
</p>
<a href="http://arxiv.org/abs/2006.04767" target="_blank">arXiv:2006.04767</a> [<a href="http://arxiv.org/pdf/2006.04767" target="_blank">pdf</a>]

<h2>On Uniform Convergence and Low-Norm Interpolation Learning. (arXiv:2006.05942v3 [stat.ML] UPDATED)</h2>
<h3>Lijia Zhou, Danica J. Sutherland, Nathan Srebro</h3>
<p>We consider an underdetermined noisy linear regression model where the
minimum-norm interpolating predictor is known to be consistent, and ask: can
uniform convergence in a norm ball, or at least (following Nagarajan and
Kolter) the subset of a norm ball that the algorithm selects on a typical input
set, explain this success? We show that uniformly bounding the difference
between empirical and population errors cannot show any learning in the norm
ball, and cannot show consistency for any set, even one depending on the exact
algorithm and distribution. But we argue we can explain the consistency of the
minimal-norm interpolator with a slightly weaker, yet standard, notion: uniform
convergence of zero-error predictors in a norm ball. We use this to bound the
generalization error of low- (but not minimal-) norm interpolating predictors.
</p>
<a href="http://arxiv.org/abs/2006.05942" target="_blank">arXiv:2006.05942</a> [<a href="http://arxiv.org/pdf/2006.05942" target="_blank">pdf</a>]

<h2>Strictly Batch Imitation Learning by Energy-based Distribution Matching. (arXiv:2006.14154v2 [stat.ML] UPDATED)</h2>
<h3>Daniel Jarrett, Ioana Bica, Mihaela van der Schaar</h3>
<p>Consider learning a policy purely on the basis of demonstrated behavior --
that is, with no access to reinforcement signals, no knowledge of transition
dynamics, and no further interaction with the environment. This *strictly batch
imitation learning* problem arises wherever live experimentation is costly,
such as in healthcare. One solution is simply to retrofit existing algorithms
for apprenticeship learning to work in the offline setting. But such an
approach leans heavily on off-policy evaluation or offline model estimation,
and can be indirect and inefficient. We argue that a good solution should be
able to explicitly parameterize a policy (i.e. respecting action conditionals),
implicitly learn from rollout dynamics (i.e. leveraging state marginals), and
-- crucially -- operate in an entirely offline fashion. To address this
challenge, we propose a novel technique by *energy-based distribution matching*
(EDM): By identifying parameterizations of the (discriminative) model of a
policy with the (generative) energy function for state distributions, EDM
yields a simple but effective solution that equivalently minimizes a divergence
between the occupancy measure for the demonstrator and a model thereof for the
imitator. Through experiments with application to control and healthcare
settings, we illustrate consistent performance gains over existing algorithms
for strictly batch imitation learning.
</p>
<a href="http://arxiv.org/abs/2006.14154" target="_blank">arXiv:2006.14154</a> [<a href="http://arxiv.org/pdf/2006.14154" target="_blank">pdf</a>]

<h2>Random Partitioning Forest for Point-Wise and Collective Anomaly Detection -- Application to Intrusion Detection. (arXiv:2006.16801v2 [cs.LG] UPDATED)</h2>
<h3>Pierre-Francois Marteau</h3>
<p>In this paper, we propose DiFF-RF, an ensemble approach composed of random
partitioning binary trees to detect point-wise and collective (as well as
contextual) anomalies. Thanks to a distance-based paradigm used at the leaves
of the trees, this semi-supervised approach solves a drawback that has been
identified in the isolation forest (IF) algorithm. Moreover, taking into
account the frequencies of visits in the leaves of the random trees allows to
significantly improve the performance of DiFF-RF when considering the presence
of collective anomalies. DiFF-RF is fairly easy to train, and excellent
performance can be obtained by using a simple semi-supervised procedure to
setup the extra hyper-parameter that is introduced. We first evaluate DiFF-RF
on a synthetic data set to i) verify that the limitation of the IF algorithm is
overcome, ii) demonstrate how collective anomalies are actually detected and
iii) to analyze the effect of the meta-parameters it involves. We assess the
DiFF-RF algorithm on a large set of datasets from the UCI repository, as well
as two benchmarks related to intrusion detection applications. Our experiments
show that DiFF-RF almost systematically outperforms the IF algorithm, but also
challenges the one-class SVM baseline and a deep learning variational
auto-encoder architecture. Furthermore, our experience shows that DiFF-RF can
work well in the presence of small-scale learning data, which is conversely
difficult for deep neural architectures. Finally, DiFF-RF is computationally
efficient and can be easily parallelized on multi-core architectures.
</p>
<a href="http://arxiv.org/abs/2006.16801" target="_blank">arXiv:2006.16801</a> [<a href="http://arxiv.org/pdf/2006.16801" target="_blank">pdf</a>]

<h2>Transformations between deep neural networks. (arXiv:2007.05646v3 [cs.LG] UPDATED)</h2>
<h3>Tom Bertalan, Felix Dietrich, Ioannis G. Kevrekidis</h3>
<p>We propose to test, and when possible establish, an equivalence between two
different artificial neural networks by attempting to construct a data-driven
transformation between them, using manifold-learning techniques. In particular,
we employ diffusion maps with a Mahalanobis-like metric. If the construction
succeeds, the two networks can be thought of as belonging to the same
equivalence class.

We first discuss transformation functions between only the outputs of the two
networks; we then also consider transformations that take into account outputs
(activations) of a number of internal neurons from each network. In general,
Whitney's theorem dictates the number of measurements from one of the networks
required to reconstruct each and every feature of the second network. The
construction of the transformation function relies on a consistent, intrinsic
representation of the network input space.

We illustrate our algorithm by matching neural network pairs trained to learn
(a) observations of scalar functions; (b) observations of two-dimensional
vector fields; and (c) representations of images of a moving three-dimensional
object (a rotating horse). The construction of such equivalence classes across
different network instantiations clearly relates to transfer learning. We also
expect that it will be valuable in establishing equivalence between different
Machine Learning-based models of the same phenomenon observed through different
instruments and by different research groups.
</p>
<a href="http://arxiv.org/abs/2007.05646" target="_blank">arXiv:2007.05646</a> [<a href="http://arxiv.org/pdf/2007.05646" target="_blank">pdf</a>]

<h2>Learning Robust State Abstractions for Hidden-Parameter Block MDPs. (arXiv:2007.07206v3 [cs.LG] UPDATED)</h2>
<h3>Amy Zhang, Shagun Sodhani, Khimya Khetarpal, Joelle Pineau</h3>
<p>Many control tasks exhibit similar dynamics that can be modeled as having
common latent structure. Hidden-Parameter Markov Decision Processes (HiP-MDPs)
explicitly model this structure to improve sample efficiency in multi-task
settings. However, this setting makes strong assumptions on the observability
of the state that limit its application in real-world scenarios with rich
observation spaces. In this work, we leverage ideas of common structure from
the HiP-MDP setting, and extend it to enable robust state abstractions inspired
by Block MDPs. We derive instantiations of this new framework for both
multi-task reinforcement learning (MTRL) and meta-reinforcement learning
(Meta-RL) settings. Further, we provide transfer and generalization bounds
based on task and state similarity, along with sample complexity bounds that
depend on the aggregate number of samples across tasks, rather than the number
of tasks, a significant improvement over prior work that use the same
environment assumptions. To further demonstrate the efficacy of the proposed
method, we empirically compare and show improvement over multi-task and
meta-reinforcement learning baselines.
</p>
<a href="http://arxiv.org/abs/2007.07206" target="_blank">arXiv:2007.07206</a> [<a href="http://arxiv.org/pdf/2007.07206" target="_blank">pdf</a>]

<h2>EMaQ: Expected-Max Q-Learning Operator for Simple Yet Effective Offline and Online RL. (arXiv:2007.11091v2 [cs.LG] UPDATED)</h2>
<h3>Seyed Kamyar Seyed Ghasemipour, Dale Schuurmans, Shixiang Shane Gu</h3>
<p>Off-policy reinforcement learning holds the promise of sample-efficient
learning of decision-making policies by leveraging past experience. However, in
the offline RL setting -- where a fixed collection of interactions are provided
and no further interactions are allowed -- it has been shown that standard
off-policy RL methods can significantly underperform. Recently proposed methods
often aim to address this shortcoming by constraining learned policies to
remain close to the given dataset of interactions. In this work, we closely
investigate an important simplification of BCQ -- a prior approach for offline
RL -- which removes a heuristic design choice and naturally restricts extracted
policies to remain exactly within the support of a given behavior policy.
Importantly, in contrast to their original theoretical considerations, we
derive this simplified algorithm through the introduction of a novel backup
operator, Expected-Max Q-Learning (EMaQ), which is more closely related to the
resulting practical algorithm. Specifically, in addition to the distribution
support, EMaQ explicitly considers the number of samples and the proposal
distribution, allowing us to derive new sub-optimality bounds which can serve
as a novel measure of complexity for offline RL problems. In the offline RL
setting -- the main focus of this work -- EMaQ matches and outperforms prior
state-of-the-art in the D4RL benchmarks. In the online RL setting, we
demonstrate that EMaQ is competitive with Soft Actor Critic. The key
contributions of our empirical findings are demonstrating the importance of
careful generative model design for estimating behavior policies, and an
intuitive notion of complexity for offline RL problems. With its simple
interpretation and fewer moving parts, such as no explicit function
approximator representing the policy, EMaQ serves as a strong yet easy to
implement baseline for future work.
</p>
<a href="http://arxiv.org/abs/2007.11091" target="_blank">arXiv:2007.11091</a> [<a href="http://arxiv.org/pdf/2007.11091" target="_blank">pdf</a>]

<h2>Relation-aware Meta-learning for Market Segment Demand Prediction with Limited Records. (arXiv:2008.00181v2 [cs.LG] UPDATED)</h2>
<h3>Jiatu Shi, Huaxiu Yao, Xian Wu, Tong Li, Zedong Lin, Tengfei Wang, Binqiang Zhao</h3>
<p>E-commerce business is revolutionizing our shopping experiences by providing
convenient and straightforward services. One of the most fundamental problems
is how to balance the demand and supply in market segments to build an
efficient platform. While conventional machine learning models have achieved
great success on data-sufficient segments, it may fail in a large-portion of
segments in E-commerce platforms, where there are not sufficient records to
learn well-trained models. In this paper, we tackle this problem in the context
of market segment demand prediction. The goal is to facilitate the learning
process in the target segments by leveraging the learned knowledge from
data-sufficient source segments. Specifically, we propose a novel algorithm,
RMLDP, to incorporate a multi-pattern fusion network (MPFN) with a
meta-learning paradigm. The multi-pattern fusion network considers both local
and seasonal temporal patterns for segment demand prediction. In the
meta-learning paradigm, transferable knowledge is regarded as the model
parameter initialization of MPFN, which are learned from diverse source
segments. Furthermore, we capture the segment relations by combining
data-driven segment representation and segment knowledge graph representation
and tailor the segment-specific relations to customize transferable model
parameter initialization. Thus, even with limited data, the target segment can
quickly find the most relevant transferred knowledge and adapt to the optimal
parameters. We conduct extensive experiments on two large-scale industrial
datasets. The results justify that our RMLDP outperforms a set of
state-of-the-art baselines. Besides, RMLDP has been deployed in Taobao, a
real-world E-commerce platform. The online A/B testing results further
demonstrate the practicality of RMLDP.
</p>
<a href="http://arxiv.org/abs/2008.00181" target="_blank">arXiv:2008.00181</a> [<a href="http://arxiv.org/pdf/2008.00181" target="_blank">pdf</a>]

<h2>VR-Caps: A Virtual Environment for Capsule Endoscopy. (arXiv:2008.12949v2 [cs.CV] UPDATED)</h2>
<h3>Kagan Incetan, Ibrahim Omer Celik, Abdulhamid Obeid, Guliz Irem Gokceler, Kutsev Bengisu Ozyoruk, Yasin Almalioglu, Richard J. Chen, Faisal Mahmood, Hunter Gilbert, Nicholas J. Durr, Mehmet Turan</h3>
<p>Current capsule endoscopes and next-generation robotic capsules for diagnosis
and treatment of gastrointestinal diseases are complex cyber-physical platforms
that must orchestrate complex software and hardware functions. The desired
tasks for these systems include visual localization, depth estimation, 3D
mapping, disease detection and segmentation, automated navigation, active
control, path realization and optional therapeutic modules such as targeted
drug delivery and biopsy sampling. Data-driven algorithms promise to enable
many advanced functionalities for capsule endoscopes, but real-world data is
challenging to obtain. Physically-realistic simulations providing synthetic
data have emerged as a solution to the development of data-driven algorithms.
In this work, we present a comprehensive simulation platform for capsule
endoscopy operations and introduce VR-Caps, a virtual active capsule
environment that simulates a range of normal and abnormal tissue conditions
(e.g., inflated, dry, wet etc.) and varied organ types, capsule endoscope
designs (e.g., mono, stereo, dual and 360{\deg}camera), and the type, number,
strength, and placement of internal and external magnetic sources that enable
active locomotion. VR-Caps makes it possible to both independently or jointly
develop, optimize, and test medical imaging and analysis software for the
current and next-generation endoscopic capsule systems. To validate this
approach, we train state-of-the-art deep neural networks to accomplish various
medical image analysis tasks using simulated data from VR-Caps and evaluate the
performance of these models on real medical data. Results demonstrate the
usefulness and effectiveness of the proposed virtual platform in developing
algorithms that quantify fractional coverage, camera trajectory, 3D map
reconstruction, and disease classification.
</p>
<a href="http://arxiv.org/abs/2008.12949" target="_blank">arXiv:2008.12949</a> [<a href="http://arxiv.org/pdf/2008.12949" target="_blank">pdf</a>]

<h2>SPAN: Spatial Pyramid Attention Network forImage Manipulation Localization. (arXiv:2009.00726v2 [cs.CV] UPDATED)</h2>
<h3>Xuefeng Hu, Zhihan Zhang, Zhenye Jiang, Syomantak Chaudhuri, Zhenheng Yang, Ram Nevatia</h3>
<p>We present a novel framework, Spatial Pyramid Attention Network (SPAN) for
detection and localization of multiple types of image manipulations. The
proposed architecture efficiently and effectively models the relationship
between image patches at multiple scales by constructing a pyramid of local
self-attention blocks. The design includes a novel position projection to
encode the spatial positions of the patches. SPAN is trained on a generic,
synthetic dataset but can also be fine tuned for specific datasets; The
proposed method shows significant gains in performance on standard datasets
over previous state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2009.00726" target="_blank">arXiv:2009.00726</a> [<a href="http://arxiv.org/pdf/2009.00726" target="_blank">pdf</a>]

<h2>Variational Deep Learning for the Identification and Reconstruction of Chaotic and Stochastic Dynamical Systems from Noisy and Partial Observations. (arXiv:2009.02296v5 [cs.LG] UPDATED)</h2>
<h3>Duong Nguyen, Said Ouala, Lucas Drumetz, Ronan Fablet</h3>
<p>The data-driven recovery of the unknown governing equations of dynamical
systems has recently received an increasing interest. However, the
identification of the governing equations remains challenging when dealing with
noisy and partial observations. Here, we address this challenge and investigate
variational deep learning schemes. Within the proposed framework, we jointly
learn an inference model to reconstruct the true states of the system from
series of noisy and partial data, and the governing laws of these states. In
doing so, this framework bridges classical data assimilation and
state-of-the-art machine learning techniques. We also demonstrate that it
generalises state-of-the-art methods. Importantly, both the inference model and
the governing model embed stochastic components to account for stochastic
variabilities, model errors, and reconstruction uncertainties. Various
experiments on chaotic and stochastic dynamical systems support the relevance
of our scheme w.r.t. state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2009.02296" target="_blank">arXiv:2009.02296</a> [<a href="http://arxiv.org/pdf/2009.02296" target="_blank">pdf</a>]

<h2>MATS: An Interpretable Trajectory Forecasting Representation for Planning and Control. (arXiv:2009.07517v2 [cs.RO] UPDATED)</h2>
<h3>Boris Ivanovic, Amine Elhafsi, Guy Rosman, Adrien Gaidon, Marco Pavone</h3>
<p>Reasoning about human motion is a core component of modern human-robot
interactive systems. In particular, one of the main uses of behavior prediction
in autonomous systems is to inform robot motion planning and control. However,
a majority of planning and control algorithms reason about system dynamics
rather than the predicted agent tracklets (i.e., ordered sets of waypoints)
that are commonly output by trajectory forecasting methods, which can hinder
their integration. Towards this end, we propose Mixtures of Affine Time-varying
Systems (MATS) as an output representation for trajectory forecasting that is
more amenable to downstream planning and control use. Our approach leverages
successful ideas from probabilistic trajectory forecasting works to learn
dynamical system representations that are well-studied in the planning and
control literature. We integrate our predictions with a proposed multimodal
planning methodology and demonstrate significant computational efficiency
improvements on a large-scale autonomous driving dataset.
</p>
<a href="http://arxiv.org/abs/2009.07517" target="_blank">arXiv:2009.07517</a> [<a href="http://arxiv.org/pdf/2009.07517" target="_blank">pdf</a>]

<h2>Multiple Exemplars-based Hallucinationfor Face Super-resolution and Editing. (arXiv:2009.07827v3 [cs.CV] UPDATED)</h2>
<h3>Kaili Wang, Jose Oramas, Tinne Tuytelaars</h3>
<p>Given a really low-resolution input image of a face (say 16x16 or 8x8
pixels), the goal of this paper is to reconstruct a high-resolution version
thereof. This, by itself, is an ill-posed problem, as the high-frequency
information is missing in the low-resolution input and needs to be
hallucinated, based on prior knowledge about the image content. Rather than
relying on a generic face prior, in this paper, we explore the use of a set of
exemplars, i.e. other high-resolution images of the same person. These guide
the neural network as we condition the output on them. Multiple exemplars work
better than a single one. To combine the information from multiple exemplars
effectively, we introduce a pixel-wise weight generation module. Besides
standard face super-resolution, our method allows to perform subtle face
editing simply by replacing the exemplars with another set with different
facial features. A user study is conducted and shows the super-resolved images
can hardly be distinguished from real images on the CelebA dataset. A
qualitative comparison indicates our model outperforms methods proposed in the
literature on the CelebA and WebFace dataset.
</p>
<a href="http://arxiv.org/abs/2009.07827" target="_blank">arXiv:2009.07827</a> [<a href="http://arxiv.org/pdf/2009.07827" target="_blank">pdf</a>]

<h2>Support-set bottlenecks for video-text representation learning. (arXiv:2010.02824v2 [cs.CV] UPDATED)</h2>
<h3>Mandela Patrick, Po-Yao Huang, Yuki Asano, Florian Metze, Alexander Hauptmann, Jo&#xe3;o Henriques, Andrea Vedaldi</h3>
<p>The dominant paradigm for learning video-text representations -- noise
contrastive learning -- increases the similarity of the representations of
pairs of samples that are known to be related, such as text and video from the
same sample, and pushes away the representations of all other pairs. We posit
that this last behaviour is too strict, enforcing dissimilar representations
even for samples that are semantically-related -- for example, visually similar
videos or ones that share the same depicted action. In this paper, we propose a
novel method that alleviates this by leveraging a generative model to naturally
push these related samples together: each sample's caption must be
reconstructed as a weighted combination of other support samples' visual
representations. This simple idea ensures that representations are not
overly-specialized to individual samples, are reusable across the dataset, and
results in representations that explicitly encode semantics shared between
samples, unlike noise contrastive learning. Our proposed method outperforms
others by a large margin on MSR-VTT, VATEX and ActivityNet, and MSVD for
video-to-text and text-to-video retrieval.
</p>
<a href="http://arxiv.org/abs/2010.02824" target="_blank">arXiv:2010.02824</a> [<a href="http://arxiv.org/pdf/2010.02824" target="_blank">pdf</a>]

<h2>Learning Mesh-Based Simulation with Graph Networks. (arXiv:2010.03409v2 [cs.LG] UPDATED)</h2>
<h3>Tobias Pfaff, Meire Fortunato, Alvaro Sanchez-Gonzalez, Peter W. Battaglia</h3>
<p>Mesh-based simulations are central to modeling complex physical systems in
many disciplines across science and engineering. Mesh representations support
powerful numerical integration methods and their resolution can be adapted to
strike favorable trade-offs between accuracy and efficiency. However,
high-dimensional scientific simulations are very expensive to run, and solvers
and parameters must often be tuned individually to each system studied. Here we
introduce MeshGraphNets, a framework for learning mesh-based simulations using
graph neural networks. Our model can be trained to pass messages on a mesh
graph and to adapt the mesh discretization during forward simulation. Our
results show it can accurately predict the dynamics of a wide range of physical
systems, including aerodynamics, structural mechanics, and cloth. The model's
adaptivity supports learning resolution-independent dynamics and can scale to
more complex state spaces at test time. Our method is also highly efficient,
running 1-2 orders of magnitude faster than the simulation on which it is
trained. Our approach broadens the range of problems on which neural network
simulators can operate and promises to improve the efficiency of complex,
scientific modeling tasks.
</p>
<a href="http://arxiv.org/abs/2010.03409" target="_blank">arXiv:2010.03409</a> [<a href="http://arxiv.org/pdf/2010.03409" target="_blank">pdf</a>]

<h2>Robust Semi-Supervised Learning with Out of Distribution Data. (arXiv:2010.03658v2 [cs.LG] UPDATED)</h2>
<h3>Xujiang Zhao, Killamsetty Krishnateja, Rishabh Iyer, Feng Chen</h3>
<p>Recent Semi-supervised learning (SSL) works show significant improvement in
SSL algorithms' performance using better-unlabeled data representations.
However, recent work [Oliver et al., 2018] shows that the SSL algorithm's
performance could degrade when the unlabeled set has out-of-distribution
examples (OODs). In this work, we first study the critical causes of OOD's
negative impact on SSL algorithms. We found that (1) the OOD's effect on the
SSL algorithm's performance increases as its distance to the decision boundary
decreases, and (2) Batch Normalization (BN), a popular module, could degrade
the performance instead of improving the performance when the unlabeled set
contains OODs. To address the above causes, we proposed a novel unified-robust
SSL approach that can be easily extended to many existing SSL algorithms, and
improve their robustness against OODs. In particular, we propose a simple
modification of batch normalization, called weighted batch normalization, that
improves BN's robustness against OODs. We also developed two efficient
hyper-parameter optimization algorithms that have different tradeoffs in
computational efficiency and accuracy. Extensive experiments on synthetic and
real-world datasets prove that our proposed approaches significantly improves
the robustness of four representative SSL algorithms against OODs compared with
four state-of-the-art robust SSL approaches.
</p>
<a href="http://arxiv.org/abs/2010.03658" target="_blank">arXiv:2010.03658</a> [<a href="http://arxiv.org/pdf/2010.03658" target="_blank">pdf</a>]

<h2>Prioritized Level Replay. (arXiv:2010.03934v2 [cs.LG] UPDATED)</h2>
<h3>Minqi Jiang, Edward Grefenstette, Tim Rockt&#xe4;schel</h3>
<p>Simulated environments with procedurally generated content have become
popular benchmarks for testing systematic generalization of reinforcement
learning agents. Every level in such an environment is algorithmically created,
thereby exhibiting a unique configuration of underlying factors of variation,
such as layout, positions of entities, asset appearances, or even the rules
governing environment transitions. Fixed sets of training levels can be
determined to aid comparison and reproducibility, and test levels can be held
out to evaluate the generalization and robustness of agents. While prior work
samples training levels in a direct way (e.g. uniformly) for the agent to learn
from, we investigate the hypothesis that different levels provide different
learning progress for an agent at specific times during training. We introduce
Prioritized Level Replay, a general framework for estimating the future
learning potential of a level given the current state of the agent's policy. We
find that temporal-difference (TD) errors, while previously used to selectively
sample past transitions, also prove effective for scoring a level's future
learning potential when the agent replays (that is, revisits) that level to
generate entirely new episodes of experiences from it. We report significantly
improved sample-efficiency and generalization on the majority of Procgen
Benchmark environments as well as two challenging MiniGrid environments.
Lastly, we present a qualitative analysis showing that Prioritized Level Replay
induces an implicit curriculum, taking the agent gradually from easier to
harder levels.
</p>
<a href="http://arxiv.org/abs/2010.03934" target="_blank">arXiv:2010.03934</a> [<a href="http://arxiv.org/pdf/2010.03934" target="_blank">pdf</a>]

<h2>Robotic Pick-and-Place With Uncertain Object Instance Segmentation and Shape Completion. (arXiv:2010.07892v2 [cs.RO] UPDATED)</h2>
<h3>Marcus Gualtieri, Robert Platt</h3>
<p>We consider robotic pick-and-place of partially visible, novel objects, where
goal placements are non-trivial, e.g., tightly packed into a bin. One approach
is (a) use object instance segmentation and shape completion to model the
objects and (b) use a regrasp planner to decide grasps and places displacing
the models to their goals. However, it is critical for the planner to account
for uncertainty in the perceived models, as object geometries in unobserved
areas are just guesses. We account for perceptual uncertainty by incorporating
it into the regrasp planner's cost function. We compare seven different costs.
One of these, which uses neural networks to estimate probability of grasp and
place stability, consistently outperforms uncertainty-unaware costs and
evaluates faster than Monte Carlo sampling. On a real robot, the proposed cost
results in successfully packing objects tightly into a bin 7.8% more often
versus the commonly used minimum-number-of-grasps cost.
</p>
<a href="http://arxiv.org/abs/2010.07892" target="_blank">arXiv:2010.07892</a> [<a href="http://arxiv.org/pdf/2010.07892" target="_blank">pdf</a>]

<h2>Causal Transfer Random Forest: Combining Logged Data and Randomized Experiments for Robust Prediction. (arXiv:2010.08710v2 [cs.LG] UPDATED)</h2>
<h3>Shuxi Zeng, Murat Ali Bayir, Joesph J.Pfeiffer III, Denis Charles, Emre Kiciman</h3>
<p>It is often critical for prediction models to be robust to distributional
shifts between training and testing data. From a causal perspective, the
challenge is to distinguish the stable causal relationships from the unstable
spurious correlations across shifts. We describe a causal transfer random
forest (CTRF) that combines existing training data with a small amount of data
from a randomized experiment to train a model which is robust to the feature
shifts and therefore transfers to a new targeting distribution. Theoretically,
we justify the robustness of the approach against feature shifts with the
knowledge from causal learning. Empirically, we evaluate the CTRF using both
synthetic data experiments and real-world experiments in the Bing Ads platform,
including a click prediction task and in the context of an end-to-end
counterfactual optimization system. The proposed CTRF produces robust
predictions and outperforms most baseline methods compared in the presence of
feature shifts.
</p>
<a href="http://arxiv.org/abs/2010.08710" target="_blank">arXiv:2010.08710</a> [<a href="http://arxiv.org/pdf/2010.08710" target="_blank">pdf</a>]

<h2>Multi-Constitutive Neural Network for Large Deformation Poromechanics Problem. (arXiv:2010.15549v3 [cs.LG] UPDATED)</h2>
<h3>Qi Zhang, Yilin Chen, Ziyi Yang, Eric Darve</h3>
<p>In this paper, we study the problem of large-strain consolidation in
poromechanics with deep neural networks (DNN). Given different material
properties and different loading conditions, the goal is to predict pore
pressure and settlement. We propose a novel method "multi-constitutive neural
network" (MCNN) such that one model can solve several different constitutive
laws. We introduce a one-hot encoding vector as an additional input vector,
which is used to label the constitutive law we wish to solve. Then we build a
DNN which takes $(\hat{X}, \hat{t})$ as input along with a constitutive law
label and outputs the corresponding solution. It is the first time, to our
knowledge, that we can evaluate multi-constitutive laws through only one
training process while still obtaining good accuracies. We found that MCNN
trained to solve multiple PDEs outperforms individual neural network solvers
trained with PDE in some cases.
</p>
<a href="http://arxiv.org/abs/2010.15549" target="_blank">arXiv:2010.15549</a> [<a href="http://arxiv.org/pdf/2010.15549" target="_blank">pdf</a>]

<h2>Do We Need to Compensate for Motion Distortion and Doppler Effects in Spinning Radar Navigation?. (arXiv:2011.03512v4 [cs.RO] UPDATED)</h2>
<h3>Keenan Burnett, Angela P. Schoellig, Timothy D. Barfoot</h3>
<p>In order to tackle the challenge of unfavorable weather conditions such as
rain and snow, radar is being revisited as a parallel sensing modality to
vision and lidar. Recent works have made tremendous progress in applying
spinning radar to odometry and place recognition. However, these works have so
far ignored the impact of motion distortion and Doppler effects on
spinning-radar-based navigation, which may be significant in the self-driving
car domain where speeds can be high. In this work, we demonstrate the effect of
these distortions on radar odometry using the Oxford Radar RobotCar Dataset and
metric localization using our own data-taking platform. We revisit a
lightweight estimator that can recover the motion between a pair of radar scans
while accounting for both effects. Our conclusion is that both motion
distortion and the Doppler effect are significant in different aspects of
spinning radar navigation, with the former more prominent than the latter. Code
for this project can be found at:
https://github.com/keenan-burnett/yeti_radar_odometry
</p>
<a href="http://arxiv.org/abs/2011.03512" target="_blank">arXiv:2011.03512</a> [<a href="http://arxiv.org/pdf/2011.03512" target="_blank">pdf</a>]

<h2>Demonstrations of Cooperative Perception: Safety and Robustness in Connected and Automated Vehicle Operations. (arXiv:2011.08581v2 [cs.RO] UPDATED)</h2>
<h3>Mao Shan, Karan Narula, Yung Fei Wong, Stewart Worrall, Malik Khan, Paul Alexander, Eduardo Nebot</h3>
<p>Cooperative perception, or collective perception (CP) is an emerging and
promising technology for intelligent transportation systems (ITS). It enables
an ITS station (ITS-S) to share its local perception information with others by
means of vehicle-to-X (V2X) communication, thereby achieving improved
efficiency and safety in road transportation. In this paper, we present our
recent progress on the development of a connected and automated vehicle (CAV)
and intelligent roadside unit (IRSU). We present three different experiments to
demonstrate the use of CP service within intelligent infrastructure to improve
awareness of vulnerable road users (VRU) and thus safety for CAVs in various
traffic scenarios. We demonstrate in the experiments that a connected vehicle
(CV) can "see" a pedestrian around the corners. More importantly, we
demonstrate how CAVs can autonomously and safely interact with walking and
running pedestrians, relying only on the CP information from the IRSU through
vehicle-to-infrastructure (V2I) communication. This is one of the first
demonstrations of urban vehicle automation using only CP information. We also
address in the paper the handling of collective perception messages (CPMs)
received from the IRSU, and passing them through a pipeline of CP information
coordinate transformation with uncertainty, multiple road user tracking, and
eventually path planning/decision making within the CAV. The experimental
results were obtained with manually driven CV, fully autonomous CAV, and an
IRSU retrofitted with vision and laser sensors and a road user tracking system.
</p>
<a href="http://arxiv.org/abs/2011.08581" target="_blank">arXiv:2011.08581</a> [<a href="http://arxiv.org/pdf/2011.08581" target="_blank">pdf</a>]

<h2>Time series classification for predictive maintenance on event logs. (arXiv:2011.10996v3 [cs.LG] UPDATED)</h2>
<h3>Antoine Guillaume, Christel Vrain, Elloumi Wael</h3>
<p>Time series classification (TSC) gained a lot of attention in the past decade
and number of methods for representing and classifying time series have been
proposed. Nowadays, methods based on convolutional networks and ensemble
techniques represent the state of the art for time series classification.
Techniques transforming time series to image or text also provide reliable ways
to extract meaningful features or representations of time series. We compare
the state-of-the-art representation and classification methods on a specific
application, that is predictive maintenance from sequences of event logs. The
contributions of this paper are twofold: introducing a new data set for
predictive maintenance on automated teller machines (ATMs) log data and
comparing the performance of different representation methods for predicting
the occurrence of a breakdown. The problem is difficult since unlike the
classic case of predictive maintenance via signals from sensors, we have
sequences of discrete event logs occurring at any time and the lengths of the
sequences, corresponding to life cycles, vary a lot.
</p>
<a href="http://arxiv.org/abs/2011.10996" target="_blank">arXiv:2011.10996</a> [<a href="http://arxiv.org/pdf/2011.10996" target="_blank">pdf</a>]

<h2>V3H: View Variation and View Heredity for Incomplete Multi-view Clustering. (arXiv:2011.11194v2 [cs.LG] UPDATED)</h2>
<h3>Xiang Fang, Yuchong Hu, Pan Zhou, Dapeng Oliver Wu</h3>
<p>Real data often appear in the form of multiple incomplete views. Incomplete
multi-view clustering is an effective method to integrate these incomplete
views. Previous methods only learn the consistent information between different
views and ignore the unique information of each view, which limits their
clustering performance and generalizations. To overcome this limitation, we
propose a novel View Variation and View Heredity approach (V3H). Inspired by
the variation and the heredity in genetics, V3H first decomposes each subspace
into a variation matrix for the corresponding view and a heredity matrix for
all the views to represent the unique information and the consistent
information respectively. Then, by aligning different views based on their
cluster indicator matrices, V3H integrates the unique information from
different views to improve the clustering performance. Finally, with the help
of the adjustable low-rank representation based on the heredity matrix, V3H
recovers the underlying true data structure to reduce the influence of the
large incompleteness. More importantly, V3H presents possibly the first work to
introduce genetics to clustering algorithms for learning simultaneously the
consistent information and the unique information from incomplete multi-view
data. Extensive experimental results on fifteen benchmark datasets validate its
superiority over other state-of-the-arts.
</p>
<a href="http://arxiv.org/abs/2011.11194" target="_blank">arXiv:2011.11194</a> [<a href="http://arxiv.org/pdf/2011.11194" target="_blank">pdf</a>]

<h2>MultiStar: Instance Segmentation of Overlapping Objects with Star-Convex Polygons. (arXiv:2011.13228v2 [cs.CV] UPDATED)</h2>
<h3>Florin C. Walter, Sebastian Damrich, Fred A. Hamprecht</h3>
<p>Instance segmentation of overlapping objects in biomedical images remains a
largely unsolved problem. We take up this challenge and present MultiStar, an
extension to the popular instance segmentation method StarDist. The key novelty
of our method is that we identify pixels at which objects overlap and use this
information to improve proposal sampling and to avoid suppressing proposals of
truly overlapping objects. This allows us to apply the ideas of StarDist to
images with overlapping objects, while incurring only a small overhead compared
to the established method. MultiStar shows promising results on two datasets
and has the advantage of using a simple and easy to train network architecture.
</p>
<a href="http://arxiv.org/abs/2011.13228" target="_blank">arXiv:2011.13228</a> [<a href="http://arxiv.org/pdf/2011.13228" target="_blank">pdf</a>]

<h2>3DSNet: Unsupervised Shape-to-Shape 3D Style Transfer. (arXiv:2011.13388v3 [cs.CV] UPDATED)</h2>
<h3>Mattia Segu, Margarita Grinvald, Roland Siegwart, Federico Tombari</h3>
<p>Transferring the style from one image onto another is a popular and widely
studied task in computer vision. Yet, learning-based style transfer in the 3D
setting remains a largely unexplored problem. To our knowledge, we propose the
first learning-based approach for style transfer between 3D objects providing
disentangled content and style representations. Our method allows to combine
the content and style of a source and target 3D model to generate a novel shape
that resembles in style the target while retaining the source content. The
proposed framework can synthesize new 3D shapes both in the form of point
clouds and meshes. Furthermore, we extend our technique to implicitly learn the
underlying multimodal style distribution of the chosen domains. By sampling
style codes from the learned distributions, we increase the variety of styles
that our model can confer to a given reference object. Experimental results
validate the effectiveness of the proposed 3D style transfer method on a number
of benchmarks. The implementation of our framework will be released upon
acceptance.
</p>
<a href="http://arxiv.org/abs/2011.13388" target="_blank">arXiv:2011.13388</a> [<a href="http://arxiv.org/pdf/2011.13388" target="_blank">pdf</a>]

<h2>When does gradient descent with logistic loss find interpolating two-layer networks?. (arXiv:2012.02409v2 [stat.ML] UPDATED)</h2>
<h3>Niladri S. Chatterji, Philip M. Long, Peter L. Bartlett</h3>
<p>We study the training of finite-width two-layer smoothed ReLU networks for
binary classification using the logistic loss. We show that gradient descent
drives the training loss to zero if the initial loss is small enough. When the
data satisfies certain cluster and separation conditions and the network is
wide enough, we show that one step of gradient descent reduces the loss
sufficiently that the first result applies.
</p>
<a href="http://arxiv.org/abs/2012.02409" target="_blank">arXiv:2012.02409</a> [<a href="http://arxiv.org/pdf/2012.02409" target="_blank">pdf</a>]

<h2>A Riemannian Block Coordinate Descent Method for Computing the Projection Robust Wasserstein Distance. (arXiv:2012.05199v3 [cs.LG] UPDATED)</h2>
<h3>Minhui Huang, Shiqian Ma, Lifeng Lai</h3>
<p>The Wasserstein distance has become increasingly important in machine
learning and deep learning. Despite its popularity, the Wasserstein distance is
hard to approximate because of the curse of dimensionality. A recently proposed
approach to alleviate the curse of dimensionality is to project the sampled
data from the high dimensional probability distribution onto a
lower-dimensional subspace, and then compute the Wasserstein distance between
the projected data. However, this approach requires to solve a max-min problem
over the Stiefel manifold, which is very challenging in practice. The only
existing work that solves this problem directly is the RGAS (Riemannian
Gradient Ascent with Sinkhorn Iteration) algorithm, which requires to solve an
entropy-regularized optimal transport problem in each iteration, and thus can
be costly for large-scale problems. In this paper, we propose a Riemannian
block coordinate descent (RBCD) method to solve this problem, which is based on
a novel reformulation of the regularized max-min problem over the Stiefel
manifold. We show that the complexity of arithmetic operations for RBCD to
obtain an $\epsilon$-stationary point is $O(\epsilon^{-3})$. This significantly
improves the corresponding complexity of RGAS, which is $O(\epsilon^{-12})$.
Moreover, our RBCD has very low per-iteration complexity, and hence is suitable
for large-scale problems. Numerical results on both synthetic and real datasets
demonstrate that our method is more efficient than existing methods, especially
when the number of sampled data is very large.
</p>
<a href="http://arxiv.org/abs/2012.05199" target="_blank">arXiv:2012.05199</a> [<a href="http://arxiv.org/pdf/2012.05199" target="_blank">pdf</a>]

<h2>Classification with Strategically Withheld Data. (arXiv:2012.10203v2 [cs.LG] UPDATED)</h2>
<h3>Anilesh K. Krishnaswamy, Haoming Li, David Rein, Hanrui Zhang, Vincent Conitzer</h3>
<p>Machine learning techniques can be useful in applications such as credit
approval and college admission. However, to be classified more favorably in
such contexts, an agent may decide to strategically withhold some of her
features, such as bad test scores. This is a missing data problem with a twist:
which data is missing {\em depends on the chosen classifier}, because the
specific classifier is what may create the incentive to withhold certain
feature values. We address the problem of training classifiers that are robust
to this behavior.

We design three classification methods: {\sc Mincut}, {\sc Hill-Climbing}
({\sc HC}) and Incentive-Compatible Logistic Regression ({\sc IC-LR}). We show
that {\sc Mincut} is optimal when the true distribution of data is fully known.
However, it can produce complex decision boundaries, and hence be prone to
overfitting in some cases. Based on a characterization of truthful classifiers
(i.e., those that give no incentive to strategically hide features), we devise
a simpler alternative called {\sc HC} which consists of a hierarchical ensemble
of out-of-the-box classifiers, trained using a specialized hill-climbing
procedure which we show to be convergent. For several reasons, {\sc Mincut} and
{\sc HC} are not effective in utilizing a large number of complementarily
informative features. To this end, we present {\sc IC-LR}, a modification of
Logistic Regression that removes the incentive to strategically drop features.
We also show that our algorithms perform well in experiments on real-world data
sets, and present insights into their relative performance in different
settings.
</p>
<a href="http://arxiv.org/abs/2012.10203" target="_blank">arXiv:2012.10203</a> [<a href="http://arxiv.org/pdf/2012.10203" target="_blank">pdf</a>]

<h2>Adversarial Training for a Continuous Robustness Control Problem in Power Systems. (arXiv:2012.11390v2 [stat.ML] UPDATED)</h2>
<h3>Lo&#xef;c Omnes, Antoine Marot, Benjamin Donnot</h3>
<p>We propose a new adversarial training approach for injecting robustness when
designing controllers for upcoming cyber-physical power systems. Previous
approaches relying deeply on simulations are not able to cope with the rising
complexity and are too costly when used online in terms of computation budget.
In comparison, our method proves to be computationally efficient online while
displaying useful robustness properties. To do so we model an adversarial
framework, propose the implementation of a fixed opponent policy and test it on
a L2RPN (Learning to Run a Power Network) environment. That environment is a
synthetic but realistic modeling of a cyber-physical system accounting for one
third of the IEEE 118 grid. Using adversarial testing, we analyze the results
of submitted trained agents from the robustness track of the L2RPN competition.
We then further assess the performance of those agents in regards to the
continuous N-1 problem through tailored evaluation metrics. We discover that
some agents trained in an adversarial way demonstrate interesting preventive
behaviors in that regard, which we discuss.
</p>
<a href="http://arxiv.org/abs/2012.11390" target="_blank">arXiv:2012.11390</a> [<a href="http://arxiv.org/pdf/2012.11390" target="_blank">pdf</a>]

<h2>Robust Kernel-based Feature Representation for 3D Point Cloud Analysis via Circular Graph Convolutional Network. (arXiv:2012.12215v4 [cs.CV] UPDATED)</h2>
<h3>Seung Hwan Jung, Minyoung Chung, Yeong-Gil Shin</h3>
<p>Feature descriptors of point clouds are used in several applications, such as
registration and part segmentation of 3D point clouds. Learning discriminative
representations of local geometric features is unquestionably the most
important task for accurate point cloud analyses. However, it is challenging to
develop rotation or scale-invariant descriptors. Most previous studies have
either ignored rotations or empirically studied optimal scale parameters, which
hinders the applicability of the methods for real-world datasets. In this
paper, we present a new local feature description method that is robust to
rotation, density, and scale variations. Moreover, to improve representations
of the local descriptors, we propose a global aggregation method. First, we
place kernels aligned around each point in the normal direction. To avoid the
sign problem of the normal vector, we use a symmetric kernel point distribution
in the tangential plane. From each kernel point, we first projected the points
from the spatial space to the feature space, which is robust to multiple scales
and rotation, based on angles and distances. Subsequently, we perform graph
convolutions by considering local kernel point structures and long-range global
context, obtained by a global aggregation method. We experimented with our
proposed descriptors on benchmark datasets (i.e., ModelNet40 and ShapeNetPart)
to evaluate the performance of registration, classification, and part
segmentation on 3D point clouds. Our method showed superior performances when
compared to the state-of-the-art methods by reducing 70$\%$ of the rotation and
translation errors in the registration task. Our method also showed comparable
performance in the classification and part-segmentation tasks with simple and
low-dimensional architectures.
</p>
<a href="http://arxiv.org/abs/2012.12215" target="_blank">arXiv:2012.12215</a> [<a href="http://arxiv.org/pdf/2012.12215" target="_blank">pdf</a>]

<h2>Logic Tensor Networks. (arXiv:2012.13635v2 [cs.AI] UPDATED)</h2>
<h3>Samy Badreddine, Artur d&#x27;Avila Garcez, Luciano Serafini, Michael Spranger</h3>
<p>Artificial Intelligence agents are required to learn from their surroundings
and to reason about the knowledge that has been learned in order to make
decisions. While state-of-the-art learning from data typically uses
sub-symbolic distributed representations, reasoning is normally useful at a
higher level of abstraction with the use of a first-order logic language for
knowledge representation. As a result, attempts at combining symbolic AI and
neural computation into neural-symbolic systems have been on the increase. In
this paper, we present Logic Tensor Networks (LTN), a neurosymbolic formalism
and computational model that supports learning and reasoning through the
introduction of a many-valued, end-to-end differentiable first-order logic
called Real Logic as a representation language for deep learning. We show that
LTN provides a uniform language for the specification and the computation of
several AI tasks such as data clustering, multi-label classification,
relational learning, query answering, semi-supervised learning, regression and
embedding learning. We implement and illustrate each of the above tasks with a
number of simple explanatory examples using TensorFlow 2. Keywords:
Neurosymbolic AI, Deep Learning and Reasoning, Many-valued Logic.
</p>
<a href="http://arxiv.org/abs/2012.13635" target="_blank">arXiv:2012.13635</a> [<a href="http://arxiv.org/pdf/2012.13635" target="_blank">pdf</a>]

<h2>Paraconsistent Foundations for Probabilistic Reasoning, Programming and Concept Formation. (arXiv:2012.14474v2 [cs.AI] UPDATED)</h2>
<h3>Ben Goertzel</h3>
<p>It is argued that 4-valued paraconsistent truth values (called here "p-bits")
can serve as a conceptual, mathematical and practical foundation for highly
AI-relevant forms of probabilistic logic and probabilistic programming and
concept formation.

First it is shown that appropriate averaging-across-situations and
renormalization of 4-valued p-bits operating in accordance with Constructible
Duality (CD) logic yields PLN (Probabilistic Logic Networks)
strength-and-confidence truth values. Then variations on the Curry-Howard
correspondence are used to map these paraconsistent and probabilistic logics
into probabilistic types suitable for use within dependent type based
programming languages.

Zach Weber's paraconsistent analysis of the sorites paradox is extended to
form a paraconsistent / probabilistic / fuzzy analysis of concept boundaries;
and a paraconsistent version of concept formation via Formal Concept Analysis
is presented, building on a definition of fuzzy property-value degrees in terms
of relative entropy on paraconsistent probability distributions.

These general points are fleshed out via reference to the realization of
probabilistic reasoning and programming and concept formation in the OpenCog
AGI framework which is centered on collaborative multi-algorithm updating of a
common knowledge metagraph.
</p>
<a href="http://arxiv.org/abs/2012.14474" target="_blank">arXiv:2012.14474</a> [<a href="http://arxiv.org/pdf/2012.14474" target="_blank">pdf</a>]

<h2>Provable Generalization of SGD-trained Neural Networks of Any Width in the Presence of Adversarial Label Noise. (arXiv:2101.01152v2 [cs.LG] UPDATED)</h2>
<h3>Spencer Frei, Yuan Cao, Quanquan Gu</h3>
<p>We consider a one-hidden-layer leaky ReLU network of arbitrary width trained
by stochastic gradient descent following an arbitrary initialization. We prove
that stochastic gradient descent (SGD) produces neural networks that have
classification accuracy competitive with that of the best halfspace over the
distribution for a broad class of distributions that includes log-concave
isotropic and hard margin distributions. Equivalently, such networks can
generalize when the data distribution is linearly separable but corrupted with
adversarial label noise, despite the capacity to overfit. We conduct
experiments which suggest that for some distributions our generalization bounds
are nearly tight. This is the first result that shows that overparameterized
neural networks trained by SGD can generalize when the data is corrupted with
adversarial label noise.
</p>
<a href="http://arxiv.org/abs/2101.01152" target="_blank">arXiv:2101.01152</a> [<a href="http://arxiv.org/pdf/2101.01152" target="_blank">pdf</a>]

<h2>dame-flame: A Python Library Providing Fast Interpretable Matching for Causal Inference. (arXiv:2101.01867v2 [cs.LG] UPDATED)</h2>
<h3>Neha R. Gupta (1), Vittorio Orlandi (1), Chia-Rui Chang (2), Tianyu Wang (1), Marco Morucci (1), Pritam Dey (1), Thomas J. Howell (1), Xian Sun (1), Angikar Ghosal (1), Sudeepa Roy (1), Cynthia Rudin (1), Alexander Volfovsky (1) ((1) Duke University, (2) Harvard University)</h3>
<p>dame-flame is a Python package for performing matching for observational
causal inference on datasets containing discrete covariates. This package
implements the Dynamic Almost Matching Exactly (DAME) and Fast Large-Scale
Almost Matching Exactly (FLAME) algorithms, which match treatment and control
units on subsets of the covariates. The resulting matched groups are
interpretable, because the matches are made on covariates (rather than, for
instance, propensity scores), and high-quality, because machine learning is
used to determine which covariates are important to match on. DAME solves an
optimization problem that matches units on as many covariates as possible,
prioritizing matches on important covariates. FLAME approximates the solution
found by DAME via a much faster backward feature selection procedure. The
package provides several adjustable parameters to adapt the algorithms to
specific applications, and can calculate treatment effects after matching.
Descriptions of these parameters, details on estimating treatment effects, and
further examples, can be found in the documentation at
https://almost-matching-exactly.github.io/DAME-FLAME-Python-Package/
</p>
<a href="http://arxiv.org/abs/2101.01867" target="_blank">arXiv:2101.01867</a> [<a href="http://arxiv.org/pdf/2101.01867" target="_blank">pdf</a>]

<h2>Exploiting Multiple Timescales in Hierarchical Echo State Networks. (arXiv:2101.04223v2 [cs.LG] UPDATED)</h2>
<h3>Luca Manneschi, Matthew O. A. Ellis, Guido Gigante, Andrew C. Lin, Paolo Del Giudice, Eleni Vasilaki</h3>
<p>Echo state networks (ESNs) are a powerful form of reservoir computing that
only require training of linear output weights whilst the internal reservoir is
formed of fixed randomly connected neurons. With a correctly scaled
connectivity matrix, the neurons' activity exhibits the echo-state property and
responds to the input dynamics with certain timescales. Tuning the timescales
of the network can be necessary for treating certain tasks, and some
environments require multiple timescales for an efficient representation. Here
we explore the timescales in hierarchical ESNs, where the reservoir is
partitioned into two smaller linked reservoirs with distinct properties. Over
three different tasks (NARMA10, a reconstruction task in a volatile
environment, and psMNIST), we show that by selecting the hyper-parameters of
each partition such that they focus on different timescales, we achieve a
significant performance improvement over a single ESN. Through a linear
analysis, and under the assumption that the timescales of the first partition
are much shorter than the second's (typically corresponding to optimal
operating conditions), we interpret the feedforward coupling of the partitions
in terms of an effective representation of the input signal, provided by the
first partition to the second, whereby the instantaneous input signal is
expanded into a weighted combination of its time derivatives. Furthermore, we
propose a data-driven approach to optimise the hyper-parameters through a
gradient descent optimisation method that is an online approximation of
backpropagation through time. We demonstrate the application of the online
learning rule across all the tasks considered.
</p>
<a href="http://arxiv.org/abs/2101.04223" target="_blank">arXiv:2101.04223</a> [<a href="http://arxiv.org/pdf/2101.04223" target="_blank">pdf</a>]

<h2>Hyperbolic Deep Neural Networks: A Survey. (arXiv:2101.04562v2 [cs.LG] UPDATED)</h2>
<h3>Wei Peng, Tuomas Varanka, Abdelrahman Mostafa, Henglin Shi, Guoying Zhao</h3>
<p>Recently, there has been a raising surge of momentum for deep representation
learning in hyperbolic spaces due to theirhigh capacity of modeling data like
knowledge graphs or synonym hierarchies, possessing hierarchical structure. We
refer it ashyperbolic deep neural network in this paper. Such a hyperbolic
neural architecture potentially leads to drastically compact models withmuch
more physical interpretability than its counterpart in Euclidean space. To
stimulate future research, this paper presents acoherent and comprehensive
review of the literature around the neural components in the construction of
hyperbolic deep neuralnetworks, as well as the generalization of the leading
deep approaches to the Hyperbolic space. It also presents current
applicationsaround various machine learning tasks on several publicly available
datasets, together with insightful observations and identifying openquestions
and promising future directions.
</p>
<a href="http://arxiv.org/abs/2101.04562" target="_blank">arXiv:2101.04562</a> [<a href="http://arxiv.org/pdf/2101.04562" target="_blank">pdf</a>]

<h2>CityFlow-NL: Tracking and Retrieval of Vehicles at City Scale by Natural Language Descriptions. (arXiv:2101.04741v2 [cs.CV] UPDATED)</h2>
<h3>Qi Feng, Vitaly Ablavsky, Stan Sclaroff</h3>
<p>Natural Language (NL) descriptions can be the most convenient or the only way
to interact with systems built to understand and detect city scale traffic
patterns and vehicle-related events. In this paper, we extend the widely
adopted CityFlow Benchmark with natural language descriptions for vehicle
targets and introduce the CityFlow-NL Benchmark. The CityFlow-NL contains more
than 5,000 unique and precise NL descriptions of vehicle targets, making it the
largest-scale tracking with NL descriptions dataset to our knowledge. Moreover,
the dataset facilitates research at the intersection of multi-object tracking,
retrieval by NL descriptions, and temporal localization of events.
</p>
<a href="http://arxiv.org/abs/2101.04741" target="_blank">arXiv:2101.04741</a> [<a href="http://arxiv.org/pdf/2101.04741" target="_blank">pdf</a>]

<h2>EEC: Learning to Encode and Regenerate Images for Continual Learning. (arXiv:2101.04904v2 [cs.CV] UPDATED)</h2>
<h3>Ali Ayub, Alan R. Wagner</h3>
<p>The two main impediments to continual learning are catastrophic forgetting
and memory limitations on the storage of data. To cope with these challenges,
we propose a novel, cognitively-inspired approach which trains autoencoders
with Neural Style Transfer to encode and store images. During training on a new
task, reconstructed images from encoded episodes are replayed in order to avoid
catastrophic forgetting. The loss function for the reconstructed images is
weighted to reduce its effect during classifier training to cope with image
degradation. When the system runs out of memory the encoded episodes are
converted into centroids and covariance matrices, which are used to generate
pseudo-images during classifier training, keeping classifier performance stable
while using less memory. Our approach increases classification accuracy by
13-17% over state-of-the-art methods on benchmark datasets, while requiring 78%
less storage space.
</p>
<a href="http://arxiv.org/abs/2101.04904" target="_blank">arXiv:2101.04904</a> [<a href="http://arxiv.org/pdf/2101.04904" target="_blank">pdf</a>]

<h2>Optimal Projected Variance Group-Sparse Block PCA. (arXiv:1705.00461v2 [stat.ML] UPDATED)</h2>
<h3>Marie Chavent, Guy Chavent</h3>
<p>We address the problem of defining a group sparse formulation for Principal
Components Analysis (PCA) - or its equivalent formulations as Low Rank
approximation or Dictionary Learning problems - which achieves a compromise
between maximizing the variance explained by the components and promoting
sparsity of the loadings. So we propose first a new definition of the variance
explained by non necessarily orthogonal components, which is optimal in some
aspect and compatible with the principal components situation. Then we use a
specific regularization of this variance by the group-$\ell_{1}$ norm to define
a Group Sparse Maximum Variance (GSMV) formulation of PCA. The GSMV formulation
achieves our objective by construction, and has the nice property that the
inner non smooth optimization problem can be solved analytically, thus reducing
GSMV to the maximization of a smooth and convex function under unit norm and
orthogonality constraints, which generalizes Journee et al. (2010) to group
sparsity. Numerical comparison with deflation on synthetic data shows that GSMV
produces steadily slightly better and more robust results for the retrieval of
hidden sparse structures, and is about three times faster on these examples.
Application to real data shows the interest of group sparsity for variables
selection in PCA of mixed data (categorical/numerical) .
</p>
<a href="http://arxiv.org/abs/1705.00461" target="_blank">arXiv:1705.00461</a> [<a href="http://arxiv.org/pdf/1705.00461" target="_blank">pdf</a>]

