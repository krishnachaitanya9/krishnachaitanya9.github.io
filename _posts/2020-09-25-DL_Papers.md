---
title: Latest Deep Learning Papers
date: 2021-02-14 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (164 Articles)</h1>
<h2>Learning Gaussian-Bernoulli RBMs using Difference of Convex Functions Optimization. (arXiv:2102.06228v1 [cs.LG])</h2>
<h3>Vidyadhar Upadhya, P S Sastry</h3>
<p>The Gaussian-Bernoulli restricted Boltzmann machine (GB-RBM) is a useful
generative model that captures meaningful features from the given
$n$-dimensional continuous data. The difficulties associated with learning
GB-RBM are reported extensively in earlier studies. They indicate that the
training of the GB-RBM using the current standard algorithms, namely,
contrastive divergence (CD) and persistent contrastive divergence (PCD), needs
a carefully chosen small learning rate to avoid divergence which, in turn,
results in slow learning. In this work, we alleviate such difficulties by
showing that the negative log-likelihood for a GB-RBM can be expressed as a
difference of convex functions if we keep the variance of the conditional
distribution of visible units (given hidden unit states) and the biases of the
visible units, constant. Using this, we propose a stochastic {\em difference of
convex functions} (DC) programming (S-DCP) algorithm for learning the GB-RBM.
We present extensive empirical studies on several benchmark datasets to
validate the performance of this S-DCP algorithm. It is seen that S-DCP is
better than the CD and PCD algorithms in terms of speed of learning and the
quality of the generative model learnt.
</p>
<a href="http://arxiv.org/abs/2102.06228" target="_blank">arXiv:2102.06228</a> [<a href="http://arxiv.org/pdf/2102.06228" target="_blank">pdf</a>]

<h2>Higher Order Generalization Error for First Order Discretization of Langevin Diffusion. (arXiv:2102.06229v1 [stat.ML])</h2>
<h3>Mufan Bill Li, Maxime Gazeau</h3>
<p>We propose a novel approach to analyze generalization error for
discretizations of Langevin diffusion, such as the stochastic gradient Langevin
dynamics (SGLD). For an $\epsilon$ tolerance of expected generalization error,
it is known that a first order discretization can reach this target if we run
$\Omega(\epsilon^{-1} \log (\epsilon^{-1}) )$ iterations with
$\Omega(\epsilon^{-1})$ samples. In this article, we show that with additional
smoothness assumptions, even first order methods can achieve arbitrarily
runtime complexity. More precisely, for each $N&gt;0$, we provide a sufficient
smoothness condition on the loss function such that a first order
discretization can reach $\epsilon$ expected generalization error given
$\Omega( \epsilon^{-1/N} \log (\epsilon^{-1}) )$ iterations with
$\Omega(\epsilon^{-1})$ samples.
</p>
<a href="http://arxiv.org/abs/2102.06229" target="_blank">arXiv:2102.06229</a> [<a href="http://arxiv.org/pdf/2102.06229" target="_blank">pdf</a>]

<h2>Optimization Issues in KL-Constrained Approximate Policy Iteration. (arXiv:2102.06234v1 [cs.LG])</h2>
<h3>Nevena Lazi&#x107;, Botao Hao, Yasin Abbasi-Yadkori, Dale Schuurmans, Csaba Szepesv&#xe1;ri</h3>
<p>Many reinforcement learning algorithms can be seen as versions of approximate
policy iteration (API). While standard API often performs poorly, it has been
shown that learning can be stabilized by regularizing each policy update by the
KL-divergence to the previous policy. Popular practical algorithms such as
TRPO, MPO, and VMPO replace regularization by a constraint on KL-divergence of
consecutive policies, arguing that this is easier to implement and tune. In
this work, we study this implementation choice in more detail. We compare the
use of KL divergence as a constraint vs. as a regularizer, and point out
several optimization issues with the widely-used constrained approach. We show
that the constrained algorithm is not guaranteed to converge even on simple
problem instances where the constrained problem can be solved exactly, and in
fact incurs linear expected regret. With approximate implementation using
softmax policies, we show that regularization can improve the optimization
landscape of the original objective. We demonstrate these issues empirically on
several bandit and RL environments.
</p>
<a href="http://arxiv.org/abs/2102.06234" target="_blank">arXiv:2102.06234</a> [<a href="http://arxiv.org/pdf/2102.06234" target="_blank">pdf</a>]

<h2>Robotic Tool Tracking under Partially Visible Kinematic Chain: A Unified Approach. (arXiv:2102.06235v1 [cs.RO])</h2>
<h3>Florian Richter, Jingpei Lu, Ryan K. Orosco, Michael C. Yip</h3>
<p>Anytime a robot manipulator is controlled via visual feedback, the
transformation between the robot and camera frame must be known. However, in
the case where cameras can only capture a portion of the robot manipulator in
order to better perceive the environment being interacted with, there is
greater sensitivity to errors in calibration of the base-to-camera transform. A
secondary source of uncertainty during robotic control are inaccuracies in
joint angle measurements which can be caused by biases in positioning and
complex transmission effects such as backlash and cable stretch. In this work,
we bring together these two sets of unknown parameters into a unified problem
formulation when the kinematic chain is partially visible in the camera view.
We prove that these parameters are non-identifiable implying that explicit
estimation of them is infeasible. To overcome this, we derive a smaller set of
parameters we call Lumped Error since it lumps together the errors of
calibration and joint angle measurements. A particle filter method is presented
and tested in simulation and on two real world robots to estimate the Lumped
Error and show the efficiency of this parameter reduction.
</p>
<a href="http://arxiv.org/abs/2102.06235" target="_blank">arXiv:2102.06235</a> [<a href="http://arxiv.org/pdf/2102.06235" target="_blank">pdf</a>]

<h2>Knowledge Infused Policy Gradients for Adaptive Pandemic Control. (arXiv:2102.06245v1 [cs.AI])</h2>
<h3>Kaushik Roy, Qi Zhang, Manas Gaur, Amit Sheth</h3>
<p>COVID-19 has impacted nations differently based on their policy
implementations. The effective policy requires taking into account public
information and adaptability to new knowledge. Epidemiological models built to
understand COVID-19 seldom provide the policymaker with the capability for
adaptive pandemic control (APC). Among the core challenges to be overcome
include (a) inability to handle a high degree of non-homogeneity in different
contributing features across the pandemic timeline, (b) lack of an approach
that enables adaptive incorporation of public health expert knowledge, and (c)
transparent models that enable understanding of the decision-making process in
suggesting policy. In this work, we take the early steps to address these
challenges using Knowledge Infused Policy Gradient (KIPG) methods. Prior work
on knowledge infusion does not handle soft and hard imposition of varying forms
of knowledge in disease information and guidelines to necessarily comply with.
Furthermore, the models do not attend to non-homogeneity in feature counts,
manifesting as partial observability in informing the policy. Additionally,
interpretable structures are extracted post-learning instead of learning an
interpretable model required for APC. To this end, we introduce a mathematical
framework for KIPG methods that can (a) induce relevant feature counts over
multi-relational features of the world, (b) handle latent non-homogeneous
counts as hidden variables that are linear combinations of kernelized
aggregates over the features, and (b) infuse knowledge as functional
constraints in a principled manner. The study establishes a theory for imposing
hard and soft constraints and simulates it through experiments. In comparison
with knowledge-intensive baselines, we show quick sample efficient adaptation
to new knowledge and interpretability in the learned policy, especially in a
pandemic context.
</p>
<a href="http://arxiv.org/abs/2102.06245" target="_blank">arXiv:2102.06245</a> [<a href="http://arxiv.org/pdf/2102.06245" target="_blank">pdf</a>]

<h2>Regret, stability, and fairness in matching markets with bandit learners. (arXiv:2102.06246v1 [cs.LG])</h2>
<h3>Sarah H. Cen, Devavrat Shah</h3>
<p>We consider the two-sided matching market with bandit learners. In the
standard matching problem, users and providers are matched to ensure incentive
compatibility via the notion of stability. However, contrary to the core
assumption of the matching problem, users and providers do not know their true
preferences a priori and must learn them. To address this assumption, recent
works propose to blend the matching and multi-armed bandit problems. They
establish that it is possible to assign matchings that are stable (i.e.,
incentive-compatible) at every time step while also allowing agents to learn
enough so that the system converges to matchings that are stable under the
agents' true preferences. However, while some agents may incur low regret under
these matchings, others can incur high regret -- specifically, $\Omega(T)$
optimal regret where $T$ is the time horizon. In this work, we incorporate
costs and transfers in the two-sided matching market with bandit learners in
order to faithfully model competition between agents. We prove that, under our
framework, it is possible to simultaneously guarantee four desiderata: (1)
incentive compatibility, i.e., stability, (2) low regret, i.e., $O(\log(T))$
optimal regret, (3) fairness in the distribution of regret among agents, and
(4) high social welfare.
</p>
<a href="http://arxiv.org/abs/2102.06246" target="_blank">arXiv:2102.06246</a> [<a href="http://arxiv.org/pdf/2102.06246" target="_blank">pdf</a>]

<h2>Sample-Optimal PAC Learning of Halfspaces with Malicious Noise. (arXiv:2102.06247v1 [cs.LG])</h2>
<h3>Jie Shen</h3>
<p>We study efficient PAC learning of homogeneous halfspaces in $\mathbb{R}^d$
in the presence of malicious noise of Valiant~(1985). This is a challenging
noise model and only until recently has near-optimal noise tolerance bound been
established under the mild condition that the unlabeled data distribution is
isotropic log-concave. However, it remains unsettled how to obtain the optimal
sample complexity simultaneously. In this work, we present a new analysis for
the algorithm of Awasthi et al.~(2017) and show that it essentially achieves
the near-optimal sample complexity bound of $\tilde{O}(d)$, improving the best
known result of $\tilde{O}(d^2)$. Our main ingredient is a novel incorporation
of a Matrix Chernoff-type inequality to bound the spectrum of an empirical
covariance matrix for well-behaved distributions, in conjunction with a careful
exploration of the localization schemes of Awasthi et al.~(2017). We further
extend the algorithm and analysis to the more general and stronger nasty noise
model of Bshouty~et~al. (2002), showing that it is still possible to achieve
near-optimal noise tolerance and sample complexity in polynomial time.
</p>
<a href="http://arxiv.org/abs/2102.06247" target="_blank">arXiv:2102.06247</a> [<a href="http://arxiv.org/pdf/2102.06247" target="_blank">pdf</a>]

<h2>Continuum: Simple Management of Complex Continual Learning Scenarios. (arXiv:2102.06253v1 [cs.LG])</h2>
<h3>Arthur Douillard, Timoth&#xe9;e Lesort</h3>
<p>Continual learning is a machine learning sub-field specialized in settings
with non-iid data. Hence, the training data distribution is not static and
drifts through time. Those drifts might cause interferences in the trained
model and knowledge learned on previous states of the data distribution might
be forgotten. Continual learning's challenge is to create algorithms able to
learn an ever-growing amount of knowledge while dealing with data distribution
drifts.

One implementation difficulty in these field is to create data loaders that
simulate non-iid scenarios. Indeed, data loaders are a key component for
continual algorithms. They should be carefully designed and reproducible. Small
errors in data loaders have a critical impact on algorithm results, e.g. with
bad preprocessing, wrong order of data or bad test set. Continuum is a simple
and efficient framework with numerous data loaders that avoid researcher to
spend time on designing data loader and eliminate time-consuming errors. Using
our proposed framework, it is possible to directly focus on the model design by
using the multiple scenarios and evaluation metrics implemented. Furthermore
the framework is easily extendable to add novel settings for specific needs.
</p>
<a href="http://arxiv.org/abs/2102.06253" target="_blank">arXiv:2102.06253</a> [<a href="http://arxiv.org/pdf/2102.06253" target="_blank">pdf</a>]

<h2>Towards DeepSentinel: An extensible corpus of labelled Sentinel-1 and -2 imagery and a general-purpose sensor-fusion semantic embedding model. (arXiv:2102.06260v1 [cs.CV])</h2>
<h3>Lucas Kruitwagen</h3>
<p>Earth observation offers new insight into anthropogenic changes to nature,
and how these changes are effecting (and are effected by) the built environment
and the real economy. With the global availability of medium-resolution
(10-30m) synthetic aperture radar (SAR) Sentinel-1 and multispectral Sentinel-2
imagery, machine learning can be employed to offer these insights at scale,
unbiased to the reporting of companies and countries. In this paper, I
introduce DeepSentinel, a data pipeline and experimentation framework for
producing general-purpose semantic embeddings of paired Sentinel-1 and
Sentinel-2 imagery. I document the development of an extensible corpus of
labelled and unlabelled imagery for the purposes of sensor fusion research.
With this new dataset I develop a set of experiments applying popular
self-supervision methods and encoder architectures to a land cover
classification problem. Tile2vec spatial encoding with a self-attention enabled
ResNet model outperforms deeper ResNet variants as well as pretraining with
variational autoencoding and contrastive loss. All supporting and derived data
and code are made publicly available.
</p>
<a href="http://arxiv.org/abs/2102.06260" target="_blank">arXiv:2102.06260</a> [<a href="http://arxiv.org/pdf/2102.06260" target="_blank">pdf</a>]

<h2>Speculative Path Planning. (arXiv:2102.06261v1 [cs.RO])</h2>
<h3>Mohammad Bakhshalipour, Mohamad Qadri, Dominic Guri</h3>
<p>Parallelization of A* path planning is mostly limited by the number of
possible motions, which is far less than the level of parallelism that modern
processors support. In this paper, we go beyond the limitations of traditional
parallelism of A* and propose Speculative Path Planning to accelerate the
search when there are abundant idle resources. The key idea of our approach is
predicting future state expansions relying on patterns among expansions and
aggressively parallelize the computations of prospective states (i.e.
pre-evaluate the expensive collision checking operation of prospective nodes).
This method allows us to maintain the same search order as of vanilla A* and
safeguard any optimality guarantees. We evaluate our method on various
configurations and show that on a machine with 32 physical cores, our method
improves the performance around 11x and 10x on average over counterpart
single-threaded and multi-threaded implementations respectively. The code to
our paper can be found here:
https://github.com/bakhshalipour/speculative-path-planning.
</p>
<a href="http://arxiv.org/abs/2102.06261" target="_blank">arXiv:2102.06261</a> [<a href="http://arxiv.org/pdf/2102.06261" target="_blank">pdf</a>]

<h2>Fair Robust Assignment using Redundancy. (arXiv:2102.06265v1 [cs.RO])</h2>
<h3>Matthew Malencia, Vijay Kumar, George Pappas, Amanda Prorok</h3>
<p>We study the consideration of fairness in redundant assignment for
multi-agent task allocation. It has recently been shown that redundant
assignment of agents to tasks provides robustness to uncertainty in task
performance. However, the question of how to fairly assign these redundant
resources across tasks remains unaddressed. In this paper, we present a novel
problem formulation for fair redundant task allocation, which we cast as the
optimization of worst-case task costs under a cardinality constraint. Solving
this problem optimally is NP-hard. Therefore, we exploit properties of
supermodularity to propose a polynomial-time, near-optimal solution. In
supermodular redundant assignment, the use of additional agents always improves
task costs. Therefore, we provide a solution set that is $\alpha$ times larger
than the cardinality constraint. This constraint relaxation enables our
approach to achieve a super-optimal cost by using a sub-optimal assignment
size.

We derive the sub-optimality bound on this cardinality relaxation, $\alpha$.
Additionally, we demonstrate that our algorithm performs near-optimally without
the cardinality relaxation. We show the algorithm in simulations of redundant
assignments of robots to goal nodes on transport networks with uncertain travel
times. Empirically, our algorithm outperforms benchmarks, scales to large
problems, and provides improvements in both fairness and average utility.
</p>
<a href="http://arxiv.org/abs/2102.06265" target="_blank">arXiv:2102.06265</a> [<a href="http://arxiv.org/pdf/2102.06265" target="_blank">pdf</a>]

<h2>Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge. (arXiv:2102.06271v1 [cs.LG])</h2>
<h3>Trent Kyono, Ioana Bica, Zhaozhi Qian, Mihaela van der Schaar</h3>
<p>Selecting causal inference models for estimating individualized treatment
effects (ITE) from observational data presents a unique challenge since the
counterfactual outcomes are never observed. The problem is challenged further
in the unsupervised domain adaptation (UDA) setting where we only have access
to labeled samples in the source domain, but desire selecting a model that
achieves good performance on a target domain for which only unlabeled samples
are available. Existing techniques for UDA model selection are designed for the
predictive setting. These methods examine discriminative density ratios between
the input covariates in the source and target domain and do not factor in the
model's predictions in the target domain. Because of this, two models with
identical performance on the source domain would receive the same risk score by
existing methods, but in reality, have significantly different performance in
the test domain. We leverage the invariance of causal structures across domains
to propose a novel model selection metric specifically designed for ITE methods
under the UDA setting. In particular, we propose selecting models whose
predictions of interventions' effects satisfy known causal structures in the
target domain. Experimentally, our method selects ITE models that are more
robust to covariate shifts on several healthcare datasets, including estimating
the effect of ventilation in COVID-19 patients from different geographic
locations.
</p>
<a href="http://arxiv.org/abs/2102.06271" target="_blank">arXiv:2102.06271</a> [<a href="http://arxiv.org/pdf/2102.06271" target="_blank">pdf</a>]

<h2>Hedging of Financial Derivative Contracts via Monte Carlo Tree Search. (arXiv:2102.06274v1 [cs.AI])</h2>
<h3>Oleg Szehr</h3>
<p>The construction of approximate replication strategies for derivative
contracts in incomplete markets is a key problem of financial engineering.
Recently Reinforcement Learning algorithms for pricing and hedging under
realistic market conditions have attracted significant interest. While
financial research mostly focused on variations of $Q$-learning, in Artificial
Intelligence Monte Carlo Tree Search is the recognized state-of-the-art method
for various planning problems, such as the games of Hex, Chess, Go,... This
article introduces Monte Carlo Tree Search for the hedging of financial
derivatives in realistic markets and shows that there are good reasons, both on
the theoretical and practical side, to favor it over other Reinforcement
Learning methods.
</p>
<a href="http://arxiv.org/abs/2102.06274" target="_blank">arXiv:2102.06274</a> [<a href="http://arxiv.org/pdf/2102.06274" target="_blank">pdf</a>]

<h2>On Agnostic PAC Learning using $\mathcal{L}_2$-polynomial Regression and Fourier-based Algorithms. (arXiv:2102.06277v1 [cs.LG])</h2>
<h3>Mohsen Heidari, Wojciech Szpankowski</h3>
<p>We develop a framework using Hilbert spaces as a proxy to analyze PAC
learning problems with structural properties. We consider a joint Hilbert space
incorporating the relation between the true label and the predictor under a
joint distribution $D$. We demonstrate that agnostic PAC learning with 0-1 loss
is equivalent to an optimization in the Hilbert space domain. With our model,
we revisit the PAC learning problem using methods based on least-squares such
as $\mathcal{L}_2$ polynomial regression and Linial's low-degree algorithm. We
study learning with respect to several hypothesis classes such as half-spaces
and polynomial-approximated classes (i.e., functions approximated by a
fixed-degree polynomial). We prove that (under some distributional assumptions)
such methods obtain generalization error up to $2opt$ with $opt$ being the
optimal error of the class. Hence, we show the tightest bound on generalization
error when $opt\leq 0.2$.
</p>
<a href="http://arxiv.org/abs/2102.06277" target="_blank">arXiv:2102.06277</a> [<a href="http://arxiv.org/pdf/2102.06277" target="_blank">pdf</a>]

<h2>Unsupervised Ground Metric Learning using Wasserstein Eigenvectors. (arXiv:2102.06278v1 [stat.ML])</h2>
<h3>Geert-Jan Huizing, Laura Cantini, Gabriel Peyr&#xe9;</h3>
<p>Optimal Transport (OT) defines geometrically meaningful "Wasserstein"
distances, used in machine learning applications to compare probability
distributions. However, a key bottleneck is the design of a "ground" cost which
should be adapted to the task under study. In most cases, supervised metric
learning is not accessible, and one usually resorts to some ad-hoc approach.
Unsupervised metric learning is thus a fundamental problem to enable
data-driven applications of Optimal Transport. In this paper, we propose for
the first time a canonical answer by computing the ground cost as a positive
eigenvector of the function mapping a cost to the pairwise OT distances between
the inputs. This map is homogeneous and monotone, thus framing unsupervised
metric learning as a non-linear Perron-Frobenius problem. We provide criteria
to ensure the existence and uniqueness of this eigenvector. In addition, we
introduce a scalable computational method using entropic regularization, which
- in the large regularization limit - operates a principal component analysis
dimensionality reduction. We showcase this method on synthetic examples and
datasets. Finally, we apply it in the context of biology to the analysis of a
high-throughput single-cell RNA sequencing (scRNAseq) dataset, to improve cell
clustering and infer the relationships between genes in an unsupervised way.
</p>
<a href="http://arxiv.org/abs/2102.06278" target="_blank">arXiv:2102.06278</a> [<a href="http://arxiv.org/pdf/2102.06278" target="_blank">pdf</a>]

<h2>kPAM 2.0: Feedback Control for Category-Level Robotic Manipulation. (arXiv:2102.06279v1 [cs.RO])</h2>
<h3>Wei Gao, Russ Tedrake</h3>
<p>In this paper, we explore generalizable, perception-to-action robotic
manipulation for precise, contact-rich tasks. In particular, we contribute a
framework for closed-loop robotic manipulation that automatically handles a
category of objects, despite potentially unseen object instances and
significant intra-category variations in shape, size and appearance. Previous
approaches typically build a feedback loop on top of a real-time 6-DOF pose
estimator. However, representing an object with a parameterized transformation
from a fixed geometric template does not capture large intra-category shape
variation. Hence we adopt the keypoint-based object representation proposed in
kPAM for category-level pick-and-place, and extend it to closed-loop
manipulation policies with contact-rich tasks. We first augment keypoints with
local orientation information. Using the oriented keypoints, we propose a novel
object-centric action representation in terms of regulating the linear/angular
velocity or force/torque of these oriented keypoints. This formulation is
surprisingly versatile -- we demonstrate that it can accomplish contact-rich
manipulation tasks that require precision and dexterity for a category of
objects with different shapes, sizes and appearances, such as peg-hole
insertion for pegs and holes with significant shape variation and tight
clearance. With the proposed object and action representation, our framework is
also agnostic to the robot grasp pose and initial object configuration, making
it flexible for integration and deployment.
</p>
<a href="http://arxiv.org/abs/2102.06279" target="_blank">arXiv:2102.06279</a> [<a href="http://arxiv.org/pdf/2102.06279" target="_blank">pdf</a>]

<h2>Straggler-Resilient Distributed Machine Learning with Dynamic Backup Workers. (arXiv:2102.06280v1 [cs.LG])</h2>
<h3>Guojun Xiong, Gang Yan, Rahul Singh, Jian Li</h3>
<p>With the increasing demand for large-scale training of machine learning
models, consensus-based distributed optimization methods have recently been
advocated as alternatives to the popular parameter server framework. In this
paradigm, each worker maintains a local estimate of the optimal parameter
vector, and iteratively updates it by waiting and averaging all estimates
obtained from its neighbors, and then corrects it on the basis of its local
dataset. However, the synchronization phase can be time consuming due to the
need to wait for \textit{stragglers}, i.e., slower workers. An efficient way to
mitigate this effect is to let each worker wait only for updates from the
fastest neighbors before updating its local parameter. The remaining neighbors
are called \textit{backup workers.} To minimize the globally training time over
the network, we propose a fully distributed algorithm to dynamically determine
the number of backup workers for each worker. We show that our algorithm
achieves a linear speedup for convergence (i.e., convergence performance
increases linearly with respect to the number of workers). We conduct extensive
experiments on MNIST and CIFAR-10 to verify our theoretical results.
</p>
<a href="http://arxiv.org/abs/2102.06280" target="_blank">arXiv:2102.06280</a> [<a href="http://arxiv.org/pdf/2102.06280" target="_blank">pdf</a>]

<h2>Large Scale Distributed Collaborative Unlabeled Motion Planning with Graph Policy Gradients. (arXiv:2102.06284v1 [cs.RO])</h2>
<h3>Arbaaz Khan, Vijay Kumar, Alejandro Ribeiro</h3>
<p>In this paper, we present a learning method to solve the unlabelled motion
problem with motion constraints and space constraints in 2D space for a large
number of robots. To solve the problem of arbitrary dynamics and constraints we
propose formulating the problem as a multi-agent problem. We are able to
demonstrate the scalability of our methods for a large number of robots by
employing a graph neural network (GNN) to parameterize policies for the robots.
The GNN reduces the dimensionality of the problem by learning filters that
aggregate information among robots locally, similar to how a convolutional
neural network is able to learn local features in an image. Additionally, by
employing a GNN we are also able to overcome the computational overhead of
training policies for a large number of robots by first training graph filters
for a small number of robots followed by zero-shot policy transfer to a larger
number of robots. We demonstrate the effectiveness of our framework through
various simulations.
</p>
<a href="http://arxiv.org/abs/2102.06284" target="_blank">arXiv:2102.06284</a> [<a href="http://arxiv.org/pdf/2102.06284" target="_blank">pdf</a>]

<h2>K-Hairstyle: A Large-scale Korean hairstyle dataset for virtual hair editing and hairstyle classification. (arXiv:2102.06288v1 [cs.CV])</h2>
<h3>Taewoo Kim, Chaeyeon Chung, Sunghyun Park, Gyojung Gu, Keonmin Nam, Wonzo Choe, Jaesung Lee, Jaegul Choo</h3>
<p>The hair and beauty industry is one of the fastest growing industries. This
led to the development of various applications, such as virtual hair dyeing or
hairstyle translations, to satisfy the need of the customers. Although there
are several public hair datasets available for these applications, they consist
of limited number of images with low resolution, which restrict their
performance on high-quality hair editing. Therefore, we introduce a novel
large-scale Korean hairstyle dataset, K-hairstyle, 256,679 with high-resolution
images. In addition, K-hairstyle contains various hair attributes annotated by
Korean expert hair stylists and hair segmentation masks. We validate the
effectiveness of our dataset by leveraging several applications, such as
hairstyle translation, and hair classification and hair retrieval. Furthermore,
we will release K-hairstyle soon.
</p>
<a href="http://arxiv.org/abs/2102.06288" target="_blank">arXiv:2102.06288</a> [<a href="http://arxiv.org/pdf/2102.06288" target="_blank">pdf</a>]

<h2>When and How Mixup Improves Calibration. (arXiv:2102.06289v1 [cs.LG])</h2>
<h3>Linjun Zhang, Zhun Deng, Kenji Kawaguchi, James Zou</h3>
<p>In many machine learning applications, it is important for the model to
provide confidence scores that accurately captures its prediction uncertainty.
Although modern learning methods have achieved great success in predictive
accuracy, generating calibrated confidence scores remains a major challenge.
Mixup, a popular yet simple data augmentation technique based on taking convex
combinations of pairs of training examples, has been empirically found to
significantly improve confidence calibration across diverse applications.
However, when and how Mixup helps calibration is still mysterious. In this
paper, we theoretically prove that Mixup improves calibration in
\textit{high-dimensional} settings by investigating two natural data models on
classification and regression. Interestingly, the calibration benefit of Mixup
increases as the model capacity increases. We support our theories with
experiments on common architectures and data sets. In addition, we study how
Mixup improves calibration in semi-supervised learning. While incorporating
unlabeled data can sometimes make the model less calibrated, adding Mixup
training mitigates this issue and provably improves calibration. Our analysis
provides new insights and a framework to understand Mixup and calibration.
</p>
<a href="http://arxiv.org/abs/2102.06289" target="_blank">arXiv:2102.06289</a> [<a href="http://arxiv.org/pdf/2102.06289" target="_blank">pdf</a>]

<h2>No-Regret Algorithms for Time-Varying Bayesian Optimization. (arXiv:2102.06296v1 [cs.LG])</h2>
<h3>Xingyu Zhou, Ness Shroff</h3>
<p>In this paper, we consider the time-varying Bayesian optimization problem.
The unknown function at each time is assumed to lie in an RKHS (reproducing
kernel Hilbert space) with a bounded norm. We adopt the general variation
budget model to capture the time-varying environment, and the variation is
characterized by the change of the RKHS norm. We adapt the restart and sliding
window mechanism to introduce two GP-UCB type algorithms: R-GP-UCB and
SW-GP-UCB, respectively. We derive the first (frequentist) regret guarantee on
the dynamic regret for both algorithms. Our results not only recover previous
linear bandit results when a linear kernel is used, but complement the previous
regret analysis of time-varying Gaussian process bandit under a Bayesian-type
regularity assumption, i.e., each function is a sample from a Gaussian process.
</p>
<a href="http://arxiv.org/abs/2102.06296" target="_blank">arXiv:2102.06296</a> [<a href="http://arxiv.org/pdf/2102.06296" target="_blank">pdf</a>]

<h2>What does LIME really see in images?. (arXiv:2102.06307v1 [cs.LG])</h2>
<h3>Damien Garreau, Dina Mardaoui</h3>
<p>The performance of modern algorithms on certain computer vision tasks such as
object recognition is now close to that of humans. This success was achieved at
the price of complicated architectures depending on millions of parameters and
it has become quite challenging to understand how particular predictions are
made. Interpretability methods propose to give us this understanding. In this
paper, we study LIME, perhaps one of the most popular. On the theoretical side,
we show that when the number of generated examples is large, LIME explanations
are concentrated around a limit explanation for which we give an explicit
expression. We further this study for elementary shape detectors and linear
models. As a consequence of this analysis, we uncover a connection between LIME
and integrated gradients, another explanation method. More precisely, the LIME
explanations are similar to the sum of integrated gradients over the
superpixels used in the preprocessing step of LIME.
</p>
<a href="http://arxiv.org/abs/2102.06307" target="_blank">arXiv:2102.06307</a> [<a href="http://arxiv.org/pdf/2102.06307" target="_blank">pdf</a>]

<h2>ReRankMatch: Semi-Supervised Learning with Semantics-Oriented Similarity Representation. (arXiv:2102.06328v1 [cs.CV])</h2>
<h3>Trung Quang Tran, Mingu Kang, Daeyoung Kim</h3>
<p>This paper proposes integrating semantics-oriented similarity representation
into RankingMatch, a recently proposed semi-supervised learning method. Our
method, dubbed ReRankMatch, aims to deal with the case in which labeled and
unlabeled data share non-overlapping categories. ReRankMatch encourages the
model to produce the similar image representations for the samples likely
belonging to the same class. We evaluate our method on various datasets such as
CIFAR-10, CIFAR-100, SVHN, STL-10, and Tiny ImageNet. We obtain promising
results (4.21% error rate on CIFAR-10 with 4000 labels, 22.32% error rate on
CIFAR-100 with 10000 labels, and 2.19% error rate on SVHN with 1000 labels)
when the amount of labeled data is sufficient to learn semantics-oriented
similarity representation.
</p>
<a href="http://arxiv.org/abs/2102.06328" target="_blank">arXiv:2102.06328</a> [<a href="http://arxiv.org/pdf/2102.06328" target="_blank">pdf</a>]

<h2>Stragglers Are Not Disaster: A Hybrid Federated Learning Algorithm with Delayed Gradients. (arXiv:2102.06329v1 [cs.LG])</h2>
<h3>Xingyu Li, Zhe Qu, Bo Tang, Zhuo Lu</h3>
<p>Federated learning (FL) is a new machine learning framework which trains a
joint model across a large amount of decentralized computing devices. Existing
methods, e.g., Federated Averaging (FedAvg), are able to provide an
optimization guarantee by synchronously training the joint model, but usually
suffer from stragglers, i.e., IoT devices with low computing power or
communication bandwidth, especially on heterogeneous optimization problems. To
mitigate the influence of stragglers, this paper presents a novel FL algorithm,
namely Hybrid Federated Learning (HFL), to achieve a learning balance in
efficiency and effectiveness. It consists of two major components: synchronous
kernel and asynchronous updater. Unlike traditional synchronous FL methods, our
HFL introduces the asynchronous updater which actively pulls unsynchronized and
delayed local weights from stragglers. An adaptive approximation method,
Adaptive Delayed-SGD (AD-SGD), is proposed to merge the delayed local updates
into the joint model. The theoretical analysis of HFL shows that the
convergence rate of the proposed algorithm is $\mathcal{O}(\frac{1}{t+\tau})$
for both convex and non-convex optimization problems.
</p>
<a href="http://arxiv.org/abs/2102.06329" target="_blank">arXiv:2102.06329</a> [<a href="http://arxiv.org/pdf/2102.06329" target="_blank">pdf</a>]

<h2>Efficient Algorithms for Federated Saddle Point Optimization. (arXiv:2102.06333v1 [cs.LG])</h2>
<h3>Charlie Hou, Kiran K. Thekumparampil, Giulia Fanti, Sewoong Oh</h3>
<p>We consider strongly convex-concave minimax problems in the federated
setting, where the communication constraint is the main bottleneck. When
clients are arbitrarily heterogeneous, a simple Minibatch Mirror-prox achieves
the best performance. As the clients become more homogeneous, using multiple
local gradient updates at the clients significantly improves upon Minibatch
Mirror-prox by communicating less frequently. Our goal is to design an
algorithm that can harness the benefit of similarity in the clients while
recovering the Minibatch Mirror-prox performance under arbitrary heterogeneity
(up to log factors). We give the first federated minimax optimization algorithm
that achieves this goal. The main idea is to combine (i) SCAFFOLD (an algorithm
that performs variance reduction across clients for convex optimization) to
erase the worst-case dependency on heterogeneity and (ii) Catalyst (a framework
for acceleration based on modifying the objective) to accelerate convergence
without amplifying client drift. We prove that this algorithm achieves our
goal, and include experiments to validate the theory.
</p>
<a href="http://arxiv.org/abs/2102.06333" target="_blank">arXiv:2102.06333</a> [<a href="http://arxiv.org/pdf/2102.06333" target="_blank">pdf</a>]

<h2>Dancing along Battery: Enabling Transformer with Run-time Reconfigurability on Mobile Devices. (arXiv:2102.06336v1 [cs.LG])</h2>
<h3>Yuhong Song, Weiwen Jiang, Bingbing Li, Panjie Qi, Qingfeng Zhuge, Edwin Hsing-Mean Sha, Sakyasingha Dasgupta, Yiyu Shi, Caiwen Ding</h3>
<p>A pruning-based AutoML framework for run-time reconfigurability, namely RT3,
is proposed in this work. This enables Transformer-based large Natural Language
Processing (NLP) models to be efficiently executed on resource-constrained
mobile devices and reconfigured (i.e., switching models for dynamic hardware
conditions) at run-time. Such reconfigurability is the key to save energy for
battery-powered mobile devices, which widely use dynamic voltage and frequency
scaling (DVFS) technique for hardware reconfiguration to prolong battery life.
In this work, we creatively explore a hybrid block-structured pruning (BP) and
pattern pruning (PP) for Transformer-based models and first attempt to combine
hardware and software reconfiguration to maximally save energy for
battery-powered mobile devices. Specifically, RT3 integrates two-level
optimizations: First, it utilizes an efficient BP as the first-step compression
for resource-constrained mobile devices; then, RT3 heuristically generates a
shrunken search space based on the first level optimization and searches
multiple pattern sets with diverse sparsity for PP via reinforcement learning
to support lightweight software reconfiguration, which corresponds to available
frequency levels of DVFS (i.e., hardware reconfiguration). At run-time, RT3 can
switch the lightweight pattern sets within 45ms to guarantee the required
real-time constraint at different frequency levels. Results further show that
RT3 can prolong battery life over 4x improvement with less than 1% accuracy
loss for Transformer and 1.5% score decrease for DistilBERT.
</p>
<a href="http://arxiv.org/abs/2102.06336" target="_blank">arXiv:2102.06336</a> [<a href="http://arxiv.org/pdf/2102.06336" target="_blank">pdf</a>]

<h2>Physics-Informed Graphical Neural Network for Parameter & State Estimations in Power Systems. (arXiv:2102.06349v1 [cs.LG])</h2>
<h3>Laurent Pagnier, Michael Chertkov</h3>
<p>Parameter Estimation (PE) and State Estimation (SE) are the most wide-spread
tasks in the system engineering. They need to be done automatically, fast and
frequently, as measurements arrive. Deep Learning (DL) holds the promise of
tackling the challenge, however in so far, as PE and SE in power systems is
concerned, (a) DL did not win trust of the system operators because of the lack
of the physics of electricity based, interpretations and (b) DL remained
illusive in the operational regimes were data is scarce. To address this, we
present a hybrid scheme which embeds physics modeling of power systems into
Graphical Neural Networks (GNN), therefore empowering system operators with a
reliable and explainable real-time predictions which can then be used to
control the critical infrastructure. To enable progress towards trustworthy DL
for PE and SE, we build a physics-informed method, named Power-GNN, which
reconstructs physical, thus interpretable, parameters within Effective Power
Flow (EPF) models, such as admittances of effective power lines, and NN
parameters, representing implicitly unobserved elements of the system. In our
experiments, we test the Power-GNN on different realistic power networks,
including these with thousands of loads and hundreds of generators. We show
that the Power-GNN outperforms vanilla NN scheme unaware of the EPF physics.
</p>
<a href="http://arxiv.org/abs/2102.06349" target="_blank">arXiv:2102.06349</a> [<a href="http://arxiv.org/pdf/2102.06349" target="_blank">pdf</a>]

<h2>Projected Wasserstein gradient descent for high-dimensional Bayesian inference. (arXiv:2102.06350v1 [cs.LG])</h2>
<h3>Yifei Wang, Wuchen Li, Peng Chen</h3>
<p>We propose a projected Wasserstein gradient descent method (pWGD) for
high-dimensional Bayesian inference problems. The underlying density function
of a particle system of WGD is approximated by kernel density estimation (KDE),
which faces the long-standing curse of dimensionality. We overcome this
challenge by exploiting the intrinsic low-rank structure in the difference
between the posterior and prior distributions. The parameters are projected
into a low-dimensional subspace to alleviate the approximation error of KDE in
high dimensions. We formulate a projected Wasserstein gradient flow and analyze
its convergence property under mild assumptions. Several numerical experiments
illustrate the accuracy, convergence, and complexity scalability of pWGD with
respect to parameter dimension, sample size, and processor cores.
</p>
<a href="http://arxiv.org/abs/2102.06350" target="_blank">arXiv:2102.06350</a> [<a href="http://arxiv.org/pdf/2102.06350" target="_blank">pdf</a>]

<h2>A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes. (arXiv:2102.06356v1 [cs.LG])</h2>
<h3>Zachary Nado, Justin M. Gilmer, Christopher J. Shallue, Rohan Anil, George E. Dahl</h3>
<p>Recently the LARS and LAMB optimizers have been proposed for training neural
networks faster using large batch sizes. LARS and LAMB add layer-wise
normalization to the update rules of Heavy-ball momentum and Adam,
respectively, and have become popular in prominent benchmarks and deep learning
libraries. However, without fair comparisons to standard optimizers, it remains
an open question whether LARS and LAMB have any benefit over traditional,
generic algorithms. In this work we demonstrate that standard optimization
algorithms such as Nesterov momentum and Adam can match or exceed the results
of LARS and LAMB at large batch sizes. Our results establish new, stronger
baselines for future comparisons at these batch sizes and shed light on the
difficulties of comparing optimizers for neural network training more
generally.
</p>
<a href="http://arxiv.org/abs/2102.06356" target="_blank">arXiv:2102.06356</a> [<a href="http://arxiv.org/pdf/2102.06356" target="_blank">pdf</a>]

<h2>SCOUT: Socially-COnsistent and UndersTandable Graph Attention Network for Trajectory Prediction of Vehicles and VRUs. (arXiv:2102.06361v1 [cs.LG])</h2>
<h3>Sandra Carrasco, David Fern&#xe1;ndez Llorca, Miguel &#xc1;ngel Sotelo</h3>
<p>Autonomous vehicles navigate in dynamically changing environments under a
wide variety of conditions, being continuously influenced by surrounding
objects. Modelling interactions among agents is essential for accurately
forecasting other agents' behaviour and achieving safe and comfortable motion
planning. In this work, we propose SCOUT, a novel Attention-based Graph Neural
Network that uses a flexible and generic representation of the scene as a graph
for modelling interactions, and predicts socially-consistent trajectories of
vehicles and Vulnerable Road Users (VRUs) under mixed traffic conditions. We
explore three different attention mechanisms and test our scheme with both
bird-eye-view and on-vehicle urban data, achieving superior performance than
existing state-of-the-art approaches on InD and ApolloScape Trajectory
benchmarks. Additionally, we evaluate our model's flexibility and
transferability by testing it under completely new scenarios on RounD dataset.
The importance and influence of each interaction in the final prediction is
explored by means of Integrated Gradients technique and the visualization of
the attention learned.
</p>
<a href="http://arxiv.org/abs/2102.06361" target="_blank">arXiv:2102.06361</a> [<a href="http://arxiv.org/pdf/2102.06361" target="_blank">pdf</a>]

<h2>Dynamic Precision Analog Computing for Neural Networks. (arXiv:2102.06365v1 [cs.LG])</h2>
<h3>Sahaj Garg, Joe Lou, Anirudh Jain, Mitchell Nahmias</h3>
<p>Analog electronic and optical computing exhibit tremendous advantages over
digital computing for accelerating deep learning when operations are executed
at low precision. In this work, we derive a relationship between analog
precision, which is limited by noise, and digital bit precision. We propose
extending analog computing architectures to support varying levels of precision
by repeating operations and averaging the result, decreasing the impact of
noise. Such architectures enable programmable tradeoffs between precision and
other desirable performance metrics such as energy efficiency or throughput. To
utilize dynamic precision, we propose a method for learning the precision of
each layer of a pre-trained model without retraining network weights. We
evaluate this method on analog architectures subject to a variety of noise
sources such as shot noise, thermal noise, and weight noise and find that
employing dynamic precision reduces energy consumption by up to 89% for
computer vision models such as Resnet50 and by 24% for natural language
processing models such as BERT. In one example, we apply dynamic precision to a
shot-noise limited homodyne optical neural network and simulate inference at an
optical energy consumption of 2.7 aJ/MAC for Resnet50 and 1.6 aJ/MAC for BERT
with &lt;2% accuracy degradation.
</p>
<a href="http://arxiv.org/abs/2102.06365" target="_blank">arXiv:2102.06365</a> [<a href="http://arxiv.org/pdf/2102.06365" target="_blank">pdf</a>]

<h2>Confounding Tradeoffs for Neural Network Quantization. (arXiv:2102.06366v1 [cs.LG])</h2>
<h3>Sahaj Garg, Anirudh Jain, Joe Lou, Mitchell Nahmias</h3>
<p>Many neural network quantization techniques have been developed to decrease
the computational and memory footprint of deep learning. However, these methods
are evaluated subject to confounding tradeoffs that may affect inference
acceleration or resource complexity in exchange for higher accuracy. In this
work, we articulate a variety of tradeoffs whose impact is often overlooked and
empirically analyze their impact on uniform and mixed-precision post-training
quantization, finding that these confounding tradeoffs may have a larger impact
on quantized network accuracy than the actual quantization methods themselves.
Because these tradeoffs constrain the attainable hardware acceleration for
different use-cases, we encourage researchers to explicitly report these design
choices through the structure of "quantization cards." We expect quantization
cards to help researchers compare methods more effectively and engineers
determine the applicability of quantization techniques for their hardware.
</p>
<a href="http://arxiv.org/abs/2102.06366" target="_blank">arXiv:2102.06366</a> [<a href="http://arxiv.org/pdf/2102.06366" target="_blank">pdf</a>]

<h2>Multiplex Bipartite Network Embedding using Dual Hypergraph Convolutional Networks. (arXiv:2102.06371v1 [cs.LG])</h2>
<h3>Hansheng Xue, Luwei Yang, Vaibhav Rajan, Wen Jiang, Yi Wei, Yu Lin</h3>
<p>A bipartite network is a graph structure where nodes are from two distinct
domains and only inter-domain interactions exist as edges. A large number of
network embedding methods exist to learn vectorial node representations from
general graphs with both homogeneous and heterogeneous node and edge types,
including some that can specifically model the distinct properties of bipartite
networks. However, these methods are inadequate to model multiplex bipartite
networks (e.g., in e-commerce), that have multiple types of interactions (e.g.,
click, inquiry, and buy) and node attributes. Most real-world multiplex
bipartite networks are also sparse and have imbalanced node distributions that
are challenging to model. In this paper, we develop an unsupervised Dual
HyperGraph Convolutional Network (DualHGCN) model that scalably transforms the
multiplex bipartite network into two sets of homogeneous hypergraphs and uses
spectral hypergraph convolutional operators, along with intra- and
inter-message passing strategies to promote information exchange within and
across domains, to learn effective node embedding. We benchmark DualHGCN using
four real-world datasets on link prediction and node classification tasks. Our
extensive experiments demonstrate that DualHGCN significantly outperforms
state-of-the-art methods, and is robust to varying sparsity levels and
imbalanced node distributions.
</p>
<a href="http://arxiv.org/abs/2102.06371" target="_blank">arXiv:2102.06371</a> [<a href="http://arxiv.org/pdf/2102.06371" target="_blank">pdf</a>]

<h2>The Symmetry between Bandits and Knapsacks: A Primal-Dual LP-based Approach. (arXiv:2102.06385v1 [cs.LG])</h2>
<h3>Xiaocheng Li, Chunlin Sun, Yinyu Ye</h3>
<p>In this paper, we study the bandits with knapsacks (BwK) problem and develop
a primal-dual based algorithm that achieves a problem-dependent logarithmic
regret bound. The BwK problem extends the multi-arm bandit (MAB) problem to
model the resource consumption associated with playing each arm, and the
existing BwK literature has been mainly focused on deriving asymptotically
optimal distribution-free regret bounds. We first study the primal and dual
linear programs underlying the BwK problem. From this primal-dual perspective,
we discover symmetry between arms and knapsacks, and then propose a new notion
of sub-optimality measure for the BwK problem. The sub-optimality measure
highlights the important role of knapsacks in determining algorithm regret and
inspires the design of our two-phase algorithm. In the first phase, the
algorithm identifies the optimal arms and the binding knapsacks, and in the
second phase, it exhausts the binding knapsacks via playing the optimal arms
through an adaptive procedure. Our regret upper bound involves the proposed
sub-optimality measure and it has a logarithmic dependence on length of horizon
$T$ and a polynomial dependence on $m$ (the numbers of arms) and $d$ (the
number of knapsacks). To the best of our knowledge, this is the first
problem-dependent logarithmic regret bound for solving the general BwK problem.
</p>
<a href="http://arxiv.org/abs/2102.06385" target="_blank">arXiv:2102.06385</a> [<a href="http://arxiv.org/pdf/2102.06385" target="_blank">pdf</a>]

<h2>Multi-source Pseudo-label Learning of Semantic Segmentation for the Scene Recognition of Agricultural Mobile Robots. (arXiv:2102.06386v1 [cs.CV])</h2>
<h3>Shigemichi Matsuzaki, Jun Miura, Hiroaki Masuzawa</h3>
<p>This paper describes a novel method of training a semantic segmentation model
for environment recognition of agricultural mobile robots by unsupervised
domain adaptation exploiting publicly available datasets of outdoor scenes that
are different from our target environments i.e., greenhouses. In conventional
semantic segmentation methods, the labels are given by manual annotation, which
is a tedious and time-consuming task. A method to work around the necessity of
the manual annotation is unsupervised domain adaptation (UDA) that transfer
knowledge from labeled source datasets to unlabeled target datasets. Most of
the UDA methods of semantic segmentation are validated by tasks of adaptation
from non-photorealistic synthetic images of urban scenes to real ones. However,
the effectiveness of the methods is not well studied in the case of adaptation
to other types of environments, such as greenhouses. In addition, it is not
always possible to prepare appropriate source datasets for such environments.
In this paper, we adopt an existing training method of UDA to a task of
training a model for greenhouse images. We propose to use multiple publicly
available datasets of outdoor images as source datasets, and also propose a
simple yet effective method of generating pseudo-labels by transferring
knowledge from the source datasets that have different appearance and a label
set from the target datasets. We demonstrate in experiments that by combining
our proposed method of pseudo-label generation with the existing training
method, the performance was improved by up to 14.3% of mIoU compared to the
best score of the single-source training.
</p>
<a href="http://arxiv.org/abs/2102.06386" target="_blank">arXiv:2102.06386</a> [<a href="http://arxiv.org/pdf/2102.06386" target="_blank">pdf</a>]

<h2>The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation. (arXiv:2102.06387v1 [cs.LG])</h2>
<h3>Peter Kairouz, Ziyu Liu, Thomas Steinke</h3>
<p>We consider training models on private data that is distributed across user
devices. To ensure privacy, we add on-device noise and use secure aggregation
so that only the noisy sum is revealed to the server. We present a
comprehensive end-to-end system, which appropriately discretizes the data and
adds discrete Gaussian noise before performing secure aggregation. We provide a
novel privacy analysis for sums of discrete Gaussians. We also analyze the
effect of rounding the input data and the modular summation arithmetic. Our
theoretical guarantees highlight the complex tension between communication,
privacy, and accuracy. Our extensive experimental results demonstrate that our
solution is essentially able to achieve a comparable accuracy to central
differential privacy with 16 bits of precision per value.
</p>
<a href="http://arxiv.org/abs/2102.06387" target="_blank">arXiv:2102.06387</a> [<a href="http://arxiv.org/pdf/2102.06387" target="_blank">pdf</a>]

<h2>A Too-Good-to-be-True Prior to Reduce Shortcut Reliance. (arXiv:2102.06406v1 [cs.CV])</h2>
<h3>Nikolay Dagaev, Brett D. Roads, Xiaoliang Luo, Daniel N. Barry, Kaustubh R. Patil, Bradley C. Love</h3>
<p>Despite their impressive performance in object recognition and other tasks
under standard testing conditions, deep convolutional neural networks (DCNNs)
often fail to generalize to out-of-distribution (o.o.d.) samples. One cause for
this shortcoming is that modern architectures tend to rely on "shortcuts" -
superficial features that correlate with categories without capturing deeper
invariants that hold across contexts. Real-world concepts often possess a
complex structure that can vary superficially across contexts, which can make
the most intuitive and promising solutions in one context not generalize to
others. One potential way to improve o.o.d. generalization is to assume simple
solutions are unlikely to be valid across contexts and downweight them, which
we refer to as the too-good-to-be-true prior. We implement this inductive bias
in a two-stage approach that uses predictions from a low-capacity network (LCN)
to inform the training of a high-capacity network (HCN). Since the shallow
architecture of the LCN can only learn surface relationships, which includes
shortcuts, we downweight training items for the HCN that the LCN can master,
thereby encouraging the HCN to rely on deeper invariant features that should
generalize broadly. Using a modified version of the CIFAR-10 dataset in which
we introduced shortcuts, we found that the two-stage LCN-HCN approach reduced
reliance on shortcuts and facilitated o.o.d. generalization.
</p>
<a href="http://arxiv.org/abs/2102.06406" target="_blank">arXiv:2102.06406</a> [<a href="http://arxiv.org/pdf/2102.06406" target="_blank">pdf</a>]

<h2>Densely Deformable Efficient Salient Object Detection Network. (arXiv:2102.06407v1 [cs.CV])</h2>
<h3>Tanveer Hussain, Saeed Anwar, Amin Ullah, Khan Muhammad, Sung Wook Baik</h3>
<p>Salient Object Detection (SOD) domain using RGB-D data has lately emerged
with some current models' adequately precise results. However, they have
restrained generalization abilities and intensive computational complexity. In
this paper, inspired by the best background/foreground separation abilities of
deformable convolutions, we employ them in our Densely Deformable Network
(DDNet) to achieve efficient SOD. The salient regions from densely deformable
convolutions are further refined using transposed convolutions to optimally
generate the saliency maps. Quantitative and qualitative evaluations using the
recent SOD dataset against 22 competing techniques show our method's efficiency
and effectiveness. We also offer evaluation using our own created
cross-dataset, surveillance-SOD (S-SOD), to check the trained models' validity
in terms of their applicability in diverse scenarios. The results indicate that
the current models have limited generalization potentials, demanding further
research in this direction. Our code and new dataset will be publicly available
at https://github.com/tanveer-hussain/EfficientSOD
</p>
<a href="http://arxiv.org/abs/2102.06407" target="_blank">arXiv:2102.06407</a> [<a href="http://arxiv.org/pdf/2102.06407" target="_blank">pdf</a>]

<h2>Supervised training of spiking neural networks for robust deployment on mixed-signal neuromorphic processors. (arXiv:2102.06408v1 [cs.LG])</h2>
<h3>Julian B&#xfc;chel, Dmitrii Zendrikov, Sergio Solinas, Giacomo Indiveri, Dylan R. Muir</h3>
<p>Mixed-signal analog/digital electronic circuits can emulate spiking neurons
and synapses with extremely high energy efficiency, following an approach known
as "neuromorphic engineering". However, analog circuits are sensitive to
variation in fabrication among transistors in a chip ("device mismatch"). In
the case of neuromorphic implementation of Spiking Neural Networks (SNNs),
mismatch is expressed as differences in effective parameters between
identically-configured neurons and synapses. Each fabricated chip therefore
provides a different distribution of parameters such as time constants or
synaptic weights. Without the expensive overhead in terms of area and power of
extra on-chip learning or calibration circuits, device mismatch and other noise
sources represent a critical challenge for the deployment of pre-trained neural
network chips. Here we present a supervised learning approach that addresses
this challenge by maximizing robustness to mismatch and other common sources of
noise.

The proposed method trains (SNNs) to perform temporal classification tasks by
mimicking a pre-trained dynamical system, using a local learning rule adapted
from non-linear control theory. We demonstrate the functionality of our model
on two tasks that require memory to perform successfully, and measure the
robustness of our approach to several forms of noise and variability present in
the network. We show that our approach is more robust than several common
alternative approaches for training SNNs.

Our method provides a viable way to robustly deploy pre-trained networks on
mixed-signal neuromorphic hardware, without requiring per-device training or
calibration.
</p>
<a href="http://arxiv.org/abs/2102.06408" target="_blank">arXiv:2102.06408</a> [<a href="http://arxiv.org/pdf/2102.06408" target="_blank">pdf</a>]

<h2>Fast Fault Detection on a Quadrotor using Onboard Sensors and a Kalman Filter Approach. (arXiv:2102.06439v1 [cs.RO])</h2>
<h3>Bram Strack van Schijndel, Sihao Sun, Coen de Visser</h3>
<p>This paper presents a novel method for fast and robust detection of actuator
failures on quadrotors. The proposed algorithm has very little model
dependency. A Kalman filter estimator estimates a stochastic effectiveness
factor for every actuator, using only onboard RPM, gyro and accelerometer
measurements. Then, a hypothesis test identifies the failed actuator. This
algorithm is validated online in real-time, also as part of an active fault
tolerant control system. Loss of actuator effectiveness is induced by ejecting
the propellers from the motors. The robustness of this algorithm is further
investigated offline over a range of parameter settings by replaying real
flight data containing 26 propeller ejections. The detection delays are found
to be in the 30 to 130 ms range, without missed detections or false alarms
occurring.
</p>
<a href="http://arxiv.org/abs/2102.06439" target="_blank">arXiv:2102.06439</a> [<a href="http://arxiv.org/pdf/2102.06439" target="_blank">pdf</a>]

<h2>Broad-UNet: Multi-scale feature learning for nowcasting tasks. (arXiv:2102.06442v1 [cs.LG])</h2>
<h3>Jesus Garcia Fernandez, Siamak Mehrkanoon</h3>
<p>Weather nowcasting consists of predicting meteorological components in the
short term at high spatial resolutions. Due to its influence in many human
activities, accurate nowcasting has recently gained plenty of attention. In
this paper, we treat the nowcasting problem as an image-to-image translation
problem using satellite imagery. We introduce Broad-UNet, a novel architecture
based on the core UNet model, to efficiently address this problem. In
particular, the proposed Broad-UNet is equipped with asymmetric parallel
convolutions as well as Atrous Spatial Pyramid Pooling (ASPP) module. In this
way, The the Broad-UNet model learns more complex patterns by combining
multi-scale features while using fewer parameters than the core UNet model. The
proposed model is applied on two different nowcasting tasks, i.e. precipitation
maps and cloud cover nowcasting. The obtained numerical results show that the
introduced Broad-UNet model performs more accurate predictions compared to the
other examined architectures.
</p>
<a href="http://arxiv.org/abs/2102.06442" target="_blank">arXiv:2102.06442</a> [<a href="http://arxiv.org/pdf/2102.06442" target="_blank">pdf</a>]

<h2>Annotation Cleaning for the MSR-Video to Text Dataset. (arXiv:2102.06448v1 [cs.CV])</h2>
<h3>Haoran Chen, Jianmin Li, Simone Frintrop, Xiaolin Hu</h3>
<p>The video captioning task is to describe the video contents with natural
language by the machine. Many methods have been proposed for solving this task.
A large dataset called MSR Video to Text (MSR-VTT) is often used as the
benckmark dataset for testing the performance of the methods. However, we found
that the human annotations, i.e., the descriptions of video contents in the
dataset are quite noisy, e.g., there are many duplicate captions and many
captions contain grammatical problems. These problems may pose difficulties to
video captioning models for learning. We cleaned the MSR-VTT annotations by
removing these problems, then tested several typical video captioning models on
the cleaned dataset. Experimental results showed that data cleaning boosted the
performances of the models measured by popular quantitative metrics. We
recruited subjects to evaluate the results of a model trained on the original
and cleaned datasets. The human behavior experiment demonstrated that trained
on the cleaned dataset, the model generated captions that were more coherent
and more relevant to contents of the video clips. The cleaned dataset is
publicly available.
</p>
<a href="http://arxiv.org/abs/2102.06448" target="_blank">arXiv:2102.06448</a> [<a href="http://arxiv.org/pdf/2102.06448" target="_blank">pdf</a>]

<h2>Two Sides of the Same Coin: Heterophily and Oversmoothing in Graph Convolutional Neural Networks. (arXiv:2102.06462v1 [cs.LG])</h2>
<h3>Yujun Yan, Milad Hashemi, Kevin Swersky, Yaoqing Yang, Danai Koutra</h3>
<p>Most graph neural networks (GNN) perform poorly in graphs where neighbors
typically have different features/classes (heterophily) and when stacking
multiple layers (oversmoothing). These two seemingly unrelated problems have
been studied independently, but there is recent empirical evidence that solving
one problem may benefit the other. In this work, going beyond empirical
observations, we theoretically characterize the connections between heterophily
and oversmoothing, both of which lead to indistinguishable node
representations. By modeling the change in node representations during message
propagation, we theoretically analyze the factors (e.g., degree, heterophily
level) that make the representations of nodes from different classes
indistinguishable. Our analysis highlights that (1) nodes with high heterophily
and nodes with low heterophily and low degrees relative to their neighbors
(degree discrepancy) trigger the oversmoothing problem, and (2) allowing
"negative" messages between neighbors can decouple the heterophily and
oversmoothing problems. Based on our insights, we design a model that addresses
the discrepancy in features and degrees between neighbors by incorporating
signed messages and learned degree corrections. Our experiments on 9 real
networks show that our model achieves state-of-the-art performance under
heterophily, and performs comparably to existing GNNs under low
heterophily(homophily). It also effectively addresses oversmoothing and even
benefits from multiple layers.
</p>
<a href="http://arxiv.org/abs/2102.06462" target="_blank">arXiv:2102.06462</a> [<a href="http://arxiv.org/pdf/2102.06462" target="_blank">pdf</a>]

<h2>Leveraging Global Parameters for Flow-based Neural Posterior Estimation. (arXiv:2102.06477v1 [stat.ML])</h2>
<h3>Pedro L. C. Rodrigues, Thomas Moreau, Gilles Louppe, Alexandre Gramfort</h3>
<p>Inferring the parameters of a stochastic model based on experimental
observations is central to the scientific method. A particularly challenging
setting is when the model is strongly indeterminate, i.e., when distinct sets
of parameters yield identical observations. This arises in many practical
situations, such as when inferring the distance and power of a radio source (is
the source close and weak or far and strong?) or when estimating the amplifier
gain and underlying brain activity of an electrophysiological experiment. In
this work, we present a method for cracking such indeterminacy by exploiting
additional information conveyed by an auxiliary set of observations sharing
global parameters. Our method extends recent developments in simulation-based
inference(SBI) based on normalizing flows to Bayesian hierarchical models. We
validate quantitatively our proposal on a motivating example amenable to
analytical solutions, and then apply it to invert a well known non-linear model
from computational neuroscience.
</p>
<a href="http://arxiv.org/abs/2102.06477" target="_blank">arXiv:2102.06477</a> [<a href="http://arxiv.org/pdf/2102.06477" target="_blank">pdf</a>]

<h2>Universal Adversarial Perturbations Through the Lens of Deep Steganography: Towards A Fourier Perspective. (arXiv:2102.06479v1 [cs.LG])</h2>
<h3>Chaoning Zhang, Philipp Benz, Adil Karjauv, In So Kweon</h3>
<p>The booming interest in adversarial attacks stems from a misalignment between
human vision and a deep neural network (DNN), i.e. a human imperceptible
perturbation fools the DNN. Moreover, a single perturbation, often called
universal adversarial perturbation (UAP), can be generated to fool the DNN for
most images. A similar misalignment phenomenon has recently also been observed
in the deep steganography task, where a decoder network can retrieve a secret
image back from a slightly perturbed cover image. We attempt explaining the
success of both in a unified manner from the Fourier perspective. We perform
task-specific and joint analysis and reveal that (a) frequency is a key factor
that influences their performance based on the proposed entropy metric for
quantifying the frequency distribution; (b) their success can be attributed to
a DNN being highly sensitive to high-frequency content. We also perform feature
layer analysis for providing deep insight on model generalization and
robustness. Additionally, we propose two new variants of universal
perturbations: (1) Universal Secret Adversarial Perturbation (USAP) that
simultaneously achieves attack and hiding; (2) high-pass UAP (HP-UAP) that is
less visible to the human eye.
</p>
<a href="http://arxiv.org/abs/2102.06479" target="_blank">arXiv:2102.06479</a> [<a href="http://arxiv.org/pdf/2102.06479" target="_blank">pdf</a>]

<h2>Scalable Bayesian Inverse Reinforcement Learning. (arXiv:2102.06483v1 [cs.LG])</h2>
<h3>Alex J. Chan, Mihaela van der Schaar</h3>
<p>Bayesian inference over the reward presents an ideal solution to the
ill-posed nature of the inverse reinforcement learning problem. Unfortunately
current methods generally do not scale well beyond the small tabular setting
due to the need for an inner-loop MDP solver, and even non-Bayesian methods
that do themselves scale often require extensive interaction with the
environment to perform well, being inappropriate for high stakes or costly
applications such as healthcare. In this paper we introduce our method,
Approximate Variational Reward Imitation Learning (AVRIL), that addresses both
of these issues by jointly learning an approximate posterior distribution over
the reward that scales to arbitrarily complicated state spaces alongside an
appropriate policy in a completely offline manner through a variational
approach to said latent reward. Applying our method to real medical data
alongside classic control simulations, we demonstrate Bayesian reward inference
in environments beyond the scope of current methods, as well as task
performance competitive with focused offline imitation learning algorithms.
</p>
<a href="http://arxiv.org/abs/2102.06483" target="_blank">arXiv:2102.06483</a> [<a href="http://arxiv.org/pdf/2102.06483" target="_blank">pdf</a>]

<h2>End-to-End Intelligent Framework for Rockfall Detection. (arXiv:2102.06491v1 [cs.LG])</h2>
<h3>Thanasis Zoumpekas, Anna Puig, Maria Salam&#xf3;, David Garc&#xed;a-Sell&#xe9;s, Laura Blanco Nu&#xf1;ez, Marta Guinau</h3>
<p>Rockfall detection is a crucial procedure in the field of geology, which
helps to reduce the associated risks. Currently, geologists identify rockfall
events almost manually utilizing point cloud and imagery data obtained from
different caption devices such as Terrestrial Laser Scanner or digital cameras.
Multi-temporal comparison of the point clouds obtained with these techniques
requires a tedious visual inspection to identify rockfall events which implies
inaccuracies that depend on several factors such as human expertise and the
sensibility of the sensors. This paper addresses this issue and provides an
intelligent framework for rockfall event detection for any individual working
in the intersection of the geology domain and decision support systems. The
development of such an analysis framework poses significant research challenges
and justifies intensive experimental analysis. In particular, we propose an
intelligent system that utilizes multiple machine learning algorithms to detect
rockfall clusters of point cloud data. Due to the extremely imbalanced nature
of the problem, a plethora of state-of-the-art resampling techniques
accompanied by multiple models and feature selection procedures are being
investigated. Various machine learning pipeline combinations have been
benchmarked and compared applying well-known metrics to be incorporated into
our system. Specifically, we developed statistical and machine learning
techniques and applied them to analyze point cloud data extracted from
Terrestrial Laser Scanner in two distinct case studies, involving different
geological contexts: the basaltic cliff of Castellfollit de la Roca and the
conglomerate Montserrat Massif, both located in Spain. Our experimental data
suggest that some of the above-mentioned machine learning pipelines can be
utilized to detect rockfall incidents on mountain walls, with experimentally
proven accuracy.
</p>
<a href="http://arxiv.org/abs/2102.06491" target="_blank">arXiv:2102.06491</a> [<a href="http://arxiv.org/pdf/2102.06491" target="_blank">pdf</a>]

<h2>Customizable Stochastic High Fidelity Model of the Sensors and Camera onboard a Low SWaP Fixed Wing Autonomous Aircraft. (arXiv:2102.06492v1 [cs.RO])</h2>
<h3>Eduado Gallo</h3>
<p>The navigation systems of autonomous aircraft rely on the readings provided
by a suite of onboard sensors to estimate the aircraft state. In the case of
fixed wing vehicles, the sensor suite is composed by triads of accelerometers,
gyroscopes, and magnetometers, a Global Navigation Satellite System (GNSS)
receiver, and an air data system (Pitot tube, air vanes, thermometer, and
barometer), and is often complemented by one or more digital cameras. An
accurate representation of the behavior and error sources of each of these
sensors, together with the images generated by the cameras, in indispensable
for flight simulation and the evaluation of novel inertial or visual navigation
algorithms, and more so in the case of low SWaP (size, weight, and power)
aircraft, in which the quality and price of the sensors is limited. This
article presents realistic and customizable models for each of these sensors,
which have been implemented as an open-source C ++ simulation. Provided with
the true variation of the aircraft state with time, the simulation provides a
time stamped series of the errors generated by all sensors, as well as
realistic images of the Earth surface that resemble those taken from a real
camera flying along the indicated state positions and attitudes.
</p>
<a href="http://arxiv.org/abs/2102.06492" target="_blank">arXiv:2102.06492</a> [<a href="http://arxiv.org/pdf/2102.06492" target="_blank">pdf</a>]

<h2>Depthwise Separable Convolutions Allow for Fast and Memory-Efficient Spectral Normalization. (arXiv:2102.06496v1 [cs.LG])</h2>
<h3>Christina Runkel, Christian Etmann, Michael M&#xf6;ller, Carola-Bibiane Sch&#xf6;nlieb</h3>
<p>An increasing number of models require the control of the spectral norm of
convolutional layers of a neural network. While there is an abundance of
methods for estimating and enforcing upper bounds on those during training,
they are typically costly in either memory or time. In this work, we introduce
a very simple method for spectral normalization of depthwise separable
convolutions, which introduces negligible computational and memory overhead. We
demonstrate the effectiveness of our method on image classification tasks using
standard architectures like MobileNetV2.
</p>
<a href="http://arxiv.org/abs/2102.06496" target="_blank">arXiv:2102.06496</a> [<a href="http://arxiv.org/pdf/2102.06496" target="_blank">pdf</a>]

<h2>Predicting and Attending to Damaging Collisions for Placing Everyday Objects in Photo-Realistic Simulations. (arXiv:2102.06507v1 [cs.RO])</h2>
<h3>Aly Magassouba, Komei Sugiura, Angelica Nakayama, Tsubasa Hirakawa, Takayoshi Yamashita, Hironobu Fujiyoshi, Hisashi Kawai</h3>
<p>Placing objects is a fundamental task for domestic service robots (DSRs).
Thus, inferring the collision-risk before a placing motion is crucial for
achieving the requested task. This problem is particularly challenging because
it is necessary to predict what happens if an object is placed in a cluttered
designated area. We show that a rule-based approach that uses plane detection,
to detect free areas, performs poorly. To address this, we develop PonNet,
which has multimodal attention branches and a self-attention mechanism to
predict damaging collisions, based on RGBD images. Our method can visualize the
risk of damaging collisions, which is convenient because it enables the user to
understand the risk. For this purpose, we build and publish an original dataset
that contains 12,000 photo-realistic images of specific placing areas, with
daily life objects, in home environments. The experimental results show that
our approach improves accuracy compared with the baseline methods.
</p>
<a href="http://arxiv.org/abs/2102.06507" target="_blank">arXiv:2102.06507</a> [<a href="http://arxiv.org/pdf/2102.06507" target="_blank">pdf</a>]

<h2>Interpretable Predictive Maintenance for Hard Drives. (arXiv:2102.06509v1 [cs.LG])</h2>
<h3>Maxime Amram, Jack Dunn, Jeremy J. Toledano, Ying Daisy Zhuo</h3>
<p>Existing machine learning approaches for data-driven predictive maintenance
are usually black boxes that claim high predictive power yet cannot be
understood by humans. This limits the ability of humans to use these models to
derive insights and understanding of the underlying failure mechanisms, and
also limits the degree of confidence that can be placed in such a system to
perform well on future data. We consider the task of predicting hard drive
failure in a data center using recent algorithms for interpretable machine
learning. We demonstrate that these methods provide meaningful insights about
short- and long-term drive health, while also maintaining high predictive
performance. We also show that these analyses still deliver useful insights
even when limited historical data is available, enabling their use in
situations where data collection has only recently begun.
</p>
<a href="http://arxiv.org/abs/2102.06509" target="_blank">arXiv:2102.06509</a> [<a href="http://arxiv.org/pdf/2102.06509" target="_blank">pdf</a>]

<h2>Bootstrapped Representation Learning on Graphs. (arXiv:2102.06514v1 [cs.LG])</h2>
<h3>Shantanu Thakoor, Corentin Tallec, Mohammad Gheshlaghi Azar, R&#xe9;mi Munos, Petar Veli&#x10d;kovi&#x107;, Michal Valko</h3>
<p>Current state-of-the-art self-supervised learning methods for graph neural
networks (GNNs) are based on contrastive learning. As such, they heavily depend
on the construction of augmentations and negative examples. For example, on the
standard PPI benchmark, increasing the number of negative pairs improves
performance, thereby requiring computation and memory cost quadratic in the
number of nodes to achieve peak performance. Inspired by BYOL, a recently
introduced method for self-supervised learning that does not require negative
pairs, we present Bootstrapped Graph Latents, BGRL, a self-supervised graph
representation method that gets rid of this potentially quadratic bottleneck.
BGRL outperforms or matches the previous unsupervised state-of-the-art results
on several established benchmark datasets. Moreover, it enables the effective
usage of graph attentional (GAT) encoders, allowing us to further improve the
state of the art. In particular on the PPI dataset, using GAT as an encoder we
achieve state-of-the-art 70.49% Micro-F1, using the linear evaluation protocol.
On all other datasets under consideration, our model is competitive with the
equivalent supervised GNN results, often exceeding them.
</p>
<a href="http://arxiv.org/abs/2102.06514" target="_blank">arXiv:2102.06514</a> [<a href="http://arxiv.org/pdf/2102.06514" target="_blank">pdf</a>]

<h2>VitrAI -- Applying Explainable AI in the Real World. (arXiv:2102.06518v1 [cs.AI])</h2>
<h3>Marc Hanussek, Falko K&#xf6;tter, Maximilien Kintz, Jens Drawehn</h3>
<p>With recent progress in the field of Explainable Artificial Intelligence
(XAI) and increasing use in practice, the need for an evaluation of different
XAI methods and their explanation quality in practical usage scenarios arises.
For this purpose, we present VitrAI, which is a web-based service with the goal
of uniformly demonstrating four different XAI algorithms in the context of
three real life scenarios and evaluating their performance and
comprehensibility for humans. This work reveals practical obstacles when
adopting XAI methods and gives qualitative estimates on how well different
approaches perform in said scenarios.
</p>
<a href="http://arxiv.org/abs/2102.06518" target="_blank">arXiv:2102.06518</a> [<a href="http://arxiv.org/pdf/2102.06518" target="_blank">pdf</a>]

<h2>Robust and integrative Bayesian neural networks for likelihood-free parameter inference. (arXiv:2102.06521v1 [stat.ML])</h2>
<h3>Fredrik Wrede, Robin Eriksson, Richard Jiang, Linda Petzold, Stefan Engblom, Andreas Hellander, Prashant Singh</h3>
<p>State-of-the-art neural network-based methods for learning summary statistics
have delivered promising results for simulation-based likelihood-free parameter
inference. Existing approaches require density estimation as a post-processing
step building upon deterministic neural networks, and do not take network
prediction uncertainty into account. This work proposes a robust integrated
approach that learns summary statistics using Bayesian neural networks, and
directly estimates the posterior density using categorical distributions. An
adaptive sampling scheme selects simulation locations to efficiently and
iteratively refine the predictive posterior of the network conditioned on
observations. This allows for more efficient and robust convergence on
comparatively large prior spaces. We demonstrate our approach on benchmark
examples and compare against related methods.
</p>
<a href="http://arxiv.org/abs/2102.06521" target="_blank">arXiv:2102.06521</a> [<a href="http://arxiv.org/pdf/2102.06521" target="_blank">pdf</a>]

<h2>Sequential Neural Posterior and Likelihood Approximation. (arXiv:2102.06522v1 [stat.ML])</h2>
<h3>Samuel Wiqvist, Jes Frellsen, Umberto Picchini</h3>
<p>We introduce the sequential neural posterior and likelihood approximation
(SNPLA) algorithm. SNPLA is a normalizing flows-based algorithm for inference
in implicit models. Thus, SNPLA is a simulation-based inference method that
only requires simulations from a generative model. Compared to similar methods,
the main advantage of SNPLA is that our method jointly learns both the
posterior and the likelihood. SNPLA completely avoid Markov chain Monte Carlo
sampling and correction-steps of the parameter proposal function that are
introduced in similar methods, but that can be numerically unstable or
restrictive. Over four experiments, we show that SNPLA performs competitively
when utilizing the same number of model simulations as used in other methods,
even though the inference problem for SNPLA is more complex due to the joint
learning of posterior and likelihood function.
</p>
<a href="http://arxiv.org/abs/2102.06522" target="_blank">arXiv:2102.06522</a> [<a href="http://arxiv.org/pdf/2102.06522" target="_blank">pdf</a>]

<h2>Leveraging Reinforcement Learning for evaluating Robustness of KNN Search Algorithms. (arXiv:2102.06525v1 [cs.LG])</h2>
<h3>Pramod Vadiraja, Christoph Peter Balada</h3>
<p>The problem of finding K-nearest neighbors in the given dataset for a given
query point has been worked upon since several years. In very high dimensional
spaces the K-nearest neighbor search (KNNS) suffers in terms of complexity in
computation of high dimensional distances. With the issue of curse of
dimensionality, it gets quite tedious to reliably bank on the results of
variety approximate nearest neighbor search approaches. In this paper, we
survey some novel K-Nearest Neighbor Search approaches that tackles the problem
of Search from the perspectives of computations, the accuracy of approximated
results and leveraging parallelism to speed-up computations. We attempt to
derive a relationship between the true positive and false points for a given
KNNS approach. Finally, in order to evaluate the robustness of a KNNS approach
against adversarial points, we propose a generic Reinforcement Learning based
framework for the same.
</p>
<a href="http://arxiv.org/abs/2102.06525" target="_blank">arXiv:2102.06525</a> [<a href="http://arxiv.org/pdf/2102.06525" target="_blank">pdf</a>]

<h2>Improving Object Detection in Art Images Using Only Style Transfer. (arXiv:2102.06529v1 [cs.CV])</h2>
<h3>David Kadish, Sebastian Risi, Anders Sundnes L&#xf8;vlie</h3>
<p>Despite recent advances in object detection using deep learning neural
networks, these neural networks still struggle to identify objects in art
images such as paintings and drawings. This challenge is known as the cross
depiction problem and it stems in part from the tendency of neural networks to
prioritize identification of an object's texture over its shape. In this paper
we propose and evaluate a process for training neural networks to localize
objects - specifically people - in art images. We generate a large dataset for
training and validation by modifying the images in the COCO dataset using AdaIn
style transfer. This dataset is used to fine-tune a Faster R-CNN object
detection network, which is then tested on the existing People-Art testing
dataset. The result is a significant improvement on the state of the art and a
new way forward for creating datasets to train neural networks to process art
images.
</p>
<a href="http://arxiv.org/abs/2102.06529" target="_blank">arXiv:2102.06529</a> [<a href="http://arxiv.org/pdf/2102.06529" target="_blank">pdf</a>]

<h2>Jacobian Determinant of Normalizing Flows. (arXiv:2102.06539v1 [cs.LG])</h2>
<h3>Huadong Liao, Jiawei He</h3>
<p>Normalizing flows learn a diffeomorphic mapping between the target and base
distribution, while the Jacobian determinant of that mapping forms another
real-valued function. In this paper, we show that the Jacobian determinant
mapping is unique for the given distributions, hence the likelihood objective
of flows has a unique global optimum. In particular, the likelihood for a class
of flows is explicitly expressed by the eigenvalues of the auto-correlation
matrix of individual data point, and independent of the parameterization of
neural network, which provides a theoretical optimal value of likelihood
objective and relates to probabilistic PCA. Additionally, Jacobian determinant
is a measure of local volume change and is maximized when MLE is used for
optimization. To stabilize normalizing flows training, it is required to
maintain a balance between the expansiveness and contraction of volume, meaning
Lipschitz constraint on the diffeomorphic mapping and its inverse. With these
theoretical results, several principles of designing normalizing flow were
proposed. And numerical experiments on highdimensional datasets (such as
CelebA-HQ 1024x1024) were conducted to show the improved stability of training.
</p>
<a href="http://arxiv.org/abs/2102.06539" target="_blank">arXiv:2102.06539</a> [<a href="http://arxiv.org/pdf/2102.06539" target="_blank">pdf</a>]

<h2>Tightening the Dependence on Horizon in the Sample Complexity of Q-Learning. (arXiv:2102.06548v1 [stat.ML])</h2>
<h3>Gen Li, Changxiao Cai, Yuxin Chen, Yuantao Gu, Yuting Wei, Yuejie Chi</h3>
<p>Q-learning, which seeks to learn the optimal Q-function of a Markov decision
process (MDP) in a model-free fashion, lies at the heart of reinforcement
learning. When it comes to the synchronous setting (such that independent
samples for all state-action pairs are drawn from a generative model in each
iteration), substantial progress has been made recently towards understanding
the sample efficiency of Q-learning. To yield an entrywise
$\varepsilon$-accurate estimate of the optimal Q-function, state-of-the-art
theory requires at least an order of
$\frac{|\mathcal{S}||\mathcal{A}|}{(1-\gamma)^5\varepsilon^{2}}$ samples for a
$\gamma$-discounted infinite-horizon MDP with state space $\mathcal{S}$ and
action space $\mathcal{A}$. In this work, we sharpen the sample complexity of
synchronous Q-learning to an order of
$\frac{|\mathcal{S}||\mathcal{A}|}{(1-\gamma)^4\varepsilon^2}$ (up to some
logarithmic factor) for any $0&lt;\varepsilon &lt;1$, leading to an order-wise
improvement in terms of the effective horizon $\frac{1}{1-\gamma}$. Analogous
results are derived for finite-horizon MDPs as well. Our finding unveils the
effectiveness of vanilla Q-learning, which matches that of speedy Q-learning
without requiring extra computation and storage. A key ingredient of our
analysis lies in the establishment of novel error decompositions and
recursions, which might shed light on how to analyze finite-sample performance
of other Q-learning variants.
</p>
<a href="http://arxiv.org/abs/2102.06548" target="_blank">arXiv:2102.06548</a> [<a href="http://arxiv.org/pdf/2102.06548" target="_blank">pdf</a>]

<h2>Exploiting Spline Models for the Training of Fully Connected Layers in Neural Network. (arXiv:2102.06554v1 [cs.LG])</h2>
<h3>Kanya Mo (1), Shen Zheng (1), Xiwei Wang (1), Jinghua Wang (2), Klaus-Dieter Schewe (1) ((1) Zhejiang University, UIUC Institute, (2) University of Illinois at Urbana-Champaign)</h3>
<p>The fully connected (FC) layer, one of the most fundamental modules in
artificial neural networks (ANN), is often considered difficult and inefficient
to train due to issues including the risk of overfitting caused by its large
amount of parameters. Based on previous work studying ANN from linear spline
perspectives, we propose a spline-based approach that eases the difficulty of
training FC layers. Given some dataset, we first obtain a continuous piece-wise
linear (CPWL) fit through spline methods such as multivariate adaptive
regression spline (MARS). Next, we construct an ANN model from the linear
spline model and continue to train the ANN model on the dataset using gradient
descent optimization algorithms. Our experimental results and theoretical
analysis show that our approach reduces the computational cost, accelerates the
convergence of FC layers, and significantly increases the interpretability of
the resulting model (FC layers) compared with standard ANN training with random
parameter initialization followed by gradient descent optimizations.
</p>
<a href="http://arxiv.org/abs/2102.06554" target="_blank">arXiv:2102.06554</a> [<a href="http://arxiv.org/pdf/2102.06554" target="_blank">pdf</a>]

<h2>Online Graph Dictionary Learning. (arXiv:2102.06555v1 [cs.LG])</h2>
<h3>C&#xe9;dric Vincent-Cuaz, Titouan Vayer, R&#xe9;mi Flamary, Marco Corneli, Nicolas Courty</h3>
<p>Dictionary learning is a key tool for representation learning, that explains
the data as linear combination of few basic elements. Yet, this analysis is not
amenable in the context of graph learning, as graphs usually belong to
different metric spaces. We fill this gap by proposing a new online Graph
Dictionary Learning approach, which uses the Gromov Wasserstein divergence for
the data fitting term. In our work, graphs are encoded through their nodes'
pairwise relations and modeled as convex combination of graph atoms, i.e.
dictionary elements, estimated thanks to an online stochastic algorithm, which
operates on a dataset of unregistered graphs with potentially different number
of nodes. Our approach naturally extends to labeled graphs, and is completed by
a novel upper bound that can be used as a fast approximation of Gromov
Wasserstein in the embedding space. We provide numerical evidences showing the
interest of our approach for unsupervised embedding of graph datasets and for
online graph subspace estimation and tracking.
</p>
<a href="http://arxiv.org/abs/2102.06555" target="_blank">arXiv:2102.06555</a> [<a href="http://arxiv.org/pdf/2102.06555" target="_blank">pdf</a>]

<h2>Infinitely Deep Bayesian Neural Networks with Stochastic Differential Equations. (arXiv:2102.06559v1 [stat.ML])</h2>
<h3>Winnie Xu, Ricky T.Q. Chen, Xuechen Li, David Duvenaud</h3>
<p>We perform scalable approximate inference in a recently-proposed family of
continuous-depth Bayesian neural networks. In this model class, uncertainty
about separate weights in each layer produces dynamics that follow a stochastic
differential equation (SDE). We demonstrate gradient-based stochastic
variational inference in this infinite-parameter setting, producing
arbitrarily-flexible approximate posteriors. We also derive a novel gradient
estimator that approaches zero variance as the approximate posterior approaches
the true posterior. This approach further inherits the memory-efficient
training and tunable precision of neural ODEs.
</p>
<a href="http://arxiv.org/abs/2102.06559" target="_blank">arXiv:2102.06559</a> [<a href="http://arxiv.org/pdf/2102.06559" target="_blank">pdf</a>]

<h2>How Far Should We Look Back to Achieve Effective Real-Time Time-Series Anomaly Detection?. (arXiv:2102.06560v1 [cs.LG])</h2>
<h3>Ming-Chang Lee, Jia-Chun Lin, Ernst Gunnar Gran</h3>
<p>Anomaly detection is the process of identifying unexpected events or
ab-normalities in data, and it has been applied in many different areas such as
system monitoring, fraud detection, healthcare, intrusion detection, etc.
Providing real-time, lightweight, and proactive anomaly detection for time
series with neither human intervention nor domain knowledge could be highly
valuable since it reduces human effort and enables appropriate countermeasures
to be undertaken before a disastrous event occurs. To our knowledge, RePAD
(Real-time Proactive Anomaly Detection algorithm) is a generic approach with
all above-mentioned features. To achieve real-time and lightweight detection,
RePAD utilizes Long Short-Term Memory (LSTM) to detect whether or not each
upcoming data point is anomalous based on short-term historical data points.
However, it is unclear that how different amounts of historical data points
affect the performance of RePAD. Therefore, in this paper, we investigate the
impact of different amounts of historical data on RePAD by introducing a set of
performance metrics that cover novel detection accuracy measures, time
efficiency, readiness, and resource consumption, etc. Empirical experiments
based on real-world time series datasets are conducted to evaluate RePAD in
different scenarios, and the experimental results are presented and discussed.
</p>
<a href="http://arxiv.org/abs/2102.06560" target="_blank">arXiv:2102.06560</a> [<a href="http://arxiv.org/pdf/2102.06560" target="_blank">pdf</a>]

<h2>Analysis of Interpolation based Image In-painting Approaches. (arXiv:2102.06564v1 [cs.CV])</h2>
<h3>Mustafa Zor, Erkan Bostanci, Mehmet Serdar Guzel, Erinc Karatas</h3>
<p>Interpolation and internal painting are one of the basic approaches in image
internal painting, which is used to eliminate undesirable parts that occur in
digital images or to enhance faulty parts. This study was designed to compare
the interpolation algorithms used in image in-painting in the literature.
Errors and noise generated on the colour and grayscale formats of some of the
commonly used standard images in the literature were corrected by using Cubic,
Kriging, Radial based function and High dimensional model representation
approaches and the results were compared using standard image comparison
criteria, namely, PSNR (peak signal-to-noise ratio), SSIM (Structural
SIMilarity), Mean Square Error (MSE). According to the results obtained from
the study, the absolute superiority of the methods against each other was not
observed. However, Kriging and RBF interpolation give better results both for
numerical data and visual evaluation for image in-painting problems with large
area losses.
</p>
<a href="http://arxiv.org/abs/2102.06564" target="_blank">arXiv:2102.06564</a> [<a href="http://arxiv.org/pdf/2102.06564" target="_blank">pdf</a>]

<h2>Bayesian Neural Network Priors Revisited. (arXiv:2102.06571v1 [stat.ML])</h2>
<h3>Vincent Fortuin, Adri&#xe0; Garriga-Alonso, Florian Wenzel, Gunnar R&#xe4;tsch, Richard Turner, Mark van der Wilk, Laurence Aitchison</h3>
<p>Isotropic Gaussian priors are the de facto standard for modern Bayesian
neural network inference. However, such simplistic priors are unlikely to
either accurately reflect our true beliefs about the weight distributions, or
to give optimal performance. We study summary statistics of neural network
weights in different networks trained using SGD. We find that fully connected
networks (FCNNs) display heavy-tailed weight distributions, while convolutional
neural network (CNN) weights display strong spatial correlations. Building
these observations into the respective priors leads to improved performance on
a variety of image classification datasets. Moreover, we find that these priors
also mitigate the cold posterior effect in FCNNs, while in CNNs we see strong
improvements at all temperatures, and hence no reduction in the cold posterior
effect.
</p>
<a href="http://arxiv.org/abs/2102.06571" target="_blank">arXiv:2102.06571</a> [<a href="http://arxiv.org/pdf/2102.06571" target="_blank">pdf</a>]

<h2>Estimation and Applications of Quantiles in Deep Binary Classification. (arXiv:2102.06575v1 [cs.LG])</h2>
<h3>Anuj Tambwekar, Anirudh Maiya, Soma Dhavala, Snehanshu Saha</h3>
<p>Quantile regression, based on check loss, is a widely used inferential
paradigm in Econometrics and Statistics. The conditional quantiles provide a
robust alternative to classical conditional means, and also allow uncertainty
quantification of the predictions, while making very few distributional
assumptions. We consider the analogue of check loss in the binary
classification setting. We assume that the conditional quantiles are smooth
functions that can be learnt by Deep Neural Networks (DNNs). Subsequently, we
compute the Lipschitz constant of the proposed loss, and also show that its
curvature is bounded, under some regularity conditions. Consequently, recent
results on the error rates and DNN architecture complexity become directly
applicable.

We quantify the uncertainty of the class probabilities in terms of prediction
intervals, and develop individualized confidence scores that can be used to
decide whether a prediction is reliable or not at scoring time. By aggregating
the confidence scores at the dataset level, we provide two additional metrics,
model confidence, and retention rate, to complement the widely used classifier
summaries. We also the robustness of the proposed non-parametric binary
quantile classification framework are also studied, and we demonstrate how to
obtain several univariate summary statistics of the conditional distributions,
in particular conditional means, using smoothed conditional quantiles, allowing
the use of explanation techniques like Shapley to explain the mean predictions.
Finally, we demonstrate an efficient training regime for this loss based on
Stochastic Gradient Descent with Lipschitz Adaptive Learning Rates (LALR).
</p>
<a href="http://arxiv.org/abs/2102.06575" target="_blank">arXiv:2102.06575</a> [<a href="http://arxiv.org/pdf/2102.06575" target="_blank">pdf</a>]

<h2>Reviving Iterative Training with Mask Guidance for Interactive Segmentation. (arXiv:2102.06583v1 [cs.CV])</h2>
<h3>Konstantin Sofiiuk, Ilia A. Petrov, Anton Konushin</h3>
<p>Recent works on click-based interactive segmentation have demonstrated
state-of-the-art results by using various inference-time optimization schemes.
These methods are considerably more computationally expensive compared to
feedforward approaches, as they require performing backward passes through a
network during inference and are hard to deploy on mobile frameworks that
usually support only forward passes. In this paper, we extensively evaluate
various design choices for interactive segmentation and discover that new
state-of-the-art results can be obtained without any additional optimization
schemes. Thus, we propose a simple feedforward model for click-based
interactive segmentation that employs the segmentation masks from previous
steps. It allows not only to segment an entirely new object, but also to start
with an external mask and correct it. When analyzing the performance of models
trained on different datasets, we observe that the choice of a training dataset
greatly impacts the quality of interactive segmentation. We find that the
models trained on a combination of COCO and LVIS with diverse and high-quality
annotations show performance superior to all existing models. The code and
trained models are available at
https://github.com/saic-vul/ritm_interactive_segmentation.
</p>
<a href="http://arxiv.org/abs/2102.06583" target="_blank">arXiv:2102.06583</a> [<a href="http://arxiv.org/pdf/2102.06583" target="_blank">pdf</a>]

<h2>A Computability Perspective on (Verified) Machine Learning. (arXiv:2102.06585v1 [cs.LG])</h2>
<h3>Tonicha Crook, Jay Morgan, Arno Pauly, Markus Roggenbach</h3>
<p>There is a strong consensus that combining the versatility of machine
learning with the assurances given by formal verification is highly desirable.
It is much less clear what verified machine learning should mean exactly. We
consider this question from the (unexpected?) perspective of computable
analysis. This allows us to define the computational tasks underlying verified
ML in a model-agnostic way, and show that they are in principle computable.
</p>
<a href="http://arxiv.org/abs/2102.06585" target="_blank">arXiv:2102.06585</a> [<a href="http://arxiv.org/pdf/2102.06585" target="_blank">pdf</a>]

<h2>Disturbing Reinforcement Learning Agents with Corrupted Rewards. (arXiv:2102.06587v1 [cs.LG])</h2>
<h3>Rub&#xe9;n Majadas, Javier Garc&#xed;a, Fernando Fern&#xe1;ndez</h3>
<p>Reinforcement Learning (RL) algorithms have led to recent successes in
solving complex games, such as Atari or Starcraft, and to a huge impact in
real-world applications, such as cybersecurity or autonomous driving. In the
side of the drawbacks, recent works have shown how the performance of RL
algorithms decreases under the influence of soft changes in the reward
function. However, little work has been done about how sensitive these
disturbances are depending on the aggressiveness of the attack and the learning
exploration strategy. In this paper, we propose to fill this gap in the
literature analyzing the effects of different attack strategies based on reward
perturbations, and studying the effect in the learner depending on its
exploration strategy. In order to explain all the behaviors, we choose a
sub-class of MDPs: episodic, stochastic goal-only-rewards MDPs, and in
particular, an intelligible grid domain as a benchmark. In this domain, we
demonstrate that smoothly crafting adversarial rewards are able to mislead the
learner, and that using low exploration probability values, the policy learned
is more robust to corrupt rewards. Finally, in the proposed learning scenario,
a counterintuitive result arises: attacking at each learning episode is the
lowest cost attack strategy.
</p>
<a href="http://arxiv.org/abs/2102.06587" target="_blank">arXiv:2102.06587</a> [<a href="http://arxiv.org/pdf/2102.06587" target="_blank">pdf</a>]

<h2>PAC-BUS: Meta-Learning Bounds via PAC-Bayes and Uniform Stability. (arXiv:2102.06589v1 [cs.LG])</h2>
<h3>Alec Farid, Anirudha Majumdar</h3>
<p>We are motivated by the problem of providing strong generalization guarantees
in the context of meta-learning. Existing generalization bounds are either
challenging to evaluate or provide vacuous guarantees in even relatively simple
settings. We derive a probably approximately correct (PAC) bound for
gradient-based meta-learning using two different generalization frameworks in
order to deal with the qualitatively different challenges of generalization at
the "base" and "meta" levels. We employ bounds for uniformly stable algorithms
at the base level and bounds from the PAC-Bayes framework at the meta level.
The result is a PAC-bound that is tighter when the base learner adapts quickly,
which is precisely the goal of meta-learning. We show that our bound provides a
tighter guarantee than other bounds on a toy non-convex problem on the unit
sphere and a text-based classification example. We also present a practical
regularization scheme motivated by the bound in settings where the bound is
loose and demonstrate improved performance over baseline techniques.
</p>
<a href="http://arxiv.org/abs/2102.06589" target="_blank">arXiv:2102.06589</a> [<a href="http://arxiv.org/pdf/2102.06589" target="_blank">pdf</a>]

<h2>Outdoor inverse rendering from a single image using multiview self-supervision. (arXiv:2102.06591v1 [cs.CV])</h2>
<h3>Ye Yu, William A. P. Smith</h3>
<p>In this paper we show how to perform scene-level inverse rendering to recover
shape, reflectance and lighting from a single, uncontrolled image using a fully
convolutional neural network. The network takes an RGB image as input,
regresses albedo, shadow and normal maps from which we infer least squares
optimal spherical harmonic lighting coefficients. Our network is trained using
large uncontrolled multiview and timelapse image collections without ground
truth. By incorporating a differentiable renderer, our network can learn from
self-supervision. Since the problem is ill-posed we introduce additional
supervision. Our key insight is to perform offline multiview stereo (MVS) on
images containing rich illumination variation. From the MVS pose and depth
maps, we can cross project between overlapping views such that Siamese training
can be used to ensure consistent estimation of photometric invariants. MVS
depth also provides direct coarse supervision for normal map estimation. We
believe this is the first attempt to use MVS supervision for learning inverse
rendering. In addition, we learn a statistical natural illumination prior. We
evaluate performance on inverse rendering, normal map estimation and intrinsic
image decomposition benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.06591" target="_blank">arXiv:2102.06591</a> [<a href="http://arxiv.org/pdf/2102.06591" target="_blank">pdf</a>]

<h2>Pareto Optimal Model Selection in Linear Bandits. (arXiv:2102.06593v1 [stat.ML])</h2>
<h3>Yinglun Zhu, Robert Nowak</h3>
<p>We study a model selection problem in the linear bandit setting, where the
learner must adapt to the dimension of the optimal hypothesis class on the fly
and balance exploration and exploitation. More specifically, we assume a
sequence of nested linear hypothesis classes with dimensions $d_1 &lt; d_2 &lt;
\dots$, and the goal is to automatically adapt to the smallest hypothesis class
that contains the true linear model. Although previous papers provide various
guarantees for this model selection problem, the analysis therein either works
in favorable cases when one can cheaply conduct statistical testing to locate
the right hypothesis class or is based on the idea of "corralling" multiple
base algorithms which often performs relatively poorly in practice. These works
also mainly focus on upper bounding the regret. In this paper, we first
establish a lower bound showing that, even with a fixed action set, adaptation
to the unknown intrinsic dimension $d_\star$ comes at a cost: there is no
algorithm that can achieve the regret bound $\widetilde{O}(\sqrt{d_\star T})$
simultaneously for all values of $d_\star$. We also bring new ideas, i.e.,
constructing virtual mixture-arms to effectively summarize useful information,
into the model selection problem in linear bandits. Under a mild assumption on
the action set, we design a Pareto optimal algorithm with guarantees matching
the rate in the lower bound. Experimental results confirm our theoretical
results and show advantages of our algorithm compared to prior work.
</p>
<a href="http://arxiv.org/abs/2102.06593" target="_blank">arXiv:2102.06593</a> [<a href="http://arxiv.org/pdf/2102.06593" target="_blank">pdf</a>]

<h2>Neural Architecture Search as Program Transformation Exploration. (arXiv:2102.06599v1 [cs.LG])</h2>
<h3>Jack Turner, Elliot J. Crowley, Michael O&#x27;Boyle</h3>
<p>Improving the performance of deep neural networks (DNNs) is important to both
the compiler and neural architecture search (NAS) communities. Compilers apply
program transformations in order to exploit hardware parallelism and memory
hierarchy. However, legality concerns mean they fail to exploit the natural
robustness of neural networks. In contrast, NAS techniques mutate networks by
operations such as the grouping or bottlenecking of convolutions, exploiting
the resilience of DNNs. In this work, we express such neural architecture
operations as program transformations whose legality depends on a notion of
representational capacity. This allows them to be combined with existing
transformations into a unified optimization framework. This unification allows
us to express existing NAS operations as combinations of simpler
transformations. Crucially, it allows us to generate and explore new tensor
convolutions. We prototyped the combined framework in TVM and were able to find
optimizations across different DNNs, that significantly reduce inference time -
over 3$\times$ in the majority of cases.

Furthermore, our scheme dramatically reduces NAS search time. Code is
available
at~\href{https://github.com/jack-willturner/nas-as-program-transformation-exploration}{this
https url}.
</p>
<a href="http://arxiv.org/abs/2102.06599" target="_blank">arXiv:2102.06599</a> [<a href="http://arxiv.org/pdf/2102.06599" target="_blank">pdf</a>]

<h2>Modeling Dynamic User Interests: A Neural Matrix Factorization Approach. (arXiv:2102.06602v1 [cs.LG])</h2>
<h3>Paramveer Dhillon, Sinan Aral</h3>
<p>In recent years, there has been significant interest in understanding users'
online content consumption patterns. But, the unstructured, high-dimensional,
and dynamic nature of such data makes extracting valuable insights challenging.
Here we propose a model that combines the simplicity of matrix factorization
with the flexibility of neural networks to efficiently extract nonlinear
patterns from massive text data collections relevant to consumers' online
consumption patterns. Our model decomposes a user's content consumption journey
into nonlinear user and content factors that are used to model their dynamic
interests. This natural decomposition allows us to summarize each user's
content consumption journey with a dynamic probabilistic weighting over a set
of underlying content attributes. The model is fast to estimate, easy to
interpret and can harness external data sources as an empirical prior. These
advantages make our method well suited to the challenges posed by modern
datasets. We use our model to understand the dynamic news consumption interests
of Boston Globe readers over five years. Thorough qualitative studies,
including a crowdsourced evaluation, highlight our model's ability to
accurately identify nuanced and coherent consumption patterns. These results
are supported by our model's superior and robust predictive performance over
several competitive baseline methods.
</p>
<a href="http://arxiv.org/abs/2102.06602" target="_blank">arXiv:2102.06602</a> [<a href="http://arxiv.org/pdf/2102.06602" target="_blank">pdf</a>]

<h2>Semantically-Conditioned Negative Samples for Efficient Contrastive Learning. (arXiv:2102.06603v1 [cs.LG])</h2>
<h3>James O&#x27; Neill, Danushka Bollegala</h3>
<p>Negative sampling is a limiting factor w.r.t. the generalization of
metric-learned neural networks. We show that uniform negative sampling provides
little information about the class boundaries and thus propose three novel
techniques for efficient negative sampling: drawing negative samples from (1)
the top-$k$ most semantically similar classes, (2) the top-$k$ most
semantically similar samples and (3) interpolating between contrastive latent
representations to create pseudo negatives. Our experiments on CIFAR-10,
CIFAR-100 and Tiny-ImageNet-200 show that our proposed \textit{Semantically
Conditioned Negative Sampling} and Latent Mixup lead to consistent performance
improvements. In the standard supervised learning setting, on average we
increase test accuracy by 1.52\% percentage points on CIFAR-10 across various
network architectures. In the knowledge distillation setting, (1) the
performance of student networks increase by 4.56\% percentage points on
Tiny-ImageNet-200 and 3.29\% on CIFAR-100 over student networks trained with no
teacher and (2) 1.23\% and 1.72\% respectively over a \textit{hard-to-beat}
baseline (Hinton et al., 2015).
</p>
<a href="http://arxiv.org/abs/2102.06603" target="_blank">arXiv:2102.06603</a> [<a href="http://arxiv.org/pdf/2102.06603" target="_blank">pdf</a>]

<h2>Cockpit: A Practical Debugging Tool for Training Deep Neural Networks. (arXiv:2102.06604v1 [cs.LG])</h2>
<h3>Frank Schneider, Felix Dangel, Philipp Hennig</h3>
<p>When engineers train deep learning models, they are very much "flying blind".
Commonly used approaches for real-time training diagnostics, such as monitoring
the train/test loss, are limited. Assessing a network's training process solely
through these performance indicators is akin to debugging software without
access to internal states through a debugger. To address this, we present
Cockpit, a collection of instruments that enable a closer look into the inner
workings of a learning machine, and a more informative and meaningful status
report for practitioners. It facilitates the identification of learning phases
and failure modes, like ill-chosen hyperparameters. These instruments leverage
novel higher-order information about the gradient distribution and curvature,
which has only recently become efficiently accessible. We believe that such a
debugging tool, which we open-source for PyTorch, represents an important step
to improve troubleshooting the training process, reveal new insights, and help
develop novel methods and heuristics.
</p>
<a href="http://arxiv.org/abs/2102.06604" target="_blank">arXiv:2102.06604</a> [<a href="http://arxiv.org/pdf/2102.06604" target="_blank">pdf</a>]

<h2>Unleashing the Power of Contrastive Self-Supervised Visual Models via Contrast-Regularized Fine-Tuning. (arXiv:2102.06605v1 [cs.CV])</h2>
<h3>Yifan Zhang, Bryan Hooi, Dapeng Hu, Jian Liang, Jiashi Feng</h3>
<p>Contrastive self-supervised learning (CSL) leverages unlabeled data to train
models that provide instance-discriminative visual representations uniformly
scattered in the feature space. In deployment, the common practice is to
directly fine-tune models with the cross-entropy loss, which however may not be
an optimal strategy. Although cross-entropy tends to separate inter-class
features, the resulted models still have limited capability of reducing
intra-class feature scattering that inherits from pre-training, and thus may
suffer unsatisfactory performance on downstream tasks. In this paper, we
investigate whether applying contrastive learning to fine-tuning would bring
further benefits, and analytically find that optimizing the supervised
contrastive loss benefits both class-discriminative representation learning and
model optimization during fine-tuning. Inspired by these findings, we propose
Contrast-regularized tuning (Core-tuning), a novel approach for fine-tuning
contrastive self-supervised visual models. Instead of simply adding the
contrastive loss to the objective of fine-tuning, Core-tuning also generates
hard sample pairs for more effective contrastive learning through a novel
feature mixup strategy, as well as improves the generalizability of the model
by smoothing the decision boundary via mixed samples. Extensive experiments on
image classification and semantic segmentation verify the effectiveness of
Core-tuning.
</p>
<a href="http://arxiv.org/abs/2102.06605" target="_blank">arXiv:2102.06605</a> [<a href="http://arxiv.org/pdf/2102.06605" target="_blank">pdf</a>]

<h2>Intelligent Software Web Agents: A Gap Analysis. (arXiv:2102.06607v1 [cs.AI])</h2>
<h3>Sabrina Kirrane</h3>
<p>Semantic web technologies have shown their effectiveness, especially when it
comes to knowledge representation, reasoning, and data integrations. However,
the original semantic web vision, whereby machine readable web data could be
automatically actioned upon by intelligent software web agents, has yet to be
realised. In order to better understand the existing technological challenges
and opportunities, in this paper we examine the status quo in terms of
intelligent software web agents, guided by research with respect to
requirements and architectural components, coming from that agents community.
We start by collating and summarising requirements and core architectural
components relating to intelligent software agent. Following on from this, we
use the identified requirements to both further elaborate on the semantic web
agent motivating use case scenario, and to summarise different perspectives on
the requirements when it comes to semantic web agent literature. Finally, we
propose a hybrid semantic web agent architecture, discuss the role played by
existing semantic web standards, and point to existing work in the broader
semantic web community any beyond that could help us to make the semantic web
agent vision a reality.
</p>
<a href="http://arxiv.org/abs/2102.06607" target="_blank">arXiv:2102.06607</a> [<a href="http://arxiv.org/pdf/2102.06607" target="_blank">pdf</a>]

<h2>MetaGrad: Adaptation using Multiple Learning Rates in Online Learning. (arXiv:2102.06622v1 [cs.LG])</h2>
<h3>Tim van Erven, Wouter M. Koolen, Dirk van der Hoeven</h3>
<p>We provide a new adaptive method for online convex optimization, MetaGrad,
that is robust to general convex losses but achieves faster rates for a broad
class of special functions, including exp-concave and strongly convex
functions, but also various types of stochastic and non-stochastic functions
without any curvature. We prove this by drawing a connection to the Bernstein
condition, which is known to imply fast rates in offline statistical learning.
MetaGrad further adapts automatically to the size of the gradients. Its main
feature is that it simultaneously considers multiple learning rates, which are
weighted directly proportional to their empirical performance on the data using
a new meta-algorithm. We provide three versions of MetaGrad. The full matrix
version maintains a full covariance matrix and is applicable to learning tasks
for which we can afford update time quadratic in the dimension. The other two
versions provide speed-ups for high-dimensional learning tasks with an update
time that is linear in the dimension: one is based on sketching, the other on
running a separate copy of the basic algorithm per coordinate. We evaluate all
versions of MetaGrad on benchmark online classification and regression tasks,
on which they consistently outperform both online gradient descent and AdaGrad.
</p>
<a href="http://arxiv.org/abs/2102.06622" target="_blank">arXiv:2102.06622</a> [<a href="http://arxiv.org/pdf/2102.06622" target="_blank">pdf</a>]

<h2>Do-calculus enables causal reasoning with latent variable models. (arXiv:2102.06626v1 [cs.LG])</h2>
<h3>Sara Mohammad-Taheri, Robert Ness, Jeremy Zucker, Olga Vitek</h3>
<p>Latent variable models (LVMs) are probabilistic models where some of the
variables are hidden during training. A broad class of LVMshave a directed
acyclic graphical structure. The directed structure suggests an intuitive
causal explanation of the data generating process. For example, a latent topic
model suggests that topics cause the occurrence of a token. Despite this
intuitive causal interpretation, a directed acyclic latent variable model
trained on data is generally insufficient for causal reasoning, as the required
model parameters may not be uniquely identified. In this manuscript we
demonstrate that an LVM can answer any causal query posed post-training,
provided that the query can be identified from the observed variables according
to the do-calculus rules. We show that causal reasoning can enhance a broad
class of LVM long established in the probabilistic modeling community, and
demonstrate its effectiveness on several case studies. These include a machine
learning model with multiple causes where there exists a set of latent
confounders and a mediator between the causes and the outcome variable, a study
where the identifiable causal query cannot be estimated using the front-door or
back-door criterion, a case study that captures unobserved crosstalk between
two biological signaling pathways, and a COVID-19 expert system that identifies
multiple causal queries.
</p>
<a href="http://arxiv.org/abs/2102.06626" target="_blank">arXiv:2102.06626</a> [<a href="http://arxiv.org/pdf/2102.06626" target="_blank">pdf</a>]

<h2>ReLU Neural Networks for Exact Maximum Flow Computation. (arXiv:2102.06635v1 [cs.LG])</h2>
<h3>Christoph Hertrich, Leon Sering</h3>
<p>Understanding the great empirical success of artificial neural networks (NNs)
from a theoretical point of view is currently one of the hottest research
topics in computer science. In this paper we study the expressive power of NNs
with rectified linear units from a combinatorial optimization perspective. In
particular, we show that, given a directed graph with $n$ nodes and $m$ arcs,
there exists an NN of polynomial size that computes a maximum flow from any
possible real-valued arc capacities as input. To prove this, we develop the
pseudo-code language Max-Affine Arithmetic Programs (MAAPs) and show
equivalence between MAAPs and NNs concerning natural complexity measures. We
then design a MAAP to exactly solve the Maximum Flow Problem, which translates
to an NN of size $\mathcal{O}(m^2 n^2)$.
</p>
<a href="http://arxiv.org/abs/2102.06635" target="_blank">arXiv:2102.06635</a> [<a href="http://arxiv.org/pdf/2102.06635" target="_blank">pdf</a>]

<h2>Bayesian Quadrature on Riemannian Data Manifolds. (arXiv:2102.06645v1 [cs.LG])</h2>
<h3>Christian Fr&#xf6;hlich, Alexandra Gessner, Philipp Hennig, Bernhard Sch&#xf6;lkopf, Georgios Arvanitidis</h3>
<p>Riemannian manifolds provide a principled way to model nonlinear geometric
structure inherent in data. A Riemannian metric on said manifolds determines
geometry-aware shortest paths and provides the means to define statistical
models accordingly. However, these operations are typically computationally
demanding. To ease this computational burden, we advocate probabilistic
numerical methods for Riemannian statistics. In particular, we focus on
Bayesian quadrature (BQ) to numerically compute integrals over normal laws on
Riemannian manifolds learned from data. In this task, each function evaluation
relies on the solution of an expensive initial value problem. We show that by
leveraging both prior knowledge and an active exploration scheme, BQ
significantly reduces the number of required evaluations and thus outperforms
Monte Carlo methods on a wide range of integration problems. As a concrete
application, we highlight the merits of adopting Riemannian geometry with our
proposed framework on a nonlinear dataset from molecular dynamics.
</p>
<a href="http://arxiv.org/abs/2102.06645" target="_blank">arXiv:2102.06645</a> [<a href="http://arxiv.org/pdf/2102.06645" target="_blank">pdf</a>]

<h2>A Critical Look At The Identifiability of Causal Effects with Deep Latent Variable Models. (arXiv:2102.06648v1 [cs.LG])</h2>
<h3>Severi Rissanen, Pekka Marttinen</h3>
<p>Using deep latent variable models in causal inference has attracted
considerable interest recently, but an essential open question is their
identifiability. While they have yielded promising results and theory exists on
the identifiability of some simple model formulations, we also know that causal
effects cannot be identified in general with latent variables. We investigate
this gap between theory and empirical results with theoretical considerations
and extensive experiments under multiple synthetic and real-world data sets,
using the causal effect variational autoencoder (CEVAE) as a case study. While
CEVAE seems to work reliably under some simple scenarios, it does not identify
the correct causal effect with a misspecified latent variable or a complex data
distribution, as opposed to the original goals of the model. Our results show
that the question of identifiability cannot be disregarded, and we argue that
more attention should be paid to it in future work.
</p>
<a href="http://arxiv.org/abs/2102.06648" target="_blank">arXiv:2102.06648</a> [<a href="http://arxiv.org/pdf/2102.06648" target="_blank">pdf</a>]

<h2>Robust White Matter Hyperintensity Segmentation on Unseen Domain. (arXiv:2102.06650v1 [cs.CV])</h2>
<h3>Xingchen Zhao, Anthony Sicilia, Davneet Minhas, Erin O&#x27;Connor, Howard Aizenstein, William Klunk, Dana Tudorascu, Seong Jae Hwang</h3>
<p>Typical machine learning frameworks heavily rely on an underlying assumption
that training and test data follow the same distribution. In medical imaging
which increasingly begun acquiring datasets from multiple sites or scanners,
this identical distribution assumption often fails to hold due to systematic
variability induced by site or scanner dependent factors. Therefore, we cannot
simply expect a model trained on a given dataset to consistently work well, or
generalize, on a dataset from another distribution. In this work, we address
this problem, investigating the application of machine learning models to
unseen medical imaging data. Specifically, we consider the challenging case of
Domain Generalization (DG) where we train a model without any knowledge about
the testing distribution. That is, we train on samples from a set of
distributions (sources) and test on samples from a new, unseen distribution
(target). We focus on the task of white matter hyperintensity (WMH) prediction
using the multi-site WMH Segmentation Challenge dataset and our local in-house
dataset. We identify how two mechanically distinct DG approaches, namely domain
adversarial learning and mix-up, have theoretical synergy. Then, we show
drastic improvements of WMH prediction on an unseen target domain.
</p>
<a href="http://arxiv.org/abs/2102.06650" target="_blank">arXiv:2102.06650</a> [<a href="http://arxiv.org/pdf/2102.06650" target="_blank">pdf</a>]

<h2>End-to-end Audio-visual Speech Recognition with Conformers. (arXiv:2102.06657v1 [cs.CV])</h2>
<h3>Pingchuan Ma, Stavros Petridis, Maja Pantic</h3>
<p>In this work, we present a hybrid CTC/Attention model based on a ResNet-18
and Convolution-augmented transformer (Conformer), that can be trained in an
end-to-end manner. In particular, the audio and visual encoders learn to
extract features directly from raw pixels and audio waveforms, respectively,
which are then fed to conformers and then fusion takes place via a Multi-Layer
Perceptron (MLP). The model learns to recognise characters using a combination
of CTC and an attention mechanism. We show that end-to-end training, instead of
using pre-computed visual features which is common in the literature, the use
of a conformer, instead of a recurrent network, and the use of a
transformer-based language model, significantly improve the performance of our
model. We present results on the largest publicly available datasets for
sentence-level speech recognition, Lip Reading Sentences 2 (LRS2) and Lip
Reading Sentences 3 (LRS3), respectively. The results show that our proposed
models raise the state-of-the-art performance by a large margin in audio-only,
visual-only, and audio-visual experiments.
</p>
<a href="http://arxiv.org/abs/2102.06657" target="_blank">arXiv:2102.06657</a> [<a href="http://arxiv.org/pdf/2102.06657" target="_blank">pdf</a>]

<h2>A model for traffic incident prediction using emergency braking data. (arXiv:2102.06674v1 [cs.LG])</h2>
<h3>Alexander Reichenbach, J.-Emeterio Navarro-B</h3>
<p>This article presents a model for traffic incident prediction. Specifically,
we address the fundamental problem of data scarcity in road traffic accident
prediction by training our model on emergency braking events instead of
accidents. Based on relevant risk factors for traffic accidents and
corresponding data categories, we evaluate different options for preprocessing
sparse data and different Machine Learning models. Furthermore, we present a
prototype implementing a traffic incident prediction model for Germany based on
emergency braking data from Mercedes-Benz vehicles as well as weather, traffic
and road data, respectively. After model evaluation and optimisation, we found
that a Random Forest model trained on artificially balanced (under-sampled)
data provided the highest classification accuracy of 85% on the original
imbalanced data. Finally, we present our conclusions and discuss further work;
from gathering more data over a longer period of time to build stronger
classification systems, to addition of internal factors such as the driver's
visual and cognitive attention.
</p>
<a href="http://arxiv.org/abs/2102.06674" target="_blank">arXiv:2102.06674</a> [<a href="http://arxiv.org/pdf/2102.06674" target="_blank">pdf</a>]

<h2>Adversarial Branch Architecture Search for Unsupervised Domain Adaptation. (arXiv:2102.06679v1 [cs.CV])</h2>
<h3>Luca Robbiano, Muhammad Rameez Ur Rahman, Fabio Galasso, Barbara Caputo, Fabio Maria Carlucci</h3>
<p>Unsupervised Domain Adaptation (UDA) is a key field in visual recognition, as
it enables robust performances across different visual domains. In the deep
learning era, the performance of UDA methods has been driven by better losses
and by improved network architectures, specifically the addition of auxiliary
domain-alignment branches to pre-trained backbones. However, all the neural
architectures proposed so far are hand-crafted, which might hinder further
progress.

The current copious offspring of Neural Architecture Search (NAS) only
alleviates hand-crafting so far, as it requires labels for model selection,
which are not available in UDA, and is usually applied to the whole
architecture, while using pre-trained models is a strict requirement for high
performance. No prior work has addressed these aspects in the context of NAS
for UDA.

Here we propose an Adversarial Branch Architecture Search (ABAS) for UDA, to
learn the auxiliary branch network from data without handcrafting. Our main
contribution include i. a novel data-driven ensemble approach for model
selection, to circumvent the lack of target labels, and ii. a pipeline to
automatically search for the best performing auxiliary branch.

To the best of our knowledge, ABAS is the first NAS method for UDA to comply
with a pre-trained backbone, a strict requirement for high performance. ABAS
outputs both the optimal auxiliary branch and its trained parameters. When
applied to two modern UDA techniques, DANN and ALDA, it improves performance on
three standard CV datasets (Office31, Office-Home and PACS). In all cases, ABAS
robustly finds the branch architectures which yield best performances. Code
will be released.
</p>
<a href="http://arxiv.org/abs/2102.06679" target="_blank">arXiv:2102.06679</a> [<a href="http://arxiv.org/pdf/2102.06679" target="_blank">pdf</a>]

<h2>DeepGLEAM: an hybrid mechanistic and deep learning model for COVID-19 forecasting. (arXiv:2102.06684v1 [cs.LG])</h2>
<h3>Dongxia Wu, Liyao Gao, Xinyue Xiong, Matteo Chinazzi, Alessandro Vespignani, Yian Ma, Rose Yu</h3>
<p>We introduce DeepGLEAM, a hybrid model for COVID-19 forecasting. DeepGLEAM
combines a mechanistic stochastic simulation model GLEAM with deep learning. It
uses deep learning to learn the correction terms from GLEAM, which leads to
improved performance. We further integrate various uncertainty quantification
methods to generate confidence intervals. We demonstrate DeepGLEAM on
real-world COVID-19 mortality forecasting tasks.
</p>
<a href="http://arxiv.org/abs/2102.06684" target="_blank">arXiv:2102.06684</a> [<a href="http://arxiv.org/pdf/2102.06684" target="_blank">pdf</a>]

<h2>Learning Depth via Leveraging Semantics: Self-supervised Monocular Depth Estimation with Both Implicit and Explicit Semantic Guidance. (arXiv:2102.06685v1 [cs.CV])</h2>
<h3>Rui Li, Xiantuo He, Danna Xue, Shaolin Su, Qing Mao, Yu Zhu, Jinqiu Sun, Yanning Zhang</h3>
<p>Self-supervised depth estimation has made a great success in learning depth
from unlabeled image sequences. While the mappings between image and pixel-wise
depth are well-studied in current methods, the correlation between image, depth
and scene semantics, however, is less considered. This hinders the network to
better understand the real geometry of the scene, since the contextual clues,
contribute not only the latent representations of scene depth, but also the
straight constraints for depth map. In this paper, we leverage the two benefits
by proposing the implicit and explicit semantic guidance for accurate
self-supervised depth estimation. We propose a Semantic-aware Spatial Feature
Alignment (SSFA) scheme to effectively align implicit semantic features with
depth features for scene-aware depth estimation. We also propose a
semantic-guided ranking loss to explicitly constrain the estimated depth maps
to be consistent with real scene contextual properties. Both semantic label
noise and prediction uncertainty is considered to yield reliable depth
supervisions. Extensive experimental results show that our method produces high
quality depth maps which are consistently superior either on complex scenes or
diverse semantic categories, and outperforms the state-of-the-art methods by a
significant margin.
</p>
<a href="http://arxiv.org/abs/2102.06685" target="_blank">arXiv:2102.06685</a> [<a href="http://arxiv.org/pdf/2102.06685" target="_blank">pdf</a>]

<h2>Bias-Free Scalable Gaussian Processes via Randomized Truncations. (arXiv:2102.06695v1 [cs.LG])</h2>
<h3>Andres Potapczynski, Luhuan Wu, Dan Biderman, Geoff Pleiss, John P. Cunningham</h3>
<p>Scalable Gaussian Process methods are computationally attractive, yet
introduce modeling biases that require rigorous study. This paper analyzes two
common techniques: early truncated conjugate gradients (CG) and random Fourier
features (RFF). We find that both methods introduce a systematic bias on the
learned hyperparameters: CG tends to underfit while RFF tends to overfit. We
address these issues using randomized truncation estimators that eliminate bias
in exchange for increased variance. In the case of RFF, we show that the
bias-to-variance conversion is indeed a trade-off: the additional variance
proves detrimental to optimization. However, in the case of CG, our unbiased
learning procedure meaningfully outperforms its biased counterpart with minimal
additional computation.
</p>
<a href="http://arxiv.org/abs/2102.06695" target="_blank">arXiv:2102.06695</a> [<a href="http://arxiv.org/pdf/2102.06695" target="_blank">pdf</a>]

<h2>Efficient Conditional GAN Transfer with Knowledge Propagation across Classes. (arXiv:2102.06696v1 [cs.CV])</h2>
<h3>Mohamad Shahbazi, Zhiwu Huang, Danda Pani Paudel, Ajad Chhatkuli, Luc Van Gool</h3>
<p>Generative adversarial networks (GANs) have shown impressive results in both
unconditional and conditional image generation. In recent literature, it is
shown that pre-trained GANs, on a different dataset, can be transferred to
improve the image generation from a small target data. The same, however, has
not been well-studied in the case of conditional GANs (cGANs), which provides
new opportunities for knowledge transfer compared to unconditional setup. In
particular, the new classes may borrow knowledge from the related old classes,
or share knowledge among themselves to improve the training. This motivates us
to study the problem of efficient conditional GAN transfer with knowledge
propagation across classes. To address this problem, we introduce a new GAN
transfer method to explicitly propagate the knowledge from the old classes to
the new classes. The key idea is to enforce the popularly used conditional
batch normalization (BN) to learn the class-specific information of the new
classes from that of the old classes, with implicit knowledge sharing among the
new ones. This allows for an efficient knowledge propagation from the old
classes to the new classes, with the BN parameters increasing linearly with the
number of new classes. The extensive evaluation demonstrates the clear
superiority of the proposed method over state-of-the-art competitors for
efficient conditional GAN transfer tasks. The code will be available at:
https://github.com/mshahbazi72/cGANTransfer
</p>
<a href="http://arxiv.org/abs/2102.06696" target="_blank">arXiv:2102.06696</a> [<a href="http://arxiv.org/pdf/2102.06696" target="_blank">pdf</a>]

<h2>A Parameterised Quantum Circuit Approach to Point Set Matching. (arXiv:2102.06697v1 [cs.CV])</h2>
<h3>Mohammadreza Noormandipour, Hanchen Wang</h3>
<p>Point set registration is one of the challenging tasks in areas such as
pattern recognition, computer vision and image processing. Efficient
performance of this task has been a hot topic of research due to its widespread
applications. We propose a parameterised quantum circuit learning approach to
point set matching problem. The proposed method benefits from a kernel-based
quantum generative model that: 1) is able to find all possible optimal matching
solution angles, 2) is potentially able to show quantum learning supremacy, and
3) benefits from kernel-embedding techniques and integral probability metrics
for the definition of a powerful loss function. Moreover, the theoretical
framework has been backed up by satisfactory preliminary and proof of concept
experimental results.
</p>
<a href="http://arxiv.org/abs/2102.06697" target="_blank">arXiv:2102.06697</a> [<a href="http://arxiv.org/pdf/2102.06697" target="_blank">pdf</a>]

<h2>Certified Defenses: Why Tighter Relaxations May Hurt Training?. (arXiv:2102.06700v1 [cs.LG])</h2>
<h3>Nikola Jovanovi&#x107;, Mislav Balunovi&#x107;, Maximilian Baader, Martin Vechev</h3>
<p>Certified defenses based on convex relaxations are an established technique
for training provably robust models. The key component is the choice of
relaxation, varying from simple intervals to tight polyhedra. Paradoxically,
however, it was empirically observed that training with tighter relaxations can
worsen certified robustness. While several methods were designed to partially
mitigate this issue, the underlying causes are poorly understood. In this work
we investigate the above phenomenon and show that tightness may not be the
determining factor for reduced certified robustness. Concretely, we identify
two key features of relaxations that impact training dynamics: continuity and
sensitivity. We then experimentally demonstrate that these two factors explain
the drop in certified robustness when using popular relaxations. Further, we
show, for the first time, that it is possible to successfully train with
tighter relaxations (i.e., triangle), a result supported by our two properties.
Overall, we believe the insights of this work can help drive the systematic
discovery of new effective certified defenses.
</p>
<a href="http://arxiv.org/abs/2102.06700" target="_blank">arXiv:2102.06700</a> [<a href="http://arxiv.org/pdf/2102.06700" target="_blank">pdf</a>]

<h2>Explaining Neural Scaling Laws. (arXiv:2102.06701v1 [cs.LG])</h2>
<h3>Yasaman Bahri, Ethan Dyer, Jared Kaplan, Jaehoon Lee, Utkarsh Sharma</h3>
<p>The test loss of well-trained neural networks often follows precise power-law
scaling relations with either the size of the training dataset or the number of
parameters in the network. We propose a theory that explains and connects these
scaling laws. We identify variance-limited and resolution-limited scaling
behavior for both dataset and model size, for a total of four scaling regimes.
The variance-limited scaling follows simply from the existence of a
well-behaved infinite data or infinite width limit, while the
resolution-limited regime can be explained by positing that models are
effectively resolving a smooth data manifold. In the large width limit, this
can be equivalently obtained from the spectrum of certain kernels, and we
present evidence that large width and large dataset resolution-limited scaling
exponents are related by a duality. We exhibit all four scaling regimes in the
controlled setting of large random feature and pretrained models and test the
predictions empirically on a range of standard architectures and datasets. We
also observe several empirical relationships between datasets and scaling
exponents: super-classing image tasks does not change exponents, while changing
input distribution (via changing datasets or adding noise) has a strong effect.
We further explore the effect of architecture aspect ratio on scaling
exponents.
</p>
<a href="http://arxiv.org/abs/2102.06701" target="_blank">arXiv:2102.06701</a> [<a href="http://arxiv.org/pdf/2102.06701" target="_blank">pdf</a>]

<h2>Proximal and Federated Random Reshuffling. (arXiv:2102.06704v1 [cs.LG])</h2>
<h3>Konstantin Mishchenko, Ahmed Khaled, Peter Richt&#xe1;rik</h3>
<p>Random Reshuffling (RR), also known as Stochastic Gradient Descent (SGD)
without replacement, is a popular and theoretically grounded method for
finite-sum minimization. We propose two new algorithms: Proximal and Federated
Random Reshuffing (ProxRR and FedRR). The first algorithm, ProxRR, solves
composite convex finite-sum minimization problems in which the objective is the
sum of a (potentially non-smooth) convex regularizer and an average of $n$
smooth objectives. We obtain the second algorithm, FedRR, as a special case of
ProxRR applied to a reformulation of distributed problems with either
homogeneous or heterogeneous data. We study the algorithms' convergence
properties with constant and decreasing stepsizes, and show that they have
considerable advantages over Proximal and Local SGD. In particular, our methods
have superior complexities and ProxRR evaluates the proximal operator once per
epoch only. When the proximal operator is expensive to compute, this small
difference makes ProxRR up to $n$ times faster than algorithms that evaluate
the proximal operator in every iteration. We give examples of practical
optimization tasks where the proximal operator is difficult to compute and
ProxRR has a clear advantage. Finally, we corroborate our results with
experiments on real data sets.
</p>
<a href="http://arxiv.org/abs/2102.06704" target="_blank">arXiv:2102.06704</a> [<a href="http://arxiv.org/pdf/2102.06704" target="_blank">pdf</a>]

<h2>Invariant Representation of Mathematical Expressions. (arXiv:1805.12495v2 [cs.AI] UPDATED)</h2>
<h3>Reza Shahbazi</h3>
<p>While there exist many methods in machine learning for comparison of letter
string data, most are better equipped to handle strings that represent natural
language, and their performance will not hold up when presented with strings
that correspond to mathematical expressions. Based on the graphical
representation of the expression tree, here we propose a simple method for
encoding such expressions that is only sensitive to their structural
properties, and invariant to the specifics which can vary between two seemingly
different, but semantically similar mathematical expressions.
</p>
<a href="http://arxiv.org/abs/1805.12495" target="_blank">arXiv:1805.12495</a> [<a href="http://arxiv.org/pdf/1805.12495" target="_blank">pdf</a>]

<h2>Active Multi-Information Source Bayesian Quadrature. (arXiv:1903.11331v3 [cs.LG] UPDATED)</h2>
<h3>Alexandra Gessner, Javier Gonzalez, Maren Mahsereci</h3>
<p>Bayesian quadrature (BQ) is a sample-efficient probabilistic numerical method
to solve integrals of expensive-to-evaluate black-box functions, yet so
far,active BQ learning schemes focus merely on the integrand itself as
information source, and do not allow for information transfer from cheaper,
related functions. Here, we set the scene for active learning in BQ when
multiple related information sources of variable cost (in input and source) are
accessible. This setting arises for example when evaluating the integrand
requires a complex simulation to be run that can be approximated by simulating
at lower levels of sophistication and at lesser expense. We construct
meaningful cost-sensitive multi-source acquisition rates as an extension to
common utility functions from vanilla BQ (VBQ),and discuss pitfalls that arise
from blindly generalizing. Furthermore, we show that the VBQ acquisition policy
is a corner-case of all considered cost-sensitive acquisition schemes, which
collapse onto one single de-generate policy in the case of one source and
constant cost. In proof-of-concept experiments we scrutinize the behavior of
our generalized acquisition functions. On an epidemiological model, we
demonstrate that active multi-source BQ (AMS-BQ) allocates budget more
efficiently than VBQ for learning the integral to a good accuracy.
</p>
<a href="http://arxiv.org/abs/1903.11331" target="_blank">arXiv:1903.11331</a> [<a href="http://arxiv.org/pdf/1903.11331" target="_blank">pdf</a>]

<h2>Beyond Folklore: A Scaling Calculus for the Design and Initialization of ReLU Networks. (arXiv:1906.04267v3 [cs.LG] UPDATED)</h2>
<h3>Aaron Defazio, L&#xe9;on Bottou</h3>
<p>We propose a system for calculating a "scaling constant" for layers and
weights of neural networks. We relate this scaling constant to two important
quantities that relate to the optimizability of neural networks, and argue that
a network that is "preconditioned" via scaling, in the sense that all weights
have the same scaling constant, will be easier to train. This scaling calculus
results in a number of consequences, among them the fact that the geometric
mean of the fan-in and fan-out, rather than the fan-in, fan-out, or arithmetic
mean, should be used for the initialization of the variance of weights in a
neural network. Our system allows for the off-line design &amp; engineering of ReLU
neural networks, potentially replacing blind experimentation.
</p>
<a href="http://arxiv.org/abs/1906.04267" target="_blank">arXiv:1906.04267</a> [<a href="http://arxiv.org/pdf/1906.04267" target="_blank">pdf</a>]

<h2>Domain-Specific Priors and Meta Learning for Few-Shot First-Person Action Recognition. (arXiv:1907.09382v2 [cs.CV] UPDATED)</h2>
<h3>Huseyin Coskun, Zeeshan Zia, Bugra Tekin, Federica Bogo, Nassir Navab, Federico Tombari, Harpreet Sawhney</h3>
<p>The lack of large-scale real datasets with annotations makes transfer
learning a necessity for video activity understanding. We aim to develop an
effective method for few-shot transfer learning for first-person action
classification. We leverage independently trained local visual cues to learn
representations that can be transferred from a source domain, which provides
primitive action labels, to a different target domain -- using only a handful
of examples. Visual cues we employ include object-object interactions, hand
grasps and motion within regions that are a function of hand locations. We
employ a framework based on meta-learning to extract the distinctive and domain
invariant components of the deployed visual cues. This enables transfer of
action classification models across public datasets captured with diverse scene
and action configurations. We present comparative results of our transfer
learning methodology and report superior results over state-of-the-art action
classification approaches for both inter-class and inter-dataset transfer.
</p>
<a href="http://arxiv.org/abs/1907.09382" target="_blank">arXiv:1907.09382</a> [<a href="http://arxiv.org/pdf/1907.09382" target="_blank">pdf</a>]

<h2>Image-Based Place Recognition on Bucolic Environment Across Seasons From Semantic Edge Description. (arXiv:1910.12468v4 [cs.CV] UPDATED)</h2>
<h3>Assia Benbihi, St&#xe9;phanie Aravechia, Matthieu Geist, C&#xe9;dric Pradalier</h3>
<p>Most of the research effort on image-based place recognition is designed for
urban environments. In bucolic environments such as natural scenes with low
texture and little semantic content, the main challenge is to handle the
variations in visual appearance across time such as illumination, weather,
vegetation state or viewpoints. The nature of the variations is different and
this leads to a different approach to describing a bucolic scene. We introduce
a global image descriptor computed from its semantic and topological
information. It is built from the wavelet transforms of the image semantic
edges. Matching two images is then equivalent to matching their semantic edge
descriptors. We show that this method reaches state-of-the-art image retrieval
performance on two multi-season environment-monitoring datasets: the
CMU-Seasons and the Symphony Lake dataset. It also generalises to urban scenes
on which it is on par with the current baselines NetVLAD and DELF.
</p>
<a href="http://arxiv.org/abs/1910.12468" target="_blank">arXiv:1910.12468</a> [<a href="http://arxiv.org/pdf/1910.12468" target="_blank">pdf</a>]

<h2>CHEETAH: An Ultra-Fast, Approximation-Free, and Privacy-Preserved Neural Network Framework based on Joint Obscure Linear and Nonlinear Computations. (arXiv:1911.05184v2 [cs.LG] UPDATED)</h2>
<h3>Qiao Zhang, Cong Wang, Chunsheng Xin, Hongyi Wu</h3>
<p>Machine Learning as a Service (MLaaS) is enabling a wide range of smart
applications on end devices. However, such convenience comes with a cost of
privacy because users have to upload their private data to the cloud. This
research aims to provide effective and efficient MLaaS such that the cloud
server learns nothing about user data and the users cannot infer the
proprietary model parameters owned by the server. This work makes the following
contributions. First, it unveils the fundamental performance bottleneck of
existing schemes due to the heavy permutations in computing linear
transformation and the use of communication intensive Garbled Circuits for
nonlinear transformation. Second, it introduces an ultra-fast secure MLaaS
framework, CHEETAH, which features a carefully crafted secret sharing scheme
that runs significantly faster than existing schemes without accuracy loss.
Third, CHEETAH is evaluated on the benchmark of well-known, practical deep
networks such as AlexNet and VGG-16 on the MNIST and ImageNet datasets. The
results demonstrate more than 100x speedup over the fastest GAZELLE (Usenix
Security'18), 2000x speedup over MiniONN (ACM CCS'17) and five orders of
magnitude speedup over CryptoNets (ICML'16). This significant speedup enables a
wide range of practical applications based on privacy-preserved deep neural
networks.
</p>
<a href="http://arxiv.org/abs/1911.05184" target="_blank">arXiv:1911.05184</a> [<a href="http://arxiv.org/pdf/1911.05184" target="_blank">pdf</a>]

<h2>Detecting Adversarial Attacks On Audiovisual Speech Recognition. (arXiv:1912.08639v2 [cs.CV] UPDATED)</h2>
<h3>Pingchuan Ma, Stavros Petridis, Maja Pantic</h3>
<p>Adversarial attacks pose a threat to deep learning models. However, research
on adversarial detection methods, especially in the multi-modal domain, is very
limited. In this work, we propose an efficient and straightforward detection
method based on the temporal correlation between audio and video streams. The
main idea is that the correlation between audio and video in adversarial
examples will be lower than benign examples due to added adversarial noise. We
use the synchronisation confidence score as a proxy for audiovisual correlation
and based on it we can detect adversarial attacks. To the best of our
knowledge, this is the first work on detection of adversarial attacks on
audiovisual speech recognition models. We apply recent adversarial attacks on
two audiovisual speech recognition models trained on the GRID and LRW datasets.
The experimental results demonstrate that the proposed approach is an effective
way for detecting such attacks.
</p>
<a href="http://arxiv.org/abs/1912.08639" target="_blank">arXiv:1912.08639</a> [<a href="http://arxiv.org/pdf/1912.08639" target="_blank">pdf</a>]

<h2>Federated Learning of a Mixture of Global and Local Models. (arXiv:2002.05516v3 [cs.LG] UPDATED)</h2>
<h3>Filip Hanzely, Peter Richt&#xe1;rik</h3>
<p>We propose a new optimization formulation for training federated learning
models. The standard formulation has the form of an empirical risk minimization
problem constructed to find a single global model trained from the private data
stored across all participating devices. In contrast, our formulation seeks an
explicit trade-off between this traditional global model and the local models,
which can be learned by each device from its own private data without any
communication. Further, we develop several efficient variants of SGD (with and
without partial participation and with and without variance reduction) for
solving the new formulation and prove communication complexity guarantees.
Notably, our methods are similar but not identical to federated averaging /
local SGD, thus shedding some light on the role of local steps in federated
learning. In particular, we are the first to i) show that local steps can
improve communication for problems with heterogeneous data, and ii) point out
that personalization yields reduced communication complexity.
</p>
<a href="http://arxiv.org/abs/2002.05516" target="_blank">arXiv:2002.05516</a> [<a href="http://arxiv.org/pdf/2002.05516" target="_blank">pdf</a>]

<h2>SURF: A Simple, Universal, Robust, Fast Distribution Learning Algorithm. (arXiv:2002.09589v2 [stat.ML] UPDATED)</h2>
<h3>Yi Hao, Ayush Jain, Alon Orlitsky, Vaishakh Ravindrakumar</h3>
<p>Sample- and computationally-efficient distribution estimation is a
fundamental tenet in statistics and machine learning. We present SURF, an
algorithm for approximating distributions by piecewise polynomials. SURF is:
simple, replacing prior complex optimization techniques by straight-forward
{empirical probability} approximation of each potential polynomial piece
{through simple empirical-probability interpolation}, and using plain
divide-and-conquer to merge the pieces; universal, as well-known
polynomial-approximation results imply that it accurately approximates a large
class of common distributions; robust to distribution mis-specification as for
any degree $d \le 8$, it estimates any distribution to an $\ell_1$ distance $&lt;
3$ times that of the nearest degree-$d$ piecewise polynomial, improving known
factor upper bounds of 3 for single polynomials and 15 for polynomials with
arbitrarily many pieces; fast, using optimal sample complexity, running in near
sample-linear time, and if given sorted samples it may be parallelized to run
in sub-linear time. In experiments, SURF outperforms state-of-the art
algorithms.
</p>
<a href="http://arxiv.org/abs/2002.09589" target="_blank">arXiv:2002.09589</a> [<a href="http://arxiv.org/pdf/2002.09589" target="_blank">pdf</a>]

<h2>Rethinking 1D-CNN for Time Series Classification: A Stronger Baseline. (arXiv:2002.10061v2 [cs.LG] UPDATED)</h2>
<h3>Wensi Tang, Guodong Long, Lu Liu, Tianyi Zhou, Jing Jiang, Michael Blumenstein</h3>
<p>For time series classification task using 1D-CNN, the selection of kernel
size is critically important to ensure the model can capture the right scale
salient signal from a long time-series. Most of the existing work on 1D-CNN
treats the kernel size as a hyper-parameter and tries to find the proper kernel
size through a grid search which is time-consuming and is inefficient. This
paper theoretically analyses how kernel size impacts the performance of 1D-CNN.
Considering the importance of kernel size, we propose a novel Omni-Scale 1D-CNN
(OS-CNN) architecture to capture the proper kernel size during the model
learning period. A specific design for kernel size configuration is developed
which enables us to assemble very few kernel-size options to represent more
receptive fields. The proposed OS-CNN method is evaluated using the UCR archive
with 85 datasets. The experiment results demonstrate that our method is a
stronger baseline in multiple performance indicators, including the critical
difference diagram, counts of wins, and average accuracy. We also published the
experimental source codes at GitHub (https://github.com/Wensi-Tang/OS-CNN/).
</p>
<a href="http://arxiv.org/abs/2002.10061" target="_blank">arXiv:2002.10061</a> [<a href="http://arxiv.org/pdf/2002.10061" target="_blank">pdf</a>]

<h2>UAV Coverage Path Planning under Varying Power Constraints using Deep Reinforcement Learning. (arXiv:2003.02609v2 [cs.RO] UPDATED)</h2>
<h3>Mirco Theile, Harald Bayerlein, Richard Nai, David Gesbert, Marco Caccamo</h3>
<p>Coverage path planning (CPP) is the task of designing a trajectory that
enables a mobile agent to travel over every point of an area of interest. We
propose a new method to control an unmanned aerial vehicle (UAV) carrying a
camera on a CPP mission with random start positions and multiple options for
landing positions in an environment containing no-fly zones. While numerous
approaches have been proposed to solve similar CPP problems, we leverage
end-to-end reinforcement learning (RL) to learn a control policy that
generalizes over varying power constraints for the UAV. Despite recent
improvements in battery technology, the maximum flying range of small UAVs is
still a severe constraint, which is exacerbated by variations in the UAV's
power consumption that are hard to predict. By using map-like input channels to
feed spatial information through convolutional network layers to the agent, we
are able to train a double deep Q-network (DDQN) to make control decisions for
the UAV, balancing limited power budget and coverage goal. The proposed method
can be applied to a wide variety of environments and harmonizes complex goal
structures with system constraints.
</p>
<a href="http://arxiv.org/abs/2003.02609" target="_blank">arXiv:2003.02609</a> [<a href="http://arxiv.org/pdf/2003.02609" target="_blank">pdf</a>]

<h2>The value of text for small business default prediction: A deep learning approach. (arXiv:2003.08964v3 [cs.LG] UPDATED)</h2>
<h3>Matthew Stevenson, Christophe Mues, Cristi&#xe1;n Bravo</h3>
<p>Compared to consumer lending, Micro, Small and Medium Enterprise (mSME)
credit risk modelling is particularly challenging, as, often, the same sources
of information are not available. Therefore, it is standard policy for a loan
officer to provide a textual loan assessment to mitigate limited data
availability. In turn, this statement is analysed by a credit expert alongside
any available standard credit data. In our paper, we exploit recent advances
from the field of Deep Learning and Natural Language Processing (NLP),
including the BERT (Bidirectional Encoder Representations from Transformers)
model, to extract information from 60000 textual assessments provided by a
lender. We consider the performance in terms of the AUC (Area Under the
receiver operating characteristic Curve) and Brier Score metrics and find that
the text alone is surprisingly effective for predicting default. However, when
combined with traditional data, it yields no additional predictive capability,
with performance dependent on the text's length. Our proposed deep learning
model does, however, appear to be robust to the quality of the text and
therefore suitable for partly automating the mSME lending process. We also
demonstrate how the content of loan assessments influences performance, leading
us to a series of recommendations on a new strategy for collecting future mSME
loan assessments.
</p>
<a href="http://arxiv.org/abs/2003.08964" target="_blank">arXiv:2003.08964</a> [<a href="http://arxiv.org/pdf/2003.08964" target="_blank">pdf</a>]

<h2>Towards a theory of machine learning. (arXiv:2004.09280v4 [cs.LG] UPDATED)</h2>
<h3>Vitaly Vanchurin</h3>
<p>We define a neural network as a septuple consisting of (1) a state vector,
(2) an input projection, (3) an output projection, (4) a weight matrix, (5) a
bias vector, (6) an activation map and (7) a loss function. We argue that the
loss function can be imposed either on the boundary (i.e. input and/or output
neurons) or in the bulk (i.e. hidden neurons) for both supervised and
unsupervised systems. We apply the principle of maximum entropy to derive a
canonical ensemble of the state vectors subject to a constraint imposed on the
bulk loss function by a Lagrange multiplier (or an inverse temperature
parameter). We show that in an equilibrium the canonical partition function
must be a product of two factors: a function of the temperature and a function
of the bias vector and weight matrix. Consequently, the total Shannon entropy
consists of two terms which represent respectively a thermodynamic entropy and
a complexity of the neural network. We derive the first and second laws of
learning: during learning the total entropy must decrease until the system
reaches an equilibrium (i.e. the second law), and the increment in the loss
function must be proportional to the increment in the thermodynamic entropy
plus the increment in the complexity (i.e. the first law). We calculate the
entropy destruction to show that the efficiency of learning is given by the
Laplacian of the total free energy which is to be maximized in an optimal
neural architecture, and explain why the optimization condition is better
satisfied in a deep network with a large number of hidden layers. The key
properties of the model are verified numerically by training a supervised
feedforward neural network using the method of stochastic gradient descent. We
also discuss a possibility that the entire universe on its most fundamental
level is a neural network.
</p>
<a href="http://arxiv.org/abs/2004.09280" target="_blank">arXiv:2004.09280</a> [<a href="http://arxiv.org/pdf/2004.09280" target="_blank">pdf</a>]

<h2>Amortized Bayesian model comparison with evidential deep learning. (arXiv:2004.10629v3 [stat.ML] UPDATED)</h2>
<h3>Stefan T. Radev, Marco D&#x27;Alessandro, Paul-Christian B&#xfc;rkner, Ulf K. Mertens, Andreas Voss, Ullrich K&#xf6;the</h3>
<p>Comparing competing mathematical models of complex natural processes is a
shared goal among many branches of science. The Bayesian probabilistic
framework offers a principled way to perform model comparison and extract
useful metrics for guiding decisions. However, many interesting models are
intractable with standard Bayesian methods, as they lack a closed-form
likelihood function or the likelihood is computationally too expensive to
evaluate. With this work, we propose a novel method for performing Bayesian
model comparison using specialized deep learning architectures. Our method is
purely simulation-based and circumvents the step of explicitly fitting all
alternative models under consideration to each observed dataset. Moreover, it
involves no hand-crafted summary statistics of the data and is designed to
amortize the cost of simulation over multiple models and observable datasets.
This makes the method applicable in scenarios where model fit needs to be
assessed for a large number of datasets, so that per-dataset inference is
practically infeasible.Finally, we propose a novel way to measure epistemic
uncertainty in model comparison problems. We demonstrate the utility of our
method on toy examples and simulated data from non-trivial models from
cognitive science and single-cell neuroscience. We show that our method
achieves excellent results in terms of accuracy, calibration, and efficiency
across the examples considered in this work. We argue that our framework can
enhance and enrich model-based analysis and inference in many fields dealing
with computational models of natural processes. We further argue that the
proposed measure of epistemic uncertainty provides a unique proxy to quantify
absolute evidence even in a framework which assumes that the true
data-generating model is within a finite set of candidate models.
</p>
<a href="http://arxiv.org/abs/2004.10629" target="_blank">arXiv:2004.10629</a> [<a href="http://arxiv.org/pdf/2004.10629" target="_blank">pdf</a>]

<h2>Improving Sample Complexity Bounds for (Natural) Actor-Critic Algorithms. (arXiv:2004.12956v4 [cs.LG] UPDATED)</h2>
<h3>Tengyu Xu, Zhe Wang, Yingbin Liang</h3>
<p>The actor-critic (AC) algorithm is a popular method to find an optimal policy
in reinforcement learning. In the infinite horizon scenario, the finite-sample
convergence rate for the AC and natural actor-critic (NAC) algorithms has been
established recently, but under independent and identically distributed
(i.i.d.) sampling and single-sample update at each iteration. In contrast, this
paper characterizes the convergence rate and sample complexity of AC and NAC
under Markovian sampling, with mini-batch data for each iteration, and with
actor having general policy class approximation. We show that the overall
sample complexity for a mini-batch AC to attain an $\epsilon$-accurate
stationary point improves the best known sample complexity of AC by an order of
$\mathcal{O}(\epsilon^{-1}\log(1/\epsilon))$, and the overall sample complexity
for a mini-batch NAC to attain an $\epsilon$-accurate globally optimal point
improves the existing sample complexity of NAC by an order of
$\mathcal{O}(\epsilon^{-1}/\log(1/\epsilon))$. Moreover, the sample complexity
of AC and NAC characterized in this work outperforms that of policy gradient
(PG) and natural policy gradient (NPG) by a factor of
$\mathcal{O}((1-\gamma)^{-3})$ and
$\mathcal{O}((1-\gamma)^{-4}\epsilon^{-1}/\log(1/\epsilon))$, respectively.
This is the first theoretical study establishing that AC and NAC attain
orderwise performance improvement over PG and NPG under infinite horizon due to
the incorporation of critic.
</p>
<a href="http://arxiv.org/abs/2004.12956" target="_blank">arXiv:2004.12956</a> [<a href="http://arxiv.org/pdf/2004.12956" target="_blank">pdf</a>]

<h2>Learning natural locomotion behaviors for humanoid robots using human knowledge. (arXiv:2005.10195v2 [cs.RO] UPDATED)</h2>
<h3>Chuanyu Yang, Kai Yuan, Shuai Heng, Taku Komura, Zhibin Li</h3>
<p>This paper presents a new learning framework that leverages the knowledge
from imitation learning, deep reinforcement learning, and control theories to
achieve human-style locomotion that is natural, dynamic, and robust for
humanoids. We proposed novel approaches to introduce human bias, i.e. motion
capture data and a special Multi-Expert network structure. We used the
Multi-Expert network structure to smoothly blend behavioral features, and used
the augmented reward design for the task and imitation rewards. Our reward
design is composable, tunable, and explainable by using fundamental concepts
from conventional humanoid control. We rigorously validated and benchmarked the
learning framework which consistently produced robust locomotion behaviors in
various test scenarios. Further, we demonstrated the capability of learning
robust and versatile policies in the presence of disturbances, such as terrain
irregularities and external pushes.
</p>
<a href="http://arxiv.org/abs/2005.10195" target="_blank">arXiv:2005.10195</a> [<a href="http://arxiv.org/pdf/2005.10195" target="_blank">pdf</a>]

<h2>Graphical Normalizing Flows. (arXiv:2006.02548v3 [cs.LG] UPDATED)</h2>
<h3>Antoine Wehenkel, Gilles Louppe</h3>
<p>Normalizing flows model complex probability distributions by combining a base
distribution with a series of bijective neural networks. State-of-the-art
architectures rely on coupling and autoregressive transformations to lift up
invertible functions from scalars to vectors. In this work, we revisit these
transformations as probabilistic graphical models, showing they reduce to
Bayesian networks with a pre-defined topology and a learnable density at each
node. From this new perspective, we propose the graphical normalizing flow, a
new invertible transformation with either a prescribed or a learnable graphical
structure. This model provides a promising way to inject domain knowledge into
normalizing flows while preserving both the interpretability of Bayesian
networks and the representation capacity of normalizing flows. We show that
graphical conditioners discover relevant graph structure when we cannot
hypothesize it. In addition, we analyze the effect of $\ell_1$-penalization on
the recovered structure and on the quality of the resulting density estimation.
Finally, we show that graphical conditioners lead to competitive white box
density estimators. Our implementation is available at
https://github.com/AWehenkel/DAG-NF.
</p>
<a href="http://arxiv.org/abs/2006.02548" target="_blank">arXiv:2006.02548</a> [<a href="http://arxiv.org/pdf/2006.02548" target="_blank">pdf</a>]

<h2>Banach Space Representer Theorems for Neural Networks and Ridge Splines. (arXiv:2006.05626v3 [stat.ML] UPDATED)</h2>
<h3>Rahul Parhi, Robert D. Nowak</h3>
<p>We develop a variational framework to understand the properties of the
functions learned by neural networks fit to data. We propose and study a family
of continuous-domain linear inverse problems with total variation-like
regularization in the Radon domain subject to data fitting constraints. We
derive a representer theorem showing that finite-width, single-hidden layer
neural networks are solutions to these inverse problems. We draw on many
techniques from variational spline theory and so we propose the notion of
polynomial ridge splines, which correspond to single-hidden layer neural
networks with truncated power functions as the activation function. The
representer theorem is reminiscent of the classical reproducing kernel Hilbert
space representer theorem, but we show that the neural network problem is posed
over a non-Hilbertian Banach space. While the learning problems are posed in
the continuous-domain, similar to kernel methods, the problems can be recast as
finite-dimensional neural network training problems. These neural network
training problems have regularizers which are related to the well-known weight
decay and path-norm regularizers. Thus, our result gives insight into
functional characteristics of trained neural networks and also into the design
neural network regularizers. We also show that these regularizers promote
neural network solutions with desirable generalization properties.
</p>
<a href="http://arxiv.org/abs/2006.05626" target="_blank">arXiv:2006.05626</a> [<a href="http://arxiv.org/pdf/2006.05626" target="_blank">pdf</a>]

<h2>Deterministic Neural SDEs for Affordable Uncertainty Quantification. (arXiv:2006.08973v3 [cs.LG] UPDATED)</h2>
<h3>Andreas Look, Melih Kandemir, Jan Peters</h3>
<p>Neural Stochastic Differential Equations (NSDEs) model the drift and
diffusion functions of a stochastic process as neural networks. While NSDEs are
known to predict time series accurately, their uncertainty quantification
properties remain unexplored. We report the empirical finding that obtaining
well-calibrated uncertainty estimations from NSDEs is computationally
prohibitive. As a remedy, we develop a computationally affordable deterministic
scheme for expressing the likelihood of a sequence, when dynamics is governed
by a NSDE, which is applicable to both training and prediction. Our method
introduces a bidirectional moment matching scheme, one vertical along the
neural net layers, and one horizontal along the time direction, which benefits
from an original combination of effective approximations. We observe in
multiple experiments that the uncertainty calibration quality of our method can
be matched by Monte Carlo sampling only after introducing at least five times
more computation cost. Thanks to the numerical stability of deterministic
training, our method also provides improvement in prediction accuracy.
</p>
<a href="http://arxiv.org/abs/2006.08973" target="_blank">arXiv:2006.08973</a> [<a href="http://arxiv.org/pdf/2006.08973" target="_blank">pdf</a>]

<h2>Robust Reinforcement Learning using Least Squares Policy Iteration with Provable Performance Guarantees. (arXiv:2006.11608v4 [cs.LG] UPDATED)</h2>
<h3>Kishan Panaganti, Dileep Kalathil</h3>
<p>This paper addresses the problem of model-free reinforcement learning for
Robust Markov Decision Process (RMDP) with large state spaces. The goal of the
RMDP framework is to find a policy that is robust against the parameter
uncertainties due to the mismatch between the simulator model and real-world
settings. We first propose the Robust Least Squares Policy Evaluation
algorithm, which is a multi-step online model-free learning algorithm for
policy evaluation. We prove the convergence of this algorithm using stochastic
approximation techniques. We then propose Robust Least Squares Policy Iteration
(RLSPI) algorithm for learning the optimal robust policy. We also give a
general weighted Euclidean norm bound on the error (closeness to optimality) of
the resulting policy. Finally, we demonstrate the performance of our RLSPI
algorithm on some standard benchmark problems.
</p>
<a href="http://arxiv.org/abs/2006.11608" target="_blank">arXiv:2006.11608</a> [<a href="http://arxiv.org/pdf/2006.11608" target="_blank">pdf</a>]

<h2>A Dynamical Systems Approach for Convergence of the Bayesian EM Algorithm. (arXiv:2006.12690v2 [cs.LG] UPDATED)</h2>
<h3>Orlando Romero, Subhro Das, Pin-Yu Chen, S&#xe9;rgio Pequito</h3>
<p>Out of the recent advances in systems and control (S\&amp;C)-based analysis of
optimization algorithms, not enough work has been specifically dedicated to
machine learning (ML) algorithms and its applications. This paper addresses
this gap by illustrating how (discrete-time) Lyapunov stability theory can
serve as a powerful tool to aid, or even lead, in the analysis (and potential
design) of optimization algorithms that are not necessarily gradient-based. The
particular ML problem that this paper focuses on is that of parameter
estimation in an incomplete-data Bayesian framework via the popular
optimization algorithm known as maximum a posteriori expectation-maximization
(MAP-EM). Following first principles from dynamical systems stability theory,
conditions for convergence of MAP-EM are developed. Furthermore, if additional
assumptions are met, we show that fast convergence (linear or quadratic) is
achieved, which could have been difficult to unveil without our adopted S\&amp;C
approach. The convergence guarantees in this paper effectively expand the set
of sufficient conditions for EM applications, thereby demonstrating the
potential of similar S\&amp;C-based convergence analysis of other ML algorithms.
</p>
<a href="http://arxiv.org/abs/2006.12690" target="_blank">arXiv:2006.12690</a> [<a href="http://arxiv.org/pdf/2006.12690" target="_blank">pdf</a>]

<h2>NASTransfer: Analyzing Architecture Transferability in Large Scale Neural Architecture Search. (arXiv:2006.13314v2 [cs.CV] UPDATED)</h2>
<h3>Rameswar Panda, Michele Merler, Mayoore Jaiswal, Hui Wu, Kandan Ramakrishnan, Ulrich Finkler, Chun-Fu Chen, Minsik Cho, David Kung, Rogerio Feris, Bishwaranjan Bhattacharjee</h3>
<p>Neural Architecture Search (NAS) is an open and challenging problem in
machine learning. While NAS offers great promise, the prohibitive computational
demand of most of the existing NAS methods makes it difficult to directly
search the architectures on large-scale tasks. The typical way of conducting
large scale NAS is to search for an architectural building block on a small
dataset (either using a proxy set from the large dataset or a completely
different small scale dataset) and then transfer the block to a larger dataset.
Despite a number of recent results that show the promise of transfer from proxy
datasets, a comprehensive evaluation of different NAS methods studying the
impact of different source datasets has not yet been addressed. In this work,
we propose to analyze the architecture transferability of different NAS methods
by performing a series of experiments on large scale benchmarks such as
ImageNet1K and ImageNet22K. We find that: (i) The size and domain of the proxy
set does not seem to influence architecture performance on the target dataset.
On average, transfer performance of architectures searched using completely
different small datasets (e.g., CIFAR10) perform similarly to the architectures
searched directly on proxy target datasets. However, design of proxy sets has
considerable impact on rankings of different NAS methods. (ii) While different
NAS methods show similar performance on a source dataset (e.g., CIFAR10), they
significantly differ on the transfer performance to a large dataset (e.g.,
ImageNet1K). (iii) Even on large datasets, random sampling baseline is very
competitive, but the choice of the appropriate combination of proxy set and
search strategy can provide significant improvement over it. We believe that
our extensive empirical analysis will prove useful for future design of NAS
algorithms.
</p>
<a href="http://arxiv.org/abs/2006.13314" target="_blank">arXiv:2006.13314</a> [<a href="http://arxiv.org/pdf/2006.13314" target="_blank">pdf</a>]

<h2>RL Unplugged: A Suite of Benchmarks for Offline Reinforcement Learning. (arXiv:2006.13888v4 [cs.LG] UPDATED)</h2>
<h3>Caglar Gulcehre, Ziyu Wang, Alexander Novikov, Tom Le Paine, Sergio Gomez Colmenarejo, Konrad Zolna, Rishabh Agarwal, Josh Merel, Daniel Mankowitz, Cosmin Paduraru, Gabriel Dulac-Arnold, Jerry Li, Mohammad Norouzi, Matt Hoffman, Ofir Nachum, George Tucker, Nicolas Heess, Nando de Freitas</h3>
<p>Offline methods for reinforcement learning have a potential to help bridge
the gap between reinforcement learning research and real-world applications.
They make it possible to learn policies from offline datasets, thus overcoming
concerns associated with online data collection in the real-world, including
cost, safety, or ethical concerns. In this paper, we propose a benchmark called
RL Unplugged to evaluate and compare offline RL methods. RL Unplugged includes
data from a diverse range of domains including games ({\em e.g.,} Atari
benchmark) and simulated motor control problems ({\em e.g.,} DM Control Suite).
The datasets include domains that are partially or fully observable, use
continuous or discrete actions, and have stochastic vs. deterministic dynamics.
We propose detailed evaluation protocols for each domain in RL Unplugged and
provide an extensive analysis of supervised learning and offline RL methods
using these protocols. We will release data for all our tasks and open-source
all algorithms presented in this paper. We hope that our suite of benchmarks
will increase the reproducibility of experiments and make it possible to study
challenging tasks with a limited computational budget, thus making RL research
both more systematic and more accessible across the community. Moving forward,
we view RL Unplugged as a living benchmark suite that will evolve and grow with
datasets contributed by the research community and ourselves. Our project page
is available on https://git.io/JJUhd.
</p>
<a href="http://arxiv.org/abs/2006.13888" target="_blank">arXiv:2006.13888</a> [<a href="http://arxiv.org/pdf/2006.13888" target="_blank">pdf</a>]

<h2>Object Detection Under Rainy Conditions for Autonomous Vehicles: A Review of State-of-the-Art and Emerging Techniques. (arXiv:2006.16471v4 [cs.CV] UPDATED)</h2>
<h3>Mazin Hnewa, Hayder Radha</h3>
<p>Advanced automotive active-safety systems, in general, and autonomous
vehicles, in particular, rely heavily on visual data to classify and localize
objects such as pedestrians, traffic signs and lights, and other nearby cars,
to assist the corresponding vehicles maneuver safely in their environments.
However, the performance of object detection methods could degrade rather
significantly under challenging weather scenarios including rainy conditions.
Despite major advancements in the development of deraining approaches, the
impact of rain on object detection has largely been understudied, especially in
the context of autonomous driving. The main objective of this paper is to
present a tutorial on state-of-the-art and emerging techniques that represent
leading candidates for mitigating the influence of rainy conditions on an
autonomous vehicle's ability to detect objects. Our goal includes surveying and
analyzing the performance of object detection methods trained and tested using
visual data captured under clear and rainy conditions. Moreover, we survey and
evaluate the efficacy and limitations of leading deraining approaches,
deep-learning based domain adaptation, and image translation frameworks that
are being considered for addressing the problem of object detection under rainy
conditions. Experimental results of a variety of the surveyed techniques are
presented as part of this tutorial.
</p>
<a href="http://arxiv.org/abs/2006.16471" target="_blank">arXiv:2006.16471</a> [<a href="http://arxiv.org/pdf/2006.16471" target="_blank">pdf</a>]

<h2>Variable Selection via Thompson Sampling. (arXiv:2007.00187v2 [cs.LG] UPDATED)</h2>
<h3>Yi Liu, Veronika Rockova</h3>
<p>Thompson sampling is a heuristic algorithm for the multi-armed bandit problem
which has a long tradition in machine learning. The algorithm has a Bayesian
spirit in the sense that it selects arms based on posterior samples of reward
probabilities of each arm. By forging a connection between combinatorial binary
bandits and spike-and-slab variable selection, we propose a stochastic
optimization approach to subset selection called Thompson Variable Selection
(TVS). TVS is a framework for interpretable machine learning which does not
rely on the underlying model to be linear. TVS brings together Bayesian
reinforcement and machine learning in order to extend the reach of Bayesian
subset selection to non-parametric models and large datasets with very many
predictors and/or very many observations. Depending on the choice of a reward,
TVS can be deployed in offline as well as online setups with streaming data
batches. Tailoring multiplay bandits to variable selection, we provide regret
bounds without necessarily assuming that the arm mean rewards be unrelated. We
show a very strong empirical performance on both simulated and real data.
Unlike deterministic optimization methods for spike-and-slab variable
selection, the stochastic nature makes TVS less prone to local convergence and
thereby more robust.
</p>
<a href="http://arxiv.org/abs/2007.00187" target="_blank">arXiv:2007.00187</a> [<a href="http://arxiv.org/pdf/2007.00187" target="_blank">pdf</a>]

<h2>Towards Practical Lipreading with Distilled and Efficient Models. (arXiv:2007.06504v2 [cs.CV] UPDATED)</h2>
<h3>Pingchuan Ma, Brais Martinez, Stavros Petridis, Maja Pantic</h3>
<p>Lipreading has witnessed a lot of progress due to the resurgence of neural
networks. Recent works have placed emphasis on aspects such as improving
performance by finding the optimal architecture or improving generalization.
However, there is still a significant gap between the current methodologies and
the requirements for an effective deployment of lipreading in practical
scenarios. In this work, we propose a series of innovations that significantly
bridge that gap: first, we raise the state-of-the-art performance by a wide
margin on LRW and LRW-1000 to 88.5% and 46.6%, respectively using
self-distillation. Secondly, we propose a series of architectural changes,
including a novel Depthwise Separable Temporal Convolutional Network (DS-TCN)
head, that slashes the computational cost to a fraction of the (already quite
efficient) original model. Thirdly, we show that knowledge distillation is a
very effective tool for recovering performance of the lightweight models. This
results in a range of models with different accuracy-efficiency trade-offs.
However, our most promising lightweight models are on par with the current
state-of-the-art while showing a reduction of 8.2x and 3.9x in terms of
computational cost and number of parameters, respectively, which we hope will
enable the deployment of lipreading models in practical applications.
</p>
<a href="http://arxiv.org/abs/2007.06504" target="_blank">arXiv:2007.06504</a> [<a href="http://arxiv.org/pdf/2007.06504" target="_blank">pdf</a>]

<h2>Learning Robust State Abstractions for Hidden-Parameter Block MDPs. (arXiv:2007.07206v4 [cs.LG] UPDATED)</h2>
<h3>Amy Zhang, Shagun Sodhani, Khimya Khetarpal, Joelle Pineau</h3>
<p>Many control tasks exhibit similar dynamics that can be modeled as having
common latent structure. Hidden-Parameter Markov Decision Processes (HiP-MDPs)
explicitly model this structure to improve sample efficiency in multi-task
settings. However, this setting makes strong assumptions on the observability
of the state that limit its application in real-world scenarios with rich
observation spaces. In this work, we leverage ideas of common structure from
the HiP-MDP setting, and extend it to enable robust state abstractions inspired
by Block MDPs. We derive instantiations of this new framework for both
multi-task reinforcement learning (MTRL) and meta-reinforcement learning
(Meta-RL) settings. Further, we provide transfer and generalization bounds
based on task and state similarity, along with sample complexity bounds that
depend on the aggregate number of samples across tasks, rather than the number
of tasks, a significant improvement over prior work that use the same
environment assumptions. To further demonstrate the efficacy of the proposed
method, we empirically compare and show improvement over multi-task and
meta-reinforcement learning baselines.
</p>
<a href="http://arxiv.org/abs/2007.07206" target="_blank">arXiv:2007.07206</a> [<a href="http://arxiv.org/pdf/2007.07206" target="_blank">pdf</a>]

<h2>Lifelong Incremental Reinforcement Learning with Online Bayesian Inference. (arXiv:2007.14196v2 [cs.LG] UPDATED)</h2>
<h3>Zhi Wang, Chunlin Chen, Daoyi Dong</h3>
<p>A central capability of a long-lived reinforcement learning (RL) agent is to
incrementally adapt its behavior as its environment changes, and to
incrementally build upon previous experiences to facilitate future learning in
real-world scenarios. In this paper, we propose LifeLong Incremental
Reinforcement Learning (LLIRL), a new incremental algorithm for efficient
lifelong adaptation to dynamic environments. We develop and maintain a library
that contains an infinite mixture of parameterized environment models, which is
equivalent to clustering environment parameters in a latent space. The prior
distribution over the mixture is formulated as a Chinese restaurant process
(CRP), which incrementally instantiates new environment models without any
external information to signal environmental changes in advance. During
lifelong learning, we employ the expectation maximization (EM) algorithm with
online Bayesian inference to update the mixture in a fully incremental manner.
In EM, the E-step involves estimating the posterior expectation of
environment-to-cluster assignments, while the M-step updates the environment
parameters for future learning. This method allows for all environment models
to be adapted as necessary, with new models instantiated for environmental
changes and old models retrieved when previously seen environments are
encountered again. Experiments demonstrate that LLIRL outperforms relevant
existing methods, and enables effective incremental adaptation to various
dynamic environments for lifelong learning.
</p>
<a href="http://arxiv.org/abs/2007.14196" target="_blank">arXiv:2007.14196</a> [<a href="http://arxiv.org/pdf/2007.14196" target="_blank">pdf</a>]

<h2>Langevin Monte Carlo: random coordinate descent and variance reduction. (arXiv:2007.14209v3 [stat.ML] UPDATED)</h2>
<h3>Zhiyan Ding, Qin Li</h3>
<p>Sampling from a log-concave distribution function on $\mathbb{R}^d$ (with
$d\gg 1$) is a popular problem that has wide applications. In this paper we
study the application of random coordinate descent method (RCD) on the Langevin
Monte Carlo (LMC) sampling method, and we find two sides of the theory:

1. The direct application of RCD on LMC does reduce the number of finite
differencing approximations per iteration, but it induces a large variance
error term. More iterations are then needed, and ultimately the method gains no
computational advantage;

2. When variance reduction techniques (such as SAGA and SVRG) are
incorporated in RCD-LMC, the variance error term is reduced. The new methods,
compared to the vanilla LMC, reduce the total computational cost by $d$ folds,
and achieve the optimal cost rate.

We perform our investigations in both overdamped and underdamped settings.
</p>
<a href="http://arxiv.org/abs/2007.14209" target="_blank">arXiv:2007.14209</a> [<a href="http://arxiv.org/pdf/2007.14209" target="_blank">pdf</a>]

<h2>DeLighT: Deep and Light-weight Transformer. (arXiv:2008.00623v2 [cs.LG] UPDATED)</h2>
<h3>Sachin Mehta, Marjan Ghazvininejad, Srinivasan Iyer, Luke Zettlemoyer, Hannaneh Hajishirzi</h3>
<p>We introduce a deep and light-weight transformer, DeLighT, that delivers
similar or better performance than standard transformer-based models with
significantly fewer parameters. DeLighT more efficiently allocates parameters
both (1) within each Transformer block using the DeLighT transformation, a deep
and light-weight transformation, and (2) across blocks using block-wise
scaling, which allows for shallower and narrower DeLighT blocks near the input
and wider and deeper DeLighT blocks near the output. Overall, DeLighT networks
are 2.5 to 4 times deeper than standard transformer models and yet have fewer
parameters and operations. Experiments on benchmark machine translation and
language modeling tasks show that DeLighT matches or improves the performance
of baseline Transformers with 2 to 3 times fewer parameters on average. Our
source code is available at: \url{https://github.com/sacmehta/delight}
</p>
<a href="http://arxiv.org/abs/2008.00623" target="_blank">arXiv:2008.00623</a> [<a href="http://arxiv.org/pdf/2008.00623" target="_blank">pdf</a>]

<h2>Offline Meta Learning of Exploration. (arXiv:2008.02598v3 [cs.LG] UPDATED)</h2>
<h3>Ron Dorfman, Idan Shenfeld, Aviv Tamar</h3>
<p>Consider the following instance of the Offline Meta Reinforcement Learning
(OMRL) problem: given the complete training logs of $N$ conventional RL agents,
trained on $N$ different tasks, design a meta-agent that can quickly maximize
reward in a new, unseen task from the same task distribution. In particular,
while each conventional RL agent explored and exploited its own different task,
the meta-agent must identify regularities in the data that lead to effective
exploration/exploitation in the unseen task. Here, we take a Bayesian RL (BRL)
view, and seek to learn a Bayes-optimal policy from the offline data. Building
on the recent VariBAD BRL approach, we develop an off-policy BRL method that
learns to plan an exploration strategy based on an adaptive neural belief
estimate. However, learning to infer such a belief from offline data brings a
new identifiability issue we term MDP ambiguity. We characterize the problem,
and suggest resolutions via data collection and modification procedures.
Finally, we evaluate our framework on a diverse set of domains, including
difficult sparse reward tasks, and demonstrate learning of effective
exploration behavior that is qualitatively different from the exploration used
by any RL agent in the data.
</p>
<a href="http://arxiv.org/abs/2008.02598" target="_blank">arXiv:2008.02598</a> [<a href="http://arxiv.org/pdf/2008.02598" target="_blank">pdf</a>]

<h2>Decoupling Exploration and Exploitation for Meta-Reinforcement Learning without Sacrifices. (arXiv:2008.02790v2 [cs.LG] UPDATED)</h2>
<h3>Evan Zheran Liu, Aditi Raghunathan, Percy Liang, Chelsea Finn</h3>
<p>The goal of meta-reinforcement learning (meta-RL) is to build agents that can
quickly learn new tasks by leveraging prior experience on related tasks.
Learning a new task often requires both exploring to gather task-relevant
information and exploiting this information to solve the task. In principle,
optimal exploration and exploitation can be learned end-to-end by simply
maximizing task performance. However, such meta-RL approaches struggle with
local optima due to a chicken-and-egg problem: learning to explore requires
good exploitation to gauge the exploration's utility, but learning to exploit
requires information gathered via exploration. Optimizing separate objectives
for exploration and exploitation can avoid this problem, but prior meta-RL
exploration objectives yield suboptimal policies that gather information
irrelevant to the task. We alleviate both concerns by constructing an
exploitation objective that automatically identifies task-relevant information
and an exploration objective to recover only this information. This avoids
local optima in end-to-end training, without sacrificing optimal exploration.
Empirically, DREAM substantially outperforms existing approaches on complex
meta-RL problems, such as sparse-reward 3D visual navigation. Videos of DREAM:
https://ezliu.github.io/dream/
</p>
<a href="http://arxiv.org/abs/2008.02790" target="_blank">arXiv:2008.02790</a> [<a href="http://arxiv.org/pdf/2008.02790" target="_blank">pdf</a>]

<h2>A Discriminative Technique for Multiple-Source Adaptation. (arXiv:2008.11036v2 [cs.LG] UPDATED)</h2>
<h3>Corinna Cortes, Mehryar Mohri, Ananda Theertha Suresh, Ningshan Zhang</h3>
<p>We present a new discriminative technique for the multiple-source adaptation,
MSA, problem. Unlike previous work, which relies on density estimation for each
source domain, our solution only requires conditional probabilities that can
easily be accurately estimated from unlabeled data from the source domains. We
give a detailed analysis of our new technique, including general guarantees
based on R\'enyi divergences, and learning bounds when conditional Maxent is
used for estimating conditional probabilities for a point to belong to a source
domain. We show that these guarantees compare favorably to those that can be
derived for the generative solution, using kernel density estimation. Our
experiments with real-world applications further demonstrate that our new
discriminative MSA algorithm outperforms the previous generative solution as
well as other domain adaptation baselines.
</p>
<a href="http://arxiv.org/abs/2008.11036" target="_blank">arXiv:2008.11036</a> [<a href="http://arxiv.org/pdf/2008.11036" target="_blank">pdf</a>]

<h2>Exploring the Interchangeability of CNN Embedding Spaces. (arXiv:2010.02323v4 [cs.CV] UPDATED)</h2>
<h3>David McNeely-White, Benjamin Sattelberg, Nathaniel Blanchard, Ross Beveridge</h3>
<p>CNN feature spaces can be linearly mapped and consequently are often
interchangeable. This equivalence holds across variations in architectures,
training datasets, and network tasks. Specifically, we mapped between 10
image-classification CNNs and between 4 facial-recognition CNNs. When image
embeddings generated by one CNN are transformed into embeddings corresponding
to the feature space of a second CNN trained on the same task, their respective
image classification or face verification performance is largely preserved. For
CNNs trained to the same classes and sharing a common backend-logit (soft-max)
architecture, a linear-mapping may always be calculated directly from the
backend layer weights. However, the case of a closed-set analysis with perfect
knowledge of classifiers is limiting. Therefore, empirical methods of
estimating mappings are presented for both the closed-set image classification
task and the open-set task of face recognition. The results presented expose
the essentially interchangeable nature of CNNs embeddings for two important and
common recognition tasks. The implications are far-reaching, suggesting an
underlying commonality between representations learned by networks designed and
trained for a common task. One practical implication is that face embeddings
from some commonly used CNNs can be compared using these mappings.
</p>
<a href="http://arxiv.org/abs/2010.02323" target="_blank">arXiv:2010.02323</a> [<a href="http://arxiv.org/pdf/2010.02323" target="_blank">pdf</a>]

<h2>UneVEn: Universal Value Exploration for Multi-Agent Reinforcement Learning. (arXiv:2010.02974v2 [cs.LG] UPDATED)</h2>
<h3>Tarun Gupta, Anuj Mahajan, Bei Peng, Wendelin B&#xf6;hmer, Shimon Whiteson</h3>
<p>VDN and QMIX are two popular value-based algorithms for cooperative MARL that
learn a centralized action value function as a monotonic mixing of per-agent
utilities. While this enables easy decentralization of the learned policy, the
restricted joint action value function can prevent them from solving tasks that
require significant coordination between agents at a given timestep. We show
that this problem can be overcome by improving the joint exploration of all
agents during training. Specifically, we propose a novel MARL approach called
Universal Value Exploration (UneVEn) that learns a set of related tasks
simultaneously with a linear decomposition of universal successor features.
With the policies of already solved related tasks, the joint exploration
process of all agents can be improved to help them achieve better coordination.
Empirical results on a set of exploration games, challenging cooperative
predator-prey tasks requiring significant coordination among agents, and
StarCraft II micromanagement benchmarks show that UneVEn can solve tasks where
other state-of-the-art MARL methods fail.
</p>
<a href="http://arxiv.org/abs/2010.02974" target="_blank">arXiv:2010.02974</a> [<a href="http://arxiv.org/pdf/2010.02974" target="_blank">pdf</a>]

<h2>Optimal quantisation of probability measures using maximum mean discrepancy. (arXiv:2010.07064v4 [stat.ML] UPDATED)</h2>
<h3>Onur Teymur, Jackson Gorham, Marina Riabiz, Chris. J. Oates</h3>
<p>Several researchers have proposed minimisation of maximum mean discrepancy
(MMD) as a method to quantise probability measures, i.e., to approximate a
target distribution by a representative point set. We consider sequential
algorithms that greedily minimise MMD over a discrete candidate set. We propose
a novel non-myopic algorithm and, in order to both improve statistical
efficiency and reduce computational cost, we investigate a variant that applies
this technique to a mini-batch of the candidate set at each iteration. When the
candidate points are sampled from the target, the consistency of these new
algorithm - and their mini-batch variants - is established. We demonstrate the
algorithms on a range of important computational problems, including
optimisation of nodes in Bayesian cubature and the thinning of Markov chain
output.
</p>
<a href="http://arxiv.org/abs/2010.07064" target="_blank">arXiv:2010.07064</a> [<a href="http://arxiv.org/pdf/2010.07064" target="_blank">pdf</a>]

<h2>Physics-informed GANs for Coastal Flood Visualization. (arXiv:2010.08103v2 [cs.CV] UPDATED)</h2>
<h3>Bj&#xf6;rn L&#xfc;tjens, Brandon Leshchinskiy, Christian Requena-Mesa, Farrukh Chishtie, Natalia D&#xed;az-Rodriguez, Oc&#xe9;ane Boulais, Aaron Pi&#xf1;a, Dava Newman, Alexander Lavin, Yarin Gal, Chedy Ra&#xef;ssi</h3>
<p>As climate change increases the intensity of natural disasters, society needs
better tools for adaptation. Floods, for example, are the most frequent natural
disaster, but during hurricanes the area is largely covered by clouds and
emergency managers must rely on nonintuitive flood visualizations for mission
planning. To assist these emergency managers, we have created a deep learning
pipeline that generates visual satellite images of current and future coastal
flooding. We advanced a state-of-the-art GAN called pix2pixHD, such that it
produces imagery that is physically-consistent with the output of an
expert-validated storm surge model (NOAA SLOSH). By evaluating the imagery
relative to physics-based flood maps, we find that our proposed framework
outperforms baseline models in both physical-consistency and photorealism.
While this work focused on the visualization of coastal floods, we envision the
creation of a global visualization of how climate change will shape our earth.
</p>
<a href="http://arxiv.org/abs/2010.08103" target="_blank">arXiv:2010.08103</a> [<a href="http://arxiv.org/pdf/2010.08103" target="_blank">pdf</a>]

<h2>Minimax Quasi-Bayesian estimation in sparse canonical correlation analysis via a Rayleigh quotient function. (arXiv:2010.08627v2 [stat.ML] UPDATED)</h2>
<h3>Qiuyun Zhu, Yves Atchade</h3>
<p>Canonical correlation analysis (CCA) is a popular statistical technique for
exploring the relationship between datasets. The estimation of sparse canonical
correlation vectors has emerged in recent years as an important but challenging
variation of the CCA problem, with widespread applications. Currently available
rate-optimal estimators for sparse canonical correlation vectors are expensive
to compute. We propose a quasi-Bayesian estimation procedure that achieves the
minimax estimation rate, and yet is easy to compute by Markov Chain Monte Carlo
(MCMC). The method builds on ([37]) and uses a re-scaled Rayleigh quotient
function as a quasi-log-likelihood. However unlike these authors, we adopt a
Bayesian framework that combines this quasi-log-likelihood with a
spike-and-slab prior that serves to regularize the inference and promote
sparsity. We investigated the empirical behavior of the proposed method on both
continuous and truncated data, and we noted that it outperforms several
state-of-the-art methods. As an application, we use the methodology to
maximally correlate clinical variables and proteomic data for a better
understanding of covid-19 disease.
</p>
<a href="http://arxiv.org/abs/2010.08627" target="_blank">arXiv:2010.08627</a> [<a href="http://arxiv.org/pdf/2010.08627" target="_blank">pdf</a>]

<h2>Two-sample Test using Projected Wasserstein Distance: Breaking the Curse of Dimensionality. (arXiv:2010.11970v2 [stat.ML] UPDATED)</h2>
<h3>Jie Wang, Rui Gao, Yao Xie</h3>
<p>We develop a projected Wasserstein distance for the two-sample test, a
fundamental problem in statistics and machine learning: given two sets of
samples, to determine whether they are from the same distribution. In
particular, we aim to circumvent the curse of dimensionality in Wasserstein
distance: when the dimension is high, it has diminishing testing power, which
is inherently due to the slow concentration property of Wasserstein metrics in
the high dimension space. A key contribution is to couple optimal projection to
find the low dimensional linear mapping to maximize the Wasserstein distance
between projected probability distributions. We characterize the theoretical
property of the finite-sample convergence rate on IPMs and present practical
algorithms for computing this metric. Numerical examples validate our
theoretical results.
</p>
<a href="http://arxiv.org/abs/2010.11970" target="_blank">arXiv:2010.11970</a> [<a href="http://arxiv.org/pdf/2010.11970" target="_blank">pdf</a>]

<h2>Approximation Methods for Kernelized Bandits. (arXiv:2010.12167v3 [cs.LG] UPDATED)</h2>
<h3>Sho Takemori, Masahiro Sato</h3>
<p>The RKHS bandit problem (also called kernelized multi-armed bandit problem)
is an online optimization problem of non-linear functions with noisy feedback.
Although the problem has been extensively studied, there are unsatisfactory
results for some problems compared to the well-studied linear bandit case.
Specifically, there is no general algorithm for the adversarial RKHS bandit
problem. In addition, high computational complexity of existing algorithms
hinders practical application. We address these issues by considering a novel
amalgamation of approximation theory and the misspecified linear bandit
problem. Using an approximation method, we propose efficient algorithms for the
stochastic RKHS bandit problem and the first general algorithm for the
adversarial RKHS bandit problem. Furthermore, we empirically confirm one of our
theoretical results, i.e., we demonstrate that our proposed method has
comparable cumulative regret to IGP-UCB and its running time is much shorter.
</p>
<a href="http://arxiv.org/abs/2010.12167" target="_blank">arXiv:2010.12167</a> [<a href="http://arxiv.org/pdf/2010.12167" target="_blank">pdf</a>]

<h2>Socially-Compatible Behavior Design of Autonomous Vehicles with Verification on Real Human Data. (arXiv:2010.14712v5 [cs.RO] UPDATED)</h2>
<h3>Letian Wang, Liting Sun, Masayoshi Tomizuka, Wei Zhan</h3>
<p>As more and more autonomous vehicles (AVs) are being deployed on public
roads, designing socially compatible behaviors for them is becoming
increasingly important. In order to generate safe and efficient actions, AVs
need to not only predict the future behaviors of other traffic participants,
but also be aware of the uncertainties associated with such behavior
prediction. In this paper, we propose an uncertain-aware integrated prediction
and planning (UAPP) framework. It allows the AVs to infer the characteristics
of other road users online and generate behaviors optimizing not only their own
rewards, but also their courtesy to others, and their confidence regarding the
prediction uncertainties. We first propose the definitions for courtesy and
confidence. Based on that, their influences on the behaviors of AVs in
interactive driving scenarios are explored. Moreover, we evaluate the proposed
algorithm on naturalistic human driving data by comparing the generated
behavior against ground truth. Results show that the online inference can
significantly improve the human-likeness of the generated behaviors.
Furthermore, we find that human drivers show great courtesy to others, even for
those without right-of-way. We also find that such driving preferences vary
significantly in different cultures.
</p>
<a href="http://arxiv.org/abs/2010.14712" target="_blank">arXiv:2010.14712</a> [<a href="http://arxiv.org/pdf/2010.14712" target="_blank">pdf</a>]

<h2>Panoster: End-to-end Panoptic Segmentation of LiDAR Point Clouds. (arXiv:2010.15157v2 [cs.CV] UPDATED)</h2>
<h3>Stefano Gasperini, Mohammad-Ali Nikouei Mahani, Alvaro Marcos-Ramiro, Nassir Navab, Federico Tombari</h3>
<p>Panoptic segmentation has recently unified semantic and instance
segmentation, previously addressed separately, thus taking a step further
towards creating more comprehensive and efficient perception systems. In this
paper, we present Panoster, a novel proposal-free panoptic segmentation method
for LiDAR point clouds. Unlike previous approaches relying on several steps to
group pixels or points into objects, Panoster proposes a simplified framework
incorporating a learning-based clustering solution to identify instances. At
inference time, this acts as a class-agnostic segmentation, allowing Panoster
to be fast, while outperforming prior methods in terms of accuracy. Without any
post-processing, Panoster reached state-of-the-art results among published
approaches on the challenging SemanticKITTI benchmark, and further increased
its lead by exploiting heuristic techniques. Additionally, we showcase how our
method can be flexibly and effectively applied on diverse existing semantic
architectures to deliver panoptic predictions.
</p>
<a href="http://arxiv.org/abs/2010.15157" target="_blank">arXiv:2010.15157</a> [<a href="http://arxiv.org/pdf/2010.15157" target="_blank">pdf</a>]

<h2>PAC Confidence Predictions for Deep Neural Network Classifiers. (arXiv:2011.00716v4 [cs.LG] UPDATED)</h2>
<h3>Sangdon Park, Shuo Li, Osbert Bastani, Insup Lee</h3>
<p>A key challenge for deploying deep neural networks (DNNs) in safety critical
settings is the need to provide rigorous ways to quantify their uncertainty. In
this paper, we propose a novel algorithm for constructing predicted
classification confidences for DNNs that comes with provable correctness
guarantees. Our approach uses Clopper-Pearson confidence intervals for the
Binomial distribution in conjunction with the histogram binning approach to
calibrated prediction. In addition, we demonstrate how our predicted
confidences can be used to enable downstream guarantees in two settings: (i)
fast DNN inference, where we demonstrate how to compose a fast but inaccurate
DNN with an accurate but slow DNN in a rigorous way to improve performance
without sacrificing accuracy, and (ii) safe planning, where we guarantee safety
when using a DNN to predict whether a given action is safe based on visual
observations. In our experiments, we demonstrate that our approach can be used
to provide guarantees for state-of-the-art DNNs.
</p>
<a href="http://arxiv.org/abs/2011.00716" target="_blank">arXiv:2011.00716</a> [<a href="http://arxiv.org/pdf/2011.00716" target="_blank">pdf</a>]

<h2>Advanced Semantics for Commonsense Knowledge Extraction. (arXiv:2011.00905v2 [cs.AI] UPDATED)</h2>
<h3>Tuan-Phong Nguyen, Simon Razniewski, Gerhard Weikum</h3>
<p>Commonsense knowledge (CSK) about concepts and their properties is useful for
AI applications such as robust chatbots. Prior works like ConceptNet, TupleKB
and others compiled large CSK collections, but are restricted in their
expressiveness to subject-predicate-object (SPO) triples with simple concepts
for S and monolithic strings for P and O. Also, these projects have either
prioritized precision or recall, but hardly reconcile these complementary
goals. This paper presents a methodology, called Ascent, to automatically build
a large-scale knowledge base (KB) of CSK assertions, with advanced
expressiveness and both better precision and recall than prior works. Ascent
goes beyond triples by capturing composite concepts with subgroups and aspects,
and by refining assertions with semantic facets. The latter are important to
express temporal and spatial validity of assertions and further qualifiers.
Ascent combines open information extraction with judicious cleaning using
language models. Intrinsic evaluation shows the superior size and quality of
the Ascent KB, and an extrinsic evaluation for QA-support tasks underlines the
benefits of Ascent.
</p>
<a href="http://arxiv.org/abs/2011.00905" target="_blank">arXiv:2011.00905</a> [<a href="http://arxiv.org/pdf/2011.00905" target="_blank">pdf</a>]

<h2>Towards Fundamental Limits of Multi-armed Bandits with Random Walk Feedback. (arXiv:2011.01445v2 [cs.LG] UPDATED)</h2>
<h3>Tianyu Wang, Lin F. Yang, Zizhuo Wang</h3>
<p>Despite the ubiquitous applications of bandit learning algorithms in
recommendation systems, social network, or online advertisement, where user
behaviors can be modeled as a random walk over a network, few studies have
utilized the network structure to improve learning efficiency. In this paper,
we address this issue by providing a novel bandit learning formulation, where
each arm is the starting node of a random walk in a network and the reward is
the length of walk. This formulation not only captures a large number of
applications in practice but also provides a framework to actively reduce
learning complexity by utilizing graph structure in the random walk feedback.
We provide a comprehensive understanding of this formulation by establishing
matching learning complexity upper and lower bounds, in both the stochastic and
the adversarial setting. In the stochastic setting, by utilizing the feedback
structure, our learning method can achieve constant regret, whereas regular
bandit algorithms' regret grows with $T$. In the adversarial setting, we
establish novel algorithms that achieve regret bound of order $\wt{\mathcal{O}}
\( \kappa \sqrt{T}\) $, where $\kappa$ is a constant that depends on the
structure of the graph, instead of number of arms (nodes). This bounds
significantly improves regular bandit algorithms, whose complexity depends on
number of arms (nodes).
</p>
<a href="http://arxiv.org/abs/2011.01445" target="_blank">arXiv:2011.01445</a> [<a href="http://arxiv.org/pdf/2011.01445" target="_blank">pdf</a>]

<h2>Episodic Linear Quadratic Regulators with Low-rank Transitions. (arXiv:2011.01568v2 [cs.LG] UPDATED)</h2>
<h3>Tianyu Wang, Lin F. Yang</h3>
<p>Linear Quadratic Regulators (LQR) achieve enormous successful real-world
applications. Very recently, people have been focusing on efficient learning
algorithms for LQRs when their dynamics are unknown. Existing results
effectively learn to control the unknown system using number of episodes
depending polynomially on the system parameters, including the ambient
dimension of the states. These traditional approaches, however, become
inefficient in common scenarios, e.g., when the states are high-resolution
images. In this paper, we propose an algorithm that utilizes the intrinsic
system low-rank structure for efficient learning. For problems of rank-$m$, our
algorithm achieves a $K$-episode regret bound of order $\widetilde{O}(m^{3/2}
K^{1/2})$. Consequently, the sample complexity of our algorithm only depends on
the rank, $m$, rather than the ambient dimension, $d$, which can be
orders-of-magnitude larger.
</p>
<a href="http://arxiv.org/abs/2011.01568" target="_blank">arXiv:2011.01568</a> [<a href="http://arxiv.org/pdf/2011.01568" target="_blank">pdf</a>]

<h2>Tabular Transformers for Modeling Multivariate Time Series. (arXiv:2011.01843v2 [cs.LG] UPDATED)</h2>
<h3>Inkit Padhi, Yair Schiff, Igor Melnyk, Mattia Rigotti, Youssef Mroueh, Pierre Dognin, Jerret Ross, Ravi Nair, Erik Altman</h3>
<p>Tabular datasets are ubiquitous in data science applications. Given their
importance, it seems natural to apply state-of-the-art deep learning algorithms
in order to fully unlock their potential. Here we propose neural network models
that represent tabular time series that can optionally leverage their
hierarchical structure. This results in two architectures for tabular time
series: one for learning representations that is analogous to BERT and can be
pre-trained end-to-end and used in downstream tasks, and one that is akin to
GPT and can be used for generation of realistic synthetic tabular sequences. We
demonstrate our models on two datasets: a synthetic credit card transaction
dataset, where the learned representations are used for fraud detection and
synthetic data generation, and on a real pollution dataset, where the learned
encodings are used to predict atmospheric pollutant concentrations. Code and
data are available at https://github.com/IBM/TabFormer.
</p>
<a href="http://arxiv.org/abs/2011.01843" target="_blank">arXiv:2011.01843</a> [<a href="http://arxiv.org/pdf/2011.01843" target="_blank">pdf</a>]

<h2>A Definition and a Test for Human-Level Artificial Intelligence. (arXiv:2011.09410v3 [cs.AI] UPDATED)</h2>
<h3>Md Ashaduzzaman Rubel Mondol, Aishwarya Pothula, Deokgun Park</h3>
<p>Despite recent advances in many application-specific domains, we do not know
how to build a human-level artificial intelligence (HLAI). We conjecture that
learning from others' experience with the language is the essential
characteristic that distinguishes human intelligence from the rest. Humans can
update the action-value function with the verbal description as if they
experience states, actions, and corresponding rewards sequences firsthand. In
this paper, we present a classification of intelligence according to how
individual agents learn and propose a definition and a test for HLAI. The main
idea is that language acquisition without explicit rewards can be a sufficient
test for HLAI.
</p>
<a href="http://arxiv.org/abs/2011.09410" target="_blank">arXiv:2011.09410</a> [<a href="http://arxiv.org/pdf/2011.09410" target="_blank">pdf</a>]

<h2>Sign language segmentation with temporal convolutional networks. (arXiv:2011.12986v2 [cs.CV] UPDATED)</h2>
<h3>Katrin Renz, Nicolaj C. Stache, Samuel Albanie, G&#xfc;l Varol</h3>
<p>The objective of this work is to determine the location of temporal
boundaries between signs in continuous sign language videos. Our approach
employs 3D convolutional neural network representations with iterative temporal
segment refinement to resolve ambiguities between sign boundary cues. We
demonstrate the effectiveness of our approach on the BSLCORPUS, PHOENIX14 and
BSL-1K datasets, showing considerable improvement over the prior state of the
art and the ability to generalise to new signers, languages and domains.
</p>
<a href="http://arxiv.org/abs/2011.12986" target="_blank">arXiv:2011.12986</a> [<a href="http://arxiv.org/pdf/2011.12986" target="_blank">pdf</a>]

<h2>Algebraically-Informed Deep Networks (AIDN): A Deep Learning Approach to Represent Algebraic Structures. (arXiv:2012.01141v3 [cs.LG] UPDATED)</h2>
<h3>Mustafa Hajij, Ghada Zamzmi, Matthew Dawson, Greg Muller</h3>
<p>One of the central problems in the interface of deep learning and mathematics
is that of building learning systems that can automatically uncover underlying
mathematical laws from observed data. In this work, we make one step towards
building a bridge between algebraic structures and deep learning, and introduce
\textbf{AIDN}, \textit{Algebraically-Informed Deep Networks}. \textbf{AIDN} is
a deep learning algorithm to represent any finitely-presented algebraic object
with a set of deep neural networks. The deep networks obtained via
\textbf{AIDN} are \textit{algebraically-informed} in the sense that they
satisfy the algebraic relations of the presentation of the algebraic structure
that serves as the input to the algorithm. Our proposed network can robustly
compute linear and non-linear representations of most finitely-presented
algebraic structures such as groups, associative algebras, and Lie algebras. We
evaluate our proposed approach and demonstrate its applicability to algebraic
and geometric objects that are significant in low-dimensional topology. In
particular, we study solutions for the Yang-Baxter equations and their
applications on braid groups. Further, we study the representations of the
Temperley-Lieb algebra. Finally, we show, using the Reshetikhin-Turaev
construction, how our proposed deep learning approach can be utilized to
construct new link invariants. We believe the proposed approach would tread a
path toward a promising future research in deep learning applied to algebraic
and geometric structures.
</p>
<a href="http://arxiv.org/abs/2012.01141" target="_blank">arXiv:2012.01141</a> [<a href="http://arxiv.org/pdf/2012.01141" target="_blank">pdf</a>]

<h2>Graph Neural Networks for Improved El Ni\~no Forecasting. (arXiv:2012.01598v3 [cs.LG] UPDATED)</h2>
<h3>Salva R&#xfc;hling Cachay, Emma Erickson, Arthur Fender C. Bucker, Ernest Pokropek, Willa Potosnak, Salomey Osei, Bj&#xf6;rn L&#xfc;tjens</h3>
<p>Deep learning-based models have recently outperformed state-of-the-art
seasonal forecasting models, such as for predicting El Ni\~no-Southern
Oscillation (ENSO). However, current deep learning models are based on
convolutional neural networks which are difficult to interpret and can fail to
model large-scale atmospheric patterns called teleconnections. Hence, we
propose the application of spatiotemporal Graph Neural Networks (GNN) to
forecast ENSO at long lead times, finer granularity and improved predictive
skill than current state-of-the-art methods. The explicit modeling of
information flow via edges may also allow for more interpretable forecasts.
Preliminary results are promising and outperform state-of-the art systems for
projections 1 and 3 months ahead.
</p>
<a href="http://arxiv.org/abs/2012.01598" target="_blank">arXiv:2012.01598</a> [<a href="http://arxiv.org/pdf/2012.01598" target="_blank">pdf</a>]

<h2>Motion-based Camera Localization System in Colonoscopy Videos. (arXiv:2012.01690v3 [cs.CV] UPDATED)</h2>
<h3>Heming Yao, Ryan W. Stidham, Zijun Gao, Jonathan Gryak, Kayvan Najarian</h3>
<p>Optical colonoscopy is an essential diagnostic and prognostic tool for many
gastrointestinal diseases, including cancer screening and staging, intestinal
bleeding, diarrhea, abdominal symptom evaluation, and inflammatory bowel
disease assessment. Automated assessment of colonoscopy is of interest
considering the subjectivity present in qualitative human interpretations of
colonoscopy findings. Localization of the camera is essential to interpreting
the meaning and context of findings for diseases evaluated by colonoscopy. In
this study, we propose a camera localization system to estimate the relative
location of the camera and classify the colon into anatomical segments. The
camera localization system begins with non-informative frame detection and
removal. Then a self-training end-to-end convolutional neural network is built
to estimate the camera motion, where several strategies are proposed to improve
its robustness and generalization on endoscopic videos. Using the estimated
camera motion a camera trajectory can be derived and a relative location index
calculated. Based on the estimated location index, anatomical colon segment
classification is performed by constructing a colon template. The proposed
motion estimation algorithm was evaluated on an external dataset containing the
ground truth for camera pose. The experimental results show that the
performance of the proposed method is superior to other published methods. The
relative location index estimation and anatomical region classification were
further validated using colonoscopy videos collected from routine clinical
practice. This validation yielded an average accuracy in classification of
0.754, which is substantially higher than the performances obtained using
location indices built from other methods.
</p>
<a href="http://arxiv.org/abs/2012.01690" target="_blank">arXiv:2012.01690</a> [<a href="http://arxiv.org/pdf/2012.01690" target="_blank">pdf</a>]

<h2>Noise and Fluctuation of Finite Learning Rate Stochastic Gradient Descent. (arXiv:2012.03636v3 [stat.ML] UPDATED)</h2>
<h3>Kangqiao Liu, Liu Ziyin, Masahito Ueda</h3>
<p>In the vanishing learning rate regime, stochastic gradient descent (SGD) is
now relatively well understood. In this work, we propose to study the basic
properties of SGD and its variants in the non-vanishing learning rate regime.
The focus is on deriving exactly solvable results and discussing their
implications. The main contributions of this work are to derive the stationary
distribution for discrete-time SGD in a quadratic loss function with and
without momentum; in particular, one implication of our result is that the
fluctuation caused by discrete-time dynamics takes a distorted shape and is
dramatically larger than a continuous-time theory could predict. Examples of
applications of the proposed theory considered in this work include the
approximation error of variants of SGD, the effect of minibatch noise, the
optimal Bayesian inference, the escape rate from a sharp minimum, and the
stationary distribution of a few second-order methods including damped Newton's
method and natural gradient descent.
</p>
<a href="http://arxiv.org/abs/2012.03636" target="_blank">arXiv:2012.03636</a> [<a href="http://arxiv.org/pdf/2012.03636" target="_blank">pdf</a>]

<h2>An Empirical Study of Assumptions in Bayesian Optimisation. (arXiv:2012.03826v3 [cs.LG] UPDATED)</h2>
<h3>Alexander I. Cowen-Rivers, Wenlong Lyu, Rasul Tutunov, Zhi Wang, Antoine Grosnit, Ryan Rhys Griffiths, Hao Jianye, Jun Wang, Haitham Bou Ammar</h3>
<p>Inspired by the increasing desire to efficiently tune machine learning
hyper-parameters, in this work we rigorously analyse conventional and
non-conventional assumptions inherent to Bayesian optimisation. Across an
extensive set of experiments we conclude that: 1) the majority of
hyper-parameter tuning tasks exhibit heteroscedasticity and non-stationarity,
2) multi-objective acquisition ensembles with Pareto-front solutions
significantly improve queried configurations, and 3) robust acquisition
maximisation affords empirical advantages relative to its non-robust
counterparts. We hope these findings may serve as guiding principles, both for
practitioners and for further research in the field.
</p>
<a href="http://arxiv.org/abs/2012.03826" target="_blank">arXiv:2012.03826</a> [<a href="http://arxiv.org/pdf/2012.03826" target="_blank">pdf</a>]

<h2>Privacy Amplification by Decentralization. (arXiv:2012.05326v2 [cs.LG] UPDATED)</h2>
<h3>Edwige Cyffers, Aur&#xe9;lien Bellet</h3>
<p>Analyzing data owned by several parties while achieving a good trade-off
between utility and privacy is a key challenge in federated learning and
analytics. In this work, we introduce a novel relaxation of local differential
privacy (LDP) that naturally arises in fully decentralized protocols, i.e.,
when participants exchange information by communicating along the edges of a
network graph. This relaxation, that we call network DP, captures the fact that
users have only a local view of the decentralized system. To show the relevance
of network DP, we study a decentralized model of computation where a token
performs a walk on the network graph and is updated sequentially by the party
who receives it. For tasks such as real summation, histogram computation and
optimization with gradient descent, we propose simple algorithms on ring and
complete topologies. We prove that the privacy-utility trade-offs of our
algorithms significantly improve upon LDP, and in some cases even match what
can be achieved with methods based on trusted/secure aggregation and shuffling.
Our experiments illustrate the superior utility of our approach when training a
machine learning model with stochastic gradient descent.
</p>
<a href="http://arxiv.org/abs/2012.05326" target="_blank">arXiv:2012.05326</a> [<a href="http://arxiv.org/pdf/2012.05326" target="_blank">pdf</a>]

<h2>Best Arm Identification in Graphical Bilinear Bandits. (arXiv:2012.07641v2 [cs.LG] UPDATED)</h2>
<h3>Geovani Rizk, Albert Thomas, Igor Colin, Rida Laraki, Yann Chevaleyre</h3>
<p>We introduce a new graphical bilinear bandit problem where a learner (or a
\emph{central entity}) allocates arms to the nodes of a graph and observes for
each edge a noisy bilinear reward representing the interaction between the two
end nodes. We study the best arm identification problem in which the learner
wants to find the graph allocation maximizing the sum of the bilinear rewards.
By efficiently exploiting the geometry of this bandit problem, we propose a
\emph{decentralized} allocation strategy based on random sampling with
theoretical guarantees. In particular, we characterize the influence of the
graph structure (e.g. star, complete or circle) on the convergence rate and
propose empirical experiments that confirm this dependency.
</p>
<a href="http://arxiv.org/abs/2012.07641" target="_blank">arXiv:2012.07641</a> [<a href="http://arxiv.org/pdf/2012.07641" target="_blank">pdf</a>]

<h2>Variational Beam Search for Learning with Distribution Shifts. (arXiv:2012.08101v2 [stat.ML] UPDATED)</h2>
<h3>Aodong Li, Alex Boyd, Padhraic Smyth, Stephan Mandt</h3>
<p>We consider the problem of online learning in the presence of sudden
distribution shifts as frequently encountered in applications such as
autonomous navigation. Distribution shifts require constant performance
monitoring and re-training. They may also be hard to detect and can lead to a
slow but steady degradation in model performance. To address this problem we
propose a new Bayesian meta-algorithm that can both (i) make inferences about
subtle distribution shifts based on minimal sequential observations and (ii)
accordingly adapt a model in an online fashion. The approach uses beam search
over multiple change point hypotheses to perform inference on a hierarchical
sequential latent variable modeling framework. Our proposed approach is
model-agnostic, applicable to both supervised and unsupervised learning, and
yields significant improvements over state-of-the-art Bayesian online learning
approaches.
</p>
<a href="http://arxiv.org/abs/2012.08101" target="_blank">arXiv:2012.08101</a> [<a href="http://arxiv.org/pdf/2012.08101" target="_blank">pdf</a>]

<h2>Making transport more robust and interpretable by moving data through a small number of anchor points. (arXiv:2012.11589v2 [cs.LG] UPDATED)</h2>
<h3>Chi-Heng Lin, Mehdi Azabou, Eva L. Dyer</h3>
<p>Optimal transport (OT) is a widely used technique for distribution alignment,
with applications throughout the machine learning, graphics, and vision
communities. Without any additional structural assumptions on trans-port,
however, OT can be fragile to outliers or noise, especially in high dimensions.
Here, we introduce a new form of structured OT that simultaneously learns
low-dimensional structure in data while leveraging this structure to solve the
alignment task. Compared with OT, the resulting transport plan has better
structural interpretability, highlighting the connections between individual
data points and local geometry, and is more robust to noise and sampling. We
apply the method to synthetic as well as real datasets, where we show that our
method can facilitate alignment in noisy settings and can be used to both
correct and interpret domain shift.
</p>
<a href="http://arxiv.org/abs/2012.11589" target="_blank">arXiv:2012.11589</a> [<a href="http://arxiv.org/pdf/2012.11589" target="_blank">pdf</a>]

<h2>Efficient Continual Learning with Modular Networks and Task-Driven Priors. (arXiv:2012.12631v2 [cs.LG] UPDATED)</h2>
<h3>Tom Veniat, Ludovic Denoyer, Marc&#x27;Aurelio Ranzato</h3>
<p>Existing literature in Continual Learning (CL) has focused on overcoming
catastrophic forgetting, the inability of the learner to recall how to perform
tasks observed in the past. There are however other desirable properties of a
CL system, such as the ability to transfer knowledge from previous tasks and to
scale memory and compute sub-linearly with the number of tasks. Since most
current benchmarks focus only on forgetting using short streams of tasks, we
first propose a new suite of benchmarks to probe CL algorithms across these new
axes. Finally, we introduce a new modular architecture, whose modules represent
atomic skills that can be composed to perform a certain task. Learning a task
reduces to figuring out which past modules to re-use, and which new modules to
instantiate to solve the current task. Our learning algorithm leverages a
task-driven prior over the exponential search space of all possible ways to
combine modules, enabling efficient learning on long streams of tasks. Our
experiments show that this modular architecture and learning algorithm perform
competitively on widely used CL benchmarks while yielding superior performance
on the more challenging benchmarks we introduce in this work.
</p>
<a href="http://arxiv.org/abs/2012.12631" target="_blank">arXiv:2012.12631</a> [<a href="http://arxiv.org/pdf/2012.12631" target="_blank">pdf</a>]

<h2>Cauchy-Schwarz Regularized Autoencoder. (arXiv:2101.02149v2 [cs.LG] UPDATED)</h2>
<h3>Linh Tran, Maja Pantic, Marc Peter Deisenroth</h3>
<p>Recent work in unsupervised learning has focused on efficient inference and
learning in latent variables models. Training these models by maximizing the
evidence (marginal likelihood) is typically intractable. Thus, a common
approximation is to maximize the Evidence Lower BOund (ELBO) instead.
Variational autoencoders (VAE) are a powerful and widely-used class of
generative models that optimize the ELBO efficiently for large datasets.
However, the VAE's default Gaussian choice for the prior imposes a strong
constraint on its ability to represent the true posterior, thereby degrading
overall performance. A Gaussian mixture model (GMM) would be a richer prior,
but cannot be handled efficiently within the VAE framework because of the
intractability of the Kullback-Leibler divergence for GMMs. We deviate from the
common VAE framework in favor of one with an analytical solution for Gaussian
mixture prior. To perform efficient inference for GMM priors, we introduce a
new constrained objective based on the Cauchy-Schwarz divergence, which can be
computed analytically for GMMs. This new objective allows us to incorporate
richer, multi-modal priors into the autoencoding framework. We provide
empirical studies on a range of datasets and show that our objective improves
upon variational auto-encoding models in density estimation, unsupervised
clustering, semi-supervised learning, and face analysis.
</p>
<a href="http://arxiv.org/abs/2101.02149" target="_blank">arXiv:2101.02149</a> [<a href="http://arxiv.org/pdf/2101.02149" target="_blank">pdf</a>]

<h2>Challenges and approaches to time-series forecasting in data center telemetry: A Survey. (arXiv:2101.04224v2 [cs.LG] UPDATED)</h2>
<h3>Shruti Jadon, Jan Kanty Milczek, Ajit Patankar</h3>
<p>Time-series forecasting has been an important research domain for so many
years. Its applications include ECG predictions, sales forecasting, weather
conditions, even COVID-19 spread predictions. These applications have motivated
many researchers to figure out an optimal forecasting approach, but the
modeling approach also changes as the application domain changes. This work has
focused on reviewing different forecasting approaches for telemetry data
predictions collected at data centers. Forecasting of telemetry data is a
critical feature of network and data center management products. However, there
are multiple options of forecasting approaches that range from a simple linear
statistical model to high capacity deep learning architectures. In this paper,
we attempted to summarize and evaluate the performance of well known time
series forecasting techniques. We hope that this evaluation provides a
comprehensive summary to innovate in forecasting approaches for telemetry data.
</p>
<a href="http://arxiv.org/abs/2101.04224" target="_blank">arXiv:2101.04224</a> [<a href="http://arxiv.org/pdf/2101.04224" target="_blank">pdf</a>]

<h2>Exploring Cross-Image Pixel Contrast for Semantic Segmentation. (arXiv:2101.11939v3 [cs.CV] UPDATED)</h2>
<h3>Wenguan Wang, Tianfei Zhou, Fisher Yu, Jifeng Dai, Ender Konukoglu, Luc Van Gool</h3>
<p>Current semantic segmentation methods focus only on mining "local" context,
i.e., dependencies between pixels within individual images, by
context-aggregation modules (e.g., dilated convolution, neural attention) or
structure-aware optimization criteria (e.g., IoU-like loss). However, they
ignore "global" context of the training data, i.e., rich semantic relations
between pixels across different images. Inspired by the recent advance in
unsupervised contrastive representation learning, we propose a pixel-wise
contrastive framework for semantic segmentation in the fully supervised
setting. The core idea is to enforce pixel embeddings belonging to a same
semantic class to be more similar than embeddings from different classes. It
raises a pixel-wise metric learning paradigm for semantic segmentation, by
explicitly exploring the structures of labeled pixels, which were rarely
explored before. Our method can be effortlessly incorporated into existing
segmentation frameworks without extra overhead during testing. We
experimentally show that, with famous segmentation models (i.e., DeepLabV3,
HRNet, OCR) and backbones (i.e., ResNet, HR-Net), our method brings consistent
performance improvements across diverse datasets (i.e., Cityscapes,
PASCAL-Context, COCO-Stuff). We expect this work will encourage our community
to rethink the current de facto training paradigm in fully supervised semantic
segmentation.
</p>
<a href="http://arxiv.org/abs/2101.11939" target="_blank">arXiv:2101.11939</a> [<a href="http://arxiv.org/pdf/2101.11939" target="_blank">pdf</a>]

<h2>PipeTransformer: Automated Elastic Pipelining for Distributed Training of Transformers. (arXiv:2102.03161v2 [cs.LG] UPDATED)</h2>
<h3>Chaoyang He, Shen Li, Mahdi Soltanolkotabi, Salman Avestimehr</h3>
<p>The size of Transformer models is growing at an unprecedented pace. It has
only taken less than one year to reach trillion-level parameters after the
release of GPT-3 (175B). Training such models requires both substantial
engineering efforts and enormous computing resources, which are luxuries most
research teams cannot afford. In this paper, we propose PipeTransformer, which
leverages automated and elastic pipelining and data parallelism for efficient
distributed training of Transformer models. PipeTransformer automatically
adjusts the pipelining and data parallelism by identifying and freezing some
layers during the training, and instead allocates resources for training of the
remaining active layers. More specifically, PipeTransformer dynamically
excludes converged layers from the pipeline, packs active layers into fewer
GPUs, and forks more replicas to increase data-parallel width. We evaluate
PipeTransformer using Vision Transformer (ViT) on ImageNet and BERT on GLUE and
SQuAD datasets. Our results show that PipeTransformer attains a 2.4 fold
speedup compared to the state-of-the-art baseline. We also provide various
performance analyses for a more comprehensive understanding of our algorithmic
and system-wise design. We also develop open-sourced flexible APIs for
PipeTransformer, which offer a clean separation among the freeze algorithm,
model definitions, and training accelerations, hence allowing it to be applied
to other algorithms that require similar freezing strategies.
</p>
<a href="http://arxiv.org/abs/2102.03161" target="_blank">arXiv:2102.03161</a> [<a href="http://arxiv.org/pdf/2102.03161" target="_blank">pdf</a>]

<h2>Learning with Density Matrices and Random Features. (arXiv:2102.04394v2 [cs.LG] UPDATED)</h2>
<h3>Fabio A. Gonz&#xe1;lez, Alejandro Gallego, Santiago Toledo-Cort&#xe9;s, Vladimir Vargas-Calder&#xf3;n</h3>
<p>A density matrix describes the statistical state of a quantum system. It is a
powerful formalism to represent both the quantum and classical uncertainty of
quantum systems and to express different statistical operations such as
measurement, system combination and expectations as linear algebra operations.
This paper explores how density matrices can be used as a building block to
build machine learning models exploiting their ability to straightforwardly
combine linear algebra and probability. One of the main results of the paper is
to show that density matrices coupled with random Fourier features could
approximate arbitrary probability distributions over $\mathbb{R}^n$. Based on
this finding the paper builds different models for density estimation,
classification and regression. These models are differentiable, so it is
possible to integrate them with other differentiable components, such as deep
learning architectures and to learn their parameters using gradient-based
optimization. In addition, the paper presents optimization-less training
strategies based on estimation and model averaging. The models are evaluated in
benchmark tasks and the results are reported and discussed.
</p>
<a href="http://arxiv.org/abs/2102.04394" target="_blank">arXiv:2102.04394</a> [<a href="http://arxiv.org/pdf/2102.04394" target="_blank">pdf</a>]

<h2>Statistical Inference for Polyak-Ruppert Averaged Zeroth-order Stochastic Gradient Algorithm. (arXiv:2102.05198v2 [stat.ML] UPDATED)</h2>
<h3>Yanhao Jin, Tesi Xiao, Krishnakumar Balasubramanian</h3>
<p>As machine learning models are deployed in critical applications, it becomes
important to not just provide point estimators of the model parameters (or
subsequent predictions), but also quantify the uncertainty associated with
estimating the model parameters via confidence sets. In the last decade,
estimating or training in several machine learning models has become synonymous
with running stochastic gradient algorithms. However, computing the stochastic
gradients in several settings is highly expensive or even impossible at times.
An important question which has thus far not been addressed sufficiently in the
statistical machine learning literature is that of equipping zeroth-order
stochastic gradient algorithms with practical yet rigorous inferential
capabilities. Towards this, in this work, we first establish a central limit
theorem for Polyak-Ruppert averaged stochastic gradient algorithm in the
zeroth-order setting. We then provide online estimators of the asymptotic
covariance matrix appearing in the central limit theorem, thereby providing a
practical procedure for constructing asymptotically valid confidence sets (or
intervals) for parameter estimation (or prediction) in the zeroth-order
setting.
</p>
<a href="http://arxiv.org/abs/2102.05198" target="_blank">arXiv:2102.05198</a> [<a href="http://arxiv.org/pdf/2102.05198" target="_blank">pdf</a>]

<h2>Sparse-Push: Communication- & Energy-Efficient Decentralized Distributed Learning over Directed & Time-Varying Graphs with non-IID Datasets. (arXiv:2102.05715v2 [cs.LG] UPDATED)</h2>
<h3>Sai Aparna Aketi, Amandeep Singh, Jan Rabaey</h3>
<p>Current deep learning (DL) systems rely on a centralized computing paradigm
which limits the amount of available training data, increases system latency,
and adds privacy and security constraints. On-device learning, enabled by
decentralized and distributed training of DL models over peer-to-peer
wirelessly connected edge devices, not only alleviate the above limitations but
also enable next-gen applications that need DL models to continuously interact
and learn from their environment. However, this necessitates the development of
novel training algorithms that train DL models over time-varying and directed
peer-to-peer graph structures while minimizing the amount of communication
between the devices and also being resilient to non-IID data distributions. In
this work we propose, Sparse-Push, a communication efficient decentralized
distributed training algorithm that supports training over peer-to-peer,
directed, and time-varying graph topologies. The proposed algorithm enables
466x reduction in communication with only 1% degradation in performance when
training various DL models such as ResNet-20 and VGG11 over the CIFAR-10
dataset. Further, we demonstrate how communication compression can lead to
significant performance degradation in-case of non-IID datasets, and propose
Skew-Compensated Sparse Push algorithm that recovers this performance drop
while maintaining similar levels of communication compression.
</p>
<a href="http://arxiv.org/abs/2102.05715" target="_blank">arXiv:2102.05715</a> [<a href="http://arxiv.org/pdf/2102.05715" target="_blank">pdf</a>]

<h2>Achieving Near Instance-Optimality and Minimax-Optimality in Stochastic and Adversarial Linear Bandits Simultaneously. (arXiv:2102.05858v2 [cs.LG] UPDATED)</h2>
<h3>Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei, Mengxiao Zhang, Xiaojin Zhang</h3>
<p>In this work, we develop linear bandit algorithms that automatically adapt to
different environments. By plugging a novel loss estimator into the
optimization problem that characterizes the instance-optimal strategy, our
first algorithm not only achieves nearly instance-optimal regret in stochastic
environments, but also works in corrupted environments with additional regret
being the amount of corruption, while the state-of-the-art (Li et al., 2019)
achieves neither instance-optimality nor the optimal dependence on the
corruption amount. Moreover, by equipping this algorithm with an adversarial
component and carefully-designed testings, our second algorithm additionally
enjoys minimax-optimal regret in completely adversarial environments, which is
the first of this kind to our knowledge. Finally, all our guarantees hold with
high probability, while existing instance-optimal guarantees only hold in
expectation.
</p>
<a href="http://arxiv.org/abs/2102.05858" target="_blank">arXiv:2102.05858</a> [<a href="http://arxiv.org/pdf/2102.05858" target="_blank">pdf</a>]

<h2>EvoSplit: An evolutionary approach to split a multi-label data set into disjoint subsets. (arXiv:2102.06154v2 [cs.LG] UPDATED)</h2>
<h3>Francisco Florez-Revuelta</h3>
<p>This paper presents a new evolutionary approach, EvoSplit, for the
distribution of multi-label data sets into disjoint subsets for supervised
machine learning. Currently, data set providers either divide a data set
randomly or using iterative stratification, a method that aims to maintain the
label (or label pair) distribution of the original data set into the different
subsets. Following the same aim, this paper first introduces a single-objective
evolutionary approach that tries to obtain a split that maximizes the
similarity between those distributions independently. Second, a new
multi-objective evolutionary algorithm is presented to maximize the similarity
considering simultaneously both distributions (label and label pair). Both
approaches are validated using well-known multi-label data sets as well as
large image data sets currently used in computer vision and machine learning
applications. EvoSplit improves the splitting of a data set in comparison to
the iterative stratification following different measures: Label Distribution,
Label Pair Distribution, Examples Distribution, folds and fold-label pairs with
zero positive examples.
</p>
<a href="http://arxiv.org/abs/2102.06154" target="_blank">arXiv:2102.06154</a> [<a href="http://arxiv.org/pdf/2102.06154" target="_blank">pdf</a>]

<h2>A Topological Approach for Motion Track Discrimination. (arXiv:2102.05705v1 [cs.CV] CROSS LISTED)</h2>
<h3>Tegan Emerson, Sarah Tymochko, George Stantchev, Jason A. Edelberg, Michael Wilson, Colin C. Olson</h3>
<p>Detecting small targets at range is difficult because there is not enough
spatial information present in an image sub-region containing the target to use
correlation-based methods to differentiate it from dynamic confusers present in
the scene. Moreover, this lack of spatial information also disqualifies the use
of most state-of-the-art deep learning image-based classifiers. Here, we use
characteristics of target tracks extracted from video sequences as data from
which to derive distinguishing topological features that help robustly
differentiate targets of interest from confusers. In particular, we calculate
persistent homology from time-delayed embeddings of dynamic statistics
calculated from motion tracks extracted from a wide field-of-view video stream.
In short, we use topological methods to extract features related to target
motion dynamics that are useful for classification and disambiguation and show
that small targets can be detected at range with high probability.
</p>
<a href="http://arxiv.org/abs/2102.05705" target="_blank">arXiv:2102.05705</a> [<a href="http://arxiv.org/pdf/2102.05705" target="_blank">pdf</a>]

