---
title: Latest Deep Learning Papers
date: 2020-11-02 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Shallow Characters and Supercuspidal Representations. (arXiv:2011.00049v1 [math.RT])</h2>
<h3>Stella Sue Gastineau</h3>
<p>In 2014, Reeder and Yu constructed epipelagic representations of a reductive
$p$-adic group $G$ from stable functions on shallowest Moy-Prasad quotients. In
this paper, we extend these methods when $G$ is split. In particular, we
classify all complex-valued characters vanshing on a slightly deeper Moy-Prasad
subgroup and show that, while sufficient, a naive extension of Reeder-Yu's
stability condition is not necessary for constructing supercuspidal
representations.
</p>
<a href="http://arxiv.org/abs/2011.00049" target="_blank">arXiv:2011.00049</a> [<a href="http://arxiv.org/pdf/2011.00049" target="_blank">pdf</a>]

<h2>On sparse identification of complex dynamical systems: A study on discovering influential reactions in chemical reaction networks. (arXiv:2011.00053v1 [physics.chem-ph])</h2>
<h3>Farshad Harirchi, Doohyun Kim, Omar Khalil, Sijia Liu, Paolo Elvati, Mayank Baranwal, Alfred Hero, Angela Violi</h3>
<p>A wide variety of real life complex networks are prohibitively large for
modeling, analysis and control. Understanding the structure and dynamics of
such networks entails creating a smaller representative network that preserves
its relevant topological and dynamical properties. While modern machine
learning methods have enabled identification of governing laws for complex
dynamical systems, their inability to produce white-box models with sufficient
physical interpretation renders such methods undesirable to domain experts. In
this paper, we introduce a hybrid black-box, white-box approach for the sparse
identification of the governing laws for complex, highly coupled dynamical
systems with particular emphasis on finding the influential reactions in
chemical reaction networks for combustion applications, using a data-driven
sparse-learning technique. The proposed approach identifies a set of
influential reactions using species concentrations and reaction rates,with
minimal computational cost without requiring additional data or simulations.
The new approach is applied to analyze the combustion chemistry of H2 and C3H8
in a constant-volume homogeneous reactor. The influential reactions determined
by the sparse-learning method are consistent with the current kinetics
knowledge of chemical mechanisms. Additionally, we show that a reduced version
of the parent mechanism can be generated as a combination of the significantly
reduced influential reactions identified at different times and conditions and
that for both H2 and C3H8 fuel, the reduced mechanisms perform closely to the
parent mechanisms as a function of the ignition delay time over a wide range of
conditions. Our results demonstrate the potential of the sparse-learning
approach as an effective and efficient tool for dynamical system analysis and
reduction. The uniqueness of this approach as applied to combustion systems
lies in the ability to identify influential reactions in specified conditions
and times during the evolution of the combustion process. This ability is of
great interest to understand chemical reaction systems.
</p>
<a href="http://arxiv.org/abs/2011.00053" target="_blank">arXiv:2011.00053</a> [<a href="http://arxiv.org/pdf/2011.00053" target="_blank">pdf</a>]

<h2>Coarse Alexander duality for pairs and applications. (arXiv:2011.00059v1 [math.GT])</h2>
<h3>G. Christopher Hruska, Emily Stark, Hung Cong Tran</h3>
<p>For a group $G$ (of type $F$) acting properly on a coarse Poincar\'{e}
duality space $X$, Kapovich-Kleiner introduced a coarse version of Alexander
duality between $G$ and its complement in $X$. More precisely, the cohomology
of $G$ with group ring coefficients is dual to a certain \v{C}ech homology
group of the family of increasing neighborhoods of a $G$-orbit in $X$. This
duality applies more generally to coarse embeddings of certain contractible
simplicial complexes into coarse $PD(n)$ spaces. In this paper we introduce a
relative version of this \v{C}ech homology that satisfies the
Eilenberg-Steenrod Exactness Axiom, and we prove a relative version of coarse
Alexander duality.

As an application we provide a detailed proof of the following result, first
stated by Kapovich-Kleiner. Given a $2$-complex formed by gluing $k$ halfplanes
along their boundary lines and a coarse embedding into a contractible
$3$-manifold, the complement consists of $k$ deep components that are arranged
cyclically in a pattern called a \emph{Jordan cycle}. We use the Jordan cycle
as an invariant in proving the existence of a $3$-manifold group that is
virtually Kleinian but not itself Kleinian.
</p>
<a href="http://arxiv.org/abs/2011.00059" target="_blank">arXiv:2011.00059</a> [<a href="http://arxiv.org/pdf/2011.00059" target="_blank">pdf</a>]

<h2>Integer Programming-based Error-Correcting Output Code Design for Robust Classification. (arXiv:2011.00144v1 [cs.LG])</h2>
<h3>Samarth Gupta, Saurabh Amin</h3>
<p>Error-Correcting Output Codes (ECOCs) offer a principled approach for
combining simple binary classifiers into multiclass classifiers. In this paper,
we investigate the problem of designing optimal ECOCs to achieve both nominal
and adversarial accuracy using Support Vector Machines (SVMs) and binary deep
learning models. In contrast to previous literature, we present an Integer
Programming (IP) formulation to design minimal codebooks with desirable error
correcting properties. Our work leverages the advances in IP solvers to
generate codebooks with optimality guarantees. To achieve tractability, we
exploit the underlying graph-theoretic structure of the constraint set in our
IP formulation. This enables us to use edge clique covers to substantially
reduce the constraint set. Our codebooks achieve a high nominal accuracy
relative to standard codebooks (e.g., one-vs-all, one-vs-one, and dense/sparse
codes). We also estimate the adversarial accuracy of our ECOC-based classifiers
in a white-box setting. Our IP-generated codebooks provide non-trivial
robustness to adversarial perturbations even without any adversarial training.
</p>
<a href="http://arxiv.org/abs/2011.00144" target="_blank">arXiv:2011.00144</a> [<a href="http://arxiv.org/pdf/2011.00144" target="_blank">pdf</a>]

<h2>Differentially Private ADMM Algorithms for Machine Learning. (arXiv:2011.00164v1 [cs.LG])</h2>
<h3>Tao Xu, Fanhua Shang, Yuanyuan Liu, Hongying Liu, Longjie Shen, Maoguo Gong</h3>
<p>In this paper, we study efficient differentially private alternating
direction methods of multipliers (ADMM) via gradient perturbation for many
machine learning problems. For smooth convex loss functions with (non)-smooth
regularization, we propose the first differentially private ADMM (DP-ADMM)
algorithm with performance guarantee of $(\epsilon,\delta)$-differential
privacy ($(\epsilon,\delta)$-DP). From the viewpoint of theoretical analysis,
we use the Gaussian mechanism and the conversion relationship between R\'enyi
Differential Privacy (RDP) and DP to perform a comprehensive privacy analysis
for our algorithm. Then we establish a new criterion to prove the convergence
of the proposed algorithms including DP-ADMM. We also give the utility analysis
of our DP-ADMM. Moreover, we propose an accelerated DP-ADMM (DP-AccADMM) with
the Nesterov's acceleration technique. Finally, we conduct numerical
experiments on many real-world datasets to show the privacy-utility tradeoff of
the two proposed algorithms, and all the comparative analysis shows that
DP-AccADMM converges faster and has a better utility than DP-ADMM, when the
privacy budget $\epsilon$ is larger than a threshold.
</p>
<a href="http://arxiv.org/abs/2011.00164" target="_blank">arXiv:2011.00164</a> [<a href="http://arxiv.org/pdf/2011.00164" target="_blank">pdf</a>]

<h2>Uplink Transmission Design for Crowded Correlated Cell-Free Massive MIMO-OFDM Systems. (arXiv:2011.00203v1 [cs.IT])</h2>
<h3>Junyuan Gao, Yongpeng Wu, Yongjian Wang, Wenjun Zhang, Fan Wei</h3>
<p>In cell-free massive multiple-input multiple-output (MIMO) orthogonal
frequency division multiplexing (OFDM) systems, user equipments (UEs) are
served by many distributed access points (APs), where channels are correlated
due to finite angle-delay spread in realistic outdoor wireless propagation
environments. Meanwhile, the number of UEs is growing rapidly for future fully
networked society. In this paper, we focus on the uplink transmission design in
crowded correlated cell-free massive MIMO-OFDM systems with limited number of
orthogonal pilots. For the pilot transmission phase, we identify active UEs
based on non-orthogonal pilot phase shift hopping patterns and non-orthogonal
adjustable phase shift pilots (APSP). We derive a closed-form expression of
mean square error of channel estimation (MSE-CE) and obtain an optimal
condition for minimizing MSE-CE. According to this condition, the APSP set
allocation scheme is proposed. Furthermore, for the data transmission, the
max-min power control algorithm is devised to maximize the minimum spectral
efficiency (SE) lower bound among active UEs. Simulation results indicate
significant performance gains in terms of MSE-CE for the proposed APSP set
allocation scheme. The proposed power control scheme can further improve the
minimum SE among active UEs. Hence, they are crucial for crowded correlated
cell-free massive MIMO-OFDM systems.
</p>
<a href="http://arxiv.org/abs/2011.00203" target="_blank">arXiv:2011.00203</a> [<a href="http://arxiv.org/pdf/2011.00203" target="_blank">pdf</a>]

<h2>Efficient Methods for Structured Nonconvex-Nonconcave Min-Max Optimization. (arXiv:2011.00364v1 [math.OC])</h2>
<h3>Jelena Diakonikolas, Constantinos Daskalakis, Michael I. Jordan</h3>
<p>The use of min-max optimization in adversarial training of deep neural
network classifiers and training of generative adversarial networks has
motivated the study of nonconvex-nonconcave optimization objectives, which
frequently arise in these applications. Unfortunately, recent results have
established that even approximate first-order stationary points of such
objectives are intractable, even under smoothness conditions, motivating the
study of min-max objectives with additional structure. We introduce a new class
of structured nonconvex-nonconcave min-max optimization problems, proposing a
generalization of the extragradient algorithm which provably converges to a
stationary point. The algorithm applies not only to Euclidean spaces, but also
to general $\ell_p$-normed finite-dimensional real vector spaces. We also
discuss its stability under stochastic oracles and provide bounds on its sample
complexity. Our iteration complexity and sample complexity bounds either match
or improve the best known bounds for the same or less general
nonconvex-nonconcave settings, such as those that satisfy variational coherence
or in which a weak solution to the associated variational inequality problem is
assumed to exist.
</p>
<a href="http://arxiv.org/abs/2011.00364" target="_blank">arXiv:2011.00364</a> [<a href="http://arxiv.org/pdf/2011.00364" target="_blank">pdf</a>]

<h2>Manifold Learning and Nonlinear Homogenization. (arXiv:2011.00568v1 [math.NA])</h2>
<h3>Shi Chen, Qin Li, Jianfeng Lu, Stephen J. Wright</h3>
<p>We describe an efficient domain decomposition-based framework for nonlinear
multiscale PDE problems. The framework is inspired by manifold learning
techniques and exploits the tangent spaces spanned by the nearest neighbors to
compress local solution manifolds. Our framework is applied to a semilinear
elliptic equation with oscillatory media and a nonlinear radiative transfer
equation; in both cases, significant improvements in efficacy are observed.
This new method does not rely on detailed analytical understanding of the
multiscale PDEs, such as their asymptotic limits, and thus is more versatile
for general multiscale problems.
</p>
<a href="http://arxiv.org/abs/2011.00568" target="_blank">arXiv:2011.00568</a> [<a href="http://arxiv.org/pdf/2011.00568" target="_blank">pdf</a>]

<h2>Distances between probability distributions of different dimensions. (arXiv:2011.00629v1 [math.ST])</h2>
<h3>Yuhang Cai, Lek-Heng Lim</h3>
<p>Comparing probability distributions is an indispensable and ubiquitous task
in machine learning and statistics. The most common way to compare a pair of
Borel probability measures is to compute a metric between them, and by far the
most widely used notions of metric are the Wasserstein metric and the total
variation metric. The next most common way is to compute a divergence between
them, and in this case almost every known divergences such as those of
Kullback-Leibler, Jensen-Shannon, R\'enyi, and many more, are special cases of
the $f$-divergence. Nevertheless these metrics and divergences may only be
computed, in fact, are only defined, when the pair of probability measures are
on spaces of the same dimension. How would one measure, say, a Wasserstein
distance between the uniform distribution on the interval $[-1,1]$ and a
Gaussian distribution on $\mathbb{R}^3$? We will show that various common
notions of metrics and divergences can be extended in a completely natural
manner to Borel probability measures defined on spaces of different dimensions,
e.g., one on $\mathbb{R}^m$ and another on $\mathbb{R}^n$ where $m, n$ are
distinct, so as to give a meaningful answer to the previous question.
</p>
<a href="http://arxiv.org/abs/2011.00629" target="_blank">arXiv:2011.00629</a> [<a href="http://arxiv.org/pdf/2011.00629" target="_blank">pdf</a>]

<h2>Asynchronous Parallel Stochastic Quasi-Newton Methods. (arXiv:2011.00667v1 [math.OC])</h2>
<h3>Qianqian Tong, Guannan Liang, Xingyu Cai, Chunjiang Zhu, Jinbo Bi</h3>
<p>Although first-order stochastic algorithms, such as stochastic gradient
descent, have been the main force to scale up machine learning models, such as
deep neural nets, the second-order quasi-Newton methods start to draw attention
due to their effectiveness in dealing with ill-conditioned optimization
problems. The L-BFGS method is one of the most widely used quasi-Newton
methods. We propose an asynchronous parallel algorithm for stochastic
quasi-Newton (AsySQN) method. Unlike prior attempts, which parallelize only the
calculation for gradient or the two-loop recursion of L-BFGS, our algorithm is
the first one that truly parallelizes L-BFGS with a convergence guarantee.
Adopting the variance reduction technique, a prior stochastic L-BFGS, which has
not been designed for parallel computing, reaches a linear convergence rate. We
prove that our asynchronous parallel scheme maintains the same linear
convergence rate but achieves significant speedup. Empirical evaluations in
both simulations and benchmark datasets demonstrate the speedup in comparison
with the non-parallel stochastic L-BFGS, as well as the better performance than
first-order methods in solving ill-conditioned problems.
</p>
<a href="http://arxiv.org/abs/2011.00667" target="_blank">arXiv:2011.00667</a> [<a href="http://arxiv.org/pdf/2011.00667" target="_blank">pdf</a>]

<h2>Machine Learning Lie Structures & Applications to Physics. (arXiv:2011.00871v1 [hep-th])</h2>
<h3>Heng-Yu Chen, Yang-Hui He, Shailesh Lal, Suvajit Majumder</h3>
<p>Classical and exceptional Lie algebras and their representations are among
the most important tools in the analysis of symmetry in physical systems. In
this letter we show how the computation of tensor products and branching rules
of irreducible representations are machine-learnable, and can achieve relative
speed-ups of orders of magnitude in comparison to the non-ML algorithms.
</p>
<a href="http://arxiv.org/abs/2011.00871" target="_blank">arXiv:2011.00871</a> [<a href="http://arxiv.org/pdf/2011.00871" target="_blank">pdf</a>]

<h2>Transfer Learning and Meta Learning Based Fast Downlink Beamforming Adaptation. (arXiv:2011.00903v1 [cs.IT])</h2>
<h3>Yi Yuan, Gan Zheng, Kai-Kit Wong, Bj&#xf6;rn Ottersten, Zhi-Quan Luo</h3>
<p>This paper studies fast adaptive beamforming optimization for the
signal-to-interference-plus-noise ratio balancing problem in a multiuser
multiple-input single-output downlink system. Existing deep learning based
approaches to predict beamforming rely on the assumption that the training and
testing channels follow the same distribution which may not hold in practice.
As a result, a trained model may lead to performance deterioration when the
testing network environment changes. To deal with this task mismatch issue, we
propose two offline adaptive algorithms based on deep transfer learning and
meta-learning, which are able to achieve fast adaptation with the limited new
labelled data when the testing wireless environment changes. Furthermore, we
propose an online algorithm to enhance the adaptation capability of the offline
meta algorithm in realistic non-stationary environments. Simulation results
demonstrate that the proposed adaptive algorithms achieve much better
performance than the direct deep learning algorithm without adaptation in new
environments. The meta-learning algorithm outperforms the deep transfer
learning algorithm and achieves near optimal performance. In addition, compared
to the offline meta-learning algorithm, the proposed online meta-learning
algorithm shows superior adaption performance in changing environments.
</p>
<a href="http://arxiv.org/abs/2011.00903" target="_blank">arXiv:2011.00903</a> [<a href="http://arxiv.org/pdf/2011.00903" target="_blank">pdf</a>]

<h2>AI Chiller: An Open IoT Cloud Based Machine Learning Framework for the Energy Saving of Building HVAC System via Big Data Analytics on the Fusion of BMS and Environmental Data. (arXiv:2011.01047v1 [cs.OH])</h2>
<h3>Yong Yu</h3>
<p>Energy saving and carbon emission reduction in buildings is one of the key
measures in combating climate change. Heating, Ventilation, and Air
Conditioning (HVAC) system account for the majority of the energy consumption
in the built environment, and among which, the chiller plant constitutes the
top portion. The optimization of chiller system power consumption had been
extensively studied in the mechanical engineering and building service domains.
Many works employ physical models from the domain knowledge. With the advance
of big data and AI, the adoption of machine learning into the optimization
problems becomes popular. Although many research works and projects turn to
this direction for energy saving, the application into the optimization problem
remains a challenging task. This work is targeted to outline a framework for
such problems on how the energy saving should be benchmarked, if holistic or
individually modeling should be used, how the optimization is to be conducted,
why data pattern augmentation at the initial deployment is a must, why the
gradually increasing changes strategy must be used. Results of analysis on
historical data and empirical experiment on live data are presented.
</p>
<a href="http://arxiv.org/abs/2011.01047" target="_blank">arXiv:2011.01047</a> [<a href="http://arxiv.org/pdf/2011.01047" target="_blank">pdf</a>]

<h2>Fractionally balanced hypergraphs and rainbow KKM theorems. (arXiv:2011.01053v1 [math.CO])</h2>
<h3>Ron Aharoni, Eli Berger, Joseph Briggs, Erel Segal-Halevi, Shira Zerbib</h3>
<p>A $d$-partite hypergraph is called fractionally balanced if there exists a
non-negative function on its edge set that has constant degrees in each vertex
side. Using a topological version of Hall's theorem we prove lower bounds on
the matching number of such hypergraphs. These, in turn, yield results on
mulitple-cake division problems and rainbow matchings in families of
$d$-intervals.
</p>
<a href="http://arxiv.org/abs/2011.01053" target="_blank">arXiv:2011.01053</a> [<a href="http://arxiv.org/pdf/2011.01053" target="_blank">pdf</a>]

<h2>Bayesian inference of heterogeneous epidemic models: Application to COVID-19 spread accounting for long-term care facilities. (arXiv:2011.01058v1 [stat.ME])</h2>
<h3>Peng Chen, Keyi Wu, Omar Ghattas</h3>
<p>We propose a high dimensional Bayesian inference framework for learning
heterogeneous dynamics of a COVID-19 model, with a specific application to the
dynamics and severity of COVID-19 inside and outside long-term care (LTC)
facilities. We develop a heterogeneous compartmental model that accounts for
the heterogeneity of the time-varying spread and severity of COVID-19 inside
and outside LTC facilities, which is characterized by time-dependent stochastic
processes and time-independent parameters in $\sim$1500 dimensions after
discretization. To infer these parameters, we use reported data on the number
of confirmed, hospitalized, and deceased cases with suitable post-processing in
both a deterministic inversion approach with appropriate regularization as a
first step, followed by Bayesian inversion with proper prior distributions. To
address the curse of dimensionality and the ill-posedness of the
high-dimensional inference problem, we propose use of a dimension-independent
projected Stein variational gradient descent method, and demonstrate the
intrinsic low-dimensionality of the inverse problem. We present inference
results with quantified uncertainties for both New Jersey and Texas, which
experienced different epidemic phases and patterns. Moreover, we also present
forecasting and validation results based on the empirical posterior samples of
our inference for the future trajectory of COVID-19.
</p>
<a href="http://arxiv.org/abs/2011.01058" target="_blank">arXiv:2011.01058</a> [<a href="http://arxiv.org/pdf/2011.01058" target="_blank">pdf</a>]

<h2>Compression, inversion, and approximate PCA of dense kernel matrices at near-linear computational complexity. (arXiv:1706.02205v5 [math.NA] UPDATED)</h2>
<h3>Florian Sch&#xe4;fer, T. J. Sullivan, Houman Owhadi</h3>
<p>Dense kernel matrices $\Theta \in \mathbb{R}^{N \times N}$ obtained from
point evaluations of a covariance function $G$ at locations $\{ x_{i} \}_{1
\leq i \leq N} \subset \mathbb{R}^{d}$ arise in statistics, machine learning,
and numerical analysis. For covariance functions that are Green's functions of
elliptic boundary value problems and homogeneously-distributed sampling points,
we show how to identify a subset $S \subset \{ 1 , \dots , N \}^2$, with $\# S
= O ( N \log (N) \log^{d} ( N /\epsilon ) )$, such that the zero fill-in
incomplete Cholesky factorisation of the sparse matrix $\Theta_{ij} 1_{( i, j )
\in S}$ is an $\epsilon$-approximation of $\Theta$. This factorisation can
provably be obtained in complexity $O ( N \log( N ) \log^{d}( N /\epsilon) )$
in space and $O ( N \log^{2}( N ) \log^{2d}( N /\epsilon) )$ in time, improving
upon the state of the art for general elliptic operators; we further present
numerical evidence that $d$ can be taken to be the intrinsic dimension of the
data set rather than that of the ambient space. The algorithm only needs to
know the spatial configuration of the $x_{i}$ and does not require an analytic
representation of $G$. Furthermore, this factorization straightforwardly
provides an approximate sparse PCA with optimal rate of convergence in the
operator norm. Hence, by using only subsampling and the incomplete Cholesky
factorization, we obtain, at nearly linear complexity, the compression,
inversion and approximate PCA of a large class of covariance matrices. By
inverting the order of the Cholesky factorization we also obtain a solver for
elliptic PDE with complexity $O ( N \log^{d}( N /\epsilon) )$ in space and $O (
N \log^{2d}( N /\epsilon) )$ in time, improving upon the state of the art for
general elliptic operators.
</p>
<a href="http://arxiv.org/abs/1706.02205" target="_blank">arXiv:1706.02205</a> [<a href="http://arxiv.org/pdf/1706.02205" target="_blank">pdf</a>]

<h2>The Geometrical Structure of Phase Space of the Controlled Hamiltonian System with Symmetry. (arXiv:1802.01988v2 [math.SG] UPDATED)</h2>
<h3>Hong Wang (Nankai University)</h3>
<p>In this paper, from the viewpoint of completeness of Marsden-Weinstein
reduction, we illustrate how to give the definitions of a controlled
Hamiltonian (CH) system and a reducible controlled Hamiltonian system with
symmetry; and how to describe the dynamics of a CH system and the controlled
Hamiltonian equivalence; as well as how to give the regular point reduction and
the regular orbit reduction for a CH system with symmetry, by analyzing
carefully the geometrical and topological structures of the phase space and the
reduced phase space of the corresponding Hamiltonian system. We also introduce
briefly some recent developments in the study of reduction theory for the CH
systems with symmetries and applications. These research work reveal the deeply
internal relationships of the geometrical structures of phase spaces, the
dynamical vector fields and controls of the CH systems.
</p>
<a href="http://arxiv.org/abs/1802.01988" target="_blank">arXiv:1802.01988</a> [<a href="http://arxiv.org/pdf/1802.01988" target="_blank">pdf</a>]

<h2>Efficient Stochastic Gradient Descent for Learning with Distributionally Robust Optimization. (arXiv:1805.08728v2 [stat.ML] UPDATED)</h2>
<h3>Soumyadip Ghosh, Mark Squillante, Ebisa Wollega</h3>
<p>Distributionally robust optimization (DRO) problems are increasingly seen as
a viable method to train machine learning models for improved model
generalization. These min-max formulations, however, are more difficult to
solve. We therefore provide a new stochastic gradient descent algorithm to
efficiently solve this DRO formulation. Our approach applies gradient descent
to the outer minimization formulation and estimates the gradient of the inner
maximization based on a sample average approximation. The latter uses a subset
of the data in each iteration, progressively increasing the subset size to
ensure convergence. Theoretical results include establishing the optimal manner
for growing the support size to balance a fundamental tradeoff between
stochastic error and computational effort. Empirical results demonstrate the
significant benefits of our approach over previous work, and also illustrate
how learning with DRO can improve generalization.
</p>
<a href="http://arxiv.org/abs/1805.08728" target="_blank">arXiv:1805.08728</a> [<a href="http://arxiv.org/pdf/1805.08728" target="_blank">pdf</a>]

<h2>Deep Energy-Based Modeling of Discrete-Time Physics. (arXiv:1905.08604v3 [math.NA] UPDATED)</h2>
<h3>Takashi Matsubara, Ai Ishikawa, Takaharu Yaguchi</h3>
<p>Physical phenomena in the real world are often described by energy-based
modeling theories, such as Hamiltonian mechanics or the Landau theory, which
yield various physical laws. Recent developments in neural networks have
enabled the mimicking of the energy conservation law by learning the underlying
continuous-time differential equations. However, this may not be possible in
discrete time, which is often the case in practical learning and computation.
Moreover, other physical laws have been overlooked in the previous neural
network models. In this study, we propose a deep energy-based physical model
that admits a specific differential geometric structure. From this structure,
the conservation or dissipation law of energy and the mass conservation law
follow naturally. To ensure the energetic behavior in discrete time, we also
propose an automatic discrete differential algorithm that enables neural
networks to employ the discrete gradient method.
</p>
<a href="http://arxiv.org/abs/1905.08604" target="_blank">arXiv:1905.08604</a> [<a href="http://arxiv.org/pdf/1905.08604" target="_blank">pdf</a>]

<h2>Toric spaces and face enumeration on simplicial manifolds. (arXiv:2001.08390v2 [math.AT] UPDATED)</h2>
<h3>Feifei Fan</h3>
<p>In this paper, we study the well-know $g$-conjecture for rational homology
spheres in a topological way. To do this, we construct a class of topological
spaces with torus actions, which can be viewed as topological generalizations
of toric varieties. Along this way we prove that after doing stellar
subdivision operations at some middle dimensional faces of an arbitrary
rational homology sphere, the $g$-conjecture is valid. Furthermore, we give
topological proofs of several fundamental algebraic results about Buchsbaum
complexes and simplicial manifolds. In this process, we also get a few
interesting results in toric topology.
</p>
<a href="http://arxiv.org/abs/2001.08390" target="_blank">arXiv:2001.08390</a> [<a href="http://arxiv.org/pdf/2001.08390" target="_blank">pdf</a>]

<h2>Stochasticity of Deterministic Gradient Descent: Large Learning Rate for Multiscale Objective Function. (arXiv:2002.06189v2 [cs.LG] UPDATED)</h2>
<h3>Lingkai Kong, Molei Tao</h3>
<p>This article suggests that deterministic Gradient Descent, which does not use
any stochastic gradient approximation, can still exhibit stochastic behaviors.
In particular, it shows that if the objective function exhibit multiscale
behaviors, then in a large learning rate regime which only resolves the
macroscopic but not the microscopic details of the objective, the deterministic
GD dynamics can become chaotic and convergent not to a local minimizer but to a
statistical distribution. A sufficient condition is also established for
approximating this long-time statistical limit by a rescaled Gibbs
distribution. Both theoretical and numerical demonstrations are provided, and
the theoretical part relies on the construction of a stochastic map that uses
bounded noise (as opposed to discretized diffusions).
</p>
<a href="http://arxiv.org/abs/2002.06189" target="_blank">arXiv:2002.06189</a> [<a href="http://arxiv.org/pdf/2002.06189" target="_blank">pdf</a>]

<h2>Entrywise convergence of iterative methods for eigenproblems. (arXiv:2002.08491v2 [math.NA] UPDATED)</h2>
<h3>Vasileios Charisopoulos, Austin R. Benson, Anil Damle</h3>
<p>Several problems in machine learning, statistics, and other fields rely on
computing eigenvectors. For large scale problems, the computation of these
eigenvectors is typically performed via iterative schemes such as subspace
iteration or Krylov methods. While there is classical and comprehensive
analysis for subspace convergence guarantees with respect to the spectral norm,
in many modern applications other notions of subspace distance are more
appropriate. Recent theoretical work has focused on perturbations of subspaces
measured in the $\ell_{2 \to \infty}$ norm, but does not consider the actual
computation of eigenvectors. Here we address the convergence of subspace
iteration when distances are measured in the $\ell_{2 \to \infty}$ norm and
provide deterministic bounds. We complement our analysis with a practical
stopping criterion and demonstrate its applicability via numerical experiments.
Our results show that one can get comparable performance on downstream tasks
while requiring fewer iterations, thereby saving substantial computational
time.
</p>
<a href="http://arxiv.org/abs/2002.08491" target="_blank">arXiv:2002.08491</a> [<a href="http://arxiv.org/pdf/2002.08491" target="_blank">pdf</a>]

<h2>Efficient Federated Learning over Multiple Access Channel with Differential Privacy Constraints. (arXiv:2005.07776v2 [cs.LG] UPDATED)</h2>
<h3>Amir Sonee, Stefano Rini</h3>
<p>In this paper, the problem of federated learning (FL) through digital
communication between clients and a parameter server (PS) over a multiple
access channel (MAC), also subject to differential privacy (DP) constraints, is
studied. More precisely, we consider the setting in which clients in a
centralized network are prompted to train a machine learning model using their
local datasets. The information exchange between the clients and the PS takes
places over a MAC channel and must also preserve the DP of the local datasets.
Accordingly, the objective of the clients is to minimize the training loss
subject to (i) rate constraints for reliable communication over the MAC and
(ii) DP constraint over the local datasets. For this optimization scenario, we
proposed a novel consensus scheme in which digital distributed stochastic
gradient descent (D-DSGD) is performed by each client. To preserve DP, a
digital artificial noise is also added by the users to the locally quantized
gradients. The performance of the scheme is evaluated in terms of the
convergence rate and DP level for a given MAC capacity. The performance is
optimized over the choice of the quantization levels and the artificial noise
parameters. Numerical evaluations are presented to validate the performance of
the proposed scheme.
</p>
<a href="http://arxiv.org/abs/2005.07776" target="_blank">arXiv:2005.07776</a> [<a href="http://arxiv.org/pdf/2005.07776" target="_blank">pdf</a>]

<h2>Theoretical Guarantees for the Architope Modification. (arXiv:2006.14378v2 [cs.LG] UPDATED)</h2>
<h3>Anastasis Kratsios, Behnoosh Zamanlooy</h3>
<p>A recently introduced architecture transformation, called the architope
modification, was shown to bypass the composite pattern learning bottlenecks of
feed-forward networks. This architecture modification acts by partitioning the
input space and optimally redistributing the neurons of a single feed-forward
network across several sub-networks, each specialized on a single part of the
generated partition. In this paper, we show that the architope modification
strictly refines the universal approximation capabilities of any classical
universal approximator while simultaneously preserving the rate at which the
model class can approximate any integrable function. We find that the architope
modification of any classical universal approximator is necessarily dense in a
refined local $L^p$-type space quantifying composite pattern learning; in which
most feed-forward architectures fail to be dense. Our second main result shows
that applying the architope modification never comes at the cost of model
efficiency. This is because, if a function can be approximated by a model class
at a rate $\mathscr{O}((1/T)^{-\alpha})$, where $T$ is the number of trainable
parameters then that model class' architope modification also achieves the same
rate of approximation and with the same number of trainable parameters. In this
way, the architope modification strictly improves expressiveness while
preserving a model class's efficiency.
</p>
<a href="http://arxiv.org/abs/2006.14378" target="_blank">arXiv:2006.14378</a> [<a href="http://arxiv.org/pdf/2006.14378" target="_blank">pdf</a>]

<h2>A Learning-boosted Quasi-Newton Method for AC Optimal Power Flow. (arXiv:2007.06074v2 [math.OC] UPDATED)</h2>
<h3>Kyri Baker</h3>
<p>Power grid operators typically solve large-scale, nonconvex optimal power
flow (OPF) problems throughout the day to determine optimal setpoints for
generators while adhering to physical constraints. Despite being at the heart
of many OPF solvers, Newton-Raphson can be slow and numerically unstable. To
reduce the computational burden associated with calculating the full Jacobian
and its inverse, many Quasi-Newton methods attempt to find a solution to the
optimality conditions by leveraging an approximate Jacobian matrix. In this
paper, a Quasi-Newton method based on machine learning is presented which
performs iterative updates for candidate optimal solutions without having to
calculate a Jacobian or approximate Jacobian matrix. The proposed
learning-based algorithm utilizes a deep neural network with feedback. With
proper choice of weights and activation functions, the model becomes a
contraction mapping and convergence can be guaranteed. Results shown for
networks up to 1,354 buses indicate the proposed method is capable of finding
approximate solutions to AC OPF very quickly.
</p>
<a href="http://arxiv.org/abs/2007.06074" target="_blank">arXiv:2007.06074</a> [<a href="http://arxiv.org/pdf/2007.06074" target="_blank">pdf</a>]

<h2>A Decentralized Approach to Bayesian Learning. (arXiv:2007.06799v3 [stat.ML] UPDATED)</h2>
<h3>Anjaly Parayil, He Bai, Jemin George, Prudhvi Gurram</h3>
<p>Motivated by decentralized approaches to machine learning, we propose a
collaborative Bayesian learning algorithm taking the form of decentralized
Langevin dynamics in a non-convex setting. Our analysis show that the initial
KL-divergence between the Markov Chain and the target posterior distribution is
exponentially decreasing while the error contributions to the overall
KL-divergence from the additive noise is decreasing in polynomial time. We
further show that the polynomial-term experiences speed-up with number of
agents and provide sufficient conditions on the time-varying step-sizes to
guarantee convergence to the desired distribution. The performance of the
proposed algorithm is evaluated on a wide variety of machine learning tasks.
The empirical results show that the performance of individual agents with
locally available data is on par with the centralized setting with considerable
improvement in the convergence rate.
</p>
<a href="http://arxiv.org/abs/2007.06799" target="_blank">arXiv:2007.06799</a> [<a href="http://arxiv.org/pdf/2007.06799" target="_blank">pdf</a>]

<h2>A Manifold Proximal Linear Method for Sparse Spectral Clustering with Application to Single-Cell RNA Sequencing Data Analysis. (arXiv:2007.09524v2 [stat.ML] UPDATED)</h2>
<h3>Zhongruo Wang, Bingyuan Liu, Shixiang Chen, Shiqian Ma, Lingzhou Xue, Hongyu Zhao</h3>
<p>Spectral clustering is one of the fundamental unsupervised learning methods
widely used in data analysis. Sparse spectral clustering (SSC) imposes sparsity
to the spectral clustering and it improves the interpretability of the model.
This paper considers a widely adopted model for SSC, which can be formulated as
an optimization problem over the Stiefel manifold with nonsmooth and nonconvex
objective. Such an optimization problem is very challenging to solve. Existing
methods usually solve its convex relaxation or need to smooth its nonsmooth
part using certain smoothing techniques. In this paper, we propose a manifold
proximal linear method (ManPL) that solves the original SSC formulation. We
also extend the algorithm to solve the multiple-kernel SSC problems, for which
an alternating ManPL algorithm is proposed. Convergence and iteration
complexity results of the proposed methods are established. We demonstrate the
advantage of our proposed methods over existing methods via the single-cell RNA
sequencing data analysis.
</p>
<a href="http://arxiv.org/abs/2007.09524" target="_blank">arXiv:2007.09524</a> [<a href="http://arxiv.org/pdf/2007.09524" target="_blank">pdf</a>]

<h2>Cross-validation Confidence Intervals for Test Error. (arXiv:2007.12671v2 [stat.ML] UPDATED)</h2>
<h3>Pierre Bayle, Alexandre Bayle, Lucas Janson, Lester Mackey</h3>
<p>This work develops central limit theorems for cross-validation and consistent
estimators of its asymptotic variance under weak stability conditions on the
learning algorithm. Together, these results provide practical,
asymptotically-exact confidence intervals for $k$-fold test error and valid,
powerful hypothesis tests of whether one learning algorithm has smaller
$k$-fold test error than another. These results are also the first of their
kind for the popular choice of leave-one-out cross-validation. In our real-data
experiments with diverse learning algorithms, the resulting intervals and tests
outperform the most popular alternative methods from the literature.
</p>
<a href="http://arxiv.org/abs/2007.12671" target="_blank">arXiv:2007.12671</a> [<a href="http://arxiv.org/pdf/2007.12671" target="_blank">pdf</a>]

<h2>A directional Gaussian smoothing optimization method for computational inverse design in nanophotonics. (arXiv:2007.15079v2 [physics.app-ph] UPDATED)</h2>
<h3>Jiaxin Zhang, Sirui Bi, Guannan Zhang</h3>
<p>Local-gradient-based optimization approaches lack nonlocal exploration
ability required for escaping from local minima in non-convex landscapes. A
directional Gaussian smoothing (DGS) approach was recently proposed by the
authors (Zhang et al., 2020) and used to define a truly nonlocal gradient,
referred to as the DGS gradient, in order to enable nonlocal exploration in
high-dimensional black-box optimization. Promising results show that replacing
the traditional local gradient with the nonlocal DGS gradient can significantly
improve the performance of gradient-based methods in optimizing highly
multi-modal loss functions. However, the current DGS method is designed for
unbounded and unconstrained optimization problems, making it inapplicable to
real-world engineering design optimization problems where the tuning parameters
are often bounded and the loss function is usually constrained by physical
processes. In this work, we propose to extend the DGS approach to the
constrained inverse design framework in order to find a better design. The
proposed framework has its advantages in portability and flexibility to
naturally incorporate the parameterization, physics simulation, and objective
formulation together to build up an effective inverse design workflow. A series
of adaptive strategies for smoothing radius and learning rate updating are
developed to improve the computational efficiency and robustness. To enable a
clear binarized design, a dynamic growth mechanism is imposed on the projection
strength in parameterization. Our methodology is demonstrated by an example of
designing a nanoscale wavelength demultiplexer and shows superior performance
compared to the state-of-the-art approaches. By incorporating volume
constraints, the optimized design achieves an equivalently high performance but
significantly reduces the amount of material usage.
</p>
<a href="http://arxiv.org/abs/2007.15079" target="_blank">arXiv:2007.15079</a> [<a href="http://arxiv.org/pdf/2007.15079" target="_blank">pdf</a>]

<h2>Maximin Optimization for Binary Regression. (arXiv:2010.05077v2 [cs.LG] UPDATED)</h2>
<h3>Nisan Chiprut, Amir Globerson, Ami Wiesel</h3>
<p>We consider regression problems with binary weights. Such optimization
problems are ubiquitous in quantized learning models and digital communication
systems. A natural approach is to optimize the corresponding Lagrangian using
variants of the gradient ascent-descent method. Such maximin techniques are
still poorly understood even in the concave-convex case. The non-convex binary
constraints may lead to spurious local minima. Interestingly, we prove that
this approach is optimal in linear regression with low noise conditions as well
as robust regression with a small number of outliers. Practically, the method
also performs well in regression with cross entropy loss, as well as non-convex
multi-layer neural networks. Taken together our approach highlights the
potential of saddle-point optimization for learning constrained models.
</p>
<a href="http://arxiv.org/abs/2010.05077" target="_blank">arXiv:2010.05077</a> [<a href="http://arxiv.org/pdf/2010.05077" target="_blank">pdf</a>]

<h2>Failures of model-dependent generalization bounds for least-norm interpolation. (arXiv:2010.08479v2 [stat.ML] UPDATED)</h2>
<h3>Peter L. Bartlett, Philip M. Long</h3>
<p>We consider bounds on the generalization performance of the least-norm linear
regressor, in the over-parameterized regime where it can interpolate the data.
We describe a sense in which any generalization bound of a type that is
commonly proved in statistical learning theory must sometimes be very loose
when applied to analyze the least-norm interpolant. In particular, for a
variety of natural joint distributions on training examples, any valid
generalization bound that depends only on the output of the learning algorithm,
the number of training examples, and the confidence parameter, and that
satisfies a mild condition (substantially weaker than monotonicity in sample
size), must sometimes be very loose---it can be bounded below by a constant
when the true excess risk goes to zero.
</p>
<a href="http://arxiv.org/abs/2010.08479" target="_blank">arXiv:2010.08479</a> [<a href="http://arxiv.org/pdf/2010.08479" target="_blank">pdf</a>]

<h2>An Adiabatic Theorem for Policy Tracking with TD-learning. (arXiv:2010.12848v2 [cs.LG] UPDATED)</h2>
<h3>Neil Walton</h3>
<p>We evaluate the ability of temporal difference learning to track the reward
function of a policy as it changes over time. Our results apply a new adiabatic
theorem that bounds the mixing time of time-inhomogeneous Markov chains. We
derive finite-time bounds for tabular temporal difference learning and
$Q$-learning when the policy used for training changes in time. To achieve
this, we develop bounds for stochastic approximation under asynchronous
adiabatic updates.
</p>
<a href="http://arxiv.org/abs/2010.12848" target="_blank">arXiv:2010.12848</a> [<a href="http://arxiv.org/pdf/2010.12848" target="_blank">pdf</a>]

<h2>Variance-Reduced Off-Policy TDC Learning: Non-Asymptotic Convergence Analysis. (arXiv:2010.13272v3 [cs.LG] UPDATED)</h2>
<h3>Shaocong Ma, Yi Zhou, Shaofeng Zou</h3>
<p>Variance reduction techniques have been successfully applied to
temporal-difference (TD) learning and help to improve the sample complexity in
policy evaluation. However, the existing work applied variance reduction to
either the less popular one time-scale TD algorithm or the two time-scale GTD
algorithm but with a finite number of i.i.d.\ samples, and both algorithms
apply to only the on-policy setting. In this work, we develop a variance
reduction scheme for the two time-scale TDC algorithm in the off-policy setting
and analyze its non-asymptotic convergence rate over both i.i.d.\ and Markovian
samples. In the i.i.d.\ setting, our algorithm achieves a sample complexity
$O(\epsilon^{-\frac{3}{5}} \log{\epsilon}^{-1})$ that is lower than the
state-of-the-art result $O(\epsilon^{-1} \log {\epsilon}^{-1})$. In the
Markovian setting, our algorithm achieves the state-of-the-art sample
complexity $O(\epsilon^{-1} \log {\epsilon}^{-1})$ that is near-optimal.
Experiments demonstrate that the proposed variance-reduced TDC achieves a
smaller asymptotic convergence error than both the conventional TDC and the
variance-reduced TD.
</p>
<a href="http://arxiv.org/abs/2010.13272" target="_blank">arXiv:2010.13272</a> [<a href="http://arxiv.org/pdf/2010.13272" target="_blank">pdf</a>]

<h2>Meta-MgNet: Meta Multigrid Networks for Solving Parameterized Partial Differential Equations. (arXiv:2010.14088v2 [math.NA] UPDATED)</h2>
<h3>Yuyan Chen, Bin Dong, Jinchao Xu</h3>
<p>This paper studies numerical solutions for parameterized partial differential
equations (P-PDEs) with deep learning (DL). P-PDEs arise in many important
application areas and the computational cost using traditional numerical
schemes can be exorbitant, especially when the parameters fall into a
particular range and the underlying PDE is required to be solved with high
accuracy. Recently, solving PDEs with DL has become an emerging field. Existing
works demonstrate great potentials of the DL based approach in speeding up
numerical solutions of PDEs. However, there is still limited research on the DL
approach for P-PDEs. If we directly apply existing supervised learning models
to P-PDEs, the models need to be constantly fine-tuned or retrained when the
parameters change. This drastically limits the applicability and utility of
these models in practice. To resolve this issue, we propose a
meta-learning-based method that can efficiently solve P-PDEs with a wide range
of parameters without retraining. Our key observation is to regard training a
solver for the P-PDE with a given set of parameters as a learning task. Then,
training a solver for the P-PDEs with varied parameters can be viewed as a
multi-task learning problem, to which meta-learning is one of the most
effective approaches. This new perspective can be applied to many existing PDE
solvers. As an example, we adopt the Multigrid Network (MgNet) as the base
solver. To achieve multi-task learning, we introduce a new hypernetwork, called
Meta-NN, in MgNet and refer to the entire network as the Meta-MgNet. Meta-NN
takes the differential operators and the right-hand-side of the underlying
P-PDEs as inputs and generates appropriate smoothers for MgNet which can
significantly affect the convergent speed. Finally, extensive numerical
experiments demonstrate that Meta-MgNet is more efficient in solving P-PDEs
than the MG methods and MgNet.
</p>
<a href="http://arxiv.org/abs/2010.14088" target="_blank">arXiv:2010.14088</a> [<a href="http://arxiv.org/pdf/2010.14088" target="_blank">pdf</a>]

<h2>Identifying Exoplanets with Deep Learning. IV. Removing Stellar Activity Signals from Radial Velocity Measurements Using Neural Networks. (arXiv:2011.00003v1 [astro-ph.EP])</h2>
<h3>Zoe L. de Beurs, Andrew Vanderburg, Christopher J. Shallue, Xavier Dumusque, Andrew Collier Cameron, Lars A. Buchhave, Rosario Cosentino, Adriano Ghedina, Rapha&#xeb;lle D. Haywood, Nicholas Langellier, David W. Latham, Mercedes L&#xf3;pez-Morales, Michel Mayor, Giusi Micela, Timothy W. Milbourne, Annelies Mortier, Emilio Molinari, Francesco Pepe, David F. Phillips, Matteo Pinamonti, Giampaolo Piotto, Ken Rice, Dimitar Sasselov, Alessandro Sozzetti, St&#xe9;phane Udry, Christopher A. Watson</h3>
<p>Exoplanet detection with precise radial velocity (RV) observations is
currently limited by spurious RV signals introduced by stellar activity. We
show that machine learning techniques such as linear regression and neural
networks can effectively remove the activity signals (due to starspots/faculae)
from RV observations. Previous efforts focused on carefully filtering out
activity signals in time using modeling techniques like Gaussian Process
regression (e.g. Haywood et al. 2014). Instead, we systematically remove
activity signals using only changes to the average shape of spectral lines, and
no information about when the observations were collected. We trained our
machine learning models on both simulated data (generated with the SOAP 2.0
software; Dumusque et al. 2014) and observations of the Sun from the HARPS-N
Solar Telescope (Dumusque et al. 2015; Phillips et al. 2016; Collier Cameron et
al. 2019). We find that these techniques can predict and remove stellar
activity from both simulated data (improving RV scatter from 82 cm/s to 3 cm/s)
and from more than 600 real observations taken nearly daily over three years
with the HARPS-N Solar Telescope (improving the RV scatter from 1.47 m/s to
0.78 m/s, a factor of ~ 1.9 improvement). In the future, these or similar
techniques could remove activity signals from observations of stars outside our
solar system and eventually help detect habitable-zone Earth-mass exoplanets
around Sun-like stars.
</p>
<a href="http://arxiv.org/abs/2011.00003" target="_blank">arXiv:2011.00003</a> [<a href="http://arxiv.org/pdf/2011.00003" target="_blank">pdf</a>]

<h2>The power of quantum neural networks. (arXiv:2011.00027v1 [quant-ph])</h2>
<h3>Amira Abbas, David Sutter, Christa Zoufal, Aur&#xe9;lien Lucchi, Alessio Figalli, Stefan Woerner</h3>
<p>Fault-tolerant quantum computers offer the promise of dramatically improving
machine learning through speed-ups in computation or improved model
scalability. In the near-term, however, the benefits of quantum machine
learning are not so clear. Understanding expressibility and trainability of
quantum models-and quantum neural networks in particular-requires further
investigation. In this work, we use tools from information geometry to define a
notion of expressibility for quantum and classical models. The effective
dimension, which depends on the Fisher information, is used to prove a novel
generalisation bound and establish a robust measure of expressibility. We show
that quantum neural networks are able to achieve a significantly better
effective dimension than comparable classical neural networks. To then assess
the trainability of quantum models, we connect the Fisher information spectrum
to barren plateaus, the problem of vanishing gradients. Importantly, certain
quantum neural networks can show resilience to this phenomenon and train faster
than classical models due to their favourable optimisation landscapes, captured
by a more evenly spread Fisher information spectrum. Our work is the first to
demonstrate that well-designed quantum neural networks offer an advantage over
classical neural networks through a higher effective dimension and faster
training ability, which we verify on real quantum hardware.
</p>
<a href="http://arxiv.org/abs/2011.00027" target="_blank">arXiv:2011.00027</a> [<a href="http://arxiv.org/pdf/2011.00027" target="_blank">pdf</a>]

<h2>Semi-Supervised Intent Inferral Using Ipsilateral Biosignals on a Hand Orthosis for Stroke Subjects. (arXiv:2011.00034v1 [cs.RO])</h2>
<h3>Cassie Meeker, Michaela Fraser, Sangwoo Park, Ava Chen, Lynne M. Weber, Mitchell Miya, Joel Stein, Matei Ciocarlie</h3>
<p>In order to provide therapy in a functional context, controls for wearable
orthoses need to be robust and intuitive. We have previously introduced an
intuitive, user-driven, EMG based orthotic control, but the process of training
a control which is robust to concept drift (changes in the input signal) places
a substantial burden on the user. In this paper, we explore semi-supervised
learning as a paradigm for wearable orthotic controls. We are the first to use
semi-supervised learning for an orthotic application. We propose a K-means
semi-supervision and a disagreement-based semi-supervision algorithm. This is
an exploratory study designed to determine the feasibility of semi-supervised
learning as a control paradigm for wearable orthotics. In offline experiments
with stroke subjects, we show that these algorithms have the potential to
reduce the training burden placed on the user, and that they merit further
study.
</p>
<a href="http://arxiv.org/abs/2011.00034" target="_blank">arXiv:2011.00034</a> [<a href="http://arxiv.org/pdf/2011.00034" target="_blank">pdf</a>]

<h2>Measure Inducing Classification and Regression Trees for Functional Data. (arXiv:2011.00046v1 [stat.ML])</h2>
<h3>Edoardo Belli, Simone Vantini</h3>
<p>We propose a tree-based algorithm for classification and regression problems
in the context of functional data analysis, which allows to leverage
representation learning and multiple splitting rules at the node level,
reducing generalization error while retaining the interpretability of a tree.
This is achieved by learning a weighted functional $L^{2}$ space by means of
constrained convex optimization, which is then used to extract multiple
weighted integral features from the input functions, in order to determine the
binary split for each internal node of the tree. The approach is designed to
manage multiple functional inputs and/or outputs, by defining suitable
splitting rules and loss functions that can depend on the specific problem and
can also be combined with scalar and categorical data, as the tree is grown
with the original greedy CART algorithm. We focus on the case of scalar-valued
functional inputs defined on unidimensional domains and illustrate the
effectiveness of our method in both classification and regression tasks,
through a simulation study and four real world applications.
</p>
<a href="http://arxiv.org/abs/2011.00046" target="_blank">arXiv:2011.00046</a> [<a href="http://arxiv.org/pdf/2011.00046" target="_blank">pdf</a>]

<h2>Dataset Meta-Learning from Kernel Ridge-Regression. (arXiv:2011.00050v1 [cs.LG])</h2>
<h3>Timothy Nguyen, Zhourung Chen, Jaehoon Lee</h3>
<p>One of the most fundamental aspects of any machine learning algorithm is the
training data used by the algorithm. We introduce the novel concept of
$\epsilon$-approximation of datasets, obtaining datasets which are much smaller
than or are significant corruptions of the original training data while
maintaining similar model performance. We introduce a meta-learning algorithm
called Kernel Inducing Points (KIP) for obtaining such remarkable datasets,
inspired by the recent developments in the correspondence between
infinitely-wide neural networks and kernel ridge-regression (KRR). For KRR
tasks, we demonstrate that KIP can compress datasets by one or two orders of
magnitude, significantly improving previous dataset distillation and subset
selection methods while obtaining state of the art results for MNIST and
CIFAR-10 classification. Furthermore, our KIP-learned datasets are transferable
to the training of finite-width neural networks even beyond the lazy-training
regime, which leads to state of the art results for neural network dataset
distillation with potential applications to privacy-preservation.
</p>
<a href="http://arxiv.org/abs/2011.00050" target="_blank">arXiv:2011.00050</a> [<a href="http://arxiv.org/pdf/2011.00050" target="_blank">pdf</a>]

<h2>(Un)Masked COVID-19 Trends from Social Media. (arXiv:2011.00052v1 [cs.CV])</h2>
<h3>Asmit Kumar Singh, Paras Mehan, Divyanshu Sharma, Rohan Pandey, Tavpritesh Sethi, Ponnurangam Kumaraguru</h3>
<p>COVID-19 has affected the entire world. One useful protection method for
people against COVID-19 is to wear masks in public areas. Across the globe,
many public service providers have mandated correctly wearing masks to use
their services. This paper proposes two new datasets VAriety MAsks -
Classification VAMA-C) and VAriety MAsks - Segmentation (VAMA-S), for mask
detection and mask fit analysis tasks, respectively. We propose a framework for
classifying masked and unmasked faces and a segmentation based model to
calculate the mask-fit score. Both the models trained in this study achieved an
accuracy of 98%. Using the two trained deep learning models, 2.04 million
social media images for six major US cities were analyzed. By comparing the
regulations, an increase in masks worn in images as the COVID-19 cases rose in
these cities was observed, particularly when their respective states imposed
strict regulations. Furthermore, mask compliance in the Black Lives Matter
protest was analyzed, eliciting that 40% of the people in group photos wore
masks, and 45% of them wore the masks with a fit score of greater than 80%.
</p>
<a href="http://arxiv.org/abs/2011.00052" target="_blank">arXiv:2011.00052</a> [<a href="http://arxiv.org/pdf/2011.00052" target="_blank">pdf</a>]

<h2>Adversarial Robust Training in MRI Reconstruction. (arXiv:2011.00070v1 [eess.IV])</h2>
<h3>Francesco Caliv&#xe1;, Kaiyang Cheng, Rutwik Shah, Valentina Pedoia</h3>
<p>Deep Learning has shown potential in accelerating Magnetic Resonance Image
acquisition and reconstruction. Nevertheless, there is a dearth of tailored
methods to guarantee that the reconstruction of small features is achieved with
high fidelity. In this work, we employ adversarial attacks to generate small
synthetic perturbations that when added to the input MRI, they are not
reconstructed by a trained DL reconstruction network. Then, we use robust
training to increase the network's sensitivity to small features and encourage
their reconstruction. Next, we investigate the generalization of said approach
to real world features. For this, a musculoskeletal radiologist annotated a set
of cartilage and meniscal lesions from the knee Fast-MRI dataset, and a
classification network was devised to assess the features reconstruction.
Experimental results show that by introducing robust training to a
reconstruction network, the rate (4.8\%) of false negative features in image
reconstruction can be reduced. The results are encouraging and highlight the
necessity for attention on this problem by the image reconstruction community,
as a milestone for the introduction of DL reconstruction in clinical practice.
To support further research, we make our annotation publicly available at
https://github.com/fcaliva/fastMRI_BB_abnormalities_annotation.
</p>
<a href="http://arxiv.org/abs/2011.00070" target="_blank">arXiv:2011.00070</a> [<a href="http://arxiv.org/pdf/2011.00070" target="_blank">pdf</a>]

<h2>83% ImageNet Accuracy in One Hour. (arXiv:2011.00071v1 [cs.LG])</h2>
<h3>Arissa Wongpanich, Hieu Pham, James Demmel, Mingxing Tan, Quoc Le, Yang You, Sameer Kumar</h3>
<p>EfficientNets are a family of state-of-the-art image classification models
based on efficiently scaled convolutional neural networks. Currently,
EfficientNets can take on the order of days to train; for example, training an
EfficientNet-B0 model takes 23 hours on a Cloud TPU v2-8 node. In this paper,
we explore techniques to scale up the training of EfficientNets on TPU-v3 Pods
with 2048 cores, motivated by speedups that can be achieved when training at
such scales. We discuss optimizations required to scale training to a batch
size of 65536 on 1024 TPU-v3 cores, such as selecting large batch optimizers
and learning rate schedules as well as utilizing distributed evaluation and
batch normalization techniques. Additionally, we present timing and performance
benchmarks for EfficientNet models trained on the ImageNet dataset in order to
analyze the behavior of EfficientNets at scale. With our optimizations, we are
able to train EfficientNet on ImageNet to an accuracy of 83% in 1 hour and 4
minutes.
</p>
<a href="http://arxiv.org/abs/2011.00071" target="_blank">arXiv:2011.00071</a> [<a href="http://arxiv.org/pdf/2011.00071" target="_blank">pdf</a>]

<h2>Learning Stable Normalizing-Flow Control for Robotic Manipulation. (arXiv:2011.00072v1 [cs.RO])</h2>
<h3>Shahbaz Abdul Khader, Hang Yin, Pietro Falco, Danica Kragic</h3>
<p>Reinforcement Learning (RL) of robotic manipulation skills, despite its
impressive successes, stands to benefit from incorporating domain knowledge
from control theory. One of the most important properties that is of interest
is control stability. Ideally, one would like to achieve stability guarantees
while staying within the framework of state-of-the-art deep RL algorithms. Such
a solution does not exist in general, especially one that scales to complex
manipulation tasks. We contribute towards closing this gap by introducing
$\textit{normalizing-flow}$ control structure, that can be deployed in any
latest deep RL algorithms. While stable exploration is not guaranteed, our
method is designed to ultimately produce deterministic controllers with
provable stability. In addition to demonstrating our method on challenging
contact-rich manipulation tasks, we also show that it is possible to achieve
considerable exploration efficiency--reduced state space coverage and actuation
efforts--without losing learning efficiency.
</p>
<a href="http://arxiv.org/abs/2011.00072" target="_blank">arXiv:2011.00072</a> [<a href="http://arxiv.org/pdf/2011.00072" target="_blank">pdf</a>]

<h2>Resource-Aware Pareto-Optimal Automated Machine Learning Platform. (arXiv:2011.00073v1 [cs.LG])</h2>
<h3>Yao Yang, Andrew Nam, Mohamad M. Nasr-Azadani, Teresa Tung</h3>
<p>In this study, we introduce a novel platform Resource-Aware AutoML
(RA-AutoML) which enables flexible and generalized algorithms to build machine
learning models subjected to multiple objectives, as well as resource and
hard-ware constraints. RA-AutoML intelligently conducts Hyper-Parameter
Search(HPS) as well as Neural Architecture Search (NAS) to build models
optimizing predefined objectives. RA-AutoML is a versatile framework that
allows user to prescribe many resource/hardware constraints along with
objectives demanded by the problem at hand or business requirements. At its
core, RA-AutoML relies on our in-house search-engine algorithm,MOBOGA, which
combines a modified constraint-aware Bayesian Optimization and Genetic
Algorithm to construct Pareto optimal candidates. Our experiments on CIFAR-10
dataset shows very good accuracy compared to results obtained by state-of-art
neural network models, while subjected to resource constraints in the form of
model size.
</p>
<a href="http://arxiv.org/abs/2011.00073" target="_blank">arXiv:2011.00073</a> [<a href="http://arxiv.org/pdf/2011.00073" target="_blank">pdf</a>]

<h2>Dynamic Data Selection for Curriculum Learning via Ability Estimation. (arXiv:2011.00080v1 [cs.CL])</h2>
<h3>John P. Lalor, Hong Yu</h3>
<p>Curriculum learning methods typically rely on heuristics to estimate the
difficulty of training examples or the ability of the model. In this work, we
propose replacing difficulty heuristics with learned difficulty parameters. We
also propose Dynamic Data selection for Curriculum Learning via Ability
Estimation (DDaCLAE), a strategy that probes model ability at each training
epoch to select the best training examples at that point. We show that models
using learned difficulty and/or ability outperform heuristic-based curriculum
learning models on the GLUE classification tasks.
</p>
<a href="http://arxiv.org/abs/2011.00080" target="_blank">arXiv:2011.00080</a> [<a href="http://arxiv.org/pdf/2011.00080" target="_blank">pdf</a>]

<h2>C-Net: A Reliable Convolutional Neural Network for Biomedical Image Classification. (arXiv:2011.00081v1 [eess.IV])</h2>
<h3>Hosein Barzekar, Zeyun Yu</h3>
<p>Cancers are the leading cause of death in many developed countries. Early
diagnosis plays a crucial role in having proper treatment for this debilitating
disease. The automated classification of the type of cancer is a challenging
task since pathologists must examine a huge number of histopathological images
to detect infinitesimal abnormalities. In this study, we propose a novel
convolutional neural network (CNN) architecture composed of a Concatenation of
multiple Networks, called C-Net, to classify biomedical images. In contrast to
conventional deep learning models in biomedical image classification, which
utilize transfer learning to solve the problem, no prior knowledge is employed.
The model incorporates multiple CNNs including Outer, Middle, and Inner. The
first two parts of the architecture contain six networks that serve as feature
extractors to feed into the Inner network to classify the images in terms of
malignancy and benignancy. The C-Net is applied for histopathological image
classification on two public datasets, including BreakHis and Osteosarcoma. To
evaluate the performance, the model is tested using several evaluation metrics
for its reliability. The C-Net model outperforms all other models on the
individual metrics for both datasets and achieves zero misclassification.
</p>
<a href="http://arxiv.org/abs/2011.00081" target="_blank">arXiv:2011.00081</a> [<a href="http://arxiv.org/pdf/2011.00081" target="_blank">pdf</a>]

<h2>Directional ASR: A New Paradigm for E2E Multi-Speaker Speech Recognition with Source Localization. (arXiv:2011.00091v1 [eess.AS])</h2>
<h3>Aswin Shanmugam Subramanian, Chao Weng, Shinji Watanabe, Meng Yu, Yong Xu, Shi-Xiong Zhang, Dong Yu</h3>
<p>This paper proposes a new paradigm for handling far-field multi-speaker data
in an end-to-end neural network manner, called directional automatic speech
recognition (D-ASR), which explicitly models source speaker locations. In
D-ASR, the azimuth angle of the sources with respect to the microphone array is
defined as a latent variable. This angle controls the quality of separation,
which in turn determines the ASR performance. All three functionalities of
D-ASR: localization, separation, and recognition are connected as a single
differentiable neural network and trained solely based on ASR error
minimization objectives. The advantages of D-ASR over existing methods are
threefold: (1) it provides explicit speaker locations, (2) it improves the
explainability factor, and (3) it achieves better ASR performance as the
process is more streamlined. In addition, D-ASR does not require explicit
direction of arrival (DOA) supervision like existing data-driven localization
models, which makes it more appropriate for realistic data. For the case of two
source mixtures, D-ASR achieves an average DOA prediction error of less than
three degrees. It also outperforms a strong far-field multi-speaker end-to-end
system in both separation quality and ASR performance.
</p>
<a href="http://arxiv.org/abs/2011.00091" target="_blank">arXiv:2011.00091</a> [<a href="http://arxiv.org/pdf/2011.00091" target="_blank">pdf</a>]

<h2>Analyzing Gender Bias within Narrative Tropes. (arXiv:2011.00092v1 [cs.CL])</h2>
<h3>Dhruvil Gala, Mohammad Omar Khursheed, Hannah Lerner, Brendan O&#x27;Connor, Mohit Iyyer</h3>
<p>Popular media reflects and reinforces societal biases through the use of
tropes, which are narrative elements, such as archetypal characters and plot
arcs, that occur frequently across media. In this paper, we specifically
investigate gender bias within a large collection of tropes. To enable our
study, we crawl tvtropes.org, an online user-created repository that contains
30K tropes associated with 1.9M examples of their occurrences across film,
television, and literature. We automatically score the "genderedness" of each
trope in our TVTROPES dataset, which enables an analysis of (1) highly-gendered
topics within tropes, (2) the relationship between gender bias and popular
reception, and (3) how the gender of a work's creator correlates with the types
of tropes that they use.
</p>
<a href="http://arxiv.org/abs/2011.00092" target="_blank">arXiv:2011.00092</a> [<a href="http://arxiv.org/pdf/2011.00092" target="_blank">pdf</a>]

<h2>Joint Masked CPC and CTC Training for ASR. (arXiv:2011.00093v1 [cs.CL])</h2>
<h3>Chaitanya Talnikar, Tatiana Likhomanenko, Ronan Collobert, Gabriel Synnaeve</h3>
<p>Self-supervised learning (SSL) has shown promise in learning representations
of audio that are useful for automatic speech recognition (ASR). But, training
SSL models like wav2vec~2.0 requires a two-stage pipeline. In this paper we
demonstrate a single-stage training of ASR models that can utilize both
unlabeled and labeled data. During training, we alternately minimize two
losses: an unsupervised masked Contrastive Predictive Coding (CPC) loss and the
supervised audio-to-text alignment loss Connectionist Temporal Classification
(CTC). We show that this joint training method directly optimizes performance
for the downstream ASR task using unsupervised data while achieving similar
word error rates to wav2vec~2.0 on the Librispeech 100-hour dataset. Finally,
we postulate that solving the contrastive task is a regularization for the
supervised CTC loss.
</p>
<a href="http://arxiv.org/abs/2011.00093" target="_blank">arXiv:2011.00093</a> [<a href="http://arxiv.org/pdf/2011.00093" target="_blank">pdf</a>]

<h2>Representation Learning for Integrating Multi-domain Outcomes to Optimize Individualized Treatments. (arXiv:2011.00094v1 [cs.LG])</h2>
<h3>Yuan Chen, Donglin Zeng, Tianchen Xu, Yuanjia Wang</h3>
<p>For mental disorders, patients' underlying mental states are non-observed
latent constructs which have to be inferred from observed multi-domain
measurements such as diagnostic symptoms and patient functioning scores.
Additionally, substantial heterogeneity in the disease diagnosis between
patients needs to be addressed for optimizing individualized treatment policy
in order to achieve precision medicine. To address these challenges, we propose
an integrated learning framework that can simultaneously learn patients'
underlying mental states and recommend optimal treatments for each individual.
This learning framework is based on the measurement theory in psychiatry for
modeling multiple disease diagnostic measures as arising from the underlying
causes (true mental states). It allows incorporation of the multivariate pre-
and post-treatment outcomes as well as biological measures while preserving the
invariant structure for representing patients' latent mental states. A
multi-layer neural network is used to allow complex treatment effect
heterogeneity. Optimal treatment policy can be inferred for future patients by
comparing their potential mental states under different treatments given the
observed multi-domain pre-treatment measurements. Experiments on simulated data
and a real-world clinical trial data show that the learned treatment polices
compare favorably to alternative methods on heterogeneous treatment effects,
and have broad utilities which lead to better patient outcomes on multiple
domains.
</p>
<a href="http://arxiv.org/abs/2011.00094" target="_blank">arXiv:2011.00094</a> [<a href="http://arxiv.org/pdf/2011.00094" target="_blank">pdf</a>]

<h2>EEG-Based Brain-Computer Interfaces Are Vulnerable to Backdoor Attacks. (arXiv:2011.00101v1 [cs.CR])</h2>
<h3>Lubin Meng, Jian Huang, Zhigang Zeng, Xue Jiang, Shan Yu, Tzyy-Ping Jung, Chin-Teng Lin, Ricardo Chavarriaga, Dongrui Wu</h3>
<p>Research and development of electroencephalogram (EEG) based brain-computer
interfaces (BCIs) have advanced rapidly, partly due to the wide adoption of
sophisticated machine learning approaches for decoding the EEG signals.
However, recent studies have shown that machine learning algorithms are
vulnerable to adversarial attacks, e.g., the attacker can add tiny adversarial
perturbations to a test sample to fool the model, or poison the training data
to insert a secret backdoor. Previous research has shown that adversarial
attacks are also possible for EEG-based BCIs. However, only adversarial
perturbations have been considered, and the approaches are theoretically sound
but very difficult to implement in practice. This article proposes to use
narrow period pulse for poisoning attack of EEG-based BCIs, which is more
feasible in practice and has never been considered before. One can create
dangerous backdoors in the machine learning model by injecting poisoning
samples into the training set. Test samples with the backdoor key will then be
classified into the target class specified by the attacker. What most
distinguishes our approach from previous ones is that the backdoor key does not
need to be synchronized with the EEG trials, making it very easy to implement.
The effectiveness and robustness of the backdoor attack approach is
demonstrated, highlighting a critical security concern for EEG-based BCIs.
</p>
<a href="http://arxiv.org/abs/2011.00101" target="_blank">arXiv:2011.00101</a> [<a href="http://arxiv.org/pdf/2011.00101" target="_blank">pdf</a>]

<h2>Learning Structured Representations of Entity Names using Active Learning and Weak Supervision. (arXiv:2011.00105v1 [cs.CL])</h2>
<h3>Kun Qian, Poornima Chozhiyath Raman, Yunyao Li, Lucian Popa</h3>
<p>Structured representations of entity names are useful for many entity-related
tasks such as entity normalization and variant generation. Learning the
implicit structured representations of entity names without context and
external knowledge is particularly challenging. In this paper, we present a
novel learning framework that combines active learning and weak supervision to
solve this problem. Our experimental evaluation show that this framework
enables the learning of high-quality models from merely a dozen or so labeled
examples.
</p>
<a href="http://arxiv.org/abs/2011.00105" target="_blank">arXiv:2011.00105</a> [<a href="http://arxiv.org/pdf/2011.00105" target="_blank">pdf</a>]

<h2>Semantic similarity-based approach to enhance supervised classification learning accuracy. (arXiv:2011.00109v1 [cs.LG])</h2>
<h3>Houcemeddine Turki, Mohamed Ali Hadj Taieb, Mohamed Ben Aouicha</h3>
<p>This brief communication discusses the usefulness of semantic similarity
measures for the evaluation and amelioration of the accuracy of supervised
classification learning. It proposes a semantic similarity-based method to
enhance the choice of adequate labels for the classification algorithm as well
as two metrics (SS-Score and TD-Score) and a curve (SA-Curve) that can be
coupled to statistical evaluation measures of supervised classification
learning to take into consideration the impact of the semantic aspect of the
labels on the classification accuracy.
</p>
<a href="http://arxiv.org/abs/2011.00109" target="_blank">arXiv:2011.00109</a> [<a href="http://arxiv.org/pdf/2011.00109" target="_blank">pdf</a>]

<h2>Photonics for artificial intelligence and neuromorphic computing. (arXiv:2011.00111v1 [physics.optics])</h2>
<h3>Bhavin J. Shastri, Alexander N. Tait, Thomas Ferreira de Lima, Wolfram H. P. Pernice, Harish Bhaskaran, C. David Wright, Paul R. Prucnal</h3>
<p>Research in photonic computing has flourished due to the proliferation of
optoelectronic components on photonic integration platforms. Photonic
integrated circuits have enabled ultrafast artificial neural networks,
providing a framework for a new class of information processing machines.
Algorithms running on such hardware have the potential to address the growing
demand for machine learning and artificial intelligence, in areas such as
medical diagnosis, telecommunications, and high-performance and scientific
computing. In parallel, the development of neuromorphic electronics has
highlighted challenges in that domain, in particular, related to processor
latency. Neuromorphic photonics offers sub-nanosecond latencies, providing a
complementary opportunity to extend the domain of artificial intelligence.
Here, we review recent advances in integrated photonic neuromorphic systems,
discuss current and future challenges, and outline the advances in science and
technology needed to meet those challenges.
</p>
<a href="http://arxiv.org/abs/2011.00111" target="_blank">arXiv:2011.00111</a> [<a href="http://arxiv.org/pdf/2011.00111" target="_blank">pdf</a>]

<h2>Optimizing Mixed Autonomy Traffic Flow With Decentralized Autonomous Vehicles and Multi-Agent RL. (arXiv:2011.00120v1 [eess.SY])</h2>
<h3>Eugene Vinitsky, Nathan Lichtle, Kanaad Parvate, Alexandre Bayen</h3>
<p>We study the ability of autonomous vehicles to improve the throughput of a
bottleneck using a fully decentralized control scheme in a mixed autonomy
setting. We consider the problem of improving the throughput of a scaled model
of the San Francisco-Oakland Bay Bridge: a two-stage bottleneck where four
lanes reduce to two and then reduce to one. Although there is extensive work
examining variants of bottleneck control in a centralized setting, there is
less study of the challenging multi-agent setting where the large number of
interacting AVs leads to significant optimization difficulties for
reinforcement learning methods. We apply multi-agent reinforcement algorithms
to this problem and demonstrate that significant improvements in bottleneck
throughput, from 20\% at a 5\% penetration rate to 33\% at a 40\% penetration
rate, can be achieved. We compare our results to a hand-designed feedback
controller and demonstrate that our results sharply outperform the feedback
controller despite extensive tuning. Additionally, we demonstrate that the
RL-based controllers adopt a robust strategy that works across penetration
rates whereas the feedback controllers degrade immediately upon penetration
rate variation. We investigate the feasibility of both action and observation
decentralization and demonstrate that effective strategies are possible using
purely local sensing. Finally, we open-source our code at
https://github.com/eugenevinitsky/decentralized_bottlenecks.
</p>
<a href="http://arxiv.org/abs/2011.00120" target="_blank">arXiv:2011.00120</a> [<a href="http://arxiv.org/pdf/2011.00120" target="_blank">pdf</a>]

<h2>Multi-stage transfer learning for lung segmentation using portable X-ray devices for patients with COVID-19. (arXiv:2011.00133v1 [eess.IV])</h2>
<h3>Pl&#xe1;cido L Vidal, Joaquim de Moura, Jorge Novo, Marcos Ortega</h3>
<p>In 2020, the SARS-CoV-2 virus causes a global pandemic of the new human
coronavirus disease COVID-19. This pathogen primarily infects the respiratory
system of the afflicted, usually resulting in pneumonia and in a severe case of
acute respiratory distress syndrome. These disease developments result in the
formation of different pathological structures in the lungs, similar to those
observed in other viral pneumonias that can be detected by the use of chest
X-rays. For this reason, the detection and analysis of the pulmonary regions,
the main focus of affection of COVID-19, becomes a crucial part of both
clinical and automatic diagnosis processes. Due to the overload of the health
services, portable X-ray devices are widely used, representing an alternative
to fixed devices to reduce the risk of cross-contamination. However, these
devices entail different complications as the image quality that, together with
the subjectivity of the clinician, make the diagnostic process more difficult.
In this work, we developed a novel fully automatic methodology specially
designed for the identification of these lung regions in X-ray images of low
quality as those from portable devices. To do so, we took advantage of a large
dataset from magnetic resonance imaging of a similar pathology and performed
two stages of transfer learning to obtain a robust methodology with a low
number of images from portable X-ray devices. This way, our methodology
obtained a satisfactory accuracy of $0.9761 \pm 0.0100$ for patients with
COVID-19, $0.9801 \pm 0.0104$ for normal patients and $0.9769 \pm 0.0111$ for
patients with pulmonary diseases with similar characteristics as COVID-19 (such
as pneumonia) but not genuine COVID-19.
</p>
<a href="http://arxiv.org/abs/2011.00133" target="_blank">arXiv:2011.00133</a> [<a href="http://arxiv.org/pdf/2011.00133" target="_blank">pdf</a>]

<h2>Improving Dialogue Breakdown Detection with Semi-Supervised Learning. (arXiv:2011.00136v1 [cs.CL])</h2>
<h3>Nathan Ng, Marzyeh Ghassemi, Narendran Thangarajan, Jiacheng Pan, Qi Guo</h3>
<p>Building user trust in dialogue agents requires smooth and consistent
dialogue exchanges. However, agents can easily lose conversational context and
generate irrelevant utterances. These situations are called dialogue breakdown,
where agent utterances prevent users from continuing the conversation. Building
systems to detect dialogue breakdown allows agents to recover appropriately or
avoid breakdown entirely. In this paper we investigate the use of
semi-supervised learning methods to improve dialogue breakdown detection,
including continued pre-training on the Reddit dataset and a manifold-based
data augmentation method. We demonstrate the effectiveness of these methods on
the Dialogue Breakdown Detection Challenge (DBDC) English shared task. Our
submissions to the 2020 DBDC5 shared task place first, beating baselines and
other submissions by over 12\% accuracy. In ablations on DBDC4 data from 2019,
our semi-supervised learning methods improve the performance of a baseline BERT
model by 2\% accuracy. These methods are applicable generally to any dialogue
task and provide a simple way to improve model performance.
</p>
<a href="http://arxiv.org/abs/2011.00136" target="_blank">arXiv:2011.00136</a> [<a href="http://arxiv.org/pdf/2011.00136" target="_blank">pdf</a>]

<h2>EDCNN: Edge enhancement-based Densely Connected Network with Compound Loss for Low-Dose CT Denoising. (arXiv:2011.00139v1 [eess.IV])</h2>
<h3>Tengfei Liang, Yi Jin, Yidong Li, Tao Wang, Songhe Feng, Congyan Lang</h3>
<p>In the past few decades, to reduce the risk of X-ray in computed tomography
(CT), low-dose CT image denoising has attracted extensive attention from
researchers, which has become an important research issue in the field of
medical images. In recent years, with the rapid development of deep learning
technology, many algorithms have emerged to apply convolutional neural networks
to this task, achieving promising results. However, there are still some
problems such as low denoising efficiency, over-smoothed result, etc. In this
paper, we propose the Edge enhancement based Densely connected Convolutional
Neural Network (EDCNN). In our network, we design an edge enhancement module
using the proposed novel trainable Sobel convolution. Based on this module, we
construct a model with dense connections to fuse the extracted edge information
and realize end-to-end image denoising. Besides, when training the model, we
introduce a compound loss that combines MSE loss and multi-scales perceptual
loss to solve the over-smoothed problem and attain a marked improvement in
image quality after denoising. Compared with the existing low-dose CT image
denoising algorithms, our proposed model has a better performance in preserving
details and suppressing noise.
</p>
<a href="http://arxiv.org/abs/2011.00139" target="_blank">arXiv:2011.00139</a> [<a href="http://arxiv.org/pdf/2011.00139" target="_blank">pdf</a>]

<h2>Leveraging Adaptive Color Augmentation in Convolutional Neural Networks for Deep Skin Lesion Segmentation. (arXiv:2011.00148v1 [cs.CV])</h2>
<h3>Anindo Saha, Prem Prasad, Abdullah Thabit</h3>
<p>Fully automatic detection of skin lesions in dermatoscopic images can
facilitate early diagnosis and repression of malignant melanoma and
non-melanoma skin cancer. Although convolutional neural networks are a powerful
solution, they are limited by the illumination spectrum of annotated
dermatoscopic screening images, where color is an important discriminative
feature. In this paper, we propose an adaptive color augmentation technique to
amplify data expression and model performance, while regulating color
difference and saturation to minimize the risks of using synthetic data.
Through deep visualization, we qualitatively identify and verify the semantic
structural features learned by the network for discriminating skin lesions
against normal skin tissue. The overall system achieves a Dice Ratio of 0.891
with 0.943 sensitivity and 0.932 specificity on the ISIC 2018 Testing Set for
segmentation.
</p>
<a href="http://arxiv.org/abs/2011.00148" target="_blank">arXiv:2011.00148</a> [<a href="http://arxiv.org/pdf/2011.00148" target="_blank">pdf</a>]

<h2>Weakly Supervised 3D Classification of Chest CT using Aggregated Multi-Resolution Deep Segmentation Features. (arXiv:2011.00149v1 [cs.CV])</h2>
<h3>Anindo Saha, Fakrul I. Tushar, Khrystyna Faryna, Vincent M. D&#x27;Anniballe, Rui Hou, Maciej A. Mazurowski, Geoffrey D. Rubin, Joseph Y. Lo</h3>
<p>Weakly supervised disease classification of CT imaging suffers from poor
localization owing to case-level annotations, where even a positive scan can
hold hundreds to thousands of negative slices along multiple planes.
Furthermore, although deep learning segmentation and classification models
extract distinctly unique combinations of anatomical features from the same
target class(es), they are typically seen as two independent processes in a
computer-aided diagnosis (CAD) pipeline, with little to no feature reuse. In
this research, we propose a medical classifier that leverages the semantic
structural concepts learned via multi-resolution segmentation feature maps, to
guide weakly supervised 3D classification of chest CT volumes. Additionally, a
comparative analysis is drawn across two different types of feature aggregation
to explore the vast possibilities surrounding feature fusion. Using a dataset
of 1593 scans labeled on a case-level basis via rule-based model, we train a
dual-stage convolutional neural network (CNN) to perform organ segmentation and
binary classification of four representative diseases (emphysema,
pneumonia/atelectasis, mass and nodules) in lungs. The baseline model, with
separate stages for segmentation and classification, results in AUC of 0.791.
Using identical hyperparameters, the connected architecture using static and
dynamic feature aggregation improves performance to AUC of 0.832 and 0.851,
respectively. This study advances the field in two key ways. First, case-level
report data is used to weakly supervise a 3D CT classifier of multiple,
simultaneous diseases for an organ. Second, segmentation and classification
models are connected with two different feature aggregation strategies to
enhance the classification performance.
</p>
<a href="http://arxiv.org/abs/2011.00149" target="_blank">arXiv:2011.00149</a> [<a href="http://arxiv.org/pdf/2011.00149" target="_blank">pdf</a>]

<h2>Deep Reactive Planning in Dynamic Environments. (arXiv:2011.00155v1 [cs.RO])</h2>
<h3>Kei Ota, Devesh K. Jha, Tadashi Onishi, Asako Kanezaki, Yusuke Yoshiyasu, Yoko Sasaki, Toshisada Mariyama, Daniel Nikovski</h3>
<p>The main novelty of the proposed approach is that it allows a robot to learn
an end-to-end policy which can adapt to changes in the environment during
execution. While goal conditioning of policies has been studied in the RL
literature, such approaches are not easily extended to cases where the robot's
goal can change during execution. This is something that humans are naturally
able to do. However, it is difficult for robots to learn such reflexes (i.e.,
to naturally respond to dynamic environments), especially when the goal
location is not explicitly provided to the robot, and instead needs to be
perceived through a vision sensor. In the current work, we present a method
that can achieve such behavior by combining traditional kinematic planning,
deep learning, and deep reinforcement learning in a synergistic fashion to
generalize to arbitrary environments. We demonstrate the proposed approach for
several reaching and pick-and-place tasks in simulation, as well as on a real
system of a 6-DoF industrial manipulator.
</p>
<a href="http://arxiv.org/abs/2011.00155" target="_blank">arXiv:2011.00155</a> [<a href="http://arxiv.org/pdf/2011.00155" target="_blank">pdf</a>]

<h2>Learning Strategies in Decentralized Matching Markets under Uncertain Preferences. (arXiv:2011.00159v1 [cs.GT])</h2>
<h3>Xiaowu Dai, Michael I. Jordan</h3>
<p>We study two-sided decentralized matching markets in which participants have
uncertain preferences. We present a statistical model to learn the preferences.
The model incorporates uncertain state and the participants' competition on one
side of the market. We derive an optimal strategy that maximizes the agent's
expected payoff and calibrate the uncertain state by taking the opportunity
costs into account. We discuss the sense in which the matching derived from the
proposed strategy has a stability property. We also prove a fairness property
that asserts that there exists no justified envy according to the proposed
strategy. We provide numerical results to demonstrate the improved payoff,
stability and fairness, compared to alternative methods.
</p>
<a href="http://arxiv.org/abs/2011.00159" target="_blank">arXiv:2011.00159</a> [<a href="http://arxiv.org/pdf/2011.00159" target="_blank">pdf</a>]

<h2>Automatic Chronic Degenerative Diseases Identification Using Enteric Nervous System Images. (arXiv:2011.00160v1 [cs.CV])</h2>
<h3>Gustavo Z. Felipe, Jacqueline N. Zanoni, Camila C. Sehaber-Sierakowski, Gleison D. P. Bossolani, Sara R. G. Souza, Franklin C. Flores, Luiz E. S. Oliveira, Rodolfo M. Pereira, Yandre M. G. Costa</h3>
<p>Studies recently accomplished on the Enteric Nervous System have shown that
chronic degenerative diseases affect the Enteric Glial Cells (EGC) and, thus,
the development of recognition methods able to identify whether or not the EGC
are affected by these type of diseases may be helpful in its diagnoses. In this
work, we propose the use of pattern recognition and machine learning techniques
to evaluate if a given animal EGC image was obtained from a healthy individual
or one affect by a chronic degenerative disease. In the proposed approach, we
have performed the classification task with handcrafted features and deep
learning based techniques, also known as non-handcrafted features. The
handcrafted features were obtained from the textural content of the ECG images
using texture descriptors, such as the Local Binary Pattern (LBP). Moreover,
the representation learning techniques employed in the approach are based on
different Convolutional Neural Network (CNN) architectures, such as AlexNet and
VGG16, with and without transfer learning. The complementarity between the
handcrafted and non-handcrafted features was also evaluated with late fusion
techniques. The datasets of EGC images used in the experiments, which are also
contributions of this paper, are composed of three different chronic
degenerative diseases: Cancer, Diabetes Mellitus, and Rheumatoid Arthritis. The
experimental results, supported by statistical analysis, shown that the
proposed approach can distinguish healthy cells from the sick ones with a
recognition rate of 89.30% (Rheumatoid Arthritis), 98.45% (Cancer), and 95.13%
(Diabetes Mellitus), being achieved by combining classifiers obtained both
feature scenarios.
</p>
<a href="http://arxiv.org/abs/2011.00160" target="_blank">arXiv:2011.00160</a> [<a href="http://arxiv.org/pdf/2011.00160" target="_blank">pdf</a>]

<h2>FireCommander: An Interactive, Probabilistic Multi-agent Environment for Joint Perception-Action Tasks. (arXiv:2011.00165v1 [cs.RO])</h2>
<h3>Esmaeil Seraj, Xiyang Wu, Matthew Gombolay</h3>
<p>The purpose of this tutorial is to help individuals use the
\underline{FireCommander} game environment for research applications. The
FireCommander is an interactive, probabilistic joint perception-action
reconnaissance environment in which a composite team of agents (e.g., robots)
cooperate to fight dynamic, propagating firespots (e.g., targets). In
FireCommander game, a team of agents must be tasked to optimally deal with a
wildfire situation in an environment with propagating fire areas and some
facilities such as houses, hospitals, power stations, etc. The team of agents
can accomplish their mission by first sensing (e.g., estimating fire states),
communicating the sensed fire-information among each other and then taking
action to put the firespots out based on the sensed information (e.g., dropping
water on estimated fire locations). The FireCommander environment can be useful
for research topics spanning a wide range of applications from Reinforcement
Learning (RL) and Learning from Demonstration (LfD), to Coordination,
Psychology, Human-Robot Interaction (HRI) and Teaming. There are four important
facets of the FireCommander environment that overall, create a non-trivial
game: (1) Complex Objectives: Multi-objective Stochastic Environment,
(2)Probabilistic Environment: Agents' actions result in probabilistic
performance, (3) Hidden Targets: Partially Observable Environment and, (4)
Uni-task Robots: Perception-only and Action-only agents. The FireCommander
environment is first-of-its-kind in terms of including Perception-only and
Action-only agents for coordination. It is a general multi-purpose game that
can be useful in a variety of combinatorial optimization problems and
stochastic games, such as applications of Reinforcement Learning (RL), Learning
from Demonstration (LfD) and Inverse RL (iRL).
</p>
<a href="http://arxiv.org/abs/2011.00165" target="_blank">arXiv:2011.00165</a> [<a href="http://arxiv.org/pdf/2011.00165" target="_blank">pdf</a>]

<h2>Multimodal and self-supervised representation learning for automatic gesture recognition in surgical robotics. (arXiv:2011.00168v1 [cs.CV])</h2>
<h3>Aniruddha Tamhane, Jie Ying Wu, Mathias Unberath</h3>
<p>Self-supervised, multi-modal learning has been successful in holistic
representation of complex scenarios. This can be useful to consolidate
information from multiple modalities which have multiple, versatile uses. Its
application in surgical robotics can lead to simultaneously developing a
generalised machine understanding of the surgical process and reduce the
dependency on quality, expert annotations which are generally difficult to
obtain. We develop a self-supervised, multi-modal representation learning
paradigm that learns representations for surgical gestures from video and
kinematics. We use an encoder-decoder network configuration that encodes
representations from surgical videos and decodes them to yield kinematics. We
quantitatively demonstrate the efficacy of our learnt representations for
gesture recognition (with accuracy between 69.6 % and 77.8 %), transfer
learning across multiple tasks (with accuracy between 44.6 % and 64.8 %) and
surgeon skill classification (with accuracy between 76.8 % and 81.2 %).
Further, we qualitatively demonstrate that our self-supervised representations
cluster in semantically meaningful properties (surgeon skill and gestures).
</p>
<a href="http://arxiv.org/abs/2011.00168" target="_blank">arXiv:2011.00168</a> [<a href="http://arxiv.org/pdf/2011.00168" target="_blank">pdf</a>]

<h2>Understanding Pre-trained BERT for Aspect-based Sentiment Analysis. (arXiv:2011.00169v1 [cs.CL])</h2>
<h3>Hu Xu, Lei Shu, Philip S. Yu, Bing Liu</h3>
<p>This paper analyzes the pre-trained hidden representations learned from
reviews on BERT for tasks in aspect-based sentiment analysis (ABSA). Our work
is motivated by the recent progress in BERT-based language models for ABSA.
However, it is not clear how the general proxy task of (masked) language model
trained on unlabeled corpus without annotations of aspects or opinions can
provide important features for downstream tasks in ABSA. By leveraging the
annotated datasets in ABSA, we investigate both the attentions and the learned
representations of BERT pre-trained on reviews. We found that BERT uses very
few self-attention heads to encode context words (such as prepositions or
pronouns that indicating an aspect) and opinion words for an aspect. Most
features in the representation of an aspect are dedicated to the fine-grained
semantics of the domain (or product category) and the aspect itself, instead of
carrying summarized opinions from its context. We hope this investigation can
help future research in improving self-supervised learning, unsupervised
learning and fine-tuning for ABSA. The pre-trained model and code can be found
at https://github.com/howardhsu/BERT-for-RRC-ABSA.
</p>
<a href="http://arxiv.org/abs/2011.00169" target="_blank">arXiv:2011.00169</a> [<a href="http://arxiv.org/pdf/2011.00169" target="_blank">pdf</a>]

<h2>A Non-Volatile Cryogenic Random-Access Memory Based on the Quantum Anomalous Hall Effect. (arXiv:2011.00170v1 [physics.app-ph])</h2>
<h3>Shamiul Alam, Md Shafayat Hossain, Ahmedullah Aziz</h3>
<p>The interplay between ferromagnetism and topological properties of electronic
band structures leads to a precise quantization of Hall resistance without any
external magnetic field. This so-called quantum anomalous Hall effect (QAHE) is
born out of topological correlations, and is oblivious of low-sample quality.
It was envisioned to lead towards dissipationless and topologically protected
electronics. However, no clear framework of how to design such an electronic
device out of it exists. Here we construct an ultra-low power, non-volatile,
cryogenic memory architecture leveraging the QAHE phenomenon. Our design
promises orders of magnitude lower cell area compared with the state-of-the-art
cryogenic memory technologies. We harness the fundamentally quantized Hall
resistance levels in moir\'e graphene heterostructures to store non-volatile
binary bits (1, 0). We perform the memory write operation through controlled
hysteretic switching between the quantized Hall states, using nano-ampere level
currents with opposite polarities. The non-destructive read operation is
performed by sensing the polarity of the transverse Hall voltage using a
separate pair of terminals. We custom design the memory architecture with a
novel sensing mechanism to avoid accidental data corruption, ensure highest
memory density and minimize array leakage power. Our design is transferrable to
any material platform exhibiting QAHE, and provides a pathway towards realizing
topologically protected memory devices.
</p>
<a href="http://arxiv.org/abs/2011.00170" target="_blank">arXiv:2011.00170</a> [<a href="http://arxiv.org/pdf/2011.00170" target="_blank">pdf</a>]

<h2>Evaluation of Inference Attack Models for Deep Learning on Medical Data. (arXiv:2011.00177v1 [cs.LG])</h2>
<h3>Maoqiang Wu, Xinyue Zhang, Jiahao Ding, Hien Nguyen, Rong Yu, Miao Pan, Stephen T. Wong</h3>
<p>Deep learning has attracted broad interest in healthcare and medical
communities. However, there has been little research into the privacy issues
created by deep networks trained for medical applications. Recently developed
inference attack algorithms indicate that images and text records can be
reconstructed by malicious parties that have the ability to query deep
networks. This gives rise to the concern that medical images and electronic
health records containing sensitive patient information are vulnerable to these
attacks. This paper aims to attract interest from researchers in the medical
deep learning community to this important problem. We evaluate two prominent
inference attack models, namely, attribute inference attack and model inversion
attack. We show that they can reconstruct real-world medical images and
clinical reports with high fidelity. We then investigate how to protect
patients' privacy using defense mechanisms, such as label perturbation and
model perturbation. We provide a comparison of attack results between the
original and the medical deep learning models with defenses. The experimental
evaluations show that our proposed defense approaches can effectively reduce
the potential privacy leakage of medical deep learning from the inference
attacks.
</p>
<a href="http://arxiv.org/abs/2011.00177" target="_blank">arXiv:2011.00177</a> [<a href="http://arxiv.org/pdf/2011.00177" target="_blank">pdf</a>]

<h2>Learning Open Set Network with Discriminative Reciprocal Points. (arXiv:2011.00178v1 [cs.CV])</h2>
<h3>Guangyao Chen, Limeng Qiao, Yemin Shi, Peixi Peng, Jia Li, Tiejun Huang, Shiliang Pu, Yonghong Tian</h3>
<p>Open set recognition is an emerging research area that aims to simultaneously
classify samples from predefined classes and identify the rest as 'unknown'. In
this process, one of the key challenges is to reduce the risk of generalizing
the inherent characteristics of numerous unknown samples learned from a small
amount of known data. In this paper, we propose a new concept, Reciprocal
Point, which is the potential representation of the extra-class space
corresponding to each known category. The sample can be classified to known or
unknown by the otherness with reciprocal points. To tackle the open set
problem, we offer a novel open space risk regularization term. Based on the
bounded space constructed by reciprocal points, the risk of unknown is reduced
through multi-category interaction. The novel learning framework called
Reciprocal Point Learning (RPL), which can indirectly introduce the unknown
information into the learner with only known classes, so as to learn more
compact and discriminative representations. Moreover, we further construct a
new large-scale challenging aircraft dataset for open set recognition: Aircraft
300 (Air-300). Extensive experiments on multiple benchmark datasets indicate
that our framework is significantly superior to other existing approaches and
achieves state-of-the-art performance on standard open set benchmarks.
</p>
<a href="http://arxiv.org/abs/2011.00178" target="_blank">arXiv:2011.00178</a> [<a href="http://arxiv.org/pdf/2011.00178" target="_blank">pdf</a>]

<h2>Combining Domain-Specific Meta-Learners in the Parameter Space for Cross-Domain Few-Shot Classification. (arXiv:2011.00179v1 [cs.LG])</h2>
<h3>Shuman Peng, Weilian Song, Martin Ester</h3>
<p>The goal of few-shot classification is to learn a model that can classify
novel classes using only a few training examples. Despite the promising results
shown by existing meta-learning algorithms in solving the few-shot
classification problem, there still remains an important challenge: how to
generalize to unseen domains while meta-learning on multiple seen domains? In
this paper, we propose an optimization-based meta-learning method, called
Combining Domain-Specific Meta-Learners (CosML), that addresses the
cross-domain few-shot classification problem. CosML first trains a set of
meta-learners, one for each training domain, to learn prior knowledge (i.e.,
meta-parameters) specific to each domain. The domain-specific meta-learners are
then combined in the \emph{parameter space}, by taking a weighted average of
their meta-parameters, which is used as the initialization parameters of a task
network that is quickly adapted to novel few-shot classification tasks in an
unseen domain. Our experiments show that CosML outperforms a range of
state-of-the-art methods and achieves strong cross-domain generalization
ability.
</p>
<a href="http://arxiv.org/abs/2011.00179" target="_blank">arXiv:2011.00179</a> [<a href="http://arxiv.org/pdf/2011.00179" target="_blank">pdf</a>]

<h2>Self-supervised Representation Learning for Evolutionary Neural Architecture Search. (arXiv:2011.00186v1 [cs.CV])</h2>
<h3>Chen Wei, Yiping Tang, Chuang Niu, Haihong Hu, Yue Wang, Jimin Liang</h3>
<p>Recently proposed neural architecture search (NAS) algorithms adopt neural
predictors to accelerate the architecture search. The capability of neural
predictors to accurately predict the performance metrics of neural architecture
is critical to NAS, and the acquisition of training datasets for neural
predictors is time-consuming. How to obtain a neural predictor with high
prediction accuracy using a small amount of training data is a central problem
to neural predictor-based NAS. Here, we firstly design a new architecture
encoding scheme that overcomes the drawbacks of existing vector-based
architecture encoding schemes to calculate the graph edit distance of neural
architectures. To enhance the predictive performance of neural predictors, we
devise two self-supervised learning methods from different perspectives to
pre-train the architecture embedding part of neural predictors to generate a
meaningful representation of neural architectures. The first one is to train a
carefully designed two branch graph neural network model to predict the graph
edit distance of two input neural architectures. The second method is inspired
by the prevalently contrastive learning, and we present a new contrastive
learning algorithm that utilizes a central feature vector as a proxy to
contrast positive pairs against negative pairs. Experimental results illustrate
that the pre-trained neural predictors can achieve comparable or superior
performance compared with their supervised counterparts with several times less
training samples. We achieve state-of-the-art performance on the NASBench-101
and NASBench201 benchmarks when integrating the pre-trained neural predictors
with an evolutionary NAS algorithm.
</p>
<a href="http://arxiv.org/abs/2011.00186" target="_blank">arXiv:2011.00186</a> [<a href="http://arxiv.org/pdf/2011.00186" target="_blank">pdf</a>]

<h2>A Novel Semi-Supervised Data-Driven Method for Chiller Fault Diagnosis with Unlabeled Data. (arXiv:2011.00187v1 [cs.LG])</h2>
<h3>Bingxu Li, Fanyong Cheng, Xin Zhang, Can Cui, Wenjian Cai</h3>
<p>In practical chiller systems, applying efficient fault diagnosis techniques
can significantly reduce energy consumption and improve energy efficiency of
buildings. The success of the existing methods for fault diagnosis of chillers
relies on the condition that sufficient labeled data are available for
training. However, label acquisition is laborious and costly in practice.
Usually, the number of labeled data is limited and most data available are
unlabeled. The existing methods cannot exploit the information contained in
unlabeled data, which significantly limits the improvement of fault diagnosis
performance in chiller systems. To make effective use of unlabeled data to
further improve fault diagnosis performance and reduce the dependency on
labeled data, we proposed a novel semi-supervised data-driven fault diagnosis
method for chiller systems based on the semi-generative adversarial network,
which incorporates both unlabeled and labeled data into learning process. The
semi-generative adversarial network can learn the information of data
distribution from unlabeled data and this information can help to significantly
improve the diagnostic performance. Experimental results demonstrate the
effectiveness of the proposed method. Under the scenario that there are only 80
labeled samples and 16000 unlabeled samples, the proposed method can improve
the diagnostic accuracy to 84%, while the supervised baseline methods only
reach the accuracy of 65% at most. Besides, the minimal required number of
labeled samples can be reduced by about 60% with the proposed method when there
are enough unlabeled samples.
</p>
<a href="http://arxiv.org/abs/2011.00187" target="_blank">arXiv:2011.00187</a> [<a href="http://arxiv.org/pdf/2011.00187" target="_blank">pdf</a>]

<h2>Personalized Multimodal Feedback Generation in Education. (arXiv:2011.00192v1 [cs.CL])</h2>
<h3>Haochen Liu, Zitao Liu, Zhongqin Wu, Jiliang Tang</h3>
<p>The automatic evaluation for school assignments is an important application
of AI in the education field. In this work, we focus on the task of
personalized multimodal feedback generation, which aims to generate
personalized feedback for various teachers to evaluate students' assignments
involving multimodal inputs such as images, audios, and texts. This task
involves the representation and fusion of multimodal information and natural
language generation, which presents the challenges from three aspects: 1) how
to encode and integrate multimodal inputs; 2) how to generate feedback specific
to each modality; and 3) how to realize personalized feedback generation. In
this paper, we propose a novel Personalized Multimodal Feedback Generation
Network (PMFGN) armed with a modality gate mechanism and a personalized bias
mechanism to address these challenges. The extensive experiments on real-world
K-12 education data show that our model significantly outperforms several
baselines by generating more accurate and diverse feedback. In addition,
detailed ablation experiments are conducted to deepen our understanding of the
proposed framework.
</p>
<a href="http://arxiv.org/abs/2011.00192" target="_blank">arXiv:2011.00192</a> [<a href="http://arxiv.org/pdf/2011.00192" target="_blank">pdf</a>]

<h2>Hyperbolic Graph Embedding with Enhanced Semi-Implicit Variational Inference. (arXiv:2011.00194v1 [cs.LG])</h2>
<h3>Ali Lotfi Rezaabad, Rahi Kalantari, Sriram Vishwanath, Mingyuan Zhou, Jon Tamir</h3>
<p>Efficient modeling of relational data arising in physical, social, and
information sciences is challenging due to complicated dependencies within the
data. In this work we build off of semi-implicit graph variational
auto-encoders to capture higher order statistics in a low-dimensional graph
latent representation. We incorporate hyperbolic geometry in the latent space
through a \poincare embedding to efficiently represent graphs exhibiting
hierarchical structure. To address the naive posterior latent distribution
assumptions in classical variational inference, we use semi-implicit
hierarchical variational Bayes to implicitly capture posteriors of given graph
data, which may exhibit heavy tails, multiple modes, skewness, and highly
correlated latent structures. We show that the existing semi-implicit
variational inference objective provably reduces information in the observed
graph. Based on this observation, we estimate and add an additional mutual
information term to the semi-implicit variational inference learning objective
to capture rich correlations arising between the input and latent spaces. We
show that the inclusion of this regularization term in conjunction with the
\poincare embedding boosts the quality of learned high-level representations
and enables more flexible and faithful graphical modeling. We experimentally
demonstrate that our approach outperforms existing graph variational
auto-encoders both in Euclidean and in hyperbolic spaces for edge link
prediction and node classification.
</p>
<a href="http://arxiv.org/abs/2011.00194" target="_blank">arXiv:2011.00194</a> [<a href="http://arxiv.org/pdf/2011.00194" target="_blank">pdf</a>]

<h2>RespireNet: A Deep Neural Network for Accurately Detecting Abnormal Lung Sounds in Limited Data Setting. (arXiv:2011.00196v1 [cs.SD])</h2>
<h3>Siddhartha Gairola, Francis Tom, Nipun Kwatra, Mohit Jain</h3>
<p>Auscultation of respiratory sounds is the primary tool for screening and
diagnosing lung diseases. Automated analysis, coupled with digital
stethoscopes, can play a crucial role in enabling tele-screening of fatal lung
diseases. Deep neural networks (DNNs) have shown a lot of promise for such
problems, and are an obvious choice. However, DNNs are extremely data hungry,
and the largest respiratory dataset ICBHI has only 6898 breathing cycles, which
is still small for training a satisfactory DNN model. In this work, RespireNet,
we propose a simple CNN-based model, along with a suite of novel
techniques---device specific fine-tuning, concatenation-based augmentation,
blank region clipping, and smart padding---enabling us to efficiently use the
small-sized dataset. We perform extensive evaluation on the ICBHI dataset, and
improve upon the state-of-the-art results for 4-class classification by 2.2%
</p>
<a href="http://arxiv.org/abs/2011.00196" target="_blank">arXiv:2011.00196</a> [<a href="http://arxiv.org/pdf/2011.00196" target="_blank">pdf</a>]

<h2>Meta-Learning with Adaptive Hyperparameters. (arXiv:2011.00209v1 [cs.LG])</h2>
<h3>Sungyong Baik, Myungsub Choi, Janghoon Choi, Heewon Kim, Kyoung Mu Lee</h3>
<p>Despite its popularity, several recent works question the effectiveness of
MAML when test tasks are different from training tasks, thus suggesting various
task-conditioned methodology to improve the initialization. Instead of
searching for better task-aware initialization, we focus on a complementary
factor in MAML framework, inner-loop optimization (or fast adaptation).
Consequently, we propose a new weight update rule that greatly enhances the
fast adaptation process. Specifically, we introduce a small meta-network that
can adaptively generate per-step hyperparameters: learning rate and weight
decay coefficients. The experimental results validate that the Adaptive
Learning of hyperparameters for Fast Adaptation (ALFA) is the equally important
ingredient that was often neglected in the recent few-shot learning approaches.
Surprisingly, fast adaptation from random initialization with ALFA can already
outperform MAML.
</p>
<a href="http://arxiv.org/abs/2011.00209" target="_blank">arXiv:2011.00209</a> [<a href="http://arxiv.org/pdf/2011.00209" target="_blank">pdf</a>]

<h2>Optimal 1-NN Prototypes for Pathological Geometries. (arXiv:2011.00228v1 [cs.LG])</h2>
<h3>Ilia Sucholutsky, Matthias Schonlau</h3>
<p>Using prototype methods to reduce the size of training datasets can
drastically reduce the computational cost of classification with instance-based
learning algorithms like the k-Nearest Neighbour classifier. The number and
distribution of prototypes required for the classifier to match its original
performance is intimately related to the geometry of the training data. As a
result, it is often difficult to find the optimal prototypes for a given
dataset, and heuristic algorithms are used instead. However, we consider a
particularly challenging setting where commonly used heuristic algorithms fail
to find suitable prototypes and show that the optimal prototypes can instead be
found analytically. We also propose an algorithm for finding nearly-optimal
prototypes in this setting, and use it to empirically validate the theoretical
results.
</p>
<a href="http://arxiv.org/abs/2011.00228" target="_blank">arXiv:2011.00228</a> [<a href="http://arxiv.org/pdf/2011.00228" target="_blank">pdf</a>]

<h2>An edge-based architecture to support the execution of ambience intelligence tasks using the IoP paradigm. (arXiv:2011.00236v1 [cs.DC])</h2>
<h3>Khaled Alanezi, Shivakant Mishra</h3>
<p>In an IoP environment, edge computing has been proposed to address the
problems of resource limitations of edge devices such as smartphones as well as
the high-latency, user privacy exposure and network bottleneck that the cloud
computing platform solutions incur. This paper presents a context management
framework comprised of sensors, mobile devices such as smartphones and an edge
server to enable high performance, context-aware computing at the edge. Key
features of this architecture include energy-efficient discovery of available
sensors and edge services for the client, an automated mechanism for task
planning and execution on the edge server, and a dynamic environment where new
sensors and services may be added to the framework. A prototype of this
architecture has been implemented, and an experimental evaluation using two
computer vision tasks as example services is presented. Performance measurement
shows that the execution of the example tasks performs quite well and the
proposed framework is well suited for an edge-computing environment.
</p>
<a href="http://arxiv.org/abs/2011.00236" target="_blank">arXiv:2011.00236</a> [<a href="http://arxiv.org/pdf/2011.00236" target="_blank">pdf</a>]

<h2>Methods for Pruning Deep Neural Networks. (arXiv:2011.00241v1 [cs.LG])</h2>
<h3>Sunil Vadera, Salem Ameen</h3>
<p>This paper presents a survey of methods for pruning deep neural networks,
from algorithms first proposed for fully connected networks in the 1990s to the
recent methods developed for reducing the size of convolutional neural
networks. The paper begins by bringing together many different algorithms by
categorising them based on the underlying approach used. It then focuses on
three categories: methods that use magnitude-based pruning, methods that
utilise clustering to identify redundancy, and methods that utilise sensitivity
analysis. Some of the key influencing studies within these categories are
presented to illuminate the underlying approaches and results achieved.

Most studies on pruning present results from empirical evaluations, which are
distributed in the literature as new architectures, algorithms and data sets
have evolved with time. This paper brings together the reported results from
some key papers in one place by providing a resource that can be used to
quickly compare reported results, and trace studies where specific methods,
data sets and architectures have been used.
</p>
<a href="http://arxiv.org/abs/2011.00241" target="_blank">arXiv:2011.00241</a> [<a href="http://arxiv.org/pdf/2011.00241" target="_blank">pdf</a>]

<h2>Free the Plural: Unrestricted Split-Antecedent Anaphora Resolution. (arXiv:2011.00245v1 [cs.CL])</h2>
<h3>Juntao Yu, Nafise Sadat Moosavi, Silviu Paun, Massimo Poesio</h3>
<p>Now that the performance of coreference resolvers on the simpler forms of
anaphoric reference has greatly improved, more attention is devoted to more
complex aspects of anaphora. One limitation of virtually all coreference
resolution models is the focus on single-antecedent anaphors. Plural anaphors
with multiple antecedents-so-called split-antecedent anaphors (as in John met
Mary. They went to the movies) have not been widely studied, because they are
not annotated in ONTONOTES and are relatively infrequent in other corpora. In
this paper, we introduce the first model for unrestricted resolution of
split-antecedent anaphors. We start with a strong baseline enhanced by BERT
embeddings, and show that we can substantially improve its performance by
addressing the sparsity issue. To do this, we experiment with auxiliary corpora
where split-antecedent anaphors were annotated by the crowd, and with transfer
learning models using element-of bridging references and single-antecedent
coreference as auxiliary tasks. Evaluation on the gold annotated ARRAU corpus
shows that the out best model uses a combination of three auxiliary corpora
achieved F1 scores of 70% and 43.6% when evaluated in a lenient and strict
setting, respectively, i.e., 11 and 21 percentage points gain when compared
with our baseline.
</p>
<a href="http://arxiv.org/abs/2011.00245" target="_blank">arXiv:2011.00245</a> [<a href="http://arxiv.org/pdf/2011.00245" target="_blank">pdf</a>]

<h2>Rumor Detection on Twitter Using Multiloss Hierarchical BiLSTM with an Attenuation Factor. (arXiv:2011.00259v1 [cs.CL])</h2>
<h3>Yudianto Sujana, Jiawen Li, Hung-Yu Kao</h3>
<p>Social media platforms such as Twitter have become a breeding ground for
unverified information or rumors. These rumors can threaten people's health,
endanger the economy, and affect the stability of a country. Many researchers
have developed models to classify rumors using traditional machine learning or
vanilla deep learning models. However, previous studies on rumor detection have
achieved low precision and are time consuming. Inspired by the hierarchical
model and multitask learning, a multiloss hierarchical BiLSTM model with an
attenuation factor is proposed in this paper. The model is divided into two
BiLSTM modules: post level and event level. By means of this hierarchical
structure, the model can extract deep in-formation from limited quantities of
text. Each module has a loss function that helps to learn bilateral features
and reduce the training time. An attenuation fac-tor is added at the post level
to increase the accuracy. The results on two rumor datasets demonstrate that
our model achieves better performance than that of state-of-the-art machine
learning and vanilla deep learning models.
</p>
<a href="http://arxiv.org/abs/2011.00259" target="_blank">arXiv:2011.00259</a> [<a href="http://arxiv.org/pdf/2011.00259" target="_blank">pdf</a>]

<h2>ProxylessKD: Direct Knowledge Distillation with Inherited Classifier for Face Recognition. (arXiv:2011.00265v1 [cs.CV])</h2>
<h3>Weidong Shi, Guanghui Ren, Yunpeng Chen, Shuicheng Yan</h3>
<p>Knowledge Distillation (KD) refers to transferring knowledge from a large
model to a smaller one, which is widely used to enhance model performance in
machine learning. It tries to align embedding spaces generated from the teacher
and the student model (i.e. to make images corresponding to the same semantics
share the same embedding across different models). In this work, we focus on
its application in face recognition. We observe that existing knowledge
distillation models optimize the proxy tasks that force the student to mimic
the teacher's behavior, instead of directly optimizing the face recognition
accuracy. Consequently, the obtained student models are not guaranteed to be
optimal on the target task or able to benefit from advanced constraints, such
as large margin constraints (e.g. margin-based softmax). We then propose a
novel method named ProxylessKD that directly optimizes face recognition
accuracy by inheriting the teacher's classifier as the student's classifier to
guide the student to learn discriminative embeddings in the teacher's embedding
space. The proposed ProxylessKD is very easy to implement and sufficiently
generic to be extended to other tasks beyond face recognition. We conduct
extensive experiments on standard face recognition benchmarks, and the results
demonstrate that ProxylessKD achieves superior performance over existing
knowledge distillation methods.
</p>
<a href="http://arxiv.org/abs/2011.00265" target="_blank">arXiv:2011.00265</a> [<a href="http://arxiv.org/pdf/2011.00265" target="_blank">pdf</a>]

<h2>LandmarkGAN: Synthesizing Faces from Landmarks. (arXiv:2011.00269v1 [cs.CV])</h2>
<h3>Pu Sun, Yuezun Li, Honggang Qi, Siwei Lyu</h3>
<p>Face synthesis is an important problem in computer vision with many
applications. In this work, we describe a new method, namely LandmarkGAN, to
synthesize faces based on facial landmarks as input. Facial landmarks are a
natural, intuitive, and effective representation for facial expressions and
orientations, which are independent from the target's texture or color and
background scene. Our method is able to transform a set of facial landmarks
into new faces of different subjects, while retains the same facial expression
and orientation. Experimental results on face synthesis and reenactments
demonstrate the effectiveness of our method.
</p>
<a href="http://arxiv.org/abs/2011.00269" target="_blank">arXiv:2011.00269</a> [<a href="http://arxiv.org/pdf/2011.00269" target="_blank">pdf</a>]

<h2>Neural Coreference Resolution for Arabic. (arXiv:2011.00286v1 [cs.CL])</h2>
<h3>Abdulrahman Aloraini, Juntao Yu, Massimo Poesio</h3>
<p>No neural coreference resolver for Arabic exists, in fact we are not aware of
any learning-based coreference resolver for Arabic since (Bjorkelund and Kuhn,
2014). In this paper, we introduce a coreference resolution system for Arabic
based on Lee et al's end to end architecture combined with the Arabic version
of bert and an external mention detector. As far as we know, this is the first
neural coreference resolution system aimed specifically to Arabic, and it
substantially outperforms the existing state of the art on OntoNotes 5.0 with a
gain of 15.2 points conll F1. We also discuss the current limitations of the
task for Arabic and possible approaches that can tackle these challenges.
</p>
<a href="http://arxiv.org/abs/2011.00286" target="_blank">arXiv:2011.00286</a> [<a href="http://arxiv.org/pdf/2011.00286" target="_blank">pdf</a>]

<h2>AGAIN-VC: A One-shot Voice Conversion using Activation Guidance and Adaptive Instance Normalization. (arXiv:2011.00316v1 [eess.AS])</h2>
<h3>Yen-Hao Chen, Da-Yi Wu, Tsung-Han Wu, Hung-yi Lee</h3>
<p>Recently, voice conversion (VC) has been widely studied. Many VC systems use
disentangle-based learning techniques to separate the speaker and the
linguistic content information from a speech signal. Subsequently, they convert
the voice by changing the speaker information to that of the target speaker. To
prevent the speaker information from leaking into the content embeddings,
previous works either reduce the dimension or quantize the content embedding as
a strong information bottleneck. These mechanisms somehow hurt the synthesis
quality. In this work, we propose AGAIN-VC, an innovative VC system using
Activation Guidance and Adaptive Instance Normalization. AGAIN-VC is an
auto-encoder-based model, comprising of a single encoder and a decoder. With a
proper activation as an information bottleneck on content embeddings, the
trade-off between the synthesis quality and the speaker similarity of the
converted speech is improved drastically. This one-shot VC system obtains the
best performance regardless of the subjective or objective evaluations.
</p>
<a href="http://arxiv.org/abs/2011.00316" target="_blank">arXiv:2011.00316</a> [<a href="http://arxiv.org/pdf/2011.00316" target="_blank">pdf</a>]

<h2>A Secure Two-Party Computation Protocol for Intersection Detection between Two Convex Hulls. (arXiv:2011.00319v1 [cs.CG])</h2>
<h3>Amirahmad Chapnevis, Babak Sadeghiyan</h3>
<p>Intersection detection between three-dimensional bodies has various
applications in computer graphics, video game development, robotics as well as
military industries. In some respects, entities do not want to disclose
sensitive information about themselves, including their location. In this
paper, we present a secure two-party protocol to determine the existence of an
intersection between entities. The protocol presented in this paper allows for
intersection detection in three-dimensional spaces in geometry. Our approach is
to use an intersecting plane between two spaces to determine their separation
or intersection. For this purpose, we introduce a computational geometry
protocol to determine the existence of an intersecting plane. In this paper, we
first use the Minkowski difference to reduce the two-space problem into
one-space. Then, the separating set is obtained and the separation of two
shapes is determined based on the inclusion of the center point. We then secure
the protocol by modifying the separating set computation method as a
privacy-preserver and changing the Minkowski difference method to achieve this
goal. The proposed protocol applies to any form of convex three-dimensional
shape. The experiments successfully found a secure protocol for intersection
detection between two convex hulls in geometrical shapes such as the pyramid
and cuboid.
</p>
<a href="http://arxiv.org/abs/2011.00319" target="_blank">arXiv:2011.00319</a> [<a href="http://arxiv.org/pdf/2011.00319" target="_blank">pdf</a>]

<h2>Scene Flow from Point Clouds with or without Learning. (arXiv:2011.00320v1 [cs.CV])</h2>
<h3>Jhony Kaesemodel Pontes, James Hays, Simon Lucey</h3>
<p>Scene flow is the three-dimensional (3D) motion field of a scene. It provides
information about the spatial arrangement and rate of change of objects in
dynamic environments. Current learning-based approaches seek to estimate the
scene flow directly from point clouds and have achieved state-of-the-art
performance. However, supervised learning methods are inherently domain
specific and require a large amount of labeled data. Annotation of scene flow
on real-world point clouds is expensive and challenging, and the lack of such
datasets has recently sparked interest in self-supervised learning methods. How
to accurately and robustly learn scene flow representations without labeled
real-world data is still an open problem. Here we present a simple and
interpretable objective function to recover the scene flow from point clouds.
We use the graph Laplacian of a point cloud to regularize the scene flow to be
"as-rigid-as-possible". Our proposed objective function can be used with or
without learning---as a self-supervisory signal to learn scene flow
representations, or as a non-learning-based method in which the scene flow is
optimized during runtime. Our approach outperforms related works in many
datasets. We also show the immediate applications of our proposed method for
two applications: motion segmentation and point cloud densification.
</p>
<a href="http://arxiv.org/abs/2011.00320" target="_blank">arXiv:2011.00320</a> [<a href="http://arxiv.org/pdf/2011.00320" target="_blank">pdf</a>]

<h2>Self-paced and self-consistent co-training for semi-supervised image segmentation. (arXiv:2011.00325v1 [cs.CV])</h2>
<h3>Ping Wang, Jizong Peng, Marco Pedersoli, Yuanfeng Zhou, Caiming Zhang, Christian Desrosiers</h3>
<p>Deep co-training has recently been proposed as an effective approach for
image segmentation when annotated data is scarce. In this paper, we improve
existing approaches for semi-supervised segmentation with a self-paced and
self-consistent co-training method. To help distillate information from
unlabeled images, we first design a self-paced learning strategy for
co-training that lets jointly-trained neural networks focus on
easier-to-segment regions first, and then gradually consider harder ones.This
is achieved via an end-to-end differentiable loss inthe form of a generalized
Jensen Shannon Divergence(JSD). Moreover, to encourage predictions from
different networks to be both consistent and confident, we enhance this
generalized JSD loss with an uncertainty regularizer based on entropy. The
robustness of individual models is further improved using a self-ensembling
loss that enforces their prediction to be consistent across different training
iterations. We demonstrate the potential of our method on three challenging
image segmentation problems with different image modalities, using small
fraction of labeled data. Results show clear advantages in terms of performance
compared to the standard co-training baselines and recently proposed
state-of-the-art approaches for semi-supervised segmentation
</p>
<a href="http://arxiv.org/abs/2011.00325" target="_blank">arXiv:2011.00325</a> [<a href="http://arxiv.org/pdf/2011.00325" target="_blank">pdf</a>]

<h2>On the rate of convergence of a deep recurrent neural network estimate in a regression problem with dependent data. (arXiv:2011.00328v1 [stat.ML])</h2>
<h3>Michael Kohler, Adam Krzyzak</h3>
<p>A regression problem with dependent data is considered. Regularity
assumptions on the dependency of the data are introduced, and it is shown that
under suitable structural assumptions on the regression function a deep
recurrent neural network estimate is able to circumvent the curse of
dimensionality.
</p>
<a href="http://arxiv.org/abs/2011.00328" target="_blank">arXiv:2011.00328</a> [<a href="http://arxiv.org/pdf/2011.00328" target="_blank">pdf</a>]

<h2>Deep learning in the ultrasound evaluation of neonatal respiratory status. (arXiv:2011.00337v1 [eess.IV])</h2>
<h3>Michela Gravina, Diego Gragnaniello, Luisa Verdoliva, Giovanni Poggi, Iuri Corsini, Carlo Dani, Fabio Meneghin, Gianluca Lista, Salvatore Aversa, Francesco Raimondi, Fiorella Migliaro, Carlo Sansone</h3>
<p>Lung ultrasound imaging is reaching growing interest from the scientific
community. On one side, thanks to its harmlessness and high descriptive power,
this kind of diagnostic imaging has been largely adopted in sensitive
applications, like the diagnosis and follow-up of preterm newborns in neonatal
intensive care units. On the other side, state-of-the-art image analysis and
pattern recognition approaches have recently proven their ability to fully
exploit the rich information contained in these data, making them attractive
for the research community. In this work, we present a thorough analysis of
recent deep learning networks and training strategies carried out on a vast and
challenging multicenter dataset comprising 87 patients with different diseases
and gestational ages. These approaches are employed to assess the lung
respiratory status from ultrasound images and are evaluated against a reference
marker. The conducted analysis sheds some light on this problem by showing the
critical points that can mislead the training procedure and proposes some
adaptations to the specific data and task. The achieved results sensibly
outperform those obtained by a previous work, which is based on textural
features, and narrow the gap with the visual score predicted by the human
experts.
</p>
<a href="http://arxiv.org/abs/2011.00337" target="_blank">arXiv:2011.00337</a> [<a href="http://arxiv.org/pdf/2011.00337" target="_blank">pdf</a>]

<h2>Unsupervised Deep Persistent Monocular Visual Odometry and Depth Estimation in Extreme Environments. (arXiv:2011.00341v1 [cs.CV])</h2>
<h3>Yasin Almalioglu, Angel Santamaria-Navarro, Benjamin Morrell, Ali-akbar Agha-mohammadi</h3>
<p>In recent years, unsupervised deep learning approaches have received
significant attention to estimate the depth and visual odometry (VO) from
unlabelled monocular image sequences. However, their performance is limited in
challenging environments due to perceptual degradation, occlusions and rapid
motions. Moreover, the existing unsupervised methods suffer from the lack of
scale-consistency constraints across frames, which causes that the VO
estimators fail to provide persistent trajectories over long sequences. In this
study, we propose an unsupervised monocular deep VO framework that predicts
six-degrees-of-freedom pose camera motion and depth map of the scene from
unlabelled RGB image sequences. We provide detailed quantitative and
qualitative evaluations of the proposed framework on a) a challenging dataset
collected during the DARPA Subterranean challenge; and b) the benchmark KITTI
and Cityscapes datasets. The proposed approach outperforms both traditional and
state-of-the-art unsupervised deep VO methods providing better results for both
pose estimation and depth recovery. The presented approach is part of the
solution used by the COSTAR team participating at the DARPA Subterranean
Challenge.
</p>
<a href="http://arxiv.org/abs/2011.00341" target="_blank">arXiv:2011.00341</a> [<a href="http://arxiv.org/pdf/2011.00341" target="_blank">pdf</a>]

<h2>On Optimality of Meta-Learning in Fixed-Design Regression with Weighted Biased Regularization. (arXiv:2011.00344v1 [stat.ML])</h2>
<h3>Mikhail Konobeev, Ilja Kuzborskij, Csaba Szepesv&#xe1;ri</h3>
<p>We consider a fixed-design linear regression in the meta-learning model of
Baxter (2000) and establish a problem-dependent finite-sample lower bound on
the transfer risk (risk on a newly observed task) valid for all estimators.
Moreover, we prove that a weighted form of a biased regularization - a popular
technique in transfer and meta-learning - is optimal, i.e. it enjoys a
problem-dependent upper bound on the risk matching our lower bound up to a
constant. Thus, our bounds characterize meta-learning linear regression
problems and reveal a fine-grained dependency on the task structure. Our
characterization suggests that in the non-asymptotic regime, for a sufficiently
large number of tasks, meta-learning can be considerably superior to a
single-task learning. Finally, we propose a practical adaptation of the optimal
estimator through Expectation-Maximization procedure and show its effectiveness
in series of experiments.
</p>
<a href="http://arxiv.org/abs/2011.00344" target="_blank">arXiv:2011.00344</a> [<a href="http://arxiv.org/pdf/2011.00344" target="_blank">pdf</a>]

<h2>Aspectuality Across Genre: A Distributional Semantics Approach. (arXiv:2011.00345v1 [cs.CL])</h2>
<h3>Thomas Kober, Malihe Alikhani, Matthew Stone, Mark Steedman</h3>
<p>The interpretation of the lexical aspect of verbs in English plays a crucial
role for recognizing textual entailment and learning discourse-level
inferences. We show that two elementary dimensions of aspectual class, states
vs. events, and telic vs. atelic events, can be modelled effectively with
distributional semantics. We find that a verb's local context is most
indicative of its aspectual class, and demonstrate that closed class words tend
to be stronger discriminating contexts than content words. Our approach
outperforms previous work on three datasets. Lastly, we contribute a dataset of
human--human conversations annotated with lexical aspect and present
experiments that show the correlation of telicity with genre and discourse
goals.
</p>
<a href="http://arxiv.org/abs/2011.00345" target="_blank">arXiv:2011.00345</a> [<a href="http://arxiv.org/pdf/2011.00345" target="_blank">pdf</a>]

<h2>Efficient Arabic emotion recognition using deep neural networks. (arXiv:2011.00346v1 [cs.CL])</h2>
<h3>Ahmed Ali, Yasser Hifny</h3>
<p>Emotion recognition from speech signal based on deep learning is an active
research area. Convolutional neural networks (CNNs) may be the dominant method
in this area. In this paper, we implement two neural architectures to address
this problem. The first architecture is an attention-based CNN-LSTM-DNN model.
In this novel architecture, the convolutional layers extract salient features
and the bi-directional long short-term memory (BLSTM) layers handle the
sequential phenomena of the speech signal. This is followed by an attention
layer, which extracts a summary vector that is fed to the fully connected dense
layer (DNN), which finally connects to a softmax output layer. The second
architecture is based on a deep CNN model. The results on an Arabic speech
emotion recognition task show that our innovative approach can lead to
significant improvements (2.2% absolute improvements) over a strong deep CNN
baseline system. On the other hand, the deep CNN models are significantly
faster than the attention based CNN-LSTM-DNN models in training and
classification.
</p>
<a href="http://arxiv.org/abs/2011.00346" target="_blank">arXiv:2011.00346</a> [<a href="http://arxiv.org/pdf/2011.00346" target="_blank">pdf</a>]

<h2>Strategic Recourse in Linear Classification. (arXiv:2011.00355v1 [cs.LG])</h2>
<h3>Yatong Chen, Jialu Wang, Yang Liu</h3>
<p>In algorithmic decision making, recourse refers to individuals' ability to
systematically reverse an unfavorable decision made by an algorithm. Meanwhile,
individuals subjected to a classification mechanism are incentivized to behave
strategically in order to gain a system's approval. However, not all strategic
behavior necessarily leads to adverse results: through appropriate mechanism
design, strategic behavior can induce genuine improvement in an individual's
qualifications. In this paper, we explore how to design a classifier that
achieves high accuracy while providing recourse to strategic individuals so as
to incentivize them to improve their features in non-manipulative ways. We
capture these dynamics using a two-stage game: first, the mechanism designer
publishes a classifier, with the goal of optimizing classification accuracy and
providing recourse to incentivize individuals' improvement. Then, agents
respond by potentially modifying their input features in order to obtain a
favorable decision from the classifier, while trying to minimize the cost of
making such modifications. Under this model, we provide analytical results
characterizing the equilibrium strategies for both the mechanism designer and
the agents. Our empirical results show the effectiveness of our mechanism in
three real-world datasets: compared to a baseline classifier that only
considers individuals' strategic behavior without explicitly incentivizing
improvement, our algorithm can provide recourse to a much higher fraction of
individuals in the direction of improvement while maintaining relatively high
prediction accuracy. We also show that our algorithm can effectively mitigate
disparities caused by differences in manipulation costs. Our results provide
insights for designing a machine learning model that focuses not only on the
static distribution as of now, but also tries to encourage future improvement.
</p>
<a href="http://arxiv.org/abs/2011.00355" target="_blank">arXiv:2011.00355</a> [<a href="http://arxiv.org/pdf/2011.00355" target="_blank">pdf</a>]

<h2>TartanVO: A Generalizable Learning-based VO. (arXiv:2011.00359v1 [cs.CV])</h2>
<h3>Wenshan Wang, Yaoyu Hu, Sebastian Scherer</h3>
<p>We present the first learning-based visual odometry (VO) model, which
generalizes to multiple datasets and real-world scenarios and outperforms
geometry-based methods in challenging scenes. We achieve this by leveraging the
SLAM dataset TartanAir, which provides a large amount of diverse synthetic data
in challenging environments. Furthermore, to make our VO model generalize
across datasets, we propose an up-to-scale loss function and incorporate the
camera intrinsic parameters into the model. Experiments show that a single
model, TartanVO, trained only on synthetic data, without any finetuning, can be
generalized to real-world datasets such as KITTI and EuRoC, demonstrating
significant advantages over the geometry-based methods on challenging
trajectories. Our code is available at https://github.com/castacks/tartanvo.
</p>
<a href="http://arxiv.org/abs/2011.00359" target="_blank">arXiv:2011.00359</a> [<a href="http://arxiv.org/pdf/2011.00359" target="_blank">pdf</a>]

<h2>A Survey on Contrastive Self-supervised Learning. (arXiv:2011.00362v1 [cs.CV])</h2>
<h3>Ashish Jaiswal, Ashwin Ramesh Babu, Mohammad Zaki Zadeh, Debapriya Banerjee, Fillia Makedon</h3>
<p>Self-supervised learning has gained popularity because of its ability to
avoid the cost of annotating large-scale datasets. It is capable of adopting
self-defined pseudo labels as supervision and use the learned representations
for several downstream tasks. Specifically, contrastive learning has recently
become a dominant component in self-supervised learning methods for computer
vision, natural language processing (NLP), and other domains. It aims at
embedding augmented versions of the same sample close to each other while
trying to push away embeddings from different samples. This paper provides an
extensive review of self-supervised methods that follow the contrastive
approach. The work explains commonly used pretext tasks in a contrastive
learning setup, followed by different architectures that have been proposed so
far. Next, we have a performance comparison of different methods for multiple
downstream tasks such as image classification, object detection, and action
recognition. Finally, we conclude with the limitations of the current methods
and the need for further techniques and future directions to make substantial
progress.
</p>
<a href="http://arxiv.org/abs/2011.00362" target="_blank">arXiv:2011.00362</a> [<a href="http://arxiv.org/pdf/2011.00362" target="_blank">pdf</a>]

<h2>DL-Reg: A Deep Learning Regularization Technique using Linear Regression. (arXiv:2011.00368v1 [cs.LG])</h2>
<h3>Maryam Dialameh, Ali Hamzeh, Hossein Rahmani</h3>
<p>Regularization plays a vital role in the context of deep learning by
preventing deep neural networks from the danger of overfitting. This paper
proposes a novel deep learning regularization method named as DL-Reg, which
carefully reduces the nonlinearity of deep networks to a certain extent by
explicitly enforcing the network to behave as much linear as possible. The key
idea is to add a linear constraint to the objective function of the deep neural
networks, which is simply the error of a linear mapping from the inputs to the
outputs of the model. More precisely, the proposed DL-Reg carefully forces the
network to behave in a linear manner. This linear constraint, which is further
adjusted by a regularization factor, prevents the network from the risk of
overfitting. The performance of DL-Reg is evaluated by training
state-of-the-art deep network models on several benchmark datasets. The
experimental results show that the proposed regularization method: 1) gives
major improvements over the existing regularization techniques, and 2)
significantly improves the performance of deep neural networks, especially in
the case of small-sized training datasets.
</p>
<a href="http://arxiv.org/abs/2011.00368" target="_blank">arXiv:2011.00368</a> [<a href="http://arxiv.org/pdf/2011.00368" target="_blank">pdf</a>]

<h2>Segmentation of Infrared Breast Images Using MultiResUnet Neural Network. (arXiv:2011.00376v1 [eess.IV])</h2>
<h3>Ange Lou, Shuyue Guan, Nada Kamona, Murray Loew</h3>
<p>Breast cancer is the second leading cause of death for women in the U.S.
Early detection of breast cancer is key to higher survival rates of breast
cancer patients. We are investigating infrared (IR) thermography as a
noninvasive adjunct to mammography for breast cancer screening. IR imaging is
radiation-free, pain-free, and non-contact. Automatic segmentation of the
breast area from the acquired full-size breast IR images will help limit the
area for tumor search, as well as reduce the time and effort costs of manual
segmentation. Autoencoder-like convolutional and deconvolutional neural
networks (C-DCNN) had been applied to automatically segment the breast area in
IR images in previous studies. In this study, we applied a state-of-the-art
deep-learning segmentation model, MultiResUnet, which consists of an encoder
part to capture features and a decoder part for precise localization. It was
used to segment the breast area by using a set of breast IR images, collected
in our pilot study by imaging breast cancer patients and normal volunteers with
a thermal infrared camera (N2 Imager). The database we used has 450 images,
acquired from 14 patients and 16 volunteers. We used a thresholding method to
remove interference in the raw images and remapped them from the original
16-bit to 8-bit, and then cropped and segmented the 8-bit images manually.
Experiments using leave-one-out cross-validation (LOOCV) and comparison with
the ground-truth images by using Tanimoto similarity show that the average
accuracy of MultiResUnet is 91.47%, which is about 2% higher than that of the
autoencoder. MultiResUnet offers a better approach to segment breast IR images
than our previous model.
</p>
<a href="http://arxiv.org/abs/2011.00376" target="_blank">arXiv:2011.00376</a> [<a href="http://arxiv.org/pdf/2011.00376" target="_blank">pdf</a>]

<h2>Leveraging Natural Language Processing to Mine Issues on Twitter During the COVID-19 Pandemic. (arXiv:2011.00377v1 [cs.IR])</h2>
<h3>Ankita Agarwal, Preetham Salehundam, Swati Padhee, William L. Romine, Tanvi Banerjee</h3>
<p>The recent global outbreak of the coronavirus disease (COVID-19) has spread
to all corners of the globe. The international travel ban, panic buying, and
the need for self-quarantine are among the many other social challenges brought
about in this new era. Twitter platforms have been used in various public
health studies to identify public opinion about an event at the local and
global scale. To understand the public concerns and responses to the pandemic,
a system that can leverage machine learning techniques to filter out irrelevant
tweets and identify the important topics of discussion on social media
platforms like Twitter is needed. In this study, we constructed a system to
identify the relevant tweets related to the COVID-19 pandemic throughout
January 1\textsuperscript{st}, 2020 to April 30\textsuperscript{th}, 2020 and
explored topic modeling to identify the most discussed topics and themes during
this period in our data set. Additionally, we analyzed the temporal changes in
the topics with respect to the events that occurred during this pandemic. We
found out that eight topics were sufficient to identify the themes in our
corpus. These topics depicted a temporal trend. The dominant topics vary over
time and align with the events related to the COVID-19 pandemic.
</p>
<a href="http://arxiv.org/abs/2011.00377" target="_blank">arXiv:2011.00377</a> [<a href="http://arxiv.org/pdf/2011.00377" target="_blank">pdf</a>]

<h2>A Policy Gradient Algorithm for Learning to Learn in Multiagent Reinforcement Learning. (arXiv:2011.00382v1 [cs.LG])</h2>
<h3>Dong-Ki Kim, Miao Liu, Matthew Riemer, Chuangchuang Sun, Marwa Abdulhai, Golnaz Habibi, Sebastian Lopez-Cot, Gerald Tesauro, Jonathan P. How</h3>
<p>A fundamental challenge in multiagent reinforcement learning is to learn
beneficial behaviors in a shared environment with other agents that are also
simultaneously learning. In particular, each agent perceives the environment as
effectively non-stationary due to the changing policies of other agents.
Moreover, each agent is itself constantly learning, leading to natural
nonstationarity in the distribution of experiences encountered. In this paper,
we propose a novel meta-multiagent policy gradient theorem that directly
accommodates for the non-stationary policy dynamics inherent to these
multiagent settings. This is achieved by modeling our gradient updates to
directly consider both an agent's own non-stationary policy dynamics and the
non-stationary policy dynamics of other agents interacting with it in the
environment. We find that our theoretically grounded approach provides a
general solution to the multiagent learning problem, which inherently combines
key aspects of previous state of the art approaches on this topic. We test our
method on several multiagent benchmarks and demonstrate a more efficient
ability to adapt to new agents as they learn than previous related approaches
across the spectrum of mixed incentive, competitive, and cooperative
environments.
</p>
<a href="http://arxiv.org/abs/2011.00382" target="_blank">arXiv:2011.00382</a> [<a href="http://arxiv.org/pdf/2011.00382" target="_blank">pdf</a>]

<h2>CityPM: Predictive Monitoring with Logic-Calibrated Uncertainty for Smart Cities. (arXiv:2011.00384v1 [cs.LG])</h2>
<h3>Meiyi Ma, John Stankovic, Ezio Bartocci, Lu Feng</h3>
<p>We present CityPM, a novel predictive monitoring system for smart cities,
that continuously generates sequential predictions of future city states using
Bayesian deep learning and monitors if the generated predictions satisfy city
safety and performance requirements. We formally define a flowpipe signal to
characterize prediction outputs of Bayesian deep learning models, and develop a
new logic, named {Signal Temporal Logic with Uncertainty} (STL-U), for
reasoning about the correctness of flowpipe signals. CityPM can monitor city
requirements specified in STL-U such as "with 90% confidence level, the
predicated air quality index in the next 10 hours should always be below 100".
We also develop novel STL-U logic-based criteria to measure uncertainty for
Bayesian deep learning. CityPM uses these logic-calibrated uncertainty
measurements to select and tune the uncertainty estimation schema in deep
learning models. We evaluate CityPM on three large-scale smart city case
studies, including two real-world city datasets and one simulated city
experiment. The results show that CityPM significantly improves the simulated
city's safety and performance, and the use of STL-U logic-based criteria leads
to improved uncertainty calibration in various Bayesian deep learning models.
</p>
<a href="http://arxiv.org/abs/2011.00384" target="_blank">arXiv:2011.00384</a> [<a href="http://arxiv.org/pdf/2011.00384" target="_blank">pdf</a>]

<h2>Be More with Less: Hypergraph Attention Networks for Inductive Text Classification. (arXiv:2011.00387v1 [cs.CL])</h2>
<h3>Kaize Ding, Jianling Wang, Jundong Li, Dingcheng Li, Huan Liu</h3>
<p>Text classification is a critical research topic with broad applications in
natural language processing. Recently, graph neural networks (GNNs) have
received increasing attention in the research community and demonstrated their
promising results on this canonical task. Despite the success, their
performance could be largely jeopardized in practice since they are: (1) unable
to capture high-order interaction between words; (2) inefficient to handle
large datasets and new documents. To address those issues, in this paper, we
propose a principled model -- hypergraph attention networks (HyperGAT), which
can obtain more expressive power with less computational consumption for text
representation learning. Extensive experiments on various benchmark datasets
demonstrate the efficacy of the proposed approach on the text classification
task.
</p>
<a href="http://arxiv.org/abs/2011.00387" target="_blank">arXiv:2011.00387</a> [<a href="http://arxiv.org/pdf/2011.00387" target="_blank">pdf</a>]

<h2>Using Monte Carlo dropout and bootstrap aggregation for uncertainty estimation in radiation therapy dose prediction with deep learning neural networks. (arXiv:2011.00388v1 [physics.med-ph])</h2>
<h3>Dan Nguyen, Azar Sadeghnejad Barkousaraie, Gyanendra Bohara, Anjali Balagopal, Rafe McBeth, Mu-Han Lin, Steve Jiang</h3>
<p>Recently, artificial intelligence technologies and algorithms have become a
major focus for advancements in treatment planning for radiation therapy. As
these are starting to become incorporated into the clinical workflow, a major
concern from clinicians is not whether the model is accurate, but whether the
model can express to a human operator when it does not know if its answer is
correct. We propose to use Monte Carlo dropout (MCDO) and the bootstrap
aggregation (bagging) technique on deep learning models to produce uncertainty
estimations for radiation therapy dose prediction. We show that both models are
capable of generating a reasonable uncertainty map, and, with our proposed
scaling technique, creating interpretable uncertainties and bounds on the
prediction and any relevant metrics. Performance-wise, bagging provides
statistically significant reduced loss value and errors in most of the metrics
investigated in this study. The addition of bagging was able to further reduce
errors by another 0.34% for Dmean and 0.19% for Dmax, on average, when compared
to the baseline framework. Overall, the bagging framework provided
significantly lower MAE of 2.62, as opposed to the baseline framework's MAE of
2.87. The usefulness of bagging, from solely a performance standpoint, does
highly depend on the problem and the acceptable predictive error, and its high
upfront computational cost during training should be factored in to deciding
whether it is advantageous to use it. In terms of deployment with uncertainty
estimations turned on, both frameworks offer the same performance time of about
12 seconds. As an ensemble-based metaheuristic, bagging can be used with
existing machine learning architectures to improve stability and performance,
and MCDO can be applied to any deep learning models that have dropout as part
of their architecture.
</p>
<a href="http://arxiv.org/abs/2011.00388" target="_blank">arXiv:2011.00388</a> [<a href="http://arxiv.org/pdf/2011.00388" target="_blank">pdf</a>]

<h2>A Passive Navigation Planning Algorithm for Collision-free Control of Mobile Robots. (arXiv:2011.00390v1 [cs.RO])</h2>
<h3>Carlo Tiseo, Vladimir Ivan, Wolfgang Merkt, Ioannis Havoutis, Michael Mistry, Sethu Vijayakumar</h3>
<p>Path planning and collision avoidance are challenging in complex and highly
variable environments due to the limited horizon of events. In literature,
there are multiple model- and learning-based approaches that require
significant computational resources to be effectively deployed and they may
have limited generality. We propose a planning algorithm based on a globally
stable passive controller that can plan smooth trajectories using limited
computational resources in challenging environmental conditions. The
architecture combines the recently proposed fractal impedance controller with
elastic bands and regions of finite time invariance. As the method is based on
an impedance controller, it can also be used directly as a force/torque
controller. We validated our method in simulation to analyse the ability of
interactive navigation in challenging concave domains via the issuing of
via-points, and its robustness to low bandwidth feedback. A swarm simulation
using 11 agents validated the scalability of the proposed method. We have
performed hardware experiments on a holonomic wheeled platform validating
smoothness and robustness of interaction with dynamic agents (i.e., humans and
robots). The computational complexity of the proposed local planner enables
deployment with low-power micro-controllers lowering the energy consumption
compared to other methods that rely upon numeric optimisation.
</p>
<a href="http://arxiv.org/abs/2011.00390" target="_blank">arXiv:2011.00390</a> [<a href="http://arxiv.org/pdf/2011.00390" target="_blank">pdf</a>]

<h2>APPLR: Adaptive Planner Parameter Learning from Reinforcement. (arXiv:2011.00397v1 [cs.RO])</h2>
<h3>Zifan Xu, Gauraang Dhamankar, Anirudh Nair, Xuesu Xiao, Garrett Warnell, Bo Liu, Zizhao Wang, Peter Stone</h3>
<p>Classical navigation systems typically operate using a fixed set of
hand-picked parameters (e.g. maximum speed, sampling rate, inflation radius,
etc.) and require heavy expert re-tuning in order to work in new environments.
To mitigate this requirement, it has been proposed to learn parameters for
different contexts in a new environment using human demonstrations collected
via teleoperation. However, learning from human demonstration limits deployment
to the training environment, and limits overall performance to that of a
potentially-suboptimal demonstrator. In this paper, we introduce APPLR,
Adaptive Planner Parameter Learning from Reinforcement, which allows existing
navigation systems to adapt to new scenarios by using a parameter selection
scheme discovered via reinforcement learning (RL) in a wide variety of
simulation environments. We evaluate APPLR on a robot in both simulated and
physical experiments, and show that it can outperform both a fixed set of
hand-tuned parameters and also a dynamic parameter tuning scheme learned from
human demonstration.
</p>
<a href="http://arxiv.org/abs/2011.00397" target="_blank">arXiv:2011.00397</a> [<a href="http://arxiv.org/pdf/2011.00397" target="_blank">pdf</a>]

<h2>APPLI: Adaptive Planner Parameter Learning From Interventions. (arXiv:2011.00400v1 [cs.RO])</h2>
<h3>Zizhao Wang, Xuesu Xiao, Bo Liu, Garrett Warnell, Peter Stone</h3>
<p>While classical autonomous navigation systems can typically move robots from
one point to another safely and in a collision-free manner, these systems may
fail or produce suboptimal behavior in certain scenarios. The current practice
in such scenarios is to manually re-tune the system's parameters, e.g. max
speed, sampling rate, inflation radius, to optimize performance. This practice
requires expert knowledge and may jeopardize performance in the originally good
scenarios. Meanwhile, it is relatively easy for a human to identify those
failure or suboptimal cases and provide a teleoperated intervention to correct
the failure or suboptimal behavior. In this work, we seek to learn from those
human interventions to improve navigation performance. In particular, we
propose Adaptive Planner Parameter Learning from Interventions (APPLI), in
which multiple sets of navigation parameters are learned during training and
applied based on a confidence measure to the underlying navigation system
during deployment. In our physical experiments, the robot achieves better
performance compared to the planner with static default parameters, and even
dynamic parameters learned from a full human demonstration. We also show
APPLI's generalizability in another unseen physical test course and a suite of
300 simulated navigation environments.
</p>
<a href="http://arxiv.org/abs/2011.00400" target="_blank">arXiv:2011.00400</a> [<a href="http://arxiv.org/pdf/2011.00400" target="_blank">pdf</a>]

<h2>The MAGICAL Benchmark for Robust Imitation. (arXiv:2011.00401v1 [cs.LG])</h2>
<h3>Sam Toyer, Rohin Shah, Andrew Critch, Stuart Russell</h3>
<p>Imitation Learning (IL) algorithms are typically evaluated in the same
environment that was used to create demonstrations. This rewards precise
reproduction of demonstrations in one particular environment, but provides
little information about how robustly an algorithm can generalise the
demonstrator's intent to substantially different deployment settings. This
paper presents the MAGICAL benchmark suite, which permits systematic evaluation
of generalisation by quantifying robustness to different kinds of distribution
shift that an IL algorithm is likely to encounter in practice. Using the
MAGICAL suite, we confirm that existing IL algorithms overfit significantly to
the context in which demonstrations are provided. We also show that standard
methods for reducing overfitting are effective at creating narrow perceptual
invariances, but are not sufficient to enable transfer to contexts that require
substantially different behaviour, which suggests that new approaches will be
needed in order to robustly generalise demonstrator intent. Code and data for
the MAGICAL suite is available at https://github.com/qxcv/magical/.
</p>
<a href="http://arxiv.org/abs/2011.00401" target="_blank">arXiv:2011.00401</a> [<a href="http://arxiv.org/pdf/2011.00401" target="_blank">pdf</a>]

<h2>Non-Autoregressive Predictive Coding for Learning Speech Representations from Local Dependencies. (arXiv:2011.00406v1 [cs.CL])</h2>
<h3>Alexander H. Liu, Yu-An Chung, James Glass</h3>
<p>Self-supervised speech representations have been shown to be effective in a
variety of speech applications. However, existing representation learning
methods generally rely on the autoregressive model and/or observed global
dependencies while generating the representation. In this work, we propose
Non-Autoregressive Predictive Coding (NPC), a self-supervised method, to learn
a speech representation in a non-autoregressive manner by relying only on local
dependencies of speech. NPC has a conceptually simple objective and can be
implemented easily with the introduced Masked Convolution Blocks. NPC offers a
significant speedup for inference since it is parallelizable in time and has a
fixed inference time for each time step regardless of the input sequence
length. We discuss and verify the effectiveness of NPC by theoretically and
empirically comparing it with other methods. We show that the NPC
representation is comparable to other methods in speech experiments on phonetic
and speaker classification while being more efficient.
</p>
<a href="http://arxiv.org/abs/2011.00406" target="_blank">arXiv:2011.00406</a> [<a href="http://arxiv.org/pdf/2011.00406" target="_blank">pdf</a>]

<h2>Graph based Clustering Algorithm for Social Community Transmission Prediction of COVID-19. (arXiv:2011.00414v1 [cs.SI])</h2>
<h3>Varun Nagesh Jolly Behera, Ashish Ranjan, Motahar Reza</h3>
<p>A system to model the spread of COVID-19 cases after lockdown has been
proposed, to define new preventive measures based on hotspots, using the graph
clustering algorithm. This method allows for more lenient measures in areas
less prone to the virus spread. There exist methods to model the spread of the
virus, by predicting the number of confirmed cases. But the proposed system
focuses more on the preventive side of the solution from a geographical point
of view, by predicting the areas or regions that may become hotspots for the
virus in the near future. The fact that the virus can only be transmitted by
being in close proximity to an already infected person, suggests that, the
regions that can easily be reached from an existing hotspot, have a higher
chance of becoming a new hotspot. Moreover, in smaller regions, even after
strict provisions, positive cases have been found. To consider this fact, the
geographic distance between the nearest hotspots can be used as a measure of
likelihood of the region also becoming a hotspot. In this paper, a weighted
graph of regions with the regions themselves as weighted nodes with weight of
the nodes as the number of active cases and the distance as edge weights. The
graph can be completely connected or connected based on a distance threshold.
The nodes are the administrative, and the distance measure tells the possible
transmission between separate communities. Using this data, the potential
regions that can become hotspots can be predicted, and preventive measures can
be devised.
</p>
<a href="http://arxiv.org/abs/2011.00414" target="_blank">arXiv:2011.00414</a> [<a href="http://arxiv.org/pdf/2011.00414" target="_blank">pdf</a>]

<h2>Inter-domain Deep Gaussian Processes. (arXiv:2011.00415v1 [stat.ML])</h2>
<h3>Tim G. J. Rudner, Dino Sejdinovic, Yarin Gal</h3>
<p>Inter-domain Gaussian processes (GPs) allow for high flexibility and low
computational cost when performing approximate inference in GP models. They are
particularly suitable for modeling data exhibiting global structure but are
limited to stationary covariance functions and thus fail to model
non-stationary data effectively. We propose Inter-domain Deep Gaussian
Processes, an extension of inter-domain shallow GPs that combines the
advantages of inter-domain and deep Gaussian processes (DGPs), and demonstrate
how to leverage existing approximate inference methods to perform simple and
scalable approximate inference using inter-domain features in DGPs. We assess
the performance of our method on a range of regression tasks and demonstrate
that it outperforms inter-domain shallow GPs and conventional DGPs on
challenging large-scale real-world datasets exhibiting both global structure as
well as a high-degree of non-stationarity.
</p>
<a href="http://arxiv.org/abs/2011.00415" target="_blank">arXiv:2011.00415</a> [<a href="http://arxiv.org/pdf/2011.00415" target="_blank">pdf</a>]

<h2>Deep Learning for Text Attribute Transfer: A Survey. (arXiv:2011.00416v1 [cs.CL])</h2>
<h3>Di Jin, Zhijing Jin, Rada Mihalcea</h3>
<p>Driven by the increasingly larger deep learning models, neural language
generation (NLG) has enjoyed unprecedentedly improvement and is now able to
generate a diversity of human-like texts on demand, granting itself the
capability of serving as a human writing assistant. Text attribute transfer is
one of the most important NLG tasks, which aims to control certain attributes
that people may expect the texts to possess, such as sentiment, tense, emotion,
political position, etc. It has a long history in Natural Language Processing
but recently gains much more attention thanks to the promising performance
brought by deep learning models. In this article, we present a systematic
survey on these works for neural text attribute transfer. We collect all
related academic works since the first appearance in 2017. We then select,
summarize, discuss, and analyze around 65 representative works in a
comprehensive way. Overall, we have covered the task formulation, existing
datasets and metrics for model development and evaluation, and all methods
developed over the last several years. We reveal that existing methods are
indeed based on a combination of several loss functions with each of which
serving a certain goal. Such a unique perspective we provide could shed light
on the design of new methods. We conclude our survey with a discussion on open
issues that need to be resolved for better future development.
</p>
<a href="http://arxiv.org/abs/2011.00416" target="_blank">arXiv:2011.00416</a> [<a href="http://arxiv.org/pdf/2011.00416" target="_blank">pdf</a>]

<h2>Monitoring-based Differential Privacy Mechanism Against Query-Flooding Parameter Duplication Attack. (arXiv:2011.00418v1 [cs.CR])</h2>
<h3>Haonan Yan, Xiaoguang Li, Hui Li, Jiamin Li, Wenhai Sun, Fenghua Li</h3>
<p>Public intelligent services enabled by machine learning algorithms are
vulnerable to model extraction attacks that can steal confidential information
of the learning models through public queries. Though there are some protection
options such as differential privacy (DP) and monitoring, which are considered
promising techniques to mitigate this attack, we still find that the
vulnerability persists. In this paper, we propose an adaptive query-flooding
parameter duplication (QPD) attack. The adversary can infer the model
information with black-box access and no prior knowledge of any model
parameters or training data via QPD. We also develop a defense strategy using
DP called monitoring-based DP (MDP) against this new attack. In MDP, we first
propose a novel real-time model extraction status assessment scheme called
Monitor to evaluate the situation of the model. Then, we design a method to
guide the differential privacy budget allocation called APBA adaptively.
Finally, all DP-based defenses with MDP could dynamically adjust the amount of
noise added in the model response according to the result from Monitor and
effectively defends the QPD attack. Furthermore, we thoroughly evaluate and
compare the QPD attack and MDP defense performance on real-world models with DP
and monitoring protection.
</p>
<a href="http://arxiv.org/abs/2011.00418" target="_blank">arXiv:2011.00418</a> [<a href="http://arxiv.org/pdf/2011.00418" target="_blank">pdf</a>]

<h2>Future-Aware Diverse Trends Framework for Recommendation. (arXiv:2011.00422v1 [cs.IR])</h2>
<h3>Yujie Lu, Shengyu Zhang, Yingxuan Huang, Luyao Wang, Xinyao Yu, Zhou Zhao, Fei Wu</h3>
<p>In recommender systems, modeling user-item behaviors is essential for user
representation learning. Existing sequential recommenders consider the
sequential correlations between historically interacted items for capturing
users' historical preferences. However, since users' preferences are by nature
time-evolving and diversified, solely modeling the historical preference
(without being aware of the time-evolving trends of preferences) can be
inferior for recommending complementary or fresh items and thus hurt the
effectiveness of recommender systems. In this paper, we bridge the gap between
the past preference and potential future preference by proposing the
future-aware diverse trends (FAT) framework. By future-aware, for each
inspected user, we construct the future sequences from other similar users,
which comprise of behaviors that happen after the last behavior of the
inspected user, based on a proposed neighbor behavior extractor. By diverse
trends, supposing the future preferences can be diversified, we propose the
diverse trends extractor and the time-aware mechanism to represent the possible
trends of preferences for a given user with multiple vectors. We leverage both
the representations of historical preference and possible future trends to
obtain the final recommendation. The quantitative and qualitative results from
relatively extensive experiments on real-world datasets demonstrate the
proposed framework not only outperforms the state-of-the-art sequential
recommendation methods across various metrics, but also makes complementary and
fresh recommendations.
</p>
<a href="http://arxiv.org/abs/2011.00422" target="_blank">arXiv:2011.00422</a> [<a href="http://arxiv.org/pdf/2011.00422" target="_blank">pdf</a>]

<h2>Sample Efficient Training in Multi-Agent Adversarial Games with Limited Teammate Communication. (arXiv:2011.00424v1 [cs.LG])</h2>
<h3>Hardik Meisheri, Harshad Khadilkar</h3>
<p>We describe our solution approach for Pommerman TeamRadio, a competition
environment associated with NeurIPS 2019. The defining feature of our algorithm
is achieving sample efficiency within a restrictive computational budget while
beating the previous years learning agents. The proposed algorithm (i) uses
imitation learning to seed the policy, (ii) explicitly defines the
communication protocol between the two teammates, (iii) shapes the reward to
provide a richer feedback signal to each agent during training and (iv) uses
masking for catastrophic bad actions. We describe extensive tests against
baselines, including those from the 2019 competition leaderboard, and also a
specific investigation of the learned policy and the effect of each
modification on performance. We show that the proposed approach is able to
achieve competitive performance within half a million games of training,
significantly faster than other studies in the literature.
</p>
<a href="http://arxiv.org/abs/2011.00424" target="_blank">arXiv:2011.00424</a> [<a href="http://arxiv.org/pdf/2011.00424" target="_blank">pdf</a>]

<h2>Analyzing the Effect of Multi-task Learning for Biomedical Named Entity Recognition. (arXiv:2011.00425v1 [cs.CL])</h2>
<h3>Arda Akdemir, Tetsuo Shibuya</h3>
<p>Developing high-performing systems for detecting biomedical named entities
has major implications. State-of-the-art deep-learning based solutions for
entity recognition often require large annotated datasets, which is not
available in the biomedical domain. Transfer learning and multi-task learning
have been shown to improve performance for low-resource domains. However, the
applications of these methods are relatively scarce in the biomedical domain,
and a theoretical understanding of why these methods improve the performance is
lacking. In this study, we performed an extensive analysis to understand the
transferability between different biomedical entity datasets. We found useful
measures to predict transferability between these datasets. Besides, we propose
combining transfer learning and multi-task learning to improve the performance
of biomedical named entity recognition systems, which is not applied before to
the best of our knowledge.
</p>
<a href="http://arxiv.org/abs/2011.00425" target="_blank">arXiv:2011.00425</a> [<a href="http://arxiv.org/pdf/2011.00425" target="_blank">pdf</a>]

<h2>Efficient Pipelines for Vision-Based Context Sensing. (arXiv:2011.00427v1 [cs.CV])</h2>
<h3>Xiaochen Liu</h3>
<p>Context awareness is an essential part of mobile and ubiquitous computing.
Its goal is to unveil situational information about mobile users like locations
and activities. The sensed context can enable many services like navigation,
AR, and smarting shopping. Such context can be sensed in different ways
including visual sensors. There is an emergence of vision sources deployed
worldwide. The cameras could be installed on roadside, in-house, and on mobile
platforms. This trend provides huge amount of vision data that could be used
for context sensing. However, the vision data collection and analytics are
still highly manual today. It is hard to deploy cameras at large scale for data
collection. Organizing and labeling context from the data are also labor
intensive. In recent years, advanced vision algorithms and deep neural networks
are used to help analyze vision data. But this approach is limited by data
quality, labeling effort, and dependency on hardware resources. In summary,
there are three major challenges for today's vision-based context sensing
systems: data collection and labeling at large scale, process large data
volumes efficiently with limited hardware resources, and extract accurate
context out of vision data. The thesis explores the design space that consists
of three dimensions: sensing task, sensor types, and task locations. Our prior
work explores several points in this design space. We make contributions by (1)
developing efficient and scalable solutions for different points in the design
space of vision-based sensing tasks; (2) achieving state-of-the-art accuracy in
those applications; (3) and developing guidelines for designing such sensing
systems.
</p>
<a href="http://arxiv.org/abs/2011.00427" target="_blank">arXiv:2011.00427</a> [<a href="http://arxiv.org/pdf/2011.00427" target="_blank">pdf</a>]

<h2>Two-layer clustering-based sparsifying transform learning for low-dose CT reconstruction. (arXiv:2011.00428v1 [eess.IV])</h2>
<h3>Xikai Yang, Yong Long, Saiprasad Ravishankar</h3>
<p>Achieving high-quality reconstructions from low-dose computed tomography
(LDCT) measurements is of much importance in clinical settings. Model-based
image reconstruction methods have been proven to be effective in removing
artifacts in LDCT. In this work, we propose an approach to learn a rich
two-layer clustering-based sparsifying transform model (MCST2), where image
patches and their subsequent feature maps (filter residuals) are clustered into
groups with different learned sparsifying filters per group. We investigate a
penalized weighted least squares (PWLS) approach for LDCT reconstruction
incorporating learned MCST2 priors. Experimental results show the superior
performance of the proposed PWLS-MCST2 approach compared to other related
recent schemes.
</p>
<a href="http://arxiv.org/abs/2011.00428" target="_blank">arXiv:2011.00428</a> [<a href="http://arxiv.org/pdf/2011.00428" target="_blank">pdf</a>]

<h2>Learning When to Switch: Composing Controllers to Traverse a Sequence of Terrain Artifacts. (arXiv:2011.00440v1 [cs.RO])</h2>
<h3>Brendan Tidd, Nicolas Hudson, Akansel Cosgun, Jurgen Leitner</h3>
<p>Legged robots often use separate control policies that are highly engineered
for traversing difficult terrain such as stairs, gaps, and steps, where
switching between policies is only possible when the robot is in a region that
is common to adjacent controllers. Deep Reinforcement Learning (DRL) is a
promising alternative to hand-crafted control design, though typically requires
the full set of test conditions to be known before training. DRL policies can
result in complex (often unrealistic) behaviours that have few or no
overlapping regions between adjacent policies, making it difficult to switch
behaviours. In this work we develop multiple DRL policies with Curriculum
Learning (CL), each that can traverse a single respective terrain condition,
while ensuring an overlap between policies. We then train a network for each
destination policy that estimates the likelihood of successfully switching from
any other policy. We evaluate our switching method on a previously unseen
combination of terrain artifacts and show that it performs better than
heuristic methods. While our method is trained on individual terrain types, it
performs comparably to a Deep Q Network trained on the full set of terrain
conditions. This approach allows the development of separate policies in
constrained conditions with embedded prior knowledge about each behaviour, that
is scalable to any number of behaviours, and prepares DRL methods for
applications in the real world
</p>
<a href="http://arxiv.org/abs/2011.00440" target="_blank">arXiv:2011.00440</a> [<a href="http://arxiv.org/pdf/2011.00440" target="_blank">pdf</a>]

<h2>CL-MAPF: Multi-Agent Path Finding for Car-Like Robots with Kinematic and Spatiotemporal Constraints. (arXiv:2011.00441v1 [cs.RO])</h2>
<h3>Licheng Wen, Zhen Zhang, Zhe Chen, Xiangrui Zhao, Yong Liu</h3>
<p>Multi-Agent Path Finding has been widely studied in the past few years due to
its broad application in the field of robotics and AI. However, previous
solvers rely on several simplifying assumptions. They limit their applicability
in numerous real-world domains that adopt nonholonomic car-like agents rather
than holonomic ones. In this paper, we give a mathematical formalization of
Multi-Agent Path Finding for Car-Like robots (CL-MAPF) problem. For the first
time, we propose a novel hierarchical search-based solver called Car-like
Conflict-Based Search to address this problem. It applies a body conflict tree
to address collisions considering shapes of the agents. We introduce a new
algorithm called Spatiotemporal Hybrid-State A* as the single-agent path
planner to generate path satisfying both kinematic and spatiotemporal
constraints. We also present a sequential planning version of our method for
the sake of efficiency. We compare our method with two baseline algorithms on a
dedicated benchmark containing 3000 instances and validate it in real-world
scenarios. The experiment results give clear evidence that our algorithm scales
well to a large number of agents and is able to produce solutions that can be
directly applied to car-like robots in the real world. The benchmark and source
code are released in https://github.com/APRIL-ZJU/CL-CBS.
</p>
<a href="http://arxiv.org/abs/2011.00441" target="_blank">arXiv:2011.00441</a> [<a href="http://arxiv.org/pdf/2011.00441" target="_blank">pdf</a>]

<h2>Discriminative Adversarial Domain Generalization with Meta-learning based Cross-domain Validation. (arXiv:2011.00444v1 [cs.LG])</h2>
<h3>Keyu Chen, Di Zhuang, J. Morris Chang</h3>
<p>The generalization capability of machine learning models, which refers to
generalizing the knowledge for an "unseen" domain via learning from one or
multiple seen domain(s), is of great importance to develop and deploy machine
learning applications in the real-world conditions. Domain Generalization (DG)
techniques aim to enhance such generalization capability of machine learning
models, where the learnt feature representation and the classifier are two
crucial factors to improve generalization and make decisions. In this paper, we
propose Discriminative Adversarial Domain Generalization (DADG) with
meta-learning-based cross-domain validation. Our proposed framework contains
two main components that work synergistically to build a domain-generalized DNN
model: (i) discriminative adversarial learning, which proactively learns a
generalized feature representation on multiple "seen" domains, and (ii)
meta-learning based cross-domain validation, which simulates train/test domain
shift via applying meta-learning techniques in the training process. In the
experimental evaluation, a comprehensive comparison has been made among our
proposed approach and other existing approaches on three benchmark datasets.
The results shown that DADG consistently outperforms a strong baseline DeepAll,
and outperforms the other existing DG algorithms in most of the evaluation
cases.
</p>
<a href="http://arxiv.org/abs/2011.00444" target="_blank">arXiv:2011.00444</a> [<a href="http://arxiv.org/pdf/2011.00444" target="_blank">pdf</a>]

<h2>Bound Controller for a Quadruped Robot using Pre-Fitting Deep Reinforcement Learning. (arXiv:2011.00446v1 [cs.RO])</h2>
<h3>Anqiao Li, Zhicheng Wang, Jun Wu, Qiuguo Zhu</h3>
<p>The bound gait is an important gait in quadruped robot locomotion. It can be
used to cross obstacles and often serves as transition mode between trot and
gallop. However, because of the complexity of the models, the bound gait built
by the conventional control method is often unnatural and slow to compute. In
the present work, we introduce a method to achieve the bound gait based on
model-free pre-fit deep reinforcement learning (PF-DRL). We first constructed a
net with the same structure as an actor net in the PPO2 and pre-fit it using
the data collected from a robot using conventional model-based controller.
Next, the trained weights are transferred into the PPO2 and be optimized
further. Moreover, target on the symmetrical and periodic characteristic during
bounding, we designed a reward function based on contact points. We also used
feature engineering to improve the input features of the DRL model and improve
performance on flat ground. Finally, we trained the bound controller in
simulation and successfully deployed it on the Jueying Mini robot. It performs
better than the conventional method with higher computational efficiency and
more stable center-of-mass height in our experiments.
</p>
<a href="http://arxiv.org/abs/2011.00446" target="_blank">arXiv:2011.00446</a> [<a href="http://arxiv.org/pdf/2011.00446" target="_blank">pdf</a>]

<h2>Fake or Real? A Study of Arabic Satirical Fake News. (arXiv:2011.00452v1 [cs.CL])</h2>
<h3>Hadeel Saadany, Emad Mohamed, Constantin Orasan</h3>
<p>One very common type of fake news is satire which comes in a form of a news
website or an online platform that parodies reputable real news agencies to
create a sarcastic version of reality. This type of fake news is often
disseminated by individuals on their online platforms as it has a much stronger
effect in delivering criticism than through a straightforward message. However,
when the satirical text is disseminated via social media without mention of its
source, it can be mistaken for real news. This study conducts several
exploratory analyses to identify the linguistic properties of Arabic fake news
with satirical content. We exploit these features to build a number of machine
learning models capable of identifying satirical fake news with an accuracy of
up to 98.6%.
</p>
<a href="http://arxiv.org/abs/2011.00452" target="_blank">arXiv:2011.00452</a> [<a href="http://arxiv.org/pdf/2011.00452" target="_blank">pdf</a>]

<h2>Seeing Both the Forest and the Trees: Multi-head Attention for Joint Classification on Different Compositional Levels. (arXiv:2011.00470v1 [cs.CL])</h2>
<h3>Miruna Pislar, Marek Rei</h3>
<p>In natural languages, words are used in association to construct sentences.
It is not words in isolation, but the appropriate combination of hierarchical
structures that conveys the meaning of the whole sentence. Neural networks can
capture expressive language features; however, insights into the link between
words and sentences are difficult to acquire automatically. In this work, we
design a deep neural network architecture that explicitly wires lower and
higher linguistic components; we then evaluate its ability to perform the same
task at different hierarchical levels. Settling on broad text classification
tasks, we show that our model, MHAL, learns to simultaneously solve them at
different levels of granularity by fluidly transferring knowledge between
hierarchies. Using a multi-head attention mechanism to tie the representations
between single words and full sentences, MHAL systematically outperforms
equivalent models that are not incentivized towards developing compositional
representations. Moreover, we demonstrate that, with the proposed architecture,
the sentence information flows naturally to individual words, allowing the
model to behave like a sequence labeller (which is a lower, word-level task)
even without any word supervision, in a zero-shot fashion.
</p>
<a href="http://arxiv.org/abs/2011.00470" target="_blank">arXiv:2011.00470</a> [<a href="http://arxiv.org/pdf/2011.00470" target="_blank">pdf</a>]

<h2>Comparing Machine Learning Algorithms with or without Feature Extraction for DNA Classification. (arXiv:2011.00485v1 [q-bio.OT])</h2>
<h3>Xiangxie Zhang, Ben Beinke, Berlian Al Kindhi, Marco Wiering</h3>
<p>The classification of DNA sequences is a key research area in bioinformatics
as it enables researchers to conduct genomic analysis and detect possible
diseases. In this paper, three state-of-the-art algorithms, namely
Convolutional Neural Networks, Deep Neural Networks, and N-gram Probabilistic
Models, are used for the task of DNA classification. Furthermore, we introduce
a novel feature extraction method based on the Levenshtein distance and
randomly generated DNA sub-sequences to compute information-rich features from
the DNA sequences. We also use an existing feature extraction method based on
3-grams to represent amino acids and combine both feature extraction methods
with a multitude of machine learning algorithms. Four different data sets, each
concerning viral diseases such as Covid-19, AIDS, Influenza, and Hepatitis C,
are used for evaluating the different approaches. The results of the
experiments show that all methods obtain high accuracies on the different DNA
datasets. Furthermore, the domain-specific 3-gram feature extraction method
leads in general to the best results in the experiments, while the newly
proposed technique outperforms all other methods on the smallest Covid-19
dataset
</p>
<a href="http://arxiv.org/abs/2011.00485" target="_blank">arXiv:2011.00485</a> [<a href="http://arxiv.org/pdf/2011.00485" target="_blank">pdf</a>]

<h2>Fast Adaptation of Manipulator Trajectories to Task Perturbation By Differentiating through the Optimal Solution. (arXiv:2011.00488v1 [cs.RO])</h2>
<h3>Shashank Srikanth, Mithun Babu, Houman Masnavi, Arun Kumar Singh, Karl Kruusam&#xe4;e, K. Madhava Krishna</h3>
<p>Joint space trajectory optimization under end-effector task constraints leads
to a challenging non-convex problem. Thus, a real-time adaptation of prior
computed trajectories to perturbation in task constraints often becomes
intractable. Existing works use the so-called warm-starting of trajectory
optimization to improve computational performance. We present a fundamentally
different approach that relies on deriving analytical gradients of the optimal
solution with respect to the task constraint parameters. This gradient map
characterizes the direction in which the prior computed joint trajectories need
to be deformed to comply with the new task constraints. Subsequently, we
develop an iterative line-search algorithm for computing the scale of
deformation. Our algorithm provides near real-time adaptation of joint
trajectories for a diverse class of task perturbations such as (i) changes in
initial and final joint configurations of end-effector orientation-constrained
trajectories and (ii) changes in end-effector goal or way-points under
end-effector orientation constraints. We relate each of these examples to
real-world applications ranging from learning from demonstration to obstacle
avoidance. We also show that our algorithm produces trajectories with quality
similar to what one would obtain by solving the trajectory optimization from
scratch with warm-start initialization. But most importantly, our algorithm
achieves a worst-case speed-up of 160x over the latter approach.
</p>
<a href="http://arxiv.org/abs/2011.00488" target="_blank">arXiv:2011.00488</a> [<a href="http://arxiv.org/pdf/2011.00488" target="_blank">pdf</a>]

<h2>MRPB 1.0: A Unified Benchmark for the Evaluation of Mobile Robot Local Planning Approaches. (arXiv:2011.00491v1 [cs.RO])</h2>
<h3>Jian Wen, Xuebo Zhang, Qingchen Bi, Zhangchao Pan, Yanghe Feng, Jing Yuan, Yongchun Fang</h3>
<p>Local planning is one of the key technologies for mobile robots to achieve
full autonomy and has been widely investigated. To evaluate mobile robot local
planning approaches in a unified and comprehensive way, a mobile robot local
planning benchmark called MRPB 1.0 is newly proposed in this paper. The
benchmark facilitates both motion planning researchers who want to compare the
performance of a new local planner relative to many other state-of-the-art
approaches as well as end users in the mobile robotics industry who want to
select a local planner that performs best on some problems of interest. We
elaborately design various simulation scenarios to challenge the applicability
of local planners, including large-scale, partially unknown, and dynamic
complex environments. Furthermore, three types of principled evaluation metrics
are carefully designed to quantitatively evaluate the performance of local
planners, wherein the safety, efficiency, and smoothness of motions are
comprehensively considered. We present the application of the proposed
benchmark in two popular open-source local planners to show the practicality of
the benchmark. In addition, some insights and guidelines about the design and
selection of local planners are also provided. The benchmark website contains
all data of the designed simulation scenarios, detailed descriptions of these
scenarios, and example code.
</p>
<a href="http://arxiv.org/abs/2011.00491" target="_blank">arXiv:2011.00491</a> [<a href="http://arxiv.org/pdf/2011.00491" target="_blank">pdf</a>]

<h2>Polymer Informatics: Current Status and Critical Next Steps. (arXiv:2011.00508v1 [cond-mat.soft])</h2>
<h3>Lihua Chen, Ghanshyam Pilania, Rohit Batra, Tran Doan Huan, Chiho Kim, Christopher Kuenneth, Rampi Ramprasad</h3>
<p>Artificial intelligence (AI) based approaches are beginning to impact several
domains of human life, science and technology. Polymer informatics is one such
domain where AI and machine learning (ML) tools are being used in the efficient
development, design and discovery of polymers. Surrogate models are trained on
available polymer data for instant property prediction, allowing screening of
promising polymer candidates with specific target property requirements.
Questions regarding synthesizability, and potential (retro)synthesis steps to
create a target polymer, are being explored using statistical means.
Data-driven strategies to tackle unique challenges resulting from the
extraordinary chemical and physical diversity of polymers at small and large
scales are being explored. Other major hurdles for polymer informatics are the
lack of widespread availability of curated and organized data, and approaches
to create machine-readable representations that capture not just the structure
of complex polymeric situations but also synthesis and processing conditions.
Methods to solve inverse problems, wherein polymer recommendations are made
using advanced AI algorithms that meet application targets, are being
investigated. As various parts of the burgeoning polymer informatics ecosystem
mature and become integrated, efficiency improvements, accelerated discoveries
and increased productivity can result. Here, we review emergent components of
this polymer informatics ecosystem and discuss imminent challenges and
opportunities.
</p>
<a href="http://arxiv.org/abs/2011.00508" target="_blank">arXiv:2011.00508</a> [<a href="http://arxiv.org/pdf/2011.00508" target="_blank">pdf</a>]

<h2>PILOT: Efficient Planning by Imitation Learning and Optimisation for Safe Autonomous Driving. (arXiv:2011.00509v1 [cs.RO])</h2>
<h3>Henry Pulver, Francisco Eiras, Ludovico Carozza, Majd Hawasly, Stefano Albrecht, Subramanian Ramamoorthy</h3>
<p>Achieving the right balance between planning quality, safety and runtime
efficiency is a major challenge for autonomous driving research.
Optimisation-based planners are typically capable of producing high-quality,
safe plans, but at the cost of efficiency. We present PILOT, a two-stage
planning framework comprising an imitation neural network and an efficient
optimisation component that guarantees the satisfaction of requirements of
safety and comfort. The neural network is trained to imitate an
expensive-to-run optimisation-based planning system with the same objective as
the efficient optimisation component of PILOT. We demonstrate in simulated
autonomous driving experiments that the proposed framework achieves a
significant reduction in runtime when compared to the optimisation-based expert
it imitates, without sacrificing the planning quality.
</p>
<a href="http://arxiv.org/abs/2011.00509" target="_blank">arXiv:2011.00509</a> [<a href="http://arxiv.org/pdf/2011.00509" target="_blank">pdf</a>]

<h2>Watermarking Graph Neural Networks by Random Graphs. (arXiv:2011.00512v1 [cs.CR])</h2>
<h3>Xiangyu Zhao, Hanzhou Wu, Xinpeng Zhang</h3>
<p>Many learning tasks require us to deal with graph data which contains rich
relational information among elements, leading increasing graph neural network
(GNN) models to be deployed in industrial products for improving the quality of
service. However, they also raise challenges to model authentication. It is
necessary to protect the ownership of the GNN models, which motivates us to
present a watermarking method to GNN models in this paper. In the proposed
method, an Erdos-Renyi (ER) random graph with random node feature vectors and
labels is randomly generated as a trigger to train the GNN to be protected
together with the normal samples. During model training, the secret watermark
is embedded into the label predictions of the ER graph nodes. During model
verification, by activating a marked GNN with the trigger ER graph, the
watermark can be reconstructed from the output to verify the ownership. Since
the ER graph was randomly generated, by feeding it to a non-marked GNN, the
label predictions of the graph nodes are random, resulting in a low false alarm
rate (of the proposed work). Experimental results have also shown that, the
performance of a marked GNN on its original task will not be impaired.
Moreover, it is robust against model compression and fine-tuning, which has
shown the superiority and applicability.
</p>
<a href="http://arxiv.org/abs/2011.00512" target="_blank">arXiv:2011.00512</a> [<a href="http://arxiv.org/pdf/2011.00512" target="_blank">pdf</a>]

<h2>On Signal-to-Noise Ratio Issues in Variational Inference for Deep Gaussian Processes. (arXiv:2011.00515v1 [stat.ML])</h2>
<h3>Tim G. J. Rudner, Oscar Key, Yarin Gal, Tom Rainforth</h3>
<p>We show that the gradient estimates used in training Deep Gaussian Processes
(DGPs) with importance-weighted variational inference are susceptible to
signal-to-noise ratio (SNR) issues. Specifically, we show both theoretically
and empirically that the SNR of the gradient estimates for the latent
variable's variational parameters decreases as the number of importance samples
increases. As a result, these gradient estimates degrade to pure noise if the
number of importance samples is too large. To address this pathology, we show
how doubly-reparameterized gradient estimators, originally proposed for
training variational autoencoders, can be adapted to the DGP setting and that
the resultant estimators completely remedy the SNR issue, thereby providing
more reliable training. Finally, we demonstrate that our fix can lead to
improvements in the predictive performance of the model's predictive posterior.
</p>
<a href="http://arxiv.org/abs/2011.00515" target="_blank">arXiv:2011.00515</a> [<a href="http://arxiv.org/pdf/2011.00515" target="_blank">pdf</a>]

<h2>Ask Your Humans: Using Human Instructions to Improve Generalization in Reinforcement Learning. (arXiv:2011.00517v1 [cs.LG])</h2>
<h3>Valerie Chen, Abhinav Gupta, Kenneth Marino</h3>
<p>Complex, multi-task problems have proven to be difficult to solve efficiently
in a sparse-reward reinforcement learning setting. In order to be sample
efficient, multi-task learning requires reuse and sharing of low-level
policies. To facilitate the automatic decomposition of hierarchical tasks, we
propose the use of step-by-step human demonstrations in the form of natural
language instructions and action trajectories. We introduce a dataset of such
demonstrations in a crafting-based grid world. Our model consists of a
high-level language generator and low-level policy, conditioned on language. We
find that human demonstrations help solve the most complex tasks. We also find
that incorporating natural language allows the model to generalize to unseen
tasks in a zero-shot setting and to learn quickly from a few demonstrations.
Generalization is not only reflected in the actions of the agent, but also in
the generated natural language instructions in unseen tasks. Our approach also
gives our trained agent interpretable behaviors because it is able to generate
a sequence of high-level descriptions of its actions.
</p>
<a href="http://arxiv.org/abs/2011.00517" target="_blank">arXiv:2011.00517</a> [<a href="http://arxiv.org/pdf/2011.00517" target="_blank">pdf</a>]

<h2>AI Marker-based Large-scale AI Literature Mining. (arXiv:2011.00518v1 [cs.IR])</h2>
<h3>Rujing Yao, Yingchun Ye, Ji Zhang, Shuxiao Li, Ou Wu</h3>
<p>The knowledge contained in academic literature is interesting to mine.
Inspired by the idea of molecular markers tracing in the field of biochemistry,
three named entities, namely, methods, datasets and metrics are used as AI
markers for AI literature. These entities can be used to trace the research
process described in the bodies of papers, which opens up new perspectives for
seeking and mining more valuable academic information. Firstly, the entity
extraction model is used in this study to extract AI markers from large-scale
AI literature. Secondly, original papers are traced for AI markers. Statistical
and propagation analysis are performed based on tracing results. Finally, the
co-occurrences of AI markers are used to achieve clustering. The evolution
within method clusters and the influencing relationships amongst different
research scene clusters are explored. The above-mentioned mining based on AI
markers yields many meaningful discoveries. For example, the propagation of
effective methods on the datasets is rapidly increasing with the development of
time; effective methods proposed by China in recent years have increasing
influence on other countries, whilst France is the opposite. Saliency
detection, a classic computer vision research scene, is the least likely to be
affected by other research scenes.
</p>
<a href="http://arxiv.org/abs/2011.00518" target="_blank">arXiv:2011.00518</a> [<a href="http://arxiv.org/pdf/2011.00518" target="_blank">pdf</a>]

<h2>Neural Network Design: Learning from Neural Architecture Search. (arXiv:2011.00521v1 [cs.LG])</h2>
<h3>Bas van Stein, Hao Wang, Thomas B&#xe4;ck</h3>
<p>Neural Architecture Search (NAS) aims to optimize deep neural networks'
architecture for better accuracy or smaller computational cost and has recently
gained more research interests. Despite various successful approaches proposed
to solve the NAS task, the landscape of it, along with its properties, are
rarely investigated. In this paper, we argue for the necessity of studying the
landscape property thereof and propose to use the so-called Exploratory
Landscape Analysis (ELA) techniques for this goal. Taking a broad set of
designs of the deep convolutional network, we conduct extensive experimentation
to obtain their performance. Based on our analysis of the experimental results,
we observed high similarities between well-performing architecture designs,
which is then used to significantly narrow the search space to improve the
efficiency of any NAS algorithm. Moreover, we extract the ELA features over the
NAS landscapes on three common image classification data sets, MNIST, Fashion,
and CIFAR-10, which shows that the NAS landscape can be distinguished for those
three data sets. Also, when comparing to the ELA features of the well-known
Black-Box Optimization Benchmarking (BBOB) problem set, we found out that the
NAS landscapes surprisingly form a new problem class on its own, which can be
separated from all $24$ BBOB problems. Given this interesting observation, we,
therefore, state the importance of further investigation on selecting an
efficient optimizer for the NAS landscape as well as the necessity of
augmenting the current benchmark problem set.
</p>
<a href="http://arxiv.org/abs/2011.00521" target="_blank">arXiv:2011.00521</a> [<a href="http://arxiv.org/pdf/2011.00521" target="_blank">pdf</a>]

<h2>Learning Euler's Elastica Model for Medical Image Segmentation. (arXiv:2011.00526v1 [eess.IV])</h2>
<h3>Xu Chen, Xiangde Luo, Yitian Zhao, Shaoting Zhang, Guotai Wang, Yalin Zheng</h3>
<p>Image segmentation is a fundamental topic in image processing and has been
studied for many decades. Deep learning-based supervised segmentation models
have achieved state-of-the-art performance but most of them are limited by
using pixel-wise loss functions for training without geometrical constraints.
Inspired by Euler's Elastica model and recent active contour models introduced
into the field of deep learning, we propose a novel active contour with
elastica (ACE) loss function incorporating Elastica (curvature and length) and
region information as geometrically-natural constraints for the image
segmentation tasks. We introduce the mean curvature i.e. the average of all
principal curvatures, as a more effective image prior to representing curvature
in our ACE loss function. Furthermore, based on the definition of the mean
curvature, we propose a fast solution to approximate the ACE loss in
three-dimensional (3D) by using Laplace operators for 3D image segmentation. We
evaluate our ACE loss function on four 2D and 3D natural and biomedical image
datasets. Our results show that the proposed loss function outperforms other
mainstream loss functions on different segmentation networks. Our source code
is available at https://github.com/HiLab-git/ACELoss.
</p>
<a href="http://arxiv.org/abs/2011.00526" target="_blank">arXiv:2011.00526</a> [<a href="http://arxiv.org/pdf/2011.00526" target="_blank">pdf</a>]

<h2>Neuromorphic control for optic-flow-based landings of MAVs using the Loihi processor. (arXiv:2011.00534v1 [cs.RO])</h2>
<h3>Julien Dupeyroux, Jesse Hagenaars, Federico Paredes-Vall&#xe9;s, Guido de Croon</h3>
<p>Neuromorphic processors like Loihi offer a promising alternative to
conventional computing modules for endowing constrained systems like micro air
vehicles (MAVs) with robust, efficient and autonomous skills such as take-off
and landing, obstacle avoidance, and pursuit. However, a major challenge for
using such processors on robotic platforms is the reality gap between
simulation and the real world. In this study, we present for the very first
time a fully embedded application of the Loihi neuromorphic chip prototype in a
flying robot. A spiking neural network (SNN) was evolved to compute the thrust
command based on the divergence of the ventral optic flow field to perform
autonomous landing. Evolution was performed in a Python-based simulator using
the PySNN library. The resulting network architecture consists of only 35
neurons distributed among 3 layers. Quantitative analysis between simulation
and Loihi reveals a root-mean-square error of the thrust setpoint as low as
0.005 g, along with a 99.8% matching of the spike sequences in the hidden
layer, and 99.7% in the output layer. The proposed approach successfully
bridges the reality gap, offering important insights for future neuromorphic
applications in robotics. Supplementary material is available at
https://mavlab.tudelft.nl/loihi/.
</p>
<a href="http://arxiv.org/abs/2011.00534" target="_blank">arXiv:2011.00534</a> [<a href="http://arxiv.org/pdf/2011.00534" target="_blank">pdf</a>]

<h2>Deep Diacritization: Efficient Hierarchical Recurrence for Improved Arabic Diacritization. (arXiv:2011.00538v1 [cs.CL])</h2>
<h3>Badr AlKhamissi, Muhammad N. ElNokrashy, Mohamed Gabr</h3>
<p>We propose a novel architecture for labelling character sequences that
achieves state-of-the-art results on the Tashkeela Arabic diacritization
benchmark. The core is a two-level recurrence hierarchy that operates on the
word and character levels separately---enabling faster training and inference
than comparable traditional models. A cross-level attention module further
connects the two, and opens the door for network interpretability. The task
module is a softmax classifier that enumerates valid combinations of
diacritics. This architecture can be extended with a recurrent decoder that
optionally accepts priors from partially diacritized text, which improves
results. We employ extra tricks such as sentence dropout and majority voting to
further boost the final result. Our best model achieves a WER of 5.34%,
outperforming the previous state-of-the-art with a 30.56% relative error
reduction.
</p>
<a href="http://arxiv.org/abs/2011.00538" target="_blank">arXiv:2011.00538</a> [<a href="http://arxiv.org/pdf/2011.00538" target="_blank">pdf</a>]

<h2>Unsupervised Intrusion Detection System for Unmanned Aerial Vehicle with Less Labeling Effort. (arXiv:2011.00540v1 [cs.CR])</h2>
<h3>Kyung Ho Park, Eunji Park, Huy Kang Kim</h3>
<p>Along with the importance of safety, an IDS has become a significant task in
the real world. Prior studies proposed various intrusion detection models for
the UAV. Past rule-based approaches provided a concrete baseline IDS model, and
the machine learning-based method achieved a precise intrusion detection
performance on the UAV with supervised learning models. However, previous
methods have room for improvement to be implemented in the real world. Prior
methods required a large labeling effort on the dataset, and the model could
not identify attacks that were not trained before. To jump over these hurdles,
we propose an IDS with unsupervised learning. As unsupervised learning does not
require labeling, our model let the practitioner not to label every type of
attack from the flight data. Moreover, the model can identify an abnormal
status of the UAV regardless of the type of attack. We trained an autoencoder
with the benign flight data only and checked the model provides a different
reconstruction loss at the benign flight and the flight under attack. We
discovered that the model produces much higher reconstruction loss with the
flight under attack than the benign flight; thus, this reconstruction loss can
be utilized to recognize an intrusion to the UAV. With consideration of the
computation overhead and the detection performance in the wild, we expect our
model can be a concrete and practical baseline IDS on the UAV.
</p>
<a href="http://arxiv.org/abs/2011.00540" target="_blank">arXiv:2011.00540</a> [<a href="http://arxiv.org/pdf/2011.00540" target="_blank">pdf</a>]

<h2>Semantic coordinates analysis reveals language changes in the AI field. (arXiv:2011.00543v1 [cs.CL])</h2>
<h3>Zining Zhu, Yang Xu, Frank Rudzicz</h3>
<p>Semantic shifts can reflect changes in beliefs across hundreds of years, but
it is less clear whether trends in fast-changing communities across a short
time can be detected. We propose semantic coordinates analysis, a method based
on semantic shifts, that reveals changes in language within publications of a
field (we use AI as example) across a short time span. We use GloVe-style
probability ratios to quantify the shifting directions and extents from
multiple viewpoints. We show that semantic coordinates analysis can detect
shifts echoing changes of research interests (e.g., "deep" shifted further from
"rigorous" to "neural"), and developments of research activities (e,g.,
"collaboration" contains less "competition" than "collaboration"), based on
publications spanning as short as 10 years.
</p>
<a href="http://arxiv.org/abs/2011.00543" target="_blank">arXiv:2011.00543</a> [<a href="http://arxiv.org/pdf/2011.00543" target="_blank">pdf</a>]

<h2>U-rank: Utility-oriented Learning to Rank with Implicit Feedback. (arXiv:2011.00550v1 [cs.IR])</h2>
<h3>Xinyi Dai, Jiawei Hou, Qing Liu, Yunjia Xi, Ruiming Tang, Weinan Zhang, Xiuqiang He, Jun Wang, Yong Yu</h3>
<p>Learning to rank with implicit feedback is one of the most important tasks in
many real-world information systems where the objective is some specific
utility, e.g., clicks and revenue. However, we point out that existing methods
based on probabilistic ranking principle do not necessarily achieve the highest
utility. To this end, we propose a novel ranking framework called U-rank that
directly optimizes the expected utility of the ranking list. With a
position-aware deep click-through rate prediction model, we address the
attention bias considering both query-level and item-level features. Due to the
item-specific attention bias modeling, the optimization for expected utility
corresponds to a maximum weight matching on the item-position bipartite graph.
We base the optimization of this objective in an efficient Lambdaloss
framework, which is supported by both theoretical and empirical analysis. We
conduct extensive experiments for both web search and recommender systems over
three benchmark datasets and two proprietary datasets, where the performance
gain of U-rank over state-of-the-arts is demonstrated. Moreover, our proposed
U-rank has been deployed on a large-scale commercial recommender and a large
improvement over the production baseline has been observed in an online A/B
testing.
</p>
<a href="http://arxiv.org/abs/2011.00550" target="_blank">arXiv:2011.00550</a> [<a href="http://arxiv.org/pdf/2011.00550" target="_blank">pdf</a>]

<h2>Building a Balanced k-d Tree with MapReduce. (arXiv:1512.06389v7 [cs.DS] UPDATED)</h2>
<h3>Russell A. Brown</h3>
<p>The original description of the k-d tree recognized that rebalancing
techniques, such as are used to build an AVL tree or a red-black tree, are not
applicable to a k-d tree. Hence, in order to build a balanced k-d tree, it is
necessary to obtain all of the data prior to building the tree then to build
the tree via recursive subdivision of the data. One algorithm for building a
balanced k-d tree finds the median of the data for each recursive subdivision
of the data and builds the tree in O(n log n) time. A new algorithm builds a
balanced k-d tree by presorting the data in each of k dimensions prior to
building the tree, then preserves the order of the k presorts during recursive
subdivision of the data and builds the tree in O(kn log n) time. This new
algorithm is amenable to execution via MapReduce and permits building and
searching a k-d tree that is represented as a distributed graph.
</p>
<a href="http://arxiv.org/abs/1512.06389" target="_blank">arXiv:1512.06389</a> [<a href="http://arxiv.org/pdf/1512.06389" target="_blank">pdf</a>]

<h2>An Empirical Analysis of Feature Engineering for Predictive Modeling. (arXiv:1701.07852v2 [cs.LG] UPDATED)</h2>
<h3>Jeff Heaton</h3>
<p>Machine learning models, such as neural networks, decision trees, random
forests, and gradient boosting machines, accept a feature vector, and provide a
prediction. These models learn in a supervised fashion where we provide feature
vectors mapped to the expected output. It is common practice to engineer new
features from the provided feature set. Such engineered features will either
augment or replace portions of the existing feature vector. These engineered
features are essentially calculated fields based on the values of the other
features.

Engineering such features is primarily a manual, time-consuming task.
Additionally, each type of model will respond differently to different kinds of
engineered features. This paper reports empirical research to demonstrate what
kinds of engineered features are best suited to various machine learning model
types. We provide this recommendation by generating several datasets that we
designed to benefit from a particular type of engineered feature. The
experiment demonstrates to what degree the machine learning model can
synthesize the needed feature on its own. If a model can synthesize a planned
feature, it is not necessary to provide that feature. The research demonstrated
that the studied models do indeed perform differently with various types of
engineered features.
</p>
<a href="http://arxiv.org/abs/1701.07852" target="_blank">arXiv:1701.07852</a> [<a href="http://arxiv.org/pdf/1701.07852" target="_blank">pdf</a>]

<h2>A General Framework for Bandit Problems Beyond Cumulative Objectives. (arXiv:1806.01380v2 [stat.ML] UPDATED)</h2>
<h3>Asaf Cassel (1), Shie Mannor (2), Assaf Zeevi (3) ((1) School of Computer Science, Tel Aviv University, (2) Faculty of Electrical Engineering, Technion, Israel Institute of Technology, (3) Graudate School of Business, Columbia University)</h3>
<p>The stochastic multi-armed bandit (MAB) problem is a common model for
sequential decision problems. In the standard setup, a decision maker has to
choose at every instant between several competing arms, each of them provides a
scalar random variable, referred to as a "reward." Nearly all research on this
topic considers the total cumulative reward as the criterion of interest. This
work focuses on other natural objectives that cannot be cast as a sum over
rewards, but rather more involved functions of the reward stream. Unlike the
case of cumulative criteria, in the problems we study here the oracle policy,
that knows the problem parameters a priori and is used to "center" the regret,
is not trivial. We provide a systematic approach to such problems, and derive
general conditions under which the oracle policy is sufficiently tractable to
facilitate the design of optimism-based (upper confidence bound) learning
policies. These conditions elucidate an interesting interplay between the arm
reward distributions and the performance metric. Our main findings are
illustrated for several commonly used objectives such as conditional
value-at-risk, mean-variance trade-offs, Sharpe-ratio, and more.
</p>
<a href="http://arxiv.org/abs/1806.01380" target="_blank">arXiv:1806.01380</a> [<a href="http://arxiv.org/pdf/1806.01380" target="_blank">pdf</a>]

<h2>Risk Bounds for Unsupervised Cross-Domain Mapping with IPMs. (arXiv:1807.08501v4 [cs.LG] UPDATED)</h2>
<h3>Tomer Galanti, Sagie Benaim, Lior Wolf</h3>
<p>The recent empirical success of unsupervised cross-domain mapping algorithms,
between two domains that share common characteristics, is not well-supported by
theoretical justifications. This lacuna is especially troubling, given the
clear ambiguity in such mappings.

We work with adversarial training methods based on IPMs and derive a novel
risk bound, which upper bounds the risk between the learned mapping $h$ and the
target mapping $y$, by a sum of three terms: (i) the risk between $h$ and the
most distant alternative mapping that was learned by the same cross-domain
mapping algorithm, (ii) the minimal discrepancy between the target domain and
the domain obtained by applying a hypothesis $h^*$ on the samples of the source
domain, where $h^*$ is a hypothesis selectable by the same algorithm. The bound
is directly related to Occam's razor and encourages the selection of the
minimal architecture that supports a small mapping discrepancy and (iii) an
approximation error term that decreases as the complexity of the class of
discriminators increases and is empirically shown to be small.

The bound leads to multiple algorithmic consequences, including a method for
hyperparameters selection and for early stopping in cross-domain mapping GANs.
We also demonstrate a novel capability for unsupervised learning of estimating
confidence in the mapping of every specific sample.
</p>
<a href="http://arxiv.org/abs/1807.08501" target="_blank">arXiv:1807.08501</a> [<a href="http://arxiv.org/pdf/1807.08501" target="_blank">pdf</a>]

<h2>On The Chain Rule Optimal Transport Distance. (arXiv:1812.08113v3 [cs.LG] UPDATED)</h2>
<h3>Frank Nielsen, Ke Sun</h3>
<p>We define a novel class of distances between statistical multivariate
distributions by modeling an optimal transport problem on their marginals with
respect to a ground distance defined on their conditionals. These new distances
are metrics whenever the ground distance between the marginals is a metric,
generalize both the Wasserstein distances between discrete measures and a
recently introduced metric distance between statistical mixtures, and provide
an upper bound for jointly convex distances between statistical mixtures. By
entropic regularization of the optimal transport, we obtain a fast
differentiable Sinkhorn-type distance. We experimentally evaluate our new
family of distances by quantifying the upper bounds of several jointly convex
distances between statistical mixtures, and by proposing a novel efficient
method to learn Gaussian mixture models (GMMs) by simplifying kernel density
estimators with respect to our distance. Our GMM learning technique
experimentally improves significantly over the EM implementation of {\tt
sklearn} on the {\tt MNIST} and {\tt Fashion MNIST} datasets.
</p>
<a href="http://arxiv.org/abs/1812.08113" target="_blank">arXiv:1812.08113</a> [<a href="http://arxiv.org/pdf/1812.08113" target="_blank">pdf</a>]

<h2>End-to-End Classification of Reverberant Rooms using DNNs. (arXiv:1812.09324v6 [eess.AS] UPDATED)</h2>
<h3>Constantinos Papayiannis, Christine Evers, Patrick A. Naylor</h3>
<p>Reverberation is present in our workplaces, our homes, concert halls and
theatres. This paper investigates how deep learning can use the effect of
reverberation on speech to classify a recording in terms of the room in which
it was recorded. Existing approaches in the literature rely on domain expertise
to manually select acoustic parameters as inputs to classifiers. Estimation of
these parameters from reverberant speech is adversely affected by estimation
errors, impacting the classification accuracy. In order to overcome the
limitations of previously proposed methods, this paper shows how DNNs can
perform the classification by operating directly on reverberant speech spectra
and a CRNN with an attention-mechanism is proposed for the task. The
relationship is investigated between the reverberant speech representations
learned by the DNNs and acoustic parameters. For evaluation, AIRs are used from
the ACE-challenge dataset that were measured in 7 real rooms. The
classification accuracy of the CRNN classifier in the experiments is 78% when
using 5 hours of training data and 90% when using 10 hours.
</p>
<a href="http://arxiv.org/abs/1812.09324" target="_blank">arXiv:1812.09324</a> [<a href="http://arxiv.org/pdf/1812.09324" target="_blank">pdf</a>]

<h2>Learning-Based Synthesis of Safety Controllers. (arXiv:1901.06801v4 [cs.GT] UPDATED)</h2>
<h3>Daniel Neider, Oliver Markgraf</h3>
<p>We propose a machine learning framework to synthesize reactive controllers
for systems whose interactions with their adversarial environment are modeled
by infinite-duration, two-player games over (potentially) infinite graphs. Our
framework targets safety games with infinitely many vertices, but it is also
applicable to safety games over finite graphs whose size is too prohibitive for
conventional synthesis techniques. The learning takes place in a feedback loop
between a teacher component, which can reason symbolically about the safety
game, and a learning algorithm, which successively learns an overapproximation
of the winning region from various kinds of examples provided by the teacher.
We develop a novel decision tree learning algorithm for this setting and show
that our algorithm is guaranteed to converge to a reactive safety controller if
a suitable overapproximation of the winning region can be expressed as a
decision tree. Finally, we empirically compare the performance of a prototype
implementation to existing approaches, which are based on constraint solving
and automata learning, respectively.
</p>
<a href="http://arxiv.org/abs/1901.06801" target="_blank">arXiv:1901.06801</a> [<a href="http://arxiv.org/pdf/1901.06801" target="_blank">pdf</a>]

<h2>Forecasting Time-to-Collision from Monocular Video: Feasibility, Dataset, and Challenges. (arXiv:1903.09102v3 [cs.RO] UPDATED)</h2>
<h3>Aashi Manglik, Xinshuo Weng, Eshed Ohn-Bar, Kris M. Kitani</h3>
<p>We explore the possibility of using a single monocular camera to forecast the
time to collision between a suitcase-shaped robot being pushed by its user and
other nearby pedestrians. We develop a purely image-based deep learning
approach that directly estimates the time to collision without the need of
relying on explicit geometric depth estimates or velocity information to
predict future collisions. While previous work has focused on detecting
immediate collision in the context of navigating Unmanned Aerial Vehicles, the
detection was limited to a binary variable (i.e., collision or no collision).
We propose a more fine-grained approach to collision forecasting by predicting
the exact time to collision in terms of milliseconds, which is more helpful for
collision avoidance in the context of dynamic path planning. To evaluate our
method, we have collected a novel dataset of over 13,000 indoor video segments
each showing a trajectory of at least one person ending in a close proximity (a
near collision) with the camera mounted on a mobile suitcase-shaped platform.
Using this dataset, we do extensive experimentation on different temporal
windows as input using an exhaustive list of state-of-the-art convolutional
neural networks (CNNs). Our results show that our proposed multi-stream CNN is
the best model for predicting time to near-collision. The average prediction
error of our time to near collision is 0.75 seconds across the test videos.
</p>
<a href="http://arxiv.org/abs/1903.09102" target="_blank">arXiv:1903.09102</a> [<a href="http://arxiv.org/pdf/1903.09102" target="_blank">pdf</a>]

<h2>Learning Decentralized Controllers for Robot Swarms with Graph Neural Networks. (arXiv:1903.10527v3 [cs.RO] UPDATED)</h2>
<h3>Ekaterina Tolstaya, Fernando Gama, James Paulos, George Pappas, Vijay Kumar, Alejandro Ribeiro</h3>
<p>We consider the problem of finding distributed controllers for large networks
of mobile robots with interacting dynamics and sparsely available
communications. Our approach is to learn local controllers that require only
local information and communications at test time by imitating the policy of
centralized controllers using global information at training time. By extending
aggregation graph neural networks to time varying signals and time varying
network support, we learn a single common local controller which exploits
information from distant teammates using only local communication interchanges.
We apply this approach to the problem of flocking to demonstrate performance on
communication graphs that change as the robots move. We examine how a
decreasing communication radius and faster velocities increase the value of
multi-hop information.
</p>
<a href="http://arxiv.org/abs/1903.10527" target="_blank">arXiv:1903.10527</a> [<a href="http://arxiv.org/pdf/1903.10527" target="_blank">pdf</a>]

<h2>Energy-Based Continuous Inverse Optimal Control. (arXiv:1904.05453v4 [cs.LG] UPDATED)</h2>
<h3>Yifei Xu, Jianwen Xie, Tianyang Zhao, Chris Baker, Yibiao Zhao, Ying Nian Wu</h3>
<p>The problem of continuous optimal control (over finite time horizon) is to
minimize a given cost function over the sequence of continuous control
variables. The problem of continuous inverse optimal control is to learn the
unknown cost function from expert demonstrations. In this article, we study
this fundamental problem in the framework of energy-based model, where the
observed expert trajectories are assumed to be random samples from a
probability density function defined as the exponential of the negative cost
function up to a normalizing constant. The parameters of the cost function are
learned by maximum likelihood via an "analysis by synthesis" scheme, which
iterates the following two steps: (1) Synthesis step: sample the synthesized
trajectories from the current probability density using the Langevin dynamics
via back-propagation through time. (2) Analysis step: update the model
parameters based on the statistical difference between the synthesized
trajectories and the observed trajectories. Given the fact that an efficient
optimization algorithm is usually available for an optimal control problem, we
also consider a convenient approximation of the above learning method, where we
replace the sampling in the synthesis step by optimization. To make the
sampling or optimization more efficient, we propose to train the energy-based
model simultaneously with a top-down trajectory generator via cooperative
learning, where the trajectory generator is used to fast initialize the
sampling step or optimization step of the energy-based model. We demonstrate
the proposed methods on autonomous driving tasks, and show that it can learn
suitable cost functions for optimal control.
</p>
<a href="http://arxiv.org/abs/1904.05453" target="_blank">arXiv:1904.05453</a> [<a href="http://arxiv.org/pdf/1904.05453" target="_blank">pdf</a>]

<h2>ATRW: A Benchmark for Amur Tiger Re-identification in the Wild. (arXiv:1906.05586v5 [cs.CV] UPDATED)</h2>
<h3>Shuyuan Li, Jianguo Li, Hanlin Tang, Rui Qian, Weiyao Lin</h3>
<p>Monitoring the population and movements of endangered species is an important
task to wildlife conversation. Traditional tagging methods do not scale to
large populations, while applying computer vision methods to camera sensor data
requires re-identification (re-ID) algorithms to obtain accurate counts and
moving trajectory of wildlife. However, existing re-ID methods are largely
targeted at persons and cars, which have limited pose variations and
constrained capture environments. This paper tries to fill the gap by
introducing a novel large-scale dataset, the Amur Tiger Re-identification in
the Wild (ATRW) dataset. ATRW contains over 8,000 video clips from 92 Amur
tigers, with bounding box, pose keypoint, and tiger identity annotations. In
contrast to typical re-ID datasets, the tigers are captured in a diverse set of
unconstrained poses and lighting conditions. We demonstrate with a set of
baseline algorithms that ATRW is a challenging dataset for re-ID. Lastly, we
propose a novel method for tiger re-identification, which introduces precise
pose parts modeling in deep neural networks to handle large pose variation of
tigers, and reaches notable performance improvement over existing re-ID
methods. The dataset is public available at https://cvwc2019.github.io/ .
</p>
<a href="http://arxiv.org/abs/1906.05586" target="_blank">arXiv:1906.05586</a> [<a href="http://arxiv.org/pdf/1906.05586" target="_blank">pdf</a>]

<h2>Optimizing Ensemble Weights and Hyperparameters of Machine Learning Models for Regression Problems. (arXiv:1908.05287v6 [stat.ML] UPDATED)</h2>
<h3>Mohsen Shahhosseini, Guiping Hu, Hieu Pham</h3>
<p>Aggregating multiple learners through an ensemble of models aim to make
better predictions by capturing the underlying distribution of the data more
accurately. Different ensembling methods, such as bagging, boosting, and
stacking/blending, have been studied and adopted extensively in research and
practice. While bagging and boosting focus more on reducing variance and bias,
respectively, stacking approaches target both by finding the optimal way to
combine base learners. In stacking with the weighted average, ensembles are
created from weighted averages of multiple base learners. It is known that
tuning hyperparameters of each base learner inside the ensemble weight
optimization process can produce better performing ensembles. To this end, an
optimization-based nested algorithm that considers tuning hyperparameters as
well as finding the optimal weights to combine ensembles (Generalized Weighted
Ensemble with Internally Tuned Hyperparameters (GEM-ITH)) is designed. Besides,
Bayesian search was used to speed-up the optimizing process, and a heuristic
was implemented to generate diverse and well-performing base learners. The
algorithm is shown to be generalizable to real data sets through analyses with
ten publicly available data sets.
</p>
<a href="http://arxiv.org/abs/1908.05287" target="_blank">arXiv:1908.05287</a> [<a href="http://arxiv.org/pdf/1908.05287" target="_blank">pdf</a>]

<h2>Binocular Rivalry Oriented Predictive Auto-Encoding Network for Blind Stereoscopic Image Quality Measurement. (arXiv:1909.01738v3 [cs.MM] UPDATED)</h2>
<h3>Jiahua Xu, Wei Zhou, Zhibo Chen, Suiyi Ling, Patrick Le Callet</h3>
<p>Stereoscopic image quality measurement (SIQM) has become increasingly
important for guiding stereo image processing and commutation systems due to
the widespread usage of 3D contents. Compared with conventional methods which
are relied on hand-crafted features, deep learning oriented measurements have
achieved remarkable performance in recent years. However, most existing deep
SIQM evaluators are not specifically built for stereoscopic contents and
consider little prior domain knowledge of the 3D human visual system (HVS) in
network design. In this paper, we develop a Predictive Auto-encoDing Network
(PAD-Net) for blind/No-Reference stereoscopic image quality measurement. In the
first stage, inspired by the predictive coding theory that the cognition system
tries to match bottom-up visual signal with top-down predictions, we adopt the
encoder-decoder architecture to reconstruct the distorted inputs. Besides,
motivated by the binocular rivalry phenomenon, we leverage the likelihood and
prior maps generated from the predictive coding process in the Siamese
framework for assisting SIQM. In the second stage, quality regression network
is applied to the fusion image for acquiring the perceptual quality prediction.
The performance of PAD-Net has been extensively evaluated on three benchmark
databases and the superiority has been well validated on both symmetrically and
asymmetrically distorted stereoscopic images under various distortion types.
</p>
<a href="http://arxiv.org/abs/1909.01738" target="_blank">arXiv:1909.01738</a> [<a href="http://arxiv.org/pdf/1909.01738" target="_blank">pdf</a>]

<h2>Neural Correction Model for Open-Domain Named Entity Recognition. (arXiv:1909.06058v2 [cs.CL] UPDATED)</h2>
<h3>Mengdi Zhu, Zheye Deng, Wenhan Xiong, Mo Yu, Ming Zhang, William Yang Wang</h3>
<p>Named Entity Recognition (NER) plays an important role in a wide range of
natural language processing tasks, such as relation extraction, question
answering, etc. However, previous studies on NER are limited to particular
genres, using small manually-annotated or large but low-quality datasets.
Meanwhile, previous datasets for open-domain NER, built using distant
supervision, suffer from low precision, recall and ratio of annotated tokens
(RAT). In this work, to address the low precision and recall problems, we first
utilize DBpedia as the source of distant supervision to annotate abstracts from
Wikipedia and design a neural correction model trained with a human-annotated
NER dataset, DocRED, to correct the false entity labels. In this way, we build
a large and high-quality dataset called AnchorNER and then train various models
with it. To address the low RAT problem of previous datasets, we introduce a
multi-task learning method to exploit the context information. We evaluate our
methods on five NER datasets and our experimental results show that models
trained with AnchorNER and our multi-task learning method obtain
state-of-the-art performances in the open-domain setting.
</p>
<a href="http://arxiv.org/abs/1909.06058" target="_blank">arXiv:1909.06058</a> [<a href="http://arxiv.org/pdf/1909.06058" target="_blank">pdf</a>]

<h2>Learning ASR-Robust Contextualized Embeddings for Spoken Language Understanding. (arXiv:1909.10861v2 [cs.CL] UPDATED)</h2>
<h3>Chao-Wei Huang, Yun-Nung Chen</h3>
<p>Employing pre-trained language models (LM) to extract contextualized word
representations has achieved state-of-the-art performance on various NLP tasks.
However, applying this technique to noisy transcripts generated by automatic
speech recognizer (ASR) is concerned. Therefore, this paper focuses on making
contextualized representations more ASR-robust. We propose a novel
confusion-aware fine-tuning method to mitigate the impact of ASR errors to
pre-trained LMs. Specifically, we fine-tune LMs to produce similar
representations for acoustically confusable words that are obtained from word
confusion networks (WCNs) produced by ASR. Experiments on the benchmark ATIS
dataset show that the proposed method significantly improves the performance of
spoken language understanding when performing on ASR transcripts. Our source
code is available at https://github.com/MiuLab/SpokenVec
</p>
<a href="http://arxiv.org/abs/1909.10861" target="_blank">arXiv:1909.10861</a> [<a href="http://arxiv.org/pdf/1909.10861" target="_blank">pdf</a>]

<h2>Distributed Attack-Robust Submodular Maximization for Multi-Robot Planning. (arXiv:1910.01208v3 [cs.RO] UPDATED)</h2>
<h3>Lifeng Zhou, Vasileios Tzoumas, George J. Pappas, Pratap Tokekar</h3>
<p>In this paper, we design algorithms to protect swarm-robotics applications
against attacks that result in robot removals. We focus on applications
requiring the robots to jointly select actions, e.g., which trajectory to
follow, among a set of available ones. Such applications are central in
large-scale robotic applications, such as multi-robot motion planning for
target tracking. But the current attack-robust algorithms are centralized. In
this paper, we propose a general-purpose distributed algorithm towards robust
optimization at scale, with local communications only. We name it Distributed
Robust Maximization (DRM). DRM proposes a divide-and-conquer approach that
distributively partitions the problem among cliques of robots. Then, the
cliques optimize in parallel, independently of each other. We prove DRM
achieves a close-to-optimal performance. We demonstrate DRM's performance in
both Gazebo and MATLAB simulations, in scenarios of active target tracking with
swarms of robots. In the simulations, DRM achieves computational speed-ups,
being 3-4 orders faster than the centralized algorithms; yet, it nearly matches
the tracking performance of the centralized counterparts. However, DRM
overestimates the number of attacks in each clique. To amend this
conservativeness of DRM, in this paper we also introduce an Improved
Distributed Robust Maximization (IDRM) algorithm. IDRM infers the number of
attacks in each clique less conservatively than DRM by leveraging 3-hop
neighboring communications. We verify IDRM improves DRM's performance in
simulations.
</p>
<a href="http://arxiv.org/abs/1910.01208" target="_blank">arXiv:1910.01208</a> [<a href="http://arxiv.org/pdf/1910.01208" target="_blank">pdf</a>]

<h2>Observer Dependent Lossy Image Compression. (arXiv:1910.03472v2 [eess.IV] UPDATED)</h2>
<h3>Maurice Weber, Cedric Renggli, Helmut Grabner, Ce Zhang</h3>
<p>Deep neural networks have recently advanced the state-of-the-art in image
compression and surpassed many traditional compression algorithms. The training
of such networks involves carefully trading off entropy of the latent
representation against reconstruction quality. The term quality crucially
depends on the observer of the images which, in the vast majority of
literature, is assumed to be human. In this paper, we aim to go beyond this
notion of compression quality and look at human visual perception and image
classification simultaneously. To that end, we use a family of loss functions
that allows to optimize deep image compression depending on the observer and to
interpolate between human perceived visual quality and classification accuracy,
enabling a more unified view on image compression. Our extensive experiments
show that using perceptual loss functions to train a compression system
preserves classification accuracy much better than traditional codecs such as
BPG without requiring retraining of classifiers on compressed images. For
example, compressing ImageNet to 0.25 bpp reduces Inception-ResNet
classification accuracy by only 2%. At the same time, when using a human
friendly loss function, the same compression system achieves competitive
performance in terms of MS-SSIM. By combining these two objective functions, we
show that there is a pronounced trade-off in compression quality between the
human visual system and classification accuracy.
</p>
<a href="http://arxiv.org/abs/1910.03472" target="_blank">arXiv:1910.03472</a> [<a href="http://arxiv.org/pdf/1910.03472" target="_blank">pdf</a>]

<h2>Learning event representations for temporal segmentation of image sequences by dynamic graph embedding. (arXiv:1910.03483v2 [cs.LG] UPDATED)</h2>
<h3>Mariella Dimiccoli, Herwig Wendt</h3>
<p>Recently, self-supervised learning has proved to be effective to learn
representations of events suitable for temporal segmentation in image
sequences, where events are understood as sets of temporally adjacent images
that are semantically perceived as a whole. However, although this approach
does not require expensive manual annotations, it is data hungry and suffers
from domain adaptation problems. As an alternative, in this work, we propose a
novel approach for learning event representations named Dynamic Graph Embedding
(DGE). The assumption underlying our model is that a sequence of images can be
represented by a graph that encodes both semantic and temporal similarity. The
key novelty of DGE is to learn jointly the graph and its graph embedding. At
its core, DGE works by iterating over two steps: 1) updating the graph
representing the semantic and temporal similarity of the data based on the
current data representation, and 2) updating the data representation to take
into account the current data graph structure. The main advantage of DGE over
state-of-the-art self-supervised approaches is that it does not require any
training set, but instead learns iteratively from the data itself a
low-dimensional embedding that reflects their temporal and semantic similarity.
Experimental results on two benchmark datasets of real image sequences captured
at regular time intervals demonstrate that the proposed DGE leads to event
representations effective for temporal segmentation. In particular, it achieves
robust temporal segmentation on the EDUBSeg and EDUBSeg-Desc benchmark
datasets, outperforming the state of the art. Additional experiments on two
Human Motion Segmentation benchmark datasets demonstrate the generalization
capabilities of the proposed DGE.
</p>
<a href="http://arxiv.org/abs/1910.03483" target="_blank">arXiv:1910.03483</a> [<a href="http://arxiv.org/pdf/1910.03483" target="_blank">pdf</a>]

<h2>Does Gender Matter? Towards Fairness in Dialogue Systems. (arXiv:1910.10486v3 [cs.CL] UPDATED)</h2>
<h3>Haochen Liu, Jamell Dacon, Wenqi Fan, Hui Liu, Zitao Liu, Jiliang Tang</h3>
<p>Recently there are increasing concerns about the fairness of Artificial
Intelligence (AI) in real-world applications such as computer vision and
recommendations. For example, recognition algorithms in computer vision are
unfair to black people such as poorly detecting their faces and inappropriately
identifying them as "gorillas". As one crucial application of AI, dialogue
systems have been extensively applied in our society. They are usually built
with real human conversational data; thus they could inherit some fairness
issues which are held in the real world. However, the fairness of dialogue
systems has not been well investigated. In this paper, we perform a pioneering
study about the fairness issues in dialogue systems. In particular, we
construct a benchmark dataset and propose quantitative measures to understand
fairness in dialogue models. Our studies demonstrate that popular dialogue
models show significant prejudice towards different genders and races. Besides,
to mitigate the bias in dialogue systems, we propose two simple but effective
debiasing methods. Experiments show that our methods can reduce the bias in
dialogue systems significantly. The dataset and the implementation are released
to foster fairness research in dialogue systems.
</p>
<a href="http://arxiv.org/abs/1910.10486" target="_blank">arXiv:1910.10486</a> [<a href="http://arxiv.org/pdf/1910.10486" target="_blank">pdf</a>]

<h2>Autoencoding with a Classifier System. (arXiv:1910.10579v6 [cs.NE] UPDATED)</h2>
<h3>Richard J. Preen, Stewart W. Wilson, Larry Bull</h3>
<p>Autoencoders enable data dimensionality reduction and are a key component of
many learning systems. This article explores the use of a learning classifier
system to perform autoencoding. Initial results using a neural network
representation in the classifiers suggest that a classifier system can be an
effective approach to data reduction. The approach adaptively subdivides the
input domain into local approximations---in effect, small autoencoders---that
together cover the problem space. By allowing the number of neurons in the
autoencoders to evolve, local solutions of different complexity emerge.
Self-adaptative mutation tunes the rate of gradient descent in each layer,
reducing the parameter optimisation task.
</p>
<a href="http://arxiv.org/abs/1910.10579" target="_blank">arXiv:1910.10579</a> [<a href="http://arxiv.org/pdf/1910.10579" target="_blank">pdf</a>]

<h2>BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement Learning. (arXiv:1910.12179v4 [cs.LG] UPDATED)</h2>
<h3>Xinyue Chen, Zijian Zhou, Zheng Wang, Che Wang, Yanqiu Wu, Keith Ross</h3>
<p>There has recently been a surge in research in batch Deep Reinforcement
Learning (DRL), which aims for learning a high-performing policy from a given
dataset without additional interactions with the environment. We propose a new
algorithm, Best-Action Imitation Learning (BAIL), which strives for both
simplicity and performance. BAIL learns a V function, uses the V function to
select actions it believes to be high-performing, and then uses those actions
to train a policy network using imitation learning. For the MuJoCo benchmark,
we provide a comprehensive experimental study of BAIL, comparing its
performance to four other batch Q-learning and imitation-learning schemes for a
large variety of batch datasets. Our experiments show that BAIL's performance
is much higher than the other schemes, and is also computationally much faster
than the batch Q-learning schemes.
</p>
<a href="http://arxiv.org/abs/1910.12179" target="_blank">arXiv:1910.12179</a> [<a href="http://arxiv.org/pdf/1910.12179" target="_blank">pdf</a>]

<h2>IPGuard: Protecting Intellectual Property of Deep Neural Networks via Fingerprinting the Classification Boundary. (arXiv:1910.12903v5 [cs.CR] UPDATED)</h2>
<h3>Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong</h3>
<p>A deep neural network (DNN) classifier represents a model owner's
intellectual property as training a DNN classifier often requires lots of
resource. Watermarking was recently proposed to protect the intellectual
property of DNN classifiers. However, watermarking suffers from a key
limitation: it sacrifices the utility/accuracy of the model owner's classifier
because it tampers the classifier's training or fine-tuning process. In this
work, we propose IPGuard, the first method to protect intellectual property of
DNN classifiers that provably incurs no accuracy loss for the classifiers. Our
key observation is that a DNN classifier can be uniquely represented by its
classification boundary. Based on this observation, IPGuard extracts some data
points near the classification boundary of the model owner's classifier and
uses them to fingerprint the classifier. A DNN classifier is said to be a
pirated version of the model owner's classifier if they predict the same labels
for most fingerprinting data points. IPGuard is qualitatively different from
watermarking. Specifically, IPGuard extracts fingerprinting data points near
the classification boundary of a classifier that is already trained, while
watermarking embeds watermarks into a classifier during its training or
fine-tuning process. We extensively evaluate IPGuard on CIFAR-10, CIFAR-100,
and ImageNet datasets. Our results show that IPGuard can robustly identify
post-processed versions of the model owner's classifier as pirated versions of
the classifier, and IPGuard can identify classifiers, which are not the model
owner's classifier nor its post-processed versions, as non-pirated versions of
the classifier.
</p>
<a href="http://arxiv.org/abs/1910.12903" target="_blank">arXiv:1910.12903</a> [<a href="http://arxiv.org/pdf/1910.12903" target="_blank">pdf</a>]

<h2>Adversarial Learning on the Latent Space for Diverse Dialog Generation. (arXiv:1911.03817v2 [cs.CL] UPDATED)</h2>
<h3>Kashif Khan, Gaurav Sahu, Vikash Balasubramanian, Lili Mou, Olga Vechtomova</h3>
<p>Generating relevant/conditioned responses in dialog is challenging, and
requires not only proper modelling of context in the conversation, but also the
ability to generate fluent sentences during inference. In this paper, we
propose a two-step framework based on generative adversarial nets for
generating conditioned responses. Our model first learns meaningful
representations of sentences, and then uses a generator to \textit{match} the
query with the response distribution. Latent codes from the latter are then
used to generate responses. Both quantitative and qualitative evaluations show
that our model generates more fluent, relevant and diverse responses than the
existing state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/1911.03817" target="_blank">arXiv:1911.03817</a> [<a href="http://arxiv.org/pdf/1911.03817" target="_blank">pdf</a>]

<h2>Provably Convergent Two-Timescale Off-Policy Actor-Critic with Function Approximation. (arXiv:1911.04384v8 [cs.LG] UPDATED)</h2>
<h3>Shangtong Zhang, Bo Liu, Hengshuai Yao, Shimon Whiteson</h3>
<p>We present the first provably convergent two-timescale off-policy
actor-critic algorithm (COF-PAC) with function approximation. Key to COF-PAC is
the introduction of a new critic, the emphasis critic, which is trained via
Gradient Emphasis Learning (GEM), a novel combination of the key ideas of
Gradient Temporal Difference Learning and Emphatic Temporal Difference
Learning. With the help of the emphasis critic and the canonical value function
critic, we show convergence for COF-PAC, where the critics are linear and the
actor can be nonlinear.
</p>
<a href="http://arxiv.org/abs/1911.04384" target="_blank">arXiv:1911.04384</a> [<a href="http://arxiv.org/pdf/1911.04384" target="_blank">pdf</a>]

<h2>Semi-Relaxed Quantization with DropBits: Training Low-Bit Neural Networks via Bit-wise Regularization. (arXiv:1911.12990v2 [cs.CV] UPDATED)</h2>
<h3>Jung Hyun Lee, Jihun Yun, Sung Ju Hwang, Eunho Yang</h3>
<p>Network quantization, which aims to reduce the bit-lengths of the network
weights and activations, has emerged as one of the key ingredients to reduce
the size of neural networks for their deployments to resource-limited devices.
In order to overcome the nature of transforming continuous activations and
weights to discrete ones, recent study called Relaxed Quantization (RQ)
[Louizos et al. 2019] successfully employ the popular Gumbel-Softmax that
allows this transformation with efficient gradient-based optimization. However,
RQ with this Gumbel-Softmax relaxation still suffers from bias-variance
trade-off depending on the temperature parameter of Gumbel-Softmax. To resolve
the issue, we propose a novel method, Semi-Relaxed Quantization (SRQ) that uses
multi-class straight-through estimator to effectively reduce the bias and
variance, along with a new regularization technique, DropBits that replaces
dropout regularization to randomly drop the bits instead of neurons to further
reduce the bias of the multi-class straight-through estimator in SRQ. As a
natural extension of DropBits, we further introduce the way of learning
heterogeneous quantization levels to find proper bit-length for each layer
using DropBits. We experimentally validate our method on various benchmark
datasets and network architectures, and also support the quantized lottery
ticket hypothesis: learning heterogeneous quantization levels outperforms the
case using the same but fixed quantization levels from scratch.
</p>
<a href="http://arxiv.org/abs/1911.12990" target="_blank">arXiv:1911.12990</a> [<a href="http://arxiv.org/pdf/1911.12990" target="_blank">pdf</a>]

<h2>DoveNet: Deep Image Harmonization via Domain Verification. (arXiv:1911.13239v3 [cs.CV] UPDATED)</h2>
<h3>Wenyan Cong, Jianfu Zhang, Li Niu, Liu Liu, Zhixin Ling, Weiyuan Li, Liqing Zhang</h3>
<p>Image composition is an important operation in image processing, but the
inconsistency between foreground and background significantly degrades the
quality of composite image. Image harmonization, aiming to make the foreground
compatible with the background, is a promising yet challenging task. However,
the lack of high-quality publicly available dataset for image harmonization
greatly hinders the development of image harmonization techniques. In this
work, we contribute an image harmonization dataset iHarmony4 by generating
synthesized composite images based on COCO (resp., Adobe5k, Flickr, day2night)
dataset, leading to our HCOCO (resp., HAdobe5k, HFlickr, Hday2night)
sub-dataset. Moreover, we propose a new deep image harmonization method DoveNet
using a novel domain verification discriminator, with the insight that the
foreground needs to be translated to the same domain as background. Extensive
experiments on our constructed dataset demonstrate the effectiveness of our
proposed method. Our dataset and code are available at
https://github.com/bcmi/Image_Harmonization_Datasets.
</p>
<a href="http://arxiv.org/abs/1911.13239" target="_blank">arXiv:1911.13239</a> [<a href="http://arxiv.org/pdf/1911.13239" target="_blank">pdf</a>]

<h2>Training Object Detectors from Few Weakly-Labeled and Many Unlabeled Images. (arXiv:1912.00384v4 [cs.CV] UPDATED)</h2>
<h3>Zhaohui Yang, Miaojing Shi, Chao Xu, Vittorio Ferrari, Yannis Avrithis</h3>
<p>Weakly-supervised object detection attempts to limit the amount of
supervision by dispensing the need for bounding boxes, but still assumes
image-level labels on the entire training set. In this work, we study the
problem of training an object detector from one or few images with image-level
labels and a larger set of completely unlabeled images. This is an extreme case
of semi-supervised learning where the labeled data are not enough to bootstrap
the learning of a detector. Our solution is to train a weakly-supervised
student detector model from image-level pseudo-labels generated on the
unlabeled set by a teacher classifier model, bootstrapped by region-level
similarities to labeled images. Building upon the recent representative
weakly-supervised pipeline PCL, our method can use more unlabeled images to
achieve performance competitive or superior to many recent weakly-supervised
detection solutions.
</p>
<a href="http://arxiv.org/abs/1912.00384" target="_blank">arXiv:1912.00384</a> [<a href="http://arxiv.org/pdf/1912.00384" target="_blank">pdf</a>]

<h2>Learning Adversarial MDPs with Bandit Feedback and Unknown Transition. (arXiv:1912.01192v5 [cs.LG] UPDATED)</h2>
<h3>Chi Jin, Tiancheng Jin, Haipeng Luo, Suvrit Sra, Tiancheng Yu</h3>
<p>We consider the problem of learning in episodic finite-horizon Markov
decision processes with an unknown transition function, bandit feedback, and
adversarial losses. We propose an efficient algorithm that achieves
$\mathcal{\tilde{O}}(L|X|\sqrt{|A|T})$ regret with high probability, where $L$
is the horizon, $|X|$ is the number of states, $|A|$ is the number of actions,
and $T$ is the number of episodes. To the best of our knowledge, our algorithm
is the first to ensure $\mathcal{\tilde{O}}(\sqrt{T})$ regret in this
challenging setting; in fact it achieves the same regret bound as (Rosenberg &amp;
Mansour, 2019a) that considers an easier setting with full-information
feedback. Our key technical contributions are two-fold: a tighter confidence
set for the transition function, and an optimistic loss estimator that is
inversely weighted by an $\textit{upper occupancy bound}$.
</p>
<a href="http://arxiv.org/abs/1912.01192" target="_blank">arXiv:1912.01192</a> [<a href="http://arxiv.org/pdf/1912.01192" target="_blank">pdf</a>]

<h2>Reinforcement Learning-based Visual Navigation with Information-Theoretic Regularization. (arXiv:1912.04078v4 [cs.RO] UPDATED)</h2>
<h3>Qiaoyun Wu, Kai Xu, Jun Wang, Mingliang Xu, Xiaoxi Gong, Dinesh Manocha</h3>
<p>To enhance the cross-target and cross-scene generalization of target-driven
visual navigation based on deep reinforcement learning (RL), we introduce an
information-theoretic regularization term into the RL objective. The
regularization maximizes the mutual information between navigation actions and
visual observation transforms of an agent, thus promoting more informed
navigation decisions. This way, the agent models the action-observation
dynamics by learning a variational generative model. Based on the model, the
agent generates (imagines) the next observation from its current observation
and navigation target. This way, the agent learns to understand the causality
between navigation actions and the changes in its observations, which allows
the agent to predict the next action for navigation by comparing the current
and the imagined next observations. Cross-target and cross-scene evaluations on
the AI2-THOR framework show that our method attains at least a $10\%$
improvement of average success rate over some state-of-the-art models. We
further evaluate our model in two real-world settings: navigation in unseen
indoor scenes from a discrete Active Vision Dataset (AVD) and continuous
real-world environments with a TurtleBot.We demonstrate that our navigation
model is able to successfully achieve navigation tasks in these scenarios.
Videos and models can be found in the supplementary material.
</p>
<a href="http://arxiv.org/abs/1912.04078" target="_blank">arXiv:1912.04078</a> [<a href="http://arxiv.org/pdf/1912.04078" target="_blank">pdf</a>]

<h2>CAE-LO: LiDAR Odometry Leveraging Fully Unsupervised Convolutional Auto-Encoder for Interest Point Detection and Feature Description. (arXiv:2001.01354v3 [cs.CV] UPDATED)</h2>
<h3>Deyu Yin, Qian Zhang, Jingbin Liu, Xinlian Liang, Yunsheng Wang, Jyri Maanp&#xe4;&#xe4;, Hao Ma, Juha Hyypp&#xe4;, Ruizhi Chen</h3>
<p>As an important technology in 3D mapping, autonomous driving, and robot
navigation, LiDAR odometry is still a challenging task. Appropriate data
structure and unsupervised deep learning are the keys to achieve an easy
adjusted LiDAR odometry solution with high performance. Utilizing compact 2D
structured spherical ring projection model and voxel model which preserves the
original shape of input data, we propose a fully unsupervised Convolutional
Auto-Encoder based LiDAR Odometry (CAE-LO) that detects interest points from
spherical ring data using 2D CAE and extracts features from multi-resolution
voxel model using 3D CAE. We make several key contributions: 1) experiments
based on KITTI dataset show that our interest points can capture more local
details to improve the matching success rate on unstructured scenarios and our
features outperform state-of-the-art by more than 50% in matching inlier ratio;
2) besides, we also propose a keyframe selection method based on matching pairs
transferring, an odometry refinement method for keyframes based on extended
interest points from spherical rings, and a backward pose update method. The
odometry refinement experiments verify the proposed ideas' feasibility and
effectiveness.
</p>
<a href="http://arxiv.org/abs/2001.01354" target="_blank">arXiv:2001.01354</a> [<a href="http://arxiv.org/pdf/2001.01354" target="_blank">pdf</a>]

<h2>Sparse Weight Activation Training. (arXiv:2001.01969v3 [cs.LG] UPDATED)</h2>
<h3>Md Aamir Raihan, Tor M. Aamodt</h3>
<p>Neural network training is computationally and memory intensive. Sparse
training can reduce the burden on emerging hardware platforms designed to
accelerate sparse computations, but it can affect network convergence. In this
work, we propose a novel CNN training algorithm Sparse Weight Activation
Training (SWAT). SWAT is more computation and memory-efficient than
conventional training. SWAT modifies back-propagation based on the empirical
insight that convergence during training tends to be robust to the elimination
of (i) small magnitude weights during the forward pass and (ii) both small
magnitude weights and activations during the backward pass. We evaluate SWAT on
recent CNN architectures such as ResNet, VGG, DenseNet and WideResNet using
CIFAR-10, CIFAR-100 and ImageNet datasets. For ResNet-50 on ImageNet SWAT
reduces total floating-point operations (FLOPS) during training by 80%
resulting in a 3.3$\times$ training speedup when run on a simulated sparse
learning accelerator representative of emerging platforms while incurring only
1.63% reduction in validation accuracy. Moreover, SWAT reduces memory footprint
during the backward pass by 23% to 50% for activations and 50% to 90% for
weights.
</p>
<a href="http://arxiv.org/abs/2001.01969" target="_blank">arXiv:2001.01969</a> [<a href="http://arxiv.org/pdf/2001.01969" target="_blank">pdf</a>]

<h2>A Dip Into a Deep Well: Online Political Advertisements, Valence, and European Electoral Campaigning. (arXiv:2001.10622v2 [cs.CY] UPDATED)</h2>
<h3>Jukka Ruohonen</h3>
<p>Online political advertisements have become an important element in electoral
campaigning throughout the world. At the same time, concepts such as
disinformation and manipulation have emerged as a global concern. Although
these concepts are distinct from online political ads and data-driven electoral
campaigning, they tend to share a similar trait related to valence, the
intrinsic attractiveness or averseness of a message. Given this background, the
paper examines online political ads by using a dataset collected from Google's
transparency reports. The examination is framed to the mid-2019 situation in
Europe, including the European Parliament elections in particular. According to
the results based on sentiment analysis of the textual ads displayed via
Google's advertisement machinery, (i) most of the political ads have expressed
positive sentiments, although these vary greatly between (ii) European
countries as well as across (iii) European political parties. In addition to
these results, the paper contributes to the timely discussion about data-driven
electoral campaigning and its relation to politics and democracy.
</p>
<a href="http://arxiv.org/abs/2001.10622" target="_blank">arXiv:2001.10622</a> [<a href="http://arxiv.org/pdf/2001.10622" target="_blank">pdf</a>]

<h2>Bayesian Meta-Prior Learning Using Empirical Bayes. (arXiv:2002.01129v2 [cs.LG] UPDATED)</h2>
<h3>Sareh Nabi, Houssam Nassif, Joseph Hong, Hamed Mamani, Guido Imbens</h3>
<p>Adding domain knowledge to a learning system is known to improve results. In
multi-parameter Bayesian frameworks, such knowledge is incorporated as a prior.
On the other hand, various model parameters can have different learning rates
in real-world problems, especially with skewed data. Two often-faced challenges
in Operation Management and Management Science applications are the absence of
informative priors, and the inability to control parameter learning rates. In
this study, we propose a hierarchical Empirical Bayes approach that addresses
both challenges, and that can generalize to any Bayesian framework. Our method
learns empirical meta-priors from the data itself and uses them to decouple the
learning rates of first-order and second-order features (or any other given
feature grouping) in a Generalized Linear Model. As the first-order features
are likely to have a more pronounced effect on the outcome, focusing on
learning first-order weights first is likely to improve performance and
convergence time. Our Empirical Bayes method clamps features in each group
together and uses the deployed model's observed data to empirically compute a
hierarchical prior in hindsight. We report theoretical results for the
unbiasedness, strong consistency, and optimal frequentist cumulative regret
properties of our meta-prior variance estimator. We apply our method to a
standard supervised learning optimization problem, as well as an online
combinatorial optimization problem in a contextual bandit setting implemented
in an Amazon production system. Both during simulations and live experiments,
our method shows marked improvements, especially in cases of small traffic. Our
findings are promising, as optimizing over sparse data is often a challenge.
</p>
<a href="http://arxiv.org/abs/2002.01129" target="_blank">arXiv:2002.01129</a> [<a href="http://arxiv.org/pdf/2002.01129" target="_blank">pdf</a>]

<h2>Locally-Adaptive Nonparametric Online Learning. (arXiv:2002.01882v2 [cs.LG] UPDATED)</h2>
<h3>Ilja Kuzborskij, Nicol&#xf2; Cesa-Bianchi</h3>
<p>One of the main strengths of online algorithms is their ability to adapt to
arbitrary data sequences. This is especially important in nonparametric
settings, where performance is measured against rich classes of comparator
functions that are able to fit complex environments. Although such hard
comparators and complex environments may exhibit local regularities, efficient
algorithms, which can provably take advantage of these local patterns, are
hardly known. We fill this gap by introducing efficient online algorithms
(based on a single versatile master algorithm) each adapting to one of the
following regularities: (i) local Lipschitzness of the competitor function,
(ii) local metric dimension of the instance sequence, (iii) local performance
of the predictor across different regions of the instance space. Extending
previous approaches, we design algorithms that dynamically grow hierarchical
$\epsilon$-nets on the instance space whose prunings correspond to different
"locality profiles" for the problem at hand. Using a technique based on tree
experts, we simultaneously and efficiently compete against all such prunings,
and prove regret bounds each scaling with a quantity associated with a
different type of local regularity. When competing against "simple" locality
profiles, our technique delivers regret bounds that are significantly better
than those proven using the previous approach. On the other hand, the time
dependence of our bounds is not worse than that obtained by ignoring any local
regularities.
</p>
<a href="http://arxiv.org/abs/2002.01882" target="_blank">arXiv:2002.01882</a> [<a href="http://arxiv.org/pdf/2002.01882" target="_blank">pdf</a>]

<h2>Liberty or Depth: Deep Bayesian Neural Nets Do Not Need Complex Weight Posterior Approximations. (arXiv:2002.03704v3 [cs.LG] UPDATED)</h2>
<h3>Sebastian Farquhar, Lewis Smith, Yarin Gal</h3>
<p>We challenge the longstanding assumption that the mean-field approximation
for variational inference in Bayesian neural networks is severely restrictive,
and show this is not the case in deep networks. We prove several results
indicating that deep mean-field variational weight posteriors can induce
similar distributions in function-space to those induced by shallower networks
with complex weight posteriors. We validate our theoretical contributions
empirically, both through examination of the weight posterior using Hamiltonian
Monte Carlo in small models and by comparing diagonal- to structured-covariance
in large settings. Since complex variational posteriors are often expensive and
cumbersome to implement, our results suggest that using mean-field variational
inference in a deeper model is both a practical and theoretically justified
alternative to structured approximations.
</p>
<a href="http://arxiv.org/abs/2002.03704" target="_blank">arXiv:2002.03704</a> [<a href="http://arxiv.org/pdf/2002.03704" target="_blank">pdf</a>]

<h2>Object Detection as a Positive-Unlabeled Problem. (arXiv:2002.04672v2 [cs.CV] UPDATED)</h2>
<h3>Yuewei Yang, Kevin J Liang, Lawrence Carin</h3>
<p>As with other deep learning methods, label quality is important for learning
modern convolutional object detectors. However, the potentially large number
and wide diversity of object instances that can be found in complex image
scenes makes constituting complete annotations a challenging task; objects
missing annotations can be observed in a variety of popular object detection
datasets. These missing annotations can be problematic, as the standard
cross-entropy loss employed to train object detection models treats
classification as a positive-negative (PN) problem: unlabeled regions are
implicitly assumed to be background. As such, any object missing a bounding box
results in a confusing learning signal, the effects of which we observe
empirically. To remedy this, we propose treating object detection as a
positive-unlabeled (PU) problem, which removes the assumption that unlabeled
regions must be negative. We demonstrate that our proposed PU classification
loss outperforms the standard PN loss on PASCAL VOC and MS COCO across a range
of label missingness, as well as on Visual Genome and DeepLesion with full
labels.
</p>
<a href="http://arxiv.org/abs/2002.04672" target="_blank">arXiv:2002.04672</a> [<a href="http://arxiv.org/pdf/2002.04672" target="_blank">pdf</a>]

<h2>Learning Bijective Feature Maps for Linear ICA. (arXiv:2002.07766v4 [cs.LG] UPDATED)</h2>
<h3>Alexander Camuto, Matthew Willetts, Brooks Paige, Chris Holmes, Stephen Roberts</h3>
<p>Separating high-dimensional data like images into independent latent factors,
i.e independent component analysis (ICA), remains an open research problem. As
we show, existing probabilistic deep generative models (DGMs), which are
tailor-made for image data, underperform on non-linear ICA tasks. To address
this, we propose a DGM which combines bijective feature maps with a linear ICA
model to learn interpretable latent structures for high-dimensional data. Given
the complexities of jointly training such a hybrid model, we introduce novel
theory that constrains linear ICA to lie close to the manifold of orthogonal
rectangular matrices, the Stiefel manifold. By doing so we create models that
converge quickly, are easy to train, and achieve better unsupervised latent
factor discovery than flow-based models, linear ICA, and Variational
Autoencoders on images.
</p>
<a href="http://arxiv.org/abs/2002.07766" target="_blank">arXiv:2002.07766</a> [<a href="http://arxiv.org/pdf/2002.07766" target="_blank">pdf</a>]

<h2>On the Modularity of Hypernetworks. (arXiv:2002.10006v2 [cs.LG] UPDATED)</h2>
<h3>Tomer Galanti, Lior Wolf</h3>
<p>In the context of learning to map an input $I$ to a function
$h_I:\mathcal{X}\to \mathbb{R}$, two alternative methods are compared: (i) an
embedding-based method, which learns a fixed function in which $I$ is encoded
as a conditioning signal $e(I)$ and the learned function takes the form $h_I(x)
= q(x,e(I))$, and (ii) hypernetworks, in which the weights $\theta_I$ of the
function $h_I(x) = g(x;\theta_I)$ are given by a hypernetwork $f$ as
$\theta_I=f(I)$. In this paper, we define the property of modularity as the
ability to effectively learn a different function for each input instance $I$.
For this purpose, we adopt an expressivity perspective of this property and
extend the theory of Devore et al. 1996 and provide a lower bound on the
complexity (number of trainable parameters) of neural networks as function
approximators, by eliminating the requirements for the approximation method to
be robust. Our results are then used to compare the complexities of $q$ and
$g$, showing that under certain conditions and when letting the functions $e$
and $f$ be as large as we wish, $g$ can be smaller than $q$ by orders of
magnitude. This sheds light on the modularity of hypernetworks in comparison
with the embedding-based method. Besides, we show that for a structured target
function, the overall number of trainable parameters in a hypernetwork is
smaller by orders of magnitude than the number of trainable parameters of a
standard neural network and an embedding method.
</p>
<a href="http://arxiv.org/abs/2002.10006" target="_blank">arXiv:2002.10006</a> [<a href="http://arxiv.org/pdf/2002.10006" target="_blank">pdf</a>]

<h2>An End-to-End Multi-Task Learning to Link Framework for Emotion-Cause Pair Extraction. (arXiv:2002.10710v2 [cs.CL] UPDATED)</h2>
<h3>Haolin Song, Chen Zhang, Qiuchi Li, Dawei Song</h3>
<p>Emotion-cause pair extraction (ECPE), as an emergent natural language
processing task, aims at jointly investigating emotions and their underlying
causes in documents. It extends the previous emotion cause extraction (ECE)
task, yet without requiring a set of pre-given emotion clauses as in ECE.
Existing approaches to ECPE generally adopt a two-stage method, i.e., (1)
emotion and cause detection, and then (2) pairing the detected emotions and
causes. Such pipeline method, while intuitive, suffers from two critical
issues, including error propagation across stages that may hinder the
effectiveness, and high computational cost that would limit the practical
application of the method. To tackle these issues, we propose a multi-task
learning model that can extract emotions, causes and emotion-cause pairs
simultaneously in an end-to-end manner. Specifically, our model regards pair
extraction as a link prediction task, and learns to link from emotion clauses
to cause clauses, i.e., the links are directional. Emotion extraction and cause
extraction are incorporated into the model as auxiliary tasks, which further
boost the pair extraction. Experiments are conducted on an ECPE benchmarking
dataset. The results show that our proposed model outperforms a range of
state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2002.10710" target="_blank">arXiv:2002.10710</a> [<a href="http://arxiv.org/pdf/2002.10710" target="_blank">pdf</a>]

<h2>Multi-task Learning Based Neural Bridging Reference Resolution. (arXiv:2003.03666v2 [cs.CL] UPDATED)</h2>
<h3>Juntao Yu, Massimo Poesio</h3>
<p>We propose a multi task learning-based neural model for resolving bridging
references tackling two key challenges. The first challenge is the lack of
large corpora annotated with bridging references. To address this, we use
multi-task learning to help bridging reference resolution with coreference
resolution. We show that substantial improvements of up to 8 p.p. can be
achieved on full bridging resolution with this architecture. The second
challenge is the different definitions of bridging used in different corpora,
meaning that hand-coded systems or systems using special features designed for
one corpus do not work well with other corpora. Our neural model only uses a
small number of corpus independent features, thus can be applied to different
corpora. Evaluations with very different bridging corpora (ARRAU, ISNOTES,
BASHI and SCICORP) suggest that our architecture works equally well on all
corpora, and achieves the SoTA results on full bridging resolution for all
corpora, outperforming the best reported results by up to 36.3 p.p..
</p>
<a href="http://arxiv.org/abs/2003.03666" target="_blank">arXiv:2003.03666</a> [<a href="http://arxiv.org/pdf/2003.03666" target="_blank">pdf</a>]

<h2>Predicting the Amount of GDPR Fines. (arXiv:2003.05151v2 [cs.CY] UPDATED)</h2>
<h3>Jukka Ruohonen, Kalle Hjerppe</h3>
<p>The General Data Protection Regulation (GDPR) was enforced in 2018. After
this enforcement, many fines have already been imposed by national data
protection authorities in the European Union (EU). This paper examines the
individual GDPR articles referenced in the enforcement decisions, as well as
predicts the amount of enforcement fines with available meta-data and text
mining features extracted from the enforcement decision documents. According to
the results, articles related to the general principles, lawfulness, and
information security have been the most frequently referenced ones. Although
the amount of fines imposed vary across the articles referenced, these three
particular articles do not stand out. Furthermore, good predictions are
attainable even with simple machine learning techniques for regression
analysis. Basic meta-data (such as the articles referenced and the country of
origin) yields slightly better performance compared to the text mining
features.
</p>
<a href="http://arxiv.org/abs/2003.05151" target="_blank">arXiv:2003.05151</a> [<a href="http://arxiv.org/pdf/2003.05151" target="_blank">pdf</a>]

<h2>Online Meta-Critic Learning for Off-Policy Actor-Critic Methods. (arXiv:2003.05334v2 [cs.LG] UPDATED)</h2>
<h3>Wei Zhou, Yiying Li, Yongxin Yang, Huaimin Wang, Timothy M. Hospedales</h3>
<p>Off-Policy Actor-Critic (Off-PAC) methods have proven successful in a variety
of continuous control tasks. Normally, the critic's action-value function is
updated using temporal-difference, and the critic in turn provides a loss for
the actor that trains it to take actions with higher expected return. In this
paper, we introduce a novel and flexible meta-critic that observes the learning
process and meta-learns an additional loss for the actor that accelerates and
improves actor-critic learning. Compared to the vanilla critic, the meta-critic
network is explicitly trained to accelerate the learning process; and compared
to existing meta-learning algorithms, meta-critic is rapidly learned online for
a single task, rather than slowly over a family of tasks. Crucially, our
meta-critic framework is designed for off-policy based learners, which
currently provide state-of-the-art reinforcement learning sample efficiency. We
demonstrate that online meta-critic learning leads to improvements in avariety
of continuous control environments when combined with contemporary Off-PAC
methods DDPG, TD3 and the state-of-the-art SAC.
</p>
<a href="http://arxiv.org/abs/2003.05334" target="_blank">arXiv:2003.05334</a> [<a href="http://arxiv.org/pdf/2003.05334" target="_blank">pdf</a>]

<h2>CAZSL: Zero-Shot Regression for Pushing Models by Generalizing Through Context. (arXiv:2003.11696v2 [cs.LG] UPDATED)</h2>
<h3>Wenyu Zhang, Skyler Seto, Devesh K. Jha</h3>
<p>Learning accurate models of the physical world is required for a lot of
robotic manipulation tasks. However, during manipulation, robots are expected
to interact with unknown workpieces so that building predictive models which
can generalize over a number of these objects is highly desirable. In this
paper, we study the problem of designing deep learning agents which can
generalize their models of the physical world by building context-aware
learning models. The purpose of these agents is to quickly adapt and/or
generalize their notion of physics of interaction in the real world based on
certain features about the interacting objects that provide different contexts
to the predictive models. With this motivation, we present context-aware zero
shot learning (CAZSL, pronounced as casual) models, an approach utilizing a
Siamese network architecture, embedding space masking and regularization based
on context variables which allows us to learn a model that can generalize to
different parameters or features of the interacting objects. We test our
proposed learning algorithm on the recently released Omnipush datatset that
allows testing of meta-learning capabilities using low-dimensional data. Codes
for CAZSL are available at https://www.merl.com/research/license/CAZSL.
</p>
<a href="http://arxiv.org/abs/2003.11696" target="_blank">arXiv:2003.11696</a> [<a href="http://arxiv.org/pdf/2003.11696" target="_blank">pdf</a>]

<h2>On Infinite-Width Hypernetworks. (arXiv:2003.12193v5 [cs.LG] UPDATED)</h2>
<h3>Etai Littwin, Tomer Galanti, Lior Wolf, Greg Yang</h3>
<p>{\em Hypernetworks} are architectures that produce the weights of a
task-specific {\em primary network}. A notable application of hypernetworks in
the recent literature involves learning to output functional representations.
In these scenarios, the hypernetwork learns a representation corresponding to
the weights of a shallow MLP, which typically encodes shape or image
information. While such representations have seen considerable success in
practice, they remain lacking in the theoretical guarantees in the wide regime
of the standard architectures. In this work, we study wide over-parameterized
hypernetworks. We show that unlike typical architectures, infinitely wide
hypernetworks do not guarantee convergence to a global minima under gradient
descent. We further show that convexity can be achieved by increasing the
dimensionality of the hypernetwork's output, to represent wide MLPs. In the
dually infinite-width regime, we identify the functional priors of these
architectures by deriving their corresponding GP and NTK kernels, the latter of
which we refer to as the {\em hyperkernel}. As part of this study, we make a
mathematical contribution by deriving tight bounds on high order Taylor
expansion terms of standard fully connected ReLU networks.
</p>
<a href="http://arxiv.org/abs/2003.12193" target="_blank">arXiv:2003.12193</a> [<a href="http://arxiv.org/pdf/2003.12193" target="_blank">pdf</a>]

<h2>Google Landmarks Dataset v2 -- A Large-Scale Benchmark for Instance-Level Recognition and Retrieval. (arXiv:2004.01804v2 [cs.CV] UPDATED)</h2>
<h3>Tobias Weyand, Andre Araujo, Bingyi Cao, Jack Sim</h3>
<p>While image retrieval and instance recognition techniques are progressing
rapidly, there is a need for challenging datasets to accurately measure their
performance -- while posing novel challenges that are relevant for practical
applications. We introduce the Google Landmarks Dataset v2 (GLDv2), a new
benchmark for large-scale, fine-grained instance recognition and image
retrieval in the domain of human-made and natural landmarks. GLDv2 is the
largest such dataset to date by a large margin, including over 5M images and
200k distinct instance labels. Its test set consists of 118k images with ground
truth annotations for both the retrieval and recognition tasks. The ground
truth construction involved over 800 hours of human annotator work. Our new
dataset has several challenging properties inspired by real world applications
that previous datasets did not consider: An extremely long-tailed class
distribution, a large fraction of out-of-domain test photos and large
intra-class variability. The dataset is sourced from Wikimedia Commons, the
world's largest crowdsourced collection of landmark photos. We provide baseline
results for both recognition and retrieval tasks based on state-of-the-art
methods as well as competitive results from a public challenge. We further
demonstrate the suitability of the dataset for transfer learning by showing
that image embeddings trained on it achieve competitive retrieval performance
on independent datasets. The dataset images, ground-truth and metric scoring
code are available at https://github.com/cvdfoundation/google-landmark.
</p>
<a href="http://arxiv.org/abs/2004.01804" target="_blank">arXiv:2004.01804</a> [<a href="http://arxiv.org/pdf/2004.01804" target="_blank">pdf</a>]

<h2>Reinforced Multi-task Approach for Multi-hop Question Generation. (arXiv:2004.02143v4 [cs.CL] UPDATED)</h2>
<h3>Deepak Gupta, Hardik Chauhan, Akella Ravi Tej, Asif Ekbal, Pushpak Bhattacharyya</h3>
<p>Question generation (QG) attempts to solve the inverse of question answering
(QA) problem by generating a natural language question given a document and an
answer. While sequence to sequence neural models surpass rule-based systems for
QG, they are limited in their capacity to focus on more than one supporting
fact. For QG, we often require multiple supporting facts to generate
high-quality questions. Inspired by recent works on multi-hop reasoning in QA,
we take up Multi-hop question generation, which aims at generating relevant
questions based on supporting facts in the context. We employ multitask
learning with the auxiliary task of answer-aware supporting fact prediction to
guide the question generator. In addition, we also proposed a question-aware
reward function in a Reinforcement Learning (RL) framework to maximize the
utilization of the supporting facts. We demonstrate the effectiveness of our
approach through experiments on the multi-hop question answering dataset,
HotPotQA. Empirical evaluation shows our model to outperform the single-hop
neural question generation models on both automatic evaluation metrics such as
BLEU, METEOR, and ROUGE, and human evaluation metrics for quality and coverage
of the generated questions.
</p>
<a href="http://arxiv.org/abs/2004.02143" target="_blank">arXiv:2004.02143</a> [<a href="http://arxiv.org/pdf/2004.02143" target="_blank">pdf</a>]

<h2>JHU-CROWD++: Large-Scale Crowd Counting Dataset and A Benchmark Method. (arXiv:2004.03597v2 [cs.CV] UPDATED)</h2>
<h3>Vishwanath A. Sindagi, Rajeev Yasarla, Vishal M. Patel</h3>
<p>Due to its variety of applications in the real-world, the task of single
image-based crowd counting has received a lot of interest in the recent years.
Recently, several approaches have been proposed to address various problems
encountered in crowd counting. These approaches are essentially based on
convolutional neural networks that require large amounts of data to train the
network parameters. Considering this, we introduce a new large scale
unconstrained crowd counting dataset (JHU-CROWD++) that contains "4,372" images
with "1.51 million" annotations. In comparison to existing datasets, the
proposed dataset is collected under a variety of diverse scenarios and
environmental conditions. Specifically, the dataset includes several images
with weather-based degradations and illumination variations, making it a very
challenging dataset. Additionally, the dataset consists of a rich set of
annotations at both image-level and head-level. Several recent methods are
evaluated and compared on this dataset. The dataset can be downloaded from
this http URL .

Furthermore, we propose a novel crowd counting network that progressively
generates crowd density maps via residual error estimation. The proposed method
uses VGG16 as the backbone network and employs density map generated by the
final layer as a coarse prediction to refine and generate finer density maps in
a progressive fashion using residual learning. Additionally, the residual
learning is guided by an uncertainty-based confidence weighting mechanism that
permits the flow of only high-confidence residuals in the refinement path. The
proposed Confidence Guided Deep Residual Counting Network (CG-DRCN) is
evaluated on recent complex datasets, and it achieves significant improvements
in errors.
</p>
<a href="http://arxiv.org/abs/2004.03597" target="_blank">arXiv:2004.03597</a> [<a href="http://arxiv.org/pdf/2004.03597" target="_blank">pdf</a>]

<h2>Deep Normalization for Speaker Vectors. (arXiv:2004.04095v2 [eess.AS] UPDATED)</h2>
<h3>Yunqi Cai, Lantian Li, Dong Wang, Andrew Abel</h3>
<p>Deep speaker embedding has demonstrated state-of-the-art performance in
speaker recognition tasks. However, one potential issue with this approach is
that the speaker vectors derived from deep embedding models tend to be
non-Gaussian for each individual speaker, and non-homogeneous for distributions
of different speakers. These irregular distributions can seriously impact
speaker recognition performance, especially with the popular PLDA scoring
method, which assumes homogeneous Gaussian distribution. In this paper, we
argue that deep speaker vectors require deep normalization, and propose a deep
normalization approach based on a novel discriminative normalization flow (DNF)
model. We demonstrate the effectiveness of the proposed approach with
experiments using the widely used SITW and CNCeleb corpora. In these
experiments, the DNF-based normalization delivered substantial performance
gains and also showed strong generalization capability in out-of-domain tests.
</p>
<a href="http://arxiv.org/abs/2004.04095" target="_blank">arXiv:2004.04095</a> [<a href="http://arxiv.org/pdf/2004.04095" target="_blank">pdf</a>]

<h2>Towards Non-I.I.D. and Invisible Data with FedNAS: Federated Deep Learning via Neural Architecture Search. (arXiv:2004.08546v3 [cs.LG] UPDATED)</h2>
<h3>Chaoyang He, Murali Annavaram, Salman Avestimehr</h3>
<p>Federated Learning (FL) has been proved to be an effective learning framework
when data cannot be centralized due to privacy, communication costs, and
regulatory restrictions. When training deep learning models under an FL
setting, people employ the predefined model architecture discovered in the
centralized environment. However, this predefined architecture may not be the
optimal choice because it may not fit data with non-identical and independent
distribution (non-IID). Thus, we advocate automating federated learning
(AutoFL) to improve model accuracy and reduce the manual design effort. We
specifically study AutoFL via Neural Architecture Search (NAS), which can
automate the design process. We propose a Federated NAS (FedNAS) algorithm to
help scattered workers collaboratively searching for a better architecture with
higher accuracy. We also build a system based on FedNAS. Our experiments on
non-IID dataset show that the architecture searched by FedNAS can outperform
the manually predefined architecture.
</p>
<a href="http://arxiv.org/abs/2004.08546" target="_blank">arXiv:2004.08546</a> [<a href="http://arxiv.org/pdf/2004.08546" target="_blank">pdf</a>]

<h2>Improving Robot Dual-System Motor Learning with Intrinsically Motivated Meta-Control and Latent-Space Experience Imagination. (arXiv:2004.08830v3 [cs.LG] UPDATED)</h2>
<h3>Muhammad Burhan Hafez, Cornelius Weber, Matthias Kerzel, Stefan Wermter</h3>
<p>Combining model-based and model-free learning systems has been shown to
improve the sample efficiency of learning to perform complex robotic tasks.
However, dual-system approaches fail to consider the reliability of the learned
model when it is applied to make multiple-step predictions, resulting in a
compounding of prediction errors and performance degradation. In this paper, we
present a novel dual-system motor learning approach where a meta-controller
arbitrates online between model-based and model-free decisions based on an
estimate of the local reliability of the learned model. The reliability
estimate is used in computing an intrinsic feedback signal, encouraging actions
that lead to data that improves the model. Our approach also integrates
arbitration with imagination where a learned latent-space model generates
imagined experiences, based on its local reliability, to be used as additional
training data. We evaluate our approach against baseline and state-of-the-art
methods on learning vision-based robotic grasping in simulation and real world.
The results show that our approach outperforms the compared methods and learns
near-optimal grasping policies in dense- and sparse-reward environments.
</p>
<a href="http://arxiv.org/abs/2004.08830" target="_blank">arXiv:2004.08830</a> [<a href="http://arxiv.org/pdf/2004.08830" target="_blank">pdf</a>]

<h2>Experience Grounds Language. (arXiv:2004.10151v3 [cs.CL] UPDATED)</h2>
<h3>Yonatan Bisk, Ari Holtzman, Jesse Thomason, Jacob Andreas, Yoshua Bengio, Joyce Chai, Mirella Lapata, Angeliki Lazaridou, Jonathan May, Aleksandr Nisnevich, Nicolas Pinto, Joseph Turian</h3>
<p>Language understanding research is held back by a failure to relate language
to the physical world it describes and to the social interactions it
facilitates. Despite the incredible effectiveness of language processing models
to tackle tasks after being trained on text alone, successful linguistic
communication relies on a shared experience of the world. It is this shared
experience that makes utterances meaningful.

Natural language processing is a diverse field, and progress throughout its
development has come from new representational theories, modeling techniques,
data collection paradigms, and tasks. We posit that the present success of
representation learning approaches trained on large, text-only corpora requires
the parallel tradition of research on the broader physical and social context
of language to address the deeper questions of communication.
</p>
<a href="http://arxiv.org/abs/2004.10151" target="_blank">arXiv:2004.10151</a> [<a href="http://arxiv.org/pdf/2004.10151" target="_blank">pdf</a>]

<h2>Optimal Any-Angle Pathfinding on a Sphere. (arXiv:2004.12781v2 [cs.CG] UPDATED)</h2>
<h3>Volodymyr Rospotniuk, Rupert Small</h3>
<p>Pathfinding in Euclidean space is a common problem faced in robotics and
computer games. For long-distance navigation on the surface of the earth or in
outer space however, approximating the geometry as Euclidean can be
insufficient for real-world applications such as the navigation of spacecraft,
aeroplanes, drones and ships. This article describes an any-angle pathfinding
algorithm for calculating the shortest path between point pairs over the
surface of a sphere. Introducing several novel adaptations, it is shown that
Anya as described by (Harabor &amp; Grastien, 2013) for Euclidean space can be
extended to Spherical geometry. There, where the shortest-distance line between
coordinates is defined instead by a great-circle path, the optimal solution is
typically a curved line in Euclidean space. In addition the turning points for
optimal paths in Spherical geometry are not necessarily corner points as they
are in Euclidean space, as will be shown, making further substantial
adaptations to Anya necessary. Spherical Anya returns the optimal path on the
sphere, given these different properties of world maps defined in Spherical
geometry. It preserves all primary benefits of Anya in Euclidean geometry,
namely the Spherical Anya algorithm always returns an optimal path on a sphere
and does so entirely on-line, without any preprocessing or large memory
overheads. Performance benchmarks are provided for several game maps including
Starcraft and Warcraft III as well as for sea navigation on Earth using the
NOAA bathymetric dataset. Always returning the shorter path compared with the
Euclidean approximation yielded by Anya, Spherical Anya is shown to be faster
than Anya for the majority of sea routes and slower for Game Maps and Random
Maps.
</p>
<a href="http://arxiv.org/abs/2004.12781" target="_blank">arXiv:2004.12781</a> [<a href="http://arxiv.org/pdf/2004.12781" target="_blank">pdf</a>]

<h2>VD-BERT: A Unified Vision and Dialog Transformer with BERT. (arXiv:2004.13278v3 [cs.CV] UPDATED)</h2>
<h3>Yue Wang, Shafiq Joty, Michael R. Lyu, Irwin King, Caiming Xiong, Steven C.H. Hoi</h3>
<p>Visual dialog is a challenging vision-language task, where a dialog agent
needs to answer a series of questions through reasoning on the image content
and dialog history. Prior work has mostly focused on various attention
mechanisms to model such intricate interactions. By contrast, in this work, we
propose VD-BERT, a simple yet effective framework of unified vision-dialog
Transformer that leverages the pretrained BERT language models for Visual
Dialog tasks. The model is unified in that (1) it captures all the interactions
between the image and the multi-turn dialog using a single-stream Transformer
encoder, and (2) it supports both answer ranking and answer generation
seamlessly through the same architecture. More crucially, we adapt BERT for the
effective fusion of vision and dialog contents via visually grounded training.
Without the need of pretraining on external vision-language data, our model
yields new state of the art, achieving the top position in both single-model
and ensemble settings (74.54 and 75.35 NDCG scores) on the visual dialog
leaderboard. Our code and pretrained models are released at
https://github.com/salesforce/VD-BERT.
</p>
<a href="http://arxiv.org/abs/2004.13278" target="_blank">arXiv:2004.13278</a> [<a href="http://arxiv.org/pdf/2004.13278" target="_blank">pdf</a>]

<h2>Scheduled DropHead: A Regularization Method for Transformer Models. (arXiv:2004.13342v2 [cs.CL] UPDATED)</h2>
<h3>Wangchunshu Zhou, Tao Ge, Ke Xu, Furu Wei, Ming Zhou</h3>
<p>In this paper, we introduce DropHead, a structured dropout method
specifically designed for regularizing the multi-head attention mechanism,
which is a key component of transformer, a state-of-the-art model for various
NLP tasks. In contrast to the conventional dropout mechanisms which randomly
drop units or connections, the proposed DropHead is a structured dropout
method. It drops entire attention-heads during training and It prevents the
multi-head attention model from being dominated by a small portion of attention
heads while also reduces the risk of overfitting the training data, thus making
use of the multi-head attention mechanism more efficiently. Motivated by recent
studies about the learning dynamic of the multi-head attention mechanism, we
propose a specific dropout rate schedule to adaptively adjust the dropout rate
of DropHead and achieve better regularization effect. Experimental results on
both machine translation and text classification benchmark datasets demonstrate
the effectiveness of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2004.13342" target="_blank">arXiv:2004.13342</a> [<a href="http://arxiv.org/pdf/2004.13342" target="_blank">pdf</a>]

<h2>Revealing the Phase Diagram of Kitaev Materials by Machine Learning: Cooperation and Competition between Spin Liquids. (arXiv:2004.14415v3 [cond-mat.str-el] UPDATED)</h2>
<h3>Ke Liu, Nicolas Sadoune, Nihal Rao, Jonas Greitemann, Lode Pollet</h3>
<p>Kitaev materials are promising materials for hosting quantum spin liquids and
investigating the interplay of topological and symmetry-breaking phases. We use
an unsupervised and interpretable machine-learning method, the tensorial-kernel
support vector machine, to study the honeycomb Kitaev-$\Gamma$ model in a
magnetic field. Our machine learns the global classical phase diagram and the
associated analytical order parameters, including several distinct spin
liquids, two exotic $S_3$ magnets, and two modulated $S_3 \times Z_3$ magnets.
We find that the extension of Kitaev spin liquids and a field-induced
suppression of magnetic order already occur in the large-$S$ limit, implying
that critical parts of the physics of Kitaev materials can be understood at the
classical level. Moreover, the two $S_3 \times Z_3$ orders are induced by
competition between Kitaev and $\Gamma$ spin liquids and feature a previously
unknown type of spin-lattice entangled modulation, which requires a matrix
description instead of scalar phase factors. Our work provides the first
instance of a machine detecting new phases and paves the way towards the
development of automated tools to explore unsolved problems in many-body
physics.
</p>
<a href="http://arxiv.org/abs/2004.14415" target="_blank">arXiv:2004.14415</a> [<a href="http://arxiv.org/pdf/2004.14415" target="_blank">pdf</a>]

<h2>Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems. (arXiv:2005.01643v3 [cs.LG] UPDATED)</h2>
<h3>Sergey Levine, Aviral Kumar, George Tucker, Justin Fu</h3>
<p>In this tutorial article, we aim to provide the reader with the conceptual
tools needed to get started on research on offline reinforcement learning
algorithms: reinforcement learning algorithms that utilize previously collected
data, without additional online data collection. Offline reinforcement learning
algorithms hold tremendous promise for making it possible to turn large
datasets into powerful decision making engines. Effective offline reinforcement
learning methods would be able to extract policies with the maximum possible
utility out of the available data, thereby allowing automation of a wide range
of decision-making domains, from healthcare and education to robotics. However,
the limitations of current algorithms make this difficult. We will aim to
provide the reader with an understanding of these challenges, particularly in
the context of modern deep reinforcement learning methods, and describe some
potential solutions that have been explored in recent work to mitigate these
challenges, along with recent applications, and a discussion of perspectives on
open problems in the field.
</p>
<a href="http://arxiv.org/abs/2005.01643" target="_blank">arXiv:2005.01643</a> [<a href="http://arxiv.org/pdf/2005.01643" target="_blank">pdf</a>]

<h2>Mirror Descent Policy Optimization. (arXiv:2005.09814v3 [cs.LG] UPDATED)</h2>
<h3>Manan Tomar, Lior Shani, Yonathan Efroni, Mohammad Ghavamzadeh</h3>
<p>Mirror descent (MD), a well-known first-order method in constrained convex
optimization, has recently been shown as an important tool to analyze
trust-region algorithms in reinforcement learning (RL). Inspired by such
theoretical analyses, we propose an efficient RL algorithm, called {\em mirror
descent policy optimization} (MDPO). MDPO iteratively updates the policy by
approximately solving a trust-region problem, whose objective function consists
of two terms: a linearization of the standard RL objective and a proximity term
that restricts two consecutive policies to be close to each other. Each update
performs this approximation by taking multiple gradient steps on this objective
function. We derive {\em on-policy} and {\em off-policy} variants of MDPO,
while emphasizing important design choices motivated by the existing theory of
MD in RL. We highlight the connections between on-policy MDPO and two popular
trust-region RL algorithms: TRPO and PPO, and show that explicitly enforcing
the trust-region constraint is in fact {\em not} a necessity for high
performance gains in TRPO. We then show how the popular soft actor-critic (SAC)
algorithm can be derived by slight modifications of off-policy MDPO. Overall,
MDPO is derived from the MD principles, offers a unified approach to viewing a
number of popular RL algorithms, and performs better than or on-par with TRPO,
PPO, and SAC in a number of continuous control tasks.
</p>
<a href="http://arxiv.org/abs/2005.09814" target="_blank">arXiv:2005.09814</a> [<a href="http://arxiv.org/pdf/2005.09814" target="_blank">pdf</a>]

<h2>Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere. (arXiv:2005.10242v7 [cs.LG] UPDATED)</h2>
<h3>Tongzhou Wang, Phillip Isola</h3>
<p>Contrastive representation learning has been outstandingly successful in
practice. In this work, we identify two key properties related to the
contrastive loss: (1) alignment (closeness) of features from positive pairs,
and (2) uniformity of the induced distribution of the (normalized) features on
the hypersphere. We prove that, asymptotically, the contrastive loss optimizes
these properties, and analyze their positive effects on downstream tasks.
Empirically, we introduce an optimizable metric to quantify each property.
Extensive experiments on standard vision and language datasets confirm the
strong agreement between both metrics and downstream task performance.
Remarkably, directly optimizing for these two metrics leads to representations
with comparable or better performance at downstream tasks than contrastive
learning.

Project Page: https://ssnl.github.io/hypersphere

Code: https://github.com/SsnL/align_uniform ,
https://github.com/SsnL/moco_align_uniform
</p>
<a href="http://arxiv.org/abs/2005.10242" target="_blank">arXiv:2005.10242</a> [<a href="http://arxiv.org/pdf/2005.10242" target="_blank">pdf</a>]

<h2>Model-Based Robust Deep Learning: Generalizing to Natural, Out-of-Distribution Data. (arXiv:2005.10247v2 [cs.LG] UPDATED)</h2>
<h3>Alexander Robey, Hamed Hassani, George J. Pappas</h3>
<p>While deep learning has resulted in major breakthroughs in many application
domains, the frameworks commonly used in deep learning remain fragile to
artificially-crafted and imperceptible changes in the data. In response to this
fragility, adversarial training has emerged as a principled approach for
enhancing the robustness of deep learning with respect to norm-bounded
perturbations. However, there are other sources of fragility for deep learning
that are arguably more common and less thoroughly studied. Indeed, natural
variation such as lighting or weather conditions can significantly degrade the
accuracy of trained neural networks, proving that such natural variation
presents a significant challenge for deep learning.

In this paper, we propose a paradigm shift from perturbation-based
adversarial robustness toward model-based robust deep learning. Our objective
is to provide general training algorithms that can be used to train deep neural
networks to be robust against natural variation in data. Critical to our
paradigm is first obtaining a model of natural variation which can be used to
vary data over a range of natural conditions. Such models may be either known a
priori or else learned from data. In the latter case, we show that deep
generative models can be used to learn models of natural variation that are
consistent with realistic conditions. We then exploit such models in three
novel model-based robust training algorithms in order to enhance the robustness
of deep learning with respect to the given model. Our extensive experiments
show that across a variety of naturally-occurring conditions and across various
datasets, deep neural networks trained with our model-based algorithms
significantly outperform both standard deep learning algorithms as well as
norm-bounded robust deep learning algorithms.
</p>
<a href="http://arxiv.org/abs/2005.10247" target="_blank">arXiv:2005.10247</a> [<a href="http://arxiv.org/pdf/2005.10247" target="_blank">pdf</a>]

<h2>From WiscKey to Bourbon: A Learned Index for Log-Structured Merge Trees. (arXiv:2005.14213v2 [cs.DB] UPDATED)</h2>
<h3>Yifan Dai, Yien Xu, Aishwarya Ganesan, Ramnatthan Alagappan, Brian Kroth, Andrea C. Arpaci-Dusseau, Remzi H. Arpaci-Dusseau</h3>
<p>We introduce BOURBON, a log-structured merge (LSM) tree that utilizes machine
learning to provide fast lookups. We base the design and implementation of
BOURBON on empirically-grounded principles that we derive through careful
analysis of LSM design. BOURBON employs greedy piecewise linear regression to
learn key distributions, enabling fast lookup with minimal computation, and
applies a cost-benefit strategy to decide when learning will be worthwhile.
Through a series of experiments on both synthetic and real-world datasets, we
show that BOURBON improves lookup performance by 1.23x-1.78x as compared to
state-of-the-art production LSMs.
</p>
<a href="http://arxiv.org/abs/2005.14213" target="_blank">arXiv:2005.14213</a> [<a href="http://arxiv.org/pdf/2005.14213" target="_blank">pdf</a>]

<h2>In the Eye of the Beholder: Gaze and Actions in First Person Video. (arXiv:2006.00626v2 [cs.CV] UPDATED)</h2>
<h3>Yin Li, Miao Liu, James M. Rehg</h3>
<p>We address the task of jointly determining what a person is doing and where
they are looking based on the analysis of video captured by a headworn camera.
To facilitate our research, we first introduce the EGTEA Gaze+ dataset. Our
dataset comes with videos, gaze tracking data, hand masks and action
annotations, thereby providing the most comprehensive benchmark for First
Person Vision (FPV). Moving beyond the dataset, we propose a novel deep model
for joint gaze estimation and action recognition in FPV. Our method describes
the participant's gaze as a probabilistic variable and models its distribution
using stochastic units in a deep network. We further sample from these
stochastic units, generating an attention map to guide the aggregation of
visual features for action recognition. Our method is evaluated on our EGTEA
Gaze+ dataset and achieves a performance level that exceeds the
state-of-the-art by a significant margin. More importantly, we demonstrate that
our model can be applied to larger scale FPV dataset---EPIC-Kitchens even
without using gaze, offering new state-of-the-art results on FPV action
recognition.
</p>
<a href="http://arxiv.org/abs/2006.00626" target="_blank">arXiv:2006.00626</a> [<a href="http://arxiv.org/pdf/2006.00626" target="_blank">pdf</a>]

<h2>Hyperparameter optimization with REINFORCE and Transformers. (arXiv:2006.00939v3 [cs.LG] UPDATED)</h2>
<h3>Chepuri Shri Krishna, Ashish Gupta, Himanshu Rai, Swarnim Narayan</h3>
<p>Reinforcement Learning has yielded promising results for Neural Architecture
Search (NAS). In this paper, we demonstrate how its performance can be improved
by using a simplified Transformer block to model the policy network. The
simplified Transformer uses a 2-stream attention-based mechanism to model
hyper-parameter dependencies while avoiding layer normalization and position
encoding. We posit that this parsimonious design balances model complexity
against expressiveness, making it suitable for discovering optimal
architectures in high-dimensional search spaces with limited exploration
budgets. We demonstrate how the algorithm's performance can be further improved
by a) using an actor-critic style algorithm instead of plain vanilla policy
gradient and b) ensembling Transformer blocks with shared parameters, each
block conditioned on a different auto-regressive factorization order. Our
algorithm works well as both a NAS and generic hyper-parameter optimization
(HPO) algorithm: it outperformed most algorithms on NAS-Bench-101, a public
data-set for benchmarking NAS algorithms. In particular, it outperformed RL
based methods that use alternate architectures to model the policy network,
underlining the value of using attention-based networks in this setting. As a
generic HPO algorithm, it outperformed Random Search in discovering more
accurate multi-layer perceptron model architectures across 2 regression tasks.
We have adhered to guidelines listed in Lindauer and Hutter while designing
experiments and reporting results.
</p>
<a href="http://arxiv.org/abs/2006.00939" target="_blank">arXiv:2006.00939</a> [<a href="http://arxiv.org/pdf/2006.00939" target="_blank">pdf</a>]

<h2>Variational Inference and Learning of Piecewise-linear Dynamical Systems. (arXiv:2006.01668v2 [cs.LG] UPDATED)</h2>
<h3>Xavier Alameda-Pineda, Vincent Drouard, Radu Horaud</h3>
<p>Modeling the temporal behavior of data is of primordial importance in many
scientific and engineering fields. Baseline methods assume that both the
dynamic and observation equations follow linear-Gaussian models. However, there
are many real-world processes that cannot be characterized by a single linear
behavior. Alternatively, it is possible to consider a piecewise-linear model
which, combined with a switching mechanism, is well suited when several modes
of behavior are needed. Nevertheless, switching dynamical systems are
intractable because of their computational complexity increases exponentially
with time. In this paper, we propose a variational approximation of piecewise
linear dynamical systems. We provide full details of the derivation of two
variational expectation-maximization algorithms, a filter and a smoother. We
show that the model parameters can be split into two sets, static and dynamic
parameters, and that the former parameters can be estimated off-line together
with the number of linear modes, or the number of states of the switching
variable. We apply the proposed method to a visual tracking problem, namely
head-pose tracking, and we thoroughly compare our algorithm with several state
of the art trackers.
</p>
<a href="http://arxiv.org/abs/2006.01668" target="_blank">arXiv:2006.01668</a> [<a href="http://arxiv.org/pdf/2006.01668" target="_blank">pdf</a>]

<h2>Learning to Scan: A Deep Reinforcement Learning Approach for Personalized Scanning in CT Imaging. (arXiv:2006.02420v3 [physics.med-ph] UPDATED)</h2>
<h3>Ziju Shen, Yufei Wang, Dufan Wu, Xu Yang, Bin Dong</h3>
<p>Computed Tomography (CT) takes X-ray measurements on the subjects to
reconstruct tomographic images. As X-ray is radioactive, it is desirable to
control the total amount of dose of X-ray for safety concerns. Therefore, we
can only select a limited number of measurement angles and assign each of them
limited amount of dose. Traditional methods such as compressed sensing usually
randomly select the angles and equally distribute the allowed dose on them. In
most CT reconstruction models, the emphasize is on designing effective image
representations, while much less emphasize is on improving the scanning
strategy. The simple scanning strategy of random angle selection and equal dose
distribution performs well in general, but they may not be ideal for each
individual subject. It is more desirable to design a personalized scanning
strategy for each subject to obtain better reconstruction result. In this
paper, we propose to use Reinforcement Learning (RL) to learn a personalized
scanning policy to select the angles and the dose at each chosen angle for each
individual subject. We first formulate the CT scanning process as an MDP, and
then use modern deep RL methods to solve it. The learned personalized scanning
strategy not only leads to better reconstruction results, but also shows strong
generalization to be combined with different reconstruction algorithms.
</p>
<a href="http://arxiv.org/abs/2006.02420" target="_blank">arXiv:2006.02420</a> [<a href="http://arxiv.org/pdf/2006.02420" target="_blank">pdf</a>]

<h2>3D Self-Supervised Methods for Medical Imaging. (arXiv:2006.03829v3 [cs.CV] UPDATED)</h2>
<h3>Aiham Taleb, Winfried Loetzsch, Noel Danz, Julius Severin, Thomas Gaertner, Benjamin Bergner, Christoph Lippert</h3>
<p>Self-supervised learning methods have witnessed a recent surge of interest
after proving successful in multiple application fields. In this work, we
leverage these techniques, and we propose 3D versions for five different
self-supervised methods, in the form of proxy tasks. Our methods facilitate
neural network feature learning from unlabeled 3D images, aiming to reduce the
required cost for expert annotation. The developed algorithms are 3D
Contrastive Predictive Coding, 3D Rotation prediction, 3D Jigsaw puzzles,
Relative 3D patch location, and 3D Exemplar networks. Our experiments show that
pretraining models with our 3D tasks yields more powerful semantic
representations, and enables solving downstream tasks more accurately and
efficiently, compared to training the models from scratch and to pretraining
them on 2D slices. We demonstrate the effectiveness of our methods on three
downstream tasks from the medical imaging domain: i) Brain Tumor Segmentation
from 3D MRI, ii) Pancreas Tumor Segmentation from 3D CT, and iii) Diabetic
Retinopathy Detection from 2D Fundus images. In each task, we assess the gains
in data-efficiency, performance, and speed of convergence. Interestingly, we
also find gains when transferring the learned representations, by our methods,
from a large unlabeled 3D corpus to a small downstream-specific dataset. We
achieve results competitive to state-of-the-art solutions at a fraction of the
computational expense. We publish our implementations for the developed
algorithms (both 3D and 2D versions) as an open-source library, in an effort to
allow other researchers to apply and extend our methods on their datasets.
</p>
<a href="http://arxiv.org/abs/2006.03829" target="_blank">arXiv:2006.03829</a> [<a href="http://arxiv.org/pdf/2006.03829" target="_blank">pdf</a>]

<h2>MeshSDF: Differentiable Iso-Surface Extraction. (arXiv:2006.03997v2 [cs.CV] UPDATED)</h2>
<h3>Edoardo Remelli, Artem Lukoianov, Stephan R. Richter, Beno&#xee;t Guillard, Timur Bagautdinov, Pierre Baque, Pascal Fua</h3>
<p>Geometric Deep Learning has recently made striking progress with the advent
of continuous Deep Implicit Fields. They allow for detailed modeling of
watertight surfaces of arbitrary topology while not relying on a 3D Euclidean
grid, resulting in a learnable parameterization that is not limited in
resolution.

Unfortunately, these methods are often not suitable for applications that
require an explicit mesh-based surface representation because converting an
implicit field to such a representation relies on the Marching Cubes algorithm,
which cannot be differentiated with respect to the underlying implicit field.

In this work, we remove this limitation and introduce a differentiable way to
produce explicit surface mesh representations from Deep Signed Distance
Functions. Our key insight is that by reasoning on how implicit field
perturbations impact local surface geometry, one can ultimately differentiate
the 3D location of surface samples with respect to the underlying deep implicit
field. We exploit this to define MeshSDF, an end-to-end differentiable mesh
representation which can vary its topology.

We use two different applications to validate our theoretical insight:
Single-View Reconstruction via Differentiable Rendering and Physically-Driven
Shape Optimization. In both cases our differentiable parameterization gives us
an edge over state-of-the-art algorithms.
</p>
<a href="http://arxiv.org/abs/2006.03997" target="_blank">arXiv:2006.03997</a> [<a href="http://arxiv.org/pdf/2006.03997" target="_blank">pdf</a>]

<h2>Interplay between Upsampling and Regularization for Provider Fairness in Recommender Systems. (arXiv:2006.04279v2 [cs.IR] UPDATED)</h2>
<h3>Ludovico Boratto, Gianni Fenu, Mirko Marras</h3>
<p>Considering the impact of recommendations on item providers is one of the
duties of multi-sided recommender systems. Item providers are key stakeholders
in online platforms, and their earnings and plans are influenced by the
exposure their items receive in recommended lists. Prior work showed that
certain minority groups of providers, characterized by a common sensitive
attribute (e.g., gender or race), are being disproportionately affected by
indirect and unintentional discrimination. Our study handles a situation where
($i$) the same provider is associated to multiple items of a list suggested to
a user, ($ii$) an item is created by more than one provider jointly, and
($iii$) predicted user-item relevance scores are biasedly estimated for items
of provider groups. Under this scenario, we assess disparities in terms of
relevance, visibility, and exposure, by simulating diverse representations of
the minority group in the catalog and the interactions. Based on emerged unfair
outcomes, we devise a treatment that combines observation upsampling and loss
regularization, while learning user-item relevance scores. Experiments on
real-world data show that our treatment leads to lower disparate relevance. The
resulting recommended lists provide fairer visibility and exposure, wider
minority-group item coverage, and no or limited loss in recommendation utility.
</p>
<a href="http://arxiv.org/abs/2006.04279" target="_blank">arXiv:2006.04279</a> [<a href="http://arxiv.org/pdf/2006.04279" target="_blank">pdf</a>]

<h2>Simultaneously Learning Stochastic and Adversarial Episodic MDPs with Known Transition. (arXiv:2006.05606v2 [cs.LG] UPDATED)</h2>
<h3>Tiancheng Jin, Haipeng Luo</h3>
<p>This work studies the problem of learning episodic Markov Decision Processes
with known transition and bandit feedback. We develop the first algorithm with
a ``best-of-both-worlds'' guarantee: it achieves $\mathcal{O}(log T)$ regret
when the losses are stochastic, and simultaneously enjoys worst-case robustness
with $\tilde{\mathcal{O}}(\sqrt{T})$ regret even when the losses are
adversarial, where $T$ is the number of episodes. More generally, it achieves
$\tilde{\mathcal{O}}(\sqrt{C})$ regret in an intermediate setting where the
losses are corrupted by a total amount of $C$. Our algorithm is based on the
Follow-the-Regularized-Leader method from Zimin and Neu (2013), with a novel
hybrid regularizer inspired by recent works of Zimmert et al. (2019a, 2019b)
for the special case of multi-armed bandits. Crucially, our regularizer admits
a non-diagonal Hessian with a highly complicated inverse. Analyzing such a
regularizer and deriving a particular self-bounding regret guarantee is our key
technical contribution and might be of independent interest.
</p>
<a href="http://arxiv.org/abs/2006.05606" target="_blank">arXiv:2006.05606</a> [<a href="http://arxiv.org/pdf/2006.05606" target="_blank">pdf</a>]

<h2>Ansor : Generating High-Performance Tensor Programs for Deep Learning. (arXiv:2006.06762v3 [cs.LG] UPDATED)</h2>
<h3>Lianmin Zheng, Chengfan Jia, Minmin Sun, Zhao Wu, Cody Hao Yu, Ameer Haj-Ali, Yida Wang, Jun Yang, Danyang Zhuo, Koushik Sen, Joseph E. Gonzalez, Ion Stoica</h3>
<p>High-performance tensor programs are crucial to guarantee efficient execution
of deep neural networks. However, obtaining performant tensor programs for
different operators on various hardware platforms is notoriously challenging.
Currently, deep learning systems rely on vendor-provided kernel libraries or
various search strategies to get performant tensor programs. These approaches
either require significant engineering effort to develop platform-specific
optimization code or fall short of finding high-performance programs due to
restricted search space and ineffective exploration strategy.

We present Ansor, a tensor program generation framework for deep learning
applications. Compared with existing search strategies, Ansor explores many
more optimization combinations by sampling programs from a hierarchical
representation of the search space. Ansor then fine-tunes the sampled programs
with evolutionary search and a learned cost model to identify the best
programs. Ansor can find high-performance programs that are outside the search
space of existing state-of-the-art approaches. In addition, Ansor utilizes a
task scheduler to simultaneously optimize multiple subgraphs in deep neural
networks. %In addition, Ansor utilizes a task scheduler to schedule the search
tasks for multiple subgraphs in deep neural networks. We show that Ansor
improves the execution performance of deep neural networks relative to the
state-of-the-art on the Intel CPU, ARM CPU, and NVIDIA GPU by up to
$3.8\times$, $2.6\times$, and $1.7\times$, respectively.
</p>
<a href="http://arxiv.org/abs/2006.06762" target="_blank">arXiv:2006.06762</a> [<a href="http://arxiv.org/pdf/2006.06762" target="_blank">pdf</a>]

<h2>Optimal Transport Kernels for Sequential and Parallel Neural Architecture Search. (arXiv:2006.07593v2 [cs.LG] UPDATED)</h2>
<h3>Vu Nguyen, Tam Le, Makoto Yamada, Michael A Osborne</h3>
<p>Neural architecture search (NAS) automates the design of deep neural
networks. One of the main challenges in searching complex and non-continuous
architectures is to compare the similarity of networks that the conventional
Euclidean metric may fail to capture. Optimal transport (OT) is resilient to
such complex structure by considering the minimal cost for transporting a
network into another. However, the OT is generally not negative definite which
may limit its ability to build the positive-definite kernels required in many
kernel-dependent frameworks. Building upon tree-Wasserstein (TW), which is a
negative definite variant of OT, we develop a novel discrepancy for neural
architectures, and demonstrate it within a Gaussian process surrogate model for
the sequential NAS settings. Furthermore, we derive a novel parallel NAS, using
quality k-determinantal point process on the GP posterior, to select diverse
and high-performing architectures from a discrete set of candidates.
Empirically, we demonstrate that our TW-based approaches outperform other
baselines in both sequential and parallel NAS.
</p>
<a href="http://arxiv.org/abs/2006.07593" target="_blank">arXiv:2006.07593</a> [<a href="http://arxiv.org/pdf/2006.07593" target="_blank">pdf</a>]

<h2>Generative 3D Part Assembly via Dynamic Graph Learning. (arXiv:2006.07793v2 [cs.CV] UPDATED)</h2>
<h3>Jialei Huang, Guanqi Zhan, Qingnan Fan, Kaichun Mo, Lin Shao, Baoquan Chen, Leonidas Guibas, Hao Dong</h3>
<p>Autonomous part assembly is a challenging yet crucial task in 3D computer
vision and robotics. Analogous to buying an IKEA furniture, given a set of 3D
parts that can assemble a single shape, an intelligent agent needs to perceive
the 3D part geometry, reason to propose pose estimations for the input parts,
and finally call robotic planning and control routines for actuation. In this
paper, we focus on the pose estimation subproblem from the vision side
involving geometric and relational reasoning over the input part geometry.
Essentially, the task of generative 3D part assembly is to predict a 6-DoF part
pose, including a rigid rotation and translation, for each input part that
assembles a single 3D shape as the final output. To tackle this problem, we
propose an assembly-oriented dynamic graph learning framework that leverages an
iterative graph neural network as a backbone. It explicitly conducts sequential
part assembly refinements in a coarse-to-fine manner, exploits a pair of part
relation reasoning module and part aggregation module for dynamically adjusting
both part features and their relations in the part graph. We conduct extensive
experiments and quantitative comparisons to three strong baseline methods,
demonstrating the effectiveness of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2006.07793" target="_blank">arXiv:2006.07793</a> [<a href="http://arxiv.org/pdf/2006.07793" target="_blank">pdf</a>]

<h2>Multimodal Generative Learning Utilizing Jensen-Shannon-Divergence. (arXiv:2006.08242v3 [cs.LG] UPDATED)</h2>
<h3>Thomas M. Sutter, Imant Daunhawer, Julia E. Vogt</h3>
<p>Learning from different data types is a long-standing goal in machine
learning research, as multiple information sources co-occur when describing
natural phenomena. However, existing generative models that approximate a
multimodal ELBO rely on difficult or inefficient training schemes to learn a
joint distribution and the dependencies between modalities. In this work, we
propose a novel, efficient objective function that utilizes the Jensen-Shannon
divergence for multiple distributions. It simultaneously approximates the
unimodal and joint multimodal posteriors directly via a dynamic prior. In
addition, we theoretically prove that the new multimodal JS-divergence (mmJSD)
objective optimizes an ELBO. In extensive experiments, we demonstrate the
advantage of the proposed mmJSD model compared to previous work in
unsupervised, generative learning tasks.
</p>
<a href="http://arxiv.org/abs/2006.08242" target="_blank">arXiv:2006.08242</a> [<a href="http://arxiv.org/pdf/2006.08242" target="_blank">pdf</a>]

<h2>Societal biases reinforcement through machine learning: A credit scoring perspective. (arXiv:2006.08350v2 [stat.ML] UPDATED)</h2>
<h3>Bertrand K. Hassani</h3>
<p>Does machine learning and AI ensure that social biases thrive ? This paper
aims to analyse this issue. Indeed, as algorithms are informed by data, if
these are corrupted, from a social bias perspective, good machine learning
algorithms would learn from the data provided and reverberate the patterns
learnt on the predictions related to either the classification or the
regression intended. In other words, the way society behaves whether positively
or negatively, would necessarily be reflected by the models. In this paper, we
analyse how social biases are transmitted from the data into banks loan
approvals by predicting either the gender or the ethnicity of the customers
using the exact same information provided by customers through their
applications.
</p>
<a href="http://arxiv.org/abs/2006.08350" target="_blank">arXiv:2006.08350</a> [<a href="http://arxiv.org/pdf/2006.08350" target="_blank">pdf</a>]

<h2>Interface learning of multiphysics and multiscale systems. (arXiv:2006.10112v2 [physics.comp-ph] UPDATED)</h2>
<h3>Shady E. Ahmed, Omer San, Kursat Kara, Rami Younis, Adil Rasheed</h3>
<p>Complex natural or engineered systems comprise multiple characteristic
scales, multiple spatiotemporal domains, and even multiple physical closure
laws. To address such challenges, we introduce an interface learning paradigm
and put forth a data-driven closure approach based on memory embedding to
provide physically correct boundary conditions at the interface. To enable the
interface learning for hyperbolic systems by considering the domain of
influence and wave structures into account, we put forth the concept of upwind
learning towards a physics-informed domain decomposition. The promise of the
proposed approach is shown for a set of canonical illustrative problems. We
highlight that high-performance computing environments can benefit from this
methodology to reduce communication costs among processing units in emerging
machine learning ready heterogeneous platforms toward exascale era.
</p>
<a href="http://arxiv.org/abs/2006.10112" target="_blank">arXiv:2006.10112</a> [<a href="http://arxiv.org/pdf/2006.10112" target="_blank">pdf</a>]

<h2>Understanding Anomaly Detection with Deep Invertible Networks through Hierarchies of Distributions and Features. (arXiv:2006.10848v3 [cs.LG] UPDATED)</h2>
<h3>Robin Tibor Schirrmeister, Yuxuan Zhou, Tonio Ball, Dan Zhang</h3>
<p>Deep generative networks trained via maximum likelihood on a natural image
dataset like CIFAR10 often assign high likelihoods to images from datasets with
different objects (e.g., SVHN). We refine previous investigations of this
failure at anomaly detection for invertible generative networks and provide a
clear explanation of it as a combination of model bias and domain prior:
Convolutional networks learn similar low-level feature distributions when
trained on any natural image dataset and these low-level features dominate the
likelihood. Hence, when the discriminative features between inliers and
outliers are on a high-level, e.g., object shapes, anomaly detection becomes
particularly challenging. To remove the negative impact of model bias and
domain prior on detecting high-level differences, we propose two methods,
first, using the log likelihood ratios of two identical models, one trained on
the in-distribution data (e.g., CIFAR10) and the other one on a more general
distribution of images (e.g., 80 Million Tiny Images). We also derive a novel
outlier loss for the in-distribution network on samples from the more general
distribution to further improve the performance. Secondly, using a multi-scale
model like Glow, we show that low-level features are mainly captured at early
scales. Therefore, using only the likelihood contribution of the final scale
performs remarkably well for detecting high-level feature differences of the
out-of-distribution and the in-distribution. This method is especially useful
if one does not have access to a suitable general distribution. Overall, our
methods achieve strong anomaly detection performance in the unsupervised
setting, and only slightly underperform state-of-the-art classifier-based
methods in the supervised setting. Code can be found at
https://github.com/boschresearch/hierarchical_anomaly_detection.
</p>
<a href="http://arxiv.org/abs/2006.10848" target="_blank">arXiv:2006.10848</a> [<a href="http://arxiv.org/pdf/2006.10848" target="_blank">pdf</a>]

<h2>D2P-Fed: Differentially Private Federated Learning With Efficient Communication. (arXiv:2006.13039v3 [stat.ML] UPDATED)</h2>
<h3>Lun Wang, Ruoxi Jia, Dawn Song</h3>
<p>In this paper, we propose the discrete Gaussian based differentially private
federated learning (D2P-Fed), a unified scheme to achieve both differential
privacy (DP) and communication efficiency in federated learning (FL). In
particular, compared with the only prior work taking care of both aspects,
D2P-Fed provides stronger privacy guarantee, better composability and smaller
communication cost. The key idea is to apply the discrete Gaussian noise to the
private data transmission. We provide complete analysis of the privacy
guarantee, communication cost and convergence rate of D2P-Fed. We evaluated
D2P-Fed on INFIMNIST and CIFAR10. The results show that D2P-Fed outperforms
the-state-of-the-art by 6.7% to 9.75% in terms of model accuracy while saving
one third of the communication cost.
</p>
<a href="http://arxiv.org/abs/2006.13039" target="_blank">arXiv:2006.13039</a> [<a href="http://arxiv.org/pdf/2006.13039" target="_blank">pdf</a>]

<h2>Expert-Supervised Reinforcement Learning for Offline Policy Learning and Evaluation. (arXiv:2006.13189v2 [cs.LG] UPDATED)</h2>
<h3>Aaron Sonabend-W, Junwei Lu, Leo A. Celi, Tianxi Cai, Peter Szolovits</h3>
<p>Offline Reinforcement Learning (RL) is a promising approach for learning
optimal policies in environments where direct exploration is expensive or
unfeasible. However, the adoption of such policies in practice is often
challenging, as they are hard to interpret within the application context, and
lack measures of uncertainty for the learned policy value and its decisions. To
overcome these issues, we propose an Expert-Supervised RL (ESRL) framework
which uses uncertainty quantification for offline policy learning. In
particular, we have three contributions: 1) the method can learn safe and
optimal policies through hypothesis testing, 2) ESRL allows for different
levels of risk averse implementations tailored to the application context, and
finally, 3) we propose a way to interpret ESRL's policy at every state through
posterior distributions, and use this framework to compute off-policy value
function posteriors. We provide theoretical guarantees for our estimators and
regret bounds consistent with Posterior Sampling for RL (PSRL). Sample
efficiency of ESRL is independent of the chosen risk aversion threshold and
quality of the behavior policy.
</p>
<a href="http://arxiv.org/abs/2006.13189" target="_blank">arXiv:2006.13189</a> [<a href="http://arxiv.org/pdf/2006.13189" target="_blank">pdf</a>]

<h2>Spectral Bias and Task-Model Alignment Explain Generalization in Kernel Regression and Infinitely Wide Neural Networks. (arXiv:2006.13198v3 [stat.ML] UPDATED)</h2>
<h3>Abdulkadir Canatar, Blake Bordelon, Cengiz Pehlevan</h3>
<p>Generalization beyond a training dataset is a main goal of machine learning,
but theoretical understanding of generalization remains an open problem for
many models. The need for new a theory is exacerbated by recent observations in
deep neural networks where overparameterization leads to better performance,
contradicting the conventional wisdom from classical statistics. In this paper,
we investigate generalization error for kernel regression, which, besides being
a popular machine learning method, also include infinitely overparameterized
neural networks trained with gradient descent. We use techniques from
statistical mechanics to derive an analytical expression for generalization
error applicable to any kernel or data distribution. We present applications of
our theory to real and synthetic datasets, and for many kernels including those
that arise from training deep neural networks in the infinite-width limit. We
elucidate an inductive bias of kernel regression to explain data with simple
functions, which are identified by solving a kernel eigenfunction problem on
the data distribution. This notion of simplicity allows us to characterize
whether a kernel is compatible with a learning task, facilitating good
generalization performance from a small number of training examples. We show
that more data may impair generalization when noisy, leading to non-monotonic
learning curves with many peaks. To further understand these phenomena, we turn
to the broad class of rotation invariant kernels, which is relevant to training
deep neural networks in the infinite-width limit, and present a detailed
mathematical analysis of them when data is drawn from a spherically symmetric
distribution and the number of input dimensions is large.
</p>
<a href="http://arxiv.org/abs/2006.13198" target="_blank">arXiv:2006.13198</a> [<a href="http://arxiv.org/pdf/2006.13198" target="_blank">pdf</a>]

<h2>Multilabel Classification by Hierarchical Partitioning and Data-dependent Grouping. (arXiv:2006.14084v2 [cs.LG] UPDATED)</h2>
<h3>Shashanka Ubaru, Sanjeeb Dash, Arya Mazumdar, Oktay Gunluk</h3>
<p>In modern multilabel classification problems, each data instance belongs to a
small number of classes from a large set of classes. In other words, these
problems involve learning very sparse binary label vectors. Moreover, in
large-scale problems, the labels typically have certain (unknown) hierarchy. In
this paper we exploit the sparsity of label vectors and the hierarchical
structure to embed them in low-dimensional space using label groupings.
Consequently, we solve the classification problem in a much lower dimensional
space and then obtain labels in the original space using an appropriately
defined lifting. Our method builds on the work of (Ubaru &amp; Mazumdar, 2017),
where the idea of group testing was also explored for multilabel
classification. We first present a novel data-dependent grouping approach,
where we use a group construction based on a low-rank Nonnegative Matrix
Factorization (NMF) of the label matrix of training instances. The construction
also allows us, using recent results, to develop a fast prediction algorithm
that has a logarithmic runtime in the number of labels. We then present a
hierarchical partitioning approach that exploits the label hierarchy in large
scale problems to divide up the large label space and create smaller
sub-problems, which can then be solved independently via the grouping approach.
Numerical results on many benchmark datasets illustrate that, compared to other
popular methods, our proposed methods achieve competitive accuracy with
significantly lower computational costs.
</p>
<a href="http://arxiv.org/abs/2006.14084" target="_blank">arXiv:2006.14084</a> [<a href="http://arxiv.org/pdf/2006.14084" target="_blank">pdf</a>]

<h2>A causal view of compositional zero-shot recognition. (arXiv:2006.14610v2 [cs.CV] UPDATED)</h2>
<h3>Yuval Atzmon, Felix Kreuk, Uri Shalit, Gal Chechik</h3>
<p>People easily recognize new visual categories that are new combinations of
known components. This compositional generalization capacity is critical for
learning in real-world domains like vision and language because the long tail
of new combinations dominates the distribution. Unfortunately, learning systems
struggle with compositional generalization because they often build on features
that are correlated with class labels even if they are not "essential" for the
class. This leads to consistent misclassification of samples from a new
distribution, like new combinations of known components.

Here we describe an approach for compositional generalization that builds on
causal ideas. First, we describe compositional zero-shot learning from a causal
perspective, and propose to view zero-shot inference as finding "which
intervention caused the image?". Second, we present a causal-inspired embedding
model that learns disentangled representations of elementary components of
visual objects from correlated (confounded) training data. We evaluate this
approach on two datasets for predicting new combinations of attribute-object
pairs: A well-controlled synthesized images dataset and a real-world dataset
which consists of fine-grained types of shoes. We show improvements compared to
strong baselines.
</p>
<a href="http://arxiv.org/abs/2006.14610" target="_blank">arXiv:2006.14610</a> [<a href="http://arxiv.org/pdf/2006.14610" target="_blank">pdf</a>]

<h2>Approximating Network Centrality Measures Using Node Embedding and Machine Learning. (arXiv:2006.16392v4 [cs.SI] UPDATED)</h2>
<h3>Matheus R. F. Mendon&#xe7;a, Andr&#xe9; M. S. Barreto, Artur Ziviani</h3>
<p>Extracting information from real-world large networks is a key challenge
nowadays. For instance, computing a node centrality may become unfeasible
depending on the intended centrality due to its computational cost. One
solution is to develop fast methods capable of approximating network
centralities. Here, we propose an approach for efficiently approximating node
centralities for large networks using Neural Networks and Graph Embedding
techniques. Our proposed model, entitled Network Centrality Approximation using
Graph Embedding (NCA-GE), uses the adjacency matrix of a graph and a set of
features for each node (here, we use only the degree) as input and computes the
approximate desired centrality rank for every node. NCA-GE has a time
complexity of $O(|E|)$, $E$ being the set of edges of a graph, making it
suitable for large networks. NCA-GE also trains pretty fast, requiring only a
set of a thousand small synthetic scale-free graphs (ranging from 100 to 1000
nodes each), and it works well for different node centralities, network sizes,
and topologies. Finally, we compare our approach to the state-of-the-art method
that approximates centrality ranks using the degree and eigenvector
centralities as input, where we show that the NCA-GE outperforms the former in
a variety of scenarios.
</p>
<a href="http://arxiv.org/abs/2006.16392" target="_blank">arXiv:2006.16392</a> [<a href="http://arxiv.org/pdf/2006.16392" target="_blank">pdf</a>]

<h2>Compressed Sensing via Measurement-Conditional Generative Models. (arXiv:2007.00873v2 [cs.LG] UPDATED)</h2>
<h3>Kyung-Su Kim, Jung Hyun Lee, Eunho Yang</h3>
<p>A pre-trained generator has been frequently adopted in compressed sensing
(CS) due to its ability to effectively estimate signals with the prior of NNs.
In order to further refine the NN-based prior, we propose a framework that
allows the generator to utilize additional information from a given measurement
for prior learning, thereby yielding more accurate prediction for signals. As
our framework has a simple form, it is easily applied to existing CS methods
using pre-trained generators. We demonstrate through extensive experiments that
our framework exhibits uniformly superior performances by large margin and can
reduce the reconstruction error up to an order of magnitude for some
applications. We also explain the experimental success in theory by showing
that our framework can slightly relax the stringent signal presence condition,
which is required to guarantee the success of signal recovery.
</p>
<a href="http://arxiv.org/abs/2007.00873" target="_blank">arXiv:2007.00873</a> [<a href="http://arxiv.org/pdf/2007.00873" target="_blank">pdf</a>]

<h2>Digit Image Recognition Using an Ensemble of One-Versus-All Deep Network Classifiers. (arXiv:2007.01192v2 [cs.CV] UPDATED)</h2>
<h3>Abdul Mueed Hafiz, Mahmoud Hassaballah</h3>
<p>In multiclass deep network classifiers, the burden of classifying samples of
different classes is put on a single classifier. As the result the optimum
classification accuracy is not obtained. Also training times are large due to
running the CNN training on single CPU/GPU. However it is known that using
ensembles of classifiers increases the performance. Also, the training times
can be reduced by running each member of the ensemble on a separate processor.
Ensemble learning has been used in the past for traditional methods to a
varying extent and is a hot topic. With the advent of deep learning, ensemble
learning has been applied to the former as well. However, an area which is
unexplored and has potential is One-Versus-All (OVA) deep ensemble learning. In
this paper we explore it and show that by using OVA ensembles of deep networks,
improvements in performance of deep networks can be obtained. As shown in this
paper, the classification capability of deep networks can be further increased
by using an ensemble of binary classification (OVA) deep networks. We implement
a novel technique for the case of digit image recognition and test and evaluate
it on the same. In the proposed approach, a single OVA deep network classifier
is dedicated to each category. Subsequently, OVA deep network ensembles have
been investigated. Every network in an ensemble has been trained by an OVA
training technique using the Stochastic Gradient Descent with Momentum
Algorithm (SGDMA). For classification of a test sample, the sample is presented
to each network in the ensemble. After prediction score voting, the network
with the largest score is assumed to have classified the sample. The
experimentation has been done on the MNIST digit dataset, the USPS+ digit
dataset, and MATLAB digit image dataset. Our proposed technique outperforms the
baseline on digit image recognition for all datasets.
</p>
<a href="http://arxiv.org/abs/2007.01192" target="_blank">arXiv:2007.01192</a> [<a href="http://arxiv.org/pdf/2007.01192" target="_blank">pdf</a>]

<h2>Localization and Mapping of Sparse Geologic Features with Unpiloted Aircraft Systems. (arXiv:2007.01220v2 [cs.RO] UPDATED)</h2>
<h3>Zhiang Chen, Sarah Bearman, J Ramon Arrowsmith, Jnaneshwar Das</h3>
<p>Robotic mapping is attractive in many scientific applications that involve
environmental surveys. This paper presents a system for localization and
mapping of sparsely distributed surface features such as precariously balanced
rocks (PBRs), whose geometric fragility parameters provide valuable information
on earthquake processes and landscape development. With this geomorphologic
problem as the test domain, we carry out a lawn-mower search pattern from a
high elevation using an Unpiloted Aerial Vehicle (UAV) equipped with a flight
controller, GPS module, stereo camera, and onboard computer. Once a potential
PBR target is detected by a deep neural network in real time, we track its
bounding box in the image coordinates by applying a Kalman filter that fuses
the deep learning detection with Kanade-Lucas-Tomasi (KLT) tracking. The target
is localized in world coordinates using depth filtering where a set of 3D
points are filtered by object bounding boxes from different camera
perspectives. The 3D points also provide a strong prior on target shape, which
is used for UAV path planning to closely map the target using RGBD SLAM. After
target mapping, the UAS resumes the lawn-mower search pattern to locate and map
the next target.
</p>
<a href="http://arxiv.org/abs/2007.01220" target="_blank">arXiv:2007.01220</a> [<a href="http://arxiv.org/pdf/2007.01220" target="_blank">pdf</a>]

<h2>Image Classification by Reinforcement Learning with Two-State Q-Learning. (arXiv:2007.01298v3 [cs.CV] UPDATED)</h2>
<h3>Abdul Mueed Hafiz</h3>
<p>In this paper, a simple and efficient Hybrid Classifier is presented which is
based on deep learning and reinforcement learning. Here, Q-Learning has been
used with two states and 'two or three' actions. Other techniques found in the
literature use feature map extracted from Convolutional Neural Networks and use
these in the Q-states along with past history. This leads to technical
difficulties in these approaches because the number of states is high due to
large dimensions of the feature map. Because the proposed technique uses only
two Q-states it is straightforward and consequently has much lesser number of
optimization parameters, and thus also has a simple reward function. Also, the
proposed technique uses novel actions for processing images as compared to
other techniques found in literature. The performance of the proposed technique
is compared with other recent algorithms like ResNet50, InceptionV3, etc. on
popular databases including ImageNet, Cats and Dogs Dataset, and Caltech-101
Dataset. The proposed approach outperforms others techniques on all the
datasets used.
</p>
<a href="http://arxiv.org/abs/2007.01298" target="_blank">arXiv:2007.01298</a> [<a href="http://arxiv.org/pdf/2007.01298" target="_blank">pdf</a>]

<h2>Learning Spoken Language Representations with Neural Lattice Language Modeling. (arXiv:2007.02629v2 [cs.CL] UPDATED)</h2>
<h3>Chao-Wei Huang, Yun-Nung Chen</h3>
<p>Pre-trained language models have achieved huge improvement on many NLP tasks.
However, these methods are usually designed for written text, so they do not
consider the properties of spoken language. Therefore, this paper aims at
generalizing the idea of language model pre-training to lattices generated by
recognition systems. We propose a framework that trains neural lattice language
models to provide contextualized representations for spoken language
understanding tasks. The proposed two-stage pre-training approach reduces the
demands of speech data and has better efficiency. Experiments on intent
detection and dialogue act recognition datasets demonstrate that our proposed
method consistently outperforms strong baselines when evaluated on spoken
inputs. The code is available at https://github.com/MiuLab/Lattice-ELMo.
</p>
<a href="http://arxiv.org/abs/2007.02629" target="_blank">arXiv:2007.02629</a> [<a href="http://arxiv.org/pdf/2007.02629" target="_blank">pdf</a>]

<h2>Localized Motion Artifact Reduction on Brain MRI Using Deep Learning with Effective Data Augmentation Techniques. (arXiv:2007.05149v2 [eess.IV] UPDATED)</h2>
<h3>Yijun Zhao, Jacek Ossowski, Xuming Wang, Shangjin Li, Orrin Devinsky, Samantha P. Martin, Heath R. Pardoe</h3>
<p>In-scanner motion degrades the quality of magnetic resonance imaging (MRI)
thereby reducing its utility in the detection of clinically relevant
abnormalities. We introduce a deep learning-based MRI artifact reduction model
(DMAR) to localize and correct head motion artifacts in brain MRI scans. Our
approach integrates the latest advances in object detection and noise reduction
in Computer Vision. Specifically, DMAR employs a two-stage approach: in the
first, degraded regions are detected using the Single Shot Multibox Detector
(SSD), and in the second, the artifacts within the found regions are reduced
using a convolutional autoencoder (CAE). We further introduce a set of novel
data augmentation techniques to address the high dimensionality of MRI images
and the scarcity of available data. As a result, our model was trained on a
large synthetic dataset of 225,000 images generated from 375 whole brain
T1-weighted MRI scans. DMAR visibly reduces image artifacts when applied to
both synthetic test images and 55 real-world motion-affected slices from 18
subjects from the multi-center Autism Brain Imaging Data Exchange (ABIDE)
study. Quantitatively, depending on the level of degradation, our model
achieves a 27.8%-48.1% reduction in RMSE and a 2.88--5.79 dB gain in PSNR on a
5000-sample set of synthetic images. For real-world artifact-affected scans
from ABIDE, our model reduced the variance of image voxel intensity within
artifact-affected brain regions (p = 0.014).
</p>
<a href="http://arxiv.org/abs/2007.05149" target="_blank">arXiv:2007.05149</a> [<a href="http://arxiv.org/pdf/2007.05149" target="_blank">pdf</a>]

<h2>Learning Retrospective Knowledge with Reverse Reinforcement Learning. (arXiv:2007.06703v3 [cs.LG] UPDATED)</h2>
<h3>Shangtong Zhang, Vivek Veeriah, Shimon Whiteson</h3>
<p>We present a Reverse Reinforcement Learning (Reverse RL) approach for
representing retrospective knowledge. General Value Functions (GVFs) have
enjoyed great success in representing predictive knowledge, i.e., answering
questions about possible future outcomes such as "how much fuel will be
consumed in expectation if we drive from A to B?". GVFs, however, cannot answer
questions like "how much fuel do we expect a car to have given it is at B at
time $t$?". To answer this question, we need to know when that car had a full
tank and how that car came to B. Since such questions emphasize the influence
of possible past events on the present, we refer to their answers as
retrospective knowledge. In this paper, we show how to represent retrospective
knowledge with Reverse GVFs, which are trained via Reverse RL. We demonstrate
empirically the utility of Reverse GVFs in both representation learning and
anomaly detection.
</p>
<a href="http://arxiv.org/abs/2007.06703" target="_blank">arXiv:2007.06703</a> [<a href="http://arxiv.org/pdf/2007.06703" target="_blank">pdf</a>]

<h2>Drinking from a Firehose: Continual Learning with Web-scale Natural Language. (arXiv:2007.09335v2 [cs.LG] UPDATED)</h2>
<h3>Hexiang Hu, Ozan Sener, Fei Sha, Vladlen Koltun</h3>
<p>Continual learning systems will interact with humans, with each other, and
with the physical world through time -- and continue to learn and adapt as they
do. An important open problem for continual learning is a large-scale benchmark
that enables realistic evaluation of algorithms. In this paper, we study a
natural setting for continual learning on a massive scale. We introduce the
problem of personalized online language learning (POLL), which involves fitting
personalized language models to a population of users that evolves over time.
To facilitate research on POLL, we collect massive datasets of Twitter posts.
These datasets, Firehose10M and Firehose100M, comprise 100 million tweets,
posted by one million users over six years. Enabled by the Firehose datasets,
we present a rigorous evaluation of continual learning algorithms on an
unprecedented scale. Based on this analysis, we develop a simple algorithm for
continual gradient descent (ConGraD) that outperforms prior continual learning
methods on the Firehose datasets as well as earlier benchmarks. Collectively,
the POLL problem setting, the Firehose datasets, and the ConGraD algorithm
enable a complete benchmark for reproducible research on web-scale continual
learning.
</p>
<a href="http://arxiv.org/abs/2007.09335" target="_blank">arXiv:2007.09335</a> [<a href="http://arxiv.org/pdf/2007.09335" target="_blank">pdf</a>]

<h2>Guided multi-branch learning systems for sound event detection with sound separation. (arXiv:2007.10638v2 [cs.SD] UPDATED)</h2>
<h3>Yuxin Huang, Liwei Lin, Shuo Ma, Xiangdong Wang, Hong Liu, Yueliang Qian, Min Liu, Kazushige Ouch</h3>
<p>In this paper, we describe in detail our systems for DCASE 2020 Task 4. The
systems are based on the 1st-place system of DCASE 2019 Task 4, which adopts
weakly-supervised framework with an attention-based embedding-level pooling
module and a semi-supervised learning approach named guided learning. This
year, we incorporate multi-branch learning (MBL) into the original system to
further improve its performance. MBL uses different branches with different
pooling strategies (including instance-level and embedding-level strategies)
and different pooling modules (including attention pooling, global max pooling
or global average pooling modules), which share the same feature encoder of the
model. Therefore, multiple branches pursuing different purposes and focusing on
different characteristics of the data can help the feature encoder model the
feature space better and avoid over-fitting. To better exploit the
strongly-labeled synthetic data, inspired by multi-task learning, we also
employ a sound event detection branch. To combine sound separation (SS) with
sound event detection (SED), we fuse the results of SED systems with SS-SED
systems which are trained using separated sound output by an SS system. The
experimental results prove that MBL can improve the model performance and using
SS has great potential to improve the performance of SED ensemble system.
</p>
<a href="http://arxiv.org/abs/2007.10638" target="_blank">arXiv:2007.10638</a> [<a href="http://arxiv.org/pdf/2007.10638" target="_blank">pdf</a>]

<h2>CrossTransformers: spatially-aware few-shot transfer. (arXiv:2007.11498v3 [cs.CV] UPDATED)</h2>
<h3>Carl Doersch, Ankush Gupta, Andrew Zisserman</h3>
<p>Given new tasks with very little data$-$such as new classes in a
classification problem or a domain shift in the input$-$performance of modern
vision systems degrades remarkably quickly. In this work, we illustrate how the
neural network representations which underpin modern vision systems are subject
to supervision collapse, whereby they lose any information that is not
necessary for performing the training task, including information that may be
necessary for transfer to new tasks or domains. We then propose two methods to
mitigate this problem. First, we employ self-supervised learning to encourage
general-purpose features that transfer better. Second, we propose a novel
Transformer based neural network architecture called CrossTransformers, which
can take a small number of labeled images and an unlabeled query, find coarse
spatial correspondence between the query and the labeled images, and then infer
class membership by computing distances between spatially-corresponding
features. The result is a classifier that is more robust to task and domain
shift, which we demonstrate via state-of-the-art performance on Meta-Dataset, a
recent dataset for evaluating transfer from ImageNet to many other vision
datasets.
</p>
<a href="http://arxiv.org/abs/2007.11498" target="_blank">arXiv:2007.11498</a> [<a href="http://arxiv.org/pdf/2007.11498" target="_blank">pdf</a>]

<h2>Fast-Convergent Federated Learning. (arXiv:2007.13137v2 [cs.LG] UPDATED)</h2>
<h3>Hung T. Nguyen, Vikash Sehwag, Seyyedali Hosseinalipour, Christopher G. Brinton, Mung Chiang, H. Vincent Poor</h3>
<p>Federated learning has emerged recently as a promising solution for
distributing machine learning tasks through modern networks of mobile devices.
Recent studies have obtained lower bounds on the expected decrease in model
loss that is achieved through each round of federated learning. However,
convergence generally requires a large number of communication rounds, which
induces delay in model training and is costly in terms of network resources. In
this paper, we propose a fast-convergent federated learning algorithm, called
FOLB, which performs intelligent sampling of devices in each round of model
training to optimize the expected convergence speed. We first theoretically
characterize a lower bound on improvement that can be obtained in each round if
devices are selected according to the expected improvement their local models
will provide to the current global model. Then, we show that FOLB obtains this
bound through uniform sampling by weighting device updates according to their
gradient information. FOLB is able to handle both communication and computation
heterogeneity of devices by adapting the aggregations according to estimates of
device's capabilities of contributing to the updates. We evaluate FOLB in
comparison with existing federated learning algorithms and experimentally show
its improvement in trained model accuracy, convergence speed, and/or model
stability across various machine learning tasks and datasets.
</p>
<a href="http://arxiv.org/abs/2007.13137" target="_blank">arXiv:2007.13137</a> [<a href="http://arxiv.org/pdf/2007.13137" target="_blank">pdf</a>]

<h2>Information Behavior During the Covid-19 Crisis in German-Speaking Countries. (arXiv:2007.13833v2 [cs.CY] UPDATED)</h2>
<h3>Stefan Dreisiebner, Sophie M&#xe4;rz, Thomas Mandl</h3>
<p>This paper explores the impact of the Covid-19 crisis at the level of
individual information behavior, based on an online survey among 308
participants from the German-speaking countries Austria, Germany and
Switzerland in April and May 2020. The results show first that the Covid-19
crisis has led to an increased demand for reliable information. This goes
alongside a significant increased use of public broadcasting, newspapers and
information provided by public organizations. Second, the majority (84%) of the
participants reported being satisfied with the information supply during the
Covid-19 crisis. Participants who were less satisfied with the information
supply during the Covid-19 crisis used reliable sources significantly less
frequently, specifically public television, national newspapers and information
provided by public organizations. Third, the amount of Covid-19-related
information during the peak of the crisis led some participants to a feeling of
information overload, which resulted in a reduction of information seeking and
media use.
</p>
<a href="http://arxiv.org/abs/2007.13833" target="_blank">arXiv:2007.13833</a> [<a href="http://arxiv.org/pdf/2007.13833" target="_blank">pdf</a>]

<h2>Learning Output Embeddings in Structured Prediction. (arXiv:2007.14703v3 [stat.ML] UPDATED)</h2>
<h3>Luc Brogat-Motte, Alessandro Rudi, C&#xe9;line Brouard, Juho Rousu, Florence d&#x27;Alch&#xe9;-Buc</h3>
<p>A powerful and flexible approach to structured prediction consists in
embedding the structured objects to be predicted into a feature space of
possibly infinite dimension by means of output kernels, and then, solving a
regression problem in this output space. A prediction in the original space is
computed by solving a pre-image problem. In such an approach, the embedding,
linked to the target loss, is defined prior to the learning phase. In this
work, we propose to jointly learn a finite approximation of the output
embedding and the regression function into the new feature space. For that
purpose, we leverage a priori information on the outputs and also unexploited
unsupervised output data, which are both often available in structured
prediction problems. We prove that the resulting structured predictor is a
consistent estimator, and derive an excess risk bound. Moreover, the novel
structured prediction tool enjoys a significantly smaller computational
complexity than former output kernel methods. The approach empirically tested
on various structured prediction problems reveals to be versatile and able to
handle large datasets.
</p>
<a href="http://arxiv.org/abs/2007.14703" target="_blank">arXiv:2007.14703</a> [<a href="http://arxiv.org/pdf/2007.14703" target="_blank">pdf</a>]

<h2>Large-scale, Language-agnostic Discourse Classification of Tweets During COVID-19. (arXiv:2008.00461v2 [cs.SI] UPDATED)</h2>
<h3>Oguzhan Gencoglu</h3>
<p>Quantifying the characteristics of public attention is an essential
prerequisite for appropriate crisis management during severe events such as
pandemics. For this purpose, we propose language-agnostic tweet representations
to perform large-scale Twitter discourse classification with machine learning.
Our analysis on more than 26 million COVID-19 tweets shows that large-scale
surveillance of public discourse is feasible with computationally lightweight
classifiers by out-of-the-box utilization of these representations.
</p>
<a href="http://arxiv.org/abs/2008.00461" target="_blank">arXiv:2008.00461</a> [<a href="http://arxiv.org/pdf/2008.00461" target="_blank">pdf</a>]

<h2>Gibbs Sampling with People. (arXiv:2008.02595v2 [q-bio.NC] UPDATED)</h2>
<h3>Peter M. C. Harrison, Raja Marjieh, Federico Adolfi, Pol van Rijn, Manuel Anglada-Tort, Ofer Tchernichovski, Pauline Larrouy-Maestri, Nori Jacoby</h3>
<p>A core problem in cognitive science and machine learning is to understand how
humans derive semantic representations from perceptual objects, such as color
from an apple, pleasantness from a musical chord, or seriousness from a face.
Markov Chain Monte Carlo with People (MCMCP) is a prominent method for studying
such representations, in which participants are presented with binary choice
trials constructed such that the decisions follow a Markov Chain Monte Carlo
acceptance rule. However, while MCMCP has strong asymptotic properties, its
binary choice paradigm generates relatively little information per trial, and
its local proposal function makes it slow to explore the parameter space and
find the modes of the distribution. Here we therefore generalize MCMCP to a
continuous-sampling paradigm, where in each iteration the participant uses a
slider to continuously manipulate a single stimulus dimension to optimize a
given criterion such as 'pleasantness'. We formulate both methods from a
utility-theory perspective, and show that the new method can be interpreted as
'Gibbs Sampling with People' (GSP). Further, we introduce an aggregation
parameter to the transition step, and show that this parameter can be
manipulated to flexibly shift between Gibbs sampling and deterministic
optimization. In an initial study, we show GSP clearly outperforming MCMCP; we
then show that GSP provides novel and interpretable results in three other
domains, namely musical chords, vocal emotions, and faces. We validate these
results through large-scale perceptual rating experiments. The final
experiments use GSP to navigate the latent space of a state-of-the-art image
synthesis network (StyleGAN), a promising approach for applying GSP to
high-dimensional perceptual spaces. We conclude by discussing future cognitive
applications and ethical implications.
</p>
<a href="http://arxiv.org/abs/2008.02595" target="_blank">arXiv:2008.02595</a> [<a href="http://arxiv.org/pdf/2008.02595" target="_blank">pdf</a>]

<h2>Combining Code Embedding with Static Analysis for Function-Call Completion. (arXiv:2008.03731v2 [cs.SE] UPDATED)</h2>
<h3>M. Weyssow, H. Sahraoui, B. Fr&#xe9;nay, B. Vanderose</h3>
<p>Code completion is an important feature of integrated development
environments (IDEs). It allows developers to produce code faster, especially
novice ones who are not fully familiar with APIs and others code. Previous
works on code completion have mainly exploited static type systems of
programming languages or code history of the project under development or of
other projects using common APIs. In this work, we present a novel approach for
improving current function-calls completion tools by learning from independent
code repositories, using well-known natural language processing models that can
learn vector representation of source code (code embeddings). Our models are
not trained on historical data of specific projects. Instead, our approach
allows to learn high-level concepts and their relationships present among
thousands of projects. As a consequence, the resulting system is able to
provide general suggestions that are not specific to particular projects or
APIs. Additionally, by taking into account the context of the call to complete,
our approach suggests function calls relevant to that context. We evaluated our
approach on a set of open-source projects unseen during the training. The
results show that the use of the trained model along with a code suggestion
plug-in based on static type analysis improves significantly the correctness of
the completion suggestions.
</p>
<a href="http://arxiv.org/abs/2008.03731" target="_blank">arXiv:2008.03731</a> [<a href="http://arxiv.org/pdf/2008.03731" target="_blank">pdf</a>]

<h2>Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements Matching. (arXiv:2008.09474v4 [cs.CV] UPDATED)</h2>
<h3>Zexi Chen, Xuecheng Xu, Yue Wang, Rong Xiong</h3>
<p>The crucial step for localization is to match the current observation to the
map. When the two sensor modalities are significantly different, matching
becomes challenging. In this paper, we present an end-to-end deep phase
correlation network (DPCN) to match heterogeneous sensor measurements. In DPCN,
the primary component is a differentiable correlation-based estimator that
back-propagates the pose error to learnable feature extractors, which addresses
the problem that there are no direct common features for supervision. Also, it
eliminates the exhaustive evaluation in some previous methods, improving
efficiency. With the interpretable modeling, the network is light-weighted and
promising for better generalization. We evaluate the system on both the
simulation data and Aero-Ground Dataset which consists of heterogeneous sensor
images and aerial images acquired by satellites or aerial robots. The results
show that our method is able to match the heterogeneous sensor measurements,
outperforming the comparative traditional phase correlation and other
learning-based methods. Code is available at
https://github.com/jessychen1016/DPCN .
</p>
<a href="http://arxiv.org/abs/2008.09474" target="_blank">arXiv:2008.09474</a> [<a href="http://arxiv.org/pdf/2008.09474" target="_blank">pdf</a>]

<h2>Multiscale Dynamic Human Mobility Flow Dataset in the U.S. during the COVID-19 Epidemic. (arXiv:2008.12238v2 [cs.SI] UPDATED)</h2>
<h3>Yuhao Kang, Song Gao, Yunlei Liang, Mingxiao Li, Jinmeng Rao, Jake Kruse</h3>
<p>Understanding dynamic human mobility changes and spatial interaction patterns
at different geographic scales is crucial for assessing the impacts of
non-pharmaceutical interventions (such as stay-at-home orders) during the
COVID-19 pandemic. In this data descriptor, we introduce a regularly-updated
multiscale dynamic human mobility flow dataset across the United States, with
data starting from March 1st, 2020. By analyzing millions of anonymous mobile
phone users' visits to various places provided by SafeGraph, the daily and
weekly dynamic origin-to-destination (O-D) population flows are computed,
aggregated, and inferred at three geographic scales: census tract, county, and
state. There is high correlation between our mobility flow dataset and openly
available data sources, which shows the reliability of the produced data. Such
a high spatiotemporal resolution human mobility flow dataset at different
geographic scales over time may help monitor epidemic spreading dynamics,
inform public health policy, and deepen our understanding of human behavior
changes under the unprecedented public health crisis. This up-to-date O-D flow
open data can support many other social sensing and transportation
applications.
</p>
<a href="http://arxiv.org/abs/2008.12238" target="_blank">arXiv:2008.12238</a> [<a href="http://arxiv.org/pdf/2008.12238" target="_blank">pdf</a>]

<h2>SketchEmbedNet: Learning Novel Concepts by Imitating Drawings. (arXiv:2009.04806v2 [cs.CV] UPDATED)</h2>
<h3>Alexander Wang, Mengye Ren, Richard Zemel</h3>
<p>Sketch drawings are an intuitive visual domain that appeals to human
instinct. Previous work has shown that recurrent neural networks are capable of
producing sketch drawings of a single or few classes at a time. In this work we
investigate representations developed by training a generative model to produce
sketches from pixel images across many classes in a sketch domain. We find that
the embeddings learned by this sketching model are informative for visual tasks
and capture some forms of visual understanding. We then use them to exceed
state-of-the-art performance in unsupervised few-shot classification on the
Omniglot and mini-ImageNet benchmarks. We also leverage the generative capacity
of our model to produce high quality sketches of novel classes based on just a
single example.
</p>
<a href="http://arxiv.org/abs/2009.04806" target="_blank">arXiv:2009.04806</a> [<a href="http://arxiv.org/pdf/2009.04806" target="_blank">pdf</a>]

<h2>Few-Shot Unsupervised Continual Learning through Meta-Examples. (arXiv:2009.08107v2 [cs.LG] UPDATED)</h2>
<h3>Alessia Bertugli, Stefano Vincenzi, Simone Calderara, Andrea Passerini</h3>
<p>In real-world applications, data do not reflect the ones commonly used for
neural networks training, since they are usually few, unlabeled and can be
available as a stream. Hence many existing deep learning solutions suffer from
a limited range of applications, in particular in the case of online streaming
data that evolve over time. To narrow this gap, in this work we introduce a
novel and complex setting involving unsupervised meta-continual learning with
unbalanced tasks. These tasks are built through a clustering procedure applied
to a fitted embedding space. We exploit a meta-learning scheme that
simultaneously alleviates catastrophic forgetting and favors the generalization
to new tasks. Moreover, to encourage feature reuse during the
meta-optimization, we exploit a single inner loop taking advantage of an
aggregated representation achieved through the use of a self-attention
mechanism. Experimental results on few-shot learning benchmarks show
competitive performance even compared to the supervised case. Additionally, we
empirically observe that in an unsupervised scenario, the small tasks and the
variability in the clusters pooling play a crucial role in the generalization
capability of the network. Further, on complex datasets, the exploitation of
more clusters than the true number of classes leads to higher results, even
compared to the ones obtained with full supervision, suggesting that a
predefined partitioning into classes can miss relevant structural information.
</p>
<a href="http://arxiv.org/abs/2009.08107" target="_blank">arXiv:2009.08107</a> [<a href="http://arxiv.org/pdf/2009.08107" target="_blank">pdf</a>]

<h2>Structure-Guided Processing Path Optimization with Deep Reinforcement Learning. (arXiv:2009.09706v2 [cs.LG] UPDATED)</h2>
<h3>Johannes Dornheim, Lukas Morand, Samuel Zeitvogel, Tarek Iraki, Norbert Link, Dirk Helm</h3>
<p>A major goal of material design is the inverse optimization of
processing-structure-property relationships. In this paper, we propose and
investigate a deep reinforcement learning approach for the optimization of
processing paths. The goal is to find optimal processing paths in the material
structure space that lead to target structures, which have been identified
beforehand to yield desired material properties. The contribution completes the
desired inversion of the processing-structure-property chain in a flexible and
generic way. As the relation between properties and structures is generally
nonunique, typically a whole set of goal structures can be identified, that
lead to desired properties. Our proposed method optimizes processing paths from
a start structure to one of the equivalent goal-structures. The algorithm
learns to find near-optimal paths by interacting with the structure-generating
process. It is guided by structure descriptors as process state features and a
reward signal, which is formulated based on a distance function in the
structure space. The model-free reinforcement learning algorithm learns through
trial and error while interacting with the process and does not rely on a
priori sampled processing data. We instantiate and evaluate the proposed method
by optimizing paths of a generic metal forming process to reach near-optimal
structures, which are represented by one-point statistics of crystallographic
textures.
</p>
<a href="http://arxiv.org/abs/2009.09706" target="_blank">arXiv:2009.09706</a> [<a href="http://arxiv.org/pdf/2009.09706" target="_blank">pdf</a>]

<h2>ContactNets: Learning Discontinuous Contact Dynamics with Smooth, Implicit Representations. (arXiv:2009.11193v2 [cs.RO] UPDATED)</h2>
<h3>Samuel Pfrommer, Mathew Halm, Michael Posa</h3>
<p>Common methods for learning robot dynamics assume motion is continuous,
causing unrealistic model predictions for systems undergoing discontinuous
impact and stiction behavior. In this work, we resolve this conflict with a
smooth, implicit encoding of the structure inherent to contact-induced
discontinuities. Our method, ContactNets, learns parameterizations of
inter-body signed distance and contact-frame Jacobians, a representation that
is compatible with many simulation, control, and planning environments for
robotics. We furthermore circumvent the need to differentiate through stiff or
non-smooth dynamics with a novel loss function inspired by the principles of
complementarity and maximum dissipation. Our method can predict realistic
impact, non-penetration, and stiction when trained on 60 seconds of real-world
data.
</p>
<a href="http://arxiv.org/abs/2009.11193" target="_blank">arXiv:2009.11193</a> [<a href="http://arxiv.org/pdf/2009.11193" target="_blank">pdf</a>]

<h2>Learning in a Small/Big World. (arXiv:2009.11917v6 [econ.TH] UPDATED)</h2>
<h3>Benson Tsz Kin Leung</h3>
<p>Savage (1972) lays down the foundation of Bayesian decision theory, but
asserts that it is not applicable in big worlds where the environment is
complex. Using the theory of finite automaton to model belief formation, this
paper studies the characteristics of optimal learning behavior in small and big
worlds, where the complexity of the environment is low and high, respectively,
relative to the cognitive ability of the decision maker. Confirming Savage's
claim, optimal learning behavior is closed to Bayesian in small worlds but
significantly different in big worlds. In addition, I show that in big worlds,
the optimal learning behavior could exhibit a wide range of well-documented
non-Bayesian learning behavior, including the use of heuristic, correlation
neglect, persistent over-confidence, inattentive learning, and other behaviors
of model simplification or misspecification. These results establish a clear
and testable relationship between the prominence of non-Bayesian learning
behavior, complexity and cognitive ability.
</p>
<a href="http://arxiv.org/abs/2009.11917" target="_blank">arXiv:2009.11917</a> [<a href="http://arxiv.org/pdf/2009.11917" target="_blank">pdf</a>]

<h2>SuPEr-SAM: Using the Supervision Signal from a Pose Estimator to Train a Spatial Attention Module for Personal Protective Equipment Recognition. (arXiv:2009.12339v2 [cs.CV] UPDATED)</h2>
<h3>Adrian Sandru, Georgian-Emilian Duta, Mariana-Iuliana Georgescu, Radu Tudor Ionescu</h3>
<p>We propose a deep learning method to automatically detect personal protective
equipment (PPE), such as helmets, surgical masks, reflective vests, boots and
so on, in images of people. Typical approaches for PPE detection based on deep
learning are (i) to train an object detector for items such as those listed
above or (ii) to train a person detector and a classifier that takes the
bounding boxes predicted by the detector and discriminates between people
wearing and people not wearing the corresponding PPE items. We propose a novel
and accurate approach that uses three components: a person detector, a body
pose estimator and a classifier. Our novelty consists in using the pose
estimator only at training time, to improve the prediction performance of the
classifier. We modify the neural architecture of the classifier by adding a
spatial attention mechanism, which is trained using supervision signal from the
pose estimator. In this way, the classifier learns to focus on PPE items, using
knowledge from the pose estimator with almost no computational overhead during
inference.
</p>
<a href="http://arxiv.org/abs/2009.12339" target="_blank">arXiv:2009.12339</a> [<a href="http://arxiv.org/pdf/2009.12339" target="_blank">pdf</a>]

<h2>Mitigating Gender Bias for Neural Dialogue Generation with Adversarial Learning. (arXiv:2009.13028v2 [cs.CL] UPDATED)</h2>
<h3>Haochen Liu, Wentao Wang, Yiqi Wang, Hui Liu, Zitao Liu, Jiliang Tang</h3>
<p>Dialogue systems play an increasingly important role in various aspects of
our daily life. It is evident from recent research that dialogue systems
trained on human conversation data are biased. In particular, they can produce
responses that reflect people's gender prejudice. Many debiasing methods have
been developed for various NLP tasks, such as word embedding. However, they are
not directly applicable to dialogue systems because they are likely to force
dialogue models to generate similar responses for different genders. This
greatly degrades the diversity of the generated responses and immensely hurts
the performance of the dialogue models. In this paper, we propose a novel
adversarial learning framework Debiased-Chat to train dialogue models free from
gender bias while keeping their performance. Extensive experiments on two
real-world conversation datasets show that our framework significantly reduces
gender bias in dialogue models while maintaining the response quality. The
implementation of the proposed framework is released.
</p>
<a href="http://arxiv.org/abs/2009.13028" target="_blank">arXiv:2009.13028</a> [<a href="http://arxiv.org/pdf/2009.13028" target="_blank">pdf</a>]

<h2>Bongard-LOGO: A New Benchmark for Human-Level Concept Learning and Reasoning. (arXiv:2010.00763v2 [cs.AI] UPDATED)</h2>
<h3>Weili Nie, Zhiding Yu, Lei Mao, Ankit B. Patel, Yuke Zhu, Animashree Anandkumar</h3>
<p>Humans have an inherent ability to learn novel concepts from only a few
samples and generalize these concepts to different situations. Even though
today's machine learning models excel with a plethora of training data on
standard recognition tasks, a considerable gap exists between machine-level
pattern recognition and human-level concept learning. To narrow this gap, the
Bongard Problems (BPs) were introduced as an inspirational challenge for visual
cognition in intelligent systems. Despite new advances in representation
learning and learning to learn, BPs remain a daunting challenge for modern AI.
Inspired by the original one hundred BPs, we propose a new benchmark
Bongard-LOGO for human-level concept learning and reasoning. We develop a
program-guided generation technique to produce a large set of
human-interpretable visual cognition problems in action-oriented LOGO language.
Our benchmark captures three core properties of human cognition: 1)
context-dependent perception, in which the same object may have disparate
interpretations given different contexts; 2) analogy-making perception, in
which some meaningful concepts are traded off for other meaningful concepts;
and 3) perception with a few samples but infinite vocabulary. In experiments,
we show that the state-of-the-art deep learning methods perform substantially
worse than human subjects, implying that they fail to capture core human
cognition properties. Finally, we discuss research directions towards a general
architecture for visual reasoning to tackle this benchmark.
</p>
<a href="http://arxiv.org/abs/2010.00763" target="_blank">arXiv:2010.00763</a> [<a href="http://arxiv.org/pdf/2010.00763" target="_blank">pdf</a>]

<h2>A Multi-task Learning Framework for Opinion Triplet Extraction. (arXiv:2010.01512v2 [cs.CL] UPDATED)</h2>
<h3>Chen Zhang, Qiuchi Li, Dawei Song, Benyou Wang</h3>
<p>The state-of-the-art Aspect-based Sentiment Analysis (ABSA) approaches are
mainly based on either detecting aspect terms and their corresponding sentiment
polarities, or co-extracting aspect and opinion terms. However, the extraction
of aspect-sentiment pairs lacks opinion terms as a reference, while
co-extraction of aspect and opinion terms would not lead to meaningful pairs
without determining their sentiment dependencies. To address the issue, we
present a novel view of ABSA as an opinion triplet extraction task, and propose
a multi-task learning framework to jointly extract aspect terms and opinion
terms, and simultaneously parses sentiment dependencies between them with a
biaffine scorer. At inference phase, the extraction of triplets is facilitated
by a triplet decoding method based on the above outputs. We evaluate the
proposed framework on four SemEval benchmarks for ASBA. The results demonstrate
that our approach significantly outperforms a range of strong baselines and
state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2010.01512" target="_blank">arXiv:2010.01512</a> [<a href="http://arxiv.org/pdf/2010.01512" target="_blank">pdf</a>]

<h2>Pointwise Binary Classification with Pairwise Confidence Comparisons. (arXiv:2010.01875v2 [cs.LG] UPDATED)</h2>
<h3>Lei Feng, Senlin Shu, Nan Lu, Bo Han, Miao Xu, Gang Niu, Bo An, Masashi Sugiyama</h3>
<p>Ordinary (pointwise) binary classification aims to learn a binary classifier
from pointwise labeled data. However, such pointwise labels may not be directly
accessible due to privacy, confidentiality, or security considerations. In this
case, can we still learn an accurate binary classifier? This paper proposes a
novel setting, namely pairwise comparison (Pcomp) classification, where we are
given only pairs of unlabeled data that we know one is more likely to be
positive than the other, instead of pointwise labeled data. Pcomp
classification is useful for private or subjective classification tasks. To
solve this problem, we present a mathematical formulation for the generation
process of pairwise comparison data, based on which we exploit an unbiased risk
estimator (URE) to train a binary classifier by empirical risk minimization and
establish an estimation error bound. We first prove that a URE can be derived
and improve it using correction functions. Then, we start from the noisy-label
learning perspective to introduce a progressive URE and improve it by imposing
consistency regularization. Finally, experiments validate the effectiveness of
our proposed solutions for Pcomp classification.
</p>
<a href="http://arxiv.org/abs/2010.01875" target="_blank">arXiv:2010.01875</a> [<a href="http://arxiv.org/pdf/2010.01875" target="_blank">pdf</a>]

<h2>Reward Propagation Using Graph Convolutional Networks. (arXiv:2010.02474v2 [cs.LG] UPDATED)</h2>
<h3>Martin Klissarov, Doina Precup</h3>
<p>Potential-based reward shaping provides an approach for designing good reward
functions, with the purpose of speeding up learning. However, automatically
finding potential functions for complex environments is a difficult problem (in
fact, of the same difficulty as learning a value function from scratch). We
propose a new framework for learning potential functions by leveraging ideas
from graph representation learning. Our approach relies on Graph Convolutional
Networks which we use as a key ingredient in combination with the probabilistic
inference view of reinforcement learning. More precisely, we leverage Graph
Convolutional Networks to perform message passing from rewarding states. The
propagated messages can then be used as potential functions for reward shaping
to accelerate learning. We verify empirically that our approach can achieve
considerable improvements in both small and high-dimensional control problems.
</p>
<a href="http://arxiv.org/abs/2010.02474" target="_blank">arXiv:2010.02474</a> [<a href="http://arxiv.org/pdf/2010.02474" target="_blank">pdf</a>]

<h2>An Audio-Video Deep and Transfer Learning Framework for Multimodal Emotion Recognition in the wild. (arXiv:2010.03692v3 [cs.LG] UPDATED)</h2>
<h3>Denis Dresvyanskiy, Elena Ryumina, Heysem Kaya, Maxim Markitantov, Alexey Karpov, Wolfgang Minker</h3>
<p>In this paper, we present our contribution to ABAW facial expression
challenge. We report the proposed system and the official challenge results
adhering to the challenge protocol. Using end-to-end deep learning and
benefiting from transfer learning approaches, we reached a test set challenge
performance measure of 42.10%.
</p>
<a href="http://arxiv.org/abs/2010.03692" target="_blank">arXiv:2010.03692</a> [<a href="http://arxiv.org/pdf/2010.03692" target="_blank">pdf</a>]

<h2>Improving Long-Tail Relation Extraction with Collaborating Relation-Augmented Attention. (arXiv:2010.03773v2 [cs.CL] UPDATED)</h2>
<h3>Yang Li, Tao Shen, Guodong Long, Jing Jiang, Tianyi Zhou, Chengqi Zhang</h3>
<p>Wrong labeling problem and long-tail relations are two main challenges caused
by distant supervision in relation extraction. Recent works alleviate the wrong
labeling by selective attention via multi-instance learning, but cannot well
handle long-tail relations even if hierarchies of the relations are introduced
to share knowledge. In this work, we propose a novel neural network,
Collaborating Relation-augmented Attention (CoRA), to handle both the wrong
labeling and long-tail relations. Particularly, we first propose
relation-augmented attention network as base model. It operates on sentence bag
with a sentence-to-relation attention to minimize the effect of wrong labeling.
Then, facilitated by the proposed base model, we introduce collaborating
relation features shared among relations in the hierarchies to promote the
relation-augmenting process and balance the training data for long-tail
relations. Besides the main training objective to predict the relation of a
sentence bag, an auxiliary objective is utilized to guide the
relation-augmenting process for a more accurate bag-level representation. In
the experiments on the popular benchmark dataset NYT, the proposed CoRA
improves the prior state-of-the-art performance by a large margin in terms of
Precision@N, AUC and Hits@K. Further analyses verify its superior capability in
handling long-tail relations in contrast to the competitors.
</p>
<a href="http://arxiv.org/abs/2010.03773" target="_blank">arXiv:2010.03773</a> [<a href="http://arxiv.org/pdf/2010.03773" target="_blank">pdf</a>]

<h2>Dissecting Hessian: Understanding Common Structure of Hessian in Neural Networks. (arXiv:2010.04261v2 [cs.LG] UPDATED)</h2>
<h3>Yikai Wu, Xingyu Zhu, Chenwei Wu, Annie Wang, Rong Ge</h3>
<p>Hessian captures important properties of the deep neural network loss
landscape. We observe that eigenvectors and eigenspaces of the layer-wise
Hessian for neural network objective have several interesting structures -- top
eigenspaces for different models have high overlap, and top eigenvectors form
low rank matrices when they are reshaped into the same shape as the
corresponding weight matrix. These structures, as well as the low rank
structure of the Hessian observed in previous studies, can be explained by
approximating the Hessian using Kronecker factorization. Our new understanding
can also explain why some of these structures become weaker when the network is
trained with batch normalization. Finally, we show that the Kronecker
factorization can be combined with PAC-Bayes techniques to get better explicit
generalization bounds.
</p>
<a href="http://arxiv.org/abs/2010.04261" target="_blank">arXiv:2010.04261</a> [<a href="http://arxiv.org/pdf/2010.04261" target="_blank">pdf</a>]

<h2>A Practical Guide to Graph Neural Networks. (arXiv:2010.05234v2 [cs.LG] UPDATED)</h2>
<h3>Isaac Ronald Ward, Jack Joyner, Casey Lickfold, Stash Rowe, Yulan Guo, Mohammed Bennamoun</h3>
<p>Graph neural networks (GNNs) have recently grown in popularity in the field
of artificial intelligence due to their unique ability to ingest relatively
unstructured data types as input data. Although some elements of the GNN
architecture are conceptually similar in operation to traditional neural
networks (and neural network variants), other elements represent a departure
from traditional deep learning techniques. This tutorial exposes the power and
novelty of GNNs to the average deep learning enthusiast by collating and
presenting details on the motivations, concepts, mathematics, and applications
of the most common types of GNNs. Importantly, we present this tutorial
concisely, alongside worked code examples, and at an introductory pace, thus
providing a practical and accessible guide to understanding and using GNNs.
</p>
<a href="http://arxiv.org/abs/2010.05234" target="_blank">arXiv:2010.05234</a> [<a href="http://arxiv.org/pdf/2010.05234" target="_blank">pdf</a>]

<h2>Efficient Wasserstein Natural Gradients for Reinforcement Learning. (arXiv:2010.05380v2 [cs.LG] UPDATED)</h2>
<h3>Ted Moskovitz, Michael Arbel, Ferenc Huszar, Arthur Gretton</h3>
<p>A novel optimization approach is proposed for application to policy gradient
methods and evolution strategies for reinforcement learning (RL). The procedure
uses a computationally efficient Wasserstein natural gradient (WNG) descent
that takes advantage of the geometry induced by a Wasserstein penalty to speed
optimization. This method follows the recent theme in RL of including a
divergence penalty in the objective to establish a trust region. Experiments on
challenging tasks demonstrate improvements in both computational cost and
performance over advanced baselines.
</p>
<a href="http://arxiv.org/abs/2010.05380" target="_blank">arXiv:2010.05380</a> [<a href="http://arxiv.org/pdf/2010.05380" target="_blank">pdf</a>]

<h2>UAV Path Planning using Global and Local Map Information with Deep Reinforcement Learning. (arXiv:2010.06917v2 [cs.RO] UPDATED)</h2>
<h3>Mirco Theile, Harald Bayerlein, Richard Nai, David Gesbert, Marco Caccamo</h3>
<p>Path planning methods for autonomous unmanned aerial vehicles (UAVs) are
typically designed for one specific type of mission. In this work, we present a
method for autonomous UAV path planning based on deep reinforcement learning
(DRL) that can be applied to a wide range of mission scenarios. Specifically,
we compare coverage path planning (CPP), where the UAV's goal is to survey an
area of interest to data harvesting (DH), where the UAV collects data from
distributed Internet of Things (IoT) sensor devices. By exploiting structured
map information of the environment, we train double deep Q-networks (DDQNs)
with identical architectures on both distinctly different mission scenarios, to
make movement decisions that balance the respective mission goal with
navigation constraints. By introducing a novel approach exploiting a compressed
global map of the environment combined with a cropped but uncompressed local
map showing the vicinity of the UAV agent, we demonstrate that the proposed
method can efficiently scale to large environments. We also extend previous
results for generalizing control policies that require no retraining when
scenario parameters change and offer a detailed analysis of crucial map
processing parameters' effects on path planning performance.
</p>
<a href="http://arxiv.org/abs/2010.06917" target="_blank">arXiv:2010.06917</a> [<a href="http://arxiv.org/pdf/2010.06917" target="_blank">pdf</a>]

<h2>Pair the Dots: Jointly Examining Training History and Test Stimuli for Model Interpretability. (arXiv:2010.06943v2 [cs.CL] UPDATED)</h2>
<h3>Yuxian Meng, Chun Fan, Zijun Sun, Eduard Hovy, Fei Wu, Jiwei Li</h3>
<p>Any prediction from a model is made by a combination of learning history and
test stimuli. This provides significant insights for improving model
interpretability: {\it because of which part(s) of which training example(s),
the model attends to which part(s) of a test example}. Unfortunately, existing
methods to interpret a model's predictions are only able to capture a single
aspect of either test stimuli or learning history, and evidences from both are
never combined or integrated. In this paper, we propose an efficient and
differentiable approach to make it feasible to interpret a model's prediction
by jointly examining training history and test stimuli. Test stimuli is first
identified by gradient-based methods, signifying {\it the part of a test
example that the model attends to}. The gradient-based saliency scores are then
propagated to training examples using influence functions to identify {\it
which part(s) of which training example(s)} make the model attends to the test
stimuli. The system is differentiable and time efficient: the adoption of
saliency scores from gradient-based methods allows us to efficiently trace a
model's prediction through test stimuli, and then back to training examples
through influence functions. We demonstrate that the proposed methodology
offers clear explanations about neural model decisions, along with being useful
for performing error analysis, crafting adversarial examples and fixing
erroneously classified examples.
</p>
<a href="http://arxiv.org/abs/2010.06943" target="_blank">arXiv:2010.06943</a> [<a href="http://arxiv.org/pdf/2010.06943" target="_blank">pdf</a>]

<h2>Learning Deep Features in Instrumental Variable Regression. (arXiv:2010.07154v3 [cs.LG] UPDATED)</h2>
<h3>Liyuan Xu, Yutian Chen, Siddarth Srinivasan, Nando de Freitas, Arnaud Doucet, Arthur Gretton</h3>
<p>Instrumental variable (IV) regression is a standard strategy for learning
causal relationships between confounded treatment and outcome variables from
observational data by utilizing an instrumental variable, which affects the
outcome only through the treatment. In classical IV regression, learning
proceeds in two stages: stage 1 performs linear regression from the instrument
to the treatment; and stage 2 performs linear regression from the treatment to
the outcome, conditioned on the instrument. We propose a novel method, deep
feature instrumental variable regression (DFIV), to address the case where
relations between instruments, treatments, and outcomes may be nonlinear. In
this case, deep neural nets are trained to define informative nonlinear
features on the instruments and treatments. We propose an alternating training
regime for these features to ensure good end-to-end performance when composing
stages 1 and 2, thus obtaining highly flexible feature maps in a
computationally efficient manner. DFIV outperforms recent state-of-the-art
methods on challenging IV benchmarks, including settings involving high
dimensional image data. DFIV also exhibits competitive performance in
off-policy policy evaluation for reinforcement learning, which can be
understood as an IV regression task.
</p>
<a href="http://arxiv.org/abs/2010.07154" target="_blank">arXiv:2010.07154</a> [<a href="http://arxiv.org/pdf/2010.07154" target="_blank">pdf</a>]

<h2>Deep Learning in Ultrasound Elastography Imaging. (arXiv:2010.07360v2 [eess.IV] UPDATED)</h2>
<h3>Hongliang Li, Manish Bhatt, Zhen Qu, Shiming Zhang, Martin C. Hartel, Ali Khademhosseini, Guy Cloutier</h3>
<p>It is known that changes in the mechanical properties of tissues are
associated with the onset and progression of certain diseases. Ultrasound
elastography is a technique to characterize tissue stiffness using ultrasound
imaging either by measuring tissue strain using quasi-static elastography or
natural organ pulsation elastography, or by tracing a propagated shear wave
induced by a source or a natural vibration using dynamic elastography. In
recent years, deep learning has begun to emerge in ultrasound elastography
research. In this review, several common deep learning frameworks in the
computer vision community, such as multilayer perceptron, convolutional neural
network, and recurrent neural network are described. Then, recent advances in
ultrasound elastography using such deep learning techniques are revisited in
terms of algorithm development and clinical diagnosis. Finally, the current
challenges and future developments of deep learning in ultrasound elastography
are prospected.
</p>
<a href="http://arxiv.org/abs/2010.07360" target="_blank">arXiv:2010.07360</a> [<a href="http://arxiv.org/pdf/2010.07360" target="_blank">pdf</a>]

<h2>Solar Coronal Magnetic Field Extrapolation from Synchronic Data with AI-generated Farside. (arXiv:2010.07553v3 [astro-ph.SR] UPDATED)</h2>
<h3>Hyun-Jin Jeong, Yong-Jae Moon, Eunsu Park, Harim Lee</h3>
<p>Solar magnetic fields play a key role in understanding the nature of the
coronal phenomena. Global coronal magnetic fields are usually extrapolated from
photospheric fields, for which farside data is taken when it was at the
frontside, about two weeks earlier. For the first time we have constructed the
extrapolations of global magnetic fields using frontside and artificial
intelligence (AI)-generated farside magnetic fields at a near-real time basis.
We generate the farside magnetograms from three channel farside observations of
Solar Terrestrial Relations Observatory (STEREO) Ahead (A) and Behind (B) by
our deep learning model trained with frontside Solar Dynamics Observatory
extreme ultraviolet images and magnetograms. For frontside testing data sets,
we demonstrate that the generated magnetic field distributions are consistent
with the real ones; not only active regions (ARs), but also quiet regions of
the Sun. We make global magnetic field synchronic maps in which conventional
farside data are replaced by farside ones generated by our model. The
synchronic maps show much better not only the appearance of ARs but also the
disappearance of others on the solar surface than before. We use these
synchronized magnetic data to extrapolate the global coronal fields using
Potential Field Source Surface (PFSS) model. We show that our results are much
more consistent with coronal observations than those of the conventional method
in view of solar active regions and coronal holes. We present several positive
prospects of our new methodology for the study of solar corona, heliosphere,
and space weather.
</p>
<a href="http://arxiv.org/abs/2010.07553" target="_blank">arXiv:2010.07553</a> [<a href="http://arxiv.org/pdf/2010.07553" target="_blank">pdf</a>]

<h2>Semantics of the Black-Box: Can knowledge graphs help make deep learning systems more interpretable and explainable?. (arXiv:2010.08660v2 [cs.AI] UPDATED)</h2>
<h3>Manas Gaur, Keyur Faldu, Amit Sheth</h3>
<p>The recent series of innovations in deep learning (DL) have shown enormous
potential to impact individuals and society, both positively and negatively.
The DL models utilizing massive computing power and enormous datasets have
significantly outperformed prior historical benchmarks on increasingly
difficult, well-defined research tasks across technology domains such as
computer vision, natural language processing, signal processing, and
human-computer interactions. However, the Black-Box nature of DL models and
their over-reliance on massive amounts of data condensed into labels and dense
representations poses challenges for interpretability and explainability of the
system. Furthermore, DLs have not yet been proven in their ability to
effectively utilize relevant domain knowledge and experience critical to human
understanding. This aspect is missing in early data-focused approaches and
necessitated knowledge-infused learning and other strategies to incorporate
computational knowledge. This article demonstrates how knowledge, provided as a
knowledge graph, is incorporated into DL methods using knowledge-infused
learning, which is one of the strategies. We then discuss how this makes a
fundamental difference in the interpretability and explainability of current
approaches, and illustrate it with examples from natural language processing
for healthcare and education applications.
</p>
<a href="http://arxiv.org/abs/2010.08660" target="_blank">arXiv:2010.08660</a> [<a href="http://arxiv.org/pdf/2010.08660" target="_blank">pdf</a>]

<h2>Belief-Grounded Networks for Accelerated Robot Learning under Partial Observability. (arXiv:2010.09170v3 [cs.RO] UPDATED)</h2>
<h3>Hai Nguyen, Brett Daley, Xinchao Song, Christopher Amato, Robert Platt</h3>
<p>Many important robotics problems are partially observable in the sense that a
single visual or force-feedback measurement is insufficient to reconstruct the
state. Standard approaches involve learning a policy over beliefs or
observation-action histories. However, both of these have drawbacks; it is
expensive to track the belief online, and it is hard to learn policies directly
over histories. We propose a method for policy learning under partial
observability called the Belief-Grounded Network (BGN) in which an auxiliary
belief-reconstruction loss incentivizes a neural network to concisely summarize
its input history. Since the resulting policy is a function of the history
rather than the belief, it can be executed easily at runtime. We compare BGN
against several baselines on classic benchmark tasks as well as three novel
robotic touch-sensing tasks. BGN outperforms all other tested methods and its
learned policies work well when transferred onto a physical robot.
</p>
<a href="http://arxiv.org/abs/2010.09170" target="_blank">arXiv:2010.09170</a> [<a href="http://arxiv.org/pdf/2010.09170" target="_blank">pdf</a>]

<h2>Tensor-based Intrinsic Subspace Representation Learning for Multi-view Clustering. (arXiv:2010.09193v3 [cs.LG] UPDATED)</h2>
<h3>Qinghai Zheng, Jihua Zhu, Zhongyu Li, Haoyu Tang, Shuangxun Ma</h3>
<p>Multi-view subspace clustering is an important and hot topic in machine
learning field, which aims to promote clustering results based on multi-view
data, which are collected from different domains or various measurements. In
this paper, we propose a novel tensor-based intrinsic subspace representation
learning for multi-view clustering. Specifically, to investigate the underlying
subspace representation, the rank preserving decomposition accompanied with the
tensor-singular value decomposition based low-rank tensor constraint is
introduced and applied on the subspace representation matrices of multiple
views. The specific information of different views can be considered by the
rank preserving decomposition and the high-order correlations of multi-view
data are fully explored by the low-rank tensor constraint in our method. Based
on the learned subspace representation, clustering results can be obtained by
employing the standard spectral clustering algorithm. The objective function is
efficiently optimized by utilizing the augmented Lagrangian multiplier based
alternating direction minimization algorithm. Experimental results on nine
real-world datasets illustrate the superiority of our method compared to
several state-of-the-arts.
</p>
<a href="http://arxiv.org/abs/2010.09193" target="_blank">arXiv:2010.09193</a> [<a href="http://arxiv.org/pdf/2010.09193" target="_blank">pdf</a>]

<h2>Probabilistic selection of inducing points in sparse Gaussian processes. (arXiv:2010.09370v3 [cs.LG] UPDATED)</h2>
<h3>Anders Kirk Uhrenholt, Valentin Charvet, Bj&#xf8;rn Sand Jensen</h3>
<p>Sparse Gaussian processes and various extensions thereof are enabled through
inducing points, that simultaneously bottleneck the predictive capacity and act
as the main contributor towards model complexity. However, the number of
inducing points is generally not associated with uncertainty which prevents us
from applying the apparatus of Bayesian reasoning in identifying an appropriate
trade-off. In this work we place a point process prior on the inducing points
and approximate the associated posterior through stochastic variational
inference. By letting the prior encourage a moderate number of inducing points,
we enable the model to learn which and how many points to utilise. We
experimentally show that fewer inducing points are preferred by the model as
the points become less informative, and further demonstrate how the method can
be applied in deep Gaussian processes and latent variable modelling.
</p>
<a href="http://arxiv.org/abs/2010.09370" target="_blank">arXiv:2010.09370</a> [<a href="http://arxiv.org/pdf/2010.09370" target="_blank">pdf</a>]

<h2>SMARTS: Scalable Multi-Agent Reinforcement Learning Training School for Autonomous Driving. (arXiv:2010.09776v2 [cs.MA] UPDATED)</h2>
<h3>Ming Zhou, Jun Luo, Julian Villella, Yaodong Yang, David Rusu, Jiayu Miao, Weinan Zhang, Montgomery Alban, Iman Fadakar, Zheng Chen, Aurora Chongxi Huang, Ying Wen, Kimia Hassanzadeh, Daniel Graves, Dong Chen, Zhengbang Zhu, Nhat Nguyen, Mohamed Elsayed, Kun Shao, Sanjeevan Ahilan, Baokuan Zhang, Jiannan Wu, Zhengang Fu, Kasra Rezaee, Peyman Yadmellat, Mohsen Rohani, Nicolas Perez Nieves, Yihan Ni, Seyedershad Banijamali, Alexander Cowen Rivers, Zheng Tian, Daniel Palenicek, Haitham bou Ammar, Hongbo Zhang, Wulong Liu, Jianye Hao, Jun Wang</h3>
<p>Multi-agent interaction is a fundamental aspect of autonomous driving in the
real world. Despite more than a decade of research and development, the problem
of how to competently interact with diverse road users in diverse scenarios
remains largely unsolved. Learning methods have much to offer towards solving
this problem. But they require a realistic multi-agent simulator that generates
diverse and competent driving interactions. To meet this need, we develop a
dedicated simulation platform called SMARTS (Scalable Multi-Agent RL Training
School). SMARTS supports the training, accumulation, and use of diverse
behavior models of road users. These are in turn used to create increasingly
more realistic and diverse interactions that enable deeper and broader research
on multi-agent interaction. In this paper, we describe the design goals of
SMARTS, explain its basic architecture and its key features, and illustrate its
use through concrete multi-agent experiments on interactive scenarios. We
open-source the SMARTS platform and the associated benchmark tasks and
evaluation metrics to encourage and empower research on multi-agent learning
for autonomous driving. Our code is available at
https://github.com/huawei-noah/SMARTS.
</p>
<a href="http://arxiv.org/abs/2010.09776" target="_blank">arXiv:2010.09776</a> [<a href="http://arxiv.org/pdf/2010.09776" target="_blank">pdf</a>]

<h2>Robust Imitation Learning from Noisy Demonstrations. (arXiv:2010.10181v2 [stat.ML] UPDATED)</h2>
<h3>Voot Tangkaratt, Nontawat Charoenphakdee, Masashi Sugiyama</h3>
<p>Learning from noisy demonstrations is a practical but highly challenging
problem in imitation learning. In this paper, we first theoretically show that
robust imitation learning can be achieved by optimizing a classification risk
with a symmetric loss. Based on this theoretical finding, we then propose a new
imitation learning method that optimizes the classification risk by effectively
combining pseudo-labeling with co-training. Unlike existing methods, our method
does not require additional labels or strict assumptions about noise
distributions. Experimental results on continuous-control benchmarks show that
our method is more robust compared to state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.10181" target="_blank">arXiv:2010.10181</a> [<a href="http://arxiv.org/pdf/2010.10181" target="_blank">pdf</a>]

<h2>A Level-wise Taxonomic Perspective on Automated Machine Learning to Date and Beyond: Challenges and Opportunities. (arXiv:2010.10777v3 [cs.LG] UPDATED)</h2>
<h3>Shubhra Kanti Karmaker Santu, Md. Mahadi Hassan, Micah J. Smith, Lei Xu, ChengXiang Zhai, Kalyan Veeramachaneni</h3>
<p>Automated machine learning (AutoML) is essentially automating the process of
applying machine learning to real-world problems. The primary goals of AutoML
tools are to provide methods and processes to make Machine Learning available
for non-Machine Learning experts (domain experts), to improve efficiency of
Machine Learning and to accelerate research on Machine Learning. Although
automation and efficiency are some of AutoML's main selling points, the process
still requires a surprising level of human involvement. A number of vital steps
of the machine learning pipeline, including understanding the attributes of
domain-specific data, defining prediction problems, creating a suitable
training data set etc. still tend to be done manually by a data scientist on an
ad-hoc basis. Often, this process requires a lot of back-and-forth between the
data scientist and domain experts, making the whole process more difficult and
inefficient. Altogether, AutoML systems are still far from a "real automatic
system". In this review article, we present a level-wise taxonomic perspective
on AutoML systems to-date and beyond, i.e., we introduce a new classification
system with seven levels to distinguish AutoML systems based on their level of
autonomy. We first start with a discussion on how an end-to-end Machine
learning pipeline actually looks like and which sub-tasks of Machine learning
Pipeline has indeed been automated so far. Next, we highlight the sub-tasks
which are still done manually by a data-scientist in most cases and how that
limits a domain expert's access to Machine learning. Then, we introduce the
novel level-based taxonomy of AutoML systems and define each level according to
their scope of automation support. Finally, we provide a road-map of future
research endeavor in the area of AutoML and discuss some important challenges
in achieving this ambitious goal.
</p>
<a href="http://arxiv.org/abs/2010.10777" target="_blank">arXiv:2010.10777</a> [<a href="http://arxiv.org/pdf/2010.10777" target="_blank">pdf</a>]

<h2>Learning Transferrable Parameters for Long-tailed Sequential User Behavior Modeling. (arXiv:2010.11401v2 [cs.LG] UPDATED)</h2>
<h3>Jianwen Yin, Chenghao Liu, Weiqing Wang, Jianling Sun, Steven C.H. Hoi</h3>
<p>Sequential user behavior modeling plays a crucial role in online
user-oriented services, such as product purchasing, news feed consumption, and
online advertising. The performance of sequential modeling heavily depends on
the scale and quality of historical behaviors. However, the number of user
behaviors inherently follows a long-tailed distribution, which has been seldom
explored. In this work, we argue that focusing on tail users could bring more
benefits and address the long tails issue by learning transferrable parameters
from both optimization and feature perspectives. Specifically, we propose a
gradient alignment optimizer and adopt an adversarial training scheme to
facilitate knowledge transfer from the head to the tail. Such methods can also
deal with the cold-start problem of new users. Moreover, it could be directly
adaptive to various well-established sequential models. Extensive experiments
on four real-world datasets verify the superiority of our framework compared
with the state-of-the-art baselines.
</p>
<a href="http://arxiv.org/abs/2010.11401" target="_blank">arXiv:2010.11401</a> [<a href="http://arxiv.org/pdf/2010.11401" target="_blank">pdf</a>]

<h2>Classification with Rejection Based on Cost-sensitive Classification. (arXiv:2010.11748v2 [stat.ML] UPDATED)</h2>
<h3>Nontawat Charoenphakdee, Zhenghang Cui, Yivan Zhang, Masashi Sugiyama</h3>
<p>The goal of classification with rejection is to avoid risky misclassification
in error-critical applications such as medical diagnosis and product
inspection. In this paper, based on the relationship between classification
with rejection and cost-sensitive classification, we propose a novel method of
classification with rejection by learning an ensemble of cost-sensitive
classifiers, which satisfies all the following properties for the first time:
(i) it can avoid estimating class-posterior probabilities, resulting in
improved classification accuracy. (ii) it allows a flexible choice of losses
including non-convex ones, (iii) it does not require complicated modifications
when using different losses, (iv) it is applicable to both binary and
multiclass cases, and (v) it is theoretically justifiable for any
classification-calibrated loss. Experimental results demonstrate the usefulness
of our proposed approach in clean-labeled, noisy-labeled, and
positive-unlabeled classification.
</p>
<a href="http://arxiv.org/abs/2010.11748" target="_blank">arXiv:2010.11748</a> [<a href="http://arxiv.org/pdf/2010.11748" target="_blank">pdf</a>]

<h2>AutoPruning for Deep Neural Network with Dynamic Channel Masking. (arXiv:2010.12021v2 [cs.CV] UPDATED)</h2>
<h3>Baopu Li, Yanwen Fan, Zhihong Pan, Gang Zhang</h3>
<p>Modern deep neural network models are large and computationally intensive.
One typical solution to this issue is model pruning. However, most current
pruning algorithms depend on hand crafted rules or domain expertise. To
overcome this problem, we propose a learning based auto pruning algorithm for
deep neural network, which is inspired by recent automatic machine
learning(AutoML). A two objectives' problem that aims for the the weights and
the best channels for each layer is first formulated. An alternative
optimization approach is then proposed to derive the optimal channel numbers
and weights simultaneously. In the process of pruning, we utilize a searchable
hyperparameter, remaining ratio, to denote the number of channels in each
convolution layer, and then a dynamic masking process is proposed to describe
the corresponding channel evolution. To control the trade-off between the
accuracy of a model and the pruning ratio of floating point operations, a novel
loss function is further introduced. Preliminary experimental results on
benchmark datasets demonstrate that our scheme achieves competitive results for
neural network pruning.
</p>
<a href="http://arxiv.org/abs/2010.12021" target="_blank">arXiv:2010.12021</a> [<a href="http://arxiv.org/pdf/2010.12021" target="_blank">pdf</a>]

<h2>Cloud Energy Micro-Moment Data Classification: A Platform Study. (arXiv:2010.12064v2 [cs.DC] UPDATED)</h2>
<h3>Abdullah Alsalemi, Ayman Al-Kababji, Yassine Himeur, Faycal Bensaali, Abbes Amira</h3>
<p>Energy efficiency is a crucial factor in the well-being of our planet. In
parallel, Machine Learning (ML) plays an instrumental role in automating our
lives and creating convenient workflows for enhancing behavior. So, analyzing
energy behavior can help understand weak points and lay the path towards better
interventions. Moving towards higher performance, cloud platforms can assist
researchers in conducting classification trials that need high computational
power. Under the larger umbrella of the Consumer Engagement Towards Energy
Saving Behavior by means of Exploiting Micro Moments and Mobile Recommendation
Systems (EM)3 framework, we aim to influence consumers behavioral change via
improving their power consumption consciousness. In this paper, common cloud
artificial intelligence platforms are benchmarked and compared for micro-moment
classification. The Amazon Web Services, Google Cloud Platform, Google Colab,
and Microsoft Azure Machine Learning are employed on simulated and real energy
consumption datasets. The KNN, DNN, and SVM classifiers have been employed.
Superb performance has been observed in the selected cloud platforms, showing
relatively close performance. Yet, the nature of some algorithms limits the
training performance.
</p>
<a href="http://arxiv.org/abs/2010.12064" target="_blank">arXiv:2010.12064</a> [<a href="http://arxiv.org/pdf/2010.12064" target="_blank">pdf</a>]

<h2>Electromagnetic Source Imaging via a Data-Synthesis-Based Denoising Autoencoder. (arXiv:2010.12876v2 [eess.IV] UPDATED)</h2>
<h3>Gexin Huang, Zhu Liang Yu, Wei Wu, Ke Liu, Zheng Hui Gu, Feifei Qi, YuanQing Li, Jiawen Liang</h3>
<p>Electromagnetic source imaging (ESI) is a highly ill-posed inverse problem.
To find a unique solution, traditional ESI methods impose a variety of priors
that may not reflect the actual source properties. Such limitations of
traditional ESI methods hinder their further applications. Inspired by deep
learning approaches, a novel data-synthesized spatio-temporal denoising
autoencoder method (DST-DAE) method was proposed to solve the ESI inverse
problem. Unlike the traditional methods, we utilize a neural network to
directly seek generalized mapping from the measured E/MEG signals to the
cortical sources. A novel data synthesis strategy is employed by introducing
the prior information of sources to the generated large-scale samples using the
forward model of ESI. All the generated data are used to drive the neural
network to automatically learn inverse mapping. To achieve better estimation
performance, a denoising autoencoder (DAE) architecture with spatio-temporal
feature extraction blocks is designed. Compared with the traditional methods,
we show (1) that the novel deep learning approach provides an effective and
easy-to-apply way to solve the ESI problem, that (2) compared to traditional
methods, DST-DAE with the data synthesis strategy can better consider the
characteristics of real sources than the mathematical formulation of prior
assumptions, and that (3) the specifically designed architecture of DAE can not
only provide a better estimation of source signals but also be robust to noise
pollution. Extensive numerical experiments show that the proposed method is
superior to the traditional knowledge-driven ESI methods.
</p>
<a href="http://arxiv.org/abs/2010.12876" target="_blank">arXiv:2010.12876</a> [<a href="http://arxiv.org/pdf/2010.12876" target="_blank">pdf</a>]

<h2>Adaptive Federated Learning and Digital Twin for Industrial Internet of Things. (arXiv:2010.13058v2 [cs.LG] UPDATED)</h2>
<h3>Wen Sun, Shiyu Lei, Lu Wang, Zhiqiang Liu, Yan Zhang</h3>
<p>Industrial Internet of Things (IoT) enables distributed intelligent services
varying with the dynamic and realtime industrial devices to achieve Industry
4.0 benefits. In this paper, we consider a new architecture of digital twin
empowered Industrial IoT where digital twins capture the characteristics of
industrial devices to assist federated learning. Noticing that digital twins
may bring estimation deviations from the actual value of device state, a
trusted based aggregation is proposed in federated learning to alleviate the
effects of such deviation. We adaptively adjust the aggregation frequency of
federated learning based on Lyapunov dynamic deficit queue and deep
reinforcement learning, to improve the learning performance under the resource
constraints. To further adapt to the heterogeneity of Industrial IoT, a
clustering-based asynchronous federated learning framework is proposed.
Numerical results show that the proposed framework is superior to the benchmark
in terms of learning accuracy, convergence, and energy saving.
</p>
<a href="http://arxiv.org/abs/2010.13058" target="_blank">arXiv:2010.13058</a> [<a href="http://arxiv.org/pdf/2010.13058" target="_blank">pdf</a>]

<h2>Monocular Depth Estimation via Listwise Ranking using the Plackett-Luce Model. (arXiv:2010.13118v3 [cs.CV] UPDATED)</h2>
<h3>Julian Lienen, Eyke H&#xfc;llermeier</h3>
<p>In many real-world applications, the relative depth of objects in an image is
crucial for scene understanding, e.g., to calculate occlusions in augmented
reality scenes. Predicting depth in monocular images has recently been tackled
using machine learning methods, mainly by treating the problem as a regression
task. Yet, being interested in an order relation in the first place, ranking
methods suggest themselves as a natural alternative to regression, and indeed,
ranking approaches leveraging pairwise comparisons as training information
("object A is closer to the camera than B") have shown promising performance on
this problem. In this paper, we elaborate on the use of so-called listwise
ranking as a generalization of the pairwise approach. Listwise ranking goes
beyond pairwise comparisons between objects and considers rankings of arbitrary
length as training information. Our approach is based on the Plackett-Luce
model, a probability distribution on rankings, which we combine with a
state-of-the-art neural network architecture and a sampling strategy to reduce
training complexity. An empirical evaluation on benchmark data in a "zero-shot"
setting demonstrates the effectiveness of our proposal compared to existing
ranking and regression methods.
</p>
<a href="http://arxiv.org/abs/2010.13118" target="_blank">arXiv:2010.13118</a> [<a href="http://arxiv.org/pdf/2010.13118" target="_blank">pdf</a>]

<h2>Deep Sequential Learning for Cervical Spine Fracture Detection on Computed Tomography Imaging. (arXiv:2010.13336v3 [eess.IV] UPDATED)</h2>
<h3>Hojjat Salehinejad, Edward Ho, Hui-Ming Lin, Priscila Crivellaro, Oleksandra Samorodova, Monica Tafur Arciniegas, Zamir Merali, Suradech Suthiphosuwan, Aditya Bharatha, Kristen Yeom, Muhammad Mamdani, Jefferson Wilson, Errol Colak</h3>
<p>Fractures of the cervical spine are a medical emergency and may lead to
permanent paralysis and even death. Accurate diagnosis in patients with
suspected fractures by computed tomography (CT) is critical to patient
management. In this paper, we propose a deep convolutional neural network
(DCNN) with a bidirectional long-short term memory (BLSTM) layer for the
automated detection of cervical spine fractures in CT axial images. We used an
annotated dataset of 3,666 CT scans (729 positive and 2,937 negative cases) to
train and validate the model. The validation results show a classification
accuracy of 70.92% and 79.18% on the balanced (104 positive and 104 negative
cases) and imbalanced (104 positive and 419 negative cases) test datasets,
respectively.
</p>
<a href="http://arxiv.org/abs/2010.13336" target="_blank">arXiv:2010.13336</a> [<a href="http://arxiv.org/pdf/2010.13336" target="_blank">pdf</a>]

<h2>High Acceleration Reinforcement Learning for Real-World Juggling with Binary Rewards. (arXiv:2010.13483v3 [cs.RO] UPDATED)</h2>
<h3>Kai Ploeger, Michael Lutter, Jan Peters</h3>
<p>Robots that can learn in the physical world will be important to en-able
robots to escape their stiff and pre-programmed movements. For dynamic
high-acceleration tasks, such as juggling, learning in the real-world is
particularly challenging as one must push the limits of the robot and its
actuation without harming the system, amplifying the necessity of sample
efficiency and safety for robot learning algorithms. In contrast to prior work
which mainly focuses on the learning algorithm, we propose a learning system,
that directly incorporates these requirements in the design of the policy
representation, initialization, and optimization. We demonstrate that this
system enables the high-speed Barrett WAM manipulator to learn juggling two
balls from 56 minutes of experience with a binary reward signal. The final
policy juggles continuously for up to 33 minutes or about 4500 repeated
catches. The videos documenting the learning process and the evaluation can be
found at https://sites.google.com/view/jugglingbot
</p>
<a href="http://arxiv.org/abs/2010.13483" target="_blank">arXiv:2010.13483</a> [<a href="http://arxiv.org/pdf/2010.13483" target="_blank">pdf</a>]

<h2>On the intrinsic robustness to noise of some leading classifiers and symetric loss function -- an empirical evaluation. (arXiv:2010.13570v2 [cs.LG] UPDATED)</h2>
<h3>Hugo Le Baher (1), Vincent Lemaire (2), Romain Trinquart (2) ((1) Polytech Nantes (France), (2) Orange Labs (France))</h3>
<p>In some industrial application as fraud detection common supervision
techniques may not be efficient because they rely on the quality of labels. In
concrete cases, these labels may be weak in quantity, quality or
trustworthiness. We propose a benchmark to evaluate the natural robustness of
various algorithms taken from various paradigms on artificially corrupted
datasets with a focus on noisy labels. This paper studies the intrinsic
robustness of some leading classifiers and, taken the result from recent
literature, how symmetric loss function may help.
</p>
<a href="http://arxiv.org/abs/2010.13570" target="_blank">arXiv:2010.13570</a> [<a href="http://arxiv.org/pdf/2010.13570" target="_blank">pdf</a>]

<h2>Continuous Lyapunov Controller and Chaotic Non-linear System Optimization using Deep Machine Learning. (arXiv:2010.14746v2 [eess.SY] UPDATED)</h2>
<h3>Amr Mahmoud, Youmna Ismaeil, Mohamed Zohdy</h3>
<p>The introduction of unexpected system disturbances and new system dynamics
does not allow initially selected static system and controller parameters to
guarantee continued system stability and performance. In this research we
present a novel approach for detecting early failure indicators of non-linear
highly chaotic system and accordingly predict the best parameter calibrations
to offset such instability using deep machine learning regression model. The
approach proposed continuously monitors the system and controller signals. The
Re-calibration of the system and controller parameters is triggered according
to a set of conditions designed to maintain system stability without compromise
to the system speed, intended outcome or required processing power. The deep
neural model predicts the parameter values that would best counteract the
expected system in-stability. To demonstrate the effectiveness of the proposed
approach, it is applied to the non-linear complex combination of Duffing Van
der pol oscillators. The approach is also tested under different scenarios the
system and controller parameters are initially chosen incorrectly or the system
parameters are changed while running or new system dynamics are introduced
while running to measure effectiveness and reaction time.
</p>
<a href="http://arxiv.org/abs/2010.14746" target="_blank">arXiv:2010.14746</a> [<a href="http://arxiv.org/pdf/2010.14746" target="_blank">pdf</a>]

<h2>Fine-grained Information Status Classification Using Discourse Context-Aware BERT. (arXiv:2010.14759v2 [cs.CL] UPDATED)</h2>
<h3>Yufang Hou</h3>
<p>Previous work on bridging anaphora recognition (Hou et al., 2013a) casts the
problem as a subtask of learning fine-grained information status (IS). However,
these systems heavily depend on many hand-crafted linguistic features. In this
paper, we propose a simple discourse context-aware BERT model for fine-grained
IS classification. On the ISNotes corpus (Markert et al., 2012), our model
achieves new state-of-the-art performance on fine-grained IS classification,
obtaining a 4.8 absolute overall accuracy improvement compared to Hou et al.
(2013a). More importantly, we also show an improvement of 10.5 F1 points for
bridging anaphora recognition without using any complex hand-crafted semantic
features designed for capturing the bridging phenomenon. We further analyze the
trained model and find that the most attended signals for each IS category
correspond well to linguistic notions of information status.
</p>
<a href="http://arxiv.org/abs/2010.14759" target="_blank">arXiv:2010.14759</a> [<a href="http://arxiv.org/pdf/2010.14759" target="_blank">pdf</a>]

<h2>Smart Anomaly Detection in Sensor Systems: A Multi-Perspective Review. (arXiv:2010.14946v2 [cs.LG] UPDATED)</h2>
<h3>L. Erhan, M. Ndubuaku, M. Di Mauro, W. Song, M. Chen, G. Fortino, O. Bagdasar, A. Liotta</h3>
<p>Anomaly detection is concerned with identifying data patterns that deviate
remarkably from the expected behaviour. This is an important research problem,
due to its broad set of application domains, from data analysis to e-health,
cybersecurity, predictive maintenance, fault prevention, and industrial
automation. Herein, we review state-of-the-art methods that may be employed to
detect anomalies in the specific area of sensor systems, which poses hard
challenges in terms of information fusion, data volumes, data speed, and
network/energy efficiency, to mention but the most pressing ones. In this
context, anomaly detection is a particularly hard problem, given the need to
find computing-energy accuracy trade-offs in a constrained environment. We
taxonomize methods ranging from conventional techniques (statistical methods,
time-series analysis, signal processing, etc.) to data-driven techniques
(supervised learning, reinforcement learning, deep learning, etc.). We also
look at the impact that different architectural environments (Cloud, Fog, Edge)
can have on the sensors ecosystem. The review points to the most promising
intelligent-sensing methods, and pinpoints a set of interesting open issues and
challenges.
</p>
<a href="http://arxiv.org/abs/2010.14946" target="_blank">arXiv:2010.14946</a> [<a href="http://arxiv.org/pdf/2010.14946" target="_blank">pdf</a>]

<h2>Genetic U-Net: Automatically Designing Lightweight U-shaped CNN Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation. (arXiv:2010.15560v2 [eess.IV] UPDATED)</h2>
<h3>Jiahong Wei, Zhun Fan</h3>
<p>Many previous works based on deep learning for retinal vessel segmentation
have achieved promising performance by manually designing U-shaped
convolutional neural networks (CNNs). However, the manual design of these CNNs
is time-consuming and requires extensive empirical knowledge. To address this
problem, we propose a novel method using genetic algorithms (GAs) to
automatically design a lightweight U-shaped CNN for retinal vessel
segmentation, called Genetic U-Net. Here we first design a special search space
containing the structure of U-Net and its corresponding operations, and then
use genetic algorithm to search for superior architectures in this search
space. Experimental results show that the proposed method outperforms the
existing methods on three public datasets, DRIVE, CHASE\_DB1 and STARE. In
addition, the architectures obtained by the proposed method are more
lightweight but accurate than the state-of-the-art models.
</p>
<a href="http://arxiv.org/abs/2010.15560" target="_blank">arXiv:2010.15560</a> [<a href="http://arxiv.org/pdf/2010.15560" target="_blank">pdf</a>]

<h2>Gaussian Process Bandit Optimization of the Thermodynamic Variational Objective. (arXiv:2010.15750v2 [cs.LG] UPDATED)</h2>
<h3>Vu Nguyen, Vaden Masrani, Rob Brekelmans, Michael A. Osborne, Frank Wood</h3>
<p>Achieving the full promise of the Thermodynamic Variational Objective (TVO),
a recently proposed variational lower bound on the log evidence involving a
one-dimensional Riemann integral approximation, requires choosing a "schedule"
of sorted discretization points. This paper introduces a bespoke Gaussian
process bandit optimization method for automatically choosing these points. Our
approach not only automates their one-time selection, but also dynamically
adapts their positions over the course of optimization, leading to improved
model learning and inference. We provide theoretical guarantees that our bandit
optimization converges to the regret-minimizing choice of integration points.
Empirical validation of our algorithm is provided in terms of improved learning
and inference in Variational Autoencoders and Sigmoid Belief Networks.
</p>
<a href="http://arxiv.org/abs/2010.15750" target="_blank">arXiv:2010.15750</a> [<a href="http://arxiv.org/pdf/2010.15750" target="_blank">pdf</a>]

<h2>Policy Iterations for Reinforcement Learning Problems in Continuous Time and Space -- Fundamental Theory and Methods. (arXiv:1705.03520v2 [cs.AI] CROSS LISTED)</h2>
<h3>Jaeyoung Lee, Richard S. Sutton</h3>
<p>Policy iteration (PI) is a recursive process of policy evaluation and
improvement for solving an optimal decision-making/control problem, or in other
words, a reinforcement learning (RL) problem. PI has also served as the
fundamental for developing RL methods. In this paper, we propose two PI
methods, called differential PI (DPI) and integral PI (IPI), and their
variants, for a general RL framework in continuous time and space (CTS), where
the environment is modeled by a system of ordinary differential equations
(ODEs). The proposed methods inherit the current ideas of PI in classical RL
and optimal control and theoretically support the existing RL algorithms in
CTS: TD-learning and value-gradient-based (VGB) greedy policy update. We also
provide case studies including 1) discounted RL and 2) optimal control tasks.
Fundamental mathematical properties -- admissibility, uniqueness of the
solution to the Bellman equation (BE), monotone improvement, convergence, and
optimality of the solution to the Hamilton-Jacobi-Bellman equation (HJBE) --
are all investigated in-depth and improved from the existing theory, along with
the general and case studies. Finally, the proposed ones are simulated with an
inverted-pendulum model and their model-based and partially model-free
implementations to support the theory and further investigate them beyond.
</p>
<a href="http://arxiv.org/abs/1705.03520" target="_blank">arXiv:1705.03520</a> [<a href="http://arxiv.org/pdf/1705.03520" target="_blank">pdf</a>]

<h2>Interpreting convolutional networks trained on textual data. (arXiv:2010.13585v1 [cs.CL] CROSS LISTED)</h2>
<h3>Reza Marzban, Christopher John Crick</h3>
<p>There have been many advances in the artificial intelligence field due to the
emergence of deep learning. In almost all sub-fields, artificial neural
networks have reached or exceeded human-level performance. However, most of the
models are not interpretable. As a result, it is hard to trust their decisions,
especially in life and death scenarios. In recent years, there has been a
movement toward creating explainable artificial intelligence, but most work to
date has concentrated on image processing models, as it is easier for humans to
perceive visual patterns. There has been little work in other fields like
natural language processing. In this paper, we train a convolutional model on
textual data and analyze the global logic of the model by studying its filter
values. In the end, we find the most important words in our corpus to our
models logic and remove the rest (95%). New models trained on just the 5% most
important words can achieve the same performance as the original model while
reducing training time by more than half. Approaches such as this will help us
to understand NLP models, explain their decisions according to their word
choices, and improve them by finding blind spots and biases.
</p>
<a href="http://arxiv.org/abs/2010.13585" target="_blank">arXiv:2010.13585</a> [<a href="http://arxiv.org/pdf/2010.13585" target="_blank">pdf</a>]

<h2>An Information-Geometric Distance on the Space of Tasks. (arXiv:2011.00613v1 [cs.LG])</h2>
<h3>Yansong Gao, Pratik Chaudhari</h3>
<p>This paper computes a distance between tasks modeled as joint distributions
on data and labels. We develop a stochastic process that transports the
marginal on the data of the source task to that of the target task, and
simultaneously updates the weights of a classifier initialized on the source
task to track this evolving data distribution. The distance between two tasks
is defined to be the shortest path on the Riemannian manifold of the
conditional distribution of labels given data as the weights evolve. We derive
connections of this distance with Rademacher complexity-based generalization
bounds; distance between tasks computed using our method can be interpreted as
the trajectory in weight space that keeps the generalization gap constant as
the task distribution changes from the source to the target. Experiments on
image classification datasets show that this task distance helps predict the
performance of transfer learning: fine-tuning techniques have an easier time
transferring to tasks that are close to each other under our distance.
</p>
<a href="http://arxiv.org/abs/2011.00613" target="_blank">arXiv:2011.00613</a> [<a href="http://arxiv.org/pdf/2011.00613" target="_blank">pdf</a>]

<h2>Active Structure Learning of Causal DAGs via Directed Clique Tree. (arXiv:2011.00641v1 [stat.ME])</h2>
<h3>Chandler Squires, Sara Magliacane, Kristjan Greenewald, Dmitriy Katz, Murat Kocaoglu, Karthikeyan Shanmugam</h3>
<p>A growing body of work has begun to study intervention design for efficient
structure learning of causal directed acyclic graphs (DAGs). A typical setting
is a causally sufficient setting, i.e. a system with no latent confounders,
selection bias, or feedback, when the essential graph of the observational
equivalence class (EC) is given as an input and interventions are assumed to be
noiseless. Most existing works focus on worst-case or average-case lower bounds
for the number of interventions required to orient a DAG. These worst-case
lower bounds only establish that the largest clique in the essential graph
could make it difficult to learn the true DAG. In this work, we develop a
universal lower bound for single-node interventions that establishes that the
largest clique is always a fundamental impediment to structure learning.
Specifically, we present a decomposition of a DAG into independently orientable
components through directed clique trees and use it to prove that the number of
single-node interventions necessary to orient any DAG in an EC is at least the
sum of half the size of the largest cliques in each chain component of the
essential graph. Moreover, we present a two-phase intervention design algorithm
that, under certain conditions on the chordal skeleton, matches the optimal
number of interventions up to a multiplicative logarithmic factor in the number
of maximal cliques. We show via synthetic experiments that our algorithm can
scale to much larger graphs than most of the related work and achieves better
worst-case performance than other scalable approaches. A code base to recreate
these results can be found at https://github.com/csquires/dct-policy
</p>
<a href="http://arxiv.org/abs/2011.00641" target="_blank">arXiv:2011.00641</a> [<a href="http://arxiv.org/pdf/2011.00641" target="_blank">pdf</a>]

<h2>PAC Confidence Predictions for Deep Neural Network Classifiers. (arXiv:2011.00716v1 [cs.LG])</h2>
<h3>Sangdon Park, Shuo Li, Osbert Bastani, Insup Lee</h3>
<p>A key challenge for deploying deep neural networks (DNNs) in safety critical
settings is the need to provide rigorous ways to quantify their uncertainty. In
this paper, we propose a novel algorithm for constructing predicted
classification confidences for DNNs that comes with provable correctness
guarantees. Our approach uses Clopper-Pearson confidence intervals for the
Binomial distribution in conjunction with the histogram binning approach to
calibrated prediction. In addition, we demonstrate how our predicted
confidences can be used to enable downstream guarantees in two settings: (i)
fast DNN inference, where we demonstrate how to compose a fast but inaccurate
DNN with an accurate but slow DNN in a rigorous way to improve performance
without sacrificing accuracy, and (ii) safe planning, where we guarantee safety
when using a DNN to predict whether a given action is safe based on visual
observations. In our experiments, we demonstrate that our approach can be used
to provide guarantees for state-of-the-art DNNs.
</p>
<a href="http://arxiv.org/abs/2011.00716" target="_blank">arXiv:2011.00716</a> [<a href="http://arxiv.org/pdf/2011.00716" target="_blank">pdf</a>]

<h2>Aggregating Incomplete and Noisy Rankings. (arXiv:2011.00810v1 [cs.LG])</h2>
<h3>Dimitris Fotakis, Alkis Kalavasis, Konstantinos Stavropoulos</h3>
<p>We consider the problem of learning the true ordering of a set of
alternatives from largely incomplete and noisy rankings. We introduce a natural
generalization of both the classical Mallows model of ranking distributions and
the extensively studied model of noisy pairwise comparisons. Our selective
Mallows model outputs a noisy ranking on any given subset of alternatives,
based on an underlying Mallows distribution. Assuming a sequence of subsets
where each pair of alternatives appears frequently enough, we obtain strong
asymptotically tight upper and lower bounds on the sample complexity of
learning the underlying complete ranking and the (identities and the) ranking
of the top-k alternatives from selective Mallows rankings. Moreover, building
on the work of (Braverman and Mossel, 2009), we show how to efficiently compute
the maximum likelihood complete ranking from selective Mallows rankings.
</p>
<a href="http://arxiv.org/abs/2011.00810" target="_blank">arXiv:2011.00810</a> [<a href="http://arxiv.org/pdf/2011.00810" target="_blank">pdf</a>]

<h2>Multi-Armed Bandits with Censored Consumption of Resources. (arXiv:2011.00813v1 [cs.LG])</h2>
<h3>Viktor Bengs, Eyke H&#xfc;llermeier</h3>
<p>We consider a resource-aware variant of the classical multi-armed bandit
problem: In each round, the learner selects an arm and determines a resource
limit. It then observes a corresponding (random) reward, provided the (random)
amount of consumed resources remains below the limit. Otherwise, the
observation is censored, i.e., no reward is obtained. For this problem setting,
we introduce a measure of regret, which incorporates the actual amount of
allocated resources of each learning round as well as the optimality of
realizable rewards. Thus, to minimize regret, the learner needs to set a
resource limit and choose an arm in such a way that the chance to realize a
high reward within the predefined resource limit is high, while the resource
limit itself should be kept as low as possible. We derive the theoretical lower
bound on the cumulative regret and propose a learning algorithm having a regret
upper bound that matches the lower bound. In a simulation study, we show that
our learning algorithm outperforms straightforward extensions of standard
multi-armed bandit algorithms.
</p>
<a href="http://arxiv.org/abs/2011.00813" target="_blank">arXiv:2011.00813</a> [<a href="http://arxiv.org/pdf/2011.00813" target="_blank">pdf</a>]

<h2>Adversarial training for predictive tasks: theoretical analysis and limitations in the deterministic case. (arXiv:2011.00835v1 [stat.ML])</h2>
<h3>Thibault Lesieur, J&#xe9;r&#xe9;mie Messud, Issa Hammoud, Hanyuan Peng, C&#xe9;line Lacombe, Paulien Jeunesse</h3>
<p>To train a deep neural network to mimic the outcomes of processing sequences,
a version of Conditional Generalized Adversarial Network (CGAN) can be used. It
has been observed by others that CGAN can help to improve the results even for
deterministic sequences, where only one output is associated with the
processing of a given input. Surprisingly, our CGAN-based tests on
deterministic geophysical processing sequences did not produce a real
improvement compared to the use of an $L_p$ loss; we here propose a first
theoretical explanation why. Our analysis goes from the non-deterministic case
to the deterministic one. It led us to develop an adversarial way to train a
content loss that gave better results on our data.
</p>
<a href="http://arxiv.org/abs/2011.00835" target="_blank">arXiv:2011.00835</a> [<a href="http://arxiv.org/pdf/2011.00835" target="_blank">pdf</a>]

<h2>Sampling Algorithms, from Survey Sampling to Monte Carlo Methods: Tutorial and Literature Review. (arXiv:2011.00901v1 [stat.ME])</h2>
<h3>Benyamin Ghojogh, Hadi Nekoei, Aydin Ghojogh, Fakhri Karray, Mark Crowley</h3>
<p>This paper is a tutorial and literature review on sampling algorithms. We
have two main types of sampling in statistics. The first type is survey
sampling which draws samples from a set or population. The second type is
sampling from probability distribution where we have a probability density or
mass function. In this paper, we cover both types of sampling. First, we review
some required background on mean squared error, variance, bias, maximum
likelihood estimation, Bernoulli, Binomial, and Hypergeometric distributions,
the Horvitz-Thompson estimator, and the Markov property. Then, we explain the
theory of simple random sampling, bootstrapping, stratified sampling, and
cluster sampling. We also briefly introduce multistage sampling, network
sampling, and snowball sampling. Afterwards, we switch to sampling from
distribution. We explain sampling from cumulative distribution function, Monte
Carlo approximation, simple Monte Carlo methods, and Markov Chain Monte Carlo
(MCMC) methods. For simple Monte Carlo methods, whose iterations are
independent, we cover importance sampling and rejection sampling. For MCMC
methods, we cover Metropolis algorithm, Metropolis-Hastings algorithm, Gibbs
sampling, and slice sampling. Then, we explain the random walk behaviour of
Monte Carlo methods and more efficient Monte Carlo methods, including
Hamiltonian (or hybrid) Monte Carlo, Adler's overrelaxation, and ordered
overrelaxation. Finally, we summarize the characteristics, pros, and cons of
sampling methods compared to each other. This paper can be useful for different
fields of statistics, machine learning, reinforcement learning, and
computational physics.
</p>
<a href="http://arxiv.org/abs/2011.00901" target="_blank">arXiv:2011.00901</a> [<a href="http://arxiv.org/pdf/2011.00901" target="_blank">pdf</a>]

<h2>Gradient Boosting for Linear Mixed Models. (arXiv:2011.00947v1 [stat.ME])</h2>
<h3>Colin Griesbach, Benjamin S&#xe4;fken, Elisabeth Waldmann</h3>
<p>Gradient boosting from the field of statistical learning is widely known as a
powerful framework for estimation and selection of predictor effects in various
regression models by adapting concepts from classification theory. Current
boosting approaches also offer methods accounting for random effects and thus
enable prediction of mixed models for longitudinal and clustered data. However,
these approaches include several flaws resulting in unbalanced effect selection
with falsely induced shrinkage and a low convergence rate on the one hand and
biased estimates of the random effects on the other hand. We therefore propose
a new boosting algorithm which explicitly accounts for the random structure by
excluding it from the selection procedure, properly correcting the random
effects estimates and in addition providing likelihood-based estimation of the
random effects variance structure. The new algorithm offers an organic and
unbiased fitting approach, which is shown via simulations and data examples.
</p>
<a href="http://arxiv.org/abs/2011.00947" target="_blank">arXiv:2011.00947</a> [<a href="http://arxiv.org/pdf/2011.00947" target="_blank">pdf</a>]

<h2>The P-T Probability Framework for Semantic Communication, Falsification, Confirmation, and Bayesian Reasoning. (arXiv:2011.00992v1 [stat.OT])</h2>
<h3>Chenguang Lu</h3>
<p>Many researchers want to unify probability and logic by defining logical
probability or probabilistic logic reasonably. This paper tries to unify
statistics and logic so that we can use both statistical probability and
logical probability at the same time. For this purpose, this paper proposes the
P-T probability framework, which is assembled with Shannon's statistical
probability framework for communication, Kolmogorov's probability axioms for
logical probability, and Zadeh's membership functions used as truth functions.
Two kinds of probabilities are connected by an extended Bayes' theorem, with
which we can convert a likelihood function and a truth function from one to
another. Hence, we can train truth functions (in logic) by sampling
distributions (in statistics). This probability framework was developed in the
author's long-term studies on semantic information, statistical learning, and
color vision. This paper first proposes the P-T probability framework and
explains different probabilities in it by its applications to semantic
information theory. Then, this framework and the semantic information methods
are applied to statistical learning, statistical mechanics, hypothesis
evaluation (including falsification), confirmation, and Bayesian reasoning.
Theoretical applications illustrate the reasonability and practicability of
this framework. This framework is helpful for interpretable AI. To interpret
neural networks, we need further study.
</p>
<a href="http://arxiv.org/abs/2011.00992" target="_blank">arXiv:2011.00992</a> [<a href="http://arxiv.org/pdf/2011.00992" target="_blank">pdf</a>]

<h2>RRScell method for automated learning immune cell phenotypes with immunofluorescence cancer tissue. (arXiv:2011.01002v1 [q-bio.QM])</h2>
<h3>Alvason Zhenhua Li, Karsten Eichholz, Anton Sholukh, Lawrence Corey</h3>
<p>Multiplexed immunofluorescence tissue imaging enables precise spatial
assessment of protein expression in medical resection specimens. However,
tissue sections are stained with a mixture of antibodies, DNA and RNA markers,
the detection of weak or broken edges due to fluorescent membrane staining
artifacts between touching or overlapping cells is a long term studied problem,
and is an active research topic in biomedical image analysis. Sometimes
detecting these kinds of edges which are even lacking discrimination or
judgment by human visual intelligence. We have built a GPU client-server and
have developed a hybrid system combining the stochastic random-reaction-seed
(RRS) method and deep neural learning U-net to identify cell-membrane
accurately and automatically. Furthermore, we have designed a high performance
machine-learning AI-pipeline in quantifying spatial distribution of cell
phenotypes from tissue images with various complexities, and extract
single-cell or even subcellular resolution profiling-map of protein and RNA
expression over a million cells tissue section.
</p>
<a href="http://arxiv.org/abs/2011.01002" target="_blank">arXiv:2011.01002</a> [<a href="http://arxiv.org/pdf/2011.01002" target="_blank">pdf</a>]

<h2>A Variant of the Wang-Foster-Kakade Lower Bound for the Discounted Setting. (arXiv:2011.01075v1 [cs.LG])</h2>
<h3>Philip Amortila, Nan Jiang, Tengyang Xie</h3>
<p>Recently, Wang et al. (2020) showed a highly intriguing hardness result for
batch reinforcement learning (RL) with linearly realizable value function and
good feature coverage in the finite-horizon case. In this note we show that
once adapted to the discounted setting, the construction can be simplified to a
2-state MDP with 1-dimensional features, such that learning is impossible even
with an infinite amount of data.
</p>
<a href="http://arxiv.org/abs/2011.01075" target="_blank">arXiv:2011.01075</a> [<a href="http://arxiv.org/pdf/2011.01075" target="_blank">pdf</a>]

<h2>Instance based Generalization in Reinforcement Learning. (arXiv:2011.01089v1 [cs.LG])</h2>
<h3>Martin Bertran, Natalia Martinez, Mariano Phielipp, Guillermo Sapiro</h3>
<p>Agents trained via deep reinforcement learning (RL) routinely fail to
generalize to unseen environments, even when these share the same underlying
dynamics as the training levels. Understanding the generalization properties of
RL is one of the challenges of modern machine learning. Towards this goal, we
analyze policy learning in the context of Partially Observable Markov Decision
Processes (POMDPs) and formalize the dynamics of training levels as instances.
We prove that, independently of the exploration strategy, reusing instances
introduces significant changes on the effective Markov dynamics the agent
observes during training. Maximizing expected rewards impacts the learned
belief state of the agent by inducing undesired instance specific speedrunning
policies instead of generalizeable ones, which are suboptimal on the training
set. We provide generalization bounds to the value gap in train and test
environments based on the number of training instances, and use insights based
on these to improve performance on unseen levels. We propose training a shared
belief representation over an ensemble of specialized policies, from which we
compute a consensus policy that is used for data collection, disallowing
instance specific exploitation. We experimentally validate our theory,
observations, and the proposed computational solution over the CoinRun
benchmark.
</p>
<a href="http://arxiv.org/abs/2011.01089" target="_blank">arXiv:2011.01089</a> [<a href="http://arxiv.org/pdf/2011.01089" target="_blank">pdf</a>]

<h2>SapAugment: Learning A Sample Adaptive Policy for Data Augmentation. (arXiv:2011.01156v1 [cs.LG])</h2>
<h3>Ting-Yao Hu, Ashish Shrivastava, Rick Chang, Hema Koppula, Stefan Braun, Kyuyeon Hwang, Ozlem Kalini, Oncel Tuzel</h3>
<p>Data augmentation methods usually apply the same augmentation (or a mix of
them) to all the training samples. For example, to perturb data with noise, the
noise is sampled from a Normal distribution with a fixed standard deviation,
for all samples. We hypothesize that a hard sample with high training loss
already provides strong training signal to update the model parameters and
should be perturbed with mild or no augmentation. Perturbing a hard sample with
a strong augmentation may also make it too hard to learn from. Furthermore, a
sample with low training loss should be perturbed by a stronger augmentation to
provide more robustness to a variety of conditions. To formalize these
intuitions, we propose a novel method to learn a Sample-Adaptive Policy for
Augmentation -- SapAugment. Our policy adapts the augmentation parameters based
on the training loss of the data samples. In the example of Gaussian noise, a
hard sample will be perturbed with a low variance noise and an easy sample with
a high variance noise. Furthermore, the proposed method combines multiple
augmentation methods into a methodical policy learning framework and obviates
hand-crafting augmentation parameters by trial-and-error. We apply our method
on an automatic speech recognition (ASR) task, and combine existing and novel
augmentations using the proposed framework. We show substantial improvement, up
to 21% relative reduction in word error rate on LibriSpeech dataset, over the
state-of-the-art speech augmentation method.
</p>
<a href="http://arxiv.org/abs/2011.01156" target="_blank">arXiv:2011.01156</a> [<a href="http://arxiv.org/pdf/2011.01156" target="_blank">pdf</a>]

<h2>Reducing Neural Network Parameter Initialization Into an SMT Problem. (arXiv:2011.01191v1 [cs.LG])</h2>
<h3>Mohamad H. Danesh</h3>
<p>Training a neural network (NN) depends on multiple factors, including but not
limited to the initial weights. In this paper, we focus on initializing deep NN
parameters such that it performs better, comparing to random or zero
initialization. We do this by reducing the process of initialization into an
SMT solver. Previous works consider certain activation functions on small NNs,
however the studied NN is a deep network with different activation functions.
Our experiments show that the proposed approach for parameter initialization
achieves better performance comparing to randomly initialized networks.
</p>
<a href="http://arxiv.org/abs/2011.01191" target="_blank">arXiv:2011.01191</a> [<a href="http://arxiv.org/pdf/2011.01191" target="_blank">pdf</a>]

<h2>A Learning Theoretic Perspective on Local Explainability. (arXiv:2011.01205v1 [cs.LG])</h2>
<h3>Jeffrey Li, Vaishnavh Nagarajan, Gregory Plumb, Ameet Talwalkar</h3>
<p>In this paper, we explore connections between interpretable machine learning
and learning theory through the lens of local approximation explanations.
First, we tackle the traditional problem of performance generalization and
bound the test-time accuracy of a model using a notion of how locally
explainable it is. Second, we explore the novel problem of explanation
generalization which is an important concern for a growing class of finite
sample-based local approximation explanations. Finally, we validate our
theoretical results empirically and show that they reflect what can be seen in
practice.
</p>
<a href="http://arxiv.org/abs/2011.01205" target="_blank">arXiv:2011.01205</a> [<a href="http://arxiv.org/pdf/2011.01205" target="_blank">pdf</a>]

<h2>The R Package stagedtrees for Structural Learning of Stratified Staged Trees. (arXiv:2004.06459v2 [stat.ME] UPDATED)</h2>
<h3>Federico Carli, Manuele Leonelli, Eva Riccomagno, Gherardo Varando</h3>
<p>stagedtrees is an R package which includes several algorithms for learning
the structure of staged trees and chain event graphs from data. Score-based and
clustering-based algorithms are implemented, as well as various functionalities
to plot the models and perform inference. The capabilities of stagedtrees are
illustrated using mainly two datasets both included in the package or bundled
in R.
</p>
<a href="http://arxiv.org/abs/2004.06459" target="_blank">arXiv:2004.06459</a> [<a href="http://arxiv.org/pdf/2004.06459" target="_blank">pdf</a>]

<h2>Estimating NBA players salary share according to their performance on court: A machine learning approach. (arXiv:2007.14694v3 [stat.AP] UPDATED)</h2>
<h3>Ioanna Papadaki, Michail Tsagris</h3>
<p>It is customary for researchers and practitioners to fit linear models in
order to predict NBA player's salary based on the players' performance on
court. On the contrary, we focus on the players salary share (with regards to
the team payroll) by first selecting the most important determinants or
statistics (years of experience in the league, games played, etc.) and then
utilise them to predict the player salaries by employing a non linear Random
Forest machine learning algorithm. We externally evaluate our salary
predictions, thus we avoid the phenomenon of over-fitting observed in most
papers. Overall, using data from three distinct periods, 2017-2019 we identify
the important factors that achieve very satisfactory salary predictions and we
draw useful conclusions.
</p>
<a href="http://arxiv.org/abs/2007.14694" target="_blank">arXiv:2007.14694</a> [<a href="http://arxiv.org/pdf/2007.14694" target="_blank">pdf</a>]

<h2>The role of feature space in atomistic learning. (arXiv:2009.02741v2 [physics.comp-ph] UPDATED)</h2>
<h3>Alexander Goscinski, Guillaume Fraux, Michele Ceriotti</h3>
<p>Eficient, physically-inspired descriptors of the structure and composition of
molecules and materials play a key role in the application of machine-learning
techniques to atomistic simulations. The proliferation of approaches, as well
as the fact that each choice of features can lead to very different behavior
depending on how they are used, e.g. by introducing non-linear kernels and
non-Euclidean metrics to manipulate them, makes it difficult to objectively
compare different methods, and to address fundamental questions on how one
feature space is related to another. In this work we introduce a framework to
compare different sets of descriptors, and different ways of transforming them
by means of metrics and kernels, in terms of the structure of the feature space
that they induce. We define diagnostic tools to determine whether alternative
feature spaces contain equivalent amounts of information, and whether the
common information is substantially distorted when going from one feature space
to another. We compare, in particular, representations that are built in terms
of n-body correlations of the atom density, quantitatively assessing the
information loss associated with the use of low-order features. We also
investigate the impact of different choices of basis functions and
hyperparameters of the widely used SOAP and Behler-Parrinello features, and
investigate how the use of non-linear kernels, and of a Wasserstein-type
metric, change the structure of the feature space in comparison to a simpler
linear feature space.
</p>
<a href="http://arxiv.org/abs/2009.02741" target="_blank">arXiv:2009.02741</a> [<a href="http://arxiv.org/pdf/2009.02741" target="_blank">pdf</a>]

<h2>Simulation-based inference methods for particle physics. (arXiv:2010.06439v2 [hep-ph] UPDATED)</h2>
<h3>Johann Brehmer, Kyle Cranmer</h3>
<p>Our predictions for particle physics processes are realized in a chain of
complex simulators. They allow us to generate high-fidelity simulated data, but
they are not well-suited for inference on the theory parameters with observed
data. We explain why the likelihood function of high-dimensional LHC data
cannot be explicitly evaluated, why this matters for data analysis, and reframe
what the field has traditionally done to circumvent this problem. We then
review new simulation-based inference methods that let us directly analyze
high-dimensional data by combining machine learning techniques and information
from the simulator. Initial studies indicate that these techniques have the
potential to substantially improve the precision of LHC measurements. Finally,
we discuss probabilistic programming, an emerging paradigm that lets us extend
inference to the latent process of the simulator.
</p>
<a href="http://arxiv.org/abs/2010.06439" target="_blank">arXiv:2010.06439</a> [<a href="http://arxiv.org/pdf/2010.06439" target="_blank">pdf</a>]

<h2>Learning to Represent Action Values as a Hypergraph on the Action Vertices. (arXiv:2010.14680v1 [cs.LG] CROSS LISTED)</h2>
<h3>Arash Tavakoli, Mehdi Fatemi, Petar Kormushev</h3>
<p>Action-value estimation is a critical component of many reinforcement
learning (RL) methods whereby sample complexity relies heavily on how fast a
good estimator for action value can be learned. By viewing this problem through
the lens of representation learning, good representations of both state and
action can facilitate action-value estimation. While advances in deep learning
have seamlessly driven progress in learning state representations, given the
specificity of the notion of agency to RL, little attention has been paid to
learning action representations. We conjecture that leveraging the
combinatorial structure of multi-dimensional action spaces is a key ingredient
for learning good representations of action. To test this, we set forth the
action hypergraph networks framework---a class of functions for learning action
representations with a relational inductive bias. Using this framework we
realise an agent class based on a combination with deep Q-networks, which we
dub hypergraph Q-networks. We show the effectiveness of our approach on a
myriad of domains: illustrative prediction problems under minimal confounding
effects, Atari 2600 games, and physical control benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.14680" target="_blank">arXiv:2010.14680</a> [<a href="http://arxiv.org/pdf/2010.14680" target="_blank">pdf</a>]

