---
title: Latest Deep Learning Papers
date: 2020-10-21 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Structured Online Learning-based Control of Continuous-time Nonlinear Systems. (arXiv:2010.10577v1 [math.OC])</h2>
<h3>Milad Farsi, Jun Liu</h3>
<p>Model-based reinforcement learning techniques accelerate the learning task by
employing a transition model to make predictions. In this paper, a model-based
learning approach is presented that iteratively computes the optimal value
function based on the most recent update of the model. Assuming a structured
continuous-time model of the system in terms of a set of bases, we formulate an
infinite horizon optimal control problem addressing a given control objective.
The structure of the system along with a value function parameterized in the
quadratic form provides a flexibility in analytically calculating an update
rule for the parameters. Hence, a matrix differential equation of the
parameters is obtained, where the solution is used to characterize the optimal
feedback control in terms of the bases, at any time step. Moreover, the
quadratic form of the value function suggests a compact way of updating the
parameters that considerably decreases the computational complexity.
Considering the state-dependency of the differential equation, we exploit the
obtained framework as an online learning-based algorithm. In the numerical
results, the presented algorithm is implemented on four nonlinear benchmark
examples, where the regulation problem is successfully solved while an
identified model of the system is obtained with a bounded prediction error.
</p>
<a href="http://arxiv.org/abs/2010.10577" target="_blank">arXiv:2010.10577</a> [<a href="http://arxiv.org/pdf/2010.10577" target="_blank">pdf</a>]

<h2>Invertible Low-Divergence Coding. (arXiv:2010.10583v1 [cs.IT])</h2>
<h3>Patrick Schulte, Rana Ali Amjad, Thomas Wiegart, Gerhard Kramer</h3>
<p>Several applications in communication, control, and learning require
approximating target distributions to within small informational divergence
(I-divergence). The additional requirement of invertibility usually leads to
using encoders that are one-to-one mappings, also known as distribution
matchers. However, even the best one-to-one encoders have I-divergences that
grow logarithmically with the block length in general. To improve performance,
an encoder is proposed that has an invertible one-to-many mapping and a
low-rate resolution code. Two algorithms are developed to design the mapping by
assigning strings in either a most-likely first or least-likely first order.
Both algorithms give information rates approaching the entropy of the target
distribution with exponentially decreasing I-divergence and with vanishing
resolution rate in the block length.
</p>
<a href="http://arxiv.org/abs/2010.10583" target="_blank">arXiv:2010.10583</a> [<a href="http://arxiv.org/pdf/2010.10583" target="_blank">pdf</a>]

<h2>A modular proof of the properness of the Coleman-Mazur eigencurve. (arXiv:2010.10705v1 [math.NT])</h2>
<h3>Lynnelle Ye</h3>
<p>We give a new proof of the properness of the Coleman-Mazur eigencurve. The
question of whether the eigencurve satisfies the valuative criterion for
properness was first asked by Coleman and Mazur in 1998 and settled by Diao and
Liu in 2016 using deep, powerful Hodge- and Galois- theoretic machinery. Our
proof is short and explicit and uses no Galois theory. Instead we adapt an
earlier method of Buzzard and Calegari based on elementary properties of
overconvergent modular forms. To facilitate this, we extend Pilloni's geometric
construction of overconvergent forms of arbitrary weight farther into the
supersingular locus. Along the way, we show that the Hecke operator $U_p$ is
injective on spaces of forms of large overconvergence radius of any analytic
weight.
</p>
<a href="http://arxiv.org/abs/2010.10705" target="_blank">arXiv:2010.10705</a> [<a href="http://arxiv.org/pdf/2010.10705" target="_blank">pdf</a>]

<h2>More constructions for Sperner partition systems. (arXiv:2010.10756v1 [math.CO])</h2>
<h3>Adam Gowty, Daniel Horsley</h3>
<p>An $(n,k)$-Sperner partition system is a set of partitions of some $n$-set
such that each partition has $k$ nonempty parts and no part in any partition is
a subset of a part in a different partition. The maximum number of partitions
in an $(n,k)$-Sperner partition system is denoted $\mathrm{SP}(n,k)$. In this
paper we introduce a new construction for Sperner partition systems based on a
division of the ground set into many equal-sized parts. We use this to
asymptotically determine $\mathrm{SP}(n,k)$ in many cases where $\frac{n}{k}$
is bounded as $n$ becomes large. Further, we show that this construction
produces a Sperner partition system of maximum size for numerous small
parameter sets $(n,k)$. By extending a separate existing construction, we also
establish the asymptotics of $\mathrm{SP}(n,k)$ when $n \equiv k \pm 1
\pmod{2k}$ for almost all odd values of $k$.
</p>
<a href="http://arxiv.org/abs/2010.10756" target="_blank">arXiv:2010.10756</a> [<a href="http://arxiv.org/pdf/2010.10756" target="_blank">pdf</a>]

<h2>Remarks on the subdivisions of bispindles and two-blocks cycles in highly chromatic digraphs. (arXiv:2010.10787v1 [math.CO])</h2>
<h3>Darine Al Mniny, Salman Ghazal</h3>
<p>A $(2+1)$-bispindle $B(k_1,k_2;k_3)$ is the union of two $xy$-dipaths of
respective lengths $k_1$ and $k_2$, and one $yx$-dipath of length $k_3$, all
these dipaths being pairwise internally disjoint. Recently, Cohen et al.
conjectured that, for every positive integers $k_1, k_2, k_3$, there is an
integer $g(k_1, k_2, k_3)$ such that every strongly connected digraph not
containing subdivisions of $B(k_1, k_2; k_3)$ has a chromatic number at most
$g(k_1, k_2, k_3)$, and they proved it only for the case where $k_2=1$. For
Hamiltonian digraphs, we prove Cohen et al.'s conjecture, namely $g(k_1, k_2,
k_3)\leq 4k$, where $k=max\{k_1, k_2, k_3\}$. A two-blocks cycle $C(k_1,k_2)$
is the union of two internally disjoint $xy$-dipaths of length $k_1$ and $k_2$
respectively. Addario et al. asked if the chromatic number of strong digraphs
not containing subdivisions of a two-blocks cycle $C(k_1,k_2)$ can be bounded
from above by $O(k_1+k_2)$, which remains an open problem. Assuming that
$k=max\{k_1,k_2\}$, the best reached upper bound, found by Kim et al., is
$12k^2$. In this article, we conjecture that this bound can be slightly
improved to $4k^2$ and we confirm our conjecture for some particular cases.
Moreover, we provide a positive answer to Addario et al.'s question for the
class of digraphs having a Hamiltonian directed path.
</p>
<a href="http://arxiv.org/abs/2010.10787" target="_blank">arXiv:2010.10787</a> [<a href="http://arxiv.org/pdf/2010.10787" target="_blank">pdf</a>]

<h2>A Note on the Approximability of Deepest-Descent Circuit Steps. (arXiv:2010.10809v1 [math.OC])</h2>
<h3>Steffen Borgwardt, Cornelius Brand, Andreas Emil Feldmann, Martin Kouteck&#xfd;</h3>
<p>Linear programs (LPs) can be solved through a polynomial number of so-called
deepest-descent circuit steps, each step following a circuit direction to a new
feasible solution of most-improved objective function value. A computation of
deepest-descent steps has recently been shown to be NP-hard [De Loera et al.,
arXiv, 2019]. This is a consequence of the hardness of what we call the optimal
circuit-neighbor problem (OCNP) for LPs with non-unique optima. However, the
non-uniqueness assumption is crucial to the hardness of OCNP, because we show
that OCNP for LPs with a unique optimum is solvable in polynomial time.
Moreover, in practical applications one is usually only interested in finding
some optimum of an LP, in which case a simple perturbation of the objective
yields an instance with a unique optimum. It is thus natural to ask whether
deepest-descent steps are also easy to compute for LPs with unique optima, or
whether this problem is hard despite OCNP being easy.

We show that deepest-descent steps can be efficiently approximated within a
factor of $n$, where $n$ is the dimension of the polyhedron at hand, but not
within a factor of $O(n^{1-\epsilon})$ for any $\epsilon &gt; 0$. While we prove
that OCNP can be solved efficiently for LPs with a unique optimum, our
different hardness approach allows us to show strong negative results:
computing deepest-descent steps is NP-hard and inapproximable even for 0/1
linear programs with a unique optimum which are defined by a totally unimodular
constraint matrix.
</p>
<a href="http://arxiv.org/abs/2010.10809" target="_blank">arXiv:2010.10809</a> [<a href="http://arxiv.org/pdf/2010.10809" target="_blank">pdf</a>]

<h2>Coordinated Online Learning for Multi-Agent Systems with Coupled Constraints and Perturbed Utility Observations. (arXiv:2010.10878v1 [math.OC])</h2>
<h3>Ezra Tampubolon, Holger Boche</h3>
<p>Competitive non-cooperative online decision-making agents whose actions
increase congestion of scarce resources constitute a model for widespread
modern large-scale applications. To ensure sustainable resource behavior, we
introduce a novel method to steer the agents toward a stable population state,
fulfilling the given coupled resource constraints. The proposed method is a
decentralized resource pricing method based on the resource loads resulting
from the augmentation of the game's Lagrangian. Assuming that the online
learning agents have only noisy first-order utility feedback, we show that for
a polynomially decaying agents' step size/learning rate, the population's
dynamic will almost surely converge to generalized Nash equilibrium. A
particular consequence of the latter is the fulfillment of resource constraints
in the asymptotic limit. Moreover, we investigate the finite-time quality of
the proposed algorithm by giving a nonasymptotic time decaying bound for the
expected amount of resource constraint violation.
</p>
<a href="http://arxiv.org/abs/2010.10878" target="_blank">arXiv:2010.10878</a> [<a href="http://arxiv.org/pdf/2010.10878" target="_blank">pdf</a>]

<h2>Conditional Mutual Information Bound for Meta Generalization Gap. (arXiv:2010.10886v1 [cs.LG])</h2>
<h3>Arezou Rezazadeh, Sharu Theresa Jose, Giuseppe Durisi, Osvaldo Simeone</h3>
<p>Meta-learning infers an inductive bias---typically in the form of the
hyperparameters of a base-learning algorithm---by observing data from a finite
number of related tasks. This paper presents an information-theoretic upper
bound on the average meta-generalization gap that builds on the conditional
mutual information (CMI) framework of Steinke and Zakynthinou (2020), which was
originally developed for conventional learning. In the context of
meta-learning, the CMI framework involves a training \textit{meta-supersample}
obtained by first sampling $2N$ independent tasks from the task environment,
and then drawing $2M$ independent training samples for each sampled task. The
meta-training data fed to the meta-learner is then obtained by randomly
selecting $N$ tasks from the available $2N$ tasks and $M$ training samples per
task from the available $2M$ training samples per task. The resulting bound is
explicit in two CMI terms, which measure the information that the meta-learner
output and the base-learner output respectively provide about which training
data are selected given the entire meta-supersample.
</p>
<a href="http://arxiv.org/abs/2010.10886" target="_blank">arXiv:2010.10886</a> [<a href="http://arxiv.org/pdf/2010.10886" target="_blank">pdf</a>]

<h2>Adaptive Gradient Method with Resilience and Momentum. (arXiv:2010.11041v1 [cs.LG])</h2>
<h3>Jie Liu, Chen Lin, Chuming Li, Lu Sheng, Ming Sun, Junjie Yan, Wanli Ouyang</h3>
<p>Several variants of stochastic gradient descent (SGD) have been proposed to
improve the learning effectiveness and efficiency when training deep neural
networks, among which some recent influential attempts would like to adaptively
control the parameter-wise learning rate (e.g., Adam and RMSProp). Although
they show a large improvement in convergence speed, most adaptive learning rate
methods suffer from compromised generalization compared with SGD. In this
paper, we proposed an Adaptive Gradient Method with Resilience and Momentum
(AdaRem), motivated by the observation that the oscillations of network
parameters slow the training, and give a theoretical proof of convergence. For
each parameter, AdaRem adjusts the parameter-wise learning rate according to
whether the direction of one parameter changes in the past is aligned with the
direction of the current gradient, and thus encourages long-term consistent
parameter updating with much fewer oscillations. Comprehensive experiments have
been conducted to verify the effectiveness of AdaRem when training various
models on a large-scale image recognition dataset, e.g., ImageNet, which also
demonstrate that our method outperforms previous adaptive learning rate-based
algorithms in terms of the training speed and the test error, respectively.
</p>
<a href="http://arxiv.org/abs/2010.11041" target="_blank">arXiv:2010.11041</a> [<a href="http://arxiv.org/pdf/2010.11041" target="_blank">pdf</a>]

<h2>Data augmentation as stochastic optimization. (arXiv:2010.11171v1 [cs.LG])</h2>
<h3>Boris Hanin, Yi Sun</h3>
<p>We present a theoretical framework recasting data augmentation as stochastic
optimization for a sequence of time-varying proxy losses. This provides a
unified approach to understanding techniques commonly thought of as data
augmentation, including synthetic noise and label-preserving transformations,
as well as more traditional ideas in stochastic optimization such as learning
rate and batch size scheduling. We prove a time-varying Monro-Robbins theorem
with rates of convergence which gives conditions on the learning rate and
augmentation schedule under which augmented gradient descent converges. Special
cases give provably good joint schedules for augmentation with additive noise,
minibatch SGD, and minibatch SGD with noise.
</p>
<a href="http://arxiv.org/abs/2010.11171" target="_blank">arXiv:2010.11171</a> [<a href="http://arxiv.org/pdf/2010.11171" target="_blank">pdf</a>]

<h2>Robust Wasserstein Profile Inference and Applications to Machine Learning. (arXiv:1610.05627v4 [math.ST] UPDATED)</h2>
<h3>Jose Blanchet, Yang Kang, Karthyek Murthy</h3>
<p>We show that several machine learning estimators, including square-root LASSO
(Least Absolute Shrinkage and Selection) and regularized logistic regression
can be represented as solutions to distributionally robust optimization (DRO)
problems. The associated uncertainty regions are based on suitably defined
Wasserstein distances. Hence, our representations allow us to view
regularization as a result of introducing an artificial adversary that perturbs
the empirical distribution to account for out-of-sample effects in loss
estimation. In addition, we introduce RWPI (Robust Wasserstein Profile
Inference), a novel inference methodology which extends the use of methods
inspired by Empirical Likelihood to the setting of optimal transport costs (of
which Wasserstein distances are a particular case). We use RWPI to show how to
optimally select the size of uncertainty regions, and as a consequence, we are
able to choose regularization parameters for these machine learning estimators
without the use of cross validation. Numerical experiments are also given to
validate our theoretical findings.
</p>
<a href="http://arxiv.org/abs/1610.05627" target="_blank">arXiv:1610.05627</a> [<a href="http://arxiv.org/pdf/1610.05627" target="_blank">pdf</a>]

<h2>Sample average approximation with heavier tails I: non-asymptotic bounds with weak assumptions and stochastic constraints. (arXiv:1705.00822v4 [math.OC] UPDATED)</h2>
<h3>Roberto I. Oliveira, Philip Thompson</h3>
<p>We derive new and improved non-asymptotic deviation inequalities for the
sample average approximation (SAA) of an optimization problem. Our results give
strong error probability bounds that are "sub-Gaussian"~even when the
randomness of the problem is fairly heavy tailed. Additionally, we obtain good
(often optimal) dependence on the sample size and geometrical parameters of the
problem. Finally, we allow for random constraints on the SAA and unbounded
feasible sets, which also do not seem to have been considered before in the
non-asymptotic literature. Our proofs combine different ideas of potential
independent interest: an adaptation of Talagrand's "generic chaining"~bound for
sub-Gaussian processes; "localization"~ideas from the Statistical Learning
literature; and the use of standard conditions in Optimization (metric
regularity, Slater-type conditions) to control fluctuations of the feasible
set.
</p>
<a href="http://arxiv.org/abs/1705.00822" target="_blank">arXiv:1705.00822</a> [<a href="http://arxiv.org/pdf/1705.00822" target="_blank">pdf</a>]

<h2>Sample average approximation with heavier tails II: localization in stochastic convex optimization and persistence results for the Lasso. (arXiv:1711.04734v3 [math.OC] UPDATED)</h2>
<h3>Roberto I. Oliveira, Philip Thompson</h3>
<p>"Localization" has proven to be a valuable tool in the Statistical Learning
literature as it allows sharp risk bounds in terms of the problem geometry.
Localized bounds seem to be much less exploited in the Stochastic Optimization
literature. In addition, there is an obvious interest in both communities in
obtaining risk bounds that require weak moment assumptions or "heavier-tails".
In this work we use a localization toolbox to derive risk bounds in two
specific applications. The first is in portfolio risk minimization with
conditional value-at-risk constraints. We describe specific assumptions that
give high-probability risk bounds of the order $\sqrt{d^*/N}$, where $d^*$ is
much smaller than the ambient dimension. This corresponds to the number of
assets with low-risk and high returns. Localization is a key tool to prove
this. As a second application of our localization toolbox, we obtain sharp
oracle inequalities for least-squares estimators with a Lasso-type constraint
under weak moment assumptions. One main consequence of these inequalities is to
obtain \emph{persistence}, as posed by Greenshtein and Ritov, with covariates
having heavier tails. This gives improvements in prior work of Bartlett,
Mendelson and Neeman.
</p>
<a href="http://arxiv.org/abs/1711.04734" target="_blank">arXiv:1711.04734</a> [<a href="http://arxiv.org/pdf/1711.04734" target="_blank">pdf</a>]

<h2>A Primal-Dual Algorithm with Line Search for General Convex-Concave Saddle Point Problems. (arXiv:1803.01401v5 [math.OC] UPDATED)</h2>
<h3>Erfan Yazdandoost Hamedani, Necdet Serhat Aybat</h3>
<p>In this paper, we propose a primal-dual algorithm with a novel momentum term
using the partial gradients of the coupling function that can be viewed as a
generalization of the method proposed by Chambolle and Pock in 2016 to solve
saddle point problems defined by a convex-concave function $\mathcal
L(x,y)=f(x)+\Phi(x,y)-h(y)$ with a general coupling term $\Phi(x,y)$ that is
not assumed to be bilinear. Assuming $\nabla_x\Phi(\cdot,y)$ is Lipschitz for
any fixed $y$, and $\nabla_y\Phi(\cdot,\cdot)$ is Lipschitz, we show that the
iterate sequence converges to a saddle point; and for any $(x,y)$, we derive
error bounds in terms of $\mathcal L(\bar{x}_k,y)-\mathcal L(x,\bar{y}_k)$ for
the ergodic sequence $\{\bar{x}_k,\bar{y}_k\}$. In particular, we show
$\mathcal O(1/k)$ rate when the problem is merely convex in $x$. Furthermore,
assuming $\Phi(x,\cdot)$ is linear for each fixed $x$ and $f$ is strongly
convex, we obtain the ergodic convergence rate of $\mathcal O(1/k^2)$ -- we are
not aware of another single-loop method in the related literature achieving the
same rate when $\Phi$ is not bilinear. Finally, we propose a backtracking
technique which does not require the knowledge of Lipschitz constants while
ensuring the same convergence results. We also consider convex optimization
problems with nonlinear functional constraints and we show that using the
backtracking scheme, the optimal convergence rate can be achieved even when the
dual domain is unbounded. We tested our method against other state-of-the-art
first-order algorithms and interior-point methods for solving quadratically
constrained quadratic problems with synthetic data, the kernel matrix learning,
and regression with fairness constraints arising in machine learning.
</p>
<a href="http://arxiv.org/abs/1803.01401" target="_blank">arXiv:1803.01401</a> [<a href="http://arxiv.org/pdf/1803.01401" target="_blank">pdf</a>]

<h2>Deeply ramified fields, semitame fields, and the classification of defect extensions. (arXiv:1811.04396v2 [math.AC] UPDATED)</h2>
<h3>Anna Blaszczok, Franz-Viktor Kuhlmann</h3>
<p>We study in detail the valuation theory of deeply ramified fields and
introduce and investigate several other related classes of valued fields.
Further, a classification of defect extensions of prime degree of valued fields
that was earlier given only for the characteristic equal case is generalized to
the case of mixed characteristic by a unified definition that works
simultaneously for both cases. It is shown that deeply ramified fields and the
other valued fields we introduce only admit one of the two types of defect
extensions, namely the ones that appear to be more harmless in open problems
such as local uniformization and the model theory of valued fields in positive
characteristic. The classes of valued fields under consideration can be seen as
generalizations of the class of tame valued fields. The present paper supports
the hope that it will be possible to generalize to deeply ramified fields
several important results that have been proven for tame fields and were at the
core of partial solutions of the two open problems mentioned above.
</p>
<a href="http://arxiv.org/abs/1811.04396" target="_blank">arXiv:1811.04396</a> [<a href="http://arxiv.org/pdf/1811.04396" target="_blank">pdf</a>]

<h2>Generalization Error Bounds Via R\'enyi-, $f$-Divergences and Maximal Leakage. (arXiv:1912.01439v3 [cs.IT] UPDATED)</h2>
<h3>Amedeo Roberto Esposito, Michael Gastpar, Ibrahim Issa</h3>
<p>In this work, the probability of an event under some joint distribution is
bounded by measuring it with the product of the marginals instead (which is
typically easier to analyze) together with a measure of the dependence between
the two random variables. These results find applications in adaptive data
analysis, where multiple dependencies are introduced and in learning theory,
where they can be employed to bound the generalization error of a learning
algorithm. Bounds are given in terms of Sibson's Mutual Information,
$\alpha-$Divergences, Hellinger Divergences, and $f-$Divergences. A case of
particular interest is the Maximal Leakage (or Sibson's Mutual Information of
order infinity), since this measure is robust to post-processing and composes
adaptively. The corresponding bound can be seen as a generalization of
classical bounds, such as Hoeffding's and McDiarmid's inequalities, to the case
of dependent random variables.
</p>
<a href="http://arxiv.org/abs/1912.01439" target="_blank">arXiv:1912.01439</a> [<a href="http://arxiv.org/pdf/1912.01439" target="_blank">pdf</a>]

<h2>Stochastic Approximation versus Sample Average Approximation for population Wasserstein barycenters. (arXiv:2001.07697v6 [math.OC] UPDATED)</h2>
<h3>Darina Dvinskikh</h3>
<p>In machine learning and optimization community there are two main approaches
for convex risk minimization problem, namely, the Stochastic Approximation (SA)
and the Sample Average Approximation (SAA). In terms of oracle complexity
(required number of stochastic gradient evaluations), both approaches are
considered equivalent on average (up to a logarithmic factor). The total
complexity depends on the specific problem, however, starting from work
\cite{nemirovski2009robust} it was generally accepted that the SA is better
than the SAA. Nevertheless, in case of large-scale problems SA may run out of
memory as storing all data on one machine and organizing online access to it
can be impossible without communications with other machines. SAA in
contradistinction to SA allows parallel/distributed calculations. In this
paper, we shed new light on the comparison of SA and SAA for particular problem
of calculating the population (regularized) Wasserstein barycenter of discrete
measures. The conclusion is valid even for non-parallel (non-decentralized)
setup.
</p>
<a href="http://arxiv.org/abs/2001.07697" target="_blank">arXiv:2001.07697</a> [<a href="http://arxiv.org/pdf/2001.07697" target="_blank">pdf</a>]

<h2>Scenario optimization with relaxation: a new tool for design and application to machine learning problems. (arXiv:2004.05839v3 [cs.LG] UPDATED)</h2>
<h3>Marco C. Campi, Simone Garatti</h3>
<p>Scenario optimization is by now a well established technique to perform
designs in the presence of uncertainty. It relies on domain knowledge
integrated with first-hand information that comes from data and generates
solutions that are also accompanied by precise statements of reliability. In
this paper, following recent developments in (Garatti and Campi, 2019), we
venture beyond the traditional set-up of scenario optimization by analyzing the
concept of constraints relaxation. By a solid theoretical underpinning, this
new paradigm furnishes fundamental tools to perform designs that meet a proper
compromise between robustness and performance. After suitably expanding the
scope of constraints relaxation as proposed in (Garatti and Campi, 2019), we
focus on various classical Support Vector methods in machine learning -
including SVM (Support Vector Machine), SVR (Support Vector Regression) and
SVDD (Support Vector Data Description) - and derive new results for the ability
of these methods to generalize.
</p>
<a href="http://arxiv.org/abs/2004.05839" target="_blank">arXiv:2004.05839</a> [<a href="http://arxiv.org/pdf/2004.05839" target="_blank">pdf</a>]

<h2>Universally Quantized Neural Compression. (arXiv:2006.09952v2 [stat.ML] UPDATED)</h2>
<h3>Eirikur Agustsson, Lucas Theis</h3>
<p>A popular approach to learning encoders for lossy compression is to use
additive uniform noise during training as a differentiable approximation to
test-time quantization. We demonstrate that a uniform noise channel can also be
implemented at test time using universal quantization (Ziv, 1985). This allows
us to eliminate the mismatch between training and test phases while maintaining
a completely differentiable loss function. Implementing the uniform noise
channel is a special case of the more general problem of communicating a
sample, which we prove is computationally hard if we do not make assumptions
about its distribution. However, the uniform special case is efficient as well
as easy to implement and thus of great interest from a practical point of view.
Finally, we show that quantization can be obtained as a limiting case of a soft
quantizer applied to the uniform noise channel, bridging compression with and
without quantization.
</p>
<a href="http://arxiv.org/abs/2006.09952" target="_blank">arXiv:2006.09952</a> [<a href="http://arxiv.org/pdf/2006.09952" target="_blank">pdf</a>]

<h2>A Minimum-Risk Dynamic Assignment Mechanism Along with Approximations, Extensions, and Application to Refugee Matching. (arXiv:2007.03069v2 [math.OC] UPDATED)</h2>
<h3>Kirk Bansak</h3>
<p>In the classic linear assignment problem, items must be assigned to agents in
a manner that minimizes the sum of the costs for each item-agent assignment,
where the costs of all possible item-agent pairings are observed in advance.
This is a well-known and well-characterized problem, and algorithms exist to
attain the solution. In contrast, less attention has been given to the dynamic
version of this problem where each item must be assigned to an agent
sequentially upon arrival without knowledge of the future items to arrive.
Motivated by an application in the globally pressing domain of international
asylum and refugee resettlement, specifically that of matching refugees and
asylum seekers to geographic localities within a host country, this study
proposes an assignment mechanism that combines linear assignment programming
solutions with stochastic programming methods to minimize the expected loss
when assignments must be made in this dynamic sequential fashion, and offers an
algorithm for implementing the mechanism. The study also presents an
approximate version of the mechanism and accompanying algorithm that is more
computationally efficient, a prediction-based alternative approximation that
combines stochastic programming with machine learning to achieve even greater
efficiency, as well as heuristic mechanisms. In addition, the study provides an
extension to dynamic batch assignment, where items arrive and must be assigned
sequentially in groups. Real-world refugee resettlement data in the United
States are used to illustrate the methods and show how they could be
practically implemented in order to optimize refugees' and asylum seekers'
employment prospects (or other integration outcomes) in their host countries.
</p>
<a href="http://arxiv.org/abs/2007.03069" target="_blank">arXiv:2007.03069</a> [<a href="http://arxiv.org/pdf/2007.03069" target="_blank">pdf</a>]

<h2>A Topological Framework for Deep Learning. (arXiv:2008.13697v10 [cs.LG] UPDATED)</h2>
<h3>Mustafa Hajij, Kyle Istvan</h3>
<p>We utilize classical facts from topology to show that the classification
problem in machine learning is always solvable under very mild conditions.
Furthermore, we show that a softmax classification network acts on an input
topological space by a finite sequence of topological moves to achieve the
classification task. Moreover, given a training dataset, we show how
topological formalism can be used to suggest the appropriate architectural
choices for neural networks designed to be trained as classifiers on the data.
Finally, we show how the architecture of a neural network cannot be chosen
independently from the shape of the underlying data. To demonstrate these
results, we provide example datasets and show how they are acted upon by neural
nets from this topological perspective.
</p>
<a href="http://arxiv.org/abs/2008.13697" target="_blank">arXiv:2008.13697</a> [<a href="http://arxiv.org/pdf/2008.13697" target="_blank">pdf</a>]

<h2>SISTA: learning optimal transport costs under sparsity constraints. (arXiv:2009.08564v2 [math.OC] UPDATED)</h2>
<h3>Guillaume Carlier, Arnaud Dupuy, Alfred Galichon, Yifei Sun</h3>
<p>In this paper, we describe a novel iterative procedure called SISTA to learn
the underlying cost in optimal transport problems. SISTA is a hybrid between
two classical methods, coordinate descent ("S"-inkhorn) and proximal gradient
descent ("ISTA"). It alternates between a phase of exact minimization over the
transport potentials and a phase of proximal gradient descent over the
parameters of the transport cost. We prove that this method converges linearly,
and we illustrate on simulated examples that it is significantly faster than
both coordinate descent and ISTA. We apply it to estimating a model of
migration, which predicts the flow of migrants using country-specific
characteristics and pairwise measures of dissimilarity between countries. This
application demonstrates the effectiveness of machine learning in quantitative
social sciences.
</p>
<a href="http://arxiv.org/abs/2009.08564" target="_blank">arXiv:2009.08564</a> [<a href="http://arxiv.org/pdf/2009.08564" target="_blank">pdf</a>]

<h2>Deep Neural Network Training with Frank-Wolfe. (arXiv:2010.07243v2 [cs.LG] UPDATED)</h2>
<h3>Sebastian Pokutta, Christoph Spiegel, Max Zimmer</h3>
<p>This paper studies the empirical efficacy and benefits of using
projection-free first-order methods in the form of Conditional Gradients,
a.k.a. Frank-Wolfe methods, for training Neural Networks with constrained
parameters. We draw comparisons both to current state-of-the-art stochastic
Gradient Descent methods as well as across different variants of stochastic
Conditional Gradients. In particular, we show the general feasibility of
training Neural Networks whose parameters are constrained by a convex feasible
region using Frank-Wolfe algorithms and compare different stochastic variants.
We then show that, by choosing an appropriate region, one can achieve
performance exceeding that of unconstrained stochastic Gradient Descent and
matching state-of-the-art results relying on $L^2$-regularization. Lastly, we
also demonstrate that, besides impacting performance, the particular choice of
constraints can have a drastic impact on the learned representations.
</p>
<a href="http://arxiv.org/abs/2010.07243" target="_blank">arXiv:2010.07243</a> [<a href="http://arxiv.org/pdf/2010.07243" target="_blank">pdf</a>]

<h2>Software-Defined Multi-domain Tactical Networks: Foundations and Future Directions. (arXiv:2010.10509v1 [cs.NI])</h2>
<h3>Redowan Mahmud, Adel N. Toosi, Maria Alejandra Rodriguez, Sharat Chandra Madanapalli, Vijay Sivaraman, Len Sciacca, Christos Sioutis, Rajkumar Buyya</h3>
<p>Software Defined Networking (SDN) has emerged as a programmable approach for
provisioning and managing network resources by defining a clear separation
between the control and data forwarding planes. Nowadays SDN has gained
significant attention in the military domain. Its use in the battlefield
communication facilitates the end-to-end interactions and assists the
exploitation of edge computing resources for processing data in the proximity.
However, there are still various challenges related to the security and
interoperability among several heterogeneous, dynamic, intermittent, and data
packet technologies like multi-bearer network (MBN) that need to be addressed
to leverage the benefits of SDN in tactical environments. In this chapter, we
explicitly analyse these challenges and review the current research initiatives
in SDN-enabled tactical networks. We also present a taxonomy on SDN-based
tactical network orchestration according to the identified challenges and map
the existing works to the taxonomy aiming at determining the research gaps and
suggesting future directions.
</p>
<a href="http://arxiv.org/abs/2010.10509" target="_blank">arXiv:2010.10509</a> [<a href="http://arxiv.org/pdf/2010.10509" target="_blank">pdf</a>]

<h2>Image-Driven Furniture Style for Interactive 3D Scene Modeling. (arXiv:2010.10557v1 [cs.CV])</h2>
<h3>Tomer Weiss, Ilkay Yildiz, Nitin Agarwal, Esra Ataer-Cansizoglu, Jae-Woo Choi</h3>
<p>Creating realistic styled spaces is a complex task, which involves design
know-how for what furniture pieces go well together. Interior style follows
abstract rules involving color, geometry and other visual elements. Following
such rules, users manually select similar-style items from large repositories
of 3D furniture models, a process which is both laborious and time-consuming.
We propose a method for fast-tracking style-similarity tasks, by learning a
furniture's style-compatibility from interior scene images. Such images contain
more style information than images depicting single furniture. To understand
style, we train a deep learning network on a classification task. Based on
image embeddings extracted from our network, we measure stylistic compatibility
of furniture. We demonstrate our method with several 3D model
style-compatibility results, and with an interactive system for modeling
style-consistent scenes.
</p>
<a href="http://arxiv.org/abs/2010.10557" target="_blank">arXiv:2010.10557</a> [<a href="http://arxiv.org/pdf/2010.10557" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Optimization of COVID-19 Mitigation policies. (arXiv:2010.10560v1 [cs.LG])</h2>
<h3>Varun Kompella, Roberto Capobianco, Stacy Jong, Jonathan Browne, Spencer Fox, Lauren Meyers, Peter Wurman, Peter Stone</h3>
<p>The year 2020 has seen the COVID-19 virus lead to one of the worst global
pandemics in history. As a result, governments around the world are faced with
the challenge of protecting public health, while keeping the economy running to
the greatest extent possible. Epidemiological models provide insight into the
spread of these types of diseases and predict the effects of possible
intervention policies. However, to date,the even the most data-driven
intervention policies rely on heuristics. In this paper, we study how
reinforcement learning (RL) can be used to optimize mitigation policies that
minimize the economic impact without overwhelming the hospital capacity. Our
main contributions are (1) a novel agent-based pandemic simulator which, unlike
traditional models, is able to model fine-grained interactions among people at
specific locations in a community; and (2) an RL-based methodology for
optimizing fine-grained mitigation policies within this simulator. Our results
validate both the overall simulator behavior and the learned policies under
realistic conditions.
</p>
<a href="http://arxiv.org/abs/2010.10560" target="_blank">arXiv:2010.10560</a> [<a href="http://arxiv.org/pdf/2010.10560" target="_blank">pdf</a>]

<h2>A Survey on Deep Learning and Explainability for Automatic Image-based Medical Report Generation. (arXiv:2010.10563v1 [cs.CV])</h2>
<h3>Pablo Messina, Pablo Pino, Denis Parra, Alvaro Soto, Cecilia Besa, Sergio Uribe, Marcelo and&#xed;a, Cristian Tejos, Claudia Prieto, Daniel Capurro</h3>
<p>Every year physicians face an increasing demand of image-based diagnosis from
patients, a problem that can be addressed with recent artificial intelligence
methods. In this context, we survey works in the area of automatic report
generation from medical images, with emphasis on methods using deep neural
networks, with respect to: (1) Datasets, (2) Architecture Design, (3)
Explainability and (4) Evaluation Metrics. Our survey identifies interesting
developments, but also remaining challenges. Among them, the current evaluation
of generated reports is especially weak, since it mostly relies on traditional
Natural Language Processing (NLP) metrics, which do not accurately capture
medical correctness.
</p>
<a href="http://arxiv.org/abs/2010.10563" target="_blank">arXiv:2010.10563</a> [<a href="http://arxiv.org/pdf/2010.10563" target="_blank">pdf</a>]

<h2>Implicit recurrent networks: A novel approach to stationary input processing with recurrent neural networks in deep learning. (arXiv:2010.10564v1 [cs.LG])</h2>
<h3>Sebastian Sanokowski</h3>
<p>The brain cortex, which processes visual, auditory and sensory data in the
brain, is known to have many recurrent connections within its layers and from
higher to lower layers. But, in the case of machine learning with neural
networks, it is generally assumed that strict feed-forward architectures are
suitable for static input data, such as images, whereas recurrent networks are
required mainly for the processing of sequential input, such as language.
However, it is not clear whether also processing of static input data benefits
from recurrent connectivity. In this work, we introduce and test a novel
implementation of recurrent neural networks with lateral and feed-back
connections into deep learning. This departure from the strict feed-forward
structure prevents the use of the standard error backpropagation algorithm for
training the networks. Therefore we provide an algorithm which implements the
backpropagation algorithm on a implicit implementation of recurrent networks,
which is different from state-of-the-art implementations of recurrent neural
networks. Our method, in contrast to current recurrent neural networks,
eliminates the use of long chains of derivatives due to many iterative update
steps, which makes learning computationally less costly. It turns out that the
presence of recurrent intra-layer connections within a one-layer implicit
recurrent network enhances the performance of neural networks considerably: A
single-layer implicit recurrent network is able to solve the XOR problem, while
a feed-forward network with monotonically increasing activation function fails
at this task. Finally, we demonstrate that a two-layer implicit recurrent
architecture leads to a better performance in a regression task of physical
parameters from the measured trajectory of a damped pendulum.
</p>
<a href="http://arxiv.org/abs/2010.10564" target="_blank">arXiv:2010.10564</a> [<a href="http://arxiv.org/pdf/2010.10564" target="_blank">pdf</a>]

<h2>Better Highlighting: Creating Sub-Sentence Summary Highlights. (arXiv:2010.10566v1 [cs.CL])</h2>
<h3>Sangwoo Cho, Kaiqiang Song, Chen Li, Dong Yu, Hassan Foroosh, Fei Liu</h3>
<p>Amongst the best means to summarize is highlighting. In this paper, we aim to
generate summary highlights to be overlaid on the original documents to make it
easier for readers to sift through a large amount of text. The method allows
summaries to be understood in context to prevent a summarizer from distorting
the original meaning, of which abstractive summarizers usually fall short. In
particular, we present a new method to produce self-contained highlights that
are understandable on their own to avoid confusion. Our method combines
determinantal point processes and deep contextualized representations to
identify an optimal set of sub-sentence segments that are both important and
non-redundant to form summary highlights. To demonstrate the flexibility and
modeling power of our method, we conduct extensive experiments on summarization
datasets. Our analysis provides evidence that highlighting is a promising
avenue of research towards future summarization.
</p>
<a href="http://arxiv.org/abs/2010.10566" target="_blank">arXiv:2010.10566</a> [<a href="http://arxiv.org/pdf/2010.10566" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning in Lane Merge Coordination for Connected Vehicles. (arXiv:2010.10567v1 [cs.LG])</h2>
<h3>Omar Nassef, Luis Sequeira, Elias Salam, Toktam Mahmoodi</h3>
<p>In this paper, a framework for lane merge coordination is presented utilising
a centralised system, for connected vehicles. The delivery of trajectory
recommendations to the connected vehicles on the road is based on a Traffic
Orchestrator and a Data Fusion as the main components. Deep Reinforcement
Learning and data analysis is used to predict trajectory recommendations for
connected vehicles, taking into account unconnected vehicles for those
suggestions. The results highlight the adaptability of the Traffic
Orchestrator, when employing Dueling Deep Q-Network in an unseen real world
merging scenario. A performance comparison of different reinforcement learning
models and evaluation against Key Performance Indicator (KPI) are also
presented.
</p>
<a href="http://arxiv.org/abs/2010.10567" target="_blank">arXiv:2010.10567</a> [<a href="http://arxiv.org/pdf/2010.10567" target="_blank">pdf</a>]

<h2>Mitigating Sybil Attacks on Differential Privacy based Federated Learning. (arXiv:2010.10572v1 [cs.CR])</h2>
<h3>Yupeng Jiang, Yong Li, Yipeng Zhou, Xi Zheng</h3>
<p>In federated learning, machine learning and deep learning models are trained
globally on distributed devices. The state-of-the-art privacy-preserving
technique in the context of federated learning is user-level differential
privacy. However, such a mechanism is vulnerable to some specific model
poisoning attacks such as Sybil attacks. A malicious adversary could create
multiple fake clients or collude compromised devices in Sybil attacks to mount
direct model updates manipulation. Recent works on novel defense against model
poisoning attacks are difficult to detect Sybil attacks when differential
privacy is utilized, as it masks clients' model updates with perturbation. In
this work, we implement the first Sybil attacks on differential privacy based
federated learning architectures and show their impacts on model convergence.
We randomly compromise some clients by manipulating different noise levels
reflected by the local privacy budget epsilon of differential privacy on the
local model updates of these Sybil clients such that the global model
convergence rates decrease or even leads to divergence. We apply our attacks to
two recent aggregation defense mechanisms, called Krum and Trimmed Mean. Our
evaluation results on the MNIST and CIFAR-10 datasets show that our attacks
effectively slow down the convergence of the global models. We then propose a
method to keep monitoring the average loss of all participants in each round
for convergence anomaly detection and defend our Sybil attacks based on the
prediction cost reported from each client. Our empirical study demonstrates
that our defense approach effectively mitigates the impact of our Sybil attacks
on model convergence.
</p>
<a href="http://arxiv.org/abs/2010.10572" target="_blank">arXiv:2010.10572</a> [<a href="http://arxiv.org/pdf/2010.10572" target="_blank">pdf</a>]

<h2>Towards Causal Understanding of Fake News Dissemination. (arXiv:2010.10580v1 [cs.CY])</h2>
<h3>Lu Cheng, Ruocheng Guo, Kai Shu, Huan Liu</h3>
<p>Recent years have witnessed remarkable progress made towards the
computational detection of fake news. To mitigate its negative impact, however,
we argue that a critical element is to understand why people spread fake news.
Central to the question of "why" is the need to study the fake news sharing
behavior. Deeply related to user characteristics and online activities, fake
news sharing behavior is important to uncover the causal relationships between
user attributes and the probability of this user to spread fake news. One
obstacle in learning such user behavior is that most data is subject to
selection bias, rendering partially observed fake news dissemination among
users. To discover causal user attributes, we confront another obstacle of
finding the confounders in fake news dissemination. Drawing on theories in
causal inference, in this work, we first propose a principled approach to
unbiased modelings of fake news dissemination under selection bias. We then
consider the learned fake news sharing behavior as the measured confounder and
further identify the user attributes that potentially cause users to spread
fake news. We theoretically and empirically characterize the effectiveness of
the proposed approach and find that it could be useful in protecting society
from the perils of fake news.
</p>
<a href="http://arxiv.org/abs/2010.10580" target="_blank">arXiv:2010.10580</a> [<a href="http://arxiv.org/pdf/2010.10580" target="_blank">pdf</a>]

<h2>A Hub-and-Spoke Model for Content-Moderation-at-Scale on an Information-Sharing Platform. (arXiv:2010.10581v1 [cs.IR])</h2>
<h3>Gregory Coppola</h3>
<p>One of the most expensive parts of maintaining a modern information-sharing
platform (e.g., web search, social network) is the task of
content-moderation-at-scale. Content moderation is the binary task of
determining whether or not a given user-created message meets the editorial
team's content guidelines for the site. The challenge is that the number of
messages to check scales with the number of users, which is much larger than
the number of moderator-employees working for the given platform.

We show how content moderation can be achieved significantly more cheaply
than before, in the special case where all messages are public, by effectively
platformizing the task of content moderation. Our approach is to use a
hub-and-spoke model. The hub is the core editorial team delegated by the
management of the given platform. The spokes are the individual users. The
ratings of the editorial team create the labels for a statistical learning
algorithm, while the ratings of the users are used as features.

We have implemented a primitive version of this algorithm into our
open-source DimensionRank code base, found at "thinkdifferentagain.art".
</p>
<a href="http://arxiv.org/abs/2010.10581" target="_blank">arXiv:2010.10581</a> [<a href="http://arxiv.org/pdf/2010.10581" target="_blank">pdf</a>]

<h2>American Sign Language Identification Using Hand Trackpoint Analysis. (arXiv:2010.10590v1 [cs.CV])</h2>
<h3>Yugam Bajaj, Puru Malhotra</h3>
<p>Sign Language helps people with Speaking and Hearing Disabilities communicate
with others efficiently. Sign Language Recognition is a challenging area in the
field of computer vision and recent developments have been able to achieve near
perfect results for the task, though some challenges are yet to be solved. In
this paper we propose a novel machine learning based pipeline for American Sign
Language recognition using hand track points. We convert a hand gesture into a
series of hand track point coordinates that serve as an input to our system. In
order to make the solution more efficient, we experimented with 28 different
combinations of pre-processing techniques, each run on three different machine
learning algorithms namely k-Nearest Neighbours, Random Forests and a Neural
Network. Their performance was contrasted to determine the best pre-processing
scheme and Algorithm Pair. Our system achieved an Accuracy of 95.66% to
recognize American sign language gestures.
</p>
<a href="http://arxiv.org/abs/2010.10590" target="_blank">arXiv:2010.10590</a> [<a href="http://arxiv.org/pdf/2010.10590" target="_blank">pdf</a>]

<h2>Cross-Modal Information Maximization for Medical Imaging: CMIM. (arXiv:2010.10593v1 [cs.CV])</h2>
<h3>Tristan Sylvain, Francis Dutil, Tess Berthier, Lisa Di Jorio, Margaux Luck, Devon Hjelm, Yoshua Bengio</h3>
<p>In hospitals, data are siloed to specific information systems that make the
same information available under different modalities such as the different
medical imaging exams the patient undergoes (CT scans, MRI, PET, Ultrasound,
etc.) and their associated radiology reports. This offers unique opportunities
to obtain and use at train-time those multiple views of the same information
that might not always be available at test-time.

In this paper, we propose an innovative framework that makes the most of
available data by learning good representations of a multi-modal input that are
resilient to modality dropping at test-time, using recent advances in mutual
information maximization. By maximizing cross-modal information at train time,
we are able to outperform several state-of-the-art baselines in two different
settings, medical image classification, and segmentation. In particular, our
method is shown to have a strong impact on the inference-time performance of
weaker modalities.
</p>
<a href="http://arxiv.org/abs/2010.10593" target="_blank">arXiv:2010.10593</a> [<a href="http://arxiv.org/pdf/2010.10593" target="_blank">pdf</a>]

<h2>Counterfactual Explanations for Machine Learning: A Review. (arXiv:2010.10596v1 [cs.LG])</h2>
<h3>Sahil Verma, John Dickerson, Keegan Hines</h3>
<p>Machine learning plays a role in many deployed decision systems, often in
ways that are difficult or impossible to understand by human stakeholders.
Explaining, in a human-understandable way, the relationship between the input
and output of machine learning models is essential to the development of
trustworthy machine-learning-based systems. A burgeoning body of research seeks
to define the goals and methods of explainability in machine learning. In this
paper, we seek to review and categorize research on counterfactual
explanations, a specific class of explanation that provides a link between what
could have happened had input to a model been changed in a particular way.
Modern approaches to counterfactual explainability in machine learning draw
connections to the established legal doctrine in many countries, making them
appealing to fielded systems in high-impact areas such as finance and
healthcare. Thus, we design a rubric with desirable properties of
counterfactual explanation algorithms and comprehensively evaluate all
currently-proposed algorithms against that rubric. Our rubric provides easy
comparison and comprehension of the advantages and disadvantages of different
approaches and serves as an introduction to major research themes in this
field. We also identify gaps and discuss promising research directions in the
space of counterfactual explainability.
</p>
<a href="http://arxiv.org/abs/2010.10596" target="_blank">arXiv:2010.10596</a> [<a href="http://arxiv.org/pdf/2010.10596" target="_blank">pdf</a>]

<h2>Bayesian Attention Modules. (arXiv:2010.10604v1 [stat.ML])</h2>
<h3>Xinjie Fan, Shujian Zhang, Bo Chen, Mingyuan Zhou</h3>
<p>Attention modules, as simple and effective tools, have not only enabled deep
neural networks to achieve state-of-the-art results in many domains, but also
enhanced their interpretability. Most current models use deterministic
attention modules due to their simplicity and ease of optimization. Stochastic
counterparts, on the other hand, are less popular despite their potential
benefits. The main reason is that stochastic attention often introduces
optimization issues or requires significant model changes. In this paper, we
propose a scalable stochastic version of attention that is easy to implement
and optimize. We construct simplex-constrained attention distributions by
normalizing reparameterizable distributions, making the training process
differentiable. We learn their parameters in a Bayesian framework where a
data-dependent prior is introduced for regularization. We apply the proposed
stochastic attention modules to various attention-based models, with
applications to graph node classification, visual question answering, image
captioning, machine translation, and language understanding. Our experiments
show the proposed method brings consistent improvements over the corresponding
baselines.
</p>
<a href="http://arxiv.org/abs/2010.10604" target="_blank">arXiv:2010.10604</a> [<a href="http://arxiv.org/pdf/2010.10604" target="_blank">pdf</a>]

<h2>A primer on model-guided exploration of fitness landscapes for biological sequence design. (arXiv:2010.10614v1 [q-bio.QM])</h2>
<h3>Sam Sinai, Eric Kelsic</h3>
<p>Machine learning methods are increasingly employed to address challenges
faced by biologists. One area that will greatly benefit from this
cross-pollination is the problem of biological sequence design, which has
massive potential for therapeutic applications. However, significant
inefficiencies remain in communication between these fields which result in
biologists finding the progress in machine learning inaccessible, and hinder
machine learning scientists from contributing to impactful problems in
bioengineering. Sequence design can be seen as a search process on a discrete,
high-dimensional space, where each sequence is associated with a function. This
sequence-to-function map is known as a "Fitness Landscape". Designing a
sequence with a particular function is hence a matter of "discovering" such a
(often rare) sequence within this space. Today we can build predictive models
with good interpolation ability due to impressive progress in the synthesis and
testing of biological sequences in large numbers, which enables model training
and validation. However, it often remains a challenge to find useful sequences
with the properties that we like using these models. In particular, in this
primer we highlight that algorithms for experimental design, what we call
"exploration strategies", are a related, yet distinct problem from building
good models of sequence-to-function maps. We review advances and insights from
current literature -- by no means a complete treatment -- while highlighting
desirable features of optimal model-guided exploration, and cover potential
pitfalls drawn from our own experience. This primer can serve as a starting
point for researchers from different domains that are interested in the problem
of searching a sequence space with a model, but are perhaps unaware of
approaches that originate outside their field.
</p>
<a href="http://arxiv.org/abs/2010.10614" target="_blank">arXiv:2010.10614</a> [<a href="http://arxiv.org/pdf/2010.10614" target="_blank">pdf</a>]

<h2>Runtime Safety Assurance Using Reinforcement Learning. (arXiv:2010.10618v1 [cs.LG])</h2>
<h3>Christopher Lazarus, James G. Lopez, Mykel J. Kochenderfer</h3>
<p>The airworthiness and safety of a non-pedigreed autopilot must be verified,
but the cost to formally do so can be prohibitive. We can bypass formal
verification of non-pedigreed components by incorporating Runtime Safety
Assurance (RTSA) as mechanism to ensure safety. RTSA consists of a
meta-controller that observes the inputs and outputs of a non-pedigreed
component and verifies formally specified behavior as the system operates. When
the system is triggered, a verified recovery controller is deployed. Recovery
controllers are designed to be safe but very likely disruptive to the
operational objective of the system, and thus RTSA systems must balance safety
and efficiency. The objective of this paper is to design a meta-controller
capable of identifying unsafe situations with high accuracy. High dimensional
and non-linear dynamics in which modern controllers are deployed along with the
black-box nature of the nominal controllers make this a difficult problem.
Current approaches rely heavily on domain expertise and human engineering. We
frame the design of RTSA with the Markov decision process (MDP) framework and
use reinforcement learning (RL) to solve it. Our learned meta-controller
consistently exhibits superior performance in our experiments compared to our
baseline, human engineered approach.
</p>
<a href="http://arxiv.org/abs/2010.10618" target="_blank">arXiv:2010.10618</a> [<a href="http://arxiv.org/pdf/2010.10618" target="_blank">pdf</a>]

<h2>Optimising the Performance of Convolutional Neural Networks across Computing Systems using Transfer Learning. (arXiv:2010.10621v1 [cs.LG])</h2>
<h3>Rik Mulder, Valentin Radu, Christophe Dubach</h3>
<p>The choice of convolutional routines (primitives) to implement neural
networks has a tremendous impact on their inference performance (execution
speed) on a given hardware platform. To optimise a neural network by primitive
selection, the optimal primitive is identified for each layer of the network.
This process requires a lengthy profiling stage, iterating over all the
available primitives for each layer configuration, to measure their execution
time on the target platform. Because each primitive exploits the hardware in
different ways, new profiling is needed to obtain the best performance when
moving to another platform. In this work, we propose to replace this
prohibitively expensive profiling stage with a machine learning based approach
of performance modeling. Our approach speeds up the optimisation time
drastically. After training, our performance model can estimate the performance
of convolutional primitives in any layer configuration. The time to optimise
the execution of large neural networks via primitive selection is reduced from
hours to just seconds. Our performance model is easily transferable to other
target platforms. We demonstrate this by training a performance model on an
Intel platform and performing transfer learning to AMD and ARM processor
devices with minimal profiled samples.
</p>
<a href="http://arxiv.org/abs/2010.10621" target="_blank">arXiv:2010.10621</a> [<a href="http://arxiv.org/pdf/2010.10621" target="_blank">pdf</a>]

<h2>Promoting High Diversity Ensemble Learning with EnsembleBench. (arXiv:2010.10623v1 [cs.LG])</h2>
<h3>Yanzhao Wu, Ling Liu, Zhongwei Xie, Juhyun Bae, Ka-Ho Chow, Wenqi Wei</h3>
<p>Ensemble learning is gaining renewed interests in recent years. This paper
presents EnsembleBench, a holistic framework for evaluating and recommending
high diversity and high accuracy ensembles. The design of EnsembleBench offers
three novel features: (1) EnsembleBench introduces a set of quantitative
metrics for assessing the quality of ensembles and for comparing alternative
ensembles constructed for the same learning tasks. (2) EnsembleBench implements
a suite of baseline diversity metrics and optimized diversity metrics for
identifying and selecting ensembles with high diversity and high quality,
making it an effective framework for benchmarking, evaluating and recommending
high diversity model ensembles. (3) Four representative ensemble consensus
methods are provided in the first release of EnsembleBench, enabling empirical
study on the impact of consensus methods on ensemble accuracy. A comprehensive
experimental evaluation on popular benchmark datasets demonstrates the utility
and effectiveness of EnsembleBench for promoting high diversity ensembles and
boosting the overall performance of selected ensembles.
</p>
<a href="http://arxiv.org/abs/2010.10623" target="_blank">arXiv:2010.10623</a> [<a href="http://arxiv.org/pdf/2010.10623" target="_blank">pdf</a>]

<h2>Data-driven Identification of 2D Partial Differential Equations using extracted physical features. (arXiv:2010.10626v1 [cs.LG])</h2>
<h3>Kazem Meidani, Amir Barati Farimani</h3>
<p>Many scientific phenomena are modeled by Partial Differential Equations
(PDEs). The development of data gathering tools along with the advances in
machine learning (ML) techniques have raised opportunities for data-driven
identification of governing equations from experimentally observed data. We
propose an ML method to discover the terms involved in the equation from
two-dimensional spatiotemporal data. Robust and useful physical features are
extracted from data samples to represent the specific behaviors imposed by each
mathematical term in the equation. Compared to the previous models, this idea
provides us with the ability to discover 2D equations with time derivatives of
different orders, and also to identify new underlying physics on which the
model has not been trained. Moreover, the model can work with small sets of
low-resolution data while avoiding numerical differentiations. The results
indicate robustness of the features extracted based on prior knowledge in
comparison to automatically detected features by a Three-dimensional
Convolutional Neural Network (3D CNN) given the same amounts of data. Although
particular PDEs are studied in this work, the idea of the proposed approach
could be extended for reliable identification of various PDEs.
</p>
<a href="http://arxiv.org/abs/2010.10626" target="_blank">arXiv:2010.10626</a> [<a href="http://arxiv.org/pdf/2010.10626" target="_blank">pdf</a>]

<h2>ENSURE: Ensemble Stein's Unbiased Risk Estimator for Unsupervised Learning. (arXiv:2010.10631v1 [cs.CV])</h2>
<h3>Hemant Kumar Aggarwal, Mathews Jacob</h3>
<p>Deep learning accelerates the MR image reconstruction process after offline
training of a deep neural network from a large volume of clean and fully
sampled data. Unfortunately, fully sampled images may not be available or are
difficult to acquire in several application areas such as high-resolution
imaging. Previous studies have utilized Stein's Unbiased Risk Estimator (SURE)
as a mean square error (MSE) estimate for the image denoising problem. Unrolled
reconstruction algorithms, where the denoiser at each iteration is trained
using SURE, has also been introduced. Unfortunately, the end-to-end training of
a network using SURE remains challenging since the projected SURE loss is a
poor approximation to the MSE, especially in the heavily undersampled setting.
We propose an ENsemble SURE (ENSURE) approach to train a deep network only from
undersampled measurements. In particular, we show that training a network using
an ensemble of images, each acquired with a different sampling pattern, can
closely approximate the MSE. Our preliminary experimental results show that the
proposed ENSURE approach gives comparable reconstruction quality to supervised
learning and a recent unsupervised learning method.
</p>
<a href="http://arxiv.org/abs/2010.10631" target="_blank">arXiv:2010.10631</a> [<a href="http://arxiv.org/pdf/2010.10631" target="_blank">pdf</a>]

<h2>Robust Constrained Reinforcement Learning for Continuous Control with Model Misspecification. (arXiv:2010.10644v1 [cs.LG])</h2>
<h3>Daniel J. Mankowitz, Dan A. Calian, Rae Jeong, Cosmin Paduraru, Nicolas Heess, Sumanth Dathathri, Martin Riedmiller, Timothy Mann</h3>
<p>Many real-world physical control systems are required to satisfy constraints
upon deployment. Furthermore, real-world systems are often subject to effects
such as non-stationarity, wear-and-tear, uncalibrated sensors and so on. Such
effects effectively perturb the system dynamics and can cause a policy trained
successfully in one domain to perform poorly when deployed to a perturbed
version of the same domain. This can affect a policy's ability to maximize
future rewards as well as the extent to which it satisfies constraints. We
refer to this as constrained model misspecification. We present an algorithm
with theoretical guarantees that mitigates this form of misspecification, and
showcase its performance in multiple Mujoco tasks from the Real World
Reinforcement Learning (RWRL) suite.
</p>
<a href="http://arxiv.org/abs/2010.10644" target="_blank">arXiv:2010.10644</a> [<a href="http://arxiv.org/pdf/2010.10644" target="_blank">pdf</a>]

<h2>Axiom Learning and Belief Tracing for Transparent Decision Making in Robotics. (arXiv:2010.10645v1 [cs.AI])</h2>
<h3>Tiago Mota, Mohan Sridharan</h3>
<p>A robot's ability to provide descriptions of its decisions and beliefs
promotes effective collaboration with humans. Providing such transparency is
particularly challenging in integrated robot systems that include
knowledge-based reasoning methods and data-driven learning algorithms. Towards
addressing this challenge, our architecture couples the complementary strengths
of non-monotonic logical reasoning, deep learning, and decision-tree induction.
During reasoning and learning, the architecture enables a robot to provide
on-demand relational descriptions of its decisions, beliefs, and the outcomes
of hypothetical actions. These capabilities are grounded and evaluated in the
context of scene understanding tasks and planning tasks performed using
simulated images and images from a physical robot manipulating tabletop
objects.
</p>
<a href="http://arxiv.org/abs/2010.10645" target="_blank">arXiv:2010.10645</a> [<a href="http://arxiv.org/pdf/2010.10645" target="_blank">pdf</a>]

<h2>Towards End-to-End In-Image Neural Machine Translation. (arXiv:2010.10648v1 [cs.CL])</h2>
<h3>Elman Mansimov, Mitchell Stern, Mia Chen, Orhan Firat, Jakob Uszkoreit, Puneet Jain</h3>
<p>In this paper, we offer a preliminary investigation into the task of in-image
machine translation: transforming an image containing text in one language into
an image containing the same text in another language. We propose an end-to-end
neural model for this task inspired by recent approaches to neural machine
translation, and demonstrate promising initial results based purely on
pixel-level supervision. We then offer a quantitative and qualitative
evaluation of our system outputs and discuss some common failure modes.
Finally, we conclude with directions for future work.
</p>
<a href="http://arxiv.org/abs/2010.10648" target="_blank">arXiv:2010.10648</a> [<a href="http://arxiv.org/pdf/2010.10648" target="_blank">pdf</a>]

<h2>Exploring Overcomplete Representations for Single Image Deraining using CNNs. (arXiv:2010.10661v1 [eess.IV])</h2>
<h3>Rajeev Yasarla (Student Member, IEEE), Jeya Maria Jose Valanarasu (Student Member, IEEE), Vishal M. Patel (Senior Member, IEEE)</h3>
<p>Removal of rain streaks from a single image is an extremely challenging
problem since the rainy images often contain rain streaks of different size,
shape, direction and density. Most recent methods for deraining use a deep
network following a generic "encoder-decoder" architecture which captures
low-level features across the initial layers and high-level features in the
deeper layers. For the task of deraining, the rain streaks which are to be
removed are relatively small and focusing much on global features is not an
efficient way to solve the problem. To this end, we propose using an
overcomplete convolutional network architecture which gives special attention
in learning local structures by restraining the receptive field of filters. We
combine it with U-Net so that it does not lose out on the global structures as
well while focusing more on low-level features, to compute the derained image.
The proposed network called, Over-and-Under Complete Deraining Network (OUCD),
consists of two branches: overcomplete branch which is confined to small
receptive field size in order to focus on the local structures and an
undercomplete branch that has larger receptive fields to primarily focus on
global structures. Extensive experiments on synthetic and real datasets
demonstrate that the proposed method achieves significant improvements over the
recent state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.10661" target="_blank">arXiv:2010.10661</a> [<a href="http://arxiv.org/pdf/2010.10661" target="_blank">pdf</a>]

<h2>Iterative Amortized Policy Optimization. (arXiv:2010.10670v1 [cs.LG])</h2>
<h3>Joseph Marino, Alexandre Pich&#xe9;, Alessandro Davide Ialongo, Yisong Yue</h3>
<p>Policy networks are a central feature of deep reinforcement learning (RL)
algorithms for continuous control, enabling the estimation and sampling of
high-value actions. From the variational inference perspective on RL, policy
networks, when employed with entropy or KL regularization, are a form of
amortized optimization, optimizing network parameters rather than the policy
distributions directly. However, this direct amortized mapping can empirically
yield suboptimal policy estimates. Given this perspective, we consider the more
flexible class of iterative amortized optimizers. We demonstrate that the
resulting technique, iterative amortized policy optimization, yields
performance improvements over conventional direct amortization methods on
benchmark continuous control tasks.
</p>
<a href="http://arxiv.org/abs/2010.10670" target="_blank">arXiv:2010.10670</a> [<a href="http://arxiv.org/pdf/2010.10670" target="_blank">pdf</a>]

<h2>Pushing the Limits of AMR Parsing with Self-Learning. (arXiv:2010.10673v1 [cs.CL])</h2>
<h3>Young-Suk Lee, Ramon Fernandez Astudillo, Tahira Naseem, Revanth Gangi Reddy, Radu Florian, Salim Roukos</h3>
<p>Abstract Meaning Representation (AMR) parsing has experienced a notable
growth in performance in the last two years, due both to the impact of transfer
learning and the development of novel architectures specific to AMR. At the
same time, self-learning techniques have helped push the performance boundaries
of other natural language processing applications, such as machine translation
or question answering. In this paper, we explore different ways in which
trained models can be applied to improve AMR parsing performance, including
generation of synthetic text and AMR annotations as well as refinement of
actions oracle. We show that, without any additional human annotations, these
techniques improve an already performant parser and achieve state-of-the-art
results on AMR 1.0 and AMR 2.0.
</p>
<a href="http://arxiv.org/abs/2010.10673" target="_blank">arXiv:2010.10673</a> [<a href="http://arxiv.org/pdf/2010.10673" target="_blank">pdf</a>]

<h2>Deep Learning Frameworks for Pavement Distress Classification: A Comparative Analysis. (arXiv:2010.10681v1 [cs.CV])</h2>
<h3>Vishal Mandal, Abdul Rashid Mussah, Yaw Adu-Gyamfi</h3>
<p>Automatic detection and classification of pavement distresses is critical in
timely maintaining and rehabilitating pavement surfaces. With the evolution of
deep learning and high performance computing, the feasibility of vision-based
pavement defect assessments has significantly improved. In this study, the
authors deploy state-of-the-art deep learning algorithms based on different
network backbones to detect and characterize pavement distresses. The influence
of different backbone models such as CSPDarknet53, Hourglass-104 and
EfficientNet were studied to evaluate their classification performance. The
models were trained using 21,041 images captured across urban and rural streets
of Japan, Czech Republic and India. Finally, the models were assessed based on
their ability to predict and classify distresses, and tested using F1 score
obtained from the statistical precision and recall values. The best performing
model achieved an F1 score of 0.58 and 0.57 on two test datasets released by
the IEEE Global Road Damage Detection Challenge. The source code including the
trained models are made available at [1].
</p>
<a href="http://arxiv.org/abs/2010.10681" target="_blank">arXiv:2010.10681</a> [<a href="http://arxiv.org/pdf/2010.10681" target="_blank">pdf</a>]

<h2>A Graph Based and Patient Demographics Aware Dialogue System for Disease Diagnosis. (arXiv:2010.10699v1 [cs.CL])</h2>
<h3>Xinyan Zhao, Liangwei Chen, Huanhuan Chen</h3>
<p>A dialogue system for disease diagnosis aims at making a diagnosis by
conversing with patients. Existing disease diagnosis dialogue systems highly
rely on data-driven methods and statistical features, lacking profound
comprehension of medical knowledge, such as symptom-disease relations. In
addition, previous work pays less attention to demographic attributes of a
patient, which are important factors in clinical diagnoses. To tackle these
issues, this work presents a graph based and demographic attributes aware
dialogue system for disease diagnosis. Specifically, we first build a weighted
bidirectional graph based on clinical dialogues to depict the relationship
between symptoms and diseases and then present a bidirectional graph based deep
Q-network (BG-DQN) for dialogue management. By extending Graph Convolutional
Network (GCN) to learn the embeddings of diseases and symptoms from both the
structural and attribute information in the graph, BG-DQN could capture the
relations between diseases and symptoms better. Moreover, BG-DQN also encodes
the demographic attributes of a patient to assist the disease diagnosis
process. Experimental results show that the proposed dialogue system
outperforms several competitive methods in terms of diagnostic accuracy. More
importantly, our method can complete the task with less dialogue turns and
possesses better distinguishing capability on diseases with similar symptoms.
</p>
<a href="http://arxiv.org/abs/2010.10699" target="_blank">arXiv:2010.10699</a> [<a href="http://arxiv.org/pdf/2010.10699" target="_blank">pdf</a>]

<h2>Geometry-based Occlusion-Aware Unsupervised Stereo Matching for Autonomous Driving. (arXiv:2010.10700v1 [cs.CV])</h2>
<h3>Liang Peng, Dan Deng, Deng Cai</h3>
<p>Recently, there are emerging many stereo matching methods for autonomous
driving based on unsupervised learning. Most of them take advantage of
reconstruction losses to remove dependency on disparity groundtruth. Occlusion
handling is a challenging problem in stereo matching, especially for
unsupervised methods. Previous unsupervised methods failed to take full
advantage of geometry properties in occlusion handling. In this paper, we
introduce an effective way to detect occlusion regions and propose a novel
unsupervised training strategy to deal with occlusion that only uses the
predicted left disparity map, by making use of its geometry features in an
iterative way. In the training process, we regard the predicted left disparity
map as pseudo groundtruth and infer occluded regions using geometry features.
The resulting occlusion mask is then used in either training, post-processing,
or both of them as guidance. Experiments show that our method could deal with
the occlusion problem effectively and significantly outperforms the other
unsupervised methods for stereo matching. Moreover, our occlusion-aware
strategies can be extended to the other stereo methods conveniently and improve
their performances.
</p>
<a href="http://arxiv.org/abs/2010.10700" target="_blank">arXiv:2010.10700</a> [<a href="http://arxiv.org/pdf/2010.10700" target="_blank">pdf</a>]

<h2>Boosting Gradient for White-Box Adversarial Attacks. (arXiv:2010.10712v1 [cs.LG])</h2>
<h3>Hongying Liu, Zhenyu Zhou, Fanhua Shang, Xiaoyu Qi, Yuanyuan Liu, Licheng Jiao</h3>
<p>Deep neural networks (DNNs) are playing key roles in various artificial
intelligence applications such as image classification and object recognition.
However, a growing number of studies have shown that there exist adversarial
examples in DNNs, which are almost imperceptibly different from original
samples, but can greatly change the network output. Existing white-box attack
algorithms can generate powerful adversarial examples. Nevertheless, most of
the algorithms concentrate on how to iteratively make the best use of gradients
to improve adversarial performance. In contrast, in this paper, we focus on the
properties of the widely-used ReLU activation function, and discover that there
exist two phenomena (i.e., wrong blocking and over transmission) misleading the
calculation of gradients in ReLU during the backpropagation. Both issues
enlarge the difference between the predicted changes of the loss function from
gradient and corresponding actual changes, and mislead the gradients which
results in larger perturbations. Therefore, we propose a universal adversarial
example generation method, called ADV-ReLU, to enhance the performance of
gradient based white-box attack algorithms. During the backpropagation of the
network, our approach calculates the gradient of the loss function versus
network input, maps the values to scores, and selects a part of them to update
the misleading gradients. Comprehensive experimental results on \emph{ImageNet}
demonstrate that our ADV-ReLU can be easily integrated into many
state-of-the-art gradient-based white-box attack algorithms, as well as
transferred to black-box attack attackers, to further decrease perturbations in
the ${\ell _2}$-norm.
</p>
<a href="http://arxiv.org/abs/2010.10712" target="_blank">arXiv:2010.10712</a> [<a href="http://arxiv.org/pdf/2010.10712" target="_blank">pdf</a>]

<h2>TargetDrop: A Targeted Regularization Method for Convolutional Neural Networks. (arXiv:2010.10716v1 [cs.CV])</h2>
<h3>Hui Zhu, Xiaofang Zhao</h3>
<p>Dropout regularization has been widely used in deep learning but performs
less effective for convolutional neural networks since the spatially correlated
features allow dropped information to still flow through the networks. Some
structured forms of dropout have been proposed to address this but prone to
result in over or under regularization as features are dropped randomly. In
this paper, we propose a targeted regularization method named TargetDrop which
incorporates the attention mechanism to drop the discriminative feature units.
Specifically, it masks out the target regions of the feature maps corresponding
to the target channels. Experimental results compared with the other methods or
applied for different networks demonstrate the regularization effect of our
method.
</p>
<a href="http://arxiv.org/abs/2010.10716" target="_blank">arXiv:2010.10716</a> [<a href="http://arxiv.org/pdf/2010.10716" target="_blank">pdf</a>]

<h2>High-Capacity Complex Convolutional Neural Networks For I/Q Modulation Classification. (arXiv:2010.10717v1 [cs.CV])</h2>
<h3>Jakob Krzyston, Rajib Bhattacharjea, Andrew Stark</h3>
<p>I/Q modulation classification is a unique pattern recognition problem as the
data for each class varies in quality, quantified by signal to noise ratio
(SNR), and has structure in the complex-plane. Previous work shows treating
these samples as complex-valued signals and computing complex-valued
convolutions within deep learning frameworks significantly increases the
performance over comparable shallow CNN architectures. In this work, we claim
state of the art performance by enabling high-capacity architectures containing
residual and/or dense connections to compute complex-valued convolutions, with
peak classification accuracy of 92.4% on a benchmark classification problem,
the RadioML 2016.10a dataset. We show statistically significant improvements in
all networks with complex convolutions for I/Q modulation classification.
Complexity and inference speed analyses show models with complex convolutions
substantially outperform architectures with a comparable number of parameters
and comparable speed by over 10% in each case.
</p>
<a href="http://arxiv.org/abs/2010.10717" target="_blank">arXiv:2010.10717</a> [<a href="http://arxiv.org/pdf/2010.10717" target="_blank">pdf</a>]

<h2>ComboLoss for Facial Attractiveness Analysis with Squeeze-and-Excitation Networks. (arXiv:2010.10721v1 [cs.MM])</h2>
<h3>Lu Xu, Jinhai Xiang</h3>
<p>Loss function is crucial for model training and feature representation
learning, conventional models usually regard facial attractiveness recognition
task as a regression problem, and adopt MSE loss or Huber variant loss as
supervision to train a deep convolutional neural network (CNN) to predict
facial attractiveness score. Little work has been done to systematically
compare the performance of diverse loss functions. In this paper, we firstly
systematically analyze model performance under diverse loss functions. Then a
novel loss function named ComboLoss is proposed to guide the SEResNeXt50
network. The proposed method achieves state-of-the-art performance on SCUT-FBP,
HotOrNot and SCUT-FBP5500 datasets with an improvement of 1.13%, 2.1% and 0.57%
compared with prior arts, respectively. Code and models are available at
https://github.com/lucasxlu/ComboLoss.git.
</p>
<a href="http://arxiv.org/abs/2010.10721" target="_blank">arXiv:2010.10721</a> [<a href="http://arxiv.org/pdf/2010.10721" target="_blank">pdf</a>]

<h2>Learning Disentangled Phone and Speaker Representations in a Semi-Supervised VQ-VAE Paradigm. (arXiv:2010.10727v1 [eess.AS])</h2>
<h3>Jennifer Williams, Yi Zhao, Erica Cooper, Junichi Yamagishi</h3>
<p>We present a new approach to disentangle speaker voice and phone content by
introducing new components to the VQ-VAE architecture for speech synthesis. The
original VQ-VAE does not generalize well to unseen speakers or content. To
alleviate this problem, we have incorporated a speaker encoder and speaker VQ
codebook that learns global speaker characteristics entirely separate from the
existing sub-phone codebooks. We also compare two training methods:
self-supervised with global conditions and semi-supervised with speaker labels.
Adding a speaker VQ component improves objective measures of speech synthesis
quality (estimated MOS, speaker similarity, ASR-based intelligibility) and
provides learned representations that are meaningful. Our speaker VQ codebook
indices can be used in a simple speaker diarization task and perform slightly
better than an x-vector baseline. Additionally, phones can be recognized from
sub-phone VQ codebook indices in our semi-supervised VQ-VAE better than
self-supervised with global conditions.
</p>
<a href="http://arxiv.org/abs/2010.10727" target="_blank">arXiv:2010.10727</a> [<a href="http://arxiv.org/pdf/2010.10727" target="_blank">pdf</a>]

<h2>Heterogeneous Hypergraph Embedding for Graph Classification. (arXiv:2010.10728v1 [cs.SI])</h2>
<h3>Xiangguo Sun, Hongzhi Yin, Bo Liu, Hongxu Chen, Jiuxin Cao, Yingxia Shao, Nguyen Quoc Viet Hung</h3>
<p>Recently, graph neural networks have been widely used for network embedding
because of their prominent performance in pairwise relationship learning. In
the real world, a more natural and common situation is the coexistence of
pairwise relationships and complex non-pairwise relationships, which is,
however, rarely studied. In light of this, we propose a graph neural
network-based representation learning framework for heterogeneous hypergraphs,
an extension of conventional graphs, which can well characterize multiple
non-pairwise relations. Our framework first projects the heterogeneous
hypergraph into a series of snapshots and then we take the Wavelet basis to
perform localized hypergraph convolution. Since the Wavelet basis is usually
much sparser than the Fourier basis, we develop an efficient polynomial
approximation to the basis to replace the time-consuming Laplacian
decomposition. Extensive evaluations have been conducted and the experimental
results show the superiority of our method. In addition to the standard tasks
of network embedding evaluation such as node classification, we also apply our
method to the task of spammers detection and the superior performance of our
framework shows that relationships beyond pairwise are also advantageous in the
spammer detection.
</p>
<a href="http://arxiv.org/abs/2010.10728" target="_blank">arXiv:2010.10728</a> [<a href="http://arxiv.org/pdf/2010.10728" target="_blank">pdf</a>]

<h2>Directed Graph Representation through Vector Cross Product. (arXiv:2010.10737v1 [cs.LG])</h2>
<h3>Ramanujam Madhavan, Mohit Wadhwa</h3>
<p>Graph embedding methods embed the nodes in a graph in low dimensional vector
space while preserving graph topology to carry out the downstream tasks such as
link prediction, node recommendation and clustering. These tasks depend on a
similarity measure such as cosine similarity and Euclidean distance between a
pair of embeddings that are symmetric in nature and hence do not hold good for
directed graphs. Recent work on directed graphs, HOPE, APP, and NERD, proposed
to preserve the direction of edges among nodes by learning two embeddings,
source and target, for every node. However, these methods do not take into
account the properties of directed edges explicitly. To understand the
directional relation among nodes, we propose a novel approach that takes
advantage of the non commutative property of vector cross product to learn
embeddings that inherently preserve the direction of edges among nodes. We
learn the node embeddings through a Siamese neural network where the
cross-product operation is incorporated into the network architecture. Although
cross product between a pair of vectors is defined in three dimensional, the
approach is extended to learn N dimensional embeddings while maintaining the
non-commutative property. In our empirical experiments on three real-world
datasets, we observed that even very low dimensional embeddings could
effectively preserve the directional property while outperforming some of the
state-of-the-art methods on link prediction and node recommendation tasks
</p>
<a href="http://arxiv.org/abs/2010.10737" target="_blank">arXiv:2010.10737</a> [<a href="http://arxiv.org/pdf/2010.10737" target="_blank">pdf</a>]

<h2>Safety Verification of Model Based Reinforcement Learning Controllers. (arXiv:2010.10740v1 [cs.LG])</h2>
<h3>Akshita Gupta, Inseok Hwang</h3>
<p>Model-based reinforcement learning (RL) has emerged as a promising tool for
developing controllers for real world systems (e.g., robotics, autonomous
driving, etc.). However, real systems often have constraints imposed on their
state space which must be satisfied to ensure the safety of the system and its
environment. Developing a verification tool for RL algorithms is challenging
because the non-linear structure of neural networks impedes analytical
verification of such models or controllers. To this end, we present a novel
safety verification framework for model-based RL controllers using reachable
set analysis. The proposed frame-work can efficiently handle models and
controllers which are represented using neural networks. Additionally, if a
controller fails to satisfy the safety constraints in general, the proposed
framework can also be used to identify the subset of initial states from which
the controller can be safely executed.
</p>
<a href="http://arxiv.org/abs/2010.10740" target="_blank">arXiv:2010.10740</a> [<a href="http://arxiv.org/pdf/2010.10740" target="_blank">pdf</a>]

<h2>Model selection in reconciling hierarchical time series. (arXiv:2010.10742v1 [cs.LG])</h2>
<h3>Mahdi Abolghasemi, Rob Hyndman, Evangelos Spiliotis, Christoph Bergmeir</h3>
<p>Model selection has been proven an effective strategy for improving accuracy
in time series forecasting applications. However, when dealing with
hierarchical time series, apart from selecting the most appropriate forecasting
model, forecasters have also to select a suitable method for reconciling the
base forecasts produced for each series to make sure they are coherent.
Although some hierarchical forecasting methods like minimum trace are strongly
supported both theoretically and empirically for reconciling the base
forecasts, there are still circumstances under which they might not produce the
most accurate results, being outperformed by other methods. In this paper we
propose an approach for dynamically selecting the most appropriate hierarchical
forecasting method and succeeding better forecasting accuracy along with
coherence. The approach, to be called conditional hierarchical forecasting, is
based on Machine Learning classification methods and uses time series features
as leading indicators for performing the selection for each hierarchy examined
considering a variety of alternatives. Our results suggest that conditional
hierarchical forecasting leads to significantly more accurate forecasts than
standard approaches, especially at lower hierarchical levels.
</p>
<a href="http://arxiv.org/abs/2010.10742" target="_blank">arXiv:2010.10742</a> [<a href="http://arxiv.org/pdf/2010.10742" target="_blank">pdf</a>]

<h2>Multi-Unit Transformer for Neural Machine Translation. (arXiv:2010.10743v1 [cs.CL])</h2>
<h3>Jianhao Yan, Fandong Meng, Jie Zhou</h3>
<p>Transformer models achieve remarkable success in Neural Machine Translation.
Many efforts have been devoted to deepening the Transformer by stacking several
units (i.e., a combination of Multihead Attentions and FFN) in a cascade, while
the investigation over multiple parallel units draws little attention. In this
paper, we propose the Multi-Unit Transformers (MUTE), which aim to promote the
expressiveness of the Transformer by introducing diverse and complementary
units. Specifically, we use several parallel units and show that modeling with
multiple units improves model performance and introduces diversity. Further, to
better leverage the advantage of the multi-unit setting, we design biased
module and sequential dependency that guide and encourage complementariness
among different units. Experimental results on three machine translation tasks,
the NIST Chinese-to-English, WMT'14 English-to-German and WMT'18
Chinese-to-English, show that the MUTE models significantly outperform the
Transformer-Base, by up to +1.52, +1.90 and +1.10 BLEU points, with only a mild
drop in inference speed (about 3.1%). In addition, our methods also surpass the
Transformer-Big model, with only 54\% of its parameters. These results
demonstrate the effectiveness of the MUTE, as well as its efficiency in both
the inference process and parameter usage.
</p>
<a href="http://arxiv.org/abs/2010.10743" target="_blank">arXiv:2010.10743</a> [<a href="http://arxiv.org/pdf/2010.10743" target="_blank">pdf</a>]

<h2>ASCII: ASsisted Classification with Ignorance Interchange. (arXiv:2010.10747v1 [cs.LG])</h2>
<h3>Jiaying Zhou, Xun Xian, Na Li, Jie Ding</h3>
<p>The rapid development in data collecting devices and computation platforms
produces an emerging number of agents, each equipped with a unique data
modality over a particular population of subjects. While the predictive
performance of an agent may be enhanced by transmitting other data to it, this
is often unrealistic due to intractable transmission costs and security
concerns. While the predictive performance of an agent may be enhanced by
transmitting other data to it, this is often unrealistic due to intractable
transmission costs and security concerns. In this paper, we propose a method
named ASCII for an agent to improve its classification performance through
assistance from other agents. The main idea is to iteratively interchange an
ignorance value between 0 and 1 for each collated sample among agents, where
the value represents the urgency of further assistance needed. The method is
naturally suitable for privacy-aware, transmission-economical, and
decentralized learning scenarios. The method is also general as it allows the
agents to use arbitrary classifiers such as logistic regression, ensemble tree,
and neural network, and they may be heterogeneous among agents. We demonstrate
the proposed method with extensive experimental studies.
</p>
<a href="http://arxiv.org/abs/2010.10747" target="_blank">arXiv:2010.10747</a> [<a href="http://arxiv.org/pdf/2010.10747" target="_blank">pdf</a>]

<h2>Reinforcement learning using Deep Q Networks and Q learning accurately localizes brain tumors on MRI with very small training sets. (arXiv:2010.10763v1 [cs.CV])</h2>
<h3>Joseph N Stember, Hrithwik Shalu</h3>
<p>Purpose Supervised deep learning in radiology suffers from notorious inherent
limitations: 1) It requires large, hand-annotated data sets, 2) It is
non-generalizable, and 3) It lacks explainability and intuition. We have
recently proposed Reinforcement Learning to address all threes. However, we
applied it to images with radiologist eye tracking points, which limits the
state-action space. Here we generalize the Deep-Q Learning to a gridworld-based
environment, so that only the images and image masks are required.

Materials and Methods We trained a Deep Q network on 30 two-dimensional image
slices from the BraTS brain tumor database. Each image contained one lesion. We
then tested the trained Deep Q network on a separate set of 30 testing set
images. For comparison, we also trained and tested a keypoint detection
supervised deep learning network for the same set of training / testing images.

Results Whereas the supervised approach quickly overfit the training data,
and predicably performed poorly on the testing set (11\% accuracy), the Deep-Q
learning approach showed progressive improved generalizability to the testing
set over training time, reaching 70\% accuracy.

Conclusion We have shown a proof-of-principle application of reinforcement
learning to radiological images, here using 2D contrast-enhanced MRI brain
images with the goal of localizing brain tumors. This represents a
generalization of recent work to a gridworld setting, naturally suitable for
analyzing medical images.
</p>
<a href="http://arxiv.org/abs/2010.10763" target="_blank">arXiv:2010.10763</a> [<a href="http://arxiv.org/pdf/2010.10763" target="_blank">pdf</a>]

<h2>Towards Real-time Drowsiness Detection for Elderly Care. (arXiv:2010.10771v1 [cs.CV])</h2>
<h3>Boris Ba&#x10d;i&#x107;, Jason Zhang</h3>
<p>The primary focus of this paper is to produce a proof of concept for
extracting drowsiness information from videos to help elderly living on their
own. To quantify yawning, eyelid and head movement over time, we extracted 3000
images from captured videos for training and testing of deep learning models
integrated with OpenCV library. The achieved classification accuracy for eyelid
and mouth open/close status were between 94.3%-97.2%. Visual inspection of head
movement from videos with generated 3D coordinate overlays, indicated clear
spatiotemporal patterns in collected data (yaw, roll and pitch). Extraction
methodology of the drowsiness information as timeseries is applicable to other
contexts including support for prior work in privacy-preserving augmented
coaching, sport rehabilitation, and integration with big data platform in
healthcare.
</p>
<a href="http://arxiv.org/abs/2010.10771" target="_blank">arXiv:2010.10771</a> [<a href="http://arxiv.org/pdf/2010.10771" target="_blank">pdf</a>]

<h2>Semantics-Guided Representation Learning with Applications to Visual Synthesis. (arXiv:2010.10772v1 [cs.CV])</h2>
<h3>Jia-Wei Yan, Ci-Siang Lin, Fu-En Yang, Yu-Jhe Li, Yu-Chiang Frank Wang</h3>
<p>Learning interpretable and interpolatable latent representations has been an
emerging research direction, allowing researchers to understand and utilize the
derived latent space for further applications such as visual synthesis or
recognition. While most existing approaches derive an interpolatable latent
space and induces smooth transition in image appearance, it is still not clear
how to observe desirable representations which would contain semantic
information of interest. In this paper, we aim to learn meaningful
representations and simultaneously perform semantic-oriented and
visually-smooth interpolation. To this end, we propose an angular
triplet-neighbor loss (ATNL) that enables learning a latent representation
whose distribution matches the semantic information of interest. With the
latent space guided by ATNL, we further utilize spherical semantic
interpolation for generating semantic warping of images, allowing synthesis of
desirable visual data. Experiments on MNIST and CMU Multi-PIE datasets
qualitatively and quantitatively verify the effectiveness of our method.
</p>
<a href="http://arxiv.org/abs/2010.10772" target="_blank">arXiv:2010.10772</a> [<a href="http://arxiv.org/pdf/2010.10772" target="_blank">pdf</a>]

<h2>A Level-wise Taxonomic Perspective on Automated Machine Learning to Date and Beyond: Challenges and Opportunities. (arXiv:2010.10777v1 [cs.LG])</h2>
<h3>Shubhra (Santu) Karmaker, Md. Mahadi Hassan, Micah J. Smith, Lei Xu, ChengXiang Zhai, Kalyan Veeramachaneni</h3>
<p>Automated machine learning (AutoML) is essentially automating the process of
applying machine learning to real-world problems. The primary goals of AutoML
tools are to provide methods and processes to make Machine Learning available
for non-Machine Learning experts (domain experts), to improve efficiency of
Machine Learning and to accelerate research on Machine Learning. Although
automation and efficiency are some of AutoML's main selling points, the process
still requires a surprising level of human involvement. A number of vital steps
of the machine learning pipeline, including understanding the attributes of
domain-specific data, defining prediction problems, creating a suitable
training data set etc. still tend to be done manually by a data scientist on an
ad-hoc basis. Often, this process requires a lot of back-and-forth between the
data scientist and domain experts, making the whole process more difficult and
inefficient. Altogether, AutoML systems are still far from a "real automatic
system". In this review article, we present a level-wise taxonomic perspective
on AutoML systems to-date and beyond, i.e., we introduce a new classification
system with seven levels to distinguish AutoML systems based on their level of
autonomy. We first start with a discussion on how an end-to-end Machine
learning pipeline actually looks like and which sub-tasks of Machine learning
Pipeline has indeed been automated so far. Next, we highlight the sub-tasks
which are still done manually by a data-scientist in most cases and how that
limits a domain expert's access to Machine learning. Then, we introduce the
novel level-based taxonomy of AutoML systems and define each level according to
their scope of automation support. Finally, we provide a road-map of future
research endeavor in the area of AutoML and discuss some important challenges
in achieving this ambitious goal.
</p>
<a href="http://arxiv.org/abs/2010.10777" target="_blank">arXiv:2010.10777</a> [<a href="http://arxiv.org/pdf/2010.10777" target="_blank">pdf</a>]

<h2>Recurrent neural network-based volumetric fluorescence microscopy. (arXiv:2010.10781v1 [physics.optics])</h2>
<h3>Luzhe Huang, Yilin Luo, Yair Rivenson, Aydogan Ozcan</h3>
<p>Volumetric imaging of samples using fluorescence microscopy plays an
important role in various fields including physical, medical and life sciences.
Here we report a deep learning-based volumetric image inference framework that
uses 2D images that are sparsely captured by a standard wide-field fluorescence
microscope at arbitrary axial positions within the sample volume. Through a
recurrent convolutional neural network, which we term as Recurrent-MZ, 2D
fluorescence information from a few axial planes within the sample is
explicitly incorporated to digitally reconstruct the sample volume over an
extended depth-of-field. Using experiments on C. Elegans and nanobead samples,
Recurrent-MZ is demonstrated to increase the depth-of-field of a 63x/1.4NA
objective lens by approximately 50-fold, also providing a 30-fold reduction in
the number of axial scans required to image the same sample volume. We further
illustrated the generalization of this recurrent network for 3D imaging by
showing its resilience to varying imaging conditions, including e.g., different
sequences of input images, covering various axial permutations and unknown
axial positioning errors. Recurrent-MZ demonstrates the first application of
recurrent neural networks in microscopic image reconstruction and provides a
flexible and rapid volumetric imaging framework, overcoming the limitations of
current 3D scanning microscopy tools.
</p>
<a href="http://arxiv.org/abs/2010.10781" target="_blank">arXiv:2010.10781</a> [<a href="http://arxiv.org/pdf/2010.10781" target="_blank">pdf</a>]

<h2>Self-supervised Graph Learning for Recommendation. (arXiv:2010.10783v1 [cs.IR])</h2>
<h3>Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, Xing Xie</h3>
<p>Representation learning on user-item graph for recommendation has evolved
from using single ID or interaction history to exploiting higher-order
neighbors. This leads to the success of graph convolution networks (GCNs) for
recommendation such as PinSage and LightGCN. Despite effectiveness, we argue
that they suffer from two limitations: (1) high-degree nodes exert larger
impact on the representation learning, deteriorating the recommendations of
low-degree (long-tail) items; and (2) representations are vulnerable to noisy
interactions, as the neighborhood aggregation scheme further enlarges the
impact of observed edges. In this work, we explore self-supervised learning on
user-item graph, so as to improve the accuracy and robustness of GCNs for
recommendation. The idea is to supplement the classical supervised task of
recommendation with an auxiliary self-supervised task, which reinforces node
representation learning via self-discrimination. Specifically, we generate
multiple views of a node, maximizing the agreement between different views of
the same node compared to that of other nodes. We devise four operators to
generate the views -- embedding masking, embedding dropout, node dropout, and
edge dropout -- that augment node representation from two perspectives of ID
embedding and graph structure. We term this new learning paradigm as
\textit{Self-supervised Graph Learning} (SGL), implementing it on the
state-of-the-art model LightGCN. Empirical studies on three benchmark datasets
demonstrate the effectiveness of SGL, which improves the recommendation
accuracy, especially on long-tail items, and the robustness against interaction
noises.
</p>
<a href="http://arxiv.org/abs/2010.10783" target="_blank">arXiv:2010.10783</a> [<a href="http://arxiv.org/pdf/2010.10783" target="_blank">pdf</a>]

<h2>Deep Hash Embedding for Large-Vocab Categorical Feature Representations. (arXiv:2010.10784v1 [cs.LG])</h2>
<h3>Wang-Cheng Kang, Derek Zhiyuan Cheng, Tiansheng Yao, Xinyang Yi, Ting Chen, Lichan Hong, Ed H. Chi</h3>
<p>Embedding learning for large-vocabulary categorical features (e.g. user/item
IDs, and words) is crucial for deep learning, and especially neural models for
recommendation systems and natural language understanding tasks. Typically, the
model creates a huge embedding table that each row represents a dedicated
embedding vector for every feature value. In practice, to handle new (i.e.,
out-of-vocab) feature values and reduce the storage cost, the hashing trick is
often adopted, that randomly maps feature values to a smaller number of hashing
buckets. Essentially, thess embedding methods can be viewed as 1-layer wide
neural networks with one-hot encodings. In this paper, we propose an
alternative embedding framework Deep Hash Embedding (DHE), with non-one-hot
encodings and a deep neural network (embedding network) to compute embeddings
on the fly without having to store them. DHE first encodes the feature value to
a dense vector with multiple hashing functions and then applies a DNN to
generate the embedding. DHE is collision-free as the dense hashing encodings
are unique identifiers for both in-vocab and out-of-vocab feature values. The
encoding module is deterministic, non-learnable, and free of storage, while the
embedding network is updated during the training time to memorize embedding
information. Empirical results show that DHE outperforms state-of-the-art
hashing-based embedding learning algorithms, and achieves comparable AUC
against the standard one-hot encoding, with significantly smaller model sizes.
Our work sheds light on design of DNN-based alternative embedding schemes for
categorical features without using embedding table lookup.
</p>
<a href="http://arxiv.org/abs/2010.10784" target="_blank">arXiv:2010.10784</a> [<a href="http://arxiv.org/pdf/2010.10784" target="_blank">pdf</a>]

<h2>Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies. (arXiv:2010.10802v1 [cs.CV])</h2>
<h3>Itai Gat, Idan Schwartz, Alexander Schwing, Tamir Hazan</h3>
<p>Many recent datasets contain a variety of different data modalities, for
instance, image, question, and answer data in visual question answering (VQA).
When training deep net classifiers on those multi-modal datasets, the
modalities get exploited at different scales, i.e., some modalities can more
easily contribute to the classification results than others. This is suboptimal
because the classifier is inherently biased towards a subset of the modalities.
To alleviate this shortcoming, we propose a novel regularization term based on
the functional entropy. Intuitively, this term encourages to balance the
contribution of each modality to the classification result. However,
regularization with the functional entropy is challenging. To address this, we
develop a method based on the log-Sobolev inequality, which bounds the
functional entropy with the functional-Fisher-information. Intuitively, this
maximizes the amount of information that the modalities contribute. On the two
challenging multi-modal datasets VQA-CPv2 and SocialIQ, we obtain
state-of-the-art results while more uniformly exploiting the modalities. In
addition, we demonstrate the efficacy of our method on Colored MNIST.
</p>
<a href="http://arxiv.org/abs/2010.10802" target="_blank">arXiv:2010.10802</a> [<a href="http://arxiv.org/pdf/2010.10802" target="_blank">pdf</a>]

<h2>UFO$^2$: A Unified Framework towards Omni-supervised Object Detection. (arXiv:2010.10804v1 [cs.CV])</h2>
<h3>Zhongzheng Ren, Zhiding Yu, Xiaodong Yang, Ming-Yu Liu, Alexander G. Schwing, Jan Kautz</h3>
<p>Existing work on object detection often relies on a single form of
annotation: the model is trained using either accurate yet costly bounding
boxes or cheaper but less expressive image-level tags. However, real-world
annotations are often diverse in form, which challenges these existing works.
In this paper, we present UFO$^2$, a unified object detection framework that
can handle different forms of supervision simultaneously. Specifically, UFO$^2$
incorporates strong supervision (e.g., boxes), various forms of partial
supervision (e.g., class tags, points, and scribbles), and unlabeled data.
Through rigorous evaluations, we demonstrate that each form of label can be
utilized to either train a model from scratch or to further improve a
pre-trained model. We also use UFO$^2$ to investigate budget-aware
omni-supervised learning, i.e., various annotation policies are studied under a
fixed annotation budget: we show that competitive performance needs no strong
labels for all data. Finally, we demonstrate the generalization of UFO$^2$,
detecting more than 1,000 different objects without bounding box annotations.
</p>
<a href="http://arxiv.org/abs/2010.10804" target="_blank">arXiv:2010.10804</a> [<a href="http://arxiv.org/pdf/2010.10804" target="_blank">pdf</a>]

<h2>SeqTrans: Automatic Vulnerability Fix via Sequence to Sequence Learning. (arXiv:2010.10805v1 [cs.CR])</h2>
<h3>Jianlei Chi, Yu Qu, Ting Liu, Qinghua Zheng, Heng Yin</h3>
<p>Software vulnerabilities are now reported at an unprecedented speed due to
the recent development of automated vulnerability hunting tools. However,
fixing vulnerabilities still mainly depends on programmers' manual efforts.
Developers need to deeply understand the vulnerability and try to affect the
system's functions as little as possible. In this paper, with the advancement
of Neural Machine Translation (NMT) techniques, we provide a novel approach
called SeqTrans to exploit historical vulnerability fixes to provide
suggestions and automatically fix the source code. To capture the contextual
information around the vulnerable code, we propose to leverage data flow
dependencies to construct code sequences and fed them into the state-of-the-art
transformer model. Attention and copy mechanisms are both exploited in
SeqTrans. We evaluate SeqTrans on both single line and multiple line
vulnerability fixes on a dataset containing 1,282 commits that fix 624
vulnerabilities in 205 Java projects. Results show that the accuracy of
SeqTrans can achieve 77.6% in single line fix and 52.5% in multiple line fix.
In the meantime, we look deep inside the result and observe that NMT model
performs very well in certain kinds of vulnerabilities like CWE-287 (Improper
Authentication) and CWE-863 (Incorrect Authorization).
</p>
<a href="http://arxiv.org/abs/2010.10805" target="_blank">arXiv:2010.10805</a> [<a href="http://arxiv.org/pdf/2010.10805" target="_blank">pdf</a>]

<h2>Leveraging Touch Sensors to Improve Mobile Manipulation. (arXiv:2010.10810v1 [cs.RO])</h2>
<h3>Luca Lach, Robert Haschke, Francesco Ferro, Jordi Pag&#xe8;s</h3>
<p>Despite many advances in service robotics, successful and secure object
manipulation on mobile platforms is still a challenge. In order to come closer
to human grasping performance, it is natural to provide robots with the same
capability that humans have: the sense of touch. This abstract presents novel,
tactile-equipped end-effectors for the service robot TIAGo that are currently
being developed. Their primary goal is to improve reliability and success of
mobile manipulation, but they also enable further research in related fields
such as learning by human demonstration, object exploration and force control
algorithms.
</p>
<a href="http://arxiv.org/abs/2010.10810" target="_blank">arXiv:2010.10810</a> [<a href="http://arxiv.org/pdf/2010.10810" target="_blank">pdf</a>]

<h2>STN4DST: A Scalable Dialogue State Tracking based on Slot Tagging Navigation. (arXiv:2010.10811v1 [cs.CL])</h2>
<h3>Puhai Yang, Heyan Huang, Xianling Mao</h3>
<p>Scalability for handling unknown slot values is a important problem in
dialogue state tracking (DST). As far as we know, previous scalable DST
approaches generally rely on either the candidate generation from slot tagging
output or the span extraction in dialogue context. However, the candidate
generation based DST often suffers from error propagation due to its pipelined
two-stage process; meanwhile span extraction based DST has the risk of
generating invalid spans in the lack of semantic constraints between start and
end position pointers. To tackle the above drawbacks, in this paper, we propose
a novel scalable dialogue state tracking method based on slot tagging
navigation, which implements an end-to-end single-step pointer to locate and
extract slot value quickly and accurately by the joint learning of slot tagging
and slot value position prediction in the dialogue context, especially for
unknown slot values. Extensive experiments over several benchmark datasets show
that the proposed model performs better than state-of-the-art baselines
greatly.
</p>
<a href="http://arxiv.org/abs/2010.10811" target="_blank">arXiv:2010.10811</a> [<a href="http://arxiv.org/pdf/2010.10811" target="_blank">pdf</a>]

<h2>Improving Generalization in Reinforcement Learning with Mixture Regularization. (arXiv:2010.10814v1 [cs.LG])</h2>
<h3>Kaixin Wang, Bingyi Kang, Jie Shao, Jiashi Feng</h3>
<p>Deep reinforcement learning (RL) agents trained in a limited set of
environments tend to suffer overfitting and fail to generalize to unseen
testing environments. To improve their generalizability, data augmentation
approaches (e.g. cutout and random convolution) are previously explored to
increase the data diversity. However, we find these approaches only locally
perturb the observations regardless of the training environments, showing
limited effectiveness on enhancing the data diversity and the generalization
performance. In this work, we introduce a simple approach, named mixreg, which
trains agents on a mixture of observations from different training environments
and imposes linearity constraints on the observation interpolations and the
supervision (e.g. associated reward) interpolations. Mixreg increases the data
diversity more effectively and helps learn smoother policies. We verify its
effectiveness on improving generalization by conducting extensive experiments
on the large-scale Procgen benchmark. Results show mixreg outperforms the
well-established baselines on unseen testing environments by a large margin.
Mixreg is simple, effective and general. It can be applied to both policy-based
and value-based RL algorithms. Code is available at
https://github.com/kaixin96/mixreg .
</p>
<a href="http://arxiv.org/abs/2010.10814" target="_blank">arXiv:2010.10814</a> [<a href="http://arxiv.org/pdf/2010.10814" target="_blank">pdf</a>]

<h2>KnowDis: Knowledge Enhanced Data Augmentation for Event Causality Detection via Distant Supervision. (arXiv:2010.10833v1 [cs.CL])</h2>
<h3>Xinyu Zuo, Yubo Chen, Kang Liu, Jun Zhao</h3>
<p>Modern models of event causality detection (ECD) are mainly based on
supervised learning from small hand-labeled corpora. However, hand-labeled
training data is expensive to produce, low coverage of causal expressions and
limited in size, which makes supervised methods hard to detect causal relations
between events. To solve this data lacking problem, we investigate a data
augmentation framework for ECD, dubbed as Knowledge Enhanced Distant Data
Augmentation (KnowDis). Experimental results on two benchmark datasets
EventStoryLine corpus and Causal-TimeBank show that 1) KnowDis can augment
available training data assisted with the lexical and causal commonsense
knowledge for ECD via distant supervision, and 2) our method outperforms
previous methods by a large margin assisted with automatically labeled training
data.
</p>
<a href="http://arxiv.org/abs/2010.10833" target="_blank">arXiv:2010.10833</a> [<a href="http://arxiv.org/pdf/2010.10833" target="_blank">pdf</a>]

<h2>TMT: A Transformer-based Modal Translator for Improving Multimodal Sequence Representations in Audio Visual Scene-aware Dialog. (arXiv:2010.10839v1 [cs.CL])</h2>
<h3>Wubo Li, Dongwei Jiang, Wei Zou, Xiangang Li</h3>
<p>Audio Visual Scene-aware Dialog (AVSD) is a task to generate responses when
discussing about a given video. The previous state-of-the-art model shows
superior performance for this task using Transformer-based architecture.
However, there remain some limitations in learning better representation of
modalities. Inspired by Neural Machine Translation (NMT), we propose the
Transformer-based Modal Translator (TMT) to learn the representations of the
source modal sequence by translating the source modal sequence to the related
target modal sequence in a supervised manner. Based on Multimodal Transformer
Networks (MTN), we apply TMT to video and dialog, proposing MTN-TMT for the
video-grounded dialog system. On the AVSD track of the Dialog System Technology
Challenge 7, MTN-TMT outperforms the MTN and other submission models in both
Video and Text task and Text Only task. Compared with MTN, MTN-TMT improves all
metrics, especially, achieving relative improvement up to 14.1% on CIDEr. Index
Terms: multimodal learning, audio-visual scene-aware dialog, neural machine
translation, multi-task learning
</p>
<a href="http://arxiv.org/abs/2010.10839" target="_blank">arXiv:2010.10839</a> [<a href="http://arxiv.org/pdf/2010.10839" target="_blank">pdf</a>]

<h2>Soft Jig-Driven Assembly Operations. (arXiv:2010.10843v1 [cs.RO])</h2>
<h3>Takuya Kiyokawa, Tatsuya Sakuma, Jun Takamatsu, Tsukasa Ogasawara</h3>
<p>To design a general-purpose assembly robot system that can handle objects of
various shapes, we propose a soft jig capable of deforming according to the
shape of assembly parts. The soft jig is based on a jamming gripper used for
robot manipulation as a general-purpose robotic gripper developed in the field
of soft robotics. The soft jig has a flexible membrane made of silicone, which
has a high friction, elongation, and contraction rate for keeping parts
strictly fixed. The inside of the membrane is filled with glass beads to
achieve a jamming transition. The usability of the soft jig was evaluated from
the viewpoint of the versatility and fixing performance for various shapes and
postures of parts in assembly operations.
</p>
<a href="http://arxiv.org/abs/2010.10843" target="_blank">arXiv:2010.10843</a> [<a href="http://arxiv.org/pdf/2010.10843" target="_blank">pdf</a>]

<h2>Gender Prediction Based on Vietnamese Names with Machine Learning Techniques. (arXiv:2010.10852v1 [cs.CL])</h2>
<h3>Huy Quoc To, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen, Anh Gia-Tuan Nguyen</h3>
<p>As biological gender is one of the aspects of presenting individual human,
much work has been done on gender classification based on people names. The
proposal for English and Chinese languages are tremendous; still, there has
been few works done for Vietnamese so far. We propose a new dataset for gender
prediction based on Vietnamese names. This dataset comprises over 26,000 full
names annotated with genders. This dataset is available on our website for
research purposes. In addition, this paper describes six machine learning
algorithms (Support Vector Machine, Multinomial Naive Bayes, Bernoulli Naive
Bayes, Decision Tree, Random Forrest and Logistic Regression) and a deep
learning model (LSTM) with fastText word embedding for gender prediction on
Vietnamese names. We create a dataset and investigate the impact of each name
component on detecting gender. As a result, the best F1-score that we have
achieved is up to 96\% on LSTM model and we generate a web API based on our
trained model.
</p>
<a href="http://arxiv.org/abs/2010.10852" target="_blank">arXiv:2010.10852</a> [<a href="http://arxiv.org/pdf/2010.10852" target="_blank">pdf</a>]

<h2>Ultimate Limits of Thermal Imaging. (arXiv:2010.10855v1 [quant-ph])</h2>
<h3>Cillian Harney, Leonardo Banchi, Stefano Pirandola</h3>
<p>Quantum Channel Discrimination (QCD) presents a fundamental task in quantum
information theory, with critical applications in quantum reading,
illumination, data-readout and more. The extension to multiple quantum channel
discrimination has seen a recent focus to characterise potential quantum
advantage associated with quantum enhanced discriminatory protocols. In this
paper, we study thermal imaging as an environment localisation task, in which
thermal images are modelled as ensembles of Gaussian phase insensitive channels
with identical transmissivity, and pixels possess properties according to
background (cold) or target (warm) thermal channels. Via the teleportation
stretching of adaptive quantum protocols, we derive ultimate limits on the
precision of pattern classification of abstract, binary thermal image spaces,
and show that quantum enhanced strategies may be used to provide significant
quantum advantage over known optimal classical strategies. The environmental
conditions and necessary resources for which advantage may be obtained are
studied and discussed. We then numerically investigate the use of quantum
enhanced statistical classifiers, in which quantum sensors are used in
conjunction with machine learning image classification methods. Proving
definitive advantage in the low loss regime, this work motivates the use of
quantum enhanced sources for short-range thermal imaging and detection
techniques for future quantum technologies.
</p>
<a href="http://arxiv.org/abs/2010.10855" target="_blank">arXiv:2010.10855</a> [<a href="http://arxiv.org/pdf/2010.10855" target="_blank">pdf</a>]

<h2>A Short Note on the Kinetics-700-2020 Human Action Dataset. (arXiv:2010.10864v1 [cs.CV])</h2>
<h3>Lucas Smaira (DeepMind), Jo&#xe3;o Carreira (DeepMind), Eric Noland (DeepMind), Ellen Clancy (DeepMind), Amy Wu (DeepMind), Andrew Zisserman (DeepMind)</h3>
<p>We describe the 2020 edition of the DeepMind Kinetics human action dataset,
which replenishes and extends the Kinetics-700 dataset. In this new version,
there are at least 700 video clips from different YouTube videos for each of
the 700 classes. This paper details the changes introduced for this new release
of the dataset and includes a comprehensive set of statistics as well as
baseline results using the I3D network.
</p>
<a href="http://arxiv.org/abs/2010.10864" target="_blank">arXiv:2010.10864</a> [<a href="http://arxiv.org/pdf/2010.10864" target="_blank">pdf</a>]

<h2>PARENTing via Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation. (arXiv:2010.10866v1 [cs.CL])</h2>
<h3>Cl&#xe9;ment Rebuffel, Laure Soulier, Geoffrey Scoutheeten, Patrick Gallinari</h3>
<p>In language generation models conditioned by structured data, the classical
training via maximum likelihood almost always leads models to pick up on
dataset divergence (i.e., hallucinations or omissions), and to incorporate them
erroneously in their own generations at inference. In this work, we build ontop
of previous Reinforcement Learning based approaches and show that a
model-agnostic framework relying on the recently introduced PARENT metric is
efficient at reducing both hallucinations and omissions. Evaluations on the
widely used WikiBIO and WebNLG benchmarks demonstrate the effectiveness of this
framework compared to state-of-the-art models.
</p>
<a href="http://arxiv.org/abs/2010.10866" target="_blank">arXiv:2010.10866</a> [<a href="http://arxiv.org/pdf/2010.10866" target="_blank">pdf</a>]

<h2>LCD -- Line Clustering and Description for Place Recognition. (arXiv:2010.10867v1 [cs.CV])</h2>
<h3>Felix Taubner, Florian Tschopp, Tonci Novkovic, Roland Siegwart, Fadri Furrer</h3>
<p>Current research on visual place recognition mostly focuses on aggregating
local visual features of an image into a single vector representation.
Therefore, high-level information such as the geometric arrangement of the
features is typically lost. In this paper, we introduce a novel learning-based
approach to place recognition, using RGB-D cameras and line clusters as visual
and geometric features. We state the place recognition problem as a problem of
recognizing clusters of lines instead of individual patches, thus maintaining
structural information. In our work, line clusters are defined as lines that
make up individual objects, hence our place recognition approach can be
understood as object recognition. 3D line segments are detected in RGB-D images
using state-of-the-art techniques. We present a neural network architecture
based on the attention mechanism for frame-wise line clustering. A similar
neural network is used for the description of these clusters with a compact
embedding of 128 floating point numbers, trained with triplet loss on training
data obtained from the InteriorNet dataset. We show experiments on a large
number of indoor scenes and compare our method with the bag-of-words
image-retrieval approach using SIFT and SuperPoint features and the global
descriptor NetVLAD. Trained only on synthetic data, our approach generalizes
well to real-world data captured with Kinect sensors, while also providing
information about the geometric arrangement of instances.
</p>
<a href="http://arxiv.org/abs/2010.10867" target="_blank">arXiv:2010.10867</a> [<a href="http://arxiv.org/pdf/2010.10867" target="_blank">pdf</a>]

<h2>Explaining black-box text classifiers for disease-treatment information extraction. (arXiv:2010.10873v1 [cs.AI])</h2>
<h3>Milad Moradi, Matthias Samwald</h3>
<p>Deep neural networks and other intricate Artificial Intelligence (AI) models
have reached high levels of accuracy on many biomedical natural language
processing tasks. However, their applicability in real-world use cases may be
limited due to their vague inner working and decision logic. A post-hoc
explanation method can approximate the behavior of a black-box AI model by
extracting relationships between feature values and outcomes. In this paper, we
introduce a post-hoc explanation method that utilizes confident itemsets to
approximate the behavior of black-box classifiers for medical information
extraction. Incorporating medical concepts and semantics into the explanation
process, our explanator finds semantic relations between inputs and outputs in
different parts of the decision space of a black-box classifier. The
experimental results show that our explanation method can outperform
perturbation and decision set based explanators in terms of fidelity and
interpretability of explanations produced for predictions on a
disease-treatment information extraction task.
</p>
<a href="http://arxiv.org/abs/2010.10873" target="_blank">arXiv:2010.10873</a> [<a href="http://arxiv.org/pdf/2010.10873" target="_blank">pdf</a>]

<h2>TurnGPT: a Transformer-based Language Model for Predicting Turn-taking in Spoken Dialog. (arXiv:2010.10874v1 [cs.CL])</h2>
<h3>Erik Ekstedt, Gabriel Skantze</h3>
<p>Syntactic and pragmatic completeness is known to be important for turn-taking
prediction, but so far machine learning models of turn-taking have used such
linguistic information in a limited way. In this paper, we introduce TurnGPT, a
transformer-based language model for predicting turn-shifts in spoken dialog.
The model has been trained and evaluated on a variety of written and spoken
dialog datasets. We show that the model outperforms two baselines used in prior
work. We also report on an ablation study, as well as attention and gradient
analyses, which show that the model is able to utilize the dialog context and
pragmatic completeness for turn-taking prediction. Finally, we explore the
model's potential in not only detecting, but also projecting, turn-completions.
</p>
<a href="http://arxiv.org/abs/2010.10874" target="_blank">arXiv:2010.10874</a> [<a href="http://arxiv.org/pdf/2010.10874" target="_blank">pdf</a>]

<h2>Probabilistic Numeric Convolutional Neural Networks. (arXiv:2010.10876v1 [cs.LG])</h2>
<h3>Marc Finzi, Roberto Bondesan, Max Welling</h3>
<p>Continuous input signals like images and time series that are irregularly
sampled or have missing values are challenging for existing deep learning
methods. Coherently defined feature representations must depend on the values
in unobserved regions of the input. Drawing from the work in probabilistic
numerics, we propose Probabilistic Numeric Convolutional Neural Networks which
represent features as Gaussian processes (GPs), providing a probabilistic
description of discretization error. We then define a convolutional layer as
the evolution of a PDE defined on this GP, followed by a nonlinearity. This
approach also naturally admits steerable equivariant convolutions under e.g.
the rotation group. In experiments we show that our approach yields a $3\times$
reduction of error from the previous state of the art on the SuperPixel-MNIST
dataset and competitive performance on the medical time series dataset
PhysioNet2012.
</p>
<a href="http://arxiv.org/abs/2010.10876" target="_blank">arXiv:2010.10876</a> [<a href="http://arxiv.org/pdf/2010.10876" target="_blank">pdf</a>]

<h2>Multi-Dimensional Randomized Response. (arXiv:2010.10881v1 [cs.CR])</h2>
<h3>Josep Domingo-Ferrer, Jordi Soria-Comas</h3>
<p>In our data world, a host of not necessarily trusted controllers gather data
on individual subjects. To preserve her privacy and, more generally, her
informational self-determination, the individual has to be empowered by giving
her agency on her own data. Maximum agency is afforded by local anonymization,
that allows each individual to anonymize her own data before handing them to
the data controller. Randomized response (RR) is a local anonymization approach
able to yield multi-dimensional full sets of anonymized microdata that are
valid for exploratory analysis and machine learning. This is so because an
unbiased estimate of the distribution of the true data of individuals can be
obtained from their pooled randomized data. Furthermore, RR offers rigorous
privacy guarantees. The main weakness of RR is the curse of dimensionality when
applied to several attributes: as the number of attributes grows, the accuracy
of the estimated true data distribution quickly degrades. We propose several
complementary approaches to mitigate the dimensionality problem. First, we
present two basic protocols, separate RR on each attribute and joint RR for all
attributes, and discuss their limitations. Then we introduce an algorithm to
form clusters of attributes so that attributes in different clusters can be
viewed as independent and joint RR can be performed within each cluster. After
that, we introduce an adjustment algorithm for the randomized data set that
repairs some of the accuracy loss due to assuming independence between
attributes when using RR separately on each attribute or due to assuming
independence between clusters in cluster-wise RR. We also present empirical
work to illustrate the proposed methods.
</p>
<a href="http://arxiv.org/abs/2010.10881" target="_blank">arXiv:2010.10881</a> [<a href="http://arxiv.org/pdf/2010.10881" target="_blank">pdf</a>]

<h2>Learning Integrodifferential Models for Image Denoising. (arXiv:2010.10888v1 [eess.IV])</h2>
<h3>Tobias Alt, Joachim Weickert</h3>
<p>We introduce an integrodifferential extension of the edge-enhancing
anisotropic diffusion model for image denoising. By accumulating weighted
structural information on multiple scales, our model is the first to create
anisotropy through multiscale integration. It follows the philosophy of
combining the advantages of model-based and data-driven approaches within
compact, insightful, and mathematically well-founded models with improved
performance. We explore trained results of scale-adaptive weighting and
contrast parameters to obtain an explicit modelling by smooth functions. This
leads to a transparent model with only three parameters, without significantly
decreasing its denoising performance. Experiments demonstrate that it
outperforms its diffusion-based predecessors. We show that both multiscale
information and anisotropy are crucial for its success.
</p>
<a href="http://arxiv.org/abs/2010.10888" target="_blank">arXiv:2010.10888</a> [<a href="http://arxiv.org/pdf/2010.10888" target="_blank">pdf</a>]

<h2>Learning to Decouple Relations: Few-Shot Relation Classification with Entity-Guided Attention and Confusion-Aware Training. (arXiv:2010.10894v1 [cs.CL])</h2>
<h3>Yingyao Wang, Junwei Bao, Guangyi Liu, Youzheng Wu, Xiaodong He, Bowen Zhou, Tiejun Zhao</h3>
<p>This paper aims to enhance the few-shot relation classification especially
for sentences that jointly describe multiple relations. Due to the fact that
some relations usually keep high co-occurrence in the same context, previous
few-shot relation classifiers struggle to distinguish them with few annotated
instances. To alleviate the above relation confusion problem, we propose CTEG,
a model equipped with two mechanisms to learn to decouple these easily-confused
relations. On the one hand, an Entity-Guided Attention (EGA) mechanism, which
leverages the syntactic relations and relative positions between each word and
the specified entity pair, is introduced to guide the attention to filter out
information causing confusion. On the other hand, a Confusion-Aware Training
(CAT) method is proposed to explicitly learn to distinguish relations by
playing a pushing-away game between classifying a sentence into a true relation
and its confusing relation. Extensive experiments are conducted on the FewRel
dataset, and the results show that our proposed model achieves comparable and
even much better results to strong baselines in terms of accuracy. Furthermore,
the ablation test and case study verify the effectiveness of our proposed EGA
and CAT, especially in addressing the relation confusion problem.
</p>
<a href="http://arxiv.org/abs/2010.10894" target="_blank">arXiv:2010.10894</a> [<a href="http://arxiv.org/pdf/2010.10894" target="_blank">pdf</a>]

<h2>Deep learning based registration using spatial gradients and noisy segmentation labels. (arXiv:2010.10897v1 [cs.CV])</h2>
<h3>Th&#xe9;o Estienne (1 and 2), Maria Vakalopoulou (1), Enzo Battistella (1 and 2), Alexandre Carr&#xe9; (2), Th&#xe9;ophraste Henry (2), Marvin Lerousseau (1 and 2), Charlotte Robert (2), Nikos Paragios (3), Eric Deutsch (2) ((1) Universit&#xe9; Paris-Saclay, CentraleSup&#xe9;lec, Math&#xe9;matiques et Informatique pour la Complexit&#xe9; et les Syst&#xe8;mes, Inria Saclay, (2) Universit&#xe9; Paris-Saclay, Institut Gustave Roussy, Inserm, Radioth&#xe9;rapie Mol&#xe9;culaire et Innovation Th&#xe9;rapeutique, (3) Therapanacea)</h3>
<p>Image registration is one of the most challenging problems in medical image
analysis. In the recent years, deep learning based approaches became quite
popular, providing fast and performing registration strategies. In this short
paper, we summarise our work presented on Learn2Reg challenge 2020. The main
contributions of our work rely on (i) a symmetric formulation, predicting the
transformations from source to target and from target to source simultaneously,
enforcing the trained representations to be similar and (ii) integration of
variety of publicly available datasets used both for pretraining and for
augmenting segmentation labels. Our method reports a mean dice of $0.64$ for
task 3 and $0.85$ for task 4 on the test sets, taking third place on the
challenge. Our code and models are publicly available at
https://github.com/TheoEst/abdominal_registration and
\https://github.com/TheoEst/hippocampus_registration.
</p>
<a href="http://arxiv.org/abs/2010.10897" target="_blank">arXiv:2010.10897</a> [<a href="http://arxiv.org/pdf/2010.10897" target="_blank">pdf</a>]

<h2>On Information Asymmetry in Competitive Multi-Agent Reinforcement Learning: Convergence and Optimality. (arXiv:2010.10901v1 [cs.LG])</h2>
<h3>Ezra Tampubolon, Haris Ceribasic, Holger Boche</h3>
<p>In this work, we study the system of interacting non-cooperative two
Q-learning agents, where one agent has the privilege of observing the other's
actions. We show that this information asymmetry can lead to a stable outcome
of population learning, which does not occur in an environment of general
independent learners. Furthermore, we discuss the resulted post-learning
policies, show that they are almost optimal in the underlying game sense, and
provide numerical hints of almost welfare-optimal of the resulted policies.
</p>
<a href="http://arxiv.org/abs/2010.10901" target="_blank">arXiv:2010.10901</a> [<a href="http://arxiv.org/pdf/2010.10901" target="_blank">pdf</a>]

<h2>Visual Navigation in Real-World Indoor Environments Using End-to-End Deep Reinforcement Learning. (arXiv:2010.10903v1 [cs.RO])</h2>
<h3>Jon&#xe1;&#x161; Kulh&#xe1;nek, Erik Derner, Robert Babu&#x161;ka</h3>
<p>Visual navigation is essential for many applications in robotics, from
manipulation, through mobile robotics to automated driving. Deep reinforcement
learning (DRL) provides an elegant map-free approach integrating image
processing, localization, and planning in one module, which can be trained and
therefore optimized for a given environment. However, to date, DRL-based visual
navigation was validated exclusively in simulation, where the simulator
provides information that is not available in the real world, e.g., the robot's
position or image segmentation masks. This precludes the use of the learned
policy on a real robot. Therefore, we propose a novel approach that enables a
direct deployment of the trained policy on real robots. We have designed visual
auxiliary tasks, a tailored reward scheme, and a new powerful simulator to
facilitate domain randomization. The policy is fine-tuned on images collected
from real-world environments. We have evaluated the method on a mobile robot in
a real office environment. The training took ~30 hours on a single GPU. In 30
navigation experiments, the robot reached a 0.3-meter neighborhood of the goal
in more than 86.7% of cases. This result makes the proposed method directly
applicable to tasks like mobile manipulation.
</p>
<a href="http://arxiv.org/abs/2010.10903" target="_blank">arXiv:2010.10903</a> [<a href="http://arxiv.org/pdf/2010.10903" target="_blank">pdf</a>]

<h2>Contrastive Learning of General-Purpose Audio Representations. (arXiv:2010.10915v1 [cs.SD])</h2>
<h3>Aaqib Saeed, David Grangier, Neil Zeghidour</h3>
<p>We introduce COLA, a self-supervised pre-training approach for learning a
general-purpose representation of audio. Our approach is based on contrastive
learning: it learns a representation which assigns high similarity to audio
segments extracted from the same recording while assigning lower similarity to
segments from different recordings. We build on top of recent advances in
contrastive learning for computer vision and reinforcement learning to design a
lightweight, easy-to-implement self-supervised model of audio. We pre-train
embeddings on the large-scale Audioset database and transfer these
representations to 9 diverse classification tasks, including speech, music,
animal sounds, and acoustic scenes. We show that despite its simplicity, our
method significantly outperforms previous self-supervised systems. We
furthermore conduct ablation studies to identify key design choices and release
a library to pre-train and fine-tune COLA models.
</p>
<a href="http://arxiv.org/abs/2010.10915" target="_blank">arXiv:2010.10915</a> [<a href="http://arxiv.org/pdf/2010.10915" target="_blank">pdf</a>]

<h2>Multi-task Metric Learning for Text-independent Speaker Verification. (arXiv:2010.10919v1 [eess.AS])</h2>
<h3>Yafeng Chen, Wu Guo, Jingjing Shi, Jiajun Qi, Tan Liu</h3>
<p>In this work, we introduce metric learning (ML) to enhance the deep embedding
learning for text-independent speaker verification (SV). Specifically, the deep
speaker embedding network is trained with conventional cross entropy loss and
auxiliary pair-based ML loss function. For the auxiliary ML task, training
samples of a mini-batch are first arranged into pairs, then positive and
negative pairs are selected and weighted through their own and relative
similarities, and finally the auxiliary ML loss is calculated by the similarity
of the selected pairs. To evaluate the proposed method, we conduct experiments
on the Speaker in the Wild (SITW) dataset. The results demonstrate the
effectiveness of the proposed method.
</p>
<a href="http://arxiv.org/abs/2010.10919" target="_blank">arXiv:2010.10919</a> [<a href="http://arxiv.org/pdf/2010.10919" target="_blank">pdf</a>]

<h2>Efficient Similarity-Preserving Unsupervised Learning using Modular Sparse Distributed Codes and Novelty-Contingent Noise. (arXiv:2010.10926v1 [cs.LG])</h2>
<h3>Rod Rinkus</h3>
<p>There is increasing realization in neuroscience that information is
represented in the brain, e.g., neocortex, hippocampus, in the form sparse
distributed codes (SDCs), a kind of cell assembly. Two essential questions are:
a) how are such codes formed on the basis of single trials, and how is
similarity preserved during learning, i.e., how do more similar inputs get
mapped to more similar SDCs. I describe a novel Modular Sparse Distributed Code
(MSDC) that provides simple, neurally plausible answers to both questions. An
MSDC coding field (CF) consists of Q WTA competitive modules (CMs), each
comprised of K binary units (analogs of principal cells). The modular nature of
the CF makes possible a single-trial, unsupervised learning algorithm that
approximately preserves similarity and crucially, runs in fixed time, i.e., the
number of steps needed to store an item remains constant as the number of
stored items grows. Further, once items are stored as MSDCs in superposition
and such that their intersection structure reflects input similarity, both
fixed time best-match retrieval and fixed time belief update (updating the
probabilities of all stored items) also become possible. The algorithm's core
principle is simply to add noise into the process of choosing a code, i.e.,
choosing a winner in each CM, which is proportional to the novelty of the
input. This causes the expected intersection of the code for an input, X, with
the code of each previously stored input, Y, to be proportional to the
similarity of X and Y. Results demonstrating these capabilities for spatial
patterns are given in the appendix.
</p>
<a href="http://arxiv.org/abs/2010.10926" target="_blank">arXiv:2010.10926</a> [<a href="http://arxiv.org/pdf/2010.10926" target="_blank">pdf</a>]

<h2>Deep learning-based citation recommendation system for patents. (arXiv:2010.10932v1 [cs.IR])</h2>
<h3>Jaewoong Choi, Sion Jang, Jaeyoung Kim, Jiho Lee, Janghyeok Yoona, Sungchul Choi</h3>
<p>In this study, we address the challenges in developing a deep learning-based
automatic patent citation recommendation system. Although deep learning-based
recommendation systems have exhibited outstanding performance in various
domains (such as movies, products, and paper citations), their validity in
patent citations has not been investigated, owing to the lack of a freely
available high-quality dataset and relevant benchmark model. To solve these
problems, we present a novel dataset called PatentNet that includes textual
information and metadata for approximately 110,000 patents from the Google Big
Query service. Further, we propose strong benchmark models considering the
similarity of textual information and metadata (such as cooperative patent
classification code). Compared with existing recommendation methods, the
proposed benchmark method achieved a mean reciprocal rank of 0.2377 on the test
set, whereas the existing state-of-the-art recommendation method achieved
0.2073.
</p>
<a href="http://arxiv.org/abs/2010.10932" target="_blank">arXiv:2010.10932</a> [<a href="http://arxiv.org/pdf/2010.10932" target="_blank">pdf</a>]

<h2>An Eager Splitting Strategy for Online Decision Trees. (arXiv:2010.10935v1 [cs.LG])</h2>
<h3>Chaitanya Manapragada, Heitor M Gomes, Mahsa Salehi, Albert Bifet, Geoffrey I Webb</h3>
<p>We study the effectiveness of replacing the split strategy for the
state-of-the-art online tree learner, Hoeffding Tree, with a rigorous but more
eager splitting strategy. Our method, Hoeffding AnyTime Tree (HATT), uses the
Hoeffding Test to determine whether the current best candidate split is
superior to the current split, with the possibility of revision, while
Hoeffding Tree aims to determine whether the top candidate is better than the
second best and fixes it for all posterity. Our method converges to the ideal
batch tree while Hoeffding Tree does not. Decision tree ensembles are widely
used in practice, and in this work, we study the efficacy of HATT as a base
learner for online bagging and online boosting ensembles. On UCI and synthetic
streams, the success of Hoeffding AnyTime Tree in terms of prequential accuracy
over Hoeffding Tree is established. HATT as a base learner component
outperforms HT within a 0.05 significance level for the majority of tested
ensembles on what we believe is the largest and most comprehensive set of
testbenches in the online learning literature. Our results indicate that HATT
is a superior alternative to Hoeffding Tree in a large number of ensemble
settings.
</p>
<a href="http://arxiv.org/abs/2010.10935" target="_blank">arXiv:2010.10935</a> [<a href="http://arxiv.org/pdf/2010.10935" target="_blank">pdf</a>]

<h2>DiSCO: Differentiable Scan Context with Orientation. (arXiv:2010.10949v1 [cs.RO])</h2>
<h3>Xuecheng Xu, Huan Yin, Zexi Chen, Yue Wang, Rong Xiong</h3>
<p>Global localization is essential for robot navigation, of which the first
step is to retrieve a query from the map database. This problem is called place
recognition. In recent years, LiDAR scan based place recognition has drawn
attention as it is robust against the environmental change. In this paper, we
propose a LiDAR-based place recognition method, named Differentiable Scan
Context with Orientation (DiSCO), which simultaneously finds the scan at a
similar place and estimates their relative orientation. The orientation can
further be used as the initial value for the down-stream local optimal metric
pose estimation, improving the pose estimation especially when a large
orientation between the current scan and retrieved scan exists. Our key idea is
to transform the feature learning into the frequency domain. We utilize the
magnitude of the spectrum as the place signature, which is theoretically
rotation-invariant. In addition, based on the differentiable phase correlation,
we can efficiently estimate the global optimal relative orientation using the
spectrum. With such structural constraints, the network can be learned in an
end-to-end manner, and the backbone is fully shared by the two tasks, achieving
interpretability and light weight. Finally, DiSCO is validated on the NCLT and
Oxford datasets with long-term outdoor conditions, showing better performance
than the compared methods.
</p>
<a href="http://arxiv.org/abs/2010.10949" target="_blank">arXiv:2010.10949</a> [<a href="http://arxiv.org/pdf/2010.10949" target="_blank">pdf</a>]

<h2>Influence Maximization on Dynamic Social Networks with Conjugate Learning Automata. (arXiv:2010.10950v1 [cs.SI])</h2>
<h3>Fangqi Li, Chong Di, Shenghong Li</h3>
<p>Selecting the optimal subset from all vertices as seeds to maximize the
influence in a social network has been a task of interest. Various methods have
been proposed to select the optimal vertices in a static network, however, they
are challenged by the dynamics, i.e. the time-dependent variation of the social
network structure. Such dynamics hinder the paradigm for static networks and
leaves a seemingly unbridgeable gap between algorithms of influence
maximization on static networks and those on dynamic ones. In this paper, we
extend our previous work and demonstrate that conjugate learning automata (an
elementary variant of reinforcement learning) that have been successfully
applied to maximize influence on static networks can be applied to dynamic
networks as well. The network dynamics is measured by the variation of the
influence range and absorbed into the learning procedure. Our proposal
delicately formulates the effect of network dynamics: the more the influence
range varies, the more likely the seeds are to be learned from scratch. Under
this assumption, the continuity of the network variation is fully taken
advantage of. Experimental results on both synthetic and real-world networks
verify the privileges of our proposal against alternative methods.
</p>
<a href="http://arxiv.org/abs/2010.10950" target="_blank">arXiv:2010.10950</a> [<a href="http://arxiv.org/pdf/2010.10950" target="_blank">pdf</a>]

<h2>Learning to Guide Local Feature Matches. (arXiv:2010.10959v1 [cs.CV])</h2>
<h3>Fran&#xe7;ois Darmon, Mathieu Aubry, Pascal Monasse</h3>
<p>We tackle the problem of finding accurate and robust keypoint correspondences
between images. We propose a learning-based approach to guide local feature
matches via a learned approximate image matching. Our approach can boost the
results of SIFT to a level similar to state-of-the-art deep descriptors, such
as Superpoint, ContextDesc, or D2-Net and can improve performance for these
descriptors. We introduce and study different levels of supervision to learn
coarse correspondences. In particular, we show that weak supervision from
epipolar geometry leads to performances higher than the stronger but more
biased point level supervision and is a clear improvement over weak image level
supervision. We demonstrate the benefits of our approach in a variety of
conditions by evaluating our guided keypoint correspondences for localization
of internet images on the YFCC100M dataset and indoor images on theSUN3D
dataset, for robust localization on the Aachen day-night benchmark and for 3D
reconstruction in challenging conditions using the LTLL historical image data.
</p>
<a href="http://arxiv.org/abs/2010.10959" target="_blank">arXiv:2010.10959</a> [<a href="http://arxiv.org/pdf/2010.10959" target="_blank">pdf</a>]

<h2>Anomaly Detection in a Large-scale Cloud Platform. (arXiv:2010.10966v1 [cs.DC])</h2>
<h3>Mohammad Saiful Islam, William Pourmajidi, Lei Zhang, John Steinbacher, Tony Erwin, Andriy Miranskyy</h3>
<p>Cloud computing is ubiquitous: more and more companies are moving the
workloads into the Cloud. However, this rise in popularity challenges Cloud
service providers, as they need to monitor the quality of their ever-growing
offerings effectively. To address the challenge, we designed and implemented an
automated monitoring system for the IBM Cloud Platform. This monitoring system
utilizes deep learning neural networks to detect anomalies in near-real-time in
multiple Platform components simultaneously.

After running the system for a year, we observed that the proposed solution
frees the DevOps team's time and human resources from manually monitoring
thousands of Cloud components. Moreover, it increases customer satisfaction by
reducing the risk of Cloud outages.

In this paper, we share our solutions' architecture, implementation notes,
and best practices that emerged while evolving the monitoring system. They can
be leveraged by other researchers and practitioners to build anomaly detectors
for complex systems.
</p>
<a href="http://arxiv.org/abs/2010.10966" target="_blank">arXiv:2010.10966</a> [<a href="http://arxiv.org/pdf/2010.10966" target="_blank">pdf</a>]

<h2>Progressive Batching for Efficient Non-linear Least Squares. (arXiv:2010.10968v1 [cs.CV])</h2>
<h3>Huu Le, Christopher Zach, Edward Rosten, Oliver J. Woodford</h3>
<p>Non-linear least squares solvers are used across a broad range of offline and
real-time model fitting problems. Most improvements of the basic Gauss-Newton
algorithm tackle convergence guarantees or leverage the sparsity of the
underlying problem structure for computational speedup. With the success of
deep learning methods leveraging large datasets, stochastic optimization
methods received recently a lot of attention. Our work borrows ideas from both
stochastic machine learning and statistics, and we present an approach for
non-linear least-squares that guarantees convergence while at the same time
significantly reduces the required amount of computation. Empirical results
show that our proposed method achieves competitive convergence rates compared
to traditional second-order approaches on common computer vision problems, such
as image alignment and essential matrix estimation, with very large numbers of
residuals.
</p>
<a href="http://arxiv.org/abs/2010.10968" target="_blank">arXiv:2010.10968</a> [<a href="http://arxiv.org/pdf/2010.10968" target="_blank">pdf</a>]

<h2>Incorporating Interpretable Output Constraints in Bayesian Neural Networks. (arXiv:2010.10969v1 [cs.LG])</h2>
<h3>Wanqian Yang, Lars Lorch, Moritz A. Graule, Himabindu Lakkaraju, Finale Doshi-Velez</h3>
<p>Domains where supervised models are deployed often come with task-specific
constraints, such as prior expert knowledge on the ground-truth function, or
desiderata like safety and fairness. We introduce a novel probabilistic
framework for reasoning with such constraints and formulate a prior that
enables us to effectively incorporate them into Bayesian neural networks
(BNNs), including a variant that can be amortized over tasks. The resulting
Output-Constrained BNN (OC-BNN) is fully consistent with the Bayesian framework
for uncertainty quantification and is amenable to black-box inference. Unlike
typical BNN inference in uninterpretable parameter space, OC-BNNs widen the
range of functional knowledge that can be incorporated, especially for model
users without expertise in machine learning. We demonstrate the efficacy of
OC-BNNs on real-world datasets, spanning multiple domains such as healthcare,
criminal justice, and credit scoring.
</p>
<a href="http://arxiv.org/abs/2010.10969" target="_blank">arXiv:2010.10969</a> [<a href="http://arxiv.org/pdf/2010.10969" target="_blank">pdf</a>]

<h2>Regularised Least-Squares Regression with Infinite-Dimensional Output Space. (arXiv:2010.10973v1 [stat.ML])</h2>
<h3>Junhyunng Park, Krikamol Muandet</h3>
<p>We present some learning theory results on reproducing kernel Hilbert space
(RKHS) regression, where the output space is an infinite-dimensional Hilbert
space.
</p>
<a href="http://arxiv.org/abs/2010.10973" target="_blank">arXiv:2010.10973</a> [<a href="http://arxiv.org/pdf/2010.10973" target="_blank">pdf</a>]

<h2>Synthetic Expressions are Better Than Real for Learning to Detect Facial Actions. (arXiv:2010.10979v1 [cs.CV])</h2>
<h3>Koichiro Niinuma, Itir Onal Ertugrul, Jeffrey F Cohn, L&#xe1;szl&#xf3; A Jeni</h3>
<p>Critical obstacles in training classifiers to detect facial actions are the
limited sizes of annotated video databases and the relatively low frequencies
of occurrence of many actions. To address these problems, we propose an
approach that makes use of facial expression generation. Our approach
reconstructs the 3D shape of the face from each video frame, aligns the 3D mesh
to a canonical view, and then trains a GAN-based network to synthesize novel
images with facial action units of interest. To evaluate this approach, a deep
neural network was trained on two separate datasets: One network was trained on
video of synthesized facial expressions generated from FERA17; the other
network was trained on unaltered video from the same database. Both networks
used the same train and validation partitions and were tested on the test
partition of actual video from FERA17. The network trained on synthesized
facial expressions outperformed the one trained on actual facial expressions
and surpassed current state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2010.10979" target="_blank">arXiv:2010.10979</a> [<a href="http://arxiv.org/pdf/2010.10979" target="_blank">pdf</a>]

<h2>Amnesiac Machine Learning. (arXiv:2010.10981v1 [cs.LG])</h2>
<h3>Laura Graves, Vineel Nagisetty, Vijay Ganesh</h3>
<p>The Right to be Forgotten is part of the recently enacted General Data
Protection Regulation (GDPR) law that affects any data holder that has data on
European Union residents. It gives EU residents the ability to request deletion
of their personal data, including training records used to train machine
learning models. Unfortunately, Deep Neural Network models are vulnerable to
information leaking attacks such as model inversion attacks which extract class
information from a trained model and membership inference attacks which
determine the presence of an example in a model's training data. If a malicious
party can mount an attack and learn private information that was meant to be
removed, then it implies that the model owner has not properly protected their
user's rights and their models may not be compliant with the GDPR law. In this
paper, we present two efficient methods that address this question of how a
model owner or data holder may delete personal data from models in such a way
that they may not be vulnerable to model inversion and membership inference
attacks while maintaining model efficacy. We start by presenting a real-world
threat model that shows that simply removing training data is insufficient to
protect users. We follow that up with two data removal methods, namely
Unlearning and Amnesiac Unlearning, that enable model owners to protect
themselves against such attacks while being compliant with regulations. We
provide extensive empirical analysis that show that these methods are indeed
efficient, safe to apply, effectively remove learned information about
sensitive data from trained models while maintaining model efficacy.
</p>
<a href="http://arxiv.org/abs/2010.10981" target="_blank">arXiv:2010.10981</a> [<a href="http://arxiv.org/pdf/2010.10981" target="_blank">pdf</a>]

<h2>Highly-scalable stochastic neuron based on Ovonic Threshold Switch (OTS) and its applications in Restricted Boltzmann Machine (RBM). (arXiv:2010.10986v1 [physics.app-ph])</h2>
<h3>Seong-il Im, Hyejin Lee, Jaesang Lee, Jae-Seung Jeong, Joon Young Kwak, Keunsu Kim, Jeong Ho Cho, Hyunsu Ju, Suyoun Lee</h3>
<p>Interest in Restricted Boltzmann Machine (RBM) is growing as a generative
stochastic artificial neural network to implement a novel energy-efficient
machine-learning (ML) technique. For a hardware implementation of the RBM, an
essential building block is a reliable stochastic binary neuron device that
generates random spikes following the Boltzmann distribution. Here, we propose
a highly-scalable stochastic neuron device based on Ovonic Threshold Switch
(OTS) which utilizes the random emission and capture process of traps as the
source of stochasticity. The switching probability is well described by the
Boltzmann distribution, which can be controlled by operating parameters. As a
candidate for a true random number generator (TRNG), it passes 15 among the 16
tests of the National Institute of Standards and Technology (NIST) Statistical
Test Suite (Special Publication 800-22). In addition, the recognition task of
handwritten digits (MNIST) is demonstrated using a simulated RBM network
consisting of the proposed device with a maximum recognition accuracy of 86.07
%. Furthermore, reconstruction of images is successfully demonstrated using
images contaminated with noises, resulting in images with the noise removed.
These results show the promising properties of OTS-based stochastic neuron
devices for applications in RBM systems.
</p>
<a href="http://arxiv.org/abs/2010.10986" target="_blank">arXiv:2010.10986</a> [<a href="http://arxiv.org/pdf/2010.10986" target="_blank">pdf</a>]

<h2>A Distributional Robustness Certificate by Randomized Smoothing. (arXiv:2010.10987v1 [cs.LG])</h2>
<h3>Jungang Yang, Liyao Xiang, Ruidong Chen, Yukun Wang, Wei Wang, Xinbing Wang</h3>
<p>The robustness of deep neural networks against adversarial example attacks
has received much attention recently. We focus on certified robustness of
smoothed classifiers in this work, and propose to use the worst-case population
loss over noisy inputs as a robustness metric. Under this metric, we provide a
tractable upper bound serving as a robustness certificate by exploiting the
duality. To improve the robustness, we further propose a noisy adversarial
learning procedure to minimize the upper bound following the robust
optimization framework. The smoothness of the loss function ensures the problem
easy to optimize even for non-smooth neural networks. We show how our
robustness certificate compares with others and the improvement over previous
works. Experiments on a variety of datasets and models verify that in terms of
empirical accuracies, our approach exceeds the state-of-the-art
certified/heuristic methods in defending adversarial examples.
</p>
<a href="http://arxiv.org/abs/2010.10987" target="_blank">arXiv:2010.10987</a> [<a href="http://arxiv.org/pdf/2010.10987" target="_blank">pdf</a>]

<h2>A Neurochaos Learning Architecture for Genome Classification. (arXiv:2010.10995v1 [cs.NE])</h2>
<h3>Harikrishnan NB, Pranay SY, Nithin Nagaraj</h3>
<p>There has been empirical evidence of presence of non-linearity and chaos at
the level of single neurons in biological neural networks. The properties of
chaotic neurons inspires us to employ them in artificial learning systems.
Here, we propose a Neurochaos Learning (NL) architecture, where the neurons
used to extract features from data are 1D chaotic maps. ChaosFEX+SVM, an
instance of this NL architecture, is proposed as a hybrid combination of chaos
and classical machine learning algorithm. We formally prove that a single layer
of NL with a finite number of 1D chaotic neurons satisfies the Universal
Approximation Theorem with an exact value for the number of chaotic neurons
needed to approximate a discrete real valued function with finite support. This
is made possible due to the topological transitivity property of chaos and the
existence of uncountably infinite number of dense orbits for the chosen 1D
chaotic map. The chaotic neurons in NL get activated under the presence of an
input stimulus (data) and output a chaotic firing trajectory. From such chaotic
firing trajectories of individual neurons of NL, we extract Firing Time, Firing
Rate, Energy and Entropy that constitute ChaosFEX features. These ChaosFEX
features are then fed to a Support Vector Machine with linear kernel for
classification. The effectiveness of chaotic feature engineering performed by
NL (ChaosFEX+SVM) is demonstrated for synthetic and real world datasets in the
low and high training sample regimes. Specifically, we consider the problem of
classification of genome sequences of SARS-CoV-2 from other coronaviruses
(SARS-CoV-1, MERS-CoV and others). With just one training sample per class for
1000 random trials of training, we report an average macro F1-score &gt; 0.99 for
the classification of SARS-CoV-2 from SARS-CoV-1 genome sequences. Robustness
of ChaosFEX features to additive noise is also demonstrated.
</p>
<a href="http://arxiv.org/abs/2010.10995" target="_blank">arXiv:2010.10995</a> [<a href="http://arxiv.org/pdf/2010.10995" target="_blank">pdf</a>]

<h2>GFL: A Decentralized Federated Learning Framework Based On Blockchain. (arXiv:2010.10996v1 [cs.LG])</h2>
<h3>Yifan Hu, Wei Xia, Jun Xiao, Chao Wu</h3>
<p>With the increasing importance of data privacy protection, federated learning
is becoming more widely used, and there are more frameworks for federated
learning. However, the centralization of federated learning has always
restricted the development of federated learning and the federated learning
framework. Although there are some decentralized federated learning algorithms,
these algorithms have some shortcomings and there is no framework that can
quickly use these algorithms. In this paper,we proposed and implemented a
blockchain-based decentralized federated learning framework called GFL
\cite{GFL} and integrated two new blockchain-based decentralized federated
learning mechanisms to try to try to make the decentralized federated learning
algorithm better landed.
</p>
<a href="http://arxiv.org/abs/2010.10996" target="_blank">arXiv:2010.10996</a> [<a href="http://arxiv.org/pdf/2010.10996" target="_blank">pdf</a>]

<h2>Open-Domain Frame Semantic Parsing Using Transformers. (arXiv:2010.10998v1 [cs.CL])</h2>
<h3>Aditya Kalyanpur, Or Biran, Tom Breloff, Jennifer Chu-Carroll, Ariel Diertani, Owen Rambow, Mark Sammons</h3>
<p>Frame semantic parsing is a complex problem which includes multiple
underlying subtasks. Recent approaches have employed joint learning of subtasks
(such as predicate and argument detection), and multi-task learning of related
tasks (such as syntactic and semantic parsing). In this paper, we explore
multi-task learning of all subtasks with transformer-based models. We show that
a purely generative encoder-decoder architecture handily beats the previous
state of the art in FrameNet 1.7 parsing, and that a mixed decoding multi-task
approach achieves even better performance.
</p>
<a href="http://arxiv.org/abs/2010.10998" target="_blank">arXiv:2010.10998</a> [<a href="http://arxiv.org/pdf/2010.10998" target="_blank">pdf</a>]

<h2>Unsupervised Deep Learning based Multiple Choices Question Answering: Start Learning from Basic Knowledge. (arXiv:2010.11003v1 [cs.CL])</h2>
<h3>Chi-Liang Liu, Hung-yi Lee</h3>
<p>In this paper, we study the possibility of almost unsupervised Multiple
Choices Question Answering (MCQA). Starting from very basic knowledge, MCQA
model knows that some choices have higher probabilities of being correct than
the others. The information, though very noisy, guides the training of an MCQA
model. The proposed method is shown to outperform the baseline approaches on
RACE and even comparable with some supervised learning approaches on MC500.
</p>
<a href="http://arxiv.org/abs/2010.11003" target="_blank">arXiv:2010.11003</a> [<a href="http://arxiv.org/pdf/2010.11003" target="_blank">pdf</a>]

<h2>What is Wrong with Continual Learning in Medical Image Segmentation?. (arXiv:2010.11008v1 [cs.CV])</h2>
<h3>Camila Gonzalez, Georgios Sakas, Anirban Mukhopadhyay</h3>
<p>Continual learning protocols are attracting increasing attention from the
medical imaging community. In a continual setup, data from different sources
arrives sequentially and each batch is only available for a limited period.
Given the inherent privacy risks associated with medical data, this setup
reflects the reality of deployment for deep learning diagnostic radiology
systems. Many techniques exist to learn continuously for classification tasks,
and several have been adapted to semantic segmentation. Yet most have at least
one of the following flaws: a) they rely too heavily on domain identity
information during inference, or b) data as seen in early training stages does
not profit from training with later data. In this work, we propose an
evaluation framework that addresses both concerns, and introduce a fair
multi-model benchmark. We show that the benchmark outperforms two popular
continual learning methods for the task of T2-weighted MR prostate
segmentation.
</p>
<a href="http://arxiv.org/abs/2010.11008" target="_blank">arXiv:2010.11008</a> [<a href="http://arxiv.org/pdf/2010.11008" target="_blank">pdf</a>]

<h2>Complex data labeling with deep learning methods: Lessons from fisheries acoustics. (arXiv:2010.11010v1 [cs.LG])</h2>
<h3>J.M.A.Sarr, T. Brochier, P.Brehmer, Y.Perrot, A.Bah, A.Sarr&#xe9;, M.A.Jeyid, M.Sidibeh, S.El Ayoub</h3>
<p>Quantitative and qualitative analysis of acoustic backscattered signals from
the seabed bottom to the sea surface is used worldwide for fish stocks
assessment and marine ecosystem monitoring. Huge amounts of raw data are
collected yet require tedious expert labeling. This paper focuses on a case
study where the ground truth labels are non-obvious: echograms labeling, which
is time-consuming and critical for the quality of fisheries and ecological
analysis. We investigate how these tasks can benefit from supervised learning
algorithms and demonstrate that convolutional neural networks trained with
non-stationary datasets can be used to stress parts of a new dataset needing
human expert correction. Further development of this approach paves the way
toward a standardization of the labeling process in fisheries acoustics and is
a good case study for non-obvious data labeling processes.
</p>
<a href="http://arxiv.org/abs/2010.11010" target="_blank">arXiv:2010.11010</a> [<a href="http://arxiv.org/pdf/2010.11010" target="_blank">pdf</a>]

<h2>Deep Neural Networks Are Congestion Games: From Loss Landscape to Wardrop Equilibrium and Beyond. (arXiv:2010.11024v1 [cs.LG])</h2>
<h3>Nina Vesseron, Ievgen Redko, Charlotte Laclau</h3>
<p>The theoretical analysis of deep neural networks (DNN) is arguably among the
most challenging research directions in machine learning (ML) right now, as it
requires from scientists to lay novel statistical learning foundations to
explain their behaviour in practice. While some success has been achieved
recently in this endeavour, the question on whether DNNs can be analyzed using
the tools from other scientific fields outside the ML community has not
received the attention it may well have deserved. In this paper, we explore the
interplay between DNNs and game theory (GT), and show how one can benefit from
the classic readily available results from the latter when analyzing the
former. In particular, we consider the widely studied class of congestion
games, and illustrate their intrinsic relatedness to both linear and non-linear
DNNs and to the properties of their loss surface. Beyond retrieving the
state-of-the-art results from the literature, we argue that our work provides a
very promising novel tool for analyzing the DNNs and support this claim by
proposing concrete open problems that can advance significantly our
understanding of DNNs when solved.
</p>
<a href="http://arxiv.org/abs/2010.11024" target="_blank">arXiv:2010.11024</a> [<a href="http://arxiv.org/pdf/2010.11024" target="_blank">pdf</a>]

<h2>I-nteract 2.0: A Cyber-Physical System to Design 3D Models using Mixed Reality Technologies and Deep Learning for Additive Manufacturing. (arXiv:2010.11025v1 [cs.HC])</h2>
<h3>Ammar Malik, Hugo Lhachemi, Robert Shorten</h3>
<p>I-nteract is a cyber-physical system that enables real-time interaction with
both virtual and real artifacts to design 3D models for additive manufacturing
by leveraging on mixed reality technologies. This paper presents novel advances
in the development of the interaction platform I-nteract to generate 3D models
using both constructive solid geometry and artificial intelligence. The system
also enables the user to adjust the dimensions of the 3D models with respect to
their physical workspace. The effectiveness of the system is demonstrated by
generating 3D models of furniture (e.g., chairs and tables) and fitting them
into the physical space in a mixed reality environment.
</p>
<a href="http://arxiv.org/abs/2010.11025" target="_blank">arXiv:2010.11025</a> [<a href="http://arxiv.org/pdf/2010.11025" target="_blank">pdf</a>]

<h2>Learning Curves for Analysis of Deep Networks. (arXiv:2010.11029v1 [cs.LG])</h2>
<h3>Derek Hoiem, Tanmay Gupta, Zhizhong Li, Michal M. Shlapentokh-Rothman</h3>
<p>A learning curve models a classifier's test error as a function of the number
of training samples. Prior works show that learning curves can be used to
select model parameters and extrapolate performance. We investigate how to use
learning curves to analyze the impact of design choices, such as pre-training,
architecture, and data augmentation. We propose a method to robustly estimate
learning curves, abstract their parameters into error and data-reliance, and
evaluate the effectiveness of different parameterizations. We also provide
several interesting observations based on learning curves for a variety of
image classification models.
</p>
<a href="http://arxiv.org/abs/2010.11029" target="_blank">arXiv:2010.11029</a> [<a href="http://arxiv.org/pdf/2010.11029" target="_blank">pdf</a>]

<h2>On Explaining Decision Trees. (arXiv:2010.11034v1 [cs.LG])</h2>
<h3>Yacine Izza, Alexey Ignatiev, Joao Marques-Silva</h3>
<p>Decision trees (DTs) epitomize what have become to be known as interpretable
machine learning (ML) models. This is informally motivated by paths in DTs
being often much smaller than the total number of features. This paper shows
that in some settings DTs can hardly be deemed interpretable, with paths in a
DT being arbitrarily larger than a PI-explanation, i.e. a subset-minimal set of
feature values that entails the prediction. As a result, the paper proposes a
novel model for computing PI-explanations of DTs, which enables computing one
PI-explanation in polynomial time. Moreover, it is shown that enumeration of
PI-explanations can be reduced to the enumeration of minimal hitting sets.
Experimental results were obtained on a wide range of publicly available
datasets with well-known DT-learning tools, and confirm that in most cases DTs
have paths that are proper supersets of PI-explanations.
</p>
<a href="http://arxiv.org/abs/2010.11034" target="_blank">arXiv:2010.11034</a> [<a href="http://arxiv.org/pdf/2010.11034" target="_blank">pdf</a>]

<h2>Influence-Augmented Online Planning for Complex Environments. (arXiv:2010.11038v1 [cs.AI])</h2>
<h3>Jinke He, Miguel Suau, Frans A. Oliehoek</h3>
<p>How can we plan efficiently in real time to control an agent in a complex
environment that may involve many other agents? While existing sample-based
planners have enjoyed empirical success in large POMDPs, their performance
heavily relies on a fast simulator. However, real-world scenarios are complex
in nature and their simulators are often computationally demanding, which
severely limits the performance of online planners. In this work, we propose
influence-augmented online planning, a principled method to transform a
factored simulator of the entire environment into a local simulator that
samples only the state variables that are most relevant to the observation and
reward of the planning agent and captures the incoming influence from the rest
of the environment using machine learning methods. Our main experimental
results show that planning on this less accurate but much faster local
simulator with POMCP leads to higher real-time planning performance than
planning on the simulator that models the entire environment.
</p>
<a href="http://arxiv.org/abs/2010.11038" target="_blank">arXiv:2010.11038</a> [<a href="http://arxiv.org/pdf/2010.11038" target="_blank">pdf</a>]

<h2>Deciphering Undersegmented Ancient Scripts Using Phonetic Prior. (arXiv:2010.11054v1 [cs.CL])</h2>
<h3>Jiaming Luo, Frederik Hartmann, Enrico Santus, Yuan Cao, Regina Barzilay</h3>
<p>Most undeciphered lost languages exhibit two characteristics that pose
significant decipherment challenges: (1) the scripts are not fully segmented
into words; (2) the closest known language is not determined. We propose a
decipherment model that handles both of these challenges by building on rich
linguistic constraints reflecting consistent patterns in historical sound
change. We capture the natural phonological geometry by learning character
embeddings based on the International Phonetic Alphabet (IPA). The resulting
generative framework jointly models word segmentation and cognate alignment,
informed by phonological constraints. We evaluate the model on both deciphered
languages (Gothic, Ugaritic) and an undeciphered one (Iberian). The experiments
show that incorporating phonetic geometry leads to clear and consistent gains.
Additionally, we propose a measure for language closeness which correctly
identifies related languages for Gothic and Ugaritic. For Iberian, the method
does not show strong evidence supporting Basque as a related language,
concurring with the favored position by the current scholarship.
</p>
<a href="http://arxiv.org/abs/2010.11054" target="_blank">arXiv:2010.11054</a> [<a href="http://arxiv.org/pdf/2010.11054" target="_blank">pdf</a>]

<h2>On Offline Evaluation of Recommender Systems. (arXiv:2010.11060v1 [cs.IR])</h2>
<h3>Yitong Ji, Aixin Sun, Jie Zhang, Chenliang Li</h3>
<p>In academic research, recommender models are often evaluated offline on
benchmark datasets. The offline dataset is first split to train and test
instances. All training instances are then modeled in a user-item interaction
matrix, and supervised learning models are trained. Many such offline
evaluations ignore the global timeline in the data, which leads to "data
leakage": a model learns from future data to predict a current value, making
the evaluation unrealistic. In this paper, we evaluate the impact of "data
leakage" using two widely adopted baseline models, BPR and NeuMF, on MovieLens
dataset. We show that accessing to different amount of future data may improve
or deteriorate a model's recommendation accuracy. That is, ignoring the global
timeline in offline evaluation makes the performance among recommendation
models not comparable. Our experiments also show that more historical data in
training set does not necessarily lead to better recommendation accuracy. We
share our understanding of these observations and highlight the importance of
preserving the global timeline. We also call for a revisit of recommender
system offline evaluation.
</p>
<a href="http://arxiv.org/abs/2010.11060" target="_blank">arXiv:2010.11060</a> [<a href="http://arxiv.org/pdf/2010.11060" target="_blank">pdf</a>]

<h2>Deep Q-Network-based Adaptive Alert Threshold Selection Policy for Payment Fraud Systems in Retail Banking. (arXiv:2010.11062v1 [cs.LG])</h2>
<h3>Hongda Shen, Eren Kurshan</h3>
<p>Machine learning models have widely been used in fraud detection systems.
Most of the research and development efforts have been concentrated on
improving the performance of the fraud scoring models. Yet, the downstream
fraud alert systems still have limited to no model adoption and rely on manual
steps. Alert systems are pervasively used across all payment channels in retail
banking and play an important role in the overall fraud detection process.
Current fraud detection systems end up with large numbers of dropped alerts due
to their inability to account for the alert processing capacity. Ideally, alert
threshold selection enables the system to maximize the fraud detection while
balancing the upstream fraud scores and the available bandwidth of the alert
processing teams. However, in practice, fixed thresholds that are used for
their simplicity do not have this ability. In this paper, we propose an
enhanced threshold selection policy for fraud alert systems. The proposed
approach formulates the threshold selection as a sequential decision making
problem and uses Deep Q-Network based reinforcement learning. Experimental
results show that this adaptive approach outperforms the current static
solutions by reducing the fraud losses as well as improving the operational
efficiency of the alert system.
</p>
<a href="http://arxiv.org/abs/2010.11062" target="_blank">arXiv:2010.11062</a> [<a href="http://arxiv.org/pdf/2010.11062" target="_blank">pdf</a>]

<h2>Knowledge Distillation for Improved Accuracy in Spoken Question Answering. (arXiv:2010.11067v1 [cs.CL])</h2>
<h3>Chenyu You, Nuo Chen, Yuexian Zou</h3>
<p>Spoken question answering (SQA) is a challenging task that requires the
machine to fully understand the complex spoken documents. Automatic speech
recognition (ASR) plays a significant role in the development of QA systems.
However, the recent work shows that ASR systems generate highly noisy
transcripts, which critically limit the capability of machine comprehension on
the SQA task. To address the issue, we present a novel distillation framework.
Specifically, we devise a training strategy to perform knowledge distillation
(KD) from spoken documents and written counterparts. Our work makes a step
towards distilling knowledge from the language model as a supervision signal to
lead to better student accuracy by reducing the misalignment between automatic
and manual transcriptions. Experiments demonstrate that our approach
outperforms several state-of-the-art language models on the Spoken-SQuAD
dataset.
</p>
<a href="http://arxiv.org/abs/2010.11067" target="_blank">arXiv:2010.11067</a> [<a href="http://arxiv.org/pdf/2010.11067" target="_blank">pdf</a>]

<h2>Neural Networks for Entity Matching. (arXiv:2010.11075v1 [cs.DB])</h2>
<h3>Nils Barlaug, Jon Atle Gulla</h3>
<p>Entity matching is the problem of identifying which records refer to the same
real-world entity. It has been actively researched for decades, and a variety
of different approaches have been developed. Even today, it remains a
challenging problem, and there is still generous room for improvement. In
recent years we have seen new methods based upon deep learning techniques for
natural language processing emerge.

In this survey, we present how neural networks have been used for entity
matching. Specifically, we identify which steps of the entity matching process
existing work have targeted using neural networks, and provide an overview of
the different techniques used at each step. We also discuss contributions from
deep learning in entity matching compared to traditional methods, and propose a
taxonomy of deep neural networks for entity matching.
</p>
<a href="http://arxiv.org/abs/2010.11075" target="_blank">arXiv:2010.11075</a> [<a href="http://arxiv.org/pdf/2010.11075" target="_blank">pdf</a>]

<h2>Online Conversation Disentanglement with Pointer Networks. (arXiv:2010.11080v1 [cs.CL])</h2>
<h3>Tao Yu, Shafiq Joty</h3>
<p>Huge amounts of textual conversations occur online every day, where multiple
conversations take place concurrently. Interleaved conversations lead to
difficulties in not only following the ongoing discussions but also extracting
relevant information from simultaneous messages. Conversation disentanglement
aims to separate intermingled messages into detached conversations. However,
existing disentanglement methods rely mostly on handcrafted features that are
dataset specific, which hinders generalization and adaptability. In this work,
we propose an end-to-end online framework for conversation disentanglement that
avoids time-consuming domain-specific feature engineering. We design a novel
way to embed the whole utterance that comprises timestamp, speaker, and message
text, and proposes a custom attention mechanism that models disentanglement as
a pointing problem while effectively capturing inter-utterance interactions in
an end-to-end fashion. We also introduce a joint-learning objective to better
capture contextual information. Our experiments on the Ubuntu IRC dataset show
that our method achieves state-of-the-art performance in both link and
conversation prediction tasks.
</p>
<a href="http://arxiv.org/abs/2010.11080" target="_blank">arXiv:2010.11080</a> [<a href="http://arxiv.org/pdf/2010.11080" target="_blank">pdf</a>]

<h2>Anatomically-Informed Deep Learning on Contrast-Enhanced Cardiac MRI for Scar Segmentation and Clinical Feature Extraction. (arXiv:2010.11081v1 [eess.IV])</h2>
<h3>Haley G. Abramson, Dan M. Popescu, Rebecca Yu, Changxin Lai, Julie K. Shade, Katherine C. Wu, Mauro Maggioni, Natalia A. Trayanova</h3>
<p>Many cardiac diseases are associated with structural remodeling of the
myocardium. Cardiac magnetic resonance (CMR) imaging with contrast enhancement,
such as late gadolinium enhancement (LGE), has unparalleled capability to
visualize fibrotic tissue remodeling, allowing for direct characterization of
the pathophysiological abnormalities leading to arrhythmias and sudden cardiac
death (SCD). Automating segmentation of the ventricles with fibrosis
distribution could dramatically enhance the utility of LGE-CMR in heart disease
clinical research and in the management of patients with risk of arrhythmias
and SCD. Here we describe an anatomically-informed deep learning (DL) approach
to myocardium and scar segmentation and clinical feature extraction from
LGE-CMR images. The technology enables clinical use by ensuring anatomical
accuracy and complete automation. Algorithm performance is strong for both
myocardium segmentation ($98\%$ accuracy and $0.79$ Dice score in a hold-out
test set) and evaluation measures shown to correlate with heart disease, such
as scar amount ($6.3\%$ relative error). Our approach for clinical feature
extraction, which satisfies highly complex geometric constraints without
stunting the learning process, has the potential of a broad applicability in
computer vision beyond cardiology, and even outside of medicine.
</p>
<a href="http://arxiv.org/abs/2010.11081" target="_blank">arXiv:2010.11081</a> [<a href="http://arxiv.org/pdf/2010.11081" target="_blank">pdf</a>]

<h2>TweetBERT: A Pretrained Language Representation Model for Twitter Text Analysis. (arXiv:2010.11091v1 [cs.CL])</h2>
<h3>Mohiuddin Md Abdul Qudar, Vijay Mago</h3>
<p>Twitter is a well-known microblogging social site where users express their
views and opinions in real-time. As a result, tweets tend to contain valuable
information. With the advancements of deep learning in the domain of natural
language processing, extracting meaningful information from tweets has become a
growing interest among natural language researchers. Applying existing language
representation models to extract information from Twitter does not often
produce good results. Moreover, there is no existing language representation
models for text analysis specific to the social media domain. Hence, in this
article, we introduce two TweetBERT models, which are domain specific language
presentation models, pre-trained on millions of tweets. We show that the
TweetBERT models significantly outperform the traditional BERT models in
Twitter text mining tasks by more than 7% on each Twitter dataset. We also
provide an extensive analysis by evaluating seven BERT models on 31 different
datasets. Our results validate our hypothesis that continuously training
language models on twitter corpus help performance with Twitter.
</p>
<a href="http://arxiv.org/abs/2010.11091" target="_blank">arXiv:2010.11091</a> [<a href="http://arxiv.org/pdf/2010.11091" target="_blank">pdf</a>]

<h2>WaveTransformer: A Novel Architecture for Audio Captioning Based on Learning Temporal and Time-Frequency Information. (arXiv:2010.11098v1 [cs.SD])</h2>
<h3>An Tran, Konstantinos Drossos, Tuomas Virtanen</h3>
<p>Automated audio captioning (AAC) is a novel task, where a method takes as an
input an audio sample and outputs a textual description (i.e. a caption) of its
contents. Most AAC methods are adapted from from image captioning of machine
translation fields. In this work we present a novel AAC novel method,
explicitly focused on the exploitation of the temporal and time-frequency
patterns in audio. We employ three learnable processes for audio encoding, two
for extracting the local and temporal information, and one to merge the output
of the previous two processes. To generate the caption, we employ the widely
used Transformer decoder. We assess our method utilizing the freely available
splits of Clotho dataset. Our results increase previously reported highest
SPIDEr to 17.3, from 16.2.
</p>
<a href="http://arxiv.org/abs/2010.11098" target="_blank">arXiv:2010.11098</a> [<a href="http://arxiv.org/pdf/2010.11098" target="_blank">pdf</a>]

<h2>UAV LiDAR Point Cloud Segmentation of A Stack Interchange with Deep Neural Networks. (arXiv:2010.11106v1 [cs.CV])</h2>
<h3>Weikai Tan, Dedong Zhang, Lingfei Ma, Ying Li, Lanying Wang, Jonathan Li</h3>
<p>Stack interchanges are essential components of transportation systems. Mobile
laser scanning (MLS) systems have been widely used in road infrastructure
mapping, but accurate mapping of complicated multi-layer stack interchanges are
still challenging. This study examined the point clouds collected by a new
Unmanned Aerial Vehicle (UAV) Light Detection and Ranging (LiDAR) system to
perform the semantic segmentation task of a stack interchange. An end-to-end
supervised 3D deep learning framework was proposed to classify the point
clouds. The proposed method has proven to capture 3D features in complicated
interchange scenarios with stacked convolution and the result achieved over 93%
classification accuracy. In addition, the new low-cost semi-solid-state LiDAR
sensor Livox Mid-40 featuring a incommensurable rosette scanning pattern has
demonstrated its potential in high-definition urban mapping.
</p>
<a href="http://arxiv.org/abs/2010.11106" target="_blank">arXiv:2010.11106</a> [<a href="http://arxiv.org/pdf/2010.11106" target="_blank">pdf</a>]

<h2>Progressive Defense Against Adversarial Attacks for Deep Learning as a Service in Internet of Things. (arXiv:2010.11143v1 [cs.CR])</h2>
<h3>Ling Wang, Cheng Zhang, Zejian Luo, Chenguang Liu, Jie Liu, Xi Zheng, Athanasios Vasilakos</h3>
<p>Nowadays, Deep Learning as a service can be deployed in Internet of Things
(IoT) to provide smart services and sensor data processing. However, recent
research has revealed that some Deep Neural Networks (DNN) can be easily misled
by adding relatively small but adversarial perturbations to the input (e.g.,
pixel mutation in input images). One challenge in defending DNN against these
attacks is to efficiently identifying and filtering out the adversarial pixels.
The state-of-the-art defense strategies with good robustness often require
additional model training for specific attacks. To reduce the computational
cost without loss of generality, we present a defense strategy called a
progressive defense against adversarial attacks (PDAAA) for efficiently and
effectively filtering out the adversarial pixel mutations, which could mislead
the neural network towards erroneous outputs, without a-priori knowledge about
the attack type. We evaluated our progressive defense strategy against various
attack methods on two well-known datasets. The result shows it outperforms the
state-of-the-art while reducing the cost of model training by 50% on average.
</p>
<a href="http://arxiv.org/abs/2010.11143" target="_blank">arXiv:2010.11143</a> [<a href="http://arxiv.org/pdf/2010.11143" target="_blank">pdf</a>]

<h2>Logistic $Q$-Learning. (arXiv:2010.11151v1 [cs.LG])</h2>
<h3>Joan Bas-Serrano, Sebastian Curi, Andreas Krause, Gergely Neu</h3>
<p>We propose a new reinforcement learning algorithm derived from a regularized
linear-programming formulation of optimal control in MDPs. The method is
closely related to the classic Relative Entropy Policy Search (REPS) algorithm
of Peters et al. (2010), with the key difference that our method introduces a
Q-function that enables efficient exact model-free implementation. The main
feature of our algorithm (called QREPS) is a convex loss function for policy
evaluation that serves as a theoretically sound alternative to the widely used
squared Bellman error. We provide a practical saddle-point optimization method
for minimizing this loss function and provide an error-propagation analysis
that relates the quality of the individual updates to the performance of the
output policy. Finally, we demonstrate the effectiveness of our method on a
range of benchmark problems.
</p>
<a href="http://arxiv.org/abs/2010.11151" target="_blank">arXiv:2010.11151</a> [<a href="http://arxiv.org/pdf/2010.11151" target="_blank">pdf</a>]

<h2>3D Meta Point Signature: Learning to Learn 3D Point Signature for 3D Dense Shape Correspondence. (arXiv:2010.11159v1 [cs.CV])</h2>
<h3>Hao Huang, Lingjing Wang, Xiang Li, Yi Fang</h3>
<p>Point signature, a representation describing the structural neighborhood of a
point in 3D shapes, can be applied to establish correspondences between points
in 3D shapes. Conventional methods apply a weight-sharing network, e.g., any
kind of graph neural networks, across all neighborhoods to directly generate
point signatures and gain the generalization ability by extensive training over
a large amount of training samples from scratch. However, these methods lack
the flexibility in rapidly adapting to unseen neighborhood structures and thus
generalizes poorly on new point sets. In this paper, we propose a novel
meta-learning based 3D point signature model, named 3Dmetapointsignature (MEPS)
network, that is capable of learning robust point signatures in 3D shapes. By
regarding each point signature learning process as a task, our method obtains
an optimized model over the best performance on the distribution of all tasks,
generating reliable signatures for new tasks, i.e., signatures of unseen point
neighborhoods. Specifically, the MEPS consists of two modules: a base signature
learner and a meta signature learner. During training, the base-learner is
trained to perform specific signature learning tasks. In the meantime, the
meta-learner is trained to update the base-learner with optimal parameters.
During testing, the meta-learner that is learned with the distribution of all
tasks can adaptively change parameters of the base-learner, accommodating to
unseen local neighborhoods. We evaluate the MEPS model on two datasets, e.g.,
FAUST and TOSCA, for dense 3Dshape correspondence. Experimental results
demonstrate that our method not only gains significant improvements over the
baseline model and achieves state-of-the-art results, but also is capable of
handling unseen 3D shapes.
</p>
<a href="http://arxiv.org/abs/2010.11159" target="_blank">arXiv:2010.11159</a> [<a href="http://arxiv.org/pdf/2010.11159" target="_blank">pdf</a>]

<h2>Decentralized Deep Learning using Momentum-Accelerated Consensus. (arXiv:2010.11166v1 [cs.LG])</h2>
<h3>Aditya Balu, Zhanhong Jiang, Sin Yong Tan, Chinmay Hedge, Young M Lee, Soumik Sarkar</h3>
<p>We consider the problem of decentralized deep learning where multiple agents
collaborate to learn from a distributed dataset. While there exist several
decentralized deep learning approaches, the majority consider a central
parameter-server topology for aggregating the model parameters from the agents.
However, such a topology may be inapplicable in networked systems such as
ad-hoc mobile networks, field robotics, and power network systems where direct
communication with the central parameter server may be inefficient. In this
context, we propose and analyze a novel decentralized deep learning algorithm
where the agents interact over a fixed communication topology (without a
central server). Our algorithm is based on the heavy-ball acceleration method
used in gradient-based optimization. We propose a novel consensus protocol
where each agent shares with its neighbors its model parameters as well as
gradient-momentum values during the optimization process. We consider both
strongly convex and non-convex objective functions and theoretically analyze
our algorithm's performance. We present several empirical comparisons with
competing decentralized learning methods to demonstrate the efficacy of our
approach under different communication topologies.
</p>
<a href="http://arxiv.org/abs/2010.11166" target="_blank">arXiv:2010.11166</a> [<a href="http://arxiv.org/pdf/2010.11166" target="_blank">pdf</a>]

<h2>Joint Blind Room Acoustic Characterization From Speech And Music Signals Using Convolutional Recurrent Neural Networks. (arXiv:2010.11167v1 [cs.SD])</h2>
<h3>Paul Callens, Milos Cernak</h3>
<p>Acoustic environment characterization opens doors for sound reproduction
innovations, smart EQing, speech enhancement, hearing aids, and forensics.
Reverberation time, clarity, and direct-to-reverberant ratio are acoustic
parameters that have been defined to describe reverberant environments. They
are closely related to speech intelligibility and sound quality. As explained
in the ISO3382 standard, they can be derived from a room measurement called the
Room Impulse Response (RIR). However, measuring RIRs requires specific
equipment and intrusive sound to be played. The recent audio combined with
machine learning suggests that one could estimate those parameters blindly
using speech or music signals. We follow these advances and propose a robust
end-to-end method to achieve blind joint acoustic parameter estimation using
speech and/or music signals. Our results indicate that convolutional recurrent
neural networks perform best for this task, and including music in training
also helps improve inference from speech.
</p>
<a href="http://arxiv.org/abs/2010.11167" target="_blank">arXiv:2010.11167</a> [<a href="http://arxiv.org/pdf/2010.11167" target="_blank">pdf</a>]

<h2>Secure Software Leasing from Standard Assumptions. (arXiv:2010.11186v1 [quant-ph])</h2>
<h3>Fuyuki Kitagawa, Ryo Nishimaki, Takashi Yamakawa</h3>
<p>Secure software leasing (SSL) is a quantum cryptographic primitive that
enables users to execute software only during the software is leased. It
prevents users from executing leased software after they return the leased
software to its owner. SSL can make software distribution more flexible and
controllable. Although SSL is an attractive cryptographic primitive, the
existing SSL scheme is based on public key quantum money, which is not
instantiated with standard cryptographic assumptions so far. Moreover, the
existing SSL scheme only supports a subclass of evasive functions. In this
work, we present SSL schemes based on the learning with errors assumption
(LWE). Specifically, our contributions consist of the following.

- We construct an SSL scheme for pseudorandom functions from the LWE
assumption against quantum adversaries.

- We construct an SSL scheme for a subclass of evasive functions from the LWE
assumption against sub-exponential quantum adversaries.

- We construct SSL schemes for the functionalities above with classical
communication from the LWE assumption against (sub-exponential) quantum
adversaries. SSL with classical communication means that entities exchange only
classical information though they run quantum computation locally.

Our crucial tool is two-tier quantum lightning, which is introduced in this
work and a relaxed version of quantum lighting. In two-tier quantum lightning
schemes, we have a public verification algorithm called semi-verification and a
private verification algorithm called full-verification. An adversary cannot
generate possibly entangled two quantum states whose serial numbers are the
same such that one passes the semi-verification, and the other also passes the
full-verification. We show that we can construct a two-tier quantum lightning
scheme from the LWE assumption.
</p>
<a href="http://arxiv.org/abs/2010.11186" target="_blank">arXiv:2010.11186</a> [<a href="http://arxiv.org/pdf/2010.11186" target="_blank">pdf</a>]

<h2>Machine Learning: Basic Principles. (arXiv:1805.05052v13 [cs.LG] UPDATED)</h2>
<h3>Alexander Jung</h3>
<p>This tutorial introduces some main concepts of machine learning (ML). From an
engineering point of view, the field of ML revolves around developing software
that implements the scientific principle: (i) formulate a hypothesis (choose a
model) about some phenomenon, (ii) collect data to test the hypothesis
(validate the model) and (iii) refine the hypothesis (iterate). One important
class of algorithms based on this principle are gradient descent methods which
aim at iteratively refining a model which is parametrized by some ("weight")
vector. A plethora of ML methods is obtained by combining different choices for
the hypothesis space (model), the quality measure (loss) and the computational
implementation of the model refinement (optimization method). %Many of the
current systems, which are considered as (artificially) intelligent, are based
on %combinations of few basic machine learning methods. After formalizing the
main building blocks of an ML problem, some popular algorithmic design patterns
for ML methods are discussed. This tutorial grew out of the lecture notes
developed for the courses "Machine Learning: Basic Principles" and "Artificial
Intelligence", which I have co-taught since 2015 at Aalto University.
</p>
<a href="http://arxiv.org/abs/1805.05052" target="_blank">arXiv:1805.05052</a> [<a href="http://arxiv.org/pdf/1805.05052" target="_blank">pdf</a>]

<h2>Autonomous Exploration, Reconstruction, and Surveillance of 3D Environments Aided by Deep Learning. (arXiv:1809.06025v4 [cs.LG] UPDATED)</h2>
<h3>Louis Ly, Yen-Hsi Richard Tsai</h3>
<p>We propose a greedy and supervised learning approach for visibility-based
exploration, reconstruction and surveillance. Using a level set representation,
we train a convolutional neural network to determine vantage points that
maximize visibility. We show that this method drastically reduces the on-line
computational cost and determines a small set of vantage points that solve the
problem. This enables us to efficiently produce highly-resolved and
topologically accurate maps of complex 3D environments. Unlike traditional
next-best-view and frontier-based strategies, the proposed method accounts for
geometric priors while evaluating potential vantage points. While existing deep
learning approaches focus on obstacle avoidance and local navigation, our
method aims at finding near-optimal solutions to the more global exploration
problem. We present realistic simulations on 2D and 3D urban environments.
</p>
<a href="http://arxiv.org/abs/1809.06025" target="_blank">arXiv:1809.06025</a> [<a href="http://arxiv.org/pdf/1809.06025" target="_blank">pdf</a>]

<h2>Deep learning algorithms out-perform veterinary pathologists in detecting the mitotically most active tumor region. (arXiv:1902.05414v3 [cs.CV] UPDATED)</h2>
<h3>Marc Aubreville, Christof A. Bertram, Christian Marzahl, Corinne Gurtner, Martina Dettwiler, Anja Schmidt, Florian Bartenschlager, Sophie Merz, Marco Fragoso, Olivia Kershaw, Robert Klopfleisch, Andreas Maier</h3>
<p>Manual count of mitotic figures, which is determined in the tumor region with
the highest mitotic activity, is a key parameter of most tumor grading schemes.
It can be, however, strongly dependent on the area selection due to uneven
mitotic figure distribution in the tumor section.We aimed to assess the
question, how significantly the area selection could impact the mitotic count,
which has a known high inter-rater disagreement. On a data set of 32 whole
slide images of H&amp;E-stained canine cutaneous mast cell tumor, fully annotated
for mitotic figures, we asked eight veterinary pathologists (five
board-certified, three in training) to select a field of interest for the
mitotic count. To assess the potential difference on the mitotic count, we
compared the mitotic count of the selected regions to the overall distribution
on the slide.Additionally, we evaluated three deep learning-based methods for
the assessment of highest mitotic density: In one approach, the model would
directly try to predict the mitotic count for the presented image patches as a
regression task. The second method aims at deriving a segmentation mask for
mitotic figures, which is then used to obtain a mitotic density. Finally, we
evaluated a two-stage object-detection pipeline based on state-of-the-art
architectures to identify individual mitotic figures. We found that the
predictions by all models were, on average, better than those of the experts.
The two-stage object detector performed best and outperformed most of the human
pathologists on the majority of tumor cases. The correlation between the
predicted and the ground truth mitotic count was also best for this approach
(0.963 to 0.979). Further, we found considerable differences in position
selection between pathologists, which could partially explain the high variance
that has been reported for the manual mitotic count.
</p>
<a href="http://arxiv.org/abs/1902.05414" target="_blank">arXiv:1902.05414</a> [<a href="http://arxiv.org/pdf/1902.05414" target="_blank">pdf</a>]

<h2>Local non-Bayesian social learning with stubborn agents. (arXiv:1904.12767v3 [cs.SI] UPDATED)</h2>
<h3>Daniel Vial, Vijay Subramanian</h3>
<p>We study a social learning model in which agents iteratively update their
beliefs about the true state of the world using private signals and the beliefs
of other agents in a non-Bayesian manner. Some agents are stubborn, meaning
they attempt to convince others of an erroneous true state (modeling fake
news). We show that while agents learn the true state on short timescales, they
"forget" it and believe the erroneous state to be true on longer timescales.
Using these results, we devise strategies for seeding stubborn agents so as to
disrupt learning, which outperform intuitive heuristics and give novel insights
regarding vulnerabilities in social learning.
</p>
<a href="http://arxiv.org/abs/1904.12767" target="_blank">arXiv:1904.12767</a> [<a href="http://arxiv.org/pdf/1904.12767" target="_blank">pdf</a>]

<h2>Multilinear Compressive Learning. (arXiv:1905.07481v3 [cs.CV] UPDATED)</h2>
<h3>Dat Thanh Tran, Mehmet Yamac, Aysen Degerli, Moncef Gabbouj, Alexandros Iosifidis</h3>
<p>Compressive Learning is an emerging topic that combines signal acquisition
via compressive sensing and machine learning to perform inference tasks
directly on a small number of measurements. Many data modalities naturally have
a multi-dimensional or tensorial format, with each dimension or tensor mode
representing different features such as the spatial and temporal information in
video sequences or the spatial and spectral information in hyperspectral
images. However, in existing compressive learning frameworks, the compressive
sensing component utilizes either random or learned linear projection on the
vectorized signal to perform signal acquisition, thus discarding the
multi-dimensional structure of the signals. In this paper, we propose
Multilinear Compressive Learning, a framework that takes into account the
tensorial nature of multi-dimensional signals in the acquisition step and
builds the subsequent inference model on the structurally sensed measurements.
Our theoretical complexity analysis shows that the proposed framework is more
efficient compared to its vector-based counterpart in both memory and
computation requirement. With extensive experiments, we also empirically show
that our Multilinear Compressive Learning framework outperforms the
vector-based framework in object classification and face recognition tasks, and
scales favorably when the dimensionalities of the original signals increase,
making it highly efficient for high-dimensional multi-dimensional signals.
</p>
<a href="http://arxiv.org/abs/1905.07481" target="_blank">arXiv:1905.07481</a> [<a href="http://arxiv.org/pdf/1905.07481" target="_blank">pdf</a>]

<h2>Multi-Sample Dropout for Accelerated Training and Better Generalization. (arXiv:1905.09788v3 [cs.NE] UPDATED)</h2>
<h3>Hiroshi Inoue</h3>
<p>Dropout is a simple but efficient regularization technique for achieving
better generalization of deep neural networks (DNNs); hence it is widely used
in tasks based on DNNs. During training, dropout randomly discards a portion of
the neurons to avoid overfitting. This paper presents an enhanced dropout
technique, which we call multi-sample dropout, for both accelerating training
and improving generalization over the original dropout. The original dropout
creates a randomly selected subset (called a dropout sample) from the input in
each training iteration while the multi-sample dropout creates multiple dropout
samples. The loss is calculated for each sample, and then the sample losses are
averaged to obtain the final loss. This technique can be easily implemented by
duplicating a part of the network after the dropout layer while sharing the
weights among the duplicated fully connected layers. Experimental results using
image classification tasks including ImageNet, CIFAR-10, and CIFAR-100 showed
that multi-sample dropout accelerates training. Moreover, the networks trained
using multi-sample dropout achieved lower error rates compared to networks
trained with the original dropout. The additional computation cost due to the
duplicated operations is not significant for deep convolutional networks
because most of the computation time is consumed in the convolution layers
before the dropout layer, which are not duplicated.
</p>
<a href="http://arxiv.org/abs/1905.09788" target="_blank">arXiv:1905.09788</a> [<a href="http://arxiv.org/pdf/1905.09788" target="_blank">pdf</a>]

<h2>Safe Reinforcement Learning with Nonlinear Dynamics via Model Predictive Shielding. (arXiv:1905.10691v3 [cs.LG] UPDATED)</h2>
<h3>Osbert Bastani</h3>
<p>Reinforcement learning is a promising approach to synthesizing policies for
challenging robotics tasks. A key problem is how to ensure safety of the
learned policy---e.g., that a walking robot does not fall over or that an
autonomous car does not run into an obstacle. We focus on the setting where the
dynamics are known, and the goal is to ensure that a policy trained in
simulation satisfies a given safety constraint. We propose an approach, called
model predictive shielding (MPS), that switches on-the-fly between a learned
policy and a backup policy to ensure safety. We prove that our approach
guarantees safety, and empirically evaluate it on the cart-pole.
</p>
<a href="http://arxiv.org/abs/1905.10691" target="_blank">arXiv:1905.10691</a> [<a href="http://arxiv.org/pdf/1905.10691" target="_blank">pdf</a>]

<h2>Interpretable and Personalized Apprenticeship Scheduling: Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations. (arXiv:1906.06397v3 [cs.LG] UPDATED)</h2>
<h3>Rohan Paleja, Andrew Silva, Letian Chen, Matthew Gombolay</h3>
<p>Resource scheduling and coordination is an NP-hard optimization requiring an
efficient allocation of agents to a set of tasks with upper- and lower bound
temporal and resource constraints. Due to the large-scale and dynamic nature of
resource coordination in hospitals and factories, human domain experts manually
plan and adjust schedules on the fly. To perform this job, domain experts
leverage heterogeneous strategies and rules-of-thumb honed over years of
apprenticeship. What is critically needed is the ability to extract this domain
knowledge in a heterogeneous and interpretable apprenticeship learning
framework to scale beyond the power of a single human expert, a necessity in
safety-critical domains. We propose a personalized and interpretable
apprenticeship scheduling algorithm that infers an interpretable representation
of all human task demonstrators by extracting decision-making criteria via an
inferred, personalized embedding non-parametric in the number of demonstrator
types. We achieve near-perfect LfD accuracy in synthetic domains and 88.22\%
accuracy on a planning domain with real-world, outperforming baselines.
Finally, our user study showed our methodology produces more interpretable and
easier-to-use models than neural networks ($p &lt; 0.05$).
</p>
<a href="http://arxiv.org/abs/1906.06397" target="_blank">arXiv:1906.06397</a> [<a href="http://arxiv.org/pdf/1906.06397" target="_blank">pdf</a>]

<h2>Weighted Envy-Freeness in Indivisible Item Allocation. (arXiv:1909.10502v6 [cs.AI] UPDATED)</h2>
<h3>Mithun Chakraborty, Ayumi Igarashi, Warut Suksompong, Yair Zick</h3>
<p>We introduce and analyze new envy-based fairness concepts for agents with
weights that quantify their entitlements in the allocation of indivisible
items. We propose two variants of weighted envy-freeness up to one item (WEF1):
strong, where envy can be eliminated by removing an item from the envied
agent's bundle, and weak, where envy can be eliminated either by removing an
item (as in the strong version) or by replicating an item from the envied
agent's bundle in the envying agent's bundle. We show that for additive
valuations, an allocation that is both Pareto optimal and strongly WEF1 always
exists and can be computed in pseudo-polynomial time; moreover, an allocation
that maximizes the weighted Nash social welfare may not be strongly WEF1, but
always satisfies the weak version of the property. Moreover, we establish that
a generalization of the round-robin picking sequence algorithm produces in
polynomial time a strongly WEF1 allocation for an arbitrary number of agents;
for two agents, we can efficiently achieve both strong WEF1 and Pareto
optimality by adapting the adjusted winner procedure. Our work highlights
several aspects in which weighted fair division is richer and more challenging
than its unweighted counterpart.
</p>
<a href="http://arxiv.org/abs/1909.10502" target="_blank">arXiv:1909.10502</a> [<a href="http://arxiv.org/pdf/1909.10502" target="_blank">pdf</a>]

<h2>Learning Maximally Predictive Prototypes in Multiple Instance Learning. (arXiv:1910.00965v3 [cs.LG] UPDATED)</h2>
<h3>Mert Yuksekgonul, Ozgur Emre Sivrikaya, Mustafa Gokce Baydogan</h3>
<p>In this work, we propose a simple model that provides permutation invariant
maximally predictive prototype generator from a given dataset, which leads to
interpretability of the solution and concrete insights to the nature and the
solution of a problem. Our aim is to find out prototypes in the feature space
to map the collection of instances (i.e. bags) to a distance feature space and
simultaneously learn a linear classifier for multiple instance learning (MIL).
Our experiments on classical MIL benchmark datasets demonstrate that proposed
framework is an accurate and efficient classifier compared to the existing
approaches.
</p>
<a href="http://arxiv.org/abs/1910.00965" target="_blank">arXiv:1910.00965</a> [<a href="http://arxiv.org/pdf/1910.00965" target="_blank">pdf</a>]

<h2>Asynchronous Online Federated Learning for Edge Devices with Non-IID Data. (arXiv:1911.02134v3 [cs.DC] UPDATED)</h2>
<h3>Yujing Chen, Yue Ning, Martin Slawski, Huzefa Rangwala</h3>
<p>Federated learning (FL) is a machine learning paradigm where a shared central
model is learned across distributed edge devices while the training data
remains on these devices. Federated Averaging (FedAvg) is the leading
optimization method for training non-convex models in this setting with a
synchronized protocol. However, the assumptions made by FedAvg are not
realistic given the heterogeneity of devices. In particular, the volume and
distribution of collected data vary in the training process due to different
sampling rates of edge devices. The edge devices themselves also vary in their
available communication bandwidth and system configurations, such as memory,
processor speed, and power requirements. This leads to vastly different
training times as well as model/data transfer times. Furthermore, availability
issues at edge devices can lead to a lack of contribution from specific edge
devices to the federated model. In this paper, we present an Asynchronous
Online Federated Learning (ASO-Fed) framework, where the edge devices perform
online learning with continuous streaming local data and a central server
aggregates model parameters from clients. Our framework updates the central
model in an asynchronous manner to tackle the challenges associated with both
varying computational loads at heterogeneous edge devices and edge devices that
lag behind or dropout. We perform extensive experiments on a simulated
benchmark image dataset and three real-world non-IID streaming datasets. The
results demonstrate the effectiveness of \model~on converging fast and
maintaining good prediction performance.
</p>
<a href="http://arxiv.org/abs/1911.02134" target="_blank">arXiv:1911.02134</a> [<a href="http://arxiv.org/pdf/1911.02134" target="_blank">pdf</a>]

<h2>HalluciNet-ing Spatiotemporal Representations Using a 2D-CNN. (arXiv:1912.04430v3 [cs.CV] UPDATED)</h2>
<h3>Paritosh Parmar, Brendan Morris</h3>
<p>Spatiotemporal representations learned using 3D convolutional neural networks
(CNN) are currently used in state-of-the-art approaches for action related
tasks. However, 3D-CNN are notorious for being memory and compute resource
intensive as compared with more simple 2D-CNN architectures. We propose to
hallucinate spatiotemporal representations from a 3D-CNN teacher with a 2D-CNN
student. By requiring the 2D-CNN to predict the future and intuit upcoming
activity, it is encouraged to gain a deeper understanding of actions and how
they evolve. The hallucination task is treated as an auxiliary task, which can
be used with any other action related task in a multitask learning setting.
Thorough experimental evaluation shows that the hallucination task indeed helps
improve performance on action recognition, action quality assessment, and
dynamic scene recognition tasks. From a practical standpoint, being able to
hallucinate spatiotemporal representations without an actual 3D-CNN can enable
deployment in resource-constrained scenarios, such as with limited computing
power and/or lower bandwidth. Codebase is available here:
https://github.com/ParitoshParmar/HalluciNet.
</p>
<a href="http://arxiv.org/abs/1912.04430" target="_blank">arXiv:1912.04430</a> [<a href="http://arxiv.org/pdf/1912.04430" target="_blank">pdf</a>]

<h2>Continuous Meta-Learning without Tasks. (arXiv:1912.08866v2 [cs.LG] UPDATED)</h2>
<h3>James Harrison, Apoorva Sharma, Chelsea Finn, Marco Pavone</h3>
<p>Meta-learning is a promising strategy for learning to efficiently learn
within new tasks, using data gathered from a distribution of tasks. However,
the meta-learning literature thus far has focused on the task segmented
setting, where at train-time, offline data is assumed to be split according to
the underlying task, and at test-time, the algorithms are optimized to learn in
a single task. In this work, we enable the application of generic meta-learning
algorithms to settings where this task segmentation is unavailable, such as
continual online learning with a time-varying task. We present meta-learning
via online changepoint analysis (MOCA), an approach which augments a
meta-learning algorithm with a differentiable Bayesian changepoint detection
scheme. The framework allows both training and testing directly on time series
data without segmenting it into discrete tasks. We demonstrate the utility of
this approach on a nonlinear meta-regression benchmark as well as two
meta-image-classification benchmarks.
</p>
<a href="http://arxiv.org/abs/1912.08866" target="_blank">arXiv:1912.08866</a> [<a href="http://arxiv.org/pdf/1912.08866" target="_blank">pdf</a>]

<h2>A Survey on Machine Reading Comprehension Systems. (arXiv:2001.01582v2 [cs.CL] UPDATED)</h2>
<h3>Razieh Baradaran, Razieh Ghiasi, Hossein Amirkhani</h3>
<p>Machine reading comprehension is a challenging task and hot topic in natural
language processing. Its goal is to develop systems to answer the questions
regarding a given context. In this paper, we present a comprehensive survey on
different aspects of machine reading comprehension systems, including their
approaches, structures, input/outputs, and research novelties. We illustrate
the recent trends in this field based on 241 reviewed papers from 2016 to 2020.
Our investigations demonstrate that the focus of research has changed in recent
years from answer extraction to answer generation, from single to
multi-document reading comprehension, and from learning from scratch to using
pre-trained embeddings. We also discuss the popular datasets and the evaluation
metrics in this field. The paper ends with investigating the most cited papers
and their contributions.
</p>
<a href="http://arxiv.org/abs/2001.01582" target="_blank">arXiv:2001.01582</a> [<a href="http://arxiv.org/pdf/2001.01582" target="_blank">pdf</a>]

<h2>Universal Adversarial Attack on Attention and the Resulting Dataset DAmageNet. (arXiv:2001.06325v3 [cs.LG] UPDATED)</h2>
<h3>Sizhe Chen, Zhengbao He, Chengjin Sun, Jie Yang, Xiaolin Huang</h3>
<p>Adversarial attacks on deep neural networks (DNNs) have been found for
several years. However, the existing adversarial attacks have high success
rates only when the information of the victim DNN is well-known or could be
estimated by the structure similarity or massive queries. In this paper, we
propose to Attack on Attention (AoA), a semantic property commonly shared by
DNNs. AoA enjoys a significant increase in transferability when the traditional
cross entropy loss is replaced with the attention loss. Since AoA alters the
loss function only, it could be easily combined with other
transferability-enhancement techniques and then achieve SOTA performance. We
apply AoA to generate 50000 adversarial samples from ImageNet validation set to
defeat many neural networks, and thus name the dataset as DAmageNet. 13
well-trained DNNs are tested on DAmageNet, and all of them have an error rate
over 85%. Even with defenses or adversarial training, most models still
maintain an error rate over 70% on DAmageNet. DAmageNet is the first universal
adversarial dataset. It could be downloaded freely and serve as a benchmark for
robustness testing and adversarial training.
</p>
<a href="http://arxiv.org/abs/2001.06325" target="_blank">arXiv:2001.06325</a> [<a href="http://arxiv.org/pdf/2001.06325" target="_blank">pdf</a>]

<h2>Supporting DNN Safety Analysis and Retraining through Heatmap-based Unsupervised Learning. (arXiv:2002.00863v3 [cs.SE] UPDATED)</h2>
<h3>Hazem Fahmy, Fabrizio Pastore, Mojtaba Bagherzadeh, Lionel Briand</h3>
<p>Deep neural networks (DNNs) are increasingly important in safety-critical
systems, for example in their perception layer to analyze images.
Unfortunately, there is a lack of methods to ensure the functional safety of
DNN-based components. We observe three major challenges with existing practices
regarding DNNs in safety-critical systems: (1) scenarios that are
underrepresented in the test set may lead to serious safety violation risks,
but may, however, remain unnoticed; (2) characterizing such high-risk scenarios
is critical for safety analysis; (3) retraining DNNs to address these risks is
poorly supported when causes of violations are difficult to determine. To
address these problems in the context of DNNs analyzing images, we propose
HUDD, an approach that automatically supports the identification of root causes
for DNN errors. HUDD identifies root causes by applying a clustering algorithm
to heatmaps capturing the relevance of every DNN neuron on the DNN outcome.
Also, HUDD retrains DNNs with images that are automatically selected based on
their relatedness to the identified image clusters. We evaluated HUDD with DNNs
from the automotive domain. HUDD was able to identify all the distinct root
causes of DNN errors, thus supporting safety analysis. Also, our retraining
approach has shown to be more effective at improving DNN accuracy than existing
approaches.
</p>
<a href="http://arxiv.org/abs/2002.00863" target="_blank">arXiv:2002.00863</a> [<a href="http://arxiv.org/pdf/2002.00863" target="_blank">pdf</a>]

<h2>Forecasting Industrial Aging Processes with Machine Learning Methods. (arXiv:2002.01768v2 [cs.LG] UPDATED)</h2>
<h3>Mihail Bogojeski, Simeon Sauer, Franziska Horn, Klaus-Robert M&#xfc;ller</h3>
<p>Accurately predicting industrial aging processes makes it possible to
schedule maintenance events further in advance, ensuring a cost-efficient and
reliable operation of the plant. So far, these degradation processes were
usually described by mechanistic or simple empirical prediction models. In this
paper, we evaluate a wider range of data-driven models, comparing some
traditional stateless models (linear and kernel ridge regression, feed-forward
neural networks) to more complex recurrent neural networks (echo state networks
and LSTMs). We first examine how much historical data is needed to train each
of the models on a synthetic dataset with known dynamics. Next, the models are
tested on real-world data from a large scale chemical plant. Our results show
that recurrent models produce near perfect predictions when trained on larger
datasets, and maintain a good performance even when trained on smaller datasets
with domain shifts, while the simpler models only performed comparably on the
smaller datasets.
</p>
<a href="http://arxiv.org/abs/2002.01768" target="_blank">arXiv:2002.01768</a> [<a href="http://arxiv.org/pdf/2002.01768" target="_blank">pdf</a>]

<h2>Towards Crowdsourced Training of Large Neural Networks using Decentralized Mixture-of-Experts. (arXiv:2002.04013v3 [cs.DC] UPDATED)</h2>
<h3>Max Ryabinin, Anton Gusev</h3>
<p>Many recent breakthroughs in deep learning were achieved by training
increasingly larger models on massive datasets. However, training such models
can be prohibitively expensive. For instance, the cluster used to train GPT-3
costs over \$250 million. As a result, most researchers cannot afford to train
state of the art models and contribute to their development. Hypothetically, a
researcher could crowdsource the training of large neural networks with
thousands of regular PCs provided by volunteers. The raw computing power of a
hundred thousand \$2500 desktops dwarfs that of a \$250M server pod, but one
cannot utilize that power efficiently with conventional distributed training
methods. In this work, we propose Learning@home: a novel neural network
training paradigm designed to handle large amounts of poorly connected
participants. We analyze the performance, reliability, and architectural
constraints of this paradigm and compare it against existing distributed
training techniques.
</p>
<a href="http://arxiv.org/abs/2002.04013" target="_blank">arXiv:2002.04013</a> [<a href="http://arxiv.org/pdf/2002.04013" target="_blank">pdf</a>]

<h2>Deep Transform and Metric Learning Network: Wedding Deep Dictionary Learning and Neural Networks. (arXiv:2002.07898v2 [cs.LG] UPDATED)</h2>
<h3>Wen Tang, Emilie Chouzenoux, Jean-Christophe Pesquet, Hamid Krim</h3>
<p>On account of its many successes in inference tasks and denoising
applications, Dictionary Learning (DL) and its related sparse optimization
problems have garnered a lot of research interest. While most solutions have
focused on single layer dictionaries, the improved recently proposed Deep DL
(DDL) methods have also fallen short on a number of issues. We propose herein,
a novel DDL approach where each DL layer can be formulated as a combination of
one linear layer and a Recurrent Neural Network (RNN). The RNN is shown to
flexibly account for the layer-associated and learned metric. Our proposed work
unveils new insights into Neural Networks and DDL and provides a new, efficient
and competitive approach to jointly learn a deep transform and a metric for
inference applications. Extensive experiments are carried out to demonstrate
that the proposed method can not only outperform existing DDL but also
state-of-the-art generic CNNs.
</p>
<a href="http://arxiv.org/abs/2002.07898" target="_blank">arXiv:2002.07898</a> [<a href="http://arxiv.org/pdf/2002.07898" target="_blank">pdf</a>]

<h2>Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints. (arXiv:2002.08159v3 [stat.ML] UPDATED)</h2>
<h3>Robin Vogel, Aur&#xe9;lien Bellet, Stephan Cl&#xe9;men&#xe7;on</h3>
<p>Many applications of AI, ranging from credit lending to medical diagnosis
support through recidivism prediction, involve scoring individuals using a
learned function of their attributes. These predictive risk scores are then
used to take decisions based on whether the score exceeds a certain threshold,
which may vary depending on the context. The level of delegation granted to
such systems will heavily depend on how questions of fairness can be answered.
In this paper, we study fairness for the problem of learning scoring functions
from binary labeled data, a standard learning task known as bipartite ranking.
We argue that the functional nature of the ROC curve, the gold standard measure
of ranking performance in this context, leads to several ways of formulating
fairness constraints. We introduce general classes of fairness definitions
based on the AUC and on ROC curves, and establish generalization bounds for
scoring functions learned under such constraints. Beyond the theoretical
formulation and results, we design practical learning algorithms and illustrate
our approach with numerical experiments on real and synthetic data.
</p>
<a href="http://arxiv.org/abs/2002.08159" target="_blank">arXiv:2002.08159</a> [<a href="http://arxiv.org/pdf/2002.08159" target="_blank">pdf</a>]

<h2>Value-driven Hindsight Modelling. (arXiv:2002.08329v2 [cs.LG] UPDATED)</h2>
<h3>Arthur Guez, Fabio Viola, Th&#xe9;ophane Weber, Lars Buesing, Steven Kapturowski, Doina Precup, David Silver, Nicolas Heess</h3>
<p>Value estimation is a critical component of the reinforcement learning (RL)
paradigm. The question of how to effectively learn value predictors from data
is one of the major problems studied by the RL community, and different
approaches exploit structure in the problem domain in different ways. Model
learning can make use of the rich transition structure present in sequences of
observations, but this approach is usually not sensitive to the reward
function. In contrast, model-free methods directly leverage the quantity of
interest from the future, but receive a potentially weak scalar signal (an
estimate of the return). We develop an approach for representation learning in
RL that sits in between these two extremes: we propose to learn what to model
in a way that can directly help value prediction. To this end, we determine
which features of the future trajectory provide useful information to predict
the associated return. This provides tractable prediction targets that are
directly relevant for a task, and can thus accelerate learning the value
function. The idea can be understood as reasoning, in hindsight, about which
aspects of the future observations could help past value prediction. We show
how this can help dramatically even in simple policy evaluation settings. We
then test our approach at scale in challenging domains, including on 57 Atari
2600 games.
</p>
<a href="http://arxiv.org/abs/2002.08329" target="_blank">arXiv:2002.08329</a> [<a href="http://arxiv.org/pdf/2002.08329" target="_blank">pdf</a>]

<h2>Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven Exploration. (arXiv:2002.09253v4 [cs.AI] UPDATED)</h2>
<h3>C&#xe9;dric Colas, Tristan Karch, Nicolas Lair, Jean-Michel Dussoux, Cl&#xe9;ment Moulin-Frier, Peter Ford Dominey, Pierre-Yves Oudeyer</h3>
<p>Developmental machine learning studies how artificial agents can model the
way children learn open-ended repertoires of skills. Such agents need to create
and represent goals, select which ones to pursue and learn to achieve them.
Recent approaches have considered goal spaces that were either fixed and
hand-defined or learned using generative models of states. This limited agents
to sample goals within the distribution of known effects. We argue that the
ability to imagine out-of-distribution goals is key to enable creative
discoveries and open-ended learning. Children do so by leveraging the
compositionality of language as a tool to imagine descriptions of outcomes they
never experienced before, targeting them as goals during play. We introduce
IMAGINE, an intrinsically motivated deep reinforcement learning architecture
that models this ability. Such imaginative agents, like children, benefit from
the guidance of a social peer who provides language descriptions. To take
advantage of goal imagination, agents must be able to leverage these
descriptions to interpret their imagined out-of-distribution goals. This
generalization is made possible by modularity: a decomposition between learned
goal-achievement reward function and policy relying on deep sets, gated
attention and object-centered representations. We introduce the Playground
environment and study how this form of goal imagination improves generalization
and exploration over agents lacking this capacity. In addition, we identify the
properties of goal imagination that enable these results and study the impacts
of modularity and social interactions.
</p>
<a href="http://arxiv.org/abs/2002.09253" target="_blank">arXiv:2002.09253</a> [<a href="http://arxiv.org/pdf/2002.09253" target="_blank">pdf</a>]

<h2>The Maximum Entropy on the Mean Method for Image Deblurring. (arXiv:2002.10434v4 [cs.CV] UPDATED)</h2>
<h3>Gabriel Rioux, Rustum Choksi, Tim Hoheisel, Pierre Marechal, Christopher Scarvelis</h3>
<p>Image deblurring is a notoriously challenging ill-posed inverse problem. In
recent years, a wide variety of approaches have been proposed based upon
regularization at the level of the image or on techniques from machine
learning. We propose an alternative approach, shifting the paradigm towards
regularization at the level of the probability distribution on the space of
images. Our method is based upon the idea of maximum entropy on the mean
wherein we work at the level of the probability density function of the image
whose expectation is our estimate of the ground truth. Using techniques from
convex analysis and probability theory, we show that the method is
computationally feasible and amenable to very large blurs. Moreover, when
images are imbedded with symbology (a known pattern), we show how our method
can be applied to approximate the unknown blur kernel with remarkable effects.
While our method is stable with respect to small amounts of noise, it does not
actively denoise. However, for moderate to large amounts of noise, it performs
well by preconditioned denoising with a state of the art method.
</p>
<a href="http://arxiv.org/abs/2002.10434" target="_blank">arXiv:2002.10434</a> [<a href="http://arxiv.org/pdf/2002.10434" target="_blank">pdf</a>]

<h2>Diversity-Based Generalization for Unsupervised Text Classification under Domain Shift. (arXiv:2002.10937v2 [cs.LG] UPDATED)</h2>
<h3>Jitin Krishnan, Hemant Purohit, Huzefa Rangwala</h3>
<p>Domain adaptation approaches seek to learn from a source domain and
generalize it to an unseen target domain. At present, the state-of-the-art
unsupervised domain adaptation approaches for subjective text classification
problems leverage unlabeled target data along with labeled source data. In this
paper, we propose a novel method for domain adaptation of single-task text
classification problems based on a simple but effective idea of diversity-based
generalization that does not require unlabeled target data but still matches
the state-of-the-art in performance. Diversity plays the role of promoting the
model to better generalize and be indiscriminate towards domain shift by
forcing the model not to rely on same features for prediction. We apply this
concept on the most explainable component of neural networks, the attention
layer. To generate sufficient diversity, we create a multi-head attention model
and infuse a diversity constraint between the attention heads such that each
head will learn differently. We further expand upon our model by tri-training
and designing a procedure with an additional diversity constraint between the
attention heads of the tri-trained classifiers. Extensive evaluation using the
standard benchmark dataset of Amazon reviews and a newly constructed dataset of
Crisis events shows that our fully unsupervised method matches with the
competing baselines that uses unlabeled target data. Our results demonstrate
that machine learning architectures that ensure sufficient diversity can
generalize better; encouraging future research to design ubiquitously usable
learning models without using unlabeled target data.
</p>
<a href="http://arxiv.org/abs/2002.10937" target="_blank">arXiv:2002.10937</a> [<a href="http://arxiv.org/pdf/2002.10937" target="_blank">pdf</a>]

<h2>Unsupervised and Interpretable Domain Adaptation to Rapidly Filter Tweets for Emergency Services. (arXiv:2003.04991v2 [cs.CL] UPDATED)</h2>
<h3>Jitin Krishnan, Hemant Purohit, Huzefa Rangwala</h3>
<p>During the onset of a disaster event, filtering relevant information from the
social web data is challenging due to its sparse availability and practical
limitations in labeling datasets of an ongoing crisis. In this paper, we
hypothesize that unsupervised domain adaptation through multi-task learning can
be a useful framework to leverage data from past crisis events for training
efficient information filtering models during the sudden onset of a new crisis.
We present a novel method to classify relevant tweets during an ongoing crisis
without seeing any new examples, using the publicly available dataset of TREC
incident streams. Specifically, we construct a customized multi-task
architecture with a multi-domain discriminator for crisis analytics: multi-task
domain adversarial attention network. This model consists of dedicated
attention layers for each task to provide model interpretability; critical for
real-word applications. As deep networks struggle with sparse datasets, we show
that this can be improved by sharing a base layer for multi-task learning and
domain adversarial training. Evaluation of domain adaptation for crisis events
is performed by choosing a target event as the test set and training on the
rest. Our results show that the multi-task model outperformed its single task
counterpart. For the qualitative evaluation of interpretability, we show that
the attention layer can be used as a guide to explain the model predictions and
empower emergency services for exploring accountability of the model, by
showcasing the words in a tweet that are deemed important in the classification
process. Finally, we show a practical implication of our work by providing a
use-case for the COVID-19 pandemic.
</p>
<a href="http://arxiv.org/abs/2003.04991" target="_blank">arXiv:2003.04991</a> [<a href="http://arxiv.org/pdf/2003.04991" target="_blank">pdf</a>]

<h2>Graph Neural Networks for Decentralized Controllers. (arXiv:2003.10280v2 [cs.LG] UPDATED)</h2>
<h3>Fernando Gama, Ekaterina Tolstaya, Alejandro Ribeiro</h3>
<p>Dynamical systems comprised of autonomous agents arise in many relevant
problems such as multi-agent robotics, smart grids, or smart cities.
Controlling these systems is of paramount importance to guarantee a successful
deployment. Optimal centralized controllers are readily available but face
limitations in terms of scalability and practical implementation. Optimal
decentralized controllers, on the other hand, are difficult to find. In this
paper, we propose a framework using graph neural networks (GNNs) to learn
decentralized controllers from data. While GNNs are naturally distributed
architectures, making them perfectly suited for the task, we adapt them to
handle delayed communications as well. Furthermore, they are equivariant and
stable, leading to good scalability and transferability properties. The problem
of flocking is explored to illustrate the potential of GNNs in learning
decentralized controllers.
</p>
<a href="http://arxiv.org/abs/2003.10280" target="_blank">arXiv:2003.10280</a> [<a href="http://arxiv.org/pdf/2003.10280" target="_blank">pdf</a>]

<h2>Channel Attention Residual U-Net for Retinal Vessel Segmentation. (arXiv:2004.03702v5 [eess.IV] UPDATED)</h2>
<h3>Changlu Guo, M&#xe1;rton Szemenyei, Yangtao Hu, Wenle Wang, Wei Zhou, Yugen Yi</h3>
<p>Retinal vessel segmentation is a vital step for the diagnosis of many early
eye-related diseases. In this work, we propose a new deep learning model,
namely Channel Attention Residual U-Net (CAR-UNet), to accurately segment
retinal vascular and non-vascular pixels. In this model, we introduced a novel
Modified Efficient Channel Attention (MECA) to enhance the discriminative
ability of the network by considering the interdependence between feature maps.
On the one hand, we apply MECA to the "skip connections" in the traditional
U-shaped networks, instead of simply copying the feature maps of the
contracting path to the corresponding expansive path. On the other hand, we
propose a Channel Attention Double Residual Block (CADRB), which integrates
MECA into a residual structure as a core structure to construct the proposed
CAR-UNet. The results show that our proposed CAR-UNet has reached the
state-of-the-art performance on three publicly available retinal vessel
datasets: DRIVE, CHASE DB1 and STARE.
</p>
<a href="http://arxiv.org/abs/2004.03702" target="_blank">arXiv:2004.03702</a> [<a href="http://arxiv.org/pdf/2004.03702" target="_blank">pdf</a>]

<h2>Instance-aware, Context-focused, and Memory-efficient Weakly Supervised Object Detection. (arXiv:2004.04725v3 [cs.CV] UPDATED)</h2>
<h3>Zhongzheng Ren, Zhiding Yu, Xiaodong Yang, Ming-Yu Liu, Yong Jae Lee, Alexander G. Schwing, Jan Kautz</h3>
<p>Weakly supervised learning has emerged as a compelling tool for object
detection by reducing the need for strong supervision during training. However,
major challenges remain: (1) differentiation of object instances can be
ambiguous; (2) detectors tend to focus on discriminative parts rather than
entire objects; (3) without ground truth, object proposals have to be redundant
for high recalls, causing significant memory consumption. Addressing these
challenges is difficult, as it often requires to eliminate uncertainties and
trivial solutions. To target these issues we develop an instance-aware and
context-focused unified framework. It employs an instance-aware self-training
algorithm and a learnable Concrete DropBlock while devising a memory-efficient
sequential batch back-propagation. Our proposed method achieves
state-of-the-art results on COCO ($12.1\% ~AP$, $24.8\% ~AP_{50}$), VOC 2007
($54.9\% ~AP$), and VOC 2012 ($52.1\% ~AP$), improving baselines by great
margins. In addition, the proposed method is the first to benchmark ResNet
based models and weakly supervised video object detection. Code, models, and
more details will be made available at: https://github.com/NVlabs/wetectron.
</p>
<a href="http://arxiv.org/abs/2004.04725" target="_blank">arXiv:2004.04725</a> [<a href="http://arxiv.org/pdf/2004.04725" target="_blank">pdf</a>]

<h2>Topological Quantum Compiling with Reinforcement Learning. (arXiv:2004.04743v2 [quant-ph] UPDATED)</h2>
<h3>Yuan-Hang Zhang, Pei-Lin Zheng, Yi Zhang, Dong-Ling Deng</h3>
<p>Quantum compiling, a process that decomposes the quantum algorithm into a
series of hardware-compatible commands or elementary gates, is of fundamental
importance for quantum computing. We introduce an efficient algorithm based on
deep reinforcement learning that compiles an arbitrary single-qubit gate into a
sequence of elementary gates from a finite universal set. It generates
near-optimal gate sequences with given accuracy and is generally applicable to
various scenarios, independent of the hardware-feasible universal set and free
from using ancillary qubits. For concreteness, we apply this algorithm to the
case of topological compiling of Fibonacci anyons and obtain near-optimal
braiding sequences for arbitrary single-qubit unitaries. Our algorithm may
carry over to other challenging quantum discrete problems, thus opening up a
new avenue for intriguing applications of deep learning in quantum physics.
</p>
<a href="http://arxiv.org/abs/2004.04743" target="_blank">arXiv:2004.04743</a> [<a href="http://arxiv.org/pdf/2004.04743" target="_blank">pdf</a>]

<h2>Transliteration of Judeo-Arabic Texts into Arabic Script Using Recurrent Neural Networks. (arXiv:2004.11405v2 [cs.CL] UPDATED)</h2>
<h3>Ori Terner, Kfir Bar, Nachum Dershowitz</h3>
<p>We trained a model to automatically transliterate Judeo-Arabic texts into
Arabic script, enabling Arabic readers to access those writings. We employ a
recurrent neural network (RNN), combined with the connectionist temporal
classification (CTC) loss to deal with unequal input/output lengths. This
obligates adjustments in the training data to avoid input sequences that are
shorter than their corresponding outputs. We also utilize a pretraining stage
with a different loss function to improve network converge. Since only a single
source of parallel text was available for training, we take advantage of the
possibility of generating data synthetically. We train a model that has the
capability to memorize words in the output language, and that also utilizes
context for distinguishing ambiguities in the transliteration. We obtain an
improvement over the baseline 9.5% character error, achieving 2% error with our
best configuration. To measure the contribution of context to learning, we also
tested word-shuffled data, for which the error rises to 2.5%.
</p>
<a href="http://arxiv.org/abs/2004.11405" target="_blank">arXiv:2004.11405</a> [<a href="http://arxiv.org/pdf/2004.11405" target="_blank">pdf</a>]

<h2>Self-Paced Deep Reinforcement Learning. (arXiv:2004.11812v4 [cs.LG] UPDATED)</h2>
<h3>Pascal Klink, Carlo D&#x27;Eramo, Jan Peters, Joni Pajarinen</h3>
<p>Curriculum reinforcement learning (CRL) improves the learning speed and
stability of an agent by exposing it to a tailored series of tasks throughout
learning. Despite empirical successes, an open question in CRL is how to
automatically generate a curriculum for a given reinforcement learning (RL)
agent, avoiding manual design. In this paper, we propose an answer by
interpreting the curriculum generation as an inference problem, where
distributions over tasks are progressively learned to approach the target task.
This approach leads to an automatic curriculum generation, whose pace is
controlled by the agent, with solid theoretical motivation and easily
integrated with deep RL algorithms. In the conducted experiments, the curricula
generated with the proposed algorithm significantly improve learning
performance across several environments and deep RL algorithms, matching or
outperforming state-of-the-art existing CRL algorithms.
</p>
<a href="http://arxiv.org/abs/2004.11812" target="_blank">arXiv:2004.11812</a> [<a href="http://arxiv.org/pdf/2004.11812" target="_blank">pdf</a>]

<h2>Transfer Learning for Thermal Comfort Prediction in Multiple Cities. (arXiv:2004.14382v3 [cs.LG] UPDATED)</h2>
<h3>Nan Gao, Wei Shao, Mohammad Saiedur Rahaman, Jun Zhai, Klaus David, Flora D. Salim</h3>
<p>HVAC (Heating, Ventilation and Air Conditioning) system is an important part
of a building, which constitutes up to 40% of building energy usage. The main
purpose of HVAC, maintaining appropriate thermal comfort, is crucial for the
best utilisation of energy usage. Besides, thermal comfort is also crucial for
well-being, health, and work productivity. Recently, data-driven thermal
comfort models have got better performance than traditional knowledge-based
methods (e.g. Predicted Mean Vote Model). An accurate thermal comfort model
requires a large amount of self-reported thermal comfort data from indoor
occupants which undoubtedly remains a challenge for researchers. In this
research, we aim to tackle this data-shortage problem and boost the performance
of thermal comfort prediction. We utilise sensor data from multiple cities in
the same climate zone to learn thermal comfort patterns. We present a transfer
learning based multilayer perceptron model from the same climate zone
(TL-MLP-C*) for accurate thermal comfort prediction. Extensive experimental
results on ASHRAE RP-884, the Scales Project and Medium US Office datasets show
that the performance of the proposed TL-MLP-C* exceeds the state-of-the-art
methods in accuracy, precision and F1-score.
</p>
<a href="http://arxiv.org/abs/2004.14382" target="_blank">arXiv:2004.14382</a> [<a href="http://arxiv.org/pdf/2004.14382" target="_blank">pdf</a>]

<h2>Derivation of a Constant Velocity Motion Model for Visual Tracking. (arXiv:2005.00844v4 [cs.CV] UPDATED)</h2>
<h3>Nathanael L. Baisa</h3>
<p>Motion models play a great role in visual tracking applications for
predicting the possible locations of objects in the next frame. Unlike target
tracking in radar or aerospace domain which considers only points, object
tracking in computer vision involves sizes of objects. Constant velocity motion
model is the most widely used motion model for visual tracking, however, there
is no clear and understandable derivation involving sizes of objects specially
for new researchers joining this research field. In this document, we derive
the constant velocity motion model that incorporates sizes of objects that, we
think, can help the new researchers to adapt to it very quickly.
</p>
<a href="http://arxiv.org/abs/2005.00844" target="_blank">arXiv:2005.00844</a> [<a href="http://arxiv.org/pdf/2005.00844" target="_blank">pdf</a>]

<h2>Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning. (arXiv:2005.08081v3 [cs.CL] UPDATED)</h2>
<h3>Fenglin Liu, Xuancheng Ren, Guangxiang Zhao, Xu Sun, Liangyou Li</h3>
<p>In sequence-to-sequence learning, the decoder relies on the attention
mechanism to efficiently extract information from the encoder. While it is
common practice to draw information from only the last encoder layer, recent
work has proposed to use representations from different encoder layers for
diversified levels of information. Nonetheless, the decoder still obtains only
a single view of the source sequences, which might lead to insufficient
training of the encoder layer stack due to the hierarchy bypassing problem. In
this work, we propose layer-wise cross-view decoding, where for each decoder
layer, together with the representations from the last encoder layer, which
serve as a global view, those from other encoder layers are supplemented for a
stereoscopic view of the source sequences. Systematic experiments show that we
successfully address the hierarchy bypassing problem and substantially improve
the performance of sequence-to-sequence learning with deep representations on
diverse tasks.
</p>
<a href="http://arxiv.org/abs/2005.08081" target="_blank">arXiv:2005.08081</a> [<a href="http://arxiv.org/pdf/2005.08081" target="_blank">pdf</a>]

<h2>Boosting First-Order Methods by Shifting Objective: New Schemes with Faster Worst-Case Rates. (arXiv:2005.12061v2 [cs.LG] UPDATED)</h2>
<h3>Kaiwen Zhou, Anthony Man-Cho So, James Cheng</h3>
<p>We propose a new methodology to design first-order methods for unconstrained
strongly convex problems. Specifically, instead of tackling the original
objective directly, we construct a shifted objective function that has the same
minimizer as the original objective and encodes both the smoothness and strong
convexity of the original objective in an interpolation condition. We then
propose an algorithmic template for tackling the shifted objective, which can
exploit such a condition. Following this template, we derive several new
accelerated schemes for problems that are equipped with various first-order
oracles and show that the interpolation condition allows us to vastly simplify
and tighten the analysis of the derived methods. In particular, all the derived
methods have faster worst-case convergence rates than their existing
counterparts. Experiments on machine learning tasks are conducted to evaluate
the new methods.
</p>
<a href="http://arxiv.org/abs/2005.12061" target="_blank">arXiv:2005.12061</a> [<a href="http://arxiv.org/pdf/2005.12061" target="_blank">pdf</a>]

<h2>Secretary and Online Matching Problems with Machine Learned Advice. (arXiv:2006.01026v2 [cs.DS] UPDATED)</h2>
<h3>Antonios Antoniadis, Themis Gouleakis, Pieter Kleer, Pavel Kolev</h3>
<p>The classical analysis of online algorithms, due to its worst-case nature,
can be quite pessimistic when the input instance at hand is far from
worst-case. Often this is not an issue with machine learning approaches, which
shine in exploiting patterns in past inputs in order to predict the future.
However, such predictions, although usually accurate, can be arbitrarily poor.
Inspired by a recent line of work, we augment three well-known online settings
with machine learned predictions about the future, and develop algorithms that
take them into account. In particular, we study the following online selection
problems: (i) the classical secretary problem, (ii) online bipartite matching
and (iii) the graphic matroid secretary problem. Our algorithms still come with
a worst-case performance guarantee in the case that predictions are subpar
while obtaining an improved competitive ratio (over the best-known classical
online algorithm for each problem) when the predictions are sufficiently
accurate. For each algorithm, we establish a trade-off between the competitive
ratios obtained in the two respective cases.
</p>
<a href="http://arxiv.org/abs/2006.01026" target="_blank">arXiv:2006.01026</a> [<a href="http://arxiv.org/pdf/2006.01026" target="_blank">pdf</a>]

<h2>Graphon Neural Networks and the Transferability of Graph Neural Networks. (arXiv:2006.03548v2 [cs.LG] UPDATED)</h2>
<h3>Luana Ruiz, Luiz F. O. Chamon, Alejandro Ribeiro</h3>
<p>Graph neural networks (GNNs) rely on graph convolutions to extract local
features from network data. These graph convolutions combine information from
adjacent nodes using coefficients that are shared across all nodes. Since these
coefficients are shared and do not depend on the graph, one can envision using
the same coefficients to define a GNN on another graph. This motivates
analyzing the transferability of GNNs across graphs. In this paper we introduce
graphon NNs as limit objects of GNNs and prove a bound on the difference
between the output of a GNN and its limit graphon-NN. This bound vanishes with
growing number of nodes if the graph convolutional filters are bandlimited in
the graph spectral domain. This result establishes a tradeoff between
discriminability and transferability of GNNs.
</p>
<a href="http://arxiv.org/abs/2006.03548" target="_blank">arXiv:2006.03548</a> [<a href="http://arxiv.org/pdf/2006.03548" target="_blank">pdf</a>]

<h2>Distributionally Robust $k$-Nearest Neighbors. (arXiv:2006.04004v3 [stat.ML] UPDATED)</h2>
<h3>Shixiang Zhu, Liyan Xie, Minghe Zhang, Rui Gao, Yao Xie</h3>
<p>Learning a robust classifier from a few samples remains a key challenge in
machine learning. A major thrust of research in classification with few
training samples has been based on metric learning to capture similarities
between samples and then perform the $k$-nearest neighbor algorithm. To make
such an algorithm more robust, in this paper, we propose a distributionally
robust $k$-nearest neighbor algorithm Dr.k-NN, which features assigning minimax
optimal weights to training samples when performing classification. We also
couple it with neural-network-based feature embedding. We demonstrate the
competitive performance of our algorithm comparing to the state-of-the-art in
the few-training-sample setting with various real-data experiments.
</p>
<a href="http://arxiv.org/abs/2006.04004" target="_blank">arXiv:2006.04004</a> [<a href="http://arxiv.org/pdf/2006.04004" target="_blank">pdf</a>]

<h2>Consistency Regularization for Certified Robustness of Smoothed Classifiers. (arXiv:2006.04062v3 [cs.LG] UPDATED)</h2>
<h3>Jongheon Jeong, Jinwoo Shin</h3>
<p>A recent technique of randomized smoothing has shown that the worst-case
(adversarial) $\ell_2$-robustness can be transformed into the average-case
Gaussian-robustness by "smoothing" a classifier, i.e., by considering the
averaged prediction over Gaussian noise. In this paradigm, one should rethink
the notion of adversarial robustness in terms of generalization ability of a
classifier under noisy observations. We found that the trade-off between
accuracy and certified robustness of smoothed classifiers can be greatly
controlled by simply regularizing the prediction consistency over noise. This
relationship allows us to design a robust training objective without
approximating a non-existing smoothed classifier, e.g., via soft smoothing. Our
experiments under various deep neural network architectures and datasets show
that the "certified" $\ell_2$-robustness can be dramatically improved with the
proposed regularization, even achieving better or comparable results to the
state-of-the-art approaches with significantly less training costs and
hyperparameters.
</p>
<a href="http://arxiv.org/abs/2006.04062" target="_blank">arXiv:2006.04062</a> [<a href="http://arxiv.org/pdf/2006.04062" target="_blank">pdf</a>]

<h2>Randomized Entity-wise Factorization for Multi-Agent Reinforcement Learning. (arXiv:2006.04222v2 [cs.LG] UPDATED)</h2>
<h3>Shariq Iqbal, Christian A. Schroeder de Witt, Bei Peng, Wendelin B&#xf6;hmer, Shimon Whiteson, Fei Sha</h3>
<p>Real world multi-agent tasks often involve varying types and quantities of
agents and non-agent entities; however, agents within these tasks rarely need
to consider all others at all times in order to act effectively. Factored value
function approaches have historically leveraged such independences to improve
learning efficiency, but these approaches typically rely on domain knowledge to
select fixed subsets of state features to include in each factor. We propose to
utilize value function factoring with random subsets of entities in each factor
as an auxiliary objective in order to disentangle value predictions from
irrelevant entities. This factoring approach is instantiated through a simple
attention mechanism masking procedure. We hypothesize that such an approach
helps agents learn more effectively in multi-agent settings by discovering
common trajectories across episodes within sub-groups of agents/entities. Our
approach, Randomized Entity-wise Factorization for Imagined Learning (REFIL),
outperforms all strong baselines by a significant margin in challenging
StarCraft micromanagement tasks.
</p>
<a href="http://arxiv.org/abs/2006.04222" target="_blank">arXiv:2006.04222</a> [<a href="http://arxiv.org/pdf/2006.04222" target="_blank">pdf</a>]

<h2>Fully Convolutional Mesh Autoencoder using Efficient Spatially Varying Kernels. (arXiv:2006.04325v2 [cs.CV] UPDATED)</h2>
<h3>Yi Zhou, Chenglei Wu, Zimo Li, Chen Cao, Yuting Ye, Jason Saragih, Hao Li, Yaser Sheikh</h3>
<p>Learning latent representations of registered meshes is useful for many 3D
tasks. Techniques have recently shifted to neural mesh autoencoders. Although
they demonstrate higher precision than traditional methods, they remain unable
to capture fine-grained deformations. Furthermore, these methods can only be
applied to a template-specific surface mesh, and is not applicable to more
general meshes, like tetrahedrons and non-manifold meshes. While more general
graph convolution methods can be employed, they lack performance in
reconstruction precision and require higher memory usage. In this paper, we
propose a non-template-specific fully convolutional mesh autoencoder for
arbitrary registered mesh data. It is enabled by our novel convolution and
(un)pooling operators learned with globally shared weights and locally varying
coefficients which can efficiently capture the spatially varying contents
presented by irregular mesh connections. Our model outperforms state-of-the-art
methods on reconstruction accuracy. In addition, the latent codes of our
network are fully localized thanks to the fully convolutional structure, and
thus have much higher interpolation capability than many traditional 3D mesh
generation models.
</p>
<a href="http://arxiv.org/abs/2006.04325" target="_blank">arXiv:2006.04325</a> [<a href="http://arxiv.org/pdf/2006.04325" target="_blank">pdf</a>]

<h2>Persona2vec: A Flexible Multi-role Representations Learning Framework for Graphs. (arXiv:2006.04941v2 [cs.SI] UPDATED)</h2>
<h3>Jisung Yoon, Kai-Cheng Yang, Woo-Sung Jung, Yong-Yeol Ahn</h3>
<p>Graph embedding techniques, which learn low-dimensional representations of a
graph, are achieving state-of-the-art performance in many graph mining tasks.
Most existing embedding algorithms assign a single vector to each node,
implicitly assuming that a single representation is enough to capture all
characteristics of the node. However, across many domains, it is common to
observe pervasively overlapping community structure, where most nodes belong to
multiple communities, playing different roles depending on the contexts. Here,
we propose persona2vec, a graph embedding framework that efficiently learns
multiple representations of nodes based on their structural contexts. Using
link prediction-based evaluation, we show that our framework is significantly
faster than the existing state-of-the-art model while achieving better
performance.
</p>
<a href="http://arxiv.org/abs/2006.04941" target="_blank">arXiv:2006.04941</a> [<a href="http://arxiv.org/pdf/2006.04941" target="_blank">pdf</a>]

<h2>Gaussian Gated Linear Networks. (arXiv:2006.05964v2 [cs.LG] UPDATED)</h2>
<h3>David Budden, Adam Marblestone, Eren Sezener, Tor Lattimore, Greg Wayne, Joel Veness</h3>
<p>We propose the Gaussian Gated Linear Network (G-GLN), an extension to the
recently proposed GLN family of deep neural networks. Instead of using
backpropagation to learn features, GLNs have a distributed and local credit
assignment mechanism based on optimizing a convex objective. This gives rise to
many desirable properties including universality, data-efficient online
learning, trivial interpretability and robustness to catastrophic forgetting.
We extend the GLN framework from classification to multiple regression and
density modelling by generalizing geometric mixing to a product of Gaussian
densities. The G-GLN achieves competitive or state-of-the-art performance on
several univariate and multivariate regression benchmarks, and we demonstrate
its applicability to practical tasks including online contextual bandits and
density estimation via denoising.
</p>
<a href="http://arxiv.org/abs/2006.05964" target="_blank">arXiv:2006.05964</a> [<a href="http://arxiv.org/pdf/2006.05964" target="_blank">pdf</a>]

<h2>A Class of Algorithms for General Instrumental Variable Models. (arXiv:2006.06366v3 [cs.LG] UPDATED)</h2>
<h3>Niki Kilbertus, Matt J. Kusner, Ricardo Silva</h3>
<p>Causal treatment effect estimation is a key problem that arises in a variety
of real-world settings, from personalized medicine to governmental policy
making. There has been a flurry of recent work in machine learning on
estimating causal effects when one has access to an instrument. However, to
achieve identifiability, they in general require one-size-fits-all assumptions
such as an additive error model for the outcome. An alternative is partial
identification, which provides bounds on the causal effect. Little exists in
terms of bounding methods that can deal with the most general case, where the
treatment itself can be continuous. Moreover, bounding methods generally do not
allow for a continuum of assumptions on the shape of the causal effect that can
smoothly trade off stronger background knowledge for more informative bounds.
In this work, we provide a method for causal effect bounding in continuous
distributions, leveraging recent advances in gradient-based methods for the
optimization of computationally intractable objective functions. We demonstrate
on a set of synthetic and real-world data that our bounds capture the causal
effect when additive methods fail, providing a useful range of answers
compatible with observation as opposed to relying on unwarranted structural
assumptions.
</p>
<a href="http://arxiv.org/abs/2006.06366" target="_blank">arXiv:2006.06366</a> [<a href="http://arxiv.org/pdf/2006.06366" target="_blank">pdf</a>]

<h2>On Second Order Behaviour in Augmented Neural ODEs. (arXiv:2006.07220v2 [cs.LG] UPDATED)</h2>
<h3>Alexander Norcliffe, Cristian Bodnar, Ben Day, Nikola Simidjievski, Pietro Li&#xf2;</h3>
<p>Neural Ordinary Differential Equations (NODEs) are a new class of models that
transform data continuously through infinite-depth architectures. The
continuous nature of NODEs has made them particularly suitable for learning the
dynamics of complex physical systems. While previous work has mostly been
focused on first order ODEs, the dynamics of many systems, especially in
classical physics, are governed by second order laws. In this work, we consider
Second Order Neural ODEs (SONODEs). We show how the adjoint sensitivity method
can be extended to SONODEs and prove that the optimisation of a first order
coupled ODE is equivalent and computationally more efficient. Furthermore, we
extend the theoretical understanding of the broader class of Augmented NODEs
(ANODEs) by showing they can also learn higher order dynamics with a minimal
number of augmented dimensions, but at the cost of interpretability. This
indicates that the advantages of ANODEs go beyond the extra space offered by
the augmented dimensions, as originally thought. Finally, we compare SONODEs
and ANODEs on synthetic and real dynamical systems and demonstrate that the
inductive biases of the former generally result in faster training and better
performance.
</p>
<a href="http://arxiv.org/abs/2006.07220" target="_blank">arXiv:2006.07220</a> [<a href="http://arxiv.org/pdf/2006.07220" target="_blank">pdf</a>]

<h2>Reservoir Computing meets Recurrent Kernels and Structured Transforms. (arXiv:2006.07310v2 [stat.ML] UPDATED)</h2>
<h3>Jonathan Dong, Ruben Ohana, Mushegh Rafayelyan, Florent Krzakala</h3>
<p>Reservoir Computing is a class of simple yet efficient Recurrent Neural
Networks where internal weights are fixed at random and only a linear output
layer is trained. In the large size limit, such random neural networks have a
deep connection with kernel methods. Our contributions are threefold: a) We
rigorously establish the recurrent kernel limit of Reservoir Computing and
prove its convergence. b) We test our models on chaotic time series prediction,
a classic but challenging benchmark in Reservoir Computing, and show how the
Recurrent Kernel is competitive and computationally efficient when the number
of data points remains moderate. c) When the number of samples is too large, we
leverage the success of structured Random Features for kernel approximation by
introducing Structured Reservoir Computing. The two proposed methods, Recurrent
Kernel and Structured Reservoir Computing, turn out to be much faster and more
memory-efficient than conventional Reservoir Computing.
</p>
<a href="http://arxiv.org/abs/2006.07310" target="_blank">arXiv:2006.07310</a> [<a href="http://arxiv.org/pdf/2006.07310" target="_blank">pdf</a>]

<h2>Self-Imitation Learning via Generalized Lower Bound Q-learning. (arXiv:2006.07442v2 [cs.LG] UPDATED)</h2>
<h3>Yunhao Tang</h3>
<p>Self-imitation learning motivated by lower-bound Q-learning is a novel and
effective approach for off-policy learning. In this work, we propose a n-step
lower bound which generalizes the original return-based lower-bound Q-learning,
and introduce a new family of self-imitation learning algorithms. To provide a
formal motivation for the potential performance gains provided by
self-imitation learning, we show that n-step lower bound Q-learning achieves a
trade-off between fixed point bias and contraction rate, drawing close
connections to the popular uncorrected n-step Q-learning. We finally show that
n-step lower bound Q-learning is a more robust alternative to return-based
self-imitation learning and uncorrected n-step, over a wide range of continuous
control benchmark tasks.
</p>
<a href="http://arxiv.org/abs/2006.07442" target="_blank">arXiv:2006.07442</a> [<a href="http://arxiv.org/pdf/2006.07442" target="_blank">pdf</a>]

<h2>Flexible Dataset Distillation: Learn Labels Instead of Images. (arXiv:2006.08572v2 [cs.LG] UPDATED)</h2>
<h3>Ondrej Bohdal, Yongxin Yang, Timothy Hospedales</h3>
<p>We study the problem of dataset distillation - creating a small set of
synthetic examples capable of training a good model. In particular, we study
the problem of label distillation - creating synthetic labels for a small set
of real images, and show it to be more effective than the prior image-based
approach to dataset distillation. Methodologically, we introduce a more robust
and flexible meta-learning algorithm for distillation, as well as an effective
first-order strategy based on convex optimization layers. Distilling labels
with our new algorithm leads to improved results over prior image-based
distillation. More importantly, it leads to clear improvements in flexibility
of the distilled dataset in terms of compatibility with off-the-shelf
optimizers and diverse neural architectures. Interestingly, label distillation
can also be applied across datasets, for example enabling learning Japanese
character recognition by training only on synthetically labeled English
letters.
</p>
<a href="http://arxiv.org/abs/2006.08572" target="_blank">arXiv:2006.08572</a> [<a href="http://arxiv.org/pdf/2006.08572" target="_blank">pdf</a>]

<h2>Deeply Learned Spectral Total Variation Decomposition. (arXiv:2006.10004v2 [cs.CV] UPDATED)</h2>
<h3>Tamara G. Grossmann, Yury Korolev, Guy Gilboa, Carola-Bibiane Sch&#xf6;nlieb</h3>
<p>Non-linear spectral decompositions of images based on one-homogeneous
functionals such as total variation have gained considerable attention in the
last few years. Due to their ability to extract spectral components
corresponding to objects of different size and contrast, such decompositions
enable filtering, feature transfer, image fusion and other applications.
However, obtaining this decomposition involves solving multiple non-smooth
optimisation problems and is therefore computationally highly intensive. In
this paper, we present a neural network approximation of a non-linear spectral
decomposition. We report up to four orders of magnitude ($\times 10,000$)
speedup in processing of mega-pixel size images, compared to classical GPU
implementations. Our proposed network, TVSpecNET, is able to implicitly learn
the underlying PDE and, despite being entirely data driven, inherits
invariances of the model based transform. To the best of our knowledge, this is
the first approach towards learning a non-linear spectral decomposition of
images. Not only do we gain a staggering computational advantage, but this
approach can also be seen as a step towards studying neural networks that can
decompose an image into spectral components defined by a user rather than a
handcrafted functional.
</p>
<a href="http://arxiv.org/abs/2006.10004" target="_blank">arXiv:2006.10004</a> [<a href="http://arxiv.org/pdf/2006.10004" target="_blank">pdf</a>]

<h2>Predictive Complexity Priors. (arXiv:2006.10801v3 [stat.ML] UPDATED)</h2>
<h3>Eric Nalisnick, Jonathan Gordon, Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</h3>
<p>Specifying a Bayesian prior is notoriously difficult for complex models such
as neural networks. Reasoning about parameters is made challenging by the
high-dimensionality and over-parameterization of the space. Priors that seem
benign and uninformative can have unintuitive and detrimental effects on a
model's predictions. For this reason, we propose predictive complexity priors:
a functional prior that is defined by comparing the model's predictions to
those of a reference model. Although originally defined on the model outputs,
we transfer the prior to the model parameters via a change of variables. The
traditional Bayesian workflow can then proceed as usual. We apply our
predictive complexity prior to high-dimensional regression, reasoning over
neural network depth, and sharing of statistical strength for few-shot
learning.
</p>
<a href="http://arxiv.org/abs/2006.10801" target="_blank">arXiv:2006.10801</a> [<a href="http://arxiv.org/pdf/2006.10801" target="_blank">pdf</a>]

<h2>Optimization and Generalization of Regularization-Based Continual Learning: a Loss Approximation Viewpoint. (arXiv:2006.10974v2 [cs.LG] UPDATED)</h2>
<h3>Dong Yin, Mehrdad Farajtabar, Ang Li, Nir Levine, Alex Mott</h3>
<p>Neural networks have achieved remarkable success in many cognitive tasks.
However, when they are trained sequentially on multiple tasks without access to
old data, their performance on early tasks tend to drop significantly. This
problem is often referred to as catastrophic forgetting, a key challenge in
continual learning of neural networks. The regularization-based approach is one
of the primary classes of methods to alleviate catastrophic forgetting. In this
paper, we provide a novel viewpoint of regularization-based continual learning
by formulating it as a second-order Taylor approximation of the loss function
of each task. This viewpoint leads to a unified framework that can be
instantiated to derive many existing algorithms such as Elastic Weight
Consolidation and Kronecker factored Laplace approximation. Based on this
viewpoint, we study the optimization aspects (i.e., convergence) as well as
generalization properties (i.e., finite-sample guarantees) of
regularization-based continual learning. Our theoretical results indicate the
importance of accurate approximation of the Hessian matrix. The experimental
results on several benchmarks provide empirical validation of our theoretical
findings.
</p>
<a href="http://arxiv.org/abs/2006.10974" target="_blank">arXiv:2006.10974</a> [<a href="http://arxiv.org/pdf/2006.10974" target="_blank">pdf</a>]

<h2>Deep Learning-based Single Image Face Depth Data Enhancement. (arXiv:2006.11091v2 [cs.CV] UPDATED)</h2>
<h3>Torsten Schlett, Christian Rathgeb, Christoph Busch</h3>
<p>Face recognition can benefit from the utilization of depth data captured
using low-cost cameras, in particular for presentation attack detection
purposes. Depth video output from these capture devices can however contain
defects such as holes, as well as general depth inaccuracies. This work
proposes a deep learning face depth enhancement method in this context of
facial biometrics, which adds a security aspect to the topic. U-Net-like
architectures are utilized, and the networks are compared against hand-crafted
enhancer types. All tested enhancer types exclusively use depth data as input,
which differs from methods that enhance depth based on additional input data
such as visible light color images. Synthetic face depth ground truth images
and degraded forms thereof are created with help of PRNet, to train the deep
learning enhancers. Quantitative evaluations are carried out on the synthetic
data, and on Kinect v1 images from the KinectFaceDB. This includes an
assessment of the falsification for occluded face depth input, which is
relevant to biometric security. Qualitative examples are shown for synthetic
images, KinectFaceDB images, and additional custom RealSense D435 images. It is
concluded that the deep learning enhancement approach is superior to the tested
hand-crafted enhancers, without overly falsifying depth data when non-face
input is provided.
</p>
<a href="http://arxiv.org/abs/2006.11091" target="_blank">arXiv:2006.11091</a> [<a href="http://arxiv.org/pdf/2006.11091" target="_blank">pdf</a>]

<h2>A Survey on Machine Reading Comprehension: Tasks, Evaluation Metrics and Benchmark Datasets. (arXiv:2006.11880v2 [cs.CL] UPDATED)</h2>
<h3>Changchang Zeng, Shaobo Li, Qin Li, Jie Hu, Jianjun Hu</h3>
<p>Machine Reading Comprehension (MRC) is a challenging Natural Language
Processing(NLP) research field with wide real-world applications. The great
progress of this field in recent years is mainly due to the emergence of
large-scale datasets and deep learning. At present, a lot of MRC models have
already surpassed human performance on various benchmark datasets despite the
obvious giant gap between existing MRC models and genuine human-level reading
comprehension. This shows the need for improving existing datasets, evaluation
metrics, and models to move current MRC models toward "real" understanding. To
address the current lack of comprehensive survey of existing MRC tasks,
evaluation metrics, and datasets, herein, (1) we analyze 57 MRC tasks and
datasets and propose a more precise classification method of MRC tasks with 4
different attributes; (2) we summarized 9 evaluation metrics of MRC tasks, 7
attributes and 10 characteristics of MRC datasets; (3) We also discuss key open
issues in MRC research and highlighted future research directions. In addition,
we have collected, organized, and published our data on the companion
website(https://mrc-datasets.github.io/) where MRC researchers could directly
access each MRC dataset, papers, baseline projects, and the leaderboard.
</p>
<a href="http://arxiv.org/abs/2006.11880" target="_blank">arXiv:2006.11880</a> [<a href="http://arxiv.org/pdf/2006.11880" target="_blank">pdf</a>]

<h2>A spherical analysis of Adam with Batch Normalization. (arXiv:2006.13382v2 [cs.LG] UPDATED)</h2>
<h3>Simon Roburin, Yann de Mont-Marin, Andrei Bursuc, Renaud Marlet, Patrick P&#xe9;rez, Mathieu Aubry</h3>
<p>Batch Normalization (BN) is a prominent deep learning technique. In spite of
its apparent simplicity, its implications over optimization are yet to be fully
understood. While previous studies mostly focus on the interaction between BN
and stochastic gradient descent (SGD), we develop a geometric perspective which
allows us to precisely characterize the relation between BN and Adam. More
precisely, we leverage the radial invariance of groups of parameters, such as
filters for convolutional neural networks, to translate the optimization steps
on the $L_2$ unit hypersphere. This formulation and the associated geometric
interpretation shed new light on the training dynamics. Firstly, we use it to
derive the first effective learning rate expression of Adam. Then we show that,
in the presence of BN layers, performing SGD alone is actually equivalent to a
variant of Adam constrained to the unit hypersphere. Finally, our analysis
outlines phenomena that previous variants of Adam act on and we experimentally
validate their importance in the optimization process.
</p>
<a href="http://arxiv.org/abs/2006.13382" target="_blank">arXiv:2006.13382</a> [<a href="http://arxiv.org/pdf/2006.13382" target="_blank">pdf</a>]

<h2>Estimating Asset Class Health Indices in Power Systems. (arXiv:2006.14193v3 [cs.CE] UPDATED)</h2>
<h3>Ming Dong</h3>
<p>Power systems have widely adopted the concept of health index to describe
asset health statuses and choose proper asset management actions. The existing
application and research works have been focused on determining the current or
near-future asset health index based on the current condition data. For
preventative asset management, it is highly desirable to estimate asset health
indices, especially for asset classes in which the assets share similar
electrical and/or mechanical characteristics. This important problem has not
been sufficiently addressed. This paper proposes a sequence learning based
method to estimate health indices for power asset classes. A comprehensive
data-driven method based on sequence learning is presented and solid tests are
conducted based on real utility data. The proposed method revealed superior
performance with comparison to other Estimation methods.
</p>
<a href="http://arxiv.org/abs/2006.14193" target="_blank">arXiv:2006.14193</a> [<a href="http://arxiv.org/pdf/2006.14193" target="_blank">pdf</a>]

<h2>Debiased Contrastive Learning. (arXiv:2007.00224v3 [cs.LG] UPDATED)</h2>
<h3>Ching-Yao Chuang, Joshua Robinson, Lin Yen-Chen, Antonio Torralba, Stefanie Jegelka</h3>
<p>A prominent technique for self-supervised representation learning has been to
contrast semantically similar and dissimilar pairs of samples. Without access
to labels, dissimilar (negative) points are typically taken to be randomly
sampled datapoints, implicitly accepting that these points may, in reality,
actually have the same label. Perhaps unsurprisingly, we observe that sampling
negative examples from truly different labels improves performance, in a
synthetic setting where labels are available. Motivated by this observation, we
develop a debiased contrastive objective that corrects for the sampling of
same-label datapoints, even without knowledge of the true labels. Empirically,
the proposed objective consistently outperforms the state-of-the-art for
representation learning in vision, language, and reinforcement learning
benchmarks. Theoretically, we establish generalization bounds for the
downstream classification task.
</p>
<a href="http://arxiv.org/abs/2007.00224" target="_blank">arXiv:2007.00224</a> [<a href="http://arxiv.org/pdf/2007.00224" target="_blank">pdf</a>]

<h2>Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval. (arXiv:2007.00808v2 [cs.IR] UPDATED)</h2>
<h3>Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, Arnold Overwijk</h3>
<p>Conducting text retrieval in a dense learned representation space has many
intriguing advantages over sparse retrieval. Yet the effectiveness of dense
retrieval (DR) often requires combination with sparse retrieval. In this paper,
we identify that the main bottleneck is in the training mechanisms, where the
negative instances used in training are not representative of the irrelevant
documents in testing. This paper presents Approximate nearest neighbor Negative
Contrastive Estimation (ANCE), a training mechanism that constructs negatives
from an Approximate Nearest Neighbor (ANN) index of the corpus, which is
parallelly updated with the learning process to select more realistic negative
training instances. This fundamentally resolves the discrepancy between the
data distribution used in the training and testing of DR. In our experiments,
ANCE boosts the BERT-Siamese DR model to outperform all competitive dense and
sparse retrieval baselines. It nearly matches the accuracy of
sparse-retrieval-and-BERT-reranking using dot-product in the ANCE-learned
representation space and provides almost 100x speed-up.
</p>
<a href="http://arxiv.org/abs/2007.00808" target="_blank">arXiv:2007.00808</a> [<a href="http://arxiv.org/pdf/2007.00808" target="_blank">pdf</a>]

<h2>Hierarchically Organized Latent Modules for Exploratory Search in Morphogenetic Systems. (arXiv:2007.01195v2 [cs.LG] UPDATED)</h2>
<h3>Mayalen Etcheverry, Clement Moulin-Frier, Pierre-Yves Oudeyer</h3>
<p>Self-organization of complex morphological patterns from local interactions
is a fascinating phenomenon in many natural and artificial systems. In the
artificial world, typical examples of such morphogenetic systems are cellular
automata. Yet, their mechanisms are often very hard to grasp and so far
scientific discoveries of novel patterns have primarily been relying on manual
tuning and ad hoc exploratory search. The problem of automated diversity-driven
discovery in these systems was recently introduced [26, 62], highlighting that
two key ingredients are autonomous exploration and unsupervised representation
learning to describe "relevant" degrees of variations in the patterns. In this
paper, we motivate the need for what we call Meta-diversity search, arguing
that there is not a unique ground truth interesting diversity as it strongly
depends on the final observer and its motives. Using a continuous game-of-life
system for experiments, we provide empirical evidences that relying on
monolithic architectures for the behavioral embedding design tends to bias the
final discoveries (both for hand-defined and unsupervisedly-learned features)
which are unlikely to be aligned with the interest of a final end-user. To
address these issues, we introduce a novel dynamic and modular architecture
that enables unsupervised learning of a hierarchy of diverse representations.
Combined with intrinsically motivated goal exploration algorithms, we show that
this system forms a discovery assistant that can efficiently adapt its
diversity search towards preferences of a user using only a very small amount
of user feedback.
</p>
<a href="http://arxiv.org/abs/2007.01195" target="_blank">arXiv:2007.01195</a> [<a href="http://arxiv.org/pdf/2007.01195" target="_blank">pdf</a>]

<h2>Multi-Fidelity Bayesian Optimization via Deep Neural Networks. (arXiv:2007.03117v3 [cs.LG] UPDATED)</h2>
<h3>Shibo Li, Wei Xing, Mike Kirby, Shandian Zhe</h3>
<p>Bayesian optimization (BO) is a popular framework to optimize black-box
functions. In many applications, the objective function can be evaluated at
multiple fidelities to enable a trade-off between the cost and accuracy. To
reduce the optimization cost, many multi-fidelity BO methods have been
proposed. Despite their success, these methods either ignore or over-simplify
the strong, complex correlations across the fidelities, and hence can be
inefficient in estimating the objective function. To address this issue, we
propose Deep Neural Network Multi-Fidelity Bayesian Optimization (DNN-MFBO)
that can flexibly capture all kinds of complicated relationships between the
fidelities to improve the objective function estimation and hence the
optimization performance. We use sequential, fidelity-wise Gauss-Hermite
quadrature and moment-matching to fulfill a mutual information-based
acquisition function, which is computationally tractable and efficient. We show
the advantages of our method in both synthetic benchmark datasets and
real-world applications in engineering design.
</p>
<a href="http://arxiv.org/abs/2007.03117" target="_blank">arXiv:2007.03117</a> [<a href="http://arxiv.org/pdf/2007.03117" target="_blank">pdf</a>]

<h2>Program Synthesis with Pragmatic Communication. (arXiv:2007.05060v3 [cs.AI] UPDATED)</h2>
<h3>Yewen Pu, Kevin Ellis, Marta Kryven, Josh Tenenbaum, Armando Solar-Lezama</h3>
<p>Program synthesis techniques construct or infer programs from user-provided
specifications, such as input-output examples. Yet most specifications,
especially those given by end-users, leave the synthesis problem radically
ill-posed, because many programs may simultaneously satisfy the specification.
Prior work resolves this ambiguity by using various inductive biases, such as a
preference for simpler programs. This work introduces a new inductive bias
derived by modeling the program synthesis task as rational communication,
drawing insights from recursive reasoning models of pragmatics. Given a
specification, we score a candidate program both on its consistency with the
specification, and also whether a rational speaker would chose this particular
specification to communicate that program. We develop efficient algorithms for
such an approach when learning from input-output examples, and build a
pragmatic program synthesizer over a simple grid-like layout domain. A user
study finds that end-user participants communicate more effectively with the
pragmatic program synthesizer over a non-pragmatic one.
</p>
<a href="http://arxiv.org/abs/2007.05060" target="_blank">arXiv:2007.05060</a> [<a href="http://arxiv.org/pdf/2007.05060" target="_blank">pdf</a>]

<h2>CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances. (arXiv:2007.08176v2 [cs.LG] UPDATED)</h2>
<h3>Jihoon Tack, Sangwoo Mo, Jongheon Jeong, Jinwoo Shin</h3>
<p>Novelty detection, i.e., identifying whether a given sample is drawn from
outside the training distribution, is essential for reliable machine learning.
To this end, there have been many attempts at learning a representation
well-suited for novelty detection and designing a score based on such
representation. In this paper, we propose a simple, yet effective method named
contrasting shifted instances (CSI), inspired by the recent success on
contrastive learning of visual representations. Specifically, in addition to
contrasting a given sample with other instances as in conventional contrastive
learning methods, our training scheme contrasts the sample with
distributionally-shifted augmentations of itself. Based on this, we propose a
new detection score that is specific to the proposed training scheme. Our
experiments demonstrate the superiority of our method under various novelty
detection scenarios, including unlabeled one-class, unlabeled multi-class and
labeled multi-class settings, with various image benchmark datasets. Code and
pre-trained models are available at https://github.com/alinlab/CSI.
</p>
<a href="http://arxiv.org/abs/2007.08176" target="_blank">arXiv:2007.08176</a> [<a href="http://arxiv.org/pdf/2007.08176" target="_blank">pdf</a>]

<h2>AE TextSpotter: Learning Visual and Linguistic Representation for Ambiguous Text Spotting. (arXiv:2008.00714v4 [cs.CV] UPDATED)</h2>
<h3>Wenhai Wang, Xuebo Liu, Xiaozhong Ji, Enze Xie, Ding Liang, Zhibo Yang, Tong Lu, Chunhua Shen, Ping Luo</h3>
<p>Scene text spotting aims to detect and recognize the entire word or sentence
with multiple characters in natural images. It is still challenging because
ambiguity often occurs when the spacing between characters is large or the
characters are evenly spread in multiple rows and columns, making many visually
plausible groupings of the characters (e.g. "BERLIN" is incorrectly detected as
"BERL" and "IN" in Fig. 1(c)). Unlike previous works that merely employed
visual features for text detection, this work proposes a novel text spotter,
named Ambiguity Eliminating Text Spotter (AE TextSpotter), which learns both
visual and linguistic features to significantly reduce ambiguity in text
detection. The proposed AE TextSpotter has three important benefits. 1) The
linguistic representation is learned together with the visual representation in
a framework. To our knowledge, it is the first time to improve text detection
by using a language model. 2) A carefully designed language module is utilized
to reduce the detection confidence of incorrect text lines, making them easily
pruned in the detection stage. 3) Extensive experiments show that AE
TextSpotter outperforms other state-of-the-art methods by a large margin. For
example, we carefully select a validation set of extremely ambiguous samples
from the IC19-ReCTS dataset, where our approach surpasses other methods by more
than 4%. The code has been released at
https://github.com/whai362/AE_TextSpotter. The image list and evaluation
scripts of the validation set have been released at
https://github.com/whai362/TDA-ReCTS.
</p>
<a href="http://arxiv.org/abs/2008.00714" target="_blank">arXiv:2008.00714</a> [<a href="http://arxiv.org/pdf/2008.00714" target="_blank">pdf</a>]

<h2>Machine Learning in Nano-Scale Biomedical Engineering. (arXiv:2008.02195v2 [cs.LG] UPDATED)</h2>
<h3>Alexandros-Apostolos A. Boulogeorgos, Stylianos E. Trevlakis, Sotiris A. Tegos, Vasilis K. Papanikolaou, George K. Karagiannidis</h3>
<p>Machine learning (ML) empowers biomedical systems with the capability to
optimize their performance through modeling of the available data extremely
well, without using strong assumptions about the modeled system. Especially in
nano-scale biosystems, where the generated data sets are too vast and complex
to mentally parse without computational assist, ML is instrumental in analyzing
and extracting new insights, accelerating material and structure discoveries,
and designing experience as well as supporting nano-scale communications and
networks. However, despite these efforts, the use of ML in nano-scale
biomedical engineering remains still under-explored in certain areas and
research challenges are still open in fields such as structure and material
design and simulations, communications and signal processing, and bio-medicine
applications. In this article, we review the existing research regarding the
use of ML in nano-scale biomedical engineering. In more detail, we first
identify and discuss the main challenges that can be formulated as ML problems.
These challenges are classified into the three aforementioned main categories.
Next, we discuss the state of the art ML methodologies that are used to
countermeasure the aforementioned challenges. For each of the presented
methodologies, special emphasis is given to its principles, applications, and
limitations. Finally, we conclude the article with insightful discussions, that
reveal research gaps and highlight possible future research directions.
</p>
<a href="http://arxiv.org/abs/2008.02195" target="_blank">arXiv:2008.02195</a> [<a href="http://arxiv.org/pdf/2008.02195" target="_blank">pdf</a>]

<h2>XNAP: Making LSTM-based Next Activity Predictions Explainable by Using LRP. (arXiv:2008.07993v2 [cs.AI] UPDATED)</h2>
<h3>Sven Weinzierl, Sandra Zilker, Jens Brunk, Kate Revoredo, Martin Matzner, J&#xf6;rg Becker</h3>
<p>Predictive business process monitoring (PBPM) is a class of techniques
designed to predict behaviour, such as next activities, in running traces. PBPM
techniques aim to improve process performance by providing predictions to
process analysts, supporting them in their decision making. However, the PBPM
techniques` limited predictive quality was considered as the essential obstacle
for establishing such techniques in practice. With the use of deep neural
networks (DNNs), the techniques` predictive quality could be improved for tasks
like the next activity prediction. While DNNs achieve a promising predictive
quality, they still lack comprehensibility due to their hierarchical approach
of learning representations. Nevertheless, process analysts need to comprehend
the cause of a prediction to identify intervention mechanisms that might affect
the decision making to secure process performance. In this paper, we propose
XNAP, the first explainable, DNN-based PBPM technique for the next activity
prediction. XNAP integrates a layer-wise relevance propagation method from the
field of explainable artificial intelligence to make predictions of a long
short-term memory DNN explainable by providing relevance values for activities.
We show the benefit of our approach through two real-life event logs.
</p>
<a href="http://arxiv.org/abs/2008.07993" target="_blank">arXiv:2008.07993</a> [<a href="http://arxiv.org/pdf/2008.07993" target="_blank">pdf</a>]

<h2>Explainable Spatial Clustering: Leveraging Spatial Data in Radiation Oncology. (arXiv:2008.11282v2 [cs.HC] UPDATED)</h2>
<h3>Andrew Wentzel, Guadalupe Canahuate, Lisanne van Dijk, Abdallah Mohamed, Clifton David Fuller, G.Elisabeta Marai</h3>
<p>Advances in data collection in radiation therapy have led to an abundance of
opportunities for applying data mining and machine learning techniques to
promote new data-driven insights. In light of these advances, supporting
collaboration between machine learning experts and clinicians is important for
facilitating better development and adoption of these models. Although many
medical use-cases rely on spatial data, where understanding and visualizing the
underlying structure of the data is important, little is known about the
interpretability of spatial clustering results by clinical audiences. In this
work, we reflect on the design of visualizations for explaining novel
approaches to clustering complex anatomical data from head and neck cancer
patients. These visualizations were developed, through participatory design,
for clinical audiences during a multi-year collaboration with radiation
oncologists and statisticians. We distill this collaboration into a set of
lessons learned for creating visual and explainable spatial clustering for
clinical users.
</p>
<a href="http://arxiv.org/abs/2008.11282" target="_blank">arXiv:2008.11282</a> [<a href="http://arxiv.org/pdf/2008.11282" target="_blank">pdf</a>]

<h2>DCN V2: Improved Deep & Cross Network and Practical Lessons for Web-scale Learning to Rank Systems. (arXiv:2008.13535v2 [cs.IR] UPDATED)</h2>
<h3>Ruoxi Wang, Rakesh Shivanna, Derek Z. Cheng, Sagar Jain, Dong Lin, Lichan Hong, Ed H. Chi</h3>
<p>Learning effective feature crosses is the key behind building recommender
systems. However, the sparse and large feature space requires exhaustive search
to identify effective crosses. Deep &amp; Cross Network (DCN) was proposed to
automatically and efficiently learn bounded-degree predictive feature
interactions. Unfortunately, in models that serve web-scale traffic with
billions of training examples, DCN showed limited expressiveness in its cross
network at learning more predictive feature interactions. Despite significant
research progress made, many deep learning models in production still rely on
traditional feed-forward neural networks to learn feature crosses
inefficiently.

In light of the pros/cons of DCN and existing feature interaction learning
approaches, we propose an improved framework DCN-V2 to make DCN more practical
in large-scale industrial settings. In a comprehensive experimental study with
extensive hyper-parameter search and model tuning, we observed that DCN-V2
approaches outperform all the state-of-the-art algorithms on popular benchmark
datasets. The improved DCN-V2 is more expressive yet remains cost efficient at
feature interaction learning, especially when coupled with a mixture of
low-rank architecture. DCN-V2 is simple, can be easily adopted as building
blocks, and has delivered significant offline accuracy and online business
metrics gains across many web-scale learning to rank systems at Google.
</p>
<a href="http://arxiv.org/abs/2008.13535" target="_blank">arXiv:2008.13535</a> [<a href="http://arxiv.org/pdf/2008.13535" target="_blank">pdf</a>]

<h2>Effective Proximal Methods for Non-convex Non-smooth Regularized Learning. (arXiv:2009.06562v3 [cs.LG] UPDATED)</h2>
<h3>Guannan Liang, Qianqian Tong, Jiahao Ding, Miao Pan, Jinbo Bi</h3>
<p>Sparse learning is a very important tool for mining useful information and
patterns from high dimensional data. Non-convex non-smooth regularized learning
problems play essential roles in sparse learning, and have drawn extensive
attentions recently. We design a family of stochastic proximal gradient methods
by applying arbitrary sampling to solve the empirical risk minimization problem
with a non-convex and non-smooth regularizer. These methods draw mini-batches
of training examples according to an arbitrary probability distribution when
computing stochastic gradients. A unified analytic approach is developed to
examine the convergence and computational complexity of these methods, allowing
us to compare the different sampling schemes. We show that the independent
sampling scheme tends to improve performance over the commonly-used uniform
sampling scheme. Our new analysis also derives a tighter bound on convergence
speed for the uniform sampling than the best one available so far. Empirical
evaluations demonstrate that the proposed algorithms converge faster than the
state of the art.
</p>
<a href="http://arxiv.org/abs/2009.06562" target="_blank">arXiv:2009.06562</a> [<a href="http://arxiv.org/pdf/2009.06562" target="_blank">pdf</a>]

<h2>ResNet-like Architecture with Low Hardware Requirements. (arXiv:2009.07190v2 [cs.CV] UPDATED)</h2>
<h3>Elena Limonova, Daniil Alfonso, Dmitry Nikolaev, Vladimir V. Arlazarov</h3>
<p>One of the most computationally intensive parts in modern recognition systems
is an inference of deep neural networks that are used for image classification,
segmentation, enhancement, and recognition. The growing popularity of edge
computing makes us look for ways to reduce its time for mobile and embedded
devices. One way to decrease the neural network inference time is to modify a
neuron model to make it moreefficient for computations on a specific device.
The example ofsuch a model is a bipolar morphological neuron model. The bipolar
morphological neuron is based on the idea of replacing multiplication with
addition and maximum operations. This model has been demonstrated for simple
image classification with LeNet-like architectures [1]. In the paper, we
introduce a bipolar morphological ResNet (BM-ResNet) model obtained from a much
more complex ResNet architecture by converting its layers to bipolar
morphological ones. We apply BM-ResNet to image classification on MNIST and
CIFAR-10 datasets with only a moderate accuracy decrease from 99.3% to 99.1%
and from 85.3% to 85.1%. We also estimate the computational complexity of the
resulting model. We show that for the majority of ResNet layers, the considered
model requires 2.1-2.9 times fewer logic gates for implementation and 15-30%
lower latency.
</p>
<a href="http://arxiv.org/abs/2009.07190" target="_blank">arXiv:2009.07190</a> [<a href="http://arxiv.org/pdf/2009.07190" target="_blank">pdf</a>]

<h2>Face Mask Detection using Transfer Learning of InceptionV3. (arXiv:2009.08369v2 [cs.CV] UPDATED)</h2>
<h3>G. Jignesh Chowdary, Narinder Singh Punn, Sanjay Kumar Sonbhadra, Sonali Agarwal</h3>
<p>The world is facing a huge health crisis due to the rapid transmission of
coronavirus (COVID-19). Several guidelines were issued by the World Health
Organization (WHO) for protection against the spread of coronavirus. According
to WHO, the most effective preventive measure against COVID-19 is wearing a
mask in public places and crowded areas. It is very difficult to monitor people
manually in these areas. In this paper, a transfer learning model is proposed
to automate the process of identifying the people who are not wearing mask. The
proposed model is built by fine-tuning the pre-trained state-of-the-art deep
learning model, InceptionV3. The proposed model is trained and tested on the
Simulated Masked Face Dataset (SMFD). Image augmentation technique is adopted
to address the limited availability of data for better training and testing of
the model. The model outperformed the other recently proposed approaches by
achieving an accuracy of 99.9% during training and 100% during testing.
</p>
<a href="http://arxiv.org/abs/2009.08369" target="_blank">arXiv:2009.08369</a> [<a href="http://arxiv.org/pdf/2009.08369" target="_blank">pdf</a>]

<h2>Domain Generalization for Medical Imaging Classification with Linear-Dependency Regularization. (arXiv:2009.12829v2 [cs.CV] UPDATED)</h2>
<h3>Haoliang Li (1), YuFei Wang (1), Renjie Wan (1), Shiqi Wang (2), Tie-Qiang Li (3), Alex C. Kot (1)</h3>
<p>Recently, we have witnessed great progress in the field of medical imaging
classification by adopting deep neural networks. However, the recent advanced
models still require accessing sufficiently large and representative datasets
for training, which is often unfeasible in clinically realistic environments.
When trained on limited datasets, the deep neural network is lack of
generalization capability, as the trained deep neural network on data within a
certain distribution (e.g. the data captured by a certain device vendor or
patient population) may not be able to generalize to the data with another
distribution.

In this paper, we introduce a simple but effective approach to improve the
generalization capability of deep neural networks in the field of medical
imaging classification. Motivated by the observation that the domain
variability of the medical images is to some extent compact, we propose to
learn a representative feature space through variational encoding with a novel
linear-dependency regularization term to capture the shareable information
among medical data collected from different domains. As a result, the trained
neural network is expected to equip with better generalization capability to
the "unseen" medical data. Experimental results on two challenging medical
imaging classification tasks indicate that our method can achieve better
cross-domain generalization capability compared with state-of-the-art
baselines.
</p>
<a href="http://arxiv.org/abs/2009.12829" target="_blank">arXiv:2009.12829</a> [<a href="http://arxiv.org/pdf/2009.12829" target="_blank">pdf</a>]

<h2>Towards Heterogeneous Multi-Agent Reinforcement Learning with Graph Neural Networks. (arXiv:2009.13161v3 [cs.AI] UPDATED)</h2>
<h3>Douglas De Rizzo Meneghetti, Reinaldo Augusto da Costa Bianchi</h3>
<p>This work proposes a neural network architecture that learns policies for
multiple agent classes in a heterogeneous multi-agent reinforcement setting.
The proposed network uses directed labeled graph representations for states,
encodes feature vectors of different sizes for different entity classes, uses
relational graph convolution layers to model different communication channels
between entity types and learns distinct policies for different agent classes,
sharing parameters wherever possible. Results have shown that specializing the
communication channels between entity classes is a promising step to achieve
higher performance in environments composed of heterogeneous entities.
</p>
<a href="http://arxiv.org/abs/2009.13161" target="_blank">arXiv:2009.13161</a> [<a href="http://arxiv.org/pdf/2009.13161" target="_blank">pdf</a>]

<h2>Measuring Systematic Generalization in Neural Proof Generation with Transformers. (arXiv:2009.14786v2 [cs.LG] UPDATED)</h2>
<h3>Nicolas Gontier, Koustuv Sinha, Siva Reddy, Christopher Pal</h3>
<p>We are interested in understanding how well Transformer language models
(TLMs) can perform reasoning tasks when trained on knowledge encoded in the
form of natural language. We investigate their systematic generalization
abilities on a logical reasoning task in natural language, which involves
reasoning over relationships between entities grounded in first-order logical
proofs. Specifically, we perform soft theorem-proving by leveraging TLMs to
generate natural language proofs. We test the generated proofs for logical
consistency, along with the accuracy of the final inference. We observe
length-generalization issues when evaluated on longer-than-trained sequences.
However, we observe TLMs improve their generalization performance after being
exposed to longer, exhaustive proofs. In addition, we discover that TLMs are
able to generalize better using backward-chaining proofs compared to their
forward-chaining counterparts, while they find it easier to generate forward
chaining proofs. We observe that models that are not trained to generate proofs
are better at generalizing to problems based on longer proofs. This suggests
that Transformers have efficient internal reasoning strategies that are harder
to interpret. These results highlight the systematic generalization behavior of
TLMs in the context of logical reasoning, and we believe this work motivates
deeper inspection of their underlying reasoning strategies.
</p>
<a href="http://arxiv.org/abs/2009.14786" target="_blank">arXiv:2009.14786</a> [<a href="http://arxiv.org/pdf/2009.14786" target="_blank">pdf</a>]

<h2>Large Scale Indexing of Generic Medical Image Data using Unbiased Shallow Keypoints and Deep CNN Features. (arXiv:2010.04283v2 [cs.CV] UPDATED)</h2>
<h3>L. Chauvin, M. Ben Lazreg, J.B. Carluer, W. Wells, M. Toews</h3>
<p>We propose a unified appearance model accounting for traditional shallow
(i.e. 3D SIFT keypoints) and deep (i.e. CNN output layers) image feature
representations, encoding respectively specific, localized neuroanatomical
patterns and rich global information into a single indexing and classification
framework. A novel Bayesian model combines shallow and deep features based on
an assumption of conditional independence and validated by experiments indexing
specific family members and general group categories in 3D MRI neuroimage data
of 1010 subjects from the Human Connectome Project, including twins and
non-twin siblings. A novel domain adaptation strategy is presented,
transforming deep CNN vectors elements into binary class-informative
descriptors. A GPU-based implementation of all processing is provided.
State-of-the-art performance is achieved in large-scale neuroimage indexing,
both in terms of computational complexity, accuracy in identifying family
members and sex classification.
</p>
<a href="http://arxiv.org/abs/2010.04283" target="_blank">arXiv:2010.04283</a> [<a href="http://arxiv.org/pdf/2010.04283" target="_blank">pdf</a>]

<h2>PathoNet: Deep learning assisted evaluation of Ki-67 and tumor infiltrating lymphocytes (TILs) as prognostic factors in breast cancer; A large dataset and baseline. (arXiv:2010.04713v2 [eess.IV] UPDATED)</h2>
<h3>Farzin Negahbani, Rasool Sabzi, Bita Pakniyat Jahromi, Fatemeh Movahedi, Mahsa Kohandel Shirazi, Shayan Majidi, Dena Firouzabadi, Amirreza Dehghanian</h3>
<p>The nuclear protein Ki-67 and Tumor infiltrating lymphocytes (TILs) have been
introduced as prognostic factors in predicting tumor progression and its
treatment response. The value of the Ki-67 index and TILs in approach to
heterogeneous tumors such as Breast cancer (BC), known as the most common
cancer in women worldwide, has been highlighted in the literature. Due to the
indeterminable and subjective nature of Ki-67 as well as TILs scoring,
automated methods using machine learning, specifically approaches based on deep
learning, have attracted attention. Yet, deep learning methods need
considerable annotated data. In the absence of publicly available benchmarks
for BC Ki-67 stained cell detection and further annotated classification of
cells, we propose SHIDC-BC-Ki-67 as a dataset for the aforementioned purpose.
We also introduce a novel pipeline and a backend, namely PathoNet for Ki-67
immunostained cell detection and classification and simultaneous determination
of intratumoral TILs score. Further, we show that despite facing challenges,
our proposed backend, PathoNet, outperforms the state of the art methods
proposed to date in the harmonic mean measure.
</p>
<a href="http://arxiv.org/abs/2010.04713" target="_blank">arXiv:2010.04713</a> [<a href="http://arxiv.org/pdf/2010.04713" target="_blank">pdf</a>]

<h2>BayReL: Bayesian Relational Learning for Multi-omics Data Integration. (arXiv:2010.05895v2 [cs.LG] UPDATED)</h2>
<h3>Ehsan Hajiramezanali, Arman Hasanzadeh, Nick Duffield, Krishna R Narayanan, Xiaoning Qian</h3>
<p>High-throughput molecular profiling technologies have produced
high-dimensional multi-omics data, enabling systematic understanding of living
systems at the genome scale. Studying molecular interactions across different
data types helps reveal signal transduction mechanisms across different classes
of molecules. In this paper, we develop a novel Bayesian representation
learning method that infers the relational interactions across multi-omics data
types. Our method, Bayesian Relational Learning (BayReL) for multi-omics data
integration, takes advantage of a priori known relationships among the same
class of molecules, modeled as a graph at each corresponding view, to learn
view-specific latent variables as well as a multi-partite graph that encodes
the interactions across views. Our experiments on several real-world datasets
demonstrate enhanced performance of BayReL in inferring meaningful interactions
compared to existing baselines.
</p>
<a href="http://arxiv.org/abs/2010.05895" target="_blank">arXiv:2010.05895</a> [<a href="http://arxiv.org/pdf/2010.05895" target="_blank">pdf</a>]

<h2>Experimental Quantum Generative Adversarial Networks for Image Generation. (arXiv:2010.06201v2 [quant-ph] UPDATED)</h2>
<h3>He-Liang Huang, Yuxuan Du, Ming Gong, Youwei Zhao, Yulin Wu, Chaoyue Wang, Shaowei Li, Futian Liang, Jin Lin, Yu Xu, Rui Yang, Tongliang Liu, Min-Hsiu Hsieh, Hui Deng, Hao Rong, Cheng-Zhi Peng, Chao-Yang Lu, Yu-Ao Chen, Dacheng Tao, Xiaobo Zhu, Jian-Wei Pan</h3>
<p>Quantum machine learning is expected to be one of the first practical
applications of near-term quantum devices. Pioneer theoretical works suggest
that quantum generative adversarial networks (GANs) may exhibit a potential
exponential advantage over classical GANs, thus attracting widespread
attention. However, it remains elusive whether quantum GANs implemented on
near-term quantum devices can actually solve real-world learning tasks. Here,
we devise a flexible quantum GAN scheme to narrow this knowledge gap, which
could accomplish image generation with arbitrarily high-dimensional features,
and could also take advantage of quantum superposition to train multiple
examples in parallel. For the first time, we experimentally achieve the
learning and generation of real-world hand-written digit images on a
superconducting quantum processor. Moreover, we utilize a gray-scale bar
dataset to exhibit the competitive performance between quantum GANs and the
classical GANs based on multilayer perceptron and convolutional neural network
architectures, respectively, benchmarked by the Fr\'echet Distance score. Our
work provides guidance for developing advanced quantum generative models on
near-term quantum devices and opens up an avenue for exploring quantum
advantages in various GAN-related learning tasks.
</p>
<a href="http://arxiv.org/abs/2010.06201" target="_blank">arXiv:2010.06201</a> [<a href="http://arxiv.org/pdf/2010.06201" target="_blank">pdf</a>]

<h2>Lightweight IoT Malware Detection Solution Using CNN Classification. (arXiv:2010.06286v2 [cs.CR] UPDATED)</h2>
<h3>Ahmad M.N. Zaza, Suleiman K. Kharroub, Khalid Abualsaud</h3>
<p>Internet of Things (IoT) is becoming more frequently used in more
applications as the number of connected devices is in a rapid increase. More
connected devices result in bigger challenges in terms of scalability,
maintainability and most importantly security especially when it comes to 5G
networks. The security aspect of IoT devices is an infant field, which is why
it is our focus in this paper. Multiple IoT device manufacturers do not
consider securing the devices they produce for different reasons like cost
reduction or to avoid using energy-harvesting components. Such potentially
malicious devices might be exploited by the adversary to do multiple harmful
attacks. Therefore, we developed a system that can recognize malicious behavior
of a specific IoT node on the network. Through convolutional neural network and
monitoring, we were able to provide malware detection for IoT using a central
node that can be installed within the network. The achievement shows how such
models can be generalized and applied easily to any network while clearing out
any stigma regarding deep learning techniques.
</p>
<a href="http://arxiv.org/abs/2010.06286" target="_blank">arXiv:2010.06286</a> [<a href="http://arxiv.org/pdf/2010.06286" target="_blank">pdf</a>]

<h2>Explain2Attack: Text Adversarial Attacks via Cross-Domain Interpretability. (arXiv:2010.06812v3 [cs.LG] UPDATED)</h2>
<h3>Mahmoud Hossam, Trung Le, He Zhao, Dinh Phung</h3>
<p>Training robust deep learning models for down-stream tasks is a critical
challenge. Research has shown that down-stream models can be easily fooled with
adversarial inputs that look like the training data, but slightly perturbed, in
a way imperceptible to humans. Understanding the behavior of natural language
models under these attacks is crucial to better defend these models against
such attacks. In the black-box attack setting, where no access to model
parameters is available, the attacker can only query the output information
from the targeted model to craft a successful attack. Current black-box
state-of-the-art models are costly in both computational complexity and number
of queries needed to craft successful adversarial examples. For real world
scenarios, the number of queries is critical, where less queries are desired to
avoid suspicion towards an attacking agent. In this paper, we propose
Explain2Attack, a black-box adversarial attack on text classification task.
Instead of searching for important words to be perturbed by querying the target
model, Explain2Attack employs an interpretable substitute model from a similar
domain to learn word importance scores. We show that our framework either
achieves or out-performs attack rates of the state-of-the-art models, yet with
lower queries cost and higher efficiency.
</p>
<a href="http://arxiv.org/abs/2010.06812" target="_blank">arXiv:2010.06812</a> [<a href="http://arxiv.org/pdf/2010.06812" target="_blank">pdf</a>]

<h2>Modeling Protagonist Emotions for Emotion-Aware Storytelling. (arXiv:2010.06822v2 [cs.CL] UPDATED)</h2>
<h3>Faeze Brahman, Snigdha Chaturvedi</h3>
<p>Emotions and their evolution play a central role in creating a captivating
story. In this paper, we present the first study on modeling the emotional
trajectory of the protagonist in neural storytelling. We design methods that
generate stories that adhere to given story titles and desired emotion arcs for
the protagonist. Our models include Emotion Supervision (EmoSup) and two
Emotion-Reinforced (EmoRL) models. The EmoRL models use special rewards
designed to regularize the story generation process through reinforcement
learning. Our automatic and manual evaluations demonstrate that these models
are significantly better at generating stories that follow the desired emotion
arcs compared to baseline methods, without sacrificing story quality.
</p>
<a href="http://arxiv.org/abs/2010.06822" target="_blank">arXiv:2010.06822</a> [<a href="http://arxiv.org/pdf/2010.06822" target="_blank">pdf</a>]

<h2>AMPA-Net: Optimization-Inspired Attention Neural Network for Deep Compressed Sensing. (arXiv:2010.06907v3 [cs.CV] UPDATED)</h2>
<h3>Nanyu Li, Charles C. Zhou</h3>
<p>Compressed sensing (CS) is a challenging problem in image processing due to
reconstructing an almost complete image from a limited measurement. To achieve
fast and accurate CS reconstruction, we synthesize the advantages of two
well-known methods (neural network and optimization algorithm) to propose a
novel optimization inspired neural network which dubbed AMP-Net. AMP-Net
realizes the fusion of the Approximate Message Passing (AMP) algorithm and
neural network. All of its parameters are learned automatically. Furthermore,
we propose an AMPA-Net which uses three attention networks to improve the
representation ability of AMP-Net. Finally, We demonstrate the effectiveness of
AMP-Net and AMPA-Net on four CS reconstruction benchmark data sets.
</p>
<a href="http://arxiv.org/abs/2010.06907" target="_blank">arXiv:2010.06907</a> [<a href="http://arxiv.org/pdf/2010.06907" target="_blank">pdf</a>]

<h2>Solar Coronal Magnetic Field Extrapolation from Synchronic Data with AI-generated Farside. (arXiv:2010.07553v2 [astro-ph.SR] UPDATED)</h2>
<h3>Hyun-Jin Jeong, Yong-Jae Moon, Eunsu Park, Harim Lee</h3>
<p>Solar magnetic fields play a key role in understanding the nature of the
coronal phenomena. Global coronal magnetic fields are usually extrapolated from
photospheric fields for which farside data were taken about two weeks ago when
it was at the frontside. For the first time we have constructed the
extrapolations of global magnetic fields using frontside and AI-generated
farside magnetic fields at a near-real time basis. We generate the farside
magnetograms from three channel farside observations of Solar Terrestrial
Relations Observatory (STEREO) $-$Ahead (A) and $-$Behind (B) by our deep
learning model trained with frontside Solar Dynamics Observatory (SDO) EUV
images and magnetograms. For frontside testing data sets, we demonstrate that
the generated magnetic field distributions are consistent with the real ones;
not only active regions (ARs), but also quiet regions of the Sun. We make
global magnetic field synchronic maps in which conventional farside data are
replaced by farside ones generated by our model. The synchronic maps show much
better not only the appearance of ARs but also the disappearance of others on
the solar surface than before. We use these synchronized magnetic data to
extrapolate the global coronal fields using Potential Field Source Surface
(PFSS) model. We show that our results are much more consistent with coronal
observations than those of the conventional method in view of solar active
regions and coronal holes. We present several positive prospects of our new
methodology for the study of solar corona, heliosphere, and space weather.
</p>
<a href="http://arxiv.org/abs/2010.07553" target="_blank">arXiv:2010.07553</a> [<a href="http://arxiv.org/pdf/2010.07553" target="_blank">pdf</a>]

<h2>Workload-Aware Systems and Interfaces for Cognitive Augmentation. (arXiv:2010.07703v2 [cs.HC] UPDATED)</h2>
<h3>Thomas Kosch</h3>
<p>In today's society, our cognition is constantly influenced by information
intake, attention switching, and task interruptions. This increases the
difficulty of a given task, adding to the existing workload and leading to
compromised cognitive performances. The human body expresses the use of
cognitive resources through physiological responses when confronted with a
plethora of cognitive workload. This temporarily mobilizes additional resources
to deal with the workload at the cost of accelerated mental exhaustion. We
predict that recent developments in physiological sensing will increasingly
create user interfaces that are aware of the user's cognitive capacities, hence
able to intervene when high or low states of cognitive workload are detected.
Subsequently, we investigate suitable feedback modalities in a user-centric
design process which are desirable for cognitive assistance. We then
investigate different physiological sensing modalities to enable suitable
real-time assessments of cognitive workload. We provide evidence that the human
brain and eye gaze are sensitive to fluctuations in cognitive resting states.
We show that electroencephalography and eye tracking are reliable modalities to
assess mental workload during user interface operation. In the end, we present
applications that regulate cognitive workload in home and work setting,
investigate how cognitive workload can be visualized to the user, and show how
cognitive workload measurements can be used to predict the efficiency of
information intake through reading interfaces. Finally, we present our vision
of future workload-aware interfaces. Previous interfaces were limited in their
ability to utilize cognitive workload for user interaction. Together with the
collected data sets, this thesis paves the way for methodical and technical
tools that integrate workload-awareness as a factor for context-aware systems.
</p>
<a href="http://arxiv.org/abs/2010.07703" target="_blank">arXiv:2010.07703</a> [<a href="http://arxiv.org/pdf/2010.07703" target="_blank">pdf</a>]

<h2>Analysis of Twitter and YouTube during USelections 2020. (arXiv:2010.08183v2 [cs.SI] UPDATED)</h2>
<h3>Alexander Shevtsov, Maria Oikonomidou, Despoina Antonakaki, Polyvios Pratikakis, Sotiris Ioannidis</h3>
<p>The upcoming November 2020 presidential elections in the United States have
caused extensive discussions on social media. A part of the content on US
elections is organic, coming from users discussing their opinions of the
candidates, political positions, or relevant content presented on television.
Another significant part of the content generated originates from organized
campaigns, both official and by astroturfing.

In this study, we obtain approximately 7.5M tweets, containing 1.4M users,
based on prevalent hashtags related to US election 2020, as well as the related
YouTube links, contained in the Twitter dataset, likes, dislikes and comments
of the videos and conduct volume, sentiment and graph analysis on the
communities formed. Particularly, we study the daily traffic per prevalent
hashtags and show the evolution of the retweet graph from July to September
2020, highlighting the two main entities ('Biden' and 'Trump') contained in our
dataset. The results of sentiment analysis indicate that 45.7 express positive
sentiment towards Trump in Twitter and 33.8 positive sentiment towards Biden,
while 14.55 of users express positive sentiment in YouTube metadata gathered
towards Trump and 8.7 positive sentiment towards Biden.
</p>
<a href="http://arxiv.org/abs/2010.08183" target="_blank">arXiv:2010.08183</a> [<a href="http://arxiv.org/pdf/2010.08183" target="_blank">pdf</a>]

<h2>Deep Learning Head Model for Real-time Estimation of Entire Brain Deformation in Concussion. (arXiv:2010.08527v2 [q-bio.TO] UPDATED)</h2>
<h3>Xianghao Zhan, Yuzhe Liu, Samuel J. Raymond, Hossein Vahid Alizadeh, August G. Domel, Olivier Gevaert, Michael Zeineh, Gerald Grant, David B. Camarillo</h3>
<p>Objective: Many recent studies have suggested that brain deformation
resulting from a head impact is linked to the corresponding clinical outcome,
such as mild traumatic brain injury (mTBI). Even though several finite element
(FE) head models have been developed and validated to calculate brain
deformation based on impact kinematics, the clinical application of these FE
head models is limited due to the time-consuming nature of FE simulations. This
work aims to accelerate the process of brain deformation calculation and thus
improve the potential for clinical applications. Methods: We propose a deep
learning head model with a five-layer deep neural network and feature
engineering, and trained and tested the model on 1803 total head impacts from a
combination of head model simulations and on-field college football and mixed
martial arts impacts. Results: The proposed deep learning head model can
calculate the maximum principal strain for every element in the entire brain in
less than 0.001s (with an average root mean squared error of 0.025, and with a
standard deviation of 0.002 over twenty repeats with random data partition and
model initialization). The contributions of various features to the predictive
power of the model were investigated, and it was noted that the features based
on angular acceleration were found to be more predictive than the features
based on angular velocity. Conclusion: Trained using the dataset of 1803 head
impacts, this model can be applied to various sports in the calculation of
brain strain with accuracy, and its applicability can even further be extended
by incorporating data from other types of head impacts. Significance: In
addition to the potential clinical application in real-time brain deformation
monitoring, this model will help researchers estimate the brain strain from a
large number of head impacts more efficiently than using FE models.
</p>
<a href="http://arxiv.org/abs/2010.08527" target="_blank">arXiv:2010.08527</a> [<a href="http://arxiv.org/pdf/2010.08527" target="_blank">pdf</a>]

<h2>Adaptive Dense-to-Sparse Paradigm for Pruning Online Recommendation System with Non-Stationary Data. (arXiv:2010.08655v2 [cs.LG] UPDATED)</h2>
<h3>Mao Ye, Dhruv Choudhary, Jiecao Yu, Ellie Wen, Zeliang Chen, Jiyan Yang, Jongsoo Park, Qiang Liu, Arun Kejariwal</h3>
<p>Large scale deep learning provides a tremendous opportunity to improve the
quality of content recommendation systems by employing both wider and deeper
models, but this comes at great infrastructural cost and carbon footprint in
modern data centers. Pruning is an effective technique that reduces both memory
and compute demand for model inference. However, pruning for online
recommendation systems is challenging due to the continuous data distribution
shift (a.k.a non-stationary data). Although incremental training on the full
model is able to adapt to the non-stationary data, directly applying it on the
pruned model leads to accuracy loss. This is because the sparsity pattern after
pruning requires adjustment to learn new patterns. To the best of our
knowledge, this is the first work to provide in-depth analysis and discussion
of applying pruning to online recommendation systems with non-stationary data
distribution. Overall, this work makes the following contributions: 1) We
present an adaptive dense to sparse paradigm equipped with a novel pruning
algorithm for pruning a large scale recommendation system with non-stationary
data distribution; 2) We design the pruning algorithm to automatically learn
the sparsity across layers to avoid repeating hand-tuning, which is critical
for pruning the heterogeneous architectures of recommendation systems trained
with non-stationary data.
</p>
<a href="http://arxiv.org/abs/2010.08655" target="_blank">arXiv:2010.08655</a> [<a href="http://arxiv.org/pdf/2010.08655" target="_blank">pdf</a>]

<h2>TensorFlow Lite Micro: Embedded Machine Learning on TinyML Systems. (arXiv:2010.08678v2 [cs.LG] UPDATED)</h2>
<h3>Robert David, Jared Duke, Advait Jain, Vijay Janapa Reddi, Nat Jeffries, Jian Li, Nick Kreeger, Ian Nappier, Meghna Natraj, Shlomi Regev, Rocky Rhodes, Tiezhen Wang, Pete Warden</h3>
<p>Deep learning inference on embedded devices is a burgeoning field with myriad
applications because tiny embedded devices are omnipresent. But we must
overcome major challenges before we can benefit from this opportunity. Embedded
processors are severely resource constrained. Their nearest mobile counterparts
exhibit at least a 100---1,000x difference in compute capability, memory
availability, and power consumption. As a result, the machine-learning (ML)
models and associated ML inference framework must not only execute efficiently
but also operate in a few kilobytes of memory. Also, the embedded devices'
ecosystem is heavily fragmented. To maximize efficiency, system vendors often
omit many features that commonly appear in mainstream systems, including
dynamic memory allocation and virtual memory, that allow for cross-platform
interoperability. The hardware comes in many flavors (e.g., instruction-set
architecture and FPU support, or lack thereof). We introduce TensorFlow Lite
Micro (TF Micro), an open-source ML inference framework for running
deep-learning models on embedded systems. TF Micro tackles the efficiency
requirements imposed by embedded-system resource constraints and the
fragmentation challenges that make cross-platform interoperability nearly
impossible. The framework adopts a unique interpreter-based approach that
provides flexibility while overcoming these challenges. This paper explains the
design decisions behind TF Micro and describes its implementation details.
Also, we present an evaluation to demonstrate its low resource requirement and
minimal run-time performance overhead.
</p>
<a href="http://arxiv.org/abs/2010.08678" target="_blank">arXiv:2010.08678</a> [<a href="http://arxiv.org/pdf/2010.08678" target="_blank">pdf</a>]

<h2>Discriminability of Single-Layer Graph Neural Networks. (arXiv:2010.08847v2 [eess.SP] UPDATED)</h2>
<h3>Samuel Pfrommer, Fernando Gama, Alejandro Ribeiro</h3>
<p>Network data can be conveniently modeled as a graph signal, where data values
are assigned to the nodes of a graph describing the underlying network
topology. Successful learning from network data requires methods that
effectively exploit this graph structure. Graph neural networks (GNNs) provide
one such method and have exhibited promising performance on a wide range of
problems. Understanding why GNNs work is of paramount importance, particularly
in applications involving physical networks. We focus on the property of
discriminability and establish conditions under which the inclusion of
pointwise nonlinearities to a stable graph filter bank leads to an increased
discriminative capacity for high-eigenvalue content. We define a notion of
discriminability tied to the stability of the architecture, show that GNNs are
at least as discriminative as linear graph filter banks, and characterize the
signals that cannot be discriminated by either.
</p>
<a href="http://arxiv.org/abs/2010.08847" target="_blank">arXiv:2010.08847</a> [<a href="http://arxiv.org/pdf/2010.08847" target="_blank">pdf</a>]

<h2>JSRT: James-Stein Regression Tree. (arXiv:2010.09022v2 [cs.LG] UPDATED)</h2>
<h3>Xingchun Xiang, Qingtao Tang, Huaixuan Zhang, Tao Dai, Jiawei Li, Shu-Tao Xia</h3>
<p>Regression tree (RT) has been widely used in machine learning and data mining
community. Given a target data for prediction, a regression tree is first
constructed based on a training dataset before making prediction for each leaf
node. In practice, the performance of RT relies heavily on the local mean of
samples from an individual node during the tree construction/prediction stage,
while neglecting the global information from different nodes, which also plays
an important role. To address this issue, we propose a novel regression tree,
named James-Stein Regression Tree (JSRT) by considering global information from
different nodes. Specifically, we incorporate the global mean information based
on James-Stein estimator from different nodes during the construction/predicton
stage. Besides, we analyze the generalization error of our method under the
mean square error (MSE) metric. Extensive experiments on public benchmark
datasets verify the effectiveness and efficiency of our method, and demonstrate
the superiority of our method over other RT prediction methods.
</p>
<a href="http://arxiv.org/abs/2010.09022" target="_blank">arXiv:2010.09022</a> [<a href="http://arxiv.org/pdf/2010.09022" target="_blank">pdf</a>]

<h2>Online-to-Offline Advertisements as Field Experiments. (arXiv:2010.09121v2 [cs.LG] UPDATED)</h2>
<h3>Akira Matsui, Daisuke Moriwaki</h3>
<p>Online advertisements have become one of today's most widely used tools for
enhancing businesses partly because of their compatibility with A/B testing.
A/B testing allows sellers to find effective advertisement strategies such as
ad creatives or segmentations. Even though several studies propose a technique
to maximize the effect of an advertisement, there is insufficient comprehension
of the customers' offline shopping behavior invited by the online
advertisements. Herein, we study the difference in offline behavior between
customers who received online advertisements and regular customers (i.e., the
customers visits the target shop voluntary), and the duration of this
difference. We analyzed approximately three thousand users' offline behavior
with their 23.5 million location records through 31 A/B testings. We first
demonstrate the externality that customers with advertisements traverse larger
areas than those without advertisements, and this spatial difference lasts
several days after their shopping day. We then find a long-run effect of this
externality of advertising that a certain portion of the customers invited to
the offline shops revisit these shops. Finally, based on this revisit effect
findings, we utilize a causal machine learning model to propose a marketing
strategy to maximize the revisit ratio. Our results suggest that advertisements
draw customers who have different behavior traits from regular customers. This
study's findings demonstrate that a simple analysis may underrate the effects
of advertisements on businesses, and an analysis considering externality can
attract potentially valuable customers.
</p>
<a href="http://arxiv.org/abs/2010.09121" target="_blank">arXiv:2010.09121</a> [<a href="http://arxiv.org/pdf/2010.09121" target="_blank">pdf</a>]

<h2>Closed-Loop Neural Interfaces with Embedded Machine Learning. (arXiv:2010.09457v2 [cs.AR] UPDATED)</h2>
<h3>Bingzhao Zhu, Uisub Shin, Mahsa Shoaran</h3>
<p>Neural interfaces capable of multi-site electrical recording, on-site signal
classification, and closed-loop therapy are critical for the diagnosis and
treatment of neurological disorders. However, deploying machine learning
algorithms on low-power neural devices is challenging, given the tight
constraints on computational and memory resources for such devices. In this
paper, we review the recent developments in embedding machine learning in
neural interfaces, with a focus on design trade-offs and hardware efficiency.
We also present our optimized tree-based model for low-power and
memory-efficient classification of neural signal in brain implants. Using
energy-aware learning and model compression, we show that the proposed oblique
trees can outperform conventional machine learning models in applications such
as seizure or tremor detection and motor decoding.
</p>
<a href="http://arxiv.org/abs/2010.09457" target="_blank">arXiv:2010.09457</a> [<a href="http://arxiv.org/pdf/2010.09457" target="_blank">pdf</a>]

<h2>Federated Bayesian Optimization via Thompson Sampling. (arXiv:2010.10154v2 [cs.LG] UPDATED)</h2>
<h3>Zhongxiang Dai, Kian Hsiang Low, Patrick Jaillet</h3>
<p>Bayesian optimization (BO) is a prominent approach to optimizing
expensive-to-evaluate black-box functions. The massive computational capability
of edge devices such as mobile phones, coupled with privacy concerns, has led
to a surging interest in federated learning (FL) which focuses on collaborative
training of deep neural networks (DNNs) via first-order optimization
techniques. However, some common machine learning tasks such as hyperparameter
tuning of DNNs lack access to gradients and thus require zeroth-order/black-box
optimization. This hints at the possibility of extending BO to the FL setting
(FBO) for agents to collaborate in these black-box optimization tasks. This
paper presents federated Thompson sampling (FTS) which overcomes a number of
key challenges of FBO and FL in a principled way: We (a) use random Fourier
features to approximate the Gaussian process surrogate model used in BO, which
naturally produces the parameters to be exchanged between agents, (b) design
FTS based on Thompson sampling, which significantly reduces the number of
parameters to be exchanged, and (c) provide a theoretical convergence guarantee
that is robust against heterogeneous agents, which is a major challenge in FL
and FBO. We empirically demonstrate the effectiveness of FTS in terms of
communication efficiency, computational efficiency, and practical performance.
</p>
<a href="http://arxiv.org/abs/2010.10154" target="_blank">arXiv:2010.10154</a> [<a href="http://arxiv.org/pdf/2010.10154" target="_blank">pdf</a>]

<h2>Bootleg: Chasing the Tail with Self-Supervised Named Entity Disambiguation. (arXiv:2010.10363v2 [cs.CL] UPDATED)</h2>
<h3>Laurel Orr, Megan Leszczynski, Simran Arora, Sen Wu, Neel Guha, Xiao Ling, Christopher Re</h3>
<p>A challenge for named entity disambiguation (NED), the task of mapping
textual mentions to entities in a knowledge base, is how to disambiguate
entities that appear rarely in the training data, termed tail entities. Humans
use subtle reasoning patterns based on knowledge of entity facts, relations,
and types to disambiguate unfamiliar entities. Inspired by these patterns, we
introduce Bootleg, a self-supervised NED system that is explicitly grounded in
reasoning patterns for disambiguation. We define core reasoning patterns for
disambiguation, create a learning procedure to encourage the self-supervised
model to learn the patterns, and show how to use weak supervision to enhance
the signals in the training data. Encoding the reasoning patterns in a simple
Transformer architecture, Bootleg meets or exceeds state-of-the-art on three
NED benchmarks. We further show that the learned representations from Bootleg
successfully transfer to other non-disambiguation tasks that require
entity-based knowledge: we set a new state-of-the-art in the popular TACRED
relation extraction task by 1.0 F1 points and demonstrate up to 8% performance
lift in highly optimized production search and assistant tasks at a major
technology company
</p>
<a href="http://arxiv.org/abs/2010.10363" target="_blank">arXiv:2010.10363</a> [<a href="http://arxiv.org/pdf/2010.10363" target="_blank">pdf</a>]

<h2>Transfer Learning in Large-scale Gaussian Graphical Models with False Discovery Rate Control. (arXiv:2010.11037v1 [stat.ME])</h2>
<h3>Sai Li, T. Tony Cai, Hongzhe Li</h3>
<p>Transfer learning for high-dimensional Gaussian graphical models (GGMs) is
studied with the goal of estimating the target GGM by utilizing the data from
similar and related auxiliary studies. The similarity between the target graph
and each auxiliary graph is characterized by the sparsity of a divergence
matrix. An estimation algorithm, Trans-CLIME, is proposed and shown to attain a
faster convergence rate than the minimax rate in the single study setting.
Furthermore, a debiased Trans-CLIME estimator is introduced and shown to be
element-wise asymptotically normal. It is used to construct a multiple testing
procedure for edge detection with false discovery rate control. The proposed
estimation and multiple testing procedures demonstrate superior numerical
performance in simulations and are applied to infer the gene networks in a
target brain tissue by leveraging the gene expressions from multiple other
brain tissues. A significant decrease in prediction errors and a significant
increase in power for link detection are observed.
</p>
<a href="http://arxiv.org/abs/2010.11037" target="_blank">arXiv:2010.11037</a> [<a href="http://arxiv.org/pdf/2010.11037" target="_blank">pdf</a>]

<h2>Dirichlet-tree multinomial mixtures for clustering microbiome compositions. (arXiv:2008.00400v2 [stat.ME] UPDATED)</h2>
<h3>Jialiang Mao, Li Ma</h3>
<p>Studying the human microbiome has gained substantial interest in recent
years, and a common task in the analysis of these data is to cluster microbiome
compositions into subtypes. This subdivision of samples into subgroups serves
as an intermediary step in achieving personalized diagnosis and treatment. In
applying existing clustering methods to modern microbiome studies including the
American Gut Project (AGP) data, we found that this seemingly standard task,
however, is very challenging in the microbiome composition context due to
several key features of such data. Standard distance-based clustering
algorithms generally do not produce reliable results as they do not take into
account the heterogeneity of the cross-sample variability among the bacterial
taxa, while existing model-based approaches do not allow sufficient flexibility
for the identification of complex within-cluster variation from cross-cluster
variation. Direct applications of such methods generally lead to overly
dispersed clusters in the AGP data and such phenomenon is common for other
microbiome data. To overcome these challenges, we introduce Dirichlet-tree
multinomial mixtures (DTMM) as a Bayesian generative model for clustering
amplicon sequencing data in microbiome studies. DTMM models the microbiome
population with a mixture of Dirichlet-tree kernels that utilizes the
phylogenetic tree to offer a more flexible covariance structure in
characterizing within-cluster variation, and it provides a means for
identifying a subset of signature taxa that distinguish the clusters. We
perform extensive simulation studies to evaluate the performance of DTMM and
compare it to state-of-the-art model-based and distance-based clustering
methods in the microbiome context. Finally, we report a case study on the fecal
data from the AGP to identify compositional clusters among individuals with
inflammatory bowel disease and diabetes.
</p>
<a href="http://arxiv.org/abs/2008.00400" target="_blank">arXiv:2008.00400</a> [<a href="http://arxiv.org/pdf/2008.00400" target="_blank">pdf</a>]

