---
title: Latest Deep Learning Papers
date: 2020-10-18 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Semi-supervised NMF Models for Topic Modeling in Learning Tasks. (arXiv:2010.07956v1 [cs.LG])</h2>
<h3>Jamie Haddock, Lara Kassab, Sixian Li, Alona Kryshchenko, Rachel Grotheer, Elena Sizikova, Chuntian Wang, Thomas Merkh, R. W. M. A. Madushani, Miju Ahn, Deanna Needell, Kathryn Leonard</h3>
<p>We propose several new models for semi-supervised nonnegative matrix
factorization (SSNMF) and provide motivation for SSNMF models as maximum
likelihood estimators given specific distributions of uncertainty. We present
multiplicative updates training methods for each new model, and demonstrate the
application of these models to classification, although they are flexible to
other supervised learning tasks. We illustrate the promise of these models and
training methods on both synthetic and real data, and achieve high
classification accuracy on the 20 Newsgroups dataset.
</p>
<a href="http://arxiv.org/abs/2010.07956" target="_blank">arXiv:2010.07956</a> [<a href="http://arxiv.org/pdf/2010.07956" target="_blank">pdf</a>]

<h2>Nilpotent Decomposition in Integral Group Rings. (arXiv:2010.07957v1 [math.RA])</h2>
<h3>Eric Jespers, Wei-Liang Sun</h3>
<p>A finite group $G$ is said to have the nilpotent decomposition property (ND)
if for every nilpotent element $\alpha$ of the integral group ring
$\mathbb{Z}[G]$ one has that $\alpha e$ also belong to $\mathbb{Z}[G]$, for
every primitive central idempotent $e$ of the rational group algebra
$\mathbb{Q}[G]$. Results of Hales, Passi and Wilson, Liu and Passman show that
this property is fundamental in the investigations of the multiplicative Jordan
decomposition of integral group rings. If $G$ and all its subgroups have ND
then Liu and Passman showed that $G$ has property SSN, that is, for subgroups
$H$, $Y$ and $N$ of $G$, if $N\lhd H $ and $Y\subseteq H$ then $N\subseteq Y$
or $YN$ is normal in $H$; and such groups have been described. In this article,
we study the nilpotent decomposition property in integral group rings and we
classify finite SSN groups $G$ such that the rational group algebra
$\mathbb{Q}[G]$ has only one Wedderburn component which is not a division ring.
</p>
<a href="http://arxiv.org/abs/2010.07957" target="_blank">arXiv:2010.07957</a> [<a href="http://arxiv.org/pdf/2010.07957" target="_blank">pdf</a>]

<h2>Provably Faster Algorithms for Bilevel Optimization and Applications to Meta-Learning. (arXiv:2010.07962v1 [cs.LG])</h2>
<h3>Kaiyi Ji, Junjie Yang, Yingbin Liang</h3>
<p>Bilevel optimization has arisen as a powerful tool for many machine learning
problems such as meta-learning, hyper-parameter optimization, reinforcement
learning, etc. In this paper, we investigate the nonconvex-strongly-convex
bilevel optimization problem, and propose two novel algorithms named deterBiO
and stocBiO respectively for the deterministic and stochastic settings. At the
core design of deterBiO is the construction of a low-cost and easy-to-implement
hyper-gradient estimator via a simple back-propagation. In addition, stocBiO
updates with the mini-batch data sampling rather than the existing
single-sample schemes, where a sample-efficient Hessian inverse estimator is
proposed. We provide the finite-time convergence guarantee for both algorithms,
and show that they outperform the best known computational complexities
orderwisely with respect to the condition number $\kappa$ and/or the target
accuracy $\epsilon$. We further demonstrate the superior efficiency of the
proposed algorithms by the experiments on meta-learning and hyper-parameter
optimization.
</p>
<a href="http://arxiv.org/abs/2010.07962" target="_blank">arXiv:2010.07962</a> [<a href="http://arxiv.org/pdf/2010.07962" target="_blank">pdf</a>]

<h2>Data-Driven Stochastic Reachability Using Hilbert Space Embeddings. (arXiv:2010.08036v1 [math.OC])</h2>
<h3>Adam J. Thorpe, Kendric R. Ortiz, Meeko M. K. Oishi</h3>
<p>We compute finite sample bounds for approximations of the solution to
stochastic reachability problems computed using kernel distribution embeddings,
a non-parametric machine learning technique. Our approach enables assurances of
safety from observed data, through construction of probabilistic violation
bounds on the computed stochastic reachability probability. By embedding the
stochastic kernel of a Markov control process in a reproducing kernel Hilbert
space, we can compute the safety probabilities for systems with arbitrary
disturbances as simple matrix operations and inner products. We present finite
sample bounds for the approximation using elements from statistical learning
theory. We numerically evaluate the approach, and demonstrate its efficacy on
neural net-controlled pendulum system.
</p>
<a href="http://arxiv.org/abs/2010.08036" target="_blank">arXiv:2010.08036</a> [<a href="http://arxiv.org/pdf/2010.08036" target="_blank">pdf</a>]

<h2>Consistent Feature Selection for Analytic Deep Neural Networks. (arXiv:2010.08097v1 [cs.LG])</h2>
<h3>Vu Dinh, Lam Si Tung Ho</h3>
<p>One of the most important steps toward interpretability and explainability of
neural network models is feature selection, which aims to identify the subset
of relevant features. Theoretical results in the field have mostly focused on
the prediction aspect of the problem with virtually no work on feature
selection consistency for deep neural networks due to the model's severe
nonlinearity and unidentifiability. This lack of theoretical foundation casts
doubt on the applicability of deep learning to contexts where correct
interpretations of the features play a central role.

In this work, we investigate the problem of feature selection for analytic
deep networks. We prove that for a wide class of networks, including deep
feed-forward neural networks, convolutional neural networks, and a major
sub-class of residual neural networks, the Adaptive Group Lasso selection
procedure with Group Lasso as the base estimator is selection-consistent. The
work provides further evidence that Group Lasso might be inefficient for
feature selection with neural networks and advocates the use of Adaptive Group
Lasso over the popular Group Lasso.
</p>
<a href="http://arxiv.org/abs/2010.08097" target="_blank">arXiv:2010.08097</a> [<a href="http://arxiv.org/pdf/2010.08097" target="_blank">pdf</a>]

<h2>The Deep Bootstrap: Good Online Learners are Good Offline Generalizers. (arXiv:2010.08127v1 [cs.LG])</h2>
<h3>Preetum Nakkiran, Behnam Neyshabur, Hanie Sedghi</h3>
<p>We propose a new framework for reasoning about generalization in deep
learning. The core idea is to couple the Real World, where optimizers take
stochastic gradient steps on the empirical loss, to an Ideal World, where
optimizers take steps on the population loss. This leads to an alternate
decomposition of test error into: (1) the Ideal World test error plus (2) the
gap between the two worlds. If the gap (2) is universally small, this reduces
the problem of generalization in offline learning to the problem of
optimization in online learning. We then give empirical evidence that this gap
between worlds can be small in realistic deep learning settings, in particular
supervised image classification. For example, CNNs generalize better than MLPs
on image distributions in the Real World, but this is "because" they optimize
faster on the population loss in the Ideal World. This suggests our framework
is a useful tool for understanding generalization in deep learning, and lays a
foundation for future research in the area.
</p>
<a href="http://arxiv.org/abs/2010.08127" target="_blank">arXiv:2010.08127</a> [<a href="http://arxiv.org/pdf/2010.08127" target="_blank">pdf</a>]

<h2>Consistency of archetypal analysis. (arXiv:2010.08148v1 [math.ST])</h2>
<h3>Braxton Osting, Dong Wang, Yiming Xu, Dominique Zosso</h3>
<p>Archetypal analysis is an unsupervised learning method that uses a convex
polytope to summarize multivariate data. For fixed $k$, the method finds a
convex polytope with $k$ vertices, called archetype points, such that the
polytope is contained in the convex hull of the data and the mean squared
distance between the data and the polytope is minimal. In this paper, we prove
a consistency result that shows if the data is independently sampled from a
probability measure with bounded support, then the archetype points converge to
a solution of the continuum version of the problem, of which we identify and
establish several properties. We also obtain the convergence rate of the
optimal objective values under appropriate assumptions on the distribution. If
the data is independently sampled from a distribution with unbounded support,
we also prove a consistency result for a modified method that penalizes the
dispersion of the archetype points. Our analysis is supported by detailed
computational experiments of the archetype points for data sampled from the
uniform distribution in a disk, the normal distribution, an annular
distribution, and a Gaussian mixture model.
</p>
<a href="http://arxiv.org/abs/2010.08148" target="_blank">arXiv:2010.08148</a> [<a href="http://arxiv.org/pdf/2010.08148" target="_blank">pdf</a>]

<h2>Projection-free Online Learning over Strongly Convex Sets. (arXiv:2010.08177v1 [cs.LG])</h2>
<h3>Yuanyu Wan, Lijun Zhang</h3>
<p>To efficiently solve online problems with complicated constraints,
projection-free algorithms including online frank-wolfe (OFW) and its variants
have received significant interest recently. However, in the general case,
existing projection-free algorithms only achieved the regret bound of
$O(T^{3/4})$, which is worse than the regret of projection-based algorithms,
where $T$ is the number of decision rounds. In this paper, we study the special
case of online learning over strongly convex sets, for which we first prove
that OFW enjoys a better regret bound of $O(T^{2/3})$ for general convex
losses. The key idea is to refine the decaying step-size in the original OFW by
a simple line search rule. Furthermore, for strongly convex losses, we propose
a strongly convex variant of OFW by redefining the surrogate loss function in
OFW. We show that it achieves a regret bound of $O(T^{2/3})$ over general
convex sets and a better regret bound of $O(\sqrt{T})$ over strongly convex
sets.
</p>
<a href="http://arxiv.org/abs/2010.08177" target="_blank">arXiv:2010.08177</a> [<a href="http://arxiv.org/pdf/2010.08177" target="_blank">pdf</a>]

<h2>Stochastic Models of Neural Synaptic Plasticity. (arXiv:2010.08195v1 [q-bio.NC])</h2>
<h3>Philippe Robert, Gaetan Vignoud</h3>
<p>In neuroscience, learning and memory are usually associated to long-term
changes of connection strength between neurons. In this context, synaptic
plasticity refers to the set of mechanisms driving the dynamics of neuronal
connections, called synapses and represented by a scalar value, the synaptic
weight. A Spike-Timing Dependent Plasticity (STDP) rule is a biologically-based
model representing the time evolution of the synaptic weight as a functional of
the past spiking activity of adjacent neurons.

If numerous models of neuronal cells have been proposed in the mathematical
literature, few of them include a variable for the time-varying strength of the
connection. In this article, a new, general, mathematical framework to study
the phenomenon of synaptic plasticity associated to STDP rules is introduced. A
system composed of two neuronal cells connected by a single synapse is
investigated and a stochastic process describing its dynamical behavior is
presented and analyzed. The notion of plasticity kernel is introduced as a key
component of plastic neural networks models. We show that a large number of
STDP rules from neuroscience and physics applied to neural systems can be
represented by this formalism.

Experiments show that long-term synaptic plasticity evolves on a much slower
timescale than the cellular mechanisms driving the activity of neuronal cells.
For this reason a scaling model of our stochastic model is also introduced and
averaging principles for a sub-class of plasticity kernels are stated, and
proved in a companion paper. These results are used to analyze two STDP models
widely used in applied physics: Pair-based rules and calcium-based rules. We
compare results of computational neuroscience on models of timing-based
synaptic plasticity with our results derived from averaging principles.
</p>
<a href="http://arxiv.org/abs/2010.08195" target="_blank">arXiv:2010.08195</a> [<a href="http://arxiv.org/pdf/2010.08195" target="_blank">pdf</a>]

<h2>On Scalar and Ricci Curvatures. (arXiv:2010.08207v1 [math.DG])</h2>
<h3>G Besson (IF), S Gallot (IF)</h3>
<p>The purpose of this report is to acknowledge the influence of M. Gromov's
vision of Geometry on our own work. It is two-fold: in the first part we aim at
describing some results, in dimension 3, around the question: which open
3-manifolds carry a complete Riemannian metric of positive or non negative
scalar curvature ? In the second part we look for weak forms of the notion of
"lower bounds of the Ricci curvature" on non necessarily smooth metric measured
spaces. We describe recent results some of which are already posted in
[BCGS20b] where we proposed to use the volume entropy. We also attempt to give
a new synthetic version of Ricci curvature boundedbelow using Bishop-Gromov's
Inequality.
</p>
<a href="http://arxiv.org/abs/2010.08207" target="_blank">arXiv:2010.08207</a> [<a href="http://arxiv.org/pdf/2010.08207" target="_blank">pdf</a>]

<h2>Improved Communication Lower Bounds for Distributed Optimisation. (arXiv:2010.08222v1 [cs.LG])</h2>
<h3>Dan Alistarh, Janne H. Korhonen</h3>
<p>Motivated by the interest in communication-efficient methods for distributed
machine learning, we consider the communication complexity of minimising a sum
of $d$-dimensional functions $\sum_{i = 1}^N f_i (x)$, where each function
$f_i$ is held by a one of the $N$ different machines. Such tasks arise
naturally in large-scale optimisation, where a standard solution is to apply
variants of (stochastic) gradient descent. As our main result, we show that
$\Omega( Nd \log d / \varepsilon)$ bits in total need to be communicated
between the machines to find an additive $\epsilon$-approximation to the
minimum of $\sum_{i = 1}^N f_i (x)$. The results holds for deterministic
algorithms, and randomised algorithms under some restrictions on the parameter
values. Importantly, our lower bounds require no assumptions on the structure
of the algorithm, and are matched within constant factors for strongly convex
objectives by a new variant of quantised gradient descent. The lower bounds are
obtained by bringing over tools from communication complexity to distributed
optimisation, an approach we hope will find further use in future.
</p>
<a href="http://arxiv.org/abs/2010.08222" target="_blank">arXiv:2010.08222</a> [<a href="http://arxiv.org/pdf/2010.08222" target="_blank">pdf</a>]

<h2>Eigenvalues of two-phase quantum walks with one defect on one dimension. (arXiv:2010.08324v1 [math-ph])</h2>
<h3>Chusei Kiumi, Kei Saito</h3>
<p>We study space-inhomogeneous quantum walks (QWs) on the integer lattice,
which we assign three different coin matrices to the positive part, negative
part, and to the origin, respectively. We call the model the two-phase QW with
one defect. It covers the one-defect and the two-phase QW, which have been
intensively researched. Localization is one of the most characteristic
properties of QWs, and various types of two-phase QW with one-defect occurs
localization. Moreover, the existence of eigenvalues is deeply related to
localization. In this paper, we obtain the necessary and sufficient condition
for the existence of eigenvalues. Our analytical methods are mainly based on
the transfer matrix, a useful tool to generate the generalized eigenfunctions.
Furthermore, we explicitly derive eigenvalues for some classes of two-phase QW
with one defect.
</p>
<a href="http://arxiv.org/abs/2010.08324" target="_blank">arXiv:2010.08324</a> [<a href="http://arxiv.org/pdf/2010.08324" target="_blank">pdf</a>]

<h2>A note on stochastic subgradient descent for persistence-based functionals: convergence and practical aspects. (arXiv:2010.08356v1 [cs.CG])</h2>
<h3>Mathieu Carri&#xe8;re, Fr&#xe9;d&#xe9;ric Chazal, Marc Glisse, Yuichi Ike, Hariprasad Kannan</h3>
<p>Solving optimization tasks based on functions and losses with a topological
flavor is a very active and growing field of research in Topological Data
Analysis, with plenty of applications in non-convex optimization, statistics
and machine learning. All of these methods rely on the fact that most of the
topological constructions are actually stratifiable and differentiable almost
everywhere. However, the corresponding gradient and associated code is always
anchored to a specific application and/or topological construction, and do not
come with theoretical guarantees. In this article, we study the
differentiability of a general functional associated with the most common
topological construction, that is, the persistence map, and we prove a
convergence result of stochastic subgradient descent for such a functional.
This result encompasses all the constructions and applications for topological
optimization in the literature, and comes with code that is easy to handle and
mix with other non-topological constraints, and that can be used to reproduce
the experiments described in the literature.
</p>
<a href="http://arxiv.org/abs/2010.08356" target="_blank">arXiv:2010.08356</a> [<a href="http://arxiv.org/pdf/2010.08356" target="_blank">pdf</a>]

<h2>HARQ in Full-Duplex Relay-Assisted Transmissions for URLLC. (arXiv:2010.08455v1 [cs.IT])</h2>
<h3>Fatima Ezzahra Airod, Houda Chafnaji, Halim Yanikomeroglu</h3>
<p>The Release 16 completion unlocks the road to an exciting phase pertain to
the sixth generation (6G) era. Meanwhile, to sustain far-reaching applications
with unprecedented challenges in terms of latency and reliability, much
interest is already getting intensified toward physical layer specifications of
6G. In support of this vision, this work exhibits the forward-looking
perception of full-duplex (FD) cooperative relaying in support of upcoming
generations and adopts as a mean concern the critical contribution of hybrid
automatic repeat request (HARQ) mechanism to ultra-reliable and low-latency
communication (URLLC). Indeed, the HARQ roundtrip time (RTT) is known to
include basic physical delays that may cause the HARQ abandonment for the 1 ms
latency use case of URLLC. Taking up these challenges, this article proposes a
hybrid FD amplify-and-forward (AF)-selective decode-and-forward (SDF)
relay-based system for URLLC. Over this build system, two HARQ procedures
within which the HARQ RTT is shortened, are suggested to face latency and
reliability issues, namely, the conventional and the enhanced HARQ procedures.
We develop then an analytical framework of this relay based HARQ system within
its different procedures. Finally, using Monte-Carlo simulations, we confirm
the theoretical results and compare the proposed relay-assisted HARQ procedures
to the source-to-destination (S2D) HARQ-based system where no relay assists the
communication between the source and the destination.
</p>
<a href="http://arxiv.org/abs/2010.08455" target="_blank">arXiv:2010.08455</a> [<a href="http://arxiv.org/pdf/2010.08455" target="_blank">pdf</a>]

<h2>Binary Choice with Asymmetric Loss in a Data-Rich Environment: Theory and an Application to Racial Justice. (arXiv:2010.08463v1 [econ.EM])</h2>
<h3>Andrii Babii, Xi Chen, Eric Ghysels, Rohit Kumar</h3>
<p>The importance of asymmetries in prediction problems arising in economics has
been recognized for a long time. In this paper, we focus on binary choice
problems in a data-rich environment with general loss functions. In contrast to
the asymmetric regression problems, the binary choice with general loss
functions and high-dimensional datasets is challenging and not well understood.
Econometricians have studied binary choice problems for a long time, but the
literature does not offer computationally attractive solutions in data-rich
environments. In contrast, the machine learning literature has many
computationally attractive algorithms that form the basis for much of the
automated procedures that are implemented in practice, but it is focused on
symmetric loss functions that are independent of individual characteristics.
One of the main contributions of our paper is to show that the theoretically
valid predictions of binary outcomes with arbitrary loss functions can be
achieved via a very simple reweighting of the logistic regression, or other
state-of-the-art machine learning techniques, such as boosting or (deep) neural
networks. We apply our analysis to racial justice in pretrial detention.
</p>
<a href="http://arxiv.org/abs/2010.08463" target="_blank">arXiv:2010.08463</a> [<a href="http://arxiv.org/pdf/2010.08463" target="_blank">pdf</a>]

<h2>Failures of model-dependent generalization bounds for least-norm interpolation. (arXiv:2010.08479v1 [stat.ML])</h2>
<h3>Peter L. Bartlett, Philip M. Long</h3>
<p>We consider bounds on the generalization performance of the least-norm linear
regressor, in the over-parameterized regime where it can interpolate the data.
We describe a sense in which any generalization bound of a type that is
commonly proved in statistical learning theory must sometimes be very loose
when applied to analyze the least-norm interpolant. In particular, for a
variety of natural joint distributions on training examples, any valid
generalization bound that depends only on the output of the learning algorithm,
the number of training examples, and the confidence parameter, and that
satisfies a mild condition (substantially weaker than monotonicity in sample
size), must sometimes be very loose---it can be bounded below by a constant
when the true excess risk goes to zero.
</p>
<a href="http://arxiv.org/abs/2010.08479" target="_blank">arXiv:2010.08479</a> [<a href="http://arxiv.org/pdf/2010.08479" target="_blank">pdf</a>]

<h2>Online non-convex optimization with imperfect feedback. (arXiv:2010.08496v1 [cs.LG])</h2>
<h3>Am&#xe9;lie H&#xe9;liou, Matthieu Martin, Panayotis Mertikopoulos, Thibaud Rahier</h3>
<p>We consider the problem of online learning with non-convex losses. In terms
of feedback, we assume that the learner observes - or otherwise constructs - an
inexact model for the loss function encountered at each stage, and we propose a
mixed-strategy learning policy based on dual averaging. In this general
context, we derive a series of tight regret minimization guarantees, both for
the learner's static (external) regret, as well as the regret incurred against
the best dynamic policy in hindsight. Subsequently, we apply this general
template to the case where the learner only has access to the actual loss
incurred at each stage of the process. This is achieved by means of a
kernel-based estimator which generates an inexact model for each round's loss
function using only the learner's realized losses as input.
</p>
<a href="http://arxiv.org/abs/2010.08496" target="_blank">arXiv:2010.08496</a> [<a href="http://arxiv.org/pdf/2010.08496" target="_blank">pdf</a>]

<h2>Universal Bayes consistency in metric spaces. (arXiv:1906.09855v6 [cs.LG] UPDATED)</h2>
<h3>Steve Hanneke, Aryeh Kontorovich, Sivan Sabato, Roi Weiss</h3>
<p>We extend a recently proposed 1-nearest-neighbor-based multiclass learning
algorithm and prove that our modification is universally strongly
Bayes-consistent in all metric spaces admitting any such learner, making it an
"optimistically universal" Bayes-consistent learner. This is the first learning
algorithm known to enjoy this property; by comparison, the $k$-NN classifier
and its variants are not generally universally Bayes-consistent, except under
additional structural assumptions, such as an inner product, a norm, finite
dimension, or a Besicovitch-type property. The metric spaces in which universal
Bayes consistency is possible are the "essentially separable" ones -- a notion
that we define, which is more general than standard separability. The existence
of metric spaces that are not essentially separable is widely believed to be
independent of the ZFC axioms of set theory. We prove that essential
separability exactly characterizes the existence of a universal
Bayes-consistent learner for the given metric space. In particular, this yields
the first impossibility result for universal Bayes consistency. Taken together,
our results completely characterize strong and weak universal Bayes consistency
in metric spaces.
</p>
<a href="http://arxiv.org/abs/1906.09855" target="_blank">arXiv:1906.09855</a> [<a href="http://arxiv.org/pdf/1906.09855" target="_blank">pdf</a>]

<h2>Election Coding for Distributed Learning: Protecting SignSGD against Byzantine Attacks. (arXiv:1910.06093v3 [cs.IT] UPDATED)</h2>
<h3>Jy-yong Sohn, Dong-Jun Han, Beongjun Choi, Jaekyun Moon</h3>
<p>Recent advances in large-scale distributed learning algorithms have enabled
communication-efficient training via SignSGD. Unfortunately, a major issue
continues to plague distributed learning: namely, Byzantine failures may incur
serious degradation in learning accuracy. This paper proposes Election Coding,
a coding-theoretic framework to guarantee Byzantine-robustness for SignSGD with
Majority Vote, which uses minimum worker-master communication in both
directions. The suggested framework explores new information-theoretic limits
of finding the majority opinion when some workers could be malicious, and paves
the road to implement robust and efficient distributed learning algorithms.
Under this framework, we construct two types of explicit codes, random
Bernoulli codes and deterministic algebraic codes, that can tolerate Byzantine
attacks with a controlled amount of computational redundancy. For the Bernoulli
codes, we provide upper bounds on the error probability in estimating the
majority opinion, which give useful insights into code design for tolerating
Byzantine attacks. As for deterministic codes, we construct an explicit code
which perfectly tolerates Byzantines, and provide tight upper/lower bounds on
the minimum required computational redundancy. Finally, the Byzantine-tolerance
of the suggested coding schemes is confirmed by deep learning experiments on
Amazon EC2 using Python with MPI4py package.
</p>
<a href="http://arxiv.org/abs/1910.06093" target="_blank">arXiv:1910.06093</a> [<a href="http://arxiv.org/pdf/1910.06093" target="_blank">pdf</a>]

<h2>Approximate Stochastic Reachability for High Dimensional Systems. (arXiv:1910.10818v3 [eess.SY] UPDATED)</h2>
<h3>Adam J. Thorpe, Vignesh Sivaramakrishnan, Meeko M. K. Oishi</h3>
<p>We present a method to compute the stochastic reachability safety
probabilities for high-dimensional stochastic dynamical systems. Our approach
takes advantage of a nonparametric learning technique known as conditional
distribution embeddings to model the stochastic kernel using a data-driven
approach. By embedding the dynamics and uncertainty within a reproducing kernel
Hilbert space, it becomes possible to compute the safety probabilities for
stochastic reachability problems as simple matrix operations and inner
products. We employ a convergent approximation technique, random Fourier
features, in order to alleviate the increased computational requirements for
high-dimensional systems. This technique avoids the curse of dimensionality,
and enables the computation of safety probabilities for high-dimensional
systems without prior knowledge of the structure of the dynamics or
uncertainty. We validate this approach on a double integrator system, and
demonstrate its capabilities on a million-dimensional, nonlinear, non-Gaussian,
repeated planar quadrotor system.
</p>
<a href="http://arxiv.org/abs/1910.10818" target="_blank">arXiv:1910.10818</a> [<a href="http://arxiv.org/pdf/1910.10818" target="_blank">pdf</a>]

<h2>Mean-Field Controls with Q-learning for Cooperative MARL: Convergence and Complexity Analysis. (arXiv:2002.04131v3 [cs.LG] UPDATED)</h2>
<h3>Haotian Gu, Xin Guo, Xiaoli Wei, Renyuan Xu</h3>
<p>Multi-agent reinforcement learning (MARL), despite its popularity and
empirical success, suffers from the curse of dimensionality. This paper builds
the mathematical framework to approximate cooperative MARL by a mean-field
control (MFC) framework, and shows that the approximation error is of
$O(\frac{1}{\sqrt{N}})$. By establishing appropriate form of the dynamic
programming principle for both the value function and the Q function, it
proposes a model-free kernel-based Q-learning algorithm (MFC-K-Q), which is
shown to be of linear convergence rate, the first of its kind in the MARL
literature. It further establishes that the convergence rate and the sample
complexity of MFC-K-Q are independent of the number of agents $N$. Empirical
studies for the network traffic congestion problem demonstrate that MFC-K-Q
outperforms existing MARL algorithms when $N$ is large, for instance when
$N&gt;50$.
</p>
<a href="http://arxiv.org/abs/2002.04131" target="_blank">arXiv:2002.04131</a> [<a href="http://arxiv.org/pdf/2002.04131" target="_blank">pdf</a>]

<h2>Geometry-Aware Gradient Algorithms for Neural Architecture Search. (arXiv:2004.07802v3 [cs.LG] UPDATED)</h2>
<h3>Liam Li, Mikhail Khodak, Maria-Florina Balcan, Ameet Talwalkar</h3>
<p>Recent state-of-the-art methods for neural architecture search (NAS) exploit
gradient-based optimization by relaxing the problem into continuous
optimization over architectures and shared-weights, a noisy process that
remains poorly understood. We argue for the study of single-level empirical
risk minimization to understand NAS with weight-sharing, reducing the design of
NAS methods to devising optimizers and regularizers that can quickly obtain
high-quality solutions to this problem. Invoking the theory of mirror descent,
we present a geometry-aware framework that exploits the underlying structure of
this optimization to return sparse architectural parameters, leading to simple
yet novel algorithms that enjoy fast convergence guarantees and achieve
state-of-the-art accuracy on the latest NAS benchmarks in computer vision.
Notably, we exceed the best published results for both CIFAR and ImageNet on
both the DARTS search space and NAS-Bench-201; on the latter we achieve
near-oracle-optimal performance on CIFAR-10 and CIFAR-100. Together, our theory
and experiments demonstrate a principled way to co-design optimizers and
continuous relaxations of discrete NAS search spaces.
</p>
<a href="http://arxiv.org/abs/2004.07802" target="_blank">arXiv:2004.07802</a> [<a href="http://arxiv.org/pdf/2004.07802" target="_blank">pdf</a>]

<h2>Revealing hidden dynamics from time-series data by ODENet. (arXiv:2005.04849v2 [math.DS] UPDATED)</h2>
<h3>Pipi Hu, Wuyue Yang, Yi Zhu, Liu Hong</h3>
<p>To derive the hidden dynamics from observed data is one of the fundamental
but also challenging problems in many different fields. In this study, we
propose a new type of interpretable network called the ordinary differential
equation network (ODENet), in which the numerical integration of explicit
ordinary differential equations (ODEs) are embedded into the machine learning
scheme to build a general framework for revealing the hidden dynamics buried in
massive time-series data efficiently and reliably. ODENet takes full advantage
of both machine learning algorithms and ODE modeling. On one hand, the
embedding of ODEs makes the framework more interpretable benefiting from the
mature theories of ODEs. On the other hand, the schemes of machine learning
enable data handling, paralleling, and optimization to be easily and
efficiently implemented. From classical Lotka-Volterra equations to chaotic
Lorenz equations, the ODENet exhibits its remarkable capability in handling
time-series data even in the presence of large noise. We further apply the
ODENet to real actin aggregation data, which shows an impressive performance as
well. These results demonstrate the superiority of ODENet in dealing with noisy
data, data with either non-equal spacing or large sampling time steps over
other traditional machine learning algorithms.
</p>
<a href="http://arxiv.org/abs/2005.04849" target="_blank">arXiv:2005.04849</a> [<a href="http://arxiv.org/pdf/2005.04849" target="_blank">pdf</a>]

<h2>Fourier Sparse Leverage Scores and Approximate Kernel Learning. (arXiv:2006.07340v2 [cs.DS] UPDATED)</h2>
<h3>Tam&#xe1;s Erd&#xe9;lyi, Cameron Musco, Christopher Musco</h3>
<p>We prove new explicit upper bounds on the leverage scores of Fourier sparse
functions under both the Gaussian and Laplace measures. In particular, we study
$s$-sparse functions of the form $f(x) = \sum_{j=1}^s a_j e^{i \lambda_j x}$
for coefficients $a_j \in \mathbb{C}$ and frequencies $\lambda_j \in
\mathbb{R}$. Bounding Fourier sparse leverage scores under various measures is
of pure mathematical interest in approximation theory, and our work extends
existing results for the uniform measure [Erd17,CP19a]. Practically, our bounds
are motivated by two important applications in machine learning:

1. Kernel Approximation. They yield a new random Fourier features algorithm
for approximating Gaussian and Cauchy (rational quadratic) kernel matrices. For
low-dimensional data, our method uses a near optimal number of features, and
its runtime is polynomial in the $statistical\ dimension$ of the approximated
kernel matrix. It is the first "oblivious sketching method" with this property
for any kernel besides the polynomial kernel, resolving an open question of
[AKM+17,AKK+20b].

2. Active Learning. They can be used as non-uniform sampling distributions
for robust active learning when data follows a Gaussian or Laplace
distribution. Using the framework of [AKM+19], we provide essentially optimal
results for bandlimited and multiband interpolation, and Gaussian process
regression. These results generalize existing work that only applies to
uniformly distributed data.
</p>
<a href="http://arxiv.org/abs/2006.07340" target="_blank">arXiv:2006.07340</a> [<a href="http://arxiv.org/pdf/2006.07340" target="_blank">pdf</a>]

<h2>Sample complexity and effective dimension for regression on manifolds. (arXiv:2006.07642v3 [stat.ML] UPDATED)</h2>
<h3>Andrew McRae, Justin Romberg, Mark Davenport</h3>
<p>We consider the theory of regression on a manifold using reproducing kernel
Hilbert space methods. Manifold models arise in a wide variety of modern
machine learning problems, and our goal is to help understand the effectiveness
of various implicit and explicit dimensionality-reduction methods that exploit
manifold structure. Our first key contribution is to establish a novel
nonasymptotic version of the Weyl law from differential geometry. From this we
are able to show that certain spaces of smooth functions on a manifold are
effectively finite-dimensional, with a complexity that scales according to the
manifold dimension rather than any ambient data dimension. Finally, we show
that given (potentially noisy) function values taken uniformly at random over a
manifold, a kernel regression estimator (derived from the spectral
decomposition of the manifold) yields minimax-optimal error bounds that are
controlled by the effective dimension.
</p>
<a href="http://arxiv.org/abs/2006.07642" target="_blank">arXiv:2006.07642</a> [<a href="http://arxiv.org/pdf/2006.07642" target="_blank">pdf</a>]

<h2>Permutation invariant networks to learn Wasserstein metrics. (arXiv:2010.05820v2 [cs.LG] UPDATED)</h2>
<h3>Arijit Sehanobish, Neal Ravindra, David van Dijk</h3>
<p>Understanding the space of probability measures on a metric space equipped
with a Wasserstein distance is one of the fundamental questions in mathematical
analysis. The Wasserstein metric has received a lot of attention in the machine
learning community especially for its principled way of comparing
distributions. In this work, we use a permutation invariant network to map
samples from probability measures into a low-dimensional space such that the
Euclidean distance between the encoded samples reflects the Wasserstein
distance between probability measures. We show that our network can generalize
to correctly compute distances between unseen densities. We also show that
these networks can learn the first and the second moments of probability
distributions.
</p>
<a href="http://arxiv.org/abs/2010.05820" target="_blank">arXiv:2010.05820</a> [<a href="http://arxiv.org/pdf/2010.05820" target="_blank">pdf</a>]

<h2>Multi-Agent Motion Planning using Deep Learning for Space Applications. (arXiv:2010.07935v1 [cs.RO])</h2>
<h3>Kyongsik Yun, Changrak Choi, Ryan Alimo, Anthony Davis, Linda Forster, Amir Rahmani, Muhammad Adil, Ramtin Madani</h3>
<p>State-of-the-art motion planners cannot scale to a large number of systems.
Motion planning for multiple agents is an NP (non-deterministic
polynomial-time) hard problem, so the computation time increases exponentially
with each addition of agents. This computational demand is a major stumbling
block to the motion planner's application to future NASA missions involving the
swarm of space vehicles. We applied a deep neural network to transform
computationally demanding mathematical motion planning problems into deep
learning-based numerical problems. We showed optimal motion trajectories can be
accurately replicated using deep learning-based numerical models in several 2D
and 3D systems with multiple agents. The deep learning-based numerical model
demonstrates superior computational efficiency with plans generated 1000 times
faster than the mathematical model counterpart.
</p>
<a href="http://arxiv.org/abs/2010.07935" target="_blank">arXiv:2010.07935</a> [<a href="http://arxiv.org/pdf/2010.07935" target="_blank">pdf</a>]

<h2>Convolutional Neural Network for Blur Images Detection as an Alternative for Laplacian Method. (arXiv:2010.07936v1 [cs.CV])</h2>
<h3>Tomasz Szandala</h3>
<p>With the prevalence of digital cameras, the number of digital images
increases quickly, which raises the demand for non-manual image quality
assessment. While there are many methods considered useful for detecting
blurriness, in this paper we propose and evaluate a new method that uses a deep
convolutional neural network, which can determine whether an image is blurry or
not. Experimental results demonstrate the effectiveness of the proposed scheme
and are compared to deterministic methods using the confusion matrix.
</p>
<a href="http://arxiv.org/abs/2010.07936" target="_blank">arXiv:2010.07936</a> [<a href="http://arxiv.org/pdf/2010.07936" target="_blank">pdf</a>]

<h2>Room-Across-Room: Multilingual Vision-and-Language Navigation with Dense Spatiotemporal Grounding. (arXiv:2010.07954v1 [cs.CV])</h2>
<h3>Alexander Ku, Peter Anderson, Roma Patel, Eugene Ie, Jason Baldridge</h3>
<p>We introduce Room-Across-Room (RxR), a new Vision-and-Language Navigation
(VLN) dataset. RxR is multilingual (English, Hindi, and Telugu) and larger
(more paths and instructions) than other VLN datasets. It emphasizes the role
of language in VLN by addressing known biases in paths and eliciting more
references to visible entities. Furthermore, each word in an instruction is
time-aligned to the virtual poses of instruction creators and validators. We
establish baseline scores for monolingual and multilingual settings and
multitask learning when including Room-to-Room annotations. We also provide
results for a model that learns from synchronized pose traces by focusing only
on portions of the panorama attended to in human demonstrations. The size,
scope and detail of RxR dramatically expands the frontier for research on
embodied language agents in simulated, photo-realistic environments.
</p>
<a href="http://arxiv.org/abs/2010.07954" target="_blank">arXiv:2010.07954</a> [<a href="http://arxiv.org/pdf/2010.07954" target="_blank">pdf</a>]

<h2>Minimax Classification with 0-1 Loss and Performance Guarantees. (arXiv:2010.07964v1 [stat.ML])</h2>
<h3>Santiago Mazuelas, Andrea Zanoni, Aritz Perez</h3>
<p>Supervised classification techniques use training samples to find
classification rules with small expected 0-1 loss. Conventional methods achieve
efficient learning and out-of-sample generalization by minimizing surrogate
losses over specific families of rules. This paper presents minimax risk
classifiers (MRCs) that do not rely on a choice of surrogate loss and family of
rules. MRCs achieve efficient learning and out-of-sample generalization by
minimizing worst-case expected 0-1 loss w.r.t. uncertainty sets that are
defined by linear constraints and include the true underlying distribution. In
addition, MRCs' learning stage provides performance guarantees as lower and
upper tight bounds for expected 0-1 loss. We also present MRCs' finite-sample
generalization bounds in terms of training size and smallest minimax risk, and
show their competitive classification performance w.r.t. state-of-the-art
techniques using benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2010.07964" target="_blank">arXiv:2010.07964</a> [<a href="http://arxiv.org/pdf/2010.07964" target="_blank">pdf</a>]

<h2>Safe Model-based Reinforcement Learning with Robust Cross-Entropy Method. (arXiv:2010.07968v1 [cs.AI])</h2>
<h3>Zuxin Liu, Hongyi Zhou, Baiming Chen, Sicheng Zhong, Martial Hebert, Ding Zhao</h3>
<p>This paper studies the safe reinforcement learning (RL) problem without
assumptions about prior knowledge of the system dynamics and the constraint
function. We employ an uncertainty-aware neural network ensemble model to learn
the dynamics, and we infer the unknown constraint function through indicator
constraint violation signals. We use model predictive control (MPC) as the
basic control framework and propose the robust cross-entropy method (RCE) to
optimize the control sequence considering the model uncertainty and
constraints. We evaluate our methods in the Safety Gym environment. The results
show that our approach achieves better constraint satisfaction than baseline
safe RL methods while maintaining good task performance. Additionally, we are
able to achieve several orders of magnitude better sample efficiency when
compared to constrained model-free RL approaches. The code is available at
https://github.com/liuzuxin/safe-mbrl.
</p>
<a href="http://arxiv.org/abs/2010.07968" target="_blank">arXiv:2010.07968</a> [<a href="http://arxiv.org/pdf/2010.07968" target="_blank">pdf</a>]

<h2>Explicit Alignment Objectives for Multilingual Bidirectional Encoders. (arXiv:2010.07972v1 [cs.CL])</h2>
<h3>Junjie Hu, Melvin Johnson, Orhan Firat, Aditya Siddhant, Graham Neubig</h3>
<p>Pre-trained cross-lingual encoders such as mBERT (Devlin et al., 2019) and
XLMR (Conneau et al., 2020) have proven to be impressively effective at
enabling transfer-learning of NLP systems from high-resource languages to
low-resource languages. This success comes despite the fact that there is no
explicit objective to align the contextual embeddings of words/sentences with
similar meanings across languages together in the same space. In this paper, we
present a new method for learning multilingual encoders, AMBER (Aligned
Multilingual Bidirectional EncodeR). AMBER is trained on additional parallel
data using two explicit alignment objectives that align the multilingual
representations at different granularities. We conduct experiments on zero-shot
cross-lingual transfer learning for different tasks including sequence tagging,
sentence retrieval and sentence classification. Experimental results show that
AMBER obtains gains of up to 1.1 average F1 score on sequence tagging and up to
27.3 average accuracy on retrieval over the XLMR-large model which has 4.6x the
parameters of AMBER.
</p>
<a href="http://arxiv.org/abs/2010.07972" target="_blank">arXiv:2010.07972</a> [<a href="http://arxiv.org/pdf/2010.07972" target="_blank">pdf</a>]

<h2>Impact of Action Unit Occurrence Patterns on Detection. (arXiv:2010.07982v1 [cs.CV])</h2>
<h3>Saurabh Hinduja, Shaun Canavan, Saandeep Aathreya</h3>
<p>Detecting action units is an important task in face analysis, especially in
facial expression recognition. This is due, in part, to the idea that
expressions can be decomposed into multiple action units. In this paper we
investigate the impact of action unit occurrence patterns on detection of
action units. To facilitate this investigation, we review state of the art
literature, for AU detection, on 2 state-of-the-art face databases that are
commonly used for this task, namely DISFA, and BP4D. Our findings, from this
literature review, suggest that action unit occurrence patterns strongly impact
evaluation metrics (e.g. F1-binary). Along with the literature review, we also
conduct multi and single action unit detection, as well as propose a new
approach to explicitly train deep neural networks using the occurrence patterns
to boost the accuracy of action unit detection. These experiments validate that
action unit patterns directly impact the evaluation metrics.
</p>
<a href="http://arxiv.org/abs/2010.07982" target="_blank">arXiv:2010.07982</a> [<a href="http://arxiv.org/pdf/2010.07982" target="_blank">pdf</a>]

<h2>An Empowerment-based Solution to Robotic Manipulation Tasks with Sparse Rewards. (arXiv:2010.07986v1 [cs.RO])</h2>
<h3>Siyu Dai, Wei Xu, Andreas Hofmann, Brian Williams</h3>
<p>In order to provide adaptive and user-friendly solutions to robotic
manipulation, it is important that the agent can learn to accomplish tasks even
if they are only provided with very sparse instruction signals. To address the
issues reinforcement learning algorithms face when task rewards are sparse,
this paper proposes a novel form of intrinsic motivation that can allow robotic
manipulators to learn useful manipulation skills with only sparse extrinsic
rewards. Through integrating and balancing empowerment and curiosity, this
approach shows superior performance compared to other existing intrinsic
exploration approaches during extensive empirical testing. Qualitative analysis
also shows that when combined with diversity-driven intrinsic motivations, this
approach can help manipulators learn a set of diverse skills which could
potentially be applied to other more complicated manipulation tasks and
accelerate their learning process.
</p>
<a href="http://arxiv.org/abs/2010.07986" target="_blank">arXiv:2010.07986</a> [<a href="http://arxiv.org/pdf/2010.07986" target="_blank">pdf</a>]

<h2>An Algorithm for Learning Smaller Representations of Models With Scarce Data. (arXiv:2010.07990v1 [cs.LG])</h2>
<h3>Adrian de Wynter</h3>
<p>We present a greedy algorithm for solving binary classification problems in
situations where the dataset is either too small or not fully representative of
the problem being solved, and obtaining more data is not possible. This
algorithm is of particular interest when training small models that have
trouble generalizing. It relies on a trained model with loose accuracy
constraints, an iterative hyperparameter pruning procedure, and a function used
to generate new data. Analysis on correctness and runtime complexity under
ideal conditions and an extension to deep neural networks is provided. In the
former case we obtain an asymptotic bound of
$O\left(|\Theta^2|\left(\log{|\Theta|} + |\theta^2| + T_f\left(|
D|\right)\right) + \bar{S}|\Theta||{E}|\right)$, where $|{\Theta}|$ is the
cardinality of the set of hyperparameters $\theta$ to be searched; $|{E}|$ and
$|{D}|$ are the sizes of the evaluation and training datasets, respectively;
$\bar{S}$ and $\bar{f}$ are the inference times for the trained model and the
candidate model; and $T_f({|{D}|})$ is a polynomial on $|{D}|$ and $\bar{f}$.
Under these conditions, this algorithm returns a solution that is $1 \leq r
\leq 2(1 - {2^{-|{\Theta}|}})$ times better than simply enumerating and
training with any $\theta \in \Theta$. As part of our analysis of the
generating function we also prove that, under certain assumptions, if an open
cover of $D$ has the same homology as the manifold where the support of the
underlying probability distribution lies, then $D$ is learnable, and viceversa.
</p>
<a href="http://arxiv.org/abs/2010.07990" target="_blank">arXiv:2010.07990</a> [<a href="http://arxiv.org/pdf/2010.07990" target="_blank">pdf</a>]

<h2>ALPaCA vs. GP-based Prior Learning: A Comparison between two Bayesian Meta-Learning Algorithms. (arXiv:2010.07994v1 [cs.LG])</h2>
<h3>Yilun Wu</h3>
<p>Meta-learning or few-shot learning, has been successfully applied in a wide
range of domains from computer vision to reinforcement learning. Among the many
frameworks proposed for meta-learning, bayesian methods are particularly
favoured when accurate and calibrated uncertainty estimate is required. In this
paper, we investigate the similarities and disparities among two recently
published bayesian meta-learning methods: ALPaCA (Harrison et al. [2018]) and
PACOH (Rothfuss et al. [2020]). We provide theoretical analysis as well as
empirical benchmarks across synthetic and real-world dataset. While ALPaCA
holds advantage in computation time by the usage of a linear kernel, general
GP-based methods provide much more flexibility and achieves better result
across datasets when using a common kernel such as SE (Squared Exponential)
kernel. The influence of different loss function choice is also discussed.
</p>
<a href="http://arxiv.org/abs/2010.07994" target="_blank">arXiv:2010.07994</a> [<a href="http://arxiv.org/pdf/2010.07994" target="_blank">pdf</a>]

<h2>What is More Likely to Happen Next? Video-and-Language Future Event Prediction. (arXiv:2010.07999v1 [cs.CL])</h2>
<h3>Jie Lei, Licheng Yu, Tamara L. Berg, Mohit Bansal</h3>
<p>Given a video with aligned dialogue, people can often infer what is more
likely to happen next. Making such predictions requires not only a deep
understanding of the rich dynamics underlying the video and dialogue, but also
a significant amount of commonsense knowledge. In this work, we explore whether
AI models are able to learn to make such multimodal commonsense next-event
predictions. To support research in this direction, we collect a new dataset,
named Video-and-Language Event Prediction (VLEP), with 28,726 future event
prediction examples (along with their rationales) from 10,234 diverse TV Show
and YouTube Lifestyle Vlog video clips. In order to promote the collection of
non-trivial challenging examples, we employ an adversarial
human-and-model-in-the-loop data collection procedure. We also present a strong
baseline incorporating information from video, dialogue, and commonsense
knowledge. Experiments show that each type of information is useful for this
challenging task, and that compared to the high human performance on VLEP, our
model provides a good starting point but leaves large room for future work. Our
dataset and code are available at:
https://github.com/jayleicn/VideoLanguageFuturePred
</p>
<a href="http://arxiv.org/abs/2010.07999" target="_blank">arXiv:2010.07999</a> [<a href="http://arxiv.org/pdf/2010.07999" target="_blank">pdf</a>]

<h2>Maximum-Entropy Adversarial Data Augmentation for Improved Generalization and Robustness. (arXiv:2010.08001v1 [cs.LG])</h2>
<h3>Long Zhao, Ting Liu, Xi Peng, Dimitris Metaxas</h3>
<p>Adversarial data augmentation has shown promise for training robust deep
neural networks against unforeseen data shifts or corruptions. However, it is
difficult to define heuristics to generate effective fictitious target
distributions containing "hard" adversarial perturbations that are largely
different from the source distribution. In this paper, we propose a novel and
effective regularization term for adversarial data augmentation. We
theoretically derive it from the information bottleneck principle, which
results in a maximum-entropy formulation. Intuitively, this regularization term
encourages perturbing the underlying source distribution to enlarge predictive
uncertainty of the current model, so that the generated "hard" adversarial
perturbations can improve the model robustness during training. Experimental
results on three standard benchmarks demonstrate that our method consistently
outperforms the existing state of the art by a statistically significant
margin.
</p>
<a href="http://arxiv.org/abs/2010.08001" target="_blank">arXiv:2010.08001</a> [<a href="http://arxiv.org/pdf/2010.08001" target="_blank">pdf</a>]

<h2>Data Valuation for Medical Imaging Using Shapley Value: Application on A Large-scale Chest X-ray Dataset. (arXiv:2010.08006v1 [cs.LG])</h2>
<h3>Siyi Tang, Amirata Ghorbani, Rikiya Yamashita, Sameer Rehman, Jared A. Dunnmon, James Zou, Daniel L. Rubin</h3>
<p>The reliability of machine learning models can be compromised when trained on
low quality data. Many large-scale medical imaging datasets contain low quality
labels extracted from sources such as medical reports. Moreover, images within
a dataset may have heterogeneous quality due to artifacts and biases arising
from equipment or measurement errors. Therefore, algorithms that can
automatically identify low quality data are highly desired. In this study, we
used data Shapley, a data valuation metric, to quantify the value of training
data to the performance of a pneumonia detection algorithm in a large chest
X-ray dataset. We characterized the effectiveness of data Shapley in
identifying low quality versus valuable data for pneumonia detection. We found
that removing training data with high Shapley values decreased the pneumonia
detection performance, whereas removing data with low Shapley values improved
the model performance. Furthermore, there were more mislabeled examples in low
Shapley value data and more true pneumonia cases in high Shapley value data.
Our results suggest that low Shapley value indicates mislabeled or poor quality
images, whereas high Shapley value indicates data that are valuable for
pneumonia detection. Our method can serve as a framework for using data Shapley
to denoise large-scale medical imaging datasets.
</p>
<a href="http://arxiv.org/abs/2010.08006" target="_blank">arXiv:2010.08006</a> [<a href="http://arxiv.org/pdf/2010.08006" target="_blank">pdf</a>]

<h2>Neural Function Modules with Sparse Arguments: A Dynamic Approach to Integrating Information across Layers. (arXiv:2010.08012v1 [cs.LG])</h2>
<h3>Alex Lamb, Anirudh Goyal, Agnieszka S&#x142;owik, Michael Mozer, Philippe Beaudoin, Yoshua Bengio</h3>
<p>Feed-forward neural networks consist of a sequence of layers, in which each
layer performs some processing on the information from the previous layer. A
downside to this approach is that each layer (or module, as multiple modules
can operate in parallel) is tasked with processing the entire hidden state,
rather than a particular part of the state which is most relevant for that
module. Methods which only operate on a small number of input variables are an
essential part of most programming languages, and they allow for improved
modularity and code re-usability. Our proposed method, Neural Function Modules
(NFM), aims to introduce the same structural capability into deep learning.
Most of the work in the context of feed-forward networks combining top-down and
bottom-up feedback is limited to classification problems. The key contribution
of our work is to combine attention, sparsity, top-down and bottom-up feedback,
in a flexible algorithm which, as we show, improves the results in standard
classification, out-of-domain generalization, generative modeling, and learning
representations in the context of reinforcement learning.
</p>
<a href="http://arxiv.org/abs/2010.08012" target="_blank">arXiv:2010.08012</a> [<a href="http://arxiv.org/pdf/2010.08012" target="_blank">pdf</a>]

<h2>Applicability and Challenges of Deep Reinforcement Learning for Satellite Frequency Plan Design. (arXiv:2010.08015v1 [cs.LG])</h2>
<h3>Juan Jose Garau Luis, Edward Crawley, Bruce Cameron</h3>
<p>The study and benchmarking of Deep Reinforcement Learning (DRL) models has
become a trend in many industries, including aerospace engineering and
communications. Recent studies in these fields propose these kinds of models to
address certain complex real-time decision-making problems in which classic
approaches do not meet time requirements or fail to obtain optimal solutions.
While the good performance of DRL models has been proved for specific use cases
or scenarios, most studies do not discuss the compromises of such models. In
this paper we explore the tradeoffs of different elements of DRL models and how
they might impact the final performance. To that end, we choose the Frequency
Plan Design (FPD) problem in the context of multibeam satellite constellations
as our use case and propose a DRL model to address it. We identify six
different core elements that have a major effect in its performance: the
policy, the policy optimizer, the state, action, and reward representations,
and the training environment. We analyze different alternatives for each of
these elements and characterize their effect. We also use multiple environments
to account for different scenarios in which we vary the dimensionality or make
the environment non-stationary. Our findings show that DRL is a potential
method to address the FPD problem in real operations, especially because of its
speed in decision-making. However, no single DRL model is able to outperform
the rest in all scenarios, and the best approach for each of the six core
elements depends on the features of the operation environment. While we agree
on the potential of DRL to solve future complex problems in the aerospace
industry, we also reflect on the importance of designing appropriate models and
training procedures, understanding the applicability of such models, and
reporting the main performance tradeoffs.
</p>
<a href="http://arxiv.org/abs/2010.08015" target="_blank">arXiv:2010.08015</a> [<a href="http://arxiv.org/pdf/2010.08015" target="_blank">pdf</a>]

<h2>On the Exploration of Incremental Learning for Fine-grained Image Retrieval. (arXiv:2010.08020v1 [cs.CV])</h2>
<h3>Wei Chen, Yu Liu, Weiping Wang, Tinne Tuytelaars, Erwin M. Bakker, Michael Lew</h3>
<p>In this paper, we consider the problem of fine-grained image retrieval in an
incremental setting, when new categories are added over time. On the one hand,
repeatedly training the representation on the extended dataset is
time-consuming. On the other hand, fine-tuning the learned representation only
with the new classes leads to catastrophic forgetting. To this end, we propose
an incremental learning method to mitigate retrieval performance degradation
caused by the forgetting issue. Without accessing any samples of the original
classes, the classifier of the original network provides soft "labels" to
transfer knowledge to train the adaptive network, so as to preserve the
previous capability for classification. More importantly, a regularization
function based on Maximum Mean Discrepancy is devised to minimize the
discrepancy of new classes features from the original network and the adaptive
network, respectively. Extensive experiments on two datasets show that our
method effectively mitigates the catastrophic forgetting on the original
classes while achieving high performance on the new classes.
</p>
<a href="http://arxiv.org/abs/2010.08020" target="_blank">arXiv:2010.08020</a> [<a href="http://arxiv.org/pdf/2010.08020" target="_blank">pdf</a>]

<h2>Cooperative-Competitive Reinforcement Learning with History-Dependent Rewards. (arXiv:2010.08030v1 [cs.LG])</h2>
<h3>Keyang He, Bikramjit Banerjee, Prashant Doshi</h3>
<p>Consider a typical organization whose worker agents seek to collectively
cooperate for its general betterment. However, each individual agent
simultaneously seeks to act to secure a larger chunk than its co-workers of the
annual increment in compensation, which usually comes from a {\em fixed} pot.
As such, the individual agent in the organization must cooperate and compete.
Another feature of many organizations is that a worker receives a bonus, which
is often a fraction of previous year's total profit. As such, the agent derives
a reward that is also partly dependent on historical performance. How should
the individual agent decide to act in this context? Few methods for the mixed
cooperative-competitive setting have been presented in recent years, but these
are challenged by problem domains whose reward functions do not depend on the
current state and action only. Recent deep multi-agent reinforcement learning
(MARL) methods using long short-term memory (LSTM) may be used, but these adopt
a joint perspective to the interaction or require explicit exchange of
information among the agents to promote cooperation, which may not be possible
under competition. In this paper, we first show that the agent's
decision-making problem can be modeled as an interactive partially observable
Markov decision process (I-POMDP) that captures the dynamic of a
history-dependent reward. We present an interactive advantage actor-critic
method (IA2C$^+$), which combines the independent advantage actor-critic
network with a belief filter that maintains a belief distribution over other
agents' models. Empirical results show that IA2C$^+$ learns the optimal policy
faster and more robustly than several other baselines including one that uses a
LSTM, even when attributed models are incorrect.
</p>
<a href="http://arxiv.org/abs/2010.08030" target="_blank">arXiv:2010.08030</a> [<a href="http://arxiv.org/pdf/2010.08030" target="_blank">pdf</a>]

<h2>QReLU and m-QReLU: Two novel quantum activation functions to aid medical diagnostics. (arXiv:2010.08031v1 [cs.CV])</h2>
<h3>L. Parisi, D. Neagu, R. Ma, F. Campean</h3>
<p>The ReLU activation function (AF) has been extensively applied in deep neural
networks, in particular Convolutional Neural Networks (CNN), for image
classification despite its unresolved dying ReLU problem, which poses
challenges to reliable applications. This issue has obvious important
implications for critical applications, such as those in healthcare. Recent
approaches are just proposing variations of the activation function within the
same unresolved dying ReLU challenge. This contribution reports a different
research direction by investigating the development of an innovative quantum
approach to the ReLU AF that avoids the dying ReLU problem by disruptive
design. The Leaky ReLU was leveraged as a baseline on which the two quantum
principles of entanglement and superposition were applied to derive the
proposed Quantum ReLU (QReLU) and the modified-QReLU (m-QReLU) activation
functions. Both QReLU and m-QReLU are implemented and made freely available in
TensorFlow and Keras. This original approach is effective and validated
extensively in case studies that facilitate the detection of COVID-19 and
Parkinson Disease (PD) from medical images. The two novel AFs were evaluated in
a two-layered CNN against nine ReLU-based AFs on seven benchmark datasets,
including images of spiral drawings taken via graphic tablets from patients
with Parkinson Disease and healthy subjects, and point-of-care ultrasound
images on the lungs of patients with COVID-19, those with pneumonia and healthy
controls. Despite a higher computational cost, results indicated an overall
higher classification accuracy, precision, recall and F1-score brought about by
either quantum AFs on five of the seven bench-mark datasets, thus demonstrating
its potential to be the new benchmark or gold standard AF in CNNs and aid image
classification tasks involved in critical applications, such as medical
diagnoses of COVID-19 and PD.
</p>
<a href="http://arxiv.org/abs/2010.08031" target="_blank">arXiv:2010.08031</a> [<a href="http://arxiv.org/pdf/2010.08031" target="_blank">pdf</a>]

<h2>Why Layer-Wise Learning is Hard to Scale-up and a Possible Solution via Accelerated Downsampling. (arXiv:2010.08038v1 [cs.CV])</h2>
<h3>Wenchi Ma, Miao Yu, Kaidong Li, Guanghui Wang</h3>
<p>Layer-wise learning, as an alternative to global back-propagation, is easy to
interpret, analyze, and it is memory efficient. Recent studies demonstrate that
layer-wise learning can achieve state-of-the-art performance in image
classification on various datasets. However, previous studies of layer-wise
learning are limited to networks with simple hierarchical structures, and the
performance decreases severely for deeper networks like ResNet. This paper, for
the first time, reveals the fundamental reason that impedes the scale-up of
layer-wise learning is due to the relatively poor separability of the feature
space in shallow layers. This argument is empirically verified by controlling
the intensity of the convolution operation in local layers. We discover that
the poorly-separable features from shallow layers are mismatched with the
strong supervision constraint throughout the entire network, making the
layer-wise learning sensitive to network depth. The paper further proposes a
downsampling acceleration approach to weaken the poor learning of shallow
layers so as to transfer the learning emphasis to deep feature space where the
separability matches better with the supervision restraint. Extensive
experiments have been conducted to verify the new finding and demonstrate the
advantages of the proposed downsampling acceleration in improving the
performance of layer-wise learning.
</p>
<a href="http://arxiv.org/abs/2010.08038" target="_blank">arXiv:2010.08038</a> [<a href="http://arxiv.org/pdf/2010.08038" target="_blank">pdf</a>]

<h2>Autotuning PolyBench Benchmarks with LLVM Clang/Polly Loop Optimization Pragmas Using Bayesian Optimization. (arXiv:2010.08040v1 [cs.PF])</h2>
<h3>Xingfu Wu, Michael Kruse, Prasanna Balaprakash, Hal Finkel, Paul Hovland, Valerie Taylor, Mary Hall</h3>
<p>An autotuning is an approach that explores a search space of possible
implementations/configurations of a kernel or an application by selecting and
evaluating a subset of implementations/configurations on a target platform
and/or use models to identify a high performance implementation/configuration.
In this paper, we develop an autotuning framework that leverages Bayesian
optimization to explore the parameter space search. We select six of the most
complex benchmarks from the application domains of the PolyBench benchmarks
(syr2k, 3mm, heat-3d, lu, covariance, and Floyd-Warshall) and apply the newly
developed LLVM Clang/Polly loop optimization pragmas to the benchmarks to
optimize them. We then use the autotuning framework to optimize the pragma
parameters to improve their performance. The experimental results show that our
autotuning approach outperforms the other compiling methods to provide the
smallest execution time for the benchmarks syr2k, 3mm, heat-3d, lu, and
covariance with two large datasets in 200 code evaluations for effectively
searching the parameter spaces with up to 170,368 different configurations. We
compare four different supervised learning methods within Bayesian optimization
and evaluate their effectiveness. We find that the Floyd-Warshall benchmark did
not benefit from autotuning because Polly uses heuristics to optimize the
benchmark to make it run much slower. To cope with this issue, we provide some
compiler option solutions to improve the performance.
</p>
<a href="http://arxiv.org/abs/2010.08040" target="_blank">arXiv:2010.08040</a> [<a href="http://arxiv.org/pdf/2010.08040" target="_blank">pdf</a>]

<h2>Decision Making Problems with Funnel Structure: A Multi-Task Learning Approach with Application to Email Marketing Campaigns. (arXiv:2010.08048v1 [stat.ML])</h2>
<h3>Ziping Xu, Amir Meisami, Ambuj Tewari</h3>
<p>This paper studies the decision making problem with Funnel Structure. Funnel
structure, a well-known concept in the marketing field, occurs in those systems
where the decision maker interacts with the environment in a layered manner
receiving far fewer observations from deep layers than shallow ones. For
example, in the email marketing campaign application, the layers correspond to
Open, Click and Purchase events. Conversions from Click to Purchase happen very
infrequently because a purchase cannot be made unless the link in an email is
clicked on.

We formulate this challenging decision making problem as a contextual bandit
with funnel structure and develop a multi-task learning algorithm that
mitigates the lack of sufficient observations from deeper layers. We analyze
both the prediction error and the regret of our algorithms. We verify our
theory on prediction errors through a simple simulation. Experiments on both a
simulated environment and an environment based on real-world data from a major
email marketing company show that our algorithms offer significant improvement
over previous methods.
</p>
<a href="http://arxiv.org/abs/2010.08048" target="_blank">arXiv:2010.08048</a> [<a href="http://arxiv.org/pdf/2010.08048" target="_blank">pdf</a>]

<h2>Program Equivalence for Assisted Grading of Functional Programs (Extended Version). (arXiv:2010.08051v1 [cs.PL])</h2>
<h3>Joshua Clune, Vijay Ramamurthy, Ruben Martins, Umut A. Acar</h3>
<p>In courses that involve programming assignments, giving meaningful feedback
to students is an important challenge. Human beings can give useful feedback by
manually grading the programs but this is a time-consuming, labor intensive,
and usually boring process. Automatic graders can be fast and scale well but
they usually provide poor feedback. Although there has been research on
improving automatic graders, research on scaling and improving human grading is
limited.

We propose to scale human grading by augmenting the manual grading process
with an equivalence algorithm that can identify the equivalences between
student submissions. This enables human graders to give targeted feedback for
multiple student submissions at once. Our technique is conservative in two
aspects. First, it identifies equivalence between submissions that are
algorithmically similar, e.g., it cannot identify the equivalence between
quicksort and mergesort. Second, it uses formal methods instead of clustering
algorithms from the machine learning literature. This allows us to prove a
soundness result that guarantees that submissions will never be clustered
together in error. Despite only reporting equivalence when there is algorithmic
similarity and the ability to formally prove equivalence, we show that our
technique can significantly reduce grading time for thousands of programming
submissions from an introductory functional programming course.
</p>
<a href="http://arxiv.org/abs/2010.08051" target="_blank">arXiv:2010.08051</a> [<a href="http://arxiv.org/pdf/2010.08051" target="_blank">pdf</a>]

<h2>Recurrent Distributed Reinforcement Learning for Partially Observable Robotic Assembly. (arXiv:2010.08052v1 [cs.RO])</h2>
<h3>Jieliang Luo, Hui Li</h3>
<p>In this work we solve for partially observable reinforcement learning (RL)
environments by adding recurrency. We focus on partially observable robotic
assembly tasks in the continuous action domain, with force/torque sensing being
the only observation. We have developed a new distributed RL agent, named
Recurrent Distributed DDPG (RD2), which adds a recurrent neural network layer
to Ape-X DDPG and makes two important improvements on prioritized experience
replay to stabilize training.

We demonstrate the effectiveness of RD2 on a variety of joint assembly tasks
and a partially observable version of the pendulum task from OpenAI Gym. Our
results show that RD2 is able to achieve better performance than Ape-X DDPG and
PPO with LSTM on partially observable tasks with varying complexity. We also
show that the trained models adapt well to different initial states and
different types of noise injected in the simulated environment. The video
presenting our experiments is available at https://sites.google.com/view/rd2-rl
</p>
<a href="http://arxiv.org/abs/2010.08052" target="_blank">arXiv:2010.08052</a> [<a href="http://arxiv.org/pdf/2010.08052" target="_blank">pdf</a>]

<h2>Robust Keypoint Detection and Pose Estimation of Robot Manipulators with Self-Occlusions via Sim-to-Real Transfer. (arXiv:2010.08054v1 [cs.RO])</h2>
<h3>Jingpei Lu, Florian Richter, Michael Yip</h3>
<p>Keypoint detection is an essential building block for many robotic
applications like motion capture and pose estimation. Historically, keypoints
are detected using uniquely engineered markers such as checkerboards,
fiducials, or markers. More recently, deep learning methods have been explored
as they have the ability to detect user-defined keypoints in a marker-less
manner. However, deep neural network (DNN) detectors can have an uneven
performance for different manually selected keypoints along the kinematic
chain. An example of this can be found on symmetric robotic tools where DNN
detectors cannot solve the correspondence problem correctly. In this work, we
propose a new and autonomous way to define the keypoint locations that
overcomes these challenges. The approach involves finding the optimal set of
keypoints on robotic manipulators for robust visual detection. Using a robotic
simulator as a medium, our algorithm utilizes synthetic data for DNN training,
and the proposed algorithm is used to optimize the selection of keypoints
through an iterative approach. The results show that when using the optimized
keypoints, the detection performance of the DNNs improved so significantly that
they can even be detected in cases of self-occlusion. We further use the
optimized keypoints for real robotic applications by using domain randomization
to bridge the reality gap between the simulator and the physical world. The
physical world experiments show how the proposed method can be applied to the
wide-breadth of robotic applications that require visual feedback, such as
camera-to-robot calibration, robotic tool tracking, and whole-arm pose
estimation.
</p>
<a href="http://arxiv.org/abs/2010.08054" target="_blank">arXiv:2010.08054</a> [<a href="http://arxiv.org/pdf/2010.08054" target="_blank">pdf</a>]

<h2>TextMage: The Automated Bangla Caption Generator Based On Deep Learning. (arXiv:2010.08066v1 [cs.CV])</h2>
<h3>Abrar Hasin Kamal, Md. Asifuzzaman Jishan, Nafees Mansoor</h3>
<p>Neural Networks and Deep Learning have seen an upsurge of research in the
past decade due to the improved results. Generates text from the given image is
a crucial task that requires the combination of both sectors which are computer
vision and natural language processing in order to understand an image and
represent it using a natural language. However existing works have all been
done on a particular lingual domain and on the same set of data. This leads to
the systems being developed to perform poorly on images that belong to specific
locales' geographical context. TextMage is a system that is capable of
understanding visual scenes that belong to the Bangladeshi geographical context
and use its knowledge to represent what it understands in Bengali. Hence, we
have trained a model on our previously developed and published dataset named
BanglaLekhaImageCaptions. This dataset contains 9,154 images along with two
annotations for each image. In order to access performance, the proposed model
has been implemented and evaluated.
</p>
<a href="http://arxiv.org/abs/2010.08066" target="_blank">arXiv:2010.08066</a> [<a href="http://arxiv.org/pdf/2010.08066" target="_blank">pdf</a>]

<h2>Performance evaluation and application of computation based low-cost homogeneous machine learning model algorithm for image classification. (arXiv:2010.08087v1 [cs.LG])</h2>
<h3>W. H. Huang</h3>
<p>The image classification machine learning model was trained with the
intention to predict the category of the input image. While multiple
state-of-the-art ensemble model methodologies are openly available, this paper
evaluates the performance of a low-cost, simple algorithm that would integrate
seamlessly into modern production-grade cloud-based applications. The
homogeneous models, trained with the full instead of subsets of data, contains
varying hyper-parameters and neural layers from one another. These models'
inferences will be processed by the new algorithm, which is loosely based on
conditional probability theories. The final output will be evaluated.
</p>
<a href="http://arxiv.org/abs/2010.08087" target="_blank">arXiv:2010.08087</a> [<a href="http://arxiv.org/pdf/2010.08087" target="_blank">pdf</a>]

<h2>Inferring symmetry in natural language. (arXiv:2010.08090v1 [cs.CL])</h2>
<h3>Chelsea Tanchip, Lei Yu, Aotao Xu, Yang Xu</h3>
<p>We present a methodological framework for inferring symmetry of verb
predicates in natural language. Empirical work on predicate symmetry has taken
two main approaches. The feature-based approach focuses on linguistic features
pertaining to symmetry. The context-based approach denies the existence of
absolute symmetry but instead argues that such inference is context dependent.
We develop methods that formalize these approaches and evaluate them against a
novel symmetry inference sentence (SIS) dataset comprised of 400 naturalistic
usages of literature-informed verbs spanning the spectrum of
symmetry-asymmetry. Our results show that a hybrid transfer learning model that
integrates linguistic features with contextualized language models most
faithfully predicts the empirical data. Our work integrates existing approaches
to symmetry in natural language and suggests how symmetry inference can improve
systematicity in state-of-the-art language models.
</p>
<a href="http://arxiv.org/abs/2010.08090" target="_blank">arXiv:2010.08090</a> [<a href="http://arxiv.org/pdf/2010.08090" target="_blank">pdf</a>]

<h2>PiRhDy: Learning Pitch-, Rhythm-, and Dynamics-aware Embeddings for Symbolic Music. (arXiv:2010.08091v1 [cs.SD])</h2>
<h3>Hongru Liang, Wenqiang Lei, Paul Yaozhu Chan, Zhenglu Yang, Maosong Sun, Tat-Seng Chua</h3>
<p>Definitive embeddings remain a fundamental challenge of computational
musicology for symbolic music in deep learning today. Analogous to natural
language, music can be modeled as a sequence of tokens. This motivates the
majority of existing solutions to explore the utilization of word embedding
models to build music embeddings. However, music differs from natural languages
in two key aspects: (1) musical token is multi-faceted -- it comprises of
pitch, rhythm and dynamics information; and (2) musical context is
two-dimensional -- each musical token is dependent on both melodic and harmonic
contexts. In this work, we provide a comprehensive solution by proposing a
novel framework named PiRhDy that integrates pitch, rhythm, and dynamics
information seamlessly. PiRhDy adopts a hierarchical strategy which can be
decomposed into two steps: (1) token (i.e., note event) modeling, which
separately represents pitch, rhythm, and dynamics and integrates them into a
single token embedding; and (2) context modeling, which utilizes melodic and
harmonic knowledge to train the token embedding. A thorough study was made on
each component and sub-strategy of PiRhDy. We further validate our embeddings
in three downstream tasks -- melody completion, accompaniment suggestion, and
genre classification. Results indicate a significant advancement of the neural
approach towards symbolic music as well as PiRhDy's potential as a pretrained
tool for a broad range of symbolic music applications.
</p>
<a href="http://arxiv.org/abs/2010.08091" target="_blank">arXiv:2010.08091</a> [<a href="http://arxiv.org/pdf/2010.08091" target="_blank">pdf</a>]

<h2>Smart Grid: A Survey of Architectural Elements, Machine Learning and Deep Learning Applications and Future Directions. (arXiv:2010.08094v1 [cs.AI])</h2>
<h3>Navod Neranjan Thilakarathne, Mohan Krishna Kagita, Dr. Surekha Lanka, Hussain Ahmad</h3>
<p>The Smart grid (SG), generally known as the next-generation power grid
emerged as a replacement for ill-suited power systems in the 21st century. It
is in-tegrated with advanced communication and computing capabilities, thus it
is ex-pected to enhance the reliability and the efficiency of energy
distribution with minimum effects. With the massive infrastructure it holds and
the underlying communication network in the system, it introduced a large
volume of data that demands various techniques for proper analysis and decision
making. Big data analytics, machine learning (ML), and deep learning (DL) plays
a key role when it comes to the analysis of this massive amount of data and
generation of valuable insights. This paper explores and surveys the Smart grid
architectural elements, machine learning, and deep learning-based applications
and approaches in the context of the Smart grid. In addition in terms of
machine learning-based data an-alytics, this paper highlights the limitations
of the current research and highlights future directions as well.
</p>
<a href="http://arxiv.org/abs/2010.08094" target="_blank">arXiv:2010.08094</a> [<a href="http://arxiv.org/pdf/2010.08094" target="_blank">pdf</a>]

<h2>Agile Robot Navigation through Hallucinated Learning and Sober Deployment. (arXiv:2010.08098v1 [cs.RO])</h2>
<h3>Xuesu Xiao, Bo Liu, Peter Stone</h3>
<p>Learning from Hallucination (LfH) is a recent machine learning paradigm for
autonomous navigation, which uses training data collected in completely safe
environments and adds numerous imaginary obstacles to make the environment
densely constrained, to learn navigation planners that produce feasible
navigation even in highly constrained (more dangerous) spaces. However, LfH
requires hallucinating the robot perception during deployment to match with the
hallucinated training data, which creates a need for sometimes-infeasible prior
knowledge and tends to generate very conservative planning. In this work, we
propose a new LfH paradigm that does not require runtime hallucination---a
feature we call "sober deployment"---and can therefore adapt to more realistic
navigation scenarios. This novel Hallucinated Learning and Sober Deployment
(HLSD) paradigm is tested in a benchmark testbed of 300 simulated navigation
environments with a wide range of difficulty levels, and in the real-world. In
most cases, HLSD outperforms both the original LfH method and a classical
navigation planner.
</p>
<a href="http://arxiv.org/abs/2010.08098" target="_blank">arXiv:2010.08098</a> [<a href="http://arxiv.org/pdf/2010.08098" target="_blank">pdf</a>]

<h2>Modeling Token-level Uncertainty to Learn Unknown Concepts in SLU via Calibrated Dirichlet Prior RNN. (arXiv:2010.08101v1 [cs.AI])</h2>
<h3>Yilin Shen, Wenhu Chen, Hongxia Jin</h3>
<p>One major task of spoken language understanding (SLU) in modern personal
assistants is to extract semantic concepts from an utterance, called slot
filling. Although existing slot filling models attempted to improve extracting
new concepts that are not seen in training data, the performance in practice is
still not satisfied. Recent research collected question and answer annotated
data to learn what is unknown and should be asked, yet not practically scalable
due to the heavy data collection effort. In this paper, we incorporate
softmax-based slot filling neural architectures to model the sequence
uncertainty without question supervision. We design a Dirichlet Prior RNN to
model high-order uncertainty by degenerating as softmax layer for RNN model
training. To further enhance the uncertainty modeling robustness, we propose a
novel multi-task training to calibrate the Dirichlet concentration parameters.
We collect unseen concepts to create two test datasets from SLU benchmark
datasets Snips and ATIS. On these two and another existing Concept Learning
benchmark datasets, we show that our approach significantly outperforms
state-of-the-art approaches by up to 8.18%. Our method is generic and can be
applied to any RNN or Transformer based slot filling models with a softmax
layer.
</p>
<a href="http://arxiv.org/abs/2010.08101" target="_blank">arXiv:2010.08101</a> [<a href="http://arxiv.org/pdf/2010.08101" target="_blank">pdf</a>]

<h2>Physics-informed GANs for Coastal Flood Visualization. (arXiv:2010.08103v1 [cs.CV])</h2>
<h3>Bj&#xf6;rn L&#xfc;tjens, Brandon Leshchinskiy, Christian Requena-Mesa, Farrukh Chishtie, Natalia D&#xed;az-Rodriguez, Oc&#xe9;ane Boulais, Aaron Pi&#xf1;a, Dava Newman, Alexander Lavin, Yarin Gal, Chedy Ra&#xef;ssi</h3>
<p>As climate change increases the intensity of natural disasters, society needs
better tools for adaptation. Floods, for example, are the most frequent natural
disaster, but during hurricanes the area is largely covered by clouds and
emergency managers must rely on nonintuitive flood visualizations for mission
planning. To assist these emergency managers, we have created a deep learning
pipeline that generates visual satellite images of current and future coastal
flooding. We advanced a state-of-the-art GAN called pix2pixHD, such that it
produces imagery that is physically-consistent with the output of an
expert-validated storm surge model (NOAA SLOSH). By evaluating the imagery
relative to physics-based flood maps, we find that our proposed framework
outperforms baseline models in both physical-consistency and photorealism.
While this work focused on the visualization of coastal floods, we envision the
creation of a global visualization of how climate change will shape our earth.
</p>
<a href="http://arxiv.org/abs/2010.08103" target="_blank">arXiv:2010.08103</a> [<a href="http://arxiv.org/pdf/2010.08103" target="_blank">pdf</a>]

<h2>Decentralized Knowledge Graph Representation Learning. (arXiv:2010.08114v1 [cs.LG])</h2>
<h3>Lingbing Guo, Weiqing Wang, Zequn Sun, Chenghao Liu, Wei Hu</h3>
<p>Knowledge graph (KG) representation learning methods have achieved
competitive performance in many KG-oriented tasks, among which the best ones
are usually based on graph neural networks (GNNs), a powerful family of
networks that learns the representation of an entity by aggregating the
features of its neighbors and itself. However, many KG representation learning
scenarios only provide the structure information that describes the
relationships among entities, causing that entities have no input features. In
this case, existing aggregation mechanisms are incapable of inducing embeddings
of unseen entities as these entities have no pre-defined features for
aggregation. In this paper, we present a decentralized KG representation
learning approach, decentRL, which encodes each entity from and only from the
embeddings of its neighbors. For optimization, we design an algorithm to
distill knowledge from the model itself such that the output embeddings can
continuously gain knowledge from the corresponding original embeddings.
Extensive experiments show that the proposed approach performed better than
many cutting-edge models on the entity alignment task, and achieved competitive
performance on the entity prediction task. Furthermore, under the inductive
setting, it significantly outperformed all baselines on both tasks.
</p>
<a href="http://arxiv.org/abs/2010.08114" target="_blank">arXiv:2010.08114</a> [<a href="http://arxiv.org/pdf/2010.08114" target="_blank">pdf</a>]

<h2>Early-stage COVID-19 diagnosis in presence of limited posteroanterior chest X-ray images via novel Pinball-OCSVM. (arXiv:2010.08115v1 [eess.IV])</h2>
<h3>Sanjay Kumar Sonbhadra, Sonali Agarwal, P. Nagabhushan</h3>
<p>It is evident that the infection with this severe acute respiratory syndrome
coronavirus 2 (SARS-CoV-2) starts with the upper respiratory tract and as the
virus grows, the infection can progress to lungs and develop pneumonia.
According to the statistics, approximately 14\% of the infected people with
COVID-19 have severe cough and shortness of breath due to pneumonia, because as
the viral infection increases, it damages the alveoli (small air sacs) and
surrounding tissues. The conventional way of COVID-19 diagnosis is reverse
transcription polymerase chain reaction (RT-PCR), which is less sensitive
during early stages specially, if the patient is asymptomatic that may further
lead to more severe pneumonia. To overcome this problem an early diagnosis
method is proposed in this paper via one-class classification approach using a
novel pinball loss function based one-class support vector machine (PB-OCSVM)
considering posteroanterior chest X-ray images. Recently, several automated
COVID-19 diagnosis models have been proposed based on various deep learning
architectures to identify pulmonary infections using publicly available chest
X-ray (CXR) where the presence of less number of COVID-19 positive samples
compared to other classes (normal, pneumonia and Tuberculosis) raises the
challenge for unbiased learning in deep learning models that has been solved
using class balancing techniques which however should be avoided in any medical
diagnosis process. Inspired by this phenomenon, this article proposes a novel
PB-OCSVM model to work in presence of limited COVID-19 positive CXR samples
with objectives to maximize the learning efficiency while minimize the
false-positive and false-negative predictions. The proposed model outperformed
over recently published deep learning approaches where accuracy, precision,
specificity and sensitivity are used as performance measure parameters.
</p>
<a href="http://arxiv.org/abs/2010.08115" target="_blank">arXiv:2010.08115</a> [<a href="http://arxiv.org/pdf/2010.08115" target="_blank">pdf</a>]

<h2>Revenue and Energy Efficiency-Driven Delay Constrained Computing Task Offloading and Resource Allocation in a Vehicular Edge Computing Network: A Deep Reinforcement Learning Approach. (arXiv:2010.08119v1 [cs.MM])</h2>
<h3>Xinyu Huang, Lijun He, Xing Chen, Liejun Wang, Fan Li</h3>
<p>For in-vehicle application,task type and vehicle state information, i.e.,
vehicle speed, bear a significant impact on the task delay requirement.
However, the joint impact of task type and vehicle speed on the task delay
constraint has not been studied, and this lack of study may cause a mismatch
between the requirement of the task delay and allocated computation and
wireless resources. In this paper, we propose a joint task type and vehicle
speed-aware task offloading and resource allocation strategy to decrease the
vehicl's energy cost for executing tasks and increase the revenue of the
vehicle for processing tasks within the delay constraint. First, we establish
the joint task type and vehicle speed-aware delay constraint model. Then, the
delay, energy cost and revenue for task execution in the vehicular edge
computing (VEC) server, local terminal and terminals of other vehicles are
calculated. Based on the energy cost and revenue from task execution,the
utility function of the vehicle is acquired. Next, we formulate a joint
optimization of task offloading and resource allocation to maximize the utility
level of the vehicles subject to the constraints of task delay, computation
resources and wireless resources. To obtain a near-optimal solution of the
formulated problem, a joint offloading and resource allocation based on the
multi-agent deep deterministic policy gradient (JORA-MADDPG) algorithm is
proposed to maximize the utility level of vehicles. Simulation results show
that our algorithm can achieve superior performance in task completion delay,
vehicles' energy cost and processing revenue.
</p>
<a href="http://arxiv.org/abs/2010.08119" target="_blank">arXiv:2010.08119</a> [<a href="http://arxiv.org/pdf/2010.08119" target="_blank">pdf</a>]

<h2>Melody Classifier with Stacked-LSTM. (arXiv:2010.08123v1 [cs.SD])</h2>
<h3>You Li, Zhuowen Lin</h3>
<p>Attempts to use neural network models for music generation have been common
in recent years, and some of them have achieved good results. However, the
research on the evaluation system of machine-generated music is still at a
relatively early stage. This paper proposes a stacked-LSTM binary classifier
based on a language model, which can distinguish the human composer's work from
the machine-generated melody by learning the MIDI file's pitch, position, and
duration.
</p>
<a href="http://arxiv.org/abs/2010.08123" target="_blank">arXiv:2010.08123</a> [<a href="http://arxiv.org/pdf/2010.08123" target="_blank">pdf</a>]

<h2>Risk-Aware Decision Making in Service Robots to Minimize Risk of Patient Falls in Hospitals. (arXiv:2010.08124v1 [cs.RO])</h2>
<h3>Roya Sabbagh Novin, Amir Yazdani, Andrew Merryweather, Tucker Hermans</h3>
<p>Planning under uncertainty is a crucial capability for autonomous systems to
operate reliably in uncertain and dynamic environments. The concern of patient
safety becomes even more critical in healthcare settings where robots interact
with humans. In this paper, we propose a novel risk-aware planning framework to
minimize the risk of patient falls by providing a patient with an assistive
device. Our approach combines learning-based prediction with model-based
control to plan for the fall prevention tasks. This provides advantages
compared to end-to-end learning methods in which the robot's performance is
limited to specific scenarios, or purely model-based approaches that use
relatively simple function approximators and are prone to high modeling errors.
We compare two different risk metrics and the combination of them and report
the results from various simulated scenarios. The results show that using the
proposed cost function, the robot can plan interventions to avoid high fall
score events.
</p>
<a href="http://arxiv.org/abs/2010.08124" target="_blank">arXiv:2010.08124</a> [<a href="http://arxiv.org/pdf/2010.08124" target="_blank">pdf</a>]

<h2>Testing the Quantitative Spacetime Hypothesis using Artificial Narrative Comprehension (I) : Bootstrapping Meaning from Episodic Narrative viewed as a Feature Landscape. (arXiv:2010.08126v1 [cs.AI])</h2>
<h3>Mark Burgess</h3>
<p>The problem of extracting important and meaningful parts of a sensory data
stream, without prior training, is studied for symbolic sequences, by using
textual narrative as a test case. This is part of a larger study concerning the
extraction of concepts from spacetime processes, and their knowledge
representations within hybrid symbolic-learning `Artificial Intelligence'. Most
approaches to text analysis make extensive use of the evolved human sense of
language and semantics. In this work, streams are parsed without knowledge of
semantics, using only measurable patterns (size and time) within the changing
stream of symbols -- as an event `landscape'. This is a form of interferometry.
Using lightweight procedures that can be run in just a few seconds on a single
CPU, this work studies the validity of the Semantic Spacetime Hypothesis, for
the extraction of concepts as process invariants. This `semantic preprocessor'
may then act as a front-end for more sophisticated long-term graph-based
learning techniques. The results suggest that what we consider important and
interesting about sensory experience is not solely based on higher reasoning,
but on simple spacetime process cues, and this may be how cognitive processing
is bootstrapped in the beginning.
</p>
<a href="http://arxiv.org/abs/2010.08126" target="_blank">arXiv:2010.08126</a> [<a href="http://arxiv.org/pdf/2010.08126" target="_blank">pdf</a>]

<h2>Input-Aware Dynamic Backdoor Attack. (arXiv:2010.08138v1 [cs.CR])</h2>
<h3>Anh Nguyen, Anh Tran</h3>
<p>In recent years, neural backdoor attack has been considered to be a potential
security threat to deep learning systems. Such systems, while achieving the
state-of-the-art performance on clean data, perform abnormally on inputs with
predefined triggers. Current backdoor techniques, however, rely on uniform
trigger patterns, which are easily detected and mitigated by current defense
methods. In this work, we propose a novel backdoor attack technique in which
the triggers vary from input to input. To achieve this goal, we implement an
input-aware trigger generator driven by diversity loss. A novel cross-trigger
test is applied to enforce trigger nonreusablity, making backdoor verification
impossible. Experiments show that our method is efficient in various attack
scenarios as well as multiple datasets. We further demonstrate that our
backdoor can bypass the state of the art defense methods. An analysis with a
famous neural network inspector again proves the stealthiness of the proposed
attack. Our code is publicly available at
https://github.com/VinAIResearch/input-aware-backdoor-attack-release.
</p>
<a href="http://arxiv.org/abs/2010.08138" target="_blank">arXiv:2010.08138</a> [<a href="http://arxiv.org/pdf/2010.08138" target="_blank">pdf</a>]

<h2>Monitoring Trust in Human-Machine Interactions for Public Sector Applications. (arXiv:2010.08140v1 [cs.AI])</h2>
<h3>Farhana Faruqe, Ryan Watkins, Larry Medsker</h3>
<p>The work reported here addresses the capacity of psychophysiological sensors
and measures using Electroencephalogram (EEG) and Galvanic Skin Response (GSR)
to detect levels of trust for humans using AI-supported Human-Machine
Interaction (HMI). Improvements to the analysis of EEG and GSR data may create
models that perform as well, or better than, traditional tools. A challenge to
analyzing the EEG and GSR data is the large amount of training data required
due to a large number of variables in the measurements. Researchers have
routinely used standard machine-learning classifiers like artificial neural
networks (ANN), support vector machines (SVM), and K-nearest neighbors (KNN).
Traditionally, these have provided few insights into which features of the EEG
and GSR data facilitate the more and least accurate predictions - thus making
it harder to improve the HMI and human-machine trust relationship. A key
ingredient to applying trust-sensor research results to practical situations
and monitoring trust in work environments is the understanding of which key
features are contributing to trust and then reducing the amount of data needed
for practical applications. We used the Local Interpretable Model-agnostic
Explanations (LIME) model as a process to reduce the volume of data required to
monitor and enhance trust in HMI systems - a technology that could be valuable
for governmental and public sector applications. Explainable AI can make HMI
systems transparent and promote trust. From customer service in government
agencies and community-level non-profit public service organizations to
national military and cybersecurity institutions, many public sector
organizations are increasingly concerned to have effective and ethical HMI with
services that are trustworthy, unbiased, and free of unintended negative
consequences.
</p>
<a href="http://arxiv.org/abs/2010.08140" target="_blank">arXiv:2010.08140</a> [<a href="http://arxiv.org/pdf/2010.08140" target="_blank">pdf</a>]

<h2>Autonomous Control of a Particle Accelerator using Deep Reinforcement Learning. (arXiv:2010.08141v1 [cs.AI])</h2>
<h3>Xiaoying Pang, Sunil Thulasidasan, Larry Rybarcyk</h3>
<p>We describe an approach to learning optimal control policies for a large,
linear particle accelerator using deep reinforcement learning coupled with a
high-fidelity physics engine. The framework consists of an AI controller that
uses deep neural nets for state and action-space representation and learns
optimal policies using reward signals that are provided by the physics
simulator. For this work, we only focus on controlling a small section of the
entire accelerator. Nevertheless, initial results indicate that we can achieve
better-than-human level performance in terms of particle beam current and
distribution. The ultimate goal of this line of work is to substantially reduce
the tuning time for such facilities by orders of magnitude, and achieve
near-autonomous control.
</p>
<a href="http://arxiv.org/abs/2010.08141" target="_blank">arXiv:2010.08141</a> [<a href="http://arxiv.org/pdf/2010.08141" target="_blank">pdf</a>]

<h2>Taking A Closer Look at Synthesis: Fine-grained Attribute Analysis for Person Re-Identification. (arXiv:2010.08145v1 [cs.CV])</h2>
<h3>Suncheng Xiang, Yuzhuo Fu, Guanjie You, Ting Liu</h3>
<p>Person re-identification (re-ID) plays an important role in applications such
as public security and video surveillance. Recently, learning from synthetic
data, which benefits from the popularity of synthetic data engine, has achieved
remarkable performance. However, in pursuit of high accuracy, researchers in
the academic always focus on training with large-scale datasets at a high cost
of time and label expenses, while neglect to explore the potential of
performing efficient training from millions of synthetic data. To facilitate
development in this field, we reviewed the previously developed synthetic
dataset GPR and built an improved one (GPR+) with larger number of identities
and distinguished attributes. Based on it, we quantitatively analyze the
influence of dataset attribute on re-ID system. To our best knowledge, we are
among the first attempts to explicitly dissect person re-ID from the aspect of
attribute on synthetic dataset. This research helps us have a deeper
understanding of the fundamental problems in person re-ID, which also provides
useful insights for dataset building and future practical usage.
</p>
<a href="http://arxiv.org/abs/2010.08145" target="_blank">arXiv:2010.08145</a> [<a href="http://arxiv.org/pdf/2010.08145" target="_blank">pdf</a>]

<h2>Online Decision Trees with Fairness. (arXiv:2010.08146v1 [cs.LG])</h2>
<h3>Wenbin Zhang, Liang Zhao</h3>
<p>While artificial intelligence (AI)-based decision-making systems are
increasingly popular, significant concerns on the potential discrimination
during the AI decision-making process have been observed. For example, the
distribution of predictions is usually biased and dependents on the sensitive
attributes (e.g., gender and ethnicity). Numerous approaches have therefore
been proposed to develop decision-making systems that are
discrimination-conscious by-design, which are typically batch-based and require
the simultaneous availability of all the training data for model learning.
However, in the real-world, the data streams usually come on the fly which
requires the model to process each input data once "on arrival" and without the
need for storage and reprocessing. In addition, the data streams might also
evolve over time, which further requires the model to be able to simultaneously
adapt to non-stationary data distributions and time-evolving bias patterns,
with an effective and robust trade-off between accuracy and fairness. In this
paper, we propose a novel framework of online decision tree with fairness in
the data stream with possible distribution drifting. Specifically, first, we
propose two novel fairness splitting criteria that encode the data as well as
possible, while simultaneously removing dependence on the sensitive attributes,
and further adapts to non-stationary distribution with fine-grained control
when needed. Second, we propose two fairness decision tree online growth
algorithms that fulfills different online fair decision-making requirements.
Our experiments show that our algorithms are able to deal with discrimination
in massive and non-stationary streaming environments, with a better trade-off
between fairness and predictive performance.
</p>
<a href="http://arxiv.org/abs/2010.08146" target="_blank">arXiv:2010.08146</a> [<a href="http://arxiv.org/pdf/2010.08146" target="_blank">pdf</a>]

<h2>On the exact computation of linear frequency principle dynamics and its generalization. (arXiv:2010.08153v1 [cs.LG])</h2>
<h3>Tao Luo, Zheng Ma, Zhi-Qin John Xu, Yaoyu Zhang</h3>
<p>Recent works show an intriguing phenomenon of Frequency Principle
(F-Principle) that deep neural networks (DNNs) fit the target function from low
to high frequency during the training, which provides insight into the training
and generalization behavior of DNNs in complex tasks. In this paper, through
analysis of an infinite-width two-layer NN in the neural tangent kernel (NTK)
regime, we derive the exact differential equation, namely Linear
Frequency-Principle (LFP) model, governing the evolution of NN output function
in the frequency domain during the training. Our exact computation applies for
general activation functions with no assumption on size and distribution of
training data. This LFP model unravels that higher frequencies evolve
polynomially or exponentially slower than lower frequencies depending on the
smoothness/regularity of the activation function. We further bridge the gap
between training dynamics and generalization by proving that LFP model
implicitly minimizes a Frequency-Principle norm (FP-norm) of the learned
function, by which higher frequencies are more severely penalized depending on
the inverse of their evolution rate. Finally, we derive an \textit{a priori}
generalization error bound controlled by the FP-norm of the target function,
which provides a theoretical justification for the empirical results that DNNs
often generalize well for low frequency functions.
</p>
<a href="http://arxiv.org/abs/2010.08153" target="_blank">arXiv:2010.08153</a> [<a href="http://arxiv.org/pdf/2010.08153" target="_blank">pdf</a>]

<h2>ALdataset: a benchmark for pool-based active learning. (arXiv:2010.08161v1 [cs.LG])</h2>
<h3>Xueying Zhan, Antoni Bert Chan</h3>
<p>Active learning (AL) is a subfield of machine learning (ML) in which a
learning algorithm could achieve good accuracy with less training samples by
interactively querying a user/oracle to label new data points. Pool-based AL is
well-motivated in many ML tasks, where unlabeled data is abundant, but their
labels are hard to obtain. Although many pool-based AL methods have been
developed, the lack of a comparative benchmarking and integration of techniques
makes it difficult to: 1) determine the current state-of-the-art technique; 2)
evaluate the relative benefit of new methods for various properties of the
dataset; 3) understand what specific problems merit greater attention; and 4)
measure the progress of the field over time. To conduct easier comparative
evaluation among AL methods, we present a benchmark task for pool-based active
learning, which consists of benchmarking datasets and quantitative metrics that
summarize overall performance. We present experiment results for various active
learning strategies, both recently proposed and classic highly-cited methods,
and draw insights from the results.
</p>
<a href="http://arxiv.org/abs/2010.08161" target="_blank">arXiv:2010.08161</a> [<a href="http://arxiv.org/pdf/2010.08161" target="_blank">pdf</a>]

<h2>SidechainNet: An All-Atom Protein Structure Dataset for Machine Learning. (arXiv:2010.08162v1 [q-bio.BM])</h2>
<h3>Jonathan E. King, David Ryan Koes</h3>
<p>Despite recent advancements in deep learning methods for protein structure
prediction and representation, little focus has been directed at the
simultaneous inclusion and prediction of protein backbone and sidechain
structure information. We present SidechainNet, a new dataset that directly
extends the ProteinNet dataset. SidechainNet includes angle and atomic
coordinate information capable of describing all heavy atoms of each protein
structure. In this paper, we first provide background information on the
availability of protein structure data and the significance of ProteinNet.
Thereafter, we argue for the potentially beneficial inclusion of sidechain
information through SidechainNet, describe the process by which we organize
SidechainNet, and provide a software package
(https://github.com/jonathanking/sidechainnet) for data manipulation and
training with machine learning models.
</p>
<a href="http://arxiv.org/abs/2010.08162" target="_blank">arXiv:2010.08162</a> [<a href="http://arxiv.org/pdf/2010.08162" target="_blank">pdf</a>]

<h2>A Generalizable and Accessible Approach to Machine Learning with Global Satellite Imagery. (arXiv:2010.08168v1 [cs.LG])</h2>
<h3>Esther Rolf, Jonathan Proctor, Tamma Carleton, Ian Bolliger, Vaishaal Shankar, Miyabi Ishihara, Benjamin Recht, Solomon Hsiang</h3>
<p>Combining satellite imagery with machine learning (SIML) has the potential to
address global challenges by remotely estimating socioeconomic and
environmental conditions in data-poor regions, yet the resource requirements of
SIML limit its accessibility and use. We show that a single encoding of
satellite imagery can generalize across diverse prediction tasks (e.g. forest
cover, house price, road length). Our method achieves accuracy competitive with
deep neural networks at orders of magnitude lower computational cost, scales
globally, delivers label super-resolution predictions, and facilitates
characterizations of uncertainty. Since image encodings are shared across
tasks, they can be centrally computed and distributed to unlimited researchers,
who need only fit a linear regression to their own ground truth data in order
to achieve state-of-the-art SIML performance.
</p>
<a href="http://arxiv.org/abs/2010.08168" target="_blank">arXiv:2010.08168</a> [<a href="http://arxiv.org/pdf/2010.08168" target="_blank">pdf</a>]

<h2>Uncertainty-aware Contact-safe Model-based Reinforcement Learning. (arXiv:2010.08169v1 [cs.RO])</h2>
<h3>Cheng-Yu Kuo, Andreas Schaarschmidt, Yunduan Cui, Tamim Asfour, Takamitsu Matsubara</h3>
<p>This paper presents contact-safe Model-based Reinforcement Learning (MBRL)
for robot applications that achieves contact-safe behaviors in the learning
process. In typical MBRL, we cannot expect the data-driven model to generate
accurate and reliable policies to the intended robotic tasks during the
learning process due to data scarcity. Operating these unreliable policies in a
contact-rich environment could cause damage to the robot and its surroundings.
To alleviate the risk of causing damage through unexpected intensive physical
contacts, we present the contact-safe MBRL that associates the probabilistic
Model Predictive Control's (pMPC) control limits with the model uncertainty so
that the allowed acceleration of controlled behavior is adjusted according to
learning progress. Control planning with such uncertainty-aware control limits
is formulated as a deterministic MPC problem using a computationally-efficient
approximated GP dynamics and an approximated inference technique. Our
approach's effectiveness is evaluated through bowl mixing tasks with simulated
and real robots, scooping tasks with a real robot as examples of contact-rich
manipulation skills. (video: https://youtu.be/8uTDYYUKeFM)
</p>
<a href="http://arxiv.org/abs/2010.08169" target="_blank">arXiv:2010.08169</a> [<a href="http://arxiv.org/pdf/2010.08169" target="_blank">pdf</a>]

<h2>USelections 2020 analysis on Twitter and YouTube. (arXiv:2010.08183v1 [cs.SI])</h2>
<h3>Alexander Shevtsov, Maria Oikonomidou, Despoina Antonakaki, Polyvios Pratikakis, Sotiris Ioannidis</h3>
<p>The upcoming November 2020 presidential elections in the United States have
caused extensive discussions on social media. A part of the content on US
elections is organic, coming from users discussing their opinions of the
candidates, political positions, or relevant content presented on television.
Another significant part of the content generated originates from organized
campaigns, both official and by astroturfing.

In this study, we obtain approximately 7.5M tweets, containing 1.4M users,
based on prevalent hashtags related to US election 2020, as well as the related
YouTube links, contained in the Twitter dataset, likes, dislikes and comments
of the videos and conduct volume, sentiment and graph analysis on the
communities formed. Particularly, we study the daily traffic per prevalent
hashtags and show the evolution of the retweet graph from July to September
2020, highlighting the two main entities ('Biden' and 'Trump') contained in our
dataset. The results of sentiment analysis indicate that 45.7 express positive
sentiment towards Trump in Twitter and 33.8 positive sentiment towards Biden,
while 14.55 of users express positive sentiment in YouTube metadata gathered
towards Trump and 8.7 positive sentiment towards Biden.
</p>
<a href="http://arxiv.org/abs/2010.08183" target="_blank">arXiv:2010.08183</a> [<a href="http://arxiv.org/pdf/2010.08183" target="_blank">pdf</a>]

<h2>PRIMAL2: Pathfinding via Reinforcement and Imitation Multi-Agent Learning -- Lifelong. (arXiv:2010.08184v1 [cs.RO])</h2>
<h3>Mehul Damani, Zhiyao Luo, Emerson Wenzel, Guillaume Sartoretti</h3>
<p>Multi-agent path finding (MAPF) is an indispensable component of large-scale
robot deployments in numerous domains ranging from airport management to
warehouse automation. In particular, this work addresses lifelong MAPF (LMAPF)
-- an online variant of the problem where agents are immediately assigned a new
goal upon reaching their current one -- in dense and highly structured
environments, typical of real-world warehouses operations. Effectively solving
LMAPF in such environments requires expensive coordination between agents as
well as frequent replanning abilities, a daunting task for existing coupled and
decoupled approaches alike. With the purpose of achieving considerable agent
coordination without any compromise on reactivity and scalability, we introduce
PRIMAL2, a distributed reinforcement learning framework for LMAPF where agents
learn fully decentralized policies to reactively plan paths online in a
partially observable world. We extend our previous work, which was effective in
low-density sparsely occupied worlds, to highly structured and constrained
worlds by identifying behaviors and conventions which improve implicit agent
coordination, and enabling their learning through the construction of a novel
local agent observation and various training aids. We present extensive results
of PRIMAL2 in both MAPF and LMAPF environments with up to 1024 agents and
compare its performance to complete state-of-the-art planners. We
experimentally observe that agents successfully learn to follow ideal
conventions and can exhibit selfless coordinated maneuvers that maximize joint
rewards. We find that not only does PRIMAL2 significantly surpass our previous
work, it is also able to perform on par and even outperform state-of-the-art
planners in terms of throughput.
</p>
<a href="http://arxiv.org/abs/2010.08184" target="_blank">arXiv:2010.08184</a> [<a href="http://arxiv.org/pdf/2010.08184" target="_blank">pdf</a>]

<h2>How many images do I need? Understanding how sample size per class affects deep learning model performance metrics for balanced designs in autonomous wildlife monitoring. (arXiv:2010.08186v1 [cs.CV])</h2>
<h3>Saleh Shahinfar, Paul Meek, Greg Falzon</h3>
<p>Deep learning (DL) algorithms are the state of the art in automated
classification of wildlife camera trap images. The challenge is that the
ecologist cannot know in advance how many images per species they need to
collect for model training in order to achieve their desired classification
accuracy. In fact there is limited empirical evidence in the context of camera
trapping to demonstrate that increasing sample size will lead to improved
accuracy. In this study we explore in depth the issues of deep learning model
performance for progressively increasing per class (species) sample sizes. We
also provide ecologists with an approximation formula to estimate how many
images per animal species they need for certain accuracy level a priori. This
will help ecologists for optimal allocation of resources, work and efficient
study design. In order to investigate the effect of number of training images;
seven training sets with 10, 20, 50, 150, 500, 1000 images per class were
designed. Six deep learning architectures namely ResNet-18, ResNet-50,
ResNet-152, DnsNet-121, DnsNet-161, and DnsNet-201 were trained and tested on a
common exclusive testing set of 250 images per class. The whole experiment was
repeated on three similar datasets from Australia, Africa and North America and
the results were compared. Simple regression equations for use by practitioners
to approximate model performance metrics are provided. Generalized additive
models (GAM) are shown to be effective in modelling DL performance metrics
based on the number of training images per class, tuning scheme and dataset.

Key-words: Camera Traps, Deep Learning, Ecological Informatics, Generalised
Additive Models, Learning Curves, Predictive Modelling, Wildlife.
</p>
<a href="http://arxiv.org/abs/2010.08186" target="_blank">arXiv:2010.08186</a> [<a href="http://arxiv.org/pdf/2010.08186" target="_blank">pdf</a>]

<h2>PrivNet: Safeguarding Private Attributes in Transfer Learning for Recommendation. (arXiv:2010.08187v1 [cs.AI])</h2>
<h3>Guangneng Hu, Qiang Yang</h3>
<p>Transfer learning is an effective technique to improve a target recommender
system with the knowledge from a source domain. Existing research focuses on
the recommendation performance of the target domain while ignores the privacy
leakage of the source domain. The transferred knowledge, however, may
unintendedly leak private information of the source domain. For example, an
attacker can accurately infer user demographics from their historical purchase
provided by a source domain data owner. This paper addresses the above
privacy-preserving issue by learning a privacy-aware neural representation by
improving target performance while protecting source privacy. The key idea is
to simulate the attacks during the training for protecting unseen users'
privacy in the future, modeled by an adversarial game, so that the transfer
learning model becomes robust to attacks. Experiments show that the proposed
PrivNet model can successfully disentangle the knowledge benefitting the
transfer from leaking the privacy.
</p>
<a href="http://arxiv.org/abs/2010.08187" target="_blank">arXiv:2010.08187</a> [<a href="http://arxiv.org/pdf/2010.08187" target="_blank">pdf</a>]

<h2>New Ideas and Trends in Deep Multimodal Content Understanding: A Review. (arXiv:2010.08189v1 [cs.CV])</h2>
<h3>Wei Chen, Weiping Wang, Li Liu, Michael S. Lew</h3>
<p>The focus of this survey is on the analysis of two modalities of multimodal
deep learning: image and text. Unlike classic reviews of deep learning where
monomodal image classifiers such as VGG, ResNet and Inception module are
central topics, this paper will examine recent multimodal deep models and
structures, including auto-encoders, generative adversarial nets and their
variants. These models go beyond the simple image classifiers in which they can
do uni-directional (e.g. image captioning, image generation) and bi-directional
(e.g. cross-modal retrieval, visual question answering) multimodal tasks.
Besides, we analyze two aspects of the challenge in terms of better content
understanding in deep multimodal applications. We then introduce current ideas
and trends in deep multimodal feature learning, such as feature embedding
approaches and objective function design, which are crucial in overcoming the
aforementioned challenges. Finally, we include several promising directions for
future research.
</p>
<a href="http://arxiv.org/abs/2010.08189" target="_blank">arXiv:2010.08189</a> [<a href="http://arxiv.org/pdf/2010.08189" target="_blank">pdf</a>]

<h2>ASMFS: Adaptive-Similarity-based Multi-modality Feature Selection for Classification of Alzheimer's Disease. (arXiv:2010.08190v1 [cs.CV])</h2>
<h3>Yuang Shi, Chen Zu, Mei Hong, Luping Zhou, Lei Wang, Xi Wu, Jiliu Zhou, Daoqiang Zhang, Yan Wang</h3>
<p>With the increasing amounts of high-dimensional heterogeneous data to be
processed, multi-modality feature selection has become an important research
direction in medical image analysis. Traditional methods usually depict the
data structure using fixed and predefined similarity matrix for each modality
separately, without considering the potential relationship structure across
different modalities. In this paper, we propose a novel multi-modality feature
selection method, which performs feature selection and local similarity
learning simultaniously. Specially, a similarity matrix is learned by jointly
considering different imaging modalities. And at the same time, feature
selection is conducted by imposing sparse l_{2, 1} norm constraint. The
effectiveness of our proposed joint learning method can be well demonstrated by
the experimental results on Alzheimer's Disease Neuroimaging Initiative (ADNI)
dataset, which outperforms existing the state-of-the-art multi-modality
approaches.
</p>
<a href="http://arxiv.org/abs/2010.08190" target="_blank">arXiv:2010.08190</a> [<a href="http://arxiv.org/pdf/2010.08190" target="_blank">pdf</a>]

<h2>Decentralized Multi-Agent Pursuit using Deep Reinforcement Learning. (arXiv:2010.08193v1 [cs.MA])</h2>
<h3>Cristino de Souza Jr, Rhys Newbury, Akansel Cosgun, Pedro Castillo, Boris Vidolov, Dana Kulic</h3>
<p>Pursuit-evasion is the problem of capturing mobile targets with one or more
pursuers. We use deep reinforcement learning for pursuing an omni-directional
target with multiple, homogeneous agents that are subject to unicycle kinematic
constraints. We use shared experience to train a policy for a given number of
pursuers that is executed independently by each agent at run-time. The training
benefits from curriculum learning, a sweeping-angle ordering to locally
represent neighboring agents and encouraging good formations with reward
structure that combines individual and group rewards. Simulated experiments
with a reactive evader and up to eight pursuers show that our learning-based
approach, with non-holonomic agents, performs on par with classical algorithms
with omni-directional agents, and outperforms their non-holonomic adaptations.
The learned policy is successfully transferred to the real world in a
proof-of-concept demonstration with three motion-constrained pursuer drones.
</p>
<a href="http://arxiv.org/abs/2010.08193" target="_blank">arXiv:2010.08193</a> [<a href="http://arxiv.org/pdf/2010.08193" target="_blank">pdf</a>]

<h2>Emergent and Unspecified Behaviors in Streaming Decision Trees. (arXiv:2010.08199v1 [cs.LG])</h2>
<h3>Chaitanya Manapragada, Geoffrey I Webb, Mahsa Salehi, Albert Bifet</h3>
<p>Hoeffding trees are the state-of-the-art methods in decision tree learning
for evolving data streams. These very fast decision trees are used in many real
applications where data is created in real-time due to their efficiency. In
this work, we extricate explanations for why these streaming decision tree
algorithms for stationary and nonstationary streams (HoeffdingTree and
HoeffdingAdaptiveTree) work as well as they do. In doing so, we identify
thirteen unique unspecified design decisions in both the theoretical constructs
and their implementations with substantial and consequential effects on
predictive accuracy---design decisions that, without necessarily changing the
essence of the algorithms, drive algorithm performance. We begin a larger
conversation about explainability not just of the model but also of the
processes responsible for an algorithm's success.
</p>
<a href="http://arxiv.org/abs/2010.08199" target="_blank">arXiv:2010.08199</a> [<a href="http://arxiv.org/pdf/2010.08199" target="_blank">pdf</a>]

<h2>Unsupervised Natural Language Inference via Decoupled Multimodal Contrastive Learning. (arXiv:2010.08200v1 [cs.CL])</h2>
<h3>Wanyun Cui, Guangyu Zheng, Wei Wang</h3>
<p>We propose to solve the natural language inference problem without any
supervision from the inference labels via task-agnostic multimodal pretraining.
Although recent studies of multimodal self-supervised learning also represent
the linguistic and visual context, their encoders for different modalities are
coupled. Thus they cannot incorporate visual information when encoding plain
text alone. In this paper, we propose Multimodal Aligned Contrastive Decoupled
learning (MACD) network. MACD forces the decoupled text encoder to represent
the visual information via contrastive learning. Therefore, it embeds visual
knowledge even for plain text inference. We conducted comprehensive experiments
over plain text inference datasets (i.e. SNLI and STS-B). The unsupervised MACD
even outperforms the fully-supervised BiLSTM and BiLSTM+ELMO on STS-B.
</p>
<a href="http://arxiv.org/abs/2010.08200" target="_blank">arXiv:2010.08200</a> [<a href="http://arxiv.org/pdf/2010.08200" target="_blank">pdf</a>]

<h2>Extracting Signals of Higgs Boson From Background Noise Using Deep Neural Networks. (arXiv:2010.08201v1 [hep-ph])</h2>
<h3>Muhammad Abbas, Asifullah Khan, Aqsa Saeed Qureshi, Muhammad Waleed Khan</h3>
<p>Higgs boson is a fundamental particle, and the classification of Higgs
signals is a well-known problem in high energy physics. The identification of
the Higgs signal is a challenging task because its signal has a resemblance to
the background signals. This study proposes a Higgs signal classification using
a novel combination of random forest, auto encoder and deep auto encoder to
build a robust and generalized Higgs boson prediction system to discriminate
the Higgs signal from the background noise. The proposed ensemble technique is
based on achieving diversity in the decision space, and the results show good
discrimination power on the private leaderboard; achieving an area under the
Receiver Operating Characteristic curve of 0.9 and an Approximate Median
Significance score of 3.429.
</p>
<a href="http://arxiv.org/abs/2010.08201" target="_blank">arXiv:2010.08201</a> [<a href="http://arxiv.org/pdf/2010.08201" target="_blank">pdf</a>]

<h2>Human Perception-based Evaluation Criterion for Ultra-high Resolution Cell Membrane Segmentation. (arXiv:2010.08209v1 [cs.CV])</h2>
<h3>Ruohua Shi, Wenyao Wang, Zhixuan Li, Liuyuan He, Kaiwen Sheng, Lei Ma, Kai Du, Tingting Jiang, Tiejun Huang</h3>
<p>Computer vision technology is widely used in biological and medical data
analysis and understanding. However, there are still two major bottlenecks in
the field of cell membrane segmentation, which seriously hinder further
research: lack of sufficient high-quality data and lack of suitable evaluation
criteria. In order to solve these two problems, this paper first proposes an
Ultra-high Resolution Image Segmentation dataset for the Cell membrane, called
U-RISC, the largest annotated Electron Microscopy (EM) dataset for the Cell
membrane with multiple iterative annotations and uncompressed high-resolution
raw data. During the analysis process of the U-RISC, we found that the current
popular segmentation evaluation criteria are inconsistent with human
perception. This interesting phenomenon is confirmed by a subjective experiment
involving twenty people. Furthermore, to resolve this inconsistency, we propose
a new evaluation criterion called Perceptual Hausdorff Distance (PHD) to
measure the quality of cell membrane segmentation results. Detailed performance
comparison and discussion of classic segmentation methods along with two
iterative manual annotation results under existing evaluation criteria and PHD
is given.
</p>
<a href="http://arxiv.org/abs/2010.08209" target="_blank">arXiv:2010.08209</a> [<a href="http://arxiv.org/pdf/2010.08209" target="_blank">pdf</a>]

<h2>Coarse-to-Fine Pre-training for Named Entity Recognition. (arXiv:2010.08210v1 [cs.CL])</h2>
<h3>Mengge Xue, Bowen Yu, Zhenyu Zhang, Tingwen Liu, Yue Zhang, Bin Wang</h3>
<p>More recently, Named Entity Recognition hasachieved great advances aided by
pre-trainingapproaches such as BERT. However, currentpre-training techniques
focus on building lan-guage modeling objectives to learn a gen-eral
representation, ignoring the named entity-related knowledge. To this end, we
proposea NER-specific pre-training framework to in-ject coarse-to-fine
automatically mined entityknowledge into pre-trained models. Specifi-cally, we
first warm-up the model via an en-tity span identification task by training it
withWikipedia anchors, which can be deemed asgeneral-typed entities. Then we
leverage thegazetteer-based distant supervision strategy totrain the model
extract coarse-grained typedentities. Finally, we devise a
self-supervisedauxiliary task to mine the fine-grained namedentity knowledge
via clustering.Empiricalstudies on three public NER datasets demon-strate that
our framework achieves significantimprovements against several pre-trained
base-lines, establishing the new state-of-the-art per-formance on three
benchmarks. Besides, weshow that our framework gains promising re-sults without
using human-labeled trainingdata, demonstrating its effectiveness in label-few
and low-resource scenarios
</p>
<a href="http://arxiv.org/abs/2010.08210" target="_blank">arXiv:2010.08210</a> [<a href="http://arxiv.org/pdf/2010.08210" target="_blank">pdf</a>]

<h2>Collaborative Training of GANs in Continuous and Discrete Spaces for Text Generation. (arXiv:2010.08213v1 [cs.CL])</h2>
<h3>Yanghoon Kim, Seungpil Won, Seunghyun Yoon, Kyomin Jung</h3>
<p>Applying generative adversarial networks (GANs) to text-related tasks is
challenging due to the discrete nature of language. One line of research
resolves this issue by employing reinforcement learning (RL) and optimizing the
next-word sampling policy directly in a discrete action space. Such methods
compute the rewards from complete sentences and avoid error accumulation due to
exposure bias. Other approaches employ approximation techniques that map the
text to continuous representation in order to circumvent the non-differentiable
discrete process. Particularly, autoencoder-based methods effectively produce
robust representations that can model complex discrete structures. In this
paper, we propose a novel text GAN architecture that promotes the collaborative
training of the continuous-space and discrete-space methods. Our method employs
an autoencoder to learn an implicit data manifold, providing a learning
objective for adversarial training in a continuous space. Furthermore, the
complete textual output is directly evaluated and updated via RL in a discrete
space. The collaborative interplay between the two adversarial trainings
effectively regularize the text representations in different spaces. The
experimental results on three standard benchmark datasets show that our model
substantially outperforms state-of-the-art text GANs with respect to quality,
diversity, and global consistency.
</p>
<a href="http://arxiv.org/abs/2010.08213" target="_blank">arXiv:2010.08213</a> [<a href="http://arxiv.org/pdf/2010.08213" target="_blank">pdf</a>]

<h2>Deep-HOSeq: Deep Higher Order Sequence Fusion for Multimodal Sentiment Analysis. (arXiv:2010.08218v1 [cs.AI])</h2>
<h3>Sunny Verma, Jiwei Wang, Zhefeng Ge, Rujia Shen, Fan Jin, Yang Wang, Fang Chen, Wei Liu</h3>
<p>Multimodal sentiment analysis utilizes multiple heterogeneous modalities for
sentiment classification. The recent multimodal fusion schemes customize LSTMs
to discover intra-modal dynamics and design sophisticated attention mechanisms
to discover the inter-modal dynamics from multimodal sequences. Although
powerful, these schemes completely rely on attention mechanisms which is
problematic due to two major drawbacks 1) deceptive attention masks, and 2)
training dynamics. Nevertheless, strenuous efforts are required to optimize
hyperparameters of these consolidate architectures, in particular their
custom-designed LSTMs constrained by attention schemes. In this research, we
first propose a common network to discover both intra-modal and inter-modal
dynamics by utilizing basic LSTMs and tensor based convolution networks. We
then propose unique networks to encapsulate temporal-granularity among the
modalities which is essential while extracting information within asynchronous
sequences. We then integrate these two kinds of information via a fusion layer
and call our novel multimodal fusion scheme as Deep-HOSeq (Deep network with
higher order Common and Unique Sequence information). The proposed Deep-HOSeq
efficiently discovers all-important information from multimodal sequences and
the effectiveness of utilizing both types of information is empirically
demonstrated on CMU-MOSEI and CMU-MOSI benchmark datasets. The source code of
our proposed Deep-HOSeq is and available at
https://github.com/sverma88/Deep-HOSeq--ICDM-2020.
</p>
<a href="http://arxiv.org/abs/2010.08218" target="_blank">arXiv:2010.08218</a> [<a href="http://arxiv.org/pdf/2010.08218" target="_blank">pdf</a>]

<h2>Improved Predictive Deep Temporal Neural Networks with Trend Filtering. (arXiv:2010.08234v1 [cs.AI])</h2>
<h3>Youngjin Park, Deokjun Eom, Byoungki Seo, Jaesik Choi</h3>
<p>Forecasting with multivariate time series, which aims to predict future
values given previous and current several univariate time series data, has been
studied for decades, with one example being ARIMA. Because it is difficult to
measure the extent to which noise is mixed with informative signals within
rapidly fluctuating financial time series data, designing a good predictive
model is not a simple task. Recently, many researchers have become interested
in recurrent neural networks and attention-based neural networks, applying them
in financial forecasting. There have been many attempts to utilize these
methods for the capturing of long-term temporal dependencies and to select more
important features in multivariate time series data in order to make accurate
predictions. In this paper, we propose a new prediction framework based on deep
neural networks and a trend filtering, which converts noisy time series data
into a piecewise linear fashion. We reveal that the predictive performance of
deep temporal neural networks improves when the training data is temporally
processed by a trend filtering. To verify the effect of our framework, three
deep temporal neural networks, state of the art models for predictions in time
series finance data, are used and compared with models that contain trend
filtering as an input feature. Extensive experiments on real-world multivariate
time series data show that the proposed method is effective and significantly
better than existing baseline methods.
</p>
<a href="http://arxiv.org/abs/2010.08234" target="_blank">arXiv:2010.08234</a> [<a href="http://arxiv.org/pdf/2010.08234" target="_blank">pdf</a>]

<h2>Auxiliary Task Reweighting for Minimum-data Learning. (arXiv:2010.08244v1 [cs.LG])</h2>
<h3>Baifeng Shi, Judy Hoffman, Kate Saenko, Trevor Darrell, Huijuan Xu</h3>
<p>Supervised learning requires a large amount of training data, limiting its
application where labeled data is scarce. To compensate for data scarcity, one
possible method is to utilize auxiliary tasks to provide additional supervision
for the main task. Assigning and optimizing the importance weights for
different auxiliary tasks remains an crucial and largely understudied research
question. In this work, we propose a method to automatically reweight auxiliary
tasks in order to reduce the data requirement on the main task. Specifically,
we formulate the weighted likelihood function of auxiliary tasks as a surrogate
prior for the main task. By adjusting the auxiliary task weights to minimize
the divergence between the surrogate prior and the true prior of the main task,
we obtain a more accurate prior estimation, achieving the goal of minimizing
the required amount of training data for the main task and avoiding a costly
grid search. In multiple experimental settings (e.g. semi-supervised learning,
multi-label classification), we demonstrate that our algorithm can effectively
utilize limited labeled data of the main task with the benefit of auxiliary
tasks compared with previous task reweighting methods. We also show that under
extreme cases with only a few extra examples (e.g. few-shot domain adaptation),
our algorithm results in significant improvement over the baseline.
</p>
<a href="http://arxiv.org/abs/2010.08244" target="_blank">arXiv:2010.08244</a> [<a href="http://arxiv.org/pdf/2010.08244" target="_blank">pdf</a>]

<h2>SIGTYP 2020 Shared Task: Prediction of Typological Features. (arXiv:2010.08246v1 [cs.CL])</h2>
<h3>Johannes Bjerva, Elizabeth Salesky, Sabrina J. Mielke, Aditi Chaudhary, Giuseppe G. A. Celano, Edoardo M. Ponti, Ekaterina Vylomova, Ryan Cotterell, Isabelle Augenstein</h3>
<p>Typological knowledge bases (KBs) such as WALS (Dryer and Haspelmath, 2013)
contain information about linguistic properties of the world's languages. They
have been shown to be useful for downstream applications, including
cross-lingual transfer learning and linguistic probing. A major drawback
hampering broader adoption of typological KBs is that they are sparsely
populated, in the sense that most languages only have annotations for some
features, and skewed, in that few features have wide coverage. As typological
features often correlate with one another, it is possible to predict them and
thus automatically populate typological KBs, which is also the focus of this
shared task. Overall, the task attracted 8 submissions from 5 teams, out of
which the most successful methods make use of such feature correlations.
However, our error analysis reveals that even the strongest submitted systems
struggle with predicting feature values for languages where few features are
known.
</p>
<a href="http://arxiv.org/abs/2010.08246" target="_blank">arXiv:2010.08246</a> [<a href="http://arxiv.org/pdf/2010.08246" target="_blank">pdf</a>]

<h2>Filtered Batch Normalization. (arXiv:2010.08251v1 [cs.LG])</h2>
<h3>Andras Horvath, Jalal Al-afandi</h3>
<p>It is a common assumption that the activation of different layers in neural
networks follow Gaussian distribution. This distribution can be transformed
using normalization techniques, such as batch-normalization, increasing
convergence speed and improving accuracy. In this paper we would like to
demonstrate, that activations do not necessarily follow Gaussian distribution
in all layers. Neurons in deeper layers are more selective and specific which
can result extremely large, out-of-distribution activations.

We will demonstrate that one can create more consistent mean and variance
values for batch normalization during training by filtering out these
activations which can further improve convergence speed and yield higher
validation accuracy.
</p>
<a href="http://arxiv.org/abs/2010.08251" target="_blank">arXiv:2010.08251</a> [<a href="http://arxiv.org/pdf/2010.08251" target="_blank">pdf</a>]

<h2>Hyperparameter Auto-tuning in Self-Supervised Robotic Learning. (arXiv:2010.08252v1 [cs.RO])</h2>
<h3>Jiancong Huang, Juan Rojas, Matthieu Zimmer, Hongmin Wu, Yisheng Guan, Paul Weng</h3>
<p>Policy optimization in reinforcement learning requires the selection of
numerous hyperparameters across different environments. Fixing them incorrectly
may negatively impact optimization performance leading notably to insufficient
or redundant learning. Insufficient learning (due to convergence to local
optima) results in under-performing policies whilst redundant learning wastes
time and resources. The effects are further exacerbated when using single
policies to solve multi-task learning problems. In this paper, we study how the
Evidence Lower Bound (ELBO) used in Variational Auto-Encoders (VAEs) is
affected by the diversity of image samples. Different tasks or setups in visual
reinforcement learning incur varying diversity. We exploit the ELBO to create
an auto-tuning technique in self-supervised reinforcement learning. Our
approach can auto-tune three hyperparameters: the replay buffer size, the
number of policy gradient updates during each epoch, and the number of
exploration steps during each epoch. We use the state-of-the-art
self-supervised robotic learning framework (Reinforcement Learning with
Imagined Goals (RIG) using Soft Actor-Critic) as baseline for experimental
verification. Experiments show that our method can auto-tune online and yields
the best performance at a fraction of the time and computational resources.
Code, video, and appendix for simulated and real-robot experiments can be found
at \url{www.JuanRojas.net/autotune}.
</p>
<a href="http://arxiv.org/abs/2010.08252" target="_blank">arXiv:2010.08252</a> [<a href="http://arxiv.org/pdf/2010.08252" target="_blank">pdf</a>]

<h2>Variational (Gradient) Estimate of the Score Function in Energy-based Latent Variable Models. (arXiv:2010.08258v1 [cs.LG])</h2>
<h3>Fan Bao, Kun Xu, Chongxuan Li, Lanqing Hong, Jun Zhu, Bo Zhang</h3>
<p>The learning and evaluation of energy-based latent variable models (EBLVMs)
without any structural assumptions are highly challenging, because the true
posteriors and the partition functions in such models are generally
intractable. This paper presents variational estimates of the score function
and its gradient with respect to the model parameters in a general EBLVM,
referred to as VaES and VaGES respectively. The variational posterior is
trained to minimize a certain divergence to the true model posterior and the
bias in both estimates can be bounded by the divergence theoretically. With a
minimal model assumption, VaES and VaGES can be applied to the kernelized Stein
discrepancy (KSD) and score matching (SM)-based methods to learn EBLVMs.
Besides, VaES can also be used to estimate the exact Fisher divergence between
the data and general EBLVMs.
</p>
<a href="http://arxiv.org/abs/2010.08258" target="_blank">arXiv:2010.08258</a> [<a href="http://arxiv.org/pdf/2010.08258" target="_blank">pdf</a>]

<h2>Towards truly local gradients with CLAPP: Contrastive, Local And Predictive Plasticity. (arXiv:2010.08262v1 [cs.LG])</h2>
<h3>Bernd Illing, Wulfram Gerstner, Guillaume Bellec</h3>
<p>Back-propagation (BP) is costly to implement in hardware and implausible as a
learning rule implemented in the brain. However, BP is surprisingly successful
in explaining neuronal activity patterns found along the cortical processing
stream. We propose a locally implementable, unsupervised learning algorithm,
CLAPP, which minimizes a simple, layer-specific loss function, and thus does
not need to back-propagate error signals. The weight updates only depend on
state variables of the pre- and post-synaptic neurons and a layer-wide third
factor. Networks trained with CLAPP build deep hierarchical representations of
images and speech.
</p>
<a href="http://arxiv.org/abs/2010.08262" target="_blank">arXiv:2010.08262</a> [<a href="http://arxiv.org/pdf/2010.08262" target="_blank">pdf</a>]

<h2>Parsimonious Quantile Regression of Financial Asset Tail Dynamics via Sequential Learning. (arXiv:2010.08263v1 [q-fin.RM])</h2>
<h3>Xing Yan, Weizhong Zhang, Lin Ma, Wei Liu, Qi Wu</h3>
<p>We propose a parsimonious quantile regression framework to learn the dynamic
tail behaviors of financial asset returns. Our model captures well both the
time-varying characteristic and the asymmetrical heavy-tail property of
financial time series. It combines the merits of a popular sequential neural
network model, i.e., LSTM, with a novel parametric quantile function that we
construct to represent the conditional distribution of asset returns. Our model
also captures individually the serial dependences of higher moments, rather
than just the volatility. Across a wide range of asset classes, the
out-of-sample forecasts of conditional quantiles or VaR of our model outperform
the GARCH family. Further, the proposed approach does not suffer from the issue
of quantile crossing, nor does it expose to the ill-posedness comparing to the
parametric probability density function approach.
</p>
<a href="http://arxiv.org/abs/2010.08263" target="_blank">arXiv:2010.08263</a> [<a href="http://arxiv.org/pdf/2010.08263" target="_blank">pdf</a>]

<h2>Training Flexible Depth Model by Multi-Task Learning for Neural Machine Translation. (arXiv:2010.08265v1 [cs.CL])</h2>
<h3>Qiang Wang, Tong Xiao, Jingbo Zhu</h3>
<p>The standard neural machine translation model can only decode with the same
depth configuration as training. Restricted by this feature, we have to deploy
models of various sizes to maintain the same translation latency, because the
hardware conditions on different terminal devices (e.g., mobile phones) may
vary greatly. Such individual training leads to increased model maintenance
costs and slower model iterations, especially for the industry. In this work,
we propose to use multi-task learning to train a flexible depth model that can
adapt to different depth configurations during inference. Experimental results
show that our approach can simultaneously support decoding in 24 depth
configurations and is superior to the individual training and another flexible
depth model training method -- LayerDrop.
</p>
<a href="http://arxiv.org/abs/2010.08265" target="_blank">arXiv:2010.08265</a> [<a href="http://arxiv.org/pdf/2010.08265" target="_blank">pdf</a>]

<h2>Training Data Generating Networks: Linking 3D Shapes and Few-Shot Classification. (arXiv:2010.08276v1 [cs.CV])</h2>
<h3>Biao Zhang, Peter Wonka</h3>
<p>We propose a novel 3d shape representation for 3d shape reconstruction from a
single image. Rather than predicting a shape directly, we train a network to
generate a training set which will be feed into another learning algorithm to
define the shape. Training data generating networks establish a link between
few-shot learning and 3d shape analysis. We propose a novel meta-learning
framework to jointly train the data generating network and other components. We
improve upon recent work on standard benchmarks for 3d shape reconstruction,
but our novel shape representation has many applications.
</p>
<a href="http://arxiv.org/abs/2010.08276" target="_blank">arXiv:2010.08276</a> [<a href="http://arxiv.org/pdf/2010.08276" target="_blank">pdf</a>]

<h2>Real-Time Face & Eye Tracking and Blink Detection using Event Cameras. (arXiv:2010.08278v1 [cs.CV])</h2>
<h3>Cian Ryan, Brian O Sullivan, Amr Elrasad, Joe Lemley, Paul Kielty, Christoph Posch, Etienne Perot</h3>
<p>Event cameras contain emerging, neuromorphic vision sensors that capture
local light intensity changes at each pixel, generating a stream of
asynchronous events. This way of acquiring visual information constitutes a
departure from traditional frame based cameras and offers several significant
advantages: low energy consumption, high temporal resolution, high dynamic
range and low latency. Driver monitoring systems (DMS) are in-cabin safety
systems designed to sense and understand a drivers physical and cognitive
state. Event cameras are particularly suited to DMS due to their inherent
advantages. This paper proposes a novel method to simultaneously detect and
track faces and eyes for driver monitoring. A unique, fully convolutional
recurrent neural network architecture is presented. To train this network, a
synthetic event-based dataset is simulated with accurate bounding box
annotations, called Neuromorphic HELEN. Additionally, a method to detect and
analyse drivers eye blinks is proposed, exploiting the high temporal resolution
of event cameras. Behaviour of blinking provides greater insights into a driver
level of fatigue or drowsiness. We show that blinks have a unique temporal
signature that can be better captured by event cameras.
</p>
<a href="http://arxiv.org/abs/2010.08278" target="_blank">arXiv:2010.08278</a> [<a href="http://arxiv.org/pdf/2010.08278" target="_blank">pdf</a>]

<h2>Embedding and Synthesis of Knowledge in Tree Ensemble Classifiers. (arXiv:2010.08281v1 [cs.CR])</h2>
<h3>Wei Huang, Xingyu Zhao, Xiaowei Huang</h3>
<p>This paper studies the embedding and synthesis of knowledge in tree ensemble
classifiers. We focus on knowledge expressible with a generic form of Boolean
formulas, and show that a typical security attack, i.e., backdoor attack, is
expressible with this knowledge expression. For the embedding, it is required
to be preservative (i.e., the original performance of the classifier is
preserved), verifiable (i.e., the knowledge can be attested), and stealthy
(i.e., the embedding cannot be easily detected). To facilitate this, we propose
two novel, and very effective, embedding algorithms, one of which is for
black-box setting and the other for white-box setting. The embedding can be
done in PTIME. Beyond the embedding, we develop an algorithm to synthesise the
embedded knowledge, by reducing the problem to be solvable with an SMT
(satisfiability modulo theories) solver. While this novel algorithmcan
successfully synthesise knowledge, the reduction leads to an NP computation.
Therefore, if applying embedding as security attack and synthesis as defence,
our results suggest acomplexity gap (P vs. NP) between security attack and
security defence when working with machine learning models. We apply our
algorithms to a diverse set of datasets to validate our conclusion empirically.
</p>
<a href="http://arxiv.org/abs/2010.08281" target="_blank">arXiv:2010.08281</a> [<a href="http://arxiv.org/pdf/2010.08281" target="_blank">pdf</a>]

<h2>Automated Iterative Training of Convolutional Neural Networks for Tree Skeleton Segmentation. (arXiv:2010.08296v1 [cs.CV])</h2>
<h3>Keenan Granland, Rhys Newbury, David Ting, Chao Chen</h3>
<p>Training of convolutional neural networks for semantic segmentation requires
accurate pixel-wise labeling. Depending on the application this can require
large amounts of human effort. The human-in-the-loop method reduces labeling
effort but still requires human intervention for a selection of images. This
paper describes a new iterative training method: Automating-the-loop.
Automating-the-loop aims to replicate the human adjustment in
human-in-the-loop, with an automated process. Thereby, removing human
intervention during the iterative process and drastically reducing labeling
effort. Using the application of segmented apple tree detection, we compare
human-in-the-loop, Self Training Loop, Filtered-Self Training Loop
(semi-supervised learning) and our proposed method automating-the-loop. These
methods are used to train U-Net, a deep learning based convolutional neural
network. The results are presented and analyzed on both traditional performance
metrics and a new metric, Horizontal Scan. It is shown that the new method of
automating-the-loop greatly reduces the labeling effort while generating a
network with comparable performance to both human-in-the-loop and completely
manual labeling.
</p>
<a href="http://arxiv.org/abs/2010.08296" target="_blank">arXiv:2010.08296</a> [<a href="http://arxiv.org/pdf/2010.08296" target="_blank">pdf</a>]

<h2>Interpretable Disease Prediction based on Reinforcement Path Reasoning over Knowledge Graphs. (arXiv:2010.08300v1 [cs.LG])</h2>
<h3>Zhoujian Sun, Wei Dong, Jinlong Shi, Zhengxing Huang</h3>
<p>Objective: To combine medical knowledge and medical data to interpretably
predict the risk of disease. Methods: We formulated the disease prediction task
as a random walk along a knowledge graph (KG). Specifically, we build a KG to
record relationships between diseases and risk factors according to validated
medical knowledge. Then, a mathematical object walks along the KG. It starts
walking at a patient entity, which connects the KG based on the patient current
diseases or risk factors and stops at a disease entity, which represents the
predicted disease. The trajectory generated by the object represents an
interpretable disease progression path of the given patient. The dynamics of
the object are controlled by a policy-based reinforcement learning (RL) module,
which is trained by electronic health records (EHRs). Experiments: We utilized
two real-world EHR datasets to evaluate the performance of our model. In the
disease prediction task, our model achieves 0.743 and 0.639 in terms of macro
area under the curve (AUC) in predicting 53 circulation system diseases in the
two datasets, respectively. This performance is comparable to the commonly used
machine learning (ML) models in medical research. In qualitative analysis, our
clinical collaborator reviewed the disease progression paths generated by our
model and advocated their interpretability and reliability. Conclusion:
Experimental results validate the proposed model in interpretably evaluating
and optimizing disease prediction. Significance: Our work contributes to
leveraging the potential of medical knowledge and medical data jointly for
interpretable prediction tasks.
</p>
<a href="http://arxiv.org/abs/2010.08300" target="_blank">arXiv:2010.08300</a> [<a href="http://arxiv.org/pdf/2010.08300" target="_blank">pdf</a>]

<h2>Peer-Assisted Robotic Learning: A Data-Driven Collaborative Learning Approach for Cloud Robotic Systems. (arXiv:2010.08303v1 [cs.RO])</h2>
<h3>Boyi Liu, Lujia Wang, Xinquan Chen, Lexiong Huang, Cheng-Zhong Xu</h3>
<p>A technological revolution is occurring in the field of robotics with the
data-driven deep learning technology. However, building datasets for each local
robot is laborious. Meanwhile, data islands between local robots make data
unable to be utilized collaboratively. To address this issue, the work presents
Peer-Assisted Robotic Learning (PARL) in robotics, which is inspired by the
peer-assisted learning in cognitive psychology and pedagogy. PARL implements
data collaboration with the framework of cloud robotic systems. Both data and
models are shared by robots to the cloud after semantic computing and training
locally. The cloud converges the data and performs augmentation, integration,
and transferring. Finally, fine tune this larger shared dataset in the cloud to
local robots. Furthermore, we propose the DAT Network (Data Augmentation and
Transferring Network) to implement the data processing in PARL. DAT Network can
realize the augmentation of data from multi-local robots. We conduct
experiments on a simplified self-driving task for robots (cars). DAT Network
has a significant improvement in the augmentation in self-driving scenarios.
Along with this, the self-driving experimental results also demonstrate that
PARL is capable of improving learning effects with data collaboration of local
robots.
</p>
<a href="http://arxiv.org/abs/2010.08303" target="_blank">arXiv:2010.08303</a> [<a href="http://arxiv.org/pdf/2010.08303" target="_blank">pdf</a>]

<h2>Formal Verification of Robustness and Resilience of Learning-Enabled State Estimation Systems for Robotics. (arXiv:2010.08311v1 [cs.RO])</h2>
<h3>Wei Huang, Yifan Zhou, Youcheng Sun, Alec Banks, Jie Meng, James Sharp, Simon Maskell, Xiaowei Huang</h3>
<p>This paper presents a formal verification guided approach for a principled
design and implementation of robust and resilient learning-enabled systems. We
focus on learning-enabled state estimation systems (LE-SESs), which have been
widely used in robotics applications to determine the current state (e.g.,
location, speed, direction, etc.) of a complex system. The LE-SESs are
networked systems composed of a set of connected components including Bayes
filters for localisation, and neural networks for processing sensory input. We
study LE-SESs from the perspective of formal verification, which determines the
satisfiability of a system model against the specified properties. Over
LE-SESs, we investigate two key properties - robustness and resilience - and
provide their formal definitions. To enable formal verification, we reduce the
LE-SESs to a novel class of labelled transition systems, named {PO}2-LTS in the
paper, and formally express the properties as constrained optimisation
objectives. We prove that the robustness verification is NP-complete. Based on
{PO}2-LTS and the optimisation objectives, practical verification algorithms
are developed to check the satisfiability of the properties on the LE-SESs. As
a major case study, we interrogate a real-world dynamic tracking system which
uses a single Kalman Filter (KF) - a special case of Bayes filter - to localise
and track a ground vehicle. Its perception system, based on convolutional
neural networks, processes a high-resolution Wide Area Motion Imagery (WAMI)
data stream. Experimental results show that our algorithms can not only verify
the properties of the WAMI tracking system but also provide representative
examples, the latter of which inspired us to take an enhanced LE-SESs design
where runtime monitors or joint-KFs are required. Experimental results confirm
the improvement of the robustness of the enhanced design.
</p>
<a href="http://arxiv.org/abs/2010.08311" target="_blank">arXiv:2010.08311</a> [<a href="http://arxiv.org/pdf/2010.08311" target="_blank">pdf</a>]

<h2>Multi-task Learning of Negation and Speculation for Targeted Sentiment Classification. (arXiv:2010.08318v1 [cs.CL])</h2>
<h3>Andrew Moore, Jeremy Barnes</h3>
<p>The majority of work in targeted sentiment analysis has concentrated on
finding better methods to improve the overall results. Within this paper we
show that these models are not robust to linguistic phenomena, specifically
negation and speculation. In this paper, we propose a multi-task learning
method to incorporate information from syntactic and semantic auxiliary tasks,
including negation and speculation scope detection, to create models that are
more robust to these phenomena. Further we create two challenge datasets to
evaluate model performance on negated and speculative samples. We find that
multi-task models and transfer learning from a language model can improve
performance on these challenge datasets. However the results indicate that
there is still much room for improvement in making our models more robust to
linguistic phenomena such as negation and speculation.
</p>
<a href="http://arxiv.org/abs/2010.08318" target="_blank">arXiv:2010.08318</a> [<a href="http://arxiv.org/pdf/2010.08318" target="_blank">pdf</a>]

<h2>Detecting ESG topics using domain-specific language models and data augmentation approaches. (arXiv:2010.08319v1 [cs.CL])</h2>
<h3>Tim Nugent, Nicole Stelea, Jochen L. Leidner</h3>
<p>Despite recent advances in deep learning-based language modelling, many
natural language processing (NLP) tasks in the financial domain remain
challenging due to the paucity of appropriately labelled data. Other issues
that can limit task performance are differences in word distribution between
the general corpora - typically used to pre-train language models - and
financial corpora, which often exhibit specialized language and symbology.
Here, we investigate two approaches that may help to mitigate these issues.
Firstly, we experiment with further language model pre-training using large
amounts of in-domain data from business and financial news. We then apply
augmentation approaches to increase the size of our dataset for model
fine-tuning. We report our findings on an Environmental, Social and Governance
(ESG) controversies dataset and demonstrate that both approaches are beneficial
to accuracy in classification tasks.
</p>
<a href="http://arxiv.org/abs/2010.08319" target="_blank">arXiv:2010.08319</a> [<a href="http://arxiv.org/pdf/2010.08319" target="_blank">pdf</a>]

<h2>Learning Accurate Entropy Model with Global Reference for Image Compression. (arXiv:2010.08321v1 [eess.IV])</h2>
<h3>Yichen Qian, Zhiyu Tan, Xiuyu Sun, Ming Lin, Dongyang Li, Zhenhong Sun, Hao Li, Rong Jin</h3>
<p>In recent deep image compression neural networks, the entropy model plays a
critical role in estimating the prior distribution of deep image encodings.
Existing methods combine hyperprior with local context in the entropy
estimation function. This greatly limits their performance due to the absence
of a global vision. In this work, we propose a novel Global Reference Model for
image compression to effectively leverage both the local and the global context
information, leading to an enhanced compression rate. The proposed method scans
decoded latents and then finds the most relevant latent to assist the
distribution estimating of the current latent. A by-product of this work is the
innovation of a mean-shifting GDN module that further improves the performance.
Experimental results demonstrate that the proposed model outperforms the
rate-distortion performance of most of the state-of-the-art methods in the
industry.
</p>
<a href="http://arxiv.org/abs/2010.08321" target="_blank">arXiv:2010.08321</a> [<a href="http://arxiv.org/pdf/2010.08321" target="_blank">pdf</a>]

<h2>Vibration Influence Evaluation of a Resonant MEMS Scanning System for Automotive Lidars. (arXiv:2010.08327v1 [eess.SY])</h2>
<h3>Han Woong Yoo, Rene Riegler, David Brunner, Stephan Albert, Thomas Thurner, Georg Schitter</h3>
<p>This paper demonstrates a vibration test for an operating resonant MEMS
scanning system to evaluate the vibration immunity for automotive lidar
applications. The MEMS mirror has a reinforcement structure on the backside of
the mirror, causing vibration coupling by a mismatch between the center of mass
and the rotation axis. An analysis of energy variation is proposed, showing
direction dependency of vibration coupling. Vibration influences are evaluated
by transient vibration response and vibration frequency sweep using a single
tone vibration for translational y- and z- axis. The measurement results
demonstrate standard deviation (STD) amplitude and frequency errors are up to
1.64 % and 0.26 %, respectively, for 2 grms single tone vibrations on y axis.
The simulation results also show a good agreement with both measurements,
proving the proposed vibration coupling mechanism of the MEMS mirror. The
phased locked loop (PLL) improves the STD amplitude and frequency errors to
0.91 % and 0.15 % for y axis vibration, corresponding to 44.4 % and 43.0 %
reduction, respectively, showing the benefit of a controlled MEMS mirror for
reliable automotive MEMS lidars.
</p>
<a href="http://arxiv.org/abs/2010.08327" target="_blank">arXiv:2010.08327</a> [<a href="http://arxiv.org/pdf/2010.08327" target="_blank">pdf</a>]

<h2>From Talk to Action with Accountability: Monitoring the Public Discussion of Finnish Decision-Makers with Deep Neural Networks and Topic Modelling. (arXiv:2010.08346v1 [cs.CL])</h2>
<h3>Vili H&#xe4;t&#xf6;nen, Fiona Melzer</h3>
<p>Decades of research on climate have provided a consensus that human activity
has changed the climate and we are currently heading into a climate crisis.
Many tools and methods, some of which utilize machine learning, have been
developed to monitor, evaluate, and predict the changing climate and its
effects on societies. However, the mere existence of tools and increased
awareness have not led to swift action to reduce emissions and mitigate climate
change. Politicians and other policy makers lack the initiative to move from
talking about the climate to concrete climate action. In this work, we
contribute to the efforts of holding decision makers accountable by describing
a system which digests politicians' speeches and statements into a topic
summary. We propose a multi-source hybrid latent Dirichlet allocation model
which can process the large number of publicly available reports, social media
posts, speeches, and other documents of Finnish politicians, providing
transparency and accountability towards the general public.
</p>
<a href="http://arxiv.org/abs/2010.08346" target="_blank">arXiv:2010.08346</a> [<a href="http://arxiv.org/pdf/2010.08346" target="_blank">pdf</a>]

<h2>Learning Monocular Dense Depth from Events. (arXiv:2010.08350v1 [cs.CV])</h2>
<h3>Javier Hidalgo-Carri&#xf3;, Daniel Gehrig, Davide Scaramuzza</h3>
<p>Event cameras are novel sensors that output brightness changes in the form of
a stream of asynchronous events instead of intensity frames. Compared to
conventional image sensors, they offer significant advantages: high temporal
resolution, high dynamic range, no motion blur, and much lower bandwidth.
Recently, learning-based approaches have been applied to event-based data, thus
unlocking their potential and making significant progress in a variety of
tasks, such as monocular depth prediction. Most existing approaches use
standard feed-forward architectures to generate network predictions, which do
not leverage the temporal consistency presents in the event stream. We propose
a recurrent architecture to solve this task and show significant improvement
over standard feed-forward methods. In particular, our method generates dense
depth predictions using a monocular setup, which has not been shown previously.
We pretrain our model using a new dataset containing events and depth maps
recorded in the CARLA simulator. We test our method on the Multi Vehicle Stereo
Event Camera Dataset (MVSEC). Quantitative experiments show up to 50%
improvement in average depth error with respect to previous event-based
methods.
</p>
<a href="http://arxiv.org/abs/2010.08350" target="_blank">arXiv:2010.08350</a> [<a href="http://arxiv.org/pdf/2010.08350" target="_blank">pdf</a>]

<h2>On the Guaranteed Almost Equivalence between Imitation Learning from Observation and Demonstration. (arXiv:2010.08353v1 [cs.RO])</h2>
<h3>Zhihao Cheng, Liu Liu, Aishan Liu, Hao Sun, Meng Fang, Dacheng Tao</h3>
<p>Imitation learning from observation (LfO) is more preferable than imitation
learning from demonstration (LfD) due to the nonnecessity of expert actions
when reconstructing the expert policy from the expert data. However, previous
studies imply that the performance of LfO is inferior to LfD by a tremendous
gap, which makes it challenging to employ LfO in practice. By contrast, this
paper proves that LfO is almost equivalent to LfD in the deterministic robot
environment, and more generally even in the robot environment with bounded
randomness. In the deterministic robot environment, from the perspective of the
control theory, we show that the inverse dynamics disagreement between LfO and
LfD approaches zero, meaning that LfO is almost equivalent to LfD. To further
relax the deterministic constraint and better adapt to the practical
environment, we consider bounded randomness in the robot environment and prove
that the optimizing targets for both LfD and LfO remain almost same in the more
generalized setting. Extensive experiments for multiple robot tasks are
conducted to empirically demonstrate that LfO achieves comparable performance
to LfD. In fact, most common robot systems in reality are the robot environment
with bounded randomness (i.e., the environment this paper considered). Hence,
our findings greatly extend the potential of LfO and suggest that we can safely
apply LfO without sacrificing the performance compared to LfD in practice.
</p>
<a href="http://arxiv.org/abs/2010.08353" target="_blank">arXiv:2010.08353</a> [<a href="http://arxiv.org/pdf/2010.08353" target="_blank">pdf</a>]

<h2>VolumeNet: A Lightweight Parallel Network for Super-Resolution of Medical Volumetric Data. (arXiv:2010.08357v1 [eess.IV])</h2>
<h3>Yinhao Li, Yutaro Iwamoto, Lanfen Lin, Rui Xu, Yen-Wei Chen</h3>
<p>Deep learning-based super-resolution (SR) techniques have generally achieved
excellent performance in the computer vision field. Recently, it has been
proven that three-dimensional (3D) SR for medical volumetric data delivers
better visual results than conventional two-dimensional (2D) processing.
However, deepening and widening 3D networks increases training difficulty
significantly due to the large number of parameters and small number of
training samples. Thus, we propose a 3D convolutional neural network (CNN) for
SR of medical volumetric data called ParallelNet using parallel connections. We
construct a parallel connection structure based on the group convolution and
feature aggregation to build a 3D CNN that is as wide as possible with few
parameters. As a result, the model thoroughly learns more feature maps with
larger receptive fields. In addition, to further improve accuracy, we present
an efficient version of ParallelNet (called VolumeNet), which reduces the
number of parameters and deepens ParallelNet using a proposed lightweight
building block module called the Queue module. Unlike most lightweight CNNs
based on depthwise convolutions, the Queue module is primarily constructed
using separable 2D cross-channel convolutions. As a result, the number of
network parameters and computational complexity can be reduced significantly
while maintaining accuracy due to full channel fusion. Experimental results
demonstrate that the proposed VolumeNet significantly reduces the number of
model parameters and achieves high precision results compared to
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.08357" target="_blank">arXiv:2010.08357</a> [<a href="http://arxiv.org/pdf/2010.08357" target="_blank">pdf</a>]

<h2>Ordinal Neural Network Transformation Models: Deep and interpretable regression models for ordinal outcomes. (arXiv:2010.08376v1 [stat.ML])</h2>
<h3>Lucas Kook, Lisa Herzog, Torsten Hothorn, Oliver D&#xfc;rr, Beate Sick</h3>
<p>Outcomes with a natural order, such as quality of life scores or movie
ratings, commonly occur in prediction tasks. The available input data are often
a mixture of complex inputs like images and tabular predictors. Deep Learning
(DL) methods have shown outstanding performances on perceptual tasks. Yet, most
DL applications treat ordered outcomes as unordered classes and lack
interpretability of individual predictors. In contrast, traditional ordinal
regression models are specific for ordered outcomes and enable to interpret
predictor effects but are limited to tabular input data. Here, we present the
highly modular class of ordinal neural network transformation models (ONTRAMs)
which can include both tabular and complex data using multiple neural networks.
All neural networks are jointly trained to optimize the likelihood, which is
parametrized to take the outcome's natural order into account. We recapitulate
statistical ordinal regression models and discuss how they can be understood as
transformation models. Transformation models use a parametric transformation
function and a simple distribution, the former of which determines the
flexibility and interpretability of the individual model components. We
demonstrate how to set up interpretable ONTRAMs with tabular and/or image data.
We show that the most flexible ONTRAMs achieve on-par performance with existing
DL approaches while outperforming them in training speed. We highlight that
ONTRAMs with image and tabular predictors yield correct effect estimates while
keeping the high prediction performance of DL methods. We showcase how to
interpret individual components of ONTRAMs and discuss the case where the
included tabular predictors are correlated with the image data. In this work,
we demonstrate how to join the benefits of DL and statistical regression
methods to create efficient and interpretable models for ordinal outcomes.
</p>
<a href="http://arxiv.org/abs/2010.08376" target="_blank">arXiv:2010.08376</a> [<a href="http://arxiv.org/pdf/2010.08376" target="_blank">pdf</a>]

<h2>On the surprising similarities between supervised and self-supervised models. (arXiv:2010.08377v1 [cs.CV])</h2>
<h3>Robert Geirhos, Kantharaju Narayanappa, Benjamin Mitzkus, Matthias Bethge, Felix A. Wichmann, Wieland Brendel</h3>
<p>How do humans learn to acquire a powerful, flexible and robust representation
of objects? While much of this process remains unknown, it is clear that humans
do not require millions of object labels. Excitingly, recent algorithmic
advancements in self-supervised learning now enable convolutional neural
networks (CNNs) to learn useful visual object representations without
supervised labels, too. In the light of this recent breakthrough, we here
compare self-supervised networks to supervised models and human behaviour. We
tested models on 15 generalisation datasets for which large-scale human
behavioural data is available (130K highly controlled psychophysical trials).
Surprisingly, current self-supervised CNNs share four key characteristics of
their supervised counterparts: (1.) relatively poor noise robustness (with the
notable exception of SimCLR), (2.) non-human category-level error patterns,
(3.) non-human image-level error patterns (yet high similarity to supervised
model errors) and (4.) a bias towards texture. Taken together, these results
suggest that the strategies learned through today's supervised and
self-supervised training objectives end up being surprisingly similar, but
distant from human-like behaviour. That being said, we are clearly just at the
beginning of what could be called a self-supervised revolution of machine
vision, and we are hopeful that future self-supervised models behave
differently from supervised ones, and---perhaps---more similar to robust human
object recognition.
</p>
<a href="http://arxiv.org/abs/2010.08377" target="_blank">arXiv:2010.08377</a> [<a href="http://arxiv.org/pdf/2010.08377" target="_blank">pdf</a>]

<h2>Volumetric Calculation of Quantization Error in 3-D Vision Systems. (arXiv:2010.08390v1 [cs.CV])</h2>
<h3>Eleni Bohacek, Andrew J. Coates, David R. Selviah</h3>
<p>This paper investigates how the inherent quantization of camera sensors
introduces uncertainty in the calculated position of an observed feature during
3-D mapping. It is typically assumed that pixels and scene features are points,
however, a pixel is a two-dimensional area that maps onto multiple points in
the scene. This uncertainty region is a bound for quantization error in the
calculated point positions. Earlier studies calculated the volume of two
intersecting pixel views, approximated as a cuboid, by projecting pyramids and
cones from the pixels into the scene. In this paper, we reverse this approach
by generating an array of scene points and calculating which scene points are
detected by which pixel in each camera. This enables us to map the uncertainty
regions for every pixel correspondence for a given camera system in one
calculation, without approximating the complex shapes. The dependence of the
volumes of the uncertainty regions on camera baseline length, focal length,
pixel size, and distance to object, shows that earlier studies overestimated
the quantization error by at least a factor of two. For static camera systems
the method can also be used to determine volumetric scene geometry without the
need to calculate disparity maps.
</p>
<a href="http://arxiv.org/abs/2010.08390" target="_blank">arXiv:2010.08390</a> [<a href="http://arxiv.org/pdf/2010.08390" target="_blank">pdf</a>]

<h2>Reconstructing A Large Scale 3D Face Dataset for Deep 3D Face Identification. (arXiv:2010.08391v1 [cs.CV])</h2>
<h3>Cuican Yu, Zihui Zhang, Huibin Li</h3>
<p>Deep learning methods have brought many breakthroughs to computer vision,
especially in 2D face recognition. However, the bottleneck of deep learning
based 3D face recognition is that it is difficult to collect millions of 3D
faces, whether for industry or academia. In view of this situation, there are
many methods to generate more 3D faces from existing 3D faces through 3D face
data augmentation, which are used to train deep 3D face recognition models.
However, to the best of our knowledge, there is no method to generate 3D faces
from 2D face images for training deep 3D face recognition models. This letter
focuses on the role of reconstructed 3D facial surfaces in 3D face
identification and proposes a framework of 2D-aided deep 3D face
identification. In particular, we propose to reconstruct millions of 3D face
scans from a large scale 2D face database (i.e.VGGFace2), using a deep learning
based 3D face reconstruction method (i.e.ExpNet). Then, we adopt a two-phase
training approach: In the first phase, we use millions of face images to
pre-train the deep convolutional neural network (DCNN), and in the second
phase, we use normal component images (NCI) of reconstructed 3D face scans to
train the DCNN. Extensive experimental results illustrate that the proposed
approach can greatly improve the rank-1 score of 3D face identification on the
FRGC v2.0, the Bosphorus, and the BU-3DFE 3D face databases, compared to the
model trained by 2D face images. Finally, our proposed approach achieves
state-of-the-art rank-1 scores on the FRGC v2.0 (97.6%), Bosphorus (98.4%), and
BU-3DFE (98.8%) databases. The experimental results show that the reconstructed
3D facial surfaces are useful and our 2D-aided deep 3D face identification
framework is meaningful, facing the scarcity of 3D faces.
</p>
<a href="http://arxiv.org/abs/2010.08391" target="_blank">arXiv:2010.08391</a> [<a href="http://arxiv.org/pdf/2010.08391" target="_blank">pdf</a>]

<h2>Few-shot model-based adaptation in noisy conditions. (arXiv:2010.08397v1 [cs.LG])</h2>
<h3>Karol Arndt, Ali Ghadirzadeh, Murtaza Hazara, Ville Kyrki</h3>
<p>Few-shot adaptation is a challenging problem in the context of
simulation-to-real transfer in robotics, requiring safe and informative data
collection. In physical systems, additional challenge may be posed by domain
noise, which is present in virtually all real-world applications. In this
paper, we propose to perform few-shot adaptation of dynamics models in noisy
conditions using an uncertainty-aware Kalman filter-based neural network
architecture. We show that the proposed method, which explicitly addresses
domain noise, improves few-shot adaptation error over a blackbox adaptation
LSTM baseline, and over a model-free on-policy reinforcement learning approach,
which tries to learn an adaptable and informative policy at the same time. The
proposed method also allows for system analysis by analyzing hidden states of
the model during and after adaptation.
</p>
<a href="http://arxiv.org/abs/2010.08397" target="_blank">arXiv:2010.08397</a> [<a href="http://arxiv.org/pdf/2010.08397" target="_blank">pdf</a>]

<h2>On Automatic Feasibility Study for Machine Learning Application Development with ease.ml/snoopy. (arXiv:2010.08410v1 [cs.LG])</h2>
<h3>Cedric Renggli, Luka Rimanic, Luka Kolar, Nora Hollenstein, Wentao Wu, Ce Zhang</h3>
<p>In our experience working with domain experts who are using today's AutoML
systems, a common problem we encountered is what we call Unrealistic
Expectation: When users have access to very noisy or challenging datasets,
whilst being expected to achieve startlingly high accuracy with ML.
Consequently, many computationally expensive AutoML runs and labour-intensive
ML development processes are predestined to fail from the beginning. In
traditional software engineering, this problem is addressed via a feasibility
study, an indispensable step before developing any software system. In this
paper we present ease.ml/snoopy with the goal of preforming an automatic
feasibility study before building ML applications. A user provides inputs in
the form of a dataset and a quality target (e.g., expected accuracy $&gt;$ 0.8)
and the system returns its deduction on whether this target is achievable using
ML given the input data. We formulate this problem as estimating the
irreducible error of the underlying task, also known as the Bayes error. The
key contribution of this work is the study of this problem from a system's and
empirical perspective -- we (1) propose practical "compromises" that enable the
application of Bayes error estimators and (2) develop an evaluation framework
that compares different estimators empirically on real-world data. We then
systematically explore the design space by evaluating a range of estimators,
reporting not only the improvements of our proposed estimator but also
limitations of both our method and existing estimators.
</p>
<a href="http://arxiv.org/abs/2010.08410" target="_blank">arXiv:2010.08410</a> [<a href="http://arxiv.org/pdf/2010.08410" target="_blank">pdf</a>]

<h2>Vector-Vector-Matrix Architecture: A Novel Hardware-Aware Framework for Low-Latency Inference in NLP Applications. (arXiv:2010.08412v1 [cs.CL])</h2>
<h3>Matthew Khoury, Rumen Dangovski, Longwu Ou, Preslav Nakov, Yichen Shen, Li Jing</h3>
<p>Deep neural networks have become the standard approach to building reliable
Natural Language Processing (NLP) applications, ranging from Neural Machine
Translation (NMT) to dialogue systems. However, improving accuracy by
increasing the model size requires a large number of hardware computations,
which can slow down NLP applications significantly at inference time. To
address this issue, we propose a novel vector-vector-matrix architecture
(VVMA), which greatly reduces the latency at inference time for NMT. This
architecture takes advantage of specialized hardware that has low-latency
vector-vector operations and higher-latency vector-matrix operations. It also
reduces the number of parameters and FLOPs for virtually all models that rely
on efficient matrix multipliers without significantly impacting accuracy. We
present empirical results suggesting that our framework can reduce the latency
of sequence-to-sequence and Transformer models used for NMT by a factor of
four. Finally, we show evidence suggesting that our VVMA extends to other
domains, and we discuss novel hardware for its efficient use.
</p>
<a href="http://arxiv.org/abs/2010.08412" target="_blank">arXiv:2010.08412</a> [<a href="http://arxiv.org/pdf/2010.08412" target="_blank">pdf</a>]

<h2>Learning Robust Algorithms for Online Allocation Problems Using Adversarial Training. (arXiv:2010.08418v1 [cs.LG])</h2>
<h3>Goran Zuzic, Di Wang, Aranyak Mehta, D. Sivakumar</h3>
<p>We address the challenge of finding algorithms for online allocation (i.e.
bipartite matching) using a machine learning approach. In this paper, we focus
on the AdWords problem, which is a classical online budgeted matching problem
of both theoretical and practical significance. In contrast to existing work,
our goal is to accomplish algorithm design {\em tabula rasa}, i.e., without any
human-provided insights or expert-tuned training data beyond specifying the
objective and constraints of the optimization problem. We construct a framework
based on insights and ideas from game theory, adversarial training and GANs Key
to our approach is to generate adversarial examples that expose the weakness of
any given algorithm. A unique challenge in our context is to generate complete
examples from scratch rather than perturbing given examples and we demonstrate
this can be accomplished for the Adwords problem. We use this framework to
co-train an algorithm network and an adversarial network against each other
until they converge to an equilibrium. This approach finds algorithms and
adversarial examples that are consistent with known optimal results. Secondly,
we address the question of robustness of the algorithm, namely can we design
algorithms that are both strong under practical distributions, as well as
exhibit robust performance against adversarial instances. To accomplish this,
we train algorithm networks using a mixture of adversarial and practical
distributions like power-laws; the resulting networks exhibit a smooth
trade-off between the two input regimes.
</p>
<a href="http://arxiv.org/abs/2010.08418" target="_blank">arXiv:2010.08418</a> [<a href="http://arxiv.org/pdf/2010.08418" target="_blank">pdf</a>]

<h2>Multi-Adversarial Learning for Cross-Lingual Word Embeddings. (arXiv:2010.08432v1 [cs.CL])</h2>
<h3>Haozhou Wang, James Henderson, Paola Merlo</h3>
<p>Generative adversarial networks (GANs) have succeeded in inducing
cross-lingual word embeddings -- maps of matching words across languages --
without supervision. Despite these successes, GANs' performance for the
difficult case of distant languages is still not satisfactory. These
limitations have been explained by GANs' incorrect assumption that source and
target embedding spaces are related by a single linear mapping and are
approximately isomorphic. We assume instead that, especially across distant
languages, the mapping is only piece-wise linear, and propose a
multi-adversarial learning method. This novel method induces the seed
cross-lingual dictionary through multiple mappings, each induced to fit the
mapping for one subspace. Our experiments on unsupervised bilingual lexicon
induction show that this method improves performance over previous
single-mapping methods, especially for distant languages.
</p>
<a href="http://arxiv.org/abs/2010.08432" target="_blank">arXiv:2010.08432</a> [<a href="http://arxiv.org/pdf/2010.08432" target="_blank">pdf</a>]

<h2>An efficient representation of chronological events in medical texts. (arXiv:2010.08433v1 [cs.CL])</h2>
<h3>Andrey Kormilitzin, Nemanja Vaci, Qiang Liu, Hao Ni, Goran Nenadic, Alejo Nevado-Holgado</h3>
<p>In this work we addressed the problem of capturing sequential information
contained in longitudinal electronic health records (EHRs). Clinical notes,
which is a particular type of EHR data, are a rich source of information and
practitioners often develop clever solutions how to maximise the sequential
information contained in free-texts. We proposed a systematic methodology for
learning from chronological events available in clinical notes. The proposed
methodological {\it path signature} framework creates a non-parametric
hierarchical representation of sequential events of any type and can be used as
features for downstream statistical learning tasks. The methodology was
developed and externally validated using the largest in the UK secondary care
mental health EHR data on a specific task of predicting survival risk of
patients diagnosed with Alzheimer's disease. The signature-based model was
compared to a common survival random forest model. Our results showed a
15.4$\%$ increase of risk prediction AUC at the time point of 20 months after
the first admission to a specialist memory clinic and the signature method
outperformed the baseline mixed-effects model by 13.2 $\%$.
</p>
<a href="http://arxiv.org/abs/2010.08433" target="_blank">arXiv:2010.08433</a> [<a href="http://arxiv.org/pdf/2010.08433" target="_blank">pdf</a>]

<h2>Deep Learning based Automated Forest Health Diagnosis from Aerial Images. (arXiv:2010.08437v1 [cs.CV])</h2>
<h3>Chia-Yen Chiang, Chloe Barnes, Plamen Angelov, Richard Jiang</h3>
<p>Global climate change has had a drastic impact on our environment. Previous
study showed that pest disaster occured from global climate change may cause a
tremendous number of trees died and they inevitably became a factor of forest
fire. An important portent of the forest fire is the condition of forests.
Aerial image-based forest analysis can give an early detection of dead trees
and living trees. In this paper, we applied a synthetic method to enlarge
imagery dataset and present a new framework for automated dead tree detection
from aerial images using a re-trained Mask RCNN (Mask Region-based
Convolutional Neural Network) approach, with a transfer learning scheme. We
apply our framework to our aerial imagery datasets,and compare eight fine-tuned
models. The mean average precision score (mAP) for the best of these models
reaches 54%. Following the automated detection, we are able to automatically
produce and calculate number of dead tree masks to label the dead trees in an
image, as an indicator of forest health that could be linked to the causal
analysis of environmental changes and the predictive likelihood of forest fire.
</p>
<a href="http://arxiv.org/abs/2010.08437" target="_blank">arXiv:2010.08437</a> [<a href="http://arxiv.org/pdf/2010.08437" target="_blank">pdf</a>]

<h2>Impersonation on Social Media: A Deep Neural Approach to Identify Ingenuine Content. (arXiv:2010.08438v1 [cs.SI])</h2>
<h3>Koosha Zarei, Reza Farahbakhsh, Noel Crespi, Gareth Tyson</h3>
<p>Impersonators are playing an important role in the production and propagation
of the content on Online Social Networks, notably on Instagram. These entities
are nefarious fake accounts that intend to disguise a legitimate account by
making similar profiles and then striking social media by fake content, which
makes it considerably harder to understand which posts are genuinely produced.
In this study, we focus on three important communities with legitimate verified
accounts. Among them, we identify a collection of 2.2K impersonator profiles
with nearly 10k generated posts, 68K comments, and 90K likes. Then, based on
profile characteristics and user behaviours, we cluster them into two
collections of `bot' and `fan'. In order to separate the impersonator-generated
post from genuine content, we propose a Deep Neural Network architecture that
measures `profiles' and `posts' features to predict the content type:
`bot-generated', 'fan-generated', or `genuine' content. Our study shed light
into this interesting phenomena and provides interesting observation on
bot-generated content that can help us to understand the role of impersonators
in the production of fake content on Instagram.
</p>
<a href="http://arxiv.org/abs/2010.08438" target="_blank">arXiv:2010.08438</a> [<a href="http://arxiv.org/pdf/2010.08438" target="_blank">pdf</a>]

<h2>Policy Gradient for Continuing Tasks in Non-stationary Markov Decision Processes. (arXiv:2010.08443v1 [cs.LG])</h2>
<h3>Santiago Paternain, Juan Andres Bazerque, Alejandro Ribeiro</h3>
<p>Reinforcement learning considers the problem of finding policies that
maximize an expected cumulative reward in a Markov decision process with
unknown transition probabilities. In this paper we consider the problem of
finding optimal policies assuming that they belong to a reproducing kernel
Hilbert space (RKHS). To that end we compute unbiased stochastic gradients of
the value function which we use as ascent directions to update the policy. A
major drawback of policy gradient-type algorithms is that they are limited to
episodic tasks unless stationarity assumptions are imposed. Hence preventing
these algorithms to be fully implemented online, which is a desirable property
for systems that need to adapt to new tasks and/or environments in deployment.
The main requirement for a policy gradient algorithm to work is that the
estimate of the gradient at any point in time is an ascent direction for the
initial value function. In this work we establish that indeed this is the case
which enables to show the convergence of the online algorithm to the critical
points of the initial value function. A numerical example shows the ability of
our online algorithm to learn to solve a navigation and surveillance problem,
in which an agent must loop between to goal locations. This example
corroborates our theoretical findings about the ascent directions of subsequent
stochastic gradients. It also shows how the agent running our online algorithm
succeeds in learning to navigate, following a continuing cyclic trajectory that
does not comply with the standard stationarity assumptions in the literature
for non episodic training.
</p>
<a href="http://arxiv.org/abs/2010.08443" target="_blank">arXiv:2010.08443</a> [<a href="http://arxiv.org/pdf/2010.08443" target="_blank">pdf</a>]

<h2>Probabilistic Programming with CuPPL. (arXiv:2010.08454v1 [cs.PL])</h2>
<h3>Alexander Collins, Vinod Grover</h3>
<p>Probabilistic Programming Languages (PPLs) are a powerful tool in machine
learning, allowing highly expressive generative models to be expressed
succinctly. They couple complex inference algorithms, implemented by the
language, with an expressive modelling language that allows a user to implement
any computable function as the generative model. Such languages are usually
implemented on top of existing high level programming languages and do not make
use of hardware accelerators. PPLs that do make use of accelerators exist, but
restrict the expressivity of the language in order to do so. In this paper, we
present a language and toolchain that generates highly efficient code for both
CPUs and GPUs. The language is functional in style, and the tool chain is built
on top of LLVM. Our implementation uses de-limited continuations on CPU to
perform inference, and custom CUDA codes on GPU. We obtain significant speed
ups across a suite of PPL workloads, compared to other state of the art
approaches on CPU. Furthermore, our compiler can also generate efficient code
that runs on CUDA GPUs.
</p>
<a href="http://arxiv.org/abs/2010.08454" target="_blank">arXiv:2010.08454</a> [<a href="http://arxiv.org/pdf/2010.08454" target="_blank">pdf</a>]

<h2>Position paper: A systematic framework for categorising IoT device fingerprinting mechanisms. (arXiv:2010.08466v1 [cs.NI])</h2>
<h3>Poonam Yadav, Angelo Feraudo, Budi Arief, Siamak F. Shahandashti, Vassilios G. Vassilakis</h3>
<p>The popularity of the Internet of Things (IoT) devices makes it increasingly
important to be able to fingerprint them, for example in order to detect if
there are misbehaving or even malicious IoT devices in one's network. The aim
of this paper is to provide a systematic categorisation of machine learning
augmented techniques that can be used for fingerprinting IoT devices. This can
serve as a baseline for comparing various IoT fingerprinting mechanisms, so
that network administrators can choose one or more mechanisms that are
appropriate for monitoring and maintaining their network. We carried out an
extensive literature review of existing papers on fingerprinting IoT devices --
paying close attention to those with machine learning features. This is
followed by an extraction of important and comparable features among the
mechanisms outlined in those papers. As a result, we came up with a key set of
terminologies that are relevant both in the fingerprinting context and in the
IoT domain. This enabled us to construct a framework called IDWork, which can
be used for categorising existing IoT fingerprinting mechanisms in a way that
will facilitate a coherent and fair comparison of these mechanisms. We found
that the majority of the IoT fingerprinting mechanisms take a passive approach
-- mainly through network sniffing -- instead of being intrusive and
interactive with the device of interest. Additionally, a significant number of
the surveyed mechanisms employ both static and dynamic approaches, in order to
benefit from complementary features that can be more robust against certain
attacks such as spoofing and replay attacks.
</p>
<a href="http://arxiv.org/abs/2010.08466" target="_blank">arXiv:2010.08466</a> [<a href="http://arxiv.org/pdf/2010.08466" target="_blank">pdf</a>]

<h2>Machine Learning-Powered Mitigation Policy Optimization in Epidemiological Models. (arXiv:2010.08478v1 [cs.LG])</h2>
<h3>Jayaraman J. Thiagarajan, Peer-Timo Bremer, Rushil Anirudh, Timothy C. Germann, Sara Y. Del Valle, Frederick H. Streitz</h3>
<p>A crucial aspect of managing a public health crisis is to effectively balance
prevention and mitigation strategies, while taking their socio-economic impact
into account. In particular, determining the influence of different
non-pharmaceutical interventions (NPIs) on the effective use of public
resources is an important problem, given the uncertainties on when a vaccine
will be made available. In this paper, we propose a new approach for obtaining
optimal policy recommendations based on epidemiological models, which can
characterize the disease progression under different interventions, and a
look-ahead reward optimization strategy to choose the suitable NPI at different
stages of an epidemic. Given the time delay inherent in any epidemiological
model and the exponential nature especially of an unmanaged epidemic, we find
that such a look-ahead strategy infers non-trivial policies that adhere well to
the constraints specified. Using two different epidemiological models, namely
SEIR and EpiCast, we evaluate the proposed algorithm to determine the optimal
NPI policy, under a constraint on the number of daily new cases and the primary
reward being the absence of restrictions.
</p>
<a href="http://arxiv.org/abs/2010.08478" target="_blank">arXiv:2010.08478</a> [<a href="http://arxiv.org/pdf/2010.08478" target="_blank">pdf</a>]

<h2>A New Open-Access Platform for Measuring and Sharing mTBI Data. (arXiv:2010.08485v1 [cs.LG])</h2>
<h3>August G. Domel, Samuel J. Raymond, Chiara Giordano, Yuzhe Liu, Seyed Abdolmajid Yousefsani, Michael Fanton, Ileana Pirozzi, Ali Kight, Brett Avery, Athanasia Boumis, Tyler Fetters, Simran Jandu, William M Mehring, Sam Monga, Nicole Mouchawar, India Rangel, Eli Rice, Pritha Roy, Sohrab Sami, Heer Singh, Lyndia Wu, Calvin Kuo, Michael Zeineh, Gerald Grant, David B. Camarillo</h3>
<p>Despite numerous research efforts, the precise mechanisms of concussion have
yet to be fully uncovered. Clinical studies on high-risk populations, such as
contact sports athletes, have become more common and give insight on the link
between impact severity and brain injury risk through the use of wearable
sensors and neurological testing. However, as the number of institutions
operating these studies grows, there is a growing need for a platform to share
these data to facilitate our understanding of concussion mechanisms and aid in
the development of suitable diagnostic tools. To that end, this paper puts
forth two contributions: 1) a centralized, open-source platform for storing and
sharing head impact data, in collaboration with the Federal Interagency
Traumatic Brain Injury Research informatics system (FITBIR), and 2) a deep
learning impact detection algorithm (MiGNet) to differentiate between true head
impacts and false positives for the previously biomechanically validated
instrumented mouthguard sensor (MiG2.0), all of which easily interfaces with
FITBIR. We report 96% accuracy using MiGNet, based on a neural network model,
improving on previous work based on Support Vector Machines achieving 91%
accuracy, on an out of sample dataset of high school and collegiate football
head impacts. The integrated MiG2.0 and FITBIR system serve as a collaborative
research tool to be disseminated across multiple institutions towards creating
a standardized dataset for furthering the knowledge of concussion biomechanics.
</p>
<a href="http://arxiv.org/abs/2010.08485" target="_blank">arXiv:2010.08485</a> [<a href="http://arxiv.org/pdf/2010.08485" target="_blank">pdf</a>]

<h2>AAMDRL: Augmented Asset Management with Deep Reinforcement Learning. (arXiv:2010.08497v1 [cs.LG])</h2>
<h3>Eric Benhamou, David Saltiel, Sandrine Ungari, Abhishek Mukhopadhyay, Jamal Atif</h3>
<p>Can an agent learn efficiently in a noisy and self adapting environment with
sequential, non-stationary and non-homogeneous observations? Through trading
bots, we illustrate how Deep Reinforcement Learning (DRL) can tackle this
challenge. Our contributions are threefold: (i) the use of contextual
information also referred to as augmented state in DRL, (ii) the impact of a
one period lag between observations and actions that is more realistic for an
asset management environment, (iii) the implementation of a new repetitive
train test method called walk forward analysis, similar in spirit to cross
validation for time series. Although our experiment is on trading bots, it can
easily be translated to other bot environments that operate in sequential
environment with regime changes and noisy data. Our experiment for an augmented
asset manager interested in finding the best portfolio for hedging strategies
shows that AAMDRL achieves superior returns and lower risk.
</p>
<a href="http://arxiv.org/abs/2010.08497" target="_blank">arXiv:2010.08497</a> [<a href="http://arxiv.org/pdf/2010.08497" target="_blank">pdf</a>]

<h2>For self-supervised learning, Rationality implies generalization, provably. (arXiv:2010.08508v1 [cs.LG])</h2>
<h3>Yamini Bansal, Gal Kaplun, Boaz Barak</h3>
<p>We prove a new upper bound on the generalization gap of classifiers that are
obtained by first using self-supervision to learn a representation $r$ of the
training data, and then fitting a simple (e.g., linear) classifier $g$ to the
labels. Specifically, we show that (under the assumptions described below) the
generalization gap of such classifiers tends to zero if $\mathsf{C}(g) \ll n$,
where $\mathsf{C}(g)$ is an appropriately-defined measure of the simple
classifier $g$'s complexity, and $n$ is the number of training samples. We
stress that our bound is independent of the complexity of the representation
$r$. We do not make any structural or conditional-independence assumptions on
the representation-learning task, which can use the same training dataset that
is later used for classification. Rather, we assume that the training procedure
satisfies certain natural noise-robustness (adding small amount of label noise
causes small degradation in performance) and rationality (getting the wrong
label is not better than getting no label at all) conditions that widely hold
across many standard architectures. We show that our bound is non-vacuous for
many popular representation-learning based classifiers on CIFAR-10 and
ImageNet, including SimCLR, AMDIM and MoCo.
</p>
<a href="http://arxiv.org/abs/2010.08508" target="_blank">arXiv:2010.08508</a> [<a href="http://arxiv.org/pdf/2010.08508" target="_blank">pdf</a>]

<h2>An Approximation Algorithm for Optimal Subarchitecture Extraction. (arXiv:2010.08512v1 [cs.LG])</h2>
<h3>Adrian de Wynter</h3>
<p>We consider the problem of finding the set of architectural parameters for a
chosen deep neural network which is optimal under three metrics: parameter
size, inference speed, and error rate. In this paper we state the problem
formally, and present an approximation algorithm that, for a large subset of
instances behaves like an FPTAS with an approximation error of $\rho \leq |{1-
\epsilon}|$, and that runs in $O(|{\Xi}| + |{W^*_T}|(1 +
|{\Theta}||{B}||{\Xi}|/({\epsilon\, s^{3/2})}))$ steps, where $\epsilon$ and
$s$ are input parameters; $|{B}|$ is the batch size; $|{W^*_T}|$ denotes the
cardinality of the largest weight set assignment; and $|{\Xi}|$ and
$|{\Theta}|$ are the cardinalities of the candidate architecture and
hyperparameter spaces, respectively.
</p>
<a href="http://arxiv.org/abs/2010.08512" target="_blank">arXiv:2010.08512</a> [<a href="http://arxiv.org/pdf/2010.08512" target="_blank">pdf</a>]

<h2>Learnable Graph-regularization for Matrix Decomposition. (arXiv:2010.08513v1 [cs.LG])</h2>
<h3>Penglong Zhai, Shihua Zhang</h3>
<p>Low-rank approximation models of data matrices have become important machine
learning and data mining tools in many fields including computer vision, text
mining, bioinformatics and many others. They allow for embedding
high-dimensional data into low-dimensional spaces, which mitigates the effects
of noise and uncovers latent relations. In order to make the learned
representations inherit the structures in the original data,
graph-regularization terms are often added to the loss function. However, the
prior graph construction often fails to reflect the true network connectivity
and the intrinsic relationships. In addition, many graph-regularized methods
fail to take the dual spaces into account. Probabilistic models are often used
to model the distribution of the representations, but most of previous methods
often assume that the hidden variables are independent and identically
distributed for simplicity. To this end, we propose a learnable
graph-regularization model for matrix decomposition (LGMD), which builds a
bridge between graph-regularized methods and probabilistic matrix decomposition
models. LGMD learns two graphical structures (i.e., two precision matrices) in
real-time in an iterative manner via sparse precision matrix estimation and is
more robust to noise and missing entries. Extensive numerical results and
comparison with competing methods demonstrate its effectiveness.
</p>
<a href="http://arxiv.org/abs/2010.08513" target="_blank">arXiv:2010.08513</a> [<a href="http://arxiv.org/pdf/2010.08513" target="_blank">pdf</a>]

<h2>Interpretable Structured Learning with Sparse Gated Sequence Encoder for Protein-Protein Interaction Prediction. (arXiv:2010.08514v1 [cs.LG])</h2>
<h3>Kishan KC, Feng Cui, Anne Haake, Rui Li</h3>
<p>Predicting protein-protein interactions (PPIs) by learning informative
representations from amino acid sequences is a challenging yet important
problem in biology. Although various deep learning models in Siamese
architecture have been proposed to model PPIs from sequences, these methods are
computationally expensive for a large number of PPIs due to the pairwise
encoding process. Furthermore, these methods are difficult to interpret because
of non-intuitive mappings from protein sequences to their sequence
representation. To address these challenges, we present a novel deep framework
to model and predict PPIs from sequence alone. Our model incorporates a
bidirectional gated recurrent unit to learn sequence representations by
leveraging contextualized and sequential information from sequences. We further
employ a sparse regularization to model long-range dependencies between amino
acids and to select important amino acids (protein motifs), thus enhancing
interpretability. Besides, the novel design of the encoding process makes our
model computationally efficient and scalable to an increasing number of
interactions. Experimental results on up-to-date interaction datasets
demonstrate that our model achieves superior performance compared to other
state-of-the-art methods. Literature-based case studies illustrate the ability
of our model to provide biological insights to interpret the predictions.
</p>
<a href="http://arxiv.org/abs/2010.08514" target="_blank">arXiv:2010.08514</a> [<a href="http://arxiv.org/pdf/2010.08514" target="_blank">pdf</a>]

<h2>Why Are Convolutional Nets More Sample-Efficient than Fully-Connected Nets?. (arXiv:2010.08515v1 [cs.LG])</h2>
<h3>Zhiyuan Li, Yi Zhang, Sanjeev Arora</h3>
<p>Convolutional neural networks often dominate fully-connected counterparts in
generalization performance, especially on image classification tasks. This is
often explained in terms of 'better inductive bias'. However, this has not been
made mathematically rigorous, and the hurdle is that the fully connected net
can always simulate the convolutional net (for a fixed task). Thus the training
algorithm plays a role. The current work describes a natural task on which a
provable sample complexity gap can be shown, for standard training algorithms.
We construct a single natural distribution on $\mathbb{R}^d\times\{\pm 1\}$ on
which any orthogonal-invariant algorithm (i.e. fully-connected networks trained
with most gradient-based methods from gaussian initialization) requires
$\Omega(d^2)$ samples to generalize while $O(1)$ samples suffice for
convolutional architectures. Furthermore, we demonstrate a single target
function, learning which on all possible distributions leads to an $O(1)$ vs
$\Omega(d^2/\varepsilon)$ gap. The proof relies on the fact that SGD on
fully-connected network is orthogonal equivariant. Similar results are achieved
for $\ell_2$ regression and adaptive training algorithms, e.g. Adam and
AdaGrad, which are only permutation equivariant.
</p>
<a href="http://arxiv.org/abs/2010.08515" target="_blank">arXiv:2010.08515</a> [<a href="http://arxiv.org/pdf/2010.08515" target="_blank">pdf</a>]

<h2>Adaptive Feature Selection for End-to-End Speech Translation. (arXiv:2010.08518v1 [cs.CL])</h2>
<h3>Biao Zhang, Ivan Titov, Barry Haddow, Rico Sennrich</h3>
<p>Information in speech signals is not evenly distributed, making it an
additional challenge for end-to-end (E2E) speech translation (ST) to learn to
focus on informative features. In this paper, we propose adaptive feature
selection (AFS) for encoder-decoder based E2E ST. We first pre-train an ASR
encoder and apply AFS to dynamically estimate the importance of each encoded
speech feature to SR. A ST encoder, stacked on top of the ASR encoder, then
receives the filtered features from the (frozen) ASR encoder. We take L0DROP
(Zhang et al., 2020) as the backbone for AFS, and adapt it to sparsify speech
features with respect to both temporal and feature dimensions. Results on
LibriSpeech En-Fr and MuST-C benchmarks show that AFS facilitates learning of
ST by pruning out ~84% temporal features, yielding an average translation gain
of ~1.3-1.6 BLEU and a decoding speedup of ~1.4x. In particular, AFS reduces
the performance gap compared to the cascade baseline, and outperforms it on
LibriSpeech En-Fr with a BLEU score of 18.56 (without data augmentation)
</p>
<a href="http://arxiv.org/abs/2010.08518" target="_blank">arXiv:2010.08518</a> [<a href="http://arxiv.org/pdf/2010.08518" target="_blank">pdf</a>]

<h2>Data Analytics-enabled Intrusion Detection: Evaluations of ToN_IoT Linux Datasets. (arXiv:2010.08521v1 [cs.CR])</h2>
<h3>Nour Moustafa, Mohiuddin Ahmed, Sherif Ahmed</h3>
<p>With the widespread of Artificial Intelligence (AI)- enabled security
applications, there is a need for collecting heterogeneous and scalable data
sources for effectively evaluating the performances of security applications.
This paper presents the description of new datasets, named ToN IoT datasets
that include distributed data sources collected from Telemetry datasets of
Internet of Things (IoT) services, Operating systems datasets of Windows and
Linux, and datasets of Network traffic. The paper aims to describe the new
testbed architecture used to collect Linux datasets from audit traces of hard
disk, memory and process. The architecture was designed in three distributed
layers of edge, fog, and cloud. The edge layer comprises IoT and network
systems, the fog layer includes virtual machines and gateways, and the cloud
layer includes data analytics and visualization tools connected with the other
two layers. The layers were programmatically controlled using Software-Defined
Network (SDN) and Network-Function Virtualization (NFV) using the VMware NSX
and vCloud NFV platform. The Linux ToN IoT datasets would be used to train and
validate various new federated and distributed AI-enabled security solutions
such as intrusion detection, threat intelligence, privacy preservation and
digital forensics. Various Data analytical and machine learning methods are
employed to determine the fidelity of the datasets in terms of examining
feature engineering, statistics of legitimate and security events, and
reliability of security events. The datasets can be publicly accessed from [1].
</p>
<a href="http://arxiv.org/abs/2010.08521" target="_blank">arXiv:2010.08521</a> [<a href="http://arxiv.org/pdf/2010.08521" target="_blank">pdf</a>]

<h2>Federated TON_IoT Windows Datasets for Evaluating AI-based Security Applications. (arXiv:2010.08522v1 [cs.CR])</h2>
<h3>Nour Moustafa, Marwa Keshk, Essam Debie, Helge Janicke</h3>
<p>Existing cyber security solutions have been basically developed using
knowledge-based models that often cannot trigger new cyber-attack families.
With the boom of Artificial Intelligence (AI), especially Deep Learning (DL)
algorithms, those security solutions have been plugged-in with AI models to
discover, trace, mitigate or respond to incidents of new security events. The
algorithms demand a large number of heterogeneous data sources to train and
validate new security systems. This paper presents the description of new
datasets, the so-called ToN_IoT, which involve federated data sources collected
from telemetry datasets of IoT services, operating system datasets of Windows
and Linux, and datasets of network traffic. The paper introduces the testbed
and description of TON_IoT datasets for Windows operating systems. The testbed
was implemented in three layers: edge, fog and cloud. The edge layer involves
IoT and network devices, the fog layer contains virtual machines and gateways,
and the cloud layer involves cloud services, such as data analytics, linked to
the other two layers. These layers were dynamically managed using the platforms
of software-Defined Network (SDN) and Network-Function Virtualization (NFV)
using the VMware NSX and vCloud NFV platform. The Windows datasets were
collected from audit traces of memories, processors, networks, processes and
hard disks. The datasets would be used to evaluate various AI-based cyber
security solutions, including intrusion detection, threat intelligence and
hunting, privacy preservation and digital forensics. This is because the
datasets have a wide range of recent normal and attack features and
observations, as well as authentic ground truth events. The datasets can be
publicly accessed from this link [1].
</p>
<a href="http://arxiv.org/abs/2010.08522" target="_blank">arXiv:2010.08522</a> [<a href="http://arxiv.org/pdf/2010.08522" target="_blank">pdf</a>]

<h2>Communication-Avoiding and Memory-Constrained Sparse Matrix-Matrix Multiplication at Extreme Scale. (arXiv:2010.08526v1 [cs.DC])</h2>
<h3>Md Taufique Hussain, Oguz Selvitopi, Aydin Bulu&#xe7;, Ariful Azad</h3>
<p>Sparse matrix-matrix multiplication (SpGEMM) is a widely used kernel in
various graph, scientific computing and machine learning algorithms. In this
paper, we consider SpGEMMs performed on hundreds of thousands of processors
generating trillions of nonzeros in the output matrix. Distributed SpGEMM at
this extreme scale faces two key challenges: (1) high communication cost and
(2) inadequate memory to generate the output. We address these challenges with
an integrated communication-avoiding and memory-constrained SpGEMM algorithm
that scales to 262,144 cores (more than 1 million hardware threads) and can
multiply sparse matrices of any size as long as inputs and a fraction of output
fit in the aggregated memory. As we go from 16,384 cores to 262,144 cores on a
Cray XC40 supercomputer, the new SpGEMM algorithm runs 10x faster when
multiplying large-scale protein-similarity matrices.
</p>
<a href="http://arxiv.org/abs/2010.08526" target="_blank">arXiv:2010.08526</a> [<a href="http://arxiv.org/pdf/2010.08526" target="_blank">pdf</a>]

<h2>Deep Learning Head Model for Real-time Estimation of Entire Brain Deformation in Concussion. (arXiv:2010.08527v1 [q-bio.TO])</h2>
<h3>Xianghao Zhan, Yuzhe Liu, Samuel J. Raymond, Hossein V. Alizadeh, August G. Domel, Olivier Gevaert, Michael Zeineh, Gerald Grant, David B. Camarillo</h3>
<p>Objective: Many recent studies have suggested that brain deformation
resulting from a head impact is linked to the corresponding clinical outcome,
such as mild traumatic brain injury (mTBI). Even though several finite element
(FE) head models have been developed and validated to calculate brain
deformation based on impact kinematics, the clinical application of these FE
head models is limited due to the time-consuming nature of FE simulations. This
work aims to accelerate the process of brain deformation calculation and thus
improve the potential for clinical applications. Methods: We propose a deep
learning head model with a five-layer deep neural network and feature
engineering, and trained and tested the model on 1803 total head impacts from a
combination of head model simulations and on-field college football and mixed
martial arts impacts. Results: The proposed deep learning head model can
calculate the maximum principal strain for every element in the entire brain in
less than 0.001s (with an average root mean squared error of 0.025, and with a
standard deviation of 0.002 over twenty repeats with random data partition and
model initialization). The contributions of various features to the predictive
power of the model were investigated, and it was noted that the features based
on angular acceleration were found to be more predictive than the features
based on angular velocity. Conclusion: Trained using the dataset of 1803 head
impacts, this model can be applied to various sports in the calculation of
brain strain with accuracy, and its applicability can even further be extended
by incorporating data from other types of head impacts. Significance: In
addition to the potential clinical application in real-time brain deformation
monitoring, this model will help researchers estimate the brain strain from a
large number of head impacts more efficiently than using FE models.
</p>
<a href="http://arxiv.org/abs/2010.08527" target="_blank">arXiv:2010.08527</a> [<a href="http://arxiv.org/pdf/2010.08527" target="_blank">pdf</a>]

<h2>Feature Selection for Huge Data via Minipatch Learning. (arXiv:2010.08529v1 [stat.ML])</h2>
<h3>Tianyi Yao, Genevera I. Allen</h3>
<p>Feature selection often leads to increased model interpretability, faster
computation, and improved model performance by discarding irrelevant or
redundant features. While feature selection is a well-studied problem with many
widely-used techniques, there are typically two key challenges: i) many
existing approaches become computationally intractable in huge-data settings
with millions of observations and features; and ii) the statistical accuracy of
selected features degrades in high-noise, high-correlation settings, thus
hindering reliable model interpretation. We tackle these problems by proposing
Stable Minipatch Selection (STAMPS) and Adaptive STAMPS (AdaSTAMPS). These are
meta-algorithms that build ensembles of selection events of base feature
selectors trained on many tiny, (adaptively-chosen) random subsets of both the
observations and features of the data, which we call minipatches. Our
approaches are general and can be employed with a variety of existing feature
selection strategies and machine learning techniques. In addition, we provide
theoretical insights on STAMPS and empirically demonstrate that our approaches,
especially AdaSTAMPS, dominate competing methods in terms of feature selection
accuracy and computational time.
</p>
<a href="http://arxiv.org/abs/2010.08529" target="_blank">arXiv:2010.08529</a> [<a href="http://arxiv.org/pdf/2010.08529" target="_blank">pdf</a>]

<h2>Multi-Agent Collaboration via Reward Attribution Decomposition. (arXiv:2010.08531v1 [cs.LG])</h2>
<h3>Tianjun Zhang, Huazhe Xu, Xiaolong Wang, Yi Wu, Kurt Keutzer, Joseph E. Gonzalez, Yuandong Tian</h3>
<p>Recent advances in multi-agent reinforcement learning (MARL) have achieved
super-human performance in games like Quake 3 and Dota 2. Unfortunately, these
techniques require orders-of-magnitude more training rounds than humans and
don't generalize to new agent configurations even on the same game. In this
work, we propose Collaborative Q-learning (CollaQ) that achieves
state-of-the-art performance in the StarCraft multi-agent challenge and
supports ad hoc team play. We first formulate multi-agent collaboration as a
joint optimization on reward assignment and show that each agent has an
approximately optimal policy that decomposes into two parts: one part that only
relies on the agent's own state, and the other part that is related to states
of nearby agents. Following this novel finding, CollaQ decomposes the
Q-function of each agent into a self term and an interactive term, with a
Multi-Agent Reward Attribution (MARA) loss that regularizes the training.
CollaQ is evaluated on various StarCraft maps and shows that it outperforms
existing state-of-the-art techniques (i.e., QMIX, QTRAN, and VDN) by improving
the win rate by 40% with the same number of samples. In the more challenging ad
hoc team play setting (i.e., reweight/add/remove units without re-training or
finetuning), CollaQ outperforms previous SoTA by over 30%.
</p>
<a href="http://arxiv.org/abs/2010.08531" target="_blank">arXiv:2010.08531</a> [<a href="http://arxiv.org/pdf/2010.08531" target="_blank">pdf</a>]

<h2>Towards Accurate Knowledge Transfer via Target-awareness Representation Disentanglement. (arXiv:2010.08532v1 [cs.LG])</h2>
<h3>Xingjian Li, Di Hu, Xuhong Li, Haoyi Xiong, Zhi Ye, Zhipeng Wang, Chengzhong Xu, Dejing Dou</h3>
<p>Fine-tuning deep neural networks pre-trained on large scale datasets is one
of the most practical transfer learning paradigm given limited quantity of
training samples. To obtain better generalization, using the starting point as
the reference, either through weights or features, has been successfully
applied to transfer learning as a regularizer. However, due to the domain
discrepancy between the source and target tasks, there exists obvious risk of
negative transfer. In this paper, we propose a novel transfer learning
algorithm, introducing the idea of Target-awareness REpresentation
Disentanglement (TRED), where the relevant knowledge with respect to the target
task is disentangled from the original source model and used as a regularizer
during fine-tuning the target model. Experiments on various real world datasets
show that our method stably improves the standard fine-tuning by more than 2%
in average. TRED also outperforms other state-of-the-art transfer learning
regularizers such as L2-SP, AT, DELTA and BSS.
</p>
<a href="http://arxiv.org/abs/2010.08532" target="_blank">arXiv:2010.08532</a> [<a href="http://arxiv.org/pdf/2010.08532" target="_blank">pdf</a>]

<h2>Latent Vector Recovery of Audio GANs. (arXiv:2010.08534v1 [cs.SD])</h2>
<h3>Andrew Keyes, Nicky Bayat, Vahid Reza Khazaie, Yalda Mohsenzadeh</h3>
<p>Advanced Generative Adversarial Networks (GANs) are remarkable in generating
intelligible audio from a random latent vector. In this paper, we examine the
task of recovering the latent vector of both synthesized and real audio.
Previous works recovered latent vectors of given audio through an auto-encoder
inspired technique that trains an encoder network either in parallel with the
GAN or after the generator is trained. With our approach, we train a deep
residual neural network architecture to project audio synthesized by WaveGAN
into the corresponding latent space with near identical reconstruction
performance. To accommodate for the lack of an original latent vector for real
audio, we optimize the residual network on the perceptual loss between the real
audio samples and the reconstructed audio of the predicted latent vectors. In
the case of synthesized audio, the Mean Squared Error (MSE) between the ground
truth and recovered latent vector is minimized as well. We further investigated
the audio reconstruction performance when several gradient optimization steps
are applied to the predicted latent vector. Through our deep neural network
based method of training on real and synthesized audio, we are able to predict
a latent vector that corresponds to a reasonable reconstruction of real audio.
Even though we evaluated our method on WaveGAN, our proposed method is
universal and can be applied to any other GANs.
</p>
<a href="http://arxiv.org/abs/2010.08534" target="_blank">arXiv:2010.08534</a> [<a href="http://arxiv.org/pdf/2010.08534" target="_blank">pdf</a>]

<h2>What Can You Learn from Your Muscles? Learning Visual Representation from Human Interactions. (arXiv:2010.08539v1 [cs.CV])</h2>
<h3>Kiana Ehsani, Daniel Gordon, Thomas Nguyen, Roozbeh Mottaghi, Ali Farhadi</h3>
<p>Learning effective representations of visual data that generalize to a
variety of downstream tasks has been a long quest for computer vision. Most
representation learning approaches rely solely on visual data such as images or
videos. In this paper, we explore a novel approach, where we use human
interaction and attention cues to investigate whether we can learn better
representations compared to visual-only representations. For this study, we
collect a dataset of human interactions capturing body part movements and gaze
in their daily lives. Our experiments show that our self-supervised
representation that encodes interaction and attention cues outperforms a
visual-only state-of-the-art method MoCo (He et al., 2020), on a variety of
target tasks: scene classification (semantic), action recognition (temporal),
depth estimation (geometric), dynamics prediction (physics) and walkable
surface estimation (affordance).
</p>
<a href="http://arxiv.org/abs/2010.08539" target="_blank">arXiv:2010.08539</a> [<a href="http://arxiv.org/pdf/2010.08539" target="_blank">pdf</a>]

<h2>Salient Object Detection with Convex Hull Overlap. (arXiv:1612.03284v2 [cs.CV] UPDATED)</h2>
<h3>Yongqing Liang</h3>
<p>Salient object detection plays an important part in a vision system to detect
important regions. Convolutional neural network (CNN) based methods directly
train their models with large-scale datasets, but what is the crucial feature
for saliency is still a problem. In this paper, we establish a novel bottom-up
feature named convex hull overlap (CHO), combining with appearance contrast
features, to detect salient objects. CHO feature is a kind of enhanced Gestalt
cue. Psychologists believe that surroundedness reflects objects overlap
relationship. An object which is on the top of the others is attractive. Our
method significantly differs from other earlier works in (1) We set up a
hand-crafted feature to detect salient object that our model does not need to
be trained by large-scale datasets; (2) Previous works only focus on appearance
features, while our CHO feature makes up the gap between the spatial object
covering and the object's saliency. Our experiments on a large number of public
datasets have obtained very positive results.
</p>
<a href="http://arxiv.org/abs/1612.03284" target="_blank">arXiv:1612.03284</a> [<a href="http://arxiv.org/pdf/1612.03284" target="_blank">pdf</a>]

<h2>SIGUA: Forgetting May Make Learning with Noisy Labels More Robust. (arXiv:1809.11008v3 [cs.LG] UPDATED)</h2>
<h3>Bo Han, Gang Niu, Xingrui Yu, Quanming Yao, Miao Xu, Ivor Tsang, Masashi Sugiyama</h3>
<p>Given data with noisy labels, over-parameterized deep networks can gradually
memorize the data, and fit everything in the end. Although equipped with
corrections for noisy labels, many learning methods in this area still suffer
overfitting due to undesired memorization. In this paper, to relieve this
issue, we propose stochastic integrated gradient underweighted ascent (SIGUA):
in a mini-batch, we adopt gradient descent on good data as usual, and
learning-rate-reduced gradient ascent on bad data; the proposal is a versatile
approach where data goodness or badness is w.r.t. desired or undesired
memorization given a base learning method. Technically, SIGUA pulls
optimization back for generalization when their goals conflict with each other;
philosophically, SIGUA shows forgetting undesired memorization can reinforce
desired memorization. Experiments demonstrate that SIGUA successfully
robustifies two typical base learning methods, so that their performance is
often significantly improved.
</p>
<a href="http://arxiv.org/abs/1809.11008" target="_blank">arXiv:1809.11008</a> [<a href="http://arxiv.org/pdf/1809.11008" target="_blank">pdf</a>]

<h2>Fair Decisions Despite Imperfect Predictions. (arXiv:1902.02979v4 [cs.LG] UPDATED)</h2>
<h3>Niki Kilbertus, Manuel Gomez-Rodriguez, Bernhard Sch&#xf6;lkopf, Krikamol Muandet, Isabel Valera</h3>
<p>Consequential decisions are increasingly informed by sophisticated
data-driven predictive models. However, to consistently learn accurate
predictive models, one needs access to ground truth labels. Unfortunately, in
practice, labels may only exist conditional on certain decisions---if a loan is
denied, there is not even an option for the individual to pay back the loan.
Hence, the observed data distribution depends on how decisions are being made.
In this paper, we show that in this selective labels setting, learning a
predictor directly only from available labeled data is suboptimal in terms of
both fairness and utility. To avoid this undesirable behavior, we propose to
directly learn decision policies that maximize utility under fairness
constraints and thereby take into account how decisions affect which data is
observed in the future. Our results suggest the need for a paradigm shift in
the context of fair machine learning from the currently prevalent idea of
simply building predictive models from a single static dataset via risk
minimization, to a more interactive notion of "learning to decide". In
particular, such policies should not entirely neglect part of the input space,
drawing connections to explore/exploit tradeoffs in reinforcement learning,
data missingness, and potential outcomes in causal inference. Experiments on
synthetic and real-world data illustrate the favorable properties of learning
to decide in terms of utility and fairness.
</p>
<a href="http://arxiv.org/abs/1902.02979" target="_blank">arXiv:1902.02979</a> [<a href="http://arxiv.org/pdf/1902.02979" target="_blank">pdf</a>]

<h2>A Novel Just-Noticeable-Difference-based Saliency-Channel Attention Residual Network for Full-Reference Image Quality Predictions. (arXiv:1902.05316v4 [cs.CV] UPDATED)</h2>
<h3>Soomin Seo, Sehwan Ki, Munchurl Kim</h3>
<p>Recently, due to the strength of deep convolutional neural networks (CNN),
many CNN-based image quality assessment (IQA) models have been studied.
However, previous CNN-based IQA models likely have yet to utilize the
characteristics of the human visual system (HVS) fully for IQA problems when
they simply entrust everything to the CNN, expecting it to learn from a
training dataset. However, in this paper, we propose a novel saliency-channel
attention residual network based on the just-noticeable-difference (JND)
concept for full-reference image quality assessments (FR-IQA). It is referred
to as JND-SalCAR and shows significant improvements in large IQA datasets with
various types of distortion. The proposed JND-SalCAR effectively learns how to
incorporate human psychophysical characteristics, such as visual saliency and
JND, into image quality predictions. In the proposed network, a SalCAR block is
devised so that perceptually important features can be extracted with the help
of saliency-based spatial attention and channel attention schemes. In addition,
a saliency map serves as a guideline for predicting a patch weight map in order
to afford stable training of end-to-end optimization for the JND-SalCAR. To the
best of our knowledge, our work presents the first HVS-inspired trainable
FR-IQA network that considers both visual saliency and the JND characteristics
of the HVS. When the visual saliency map and the JND probability map are
explicitly given as priors, they can be usefully combined to predict IQA scores
rated by humans more precisely, eventually leading to performance improvements
and faster convergence. The experimental results show that the proposed
JND-SalCAR significantly outperforms all recent state-of-the-art FR-IQA methods
on large IQA datasets in terms of the Spearman rank order coefficient (SRCC)
and the Pearson linear correlation coefficient (PLCC).
</p>
<a href="http://arxiv.org/abs/1902.05316" target="_blank">arXiv:1902.05316</a> [<a href="http://arxiv.org/pdf/1902.05316" target="_blank">pdf</a>]

<h2>Algorithms for Verifying Deep Neural Networks. (arXiv:1903.06758v2 [cs.LG] UPDATED)</h2>
<h3>Changliu Liu, Tomer Arnon, Christopher Lazarus, Clark Barrett, Mykel J. Kochenderfer</h3>
<p>Deep neural networks are widely used for nonlinear function approximation
with applications ranging from computer vision to control. Although these
networks involve the composition of simple arithmetic operations, it can be
very challenging to verify whether a particular network satisfies certain
input-output properties. This article surveys methods that have emerged
recently for soundly verifying such properties. These methods borrow insights
from reachability analysis, optimization, and search. We discuss fundamental
differences and connections between existing algorithms. In addition, we
provide pedagogical implementations of existing methods and compare them on a
set of benchmark problems.
</p>
<a href="http://arxiv.org/abs/1903.06758" target="_blank">arXiv:1903.06758</a> [<a href="http://arxiv.org/pdf/1903.06758" target="_blank">pdf</a>]

<h2>Dynamic Control of Stochastic Evolution: A Deep Reinforcement Learning Approach to Adaptively Targeting Emergent Drug Resistance. (arXiv:1903.11373v2 [q-bio.PE] UPDATED)</h2>
<h3>Dalit Engelhardt</h3>
<p>The challenge in controlling stochastic systems in which low-probability
events can set the system on catastrophic trajectories is to develop a robust
ability to respond to such events without significantly compromising the
optimality of the baseline control policy. This paper presents CelluDose, a
stochastic simulation-trained deep reinforcement learning adaptive feedback
control prototype for automated precision drug dosing targeting stochastic and
heterogeneous cell proliferation. Drug resistance can emerge from random and
variable mutations in targeted cell populations; in the absence of an
appropriate dosing policy, emergent resistant subpopulations can proliferate
and lead to treatment failure. Dynamic feedback dosage control holds promise in
combatting this phenomenon, but the application of traditional control
approaches to such systems is fraught with challenges due to the complexity of
cell dynamics, uncertainty in model parameters, and the need in medical
applications for a robust controller that can be trusted to properly handle
unexpected outcomes. Here, training on a sample biological scenario identified
single-drug and combination therapy policies that exhibit a 100% success rate
at suppressing cell proliferation and responding to diverse system
perturbations while establishing low-dose no-event baselines. These policies
were found to be highly robust to variations in a key model parameter subject
to significant uncertainty and unpredictable dynamical changes.
</p>
<a href="http://arxiv.org/abs/1903.11373" target="_blank">arXiv:1903.11373</a> [<a href="http://arxiv.org/pdf/1903.11373" target="_blank">pdf</a>]

<h2>Minimum Uncertainty Based Detection of Adversaries in Deep Neural Networks. (arXiv:1904.02841v2 [cs.LG] UPDATED)</h2>
<h3>Fatemeh Sheikholeslami, Swayambhoo Jain, Georgios B. Giannakis</h3>
<p>Despite their unprecedented performance in various domains, utilization of
Deep Neural Networks (DNNs) in safety-critical environments is severely limited
in the presence of even small adversarial perturbations. The present work
develops a randomized approach to detecting such perturbations based on minimum
uncertainty metrics that rely on sampling at the hidden layers during the DNN
inference stage. Inspired by Bayesian approaches to uncertainty estimation, the
sampling probabilities are designed for effective detection of the
adversarially corrupted inputs. Being modular, the novel detector of
adversaries can be conveniently employed by any pre-trained DNN at no extra
training overhead. Selecting which units to sample per hidden layer entails
quantifying the amount of DNN output uncertainty, where the overall uncertainty
is expressed in terms of its layer-wise components - what also promotes
scalability. Sampling probabilities are then sought by minimizing uncertainty
measures layer-by-layer, leading to a novel convex optimization problem that
admits an exact solver with superlinear convergence rate. By simplifying the
objective function, low-complexity approximate solvers are also developed. In
addition to valuable insights, these approximations link the novel approach
with state-of-the-art randomized adversarial detectors. The effectiveness of
the novel detectors in the context of competing alternatives is highlighted
through extensive tests for various types of adversarial attacks with variable
levels of strength.
</p>
<a href="http://arxiv.org/abs/1904.02841" target="_blank">arXiv:1904.02841</a> [<a href="http://arxiv.org/pdf/1904.02841" target="_blank">pdf</a>]

<h2>Learning-Driven Exploration for Reinforcement Learning. (arXiv:1906.06890v2 [cs.LG] UPDATED)</h2>
<h3>Muhammad Usama, Dong Eui Chang</h3>
<p>Effective and intelligent exploration has been an unresolved problem for
reinforcement learning. Most contemporary reinforcement learning relies on
simple heuristic strategies such as $\epsilon$-greedy exploration or adding
Gaussian noise to actions. These heuristics, however, are unable to
intelligently distinguish the well explored and the unexplored regions of state
space, which can lead to inefficient use of training time. We introduce
entropy-based exploration (EBE) that enables an agent to explore efficiently
the unexplored regions of state space. EBE quantifies the agent's learning in a
state using merely state-dependent action values and adaptively explores the
state space, i.e. more exploration for the unexplored region of the state
space. We perform experiments on a diverse set of environments and demonstrate
that EBE enables efficient exploration that ultimately results in faster
learning without having to tune any hyperparameter.

The code to reproduce the experiments is given at
\url{https://github.com/Usama1002/EBE-Exploration} and the supplementary video
is given at \url{https://youtu.be/nJggIjjzKic}.
</p>
<a href="http://arxiv.org/abs/1906.06890" target="_blank">arXiv:1906.06890</a> [<a href="http://arxiv.org/pdf/1906.06890" target="_blank">pdf</a>]

<h2>Inherent Tradeoffs in Learning Fair Representations. (arXiv:1906.08386v4 [cs.LG] UPDATED)</h2>
<h3>Han Zhao, Geoffrey J. Gordon</h3>
<p>With the prevalence of machine learning in high-stakes applications,
especially the ones regulated by anti-discrimination laws or societal norms, it
is crucial to ensure that the predictive models do not propagate any existing
bias or discrimination. Due to the ability of deep neural nets to learn rich
representations, recent advances in algorithmic fairness have focused on
learning fair representations with adversarial techniques to reduce bias in
data while preserving utility simultaneously. In this paper, through the lens
of information theory, we provide the first result that quantitatively
characterizes the tradeoff between demographic parity and the joint utility
across different population groups. Specifically, when the base rates differ
between groups, we show that any method aiming to learn fair representations
admits an information-theoretic lower bound on the joint error across these
groups. To complement our negative results, we also prove that if the optimal
decision functions across different groups are close, then learning fair
representations leads to an alternative notion of fairness, known as the
accuracy parity, which states that the error rates are close between groups.
Finally, our theoretical findings are also confirmed empirically on real-world
datasets.
</p>
<a href="http://arxiv.org/abs/1906.08386" target="_blank">arXiv:1906.08386</a> [<a href="http://arxiv.org/pdf/1906.08386" target="_blank">pdf</a>]

<h2>DeepNC: Deep Generative Network Completion. (arXiv:1907.07381v3 [cs.SI] UPDATED)</h2>
<h3>Cong Tran, Won-Yong Shin, Andreas Spitz, Michael Gertz</h3>
<p>Most network data are collected from partially observable networks with both
missing nodes and missing edges, for example, due to limited resources and
privacy settings specified by users on social media. Thus, it stands to reason
that inferring the missing parts of the networks by performing network
completion should precede downstream applications. However, despite this need,
the recovery of missing nodes and edges in such incomplete networks is an
insufficiently explored problem due to the modeling difficulty, which is much
more challenging than link prediction that only infers missing edges. In this
paper, we present DeepNC, a novel method for inferring the missing parts of a
network based on a deep generative model of graphs. Specifically, our method
first learns a likelihood over edges via an autoregressive generative model,
and then identifies the graph that maximizes the learned likelihood conditioned
on the observable graph topology. Moreover, we propose a computationally
efficient DeepNC algorithm that consecutively finds individual nodes that
maximize the probability in each node generation step, as well as an enhanced
version using the expectation-maximization algorithm. The runtime complexities
of both algorithms are shown to be almost linear in the number of nodes in the
network. We empirically demonstrate the superiority of DeepNC over
state-of-the-art network completion approaches.
</p>
<a href="http://arxiv.org/abs/1907.07381" target="_blank">arXiv:1907.07381</a> [<a href="http://arxiv.org/pdf/1907.07381" target="_blank">pdf</a>]

<h2>Evolutionary Algorithms and Efficient Data Analytics for Image Processing. (arXiv:1907.12914v2 [cs.CV] UPDATED)</h2>
<h3>Farid Ghareh Mohammadi, Farzan Shenavarmasouleh, M. Hadi Amini, Hamid R. Arabnia</h3>
<p>NP-hard problems always have been attracting scientists' attentions, and most
often seen in the emerging challenging issues. The most interesting NP-hard
problems emerging in the world of data science is Curse of dimensionality
(CoD). Recently, this problem has penetrated most of high technology domains
like advanced image processing, particularly image steganalysis. The universal
and smarter steganalysis algorithms provide a huge number of attributes, which
make working with data hard to process. In large data sets, finding a pattern
which governs whole data takes long time, and yet no guarantee to reach the
optimal pattern. In general, the purpose of the researchers in image
steganalysis stands for distinguishing stego images from cover images. In this
paper, we investigated recent works on detecting stego images, particularly
those algorithms that adopted evolutionary algorithms. Thus, our work is
categorized as supervised learning which consider ground truth to evaluate the
performance of given algorithm. The objective is to provide a comprehensive
understanding of evolutionary algorithms which are attempted to solve this
NP-hard problems.
</p>
<a href="http://arxiv.org/abs/1907.12914" target="_blank">arXiv:1907.12914</a> [<a href="http://arxiv.org/pdf/1907.12914" target="_blank">pdf</a>]

<h2>P2L: Predicting Transfer Learning for Images and Semantic Relations. (arXiv:1908.07630v2 [cs.LG] UPDATED)</h2>
<h3>Bishwaranjan Bhattacharjee, John R. Kender, Matthew Hill, Parijat Dube, Siyu Huo, Michael R. Glass, Brian Belgodere, Sharath Pankanti, Noel Codella, Patrick Watson</h3>
<p>Transfer learning enhances learning across tasks, by leveraging previously
learned representations -- if they are properly chosen. We describe an
efficient method to accurately estimate the appropriateness of a previously
trained model for use in a new learning task. We use this measure, which we
call "Predict To Learn" ("P2L"), in the two very different domains of images
and semantic relations, where it predicts, from a set of "source" models, the
one model most likely to produce effective transfer for training a given
"target" model. We validate our approach thoroughly, by assembling a collection
of candidate source models, then fine-tuning each candidate to perform each of
a collection of target tasks, and finally measuring how well transfer has been
enhanced. Across 95 tasks within multiple domains (images classification and
semantic relations), the P2L approach was able to select the best transfer
learning model on average, while the heuristic of choosing model trained with
the largest data set selected the best model in only 55 cases. These results
suggest that P2L captures important information in common between source and
target tasks, and that this shared informational structure contributes to
successful transfer learning more than simple data size.
</p>
<a href="http://arxiv.org/abs/1908.07630" target="_blank">arXiv:1908.07630</a> [<a href="http://arxiv.org/pdf/1908.07630" target="_blank">pdf</a>]

<h2>TinyBERT: Distilling BERT for Natural Language Understanding. (arXiv:1909.10351v5 [cs.CL] UPDATED)</h2>
<h3>Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin Li, Fang Wang, Qun Liu</h3>
<p>Language model pre-training, such as BERT, has significantly improved the
performances of many natural language processing tasks. However, pre-trained
language models are usually computationally expensive, so it is difficult to
efficiently execute them on resource-restricted devices. To accelerate
inference and reduce model size while maintaining accuracy, we first propose a
novel Transformer distillation method that is specially designed for knowledge
distillation (KD) of the Transformer-based models. By leveraging this new KD
method, the plenty of knowledge encoded in a large teacher BERT can be
effectively transferred to a small student Tiny-BERT. Then, we introduce a new
two-stage learning framework for TinyBERT, which performs Transformer
distillation at both the pretraining and task-specific learning stages. This
framework ensures that TinyBERT can capture he general-domain as well as the
task-specific knowledge in BERT.

TinyBERT with 4 layers is empirically effective and achieves more than 96.8%
the performance of its teacher BERTBASE on GLUE benchmark, while being 7.5x
smaller and 9.4x faster on inference. TinyBERT with 4 layers is also
significantly better than 4-layer state-of-the-art baselines on BERT
distillation, with only about 28% parameters and about 31% inference time of
them. Moreover, TinyBERT with 6 layers performs on-par with its teacher
BERTBASE.
</p>
<a href="http://arxiv.org/abs/1909.10351" target="_blank">arXiv:1909.10351</a> [<a href="http://arxiv.org/pdf/1909.10351" target="_blank">pdf</a>]

<h2>Compositional Generalization with Tree Stack Memory Units. (arXiv:1911.01545v5 [cs.LG] UPDATED)</h2>
<h3>Forough Arabshahi, Zhichu Lu, Pranay Mundra, Sameer Singh, Animashree Anandkumar</h3>
<p>We study compositional generalization, viz., the problem of zero-shot
generalization to novel compositions of concepts in a domain. Standard neural
networks fail to a large extent on compositional learning. We propose Tree
Stack Memory Units (Tree-SMU) to enable strong compositional generalization.
Tree-SMU is a recursive neural network with Stack Memory Units (\SMU s), a
novel memory augmented neural network whose memory has a differentiable stack
structure. Each SMU in the tree architecture learns to read from its stack and
to write to it by combining the stacks and states of its children through
gating. The stack helps capture long-range dependencies in the problem domain,
thereby enabling compositional generalization. Additionally, the stack also
preserves the ordering of each node's descendants, thereby retaining locality
on the tree. We demonstrate strong empirical results on two mathematical
reasoning benchmarks. We use four compositionality tests to assess the
generalization performance of Tree-SMU and show that it enables accurate
compositional generalization compared to strong baselines such as Transformers
and Tree-LSTMs.
</p>
<a href="http://arxiv.org/abs/1911.01545" target="_blank">arXiv:1911.01545</a> [<a href="http://arxiv.org/pdf/1911.01545" target="_blank">pdf</a>]

<h2>Kernelized Multiview Subspace Analysis by Self-weighted Learning. (arXiv:1911.10357v3 [cs.LG] UPDATED)</h2>
<h3>Huibing Wang, Yang Wang, Zhao Zhang, Xianping Fu, Zhuo Li, Mingliang Xu, Meng Wang</h3>
<p>With the popularity of multimedia technology, information is always
represented or transmitted from multiple views. Most of the existing algorithms
are graph-based ones to learn the complex structures within multiview data but
overlooked the information within data representations. Furthermore, many
existing works treat multiple views discriminatively by introducing some
hyperparameters, which is undesirable in practice. To this end, abundant
multiview based methods have been proposed for dimension reduction. However,
there are still no research to leverage the existing work into a unified
framework. To address this issue, in this paper, we propose a general framework
for multiview data dimension reduction, named Kernelized Multiview Subspace
Analysis (KMSA). It directly handles the multi-view feature representation in
the kernel space, which provides a feasible channel for direct manipulations on
multiview data with different dimensions. Meanwhile, compared with those
graph-based methods, KMSA can fully exploit information from multiview data
with nothing to lose. Furthermore, since different views have different
influences on KMSA, we propose a self-weighted strategy to treat different
views discriminatively according to their contributions. A co-regularized term
is proposed to promote the mutual learning from multi-views. KMSA combines
self-weighted learning with the co-regularized term to learn appropriate
weights for all views. We also discuss the influence of the parameters in KMSA
regarding the weights of multi-views. We evaluate our proposed framework on 6
multiview datasets for classification and image retrieval. The experimental
results validate the advantages of our proposed method.
</p>
<a href="http://arxiv.org/abs/1911.10357" target="_blank">arXiv:1911.10357</a> [<a href="http://arxiv.org/pdf/1911.10357" target="_blank">pdf</a>]

<h2>Policy Optimization Reinforcement Learning with Entropy Regularization. (arXiv:1912.01557v3 [cs.LG] UPDATED)</h2>
<h3>Jingbin Liu, Xinyang Gu, Shuai Liu</h3>
<p>Entropy regularization is an important idea in reinforcement learning, with
great success in recent algorithms like Soft Q Network (SQN) and Soft
Actor-Critic (SAC1). In this work, we extend this idea into the on-policy
realm. We propose the soft policy gradient theorem (SPGT) for on-policy maximum
entropy reinforcement learning. With SPGT, a series of new policy optimization
algorithms are derived, such as SPG, SA2C, SA3C, SDDPG, STRPO, SPPO, SIMPALA
and so on. We find that SDDPG is equivalent to SAC1. For policy gradient, the
policy network is often represented as a Gaussian distribution with a global
action variance, which damages the representation capacity. We introduce a
local action variance for policy network and find it can work collaboratively
with the idea of entropy regularization. Our method outperforms prior works on
a range of benchmark tasks. Furthermore, our method can be easily extended to
large scale experiment with great stability and parallelism.
</p>
<a href="http://arxiv.org/abs/1912.01557" target="_blank">arXiv:1912.01557</a> [<a href="http://arxiv.org/pdf/1912.01557" target="_blank">pdf</a>]

<h2>Node Masking: Making Graph Neural Networks Generalize and Scale Better. (arXiv:2001.07524v3 [cs.LG] UPDATED)</h2>
<h3>Pushkar Mishra, Aleksandra Piktus, Gerard Goossen, Fabrizio Silvestri</h3>
<p>Graph Neural Networks (GNNs) have received a lot of interest in the recent
times. From the early spectral architectures that could only operate on
undirected graphs per a transductive learning paradigm to the current state of
the art spatial ones that can apply inductively to arbitrary graphs, GNNs have
seen significant contributions from the research community. In this paper, we
discuss some theoretical tools to better visualize the operations performed by
state of the art spatial GNNs. We analyze the inner workings of these
architectures and introduce a simple concept, node masking, that allows them to
generalize and scale better. To empirically validate the theory, we perform
several experiments on three widely-used benchmark datasets for node
classification in both transductive and inductive settings.
</p>
<a href="http://arxiv.org/abs/2001.07524" target="_blank">arXiv:2001.07524</a> [<a href="http://arxiv.org/pdf/2001.07524" target="_blank">pdf</a>]

<h2>A versatile anomaly detection method for medical images with a flow-based generative model in semi-supervision setting. (arXiv:2001.07847v2 [eess.IV] UPDATED)</h2>
<h3>H. Shibata (1), S. Hanaoka (2), Y. Nomura (1), T. Nakao (1), I. Sato (2 and 4 and 5), D. Sato (3), N. Hayashi (1), O. Abe (2 and 3) ((1) Department of Computational Diagnostic Radiology and Preventive Medicine, The University of Tokyo Hospital, (2) Department of Radiology, The University of Tokyo Hospital, (3) Division of Radiology and Biomedical Engineering, Graduate School of Medicine, The University of Tokyo, (4) Department of Computer Science, Graduate School of Information Science and Technology, The University of Tokyo, (5) Center for Advanced Intelligence Project, RIKEN)</h3>
<p>Oversight in medical images is a crucial problem, and timely reporting of
medical images is desired. Therefore, an all-purpose anomaly detection method
that can detect virtually all types of lesions/diseases in a given image is
strongly desired. However, few commercially available and versatile anomaly
detection methods for medical images have been provided so far. Recently,
anomaly detection methods built upon deep learning methods have been rapidly
growing in popularity, and these methods seem to provide reasonable solutions
to the problem. However, the workload to label the images necessary for
training in deep learning remains heavy. In this study, we present an anomaly
detection method based on two trained flow-based generative models. With this
method, the posterior probability can be computed as a normality metric for any
given image. The training of the generative models requires two sets of images:
a set containing only normal images and another set containing both normal and
abnormal images without any labels. In the latter set, each sample does not
have to be labeled as normal or abnormal; therefore, any mixture of images
(e.g., all cases in a hospital) can be used as the dataset without cumbersome
manual labeling. The method was validated with two types of medical images:
chest X-ray radiographs (CXRs) and brain computed tomographies (BCTs). The
areas under the receiver operating characteristic curves for logarithm
posterior probabilities of CXRs (0.868 for pneumonia-like opacities) and BCTs
(0.904 for infarction) were comparable to those in previous studies with other
anomaly detection methods. This result showed the versatility of our method.
</p>
<a href="http://arxiv.org/abs/2001.07847" target="_blank">arXiv:2001.07847</a> [<a href="http://arxiv.org/pdf/2001.07847" target="_blank">pdf</a>]

<h2>StegColNet: Steganalysis based on an ensemble colorspace approach. (arXiv:2002.02413v2 [eess.IV] UPDATED)</h2>
<h3>Shreyank N Gowda, Chun Yuan</h3>
<p>Image steganography refers to the process of hiding information inside
images. Steganalysis is the process of detecting a steganographic image. We
introduce a steganalysis approach that uses an ensemble color space model to
obtain a weighted concatenated feature activation map. The concatenated map
helps to obtain certain features explicit to each color space. We use a
levy-flight grey wolf optimization strategy to reduce the number of features
selected in the map. We then use these features to classify the image into one
of two classes: whether the given image has secret information stored or not.
Extensive experiments have been done on a large scale dataset extracted from
the Bossbase dataset. Also, we show that the model can be transferred to
different datasets and perform extensive experiments on a mixture of datasets.
Our results show that the proposed approach outperforms the recent state of the
art deep learning steganalytical approaches by 2.32 percent on average for 0.2
bits per channel (bpc) and 1.87 percent on average for 0.4 bpc.
</p>
<a href="http://arxiv.org/abs/2002.02413" target="_blank">arXiv:2002.02413</a> [<a href="http://arxiv.org/pdf/2002.02413" target="_blank">pdf</a>]

<h2>Multimodal Controller for Generative Models. (arXiv:2002.02572v5 [cs.LG] UPDATED)</h2>
<h3>Enmao Diao, Jie Ding, Vahid Tarokh</h3>
<p>Class-conditional generative models are crucial tools for data generation
from user-specified class labels. Existing approaches for class-conditional
generative models require nontrivial modifications of backbone generative
architectures to model conditional information fed into the model. This paper
introduces a plug-and-play module named `multimodal controller' to generate
multimodal data without introducing additional learning parameters. In the
absence of the controllers, our model reduces to non-conditional generative
models. We test the efficacy of multimodal controller on CIFAR10, CIFAR100,
COIL100, and Omniglot benchmark datasets. We demonstrate that multimodal
controlled generative models (including VAE, PixelCNN, Glow, and GAN) can
generate class-conditional images of significantly better quality when compared
with the state-of-the-art conditional generative models. Moreover, we show that
multimodal controlled models can also transit images between classes and create
novel modalities of images.
</p>
<a href="http://arxiv.org/abs/2002.02572" target="_blank">arXiv:2002.02572</a> [<a href="http://arxiv.org/pdf/2002.02572" target="_blank">pdf</a>]

<h2>Hierarchical Quantized Autoencoders. (arXiv:2002.08111v3 [cs.LG] UPDATED)</h2>
<h3>Will Williams, Sam Ringer, Tom Ash, John Hughes, David MacLeod, Jamie Dougherty</h3>
<p>Despite progress in training neural networks for lossy image compression,
current approaches fail to maintain both perceptual quality and abstract
features at very low bitrates. Encouraged by recent success in learning
discrete representations with Vector Quantized Variational Autoencoders
(VQ-VAEs), we motivate the use of a hierarchy of VQ-VAEs to attain high factors
of compression. We show that the combination of stochastic quantization and
hierarchical latent structure aids likelihood-based image compression. This
leads us to introduce a novel objective for training hierarchical VQ-VAEs. Our
resulting scheme produces a Markovian series of latent variables that
reconstruct images of high-perceptual quality which retain semantically
meaningful features. We provide qualitative and quantitative evaluations on the
CelebA and MNIST datasets.
</p>
<a href="http://arxiv.org/abs/2002.08111" target="_blank">arXiv:2002.08111</a> [<a href="http://arxiv.org/pdf/2002.08111" target="_blank">pdf</a>]

<h2>Unsupervised Discovery, Control, and Disentanglement of Semantic Attributes with Applications to Anomaly Detection. (arXiv:2002.11169v3 [cs.CV] UPDATED)</h2>
<h3>William Paul, I-Jeng Wang, Fady Alajaji, Philippe Burlina</h3>
<p>Our work focuses on unsupervised and generative methods that address the
following goals: (a) learning unsupervised generative representations that
discover latent factors controlling image semantic attributes, (b) studying how
this ability to control attributes formally relates to the issue of latent
factor disentanglement, clarifying related but dissimilar concepts that had
been confounded in the past, and (c) developing anomaly detection methods that
leverage representations learned in (a). For (a), we propose a network
architecture that exploits the combination of multiscale generative models with
mutual information (MI) maximization. For (b), we derive an analytical result
(Lemma 1) that brings clarity to two related but distinct concepts: the ability
of generative networks to control semantic attributes of images they generate,
resulting from MI maximization, and the ability to disentangle latent space
representations, obtained via total correlation minimization. More
specifically, we demonstrate that maximizing semantic attribute control
encourages disentanglement of latent factors. Using Lemma 1 and adopting MI in
our loss function, we then show empirically that, for image generation tasks,
the proposed approach exhibits superior performance as measured in the quality
and disentanglement trade space, when compared to other state of the art
methods, with quality assessed via the Frechet Inception Distance (FID), and
disentanglement via mutual information gap. For (c), we design several systems
for anomaly detection exploiting representations learned in (a), and
demonstrate their performance benefits when compared to state-of-the-art
generative and discriminative algorithms. The above contributions in
representation learning have potential applications in addressing other
important problems in computer vision, such as bias and privacy in AI.
</p>
<a href="http://arxiv.org/abs/2002.11169" target="_blank">arXiv:2002.11169</a> [<a href="http://arxiv.org/pdf/2002.11169" target="_blank">pdf</a>]

<h2>Off-Policy Evaluation and Learning for External Validity under a Covariate Shift. (arXiv:2002.11642v3 [stat.ML] UPDATED)</h2>
<h3>Masahiro Kato, Masatoshi Uehara, Shota Yasui</h3>
<p>We consider evaluating and training a new policy for the evaluation data by
using the historical data obtained from a different policy. The goal of
off-policy evaluation (OPE) is to estimate the expected reward of a new policy
over the evaluation data, and that of off-policy learning (OPL) is to find a
new policy that maximizes the expected reward over the evaluation data.
Although the standard OPE and OPL assume the same distribution of covariate
between the historical and evaluation data, a covariate shift often exists,
i.e., the distribution of the covariate of the historical data is different
from that of the evaluation data. In this paper, we derive the efficiency bound
of OPE under a covariate shift. Then, we propose doubly robust and efficient
estimators for OPE and OPL under a covariate shift by using a nonparametric
estimator of the density ratio between the historical and evaluation data
distributions. We also discuss other possible estimators and compare their
theoretical properties. Finally, we confirm the effectiveness of the proposed
estimators through experiments.
</p>
<a href="http://arxiv.org/abs/2002.11642" target="_blank">arXiv:2002.11642</a> [<a href="http://arxiv.org/pdf/2002.11642" target="_blank">pdf</a>]

<h2>Woodbury Transformations for Deep Generative Flows. (arXiv:2002.12229v2 [cs.LG] UPDATED)</h2>
<h3>You Lu, Bert Huang</h3>
<p>Normalizing flows are deep generative models that allow efficient likelihood
calculation and sampling. The core requirement for this advantage is that they
are constructed using functions that can be efficiently inverted and for which
the determinant of the function's Jacobian can be efficiently computed.
Researchers have introduced various such flow operations, but few of these
allow rich interactions among variables without incurring significant
computational costs. In this paper, we introduce Woodbury transformations,
which achieve efficient invertibility via the Woodbury matrix identity and
efficient determinant calculation via Sylvester's determinant identity. In
contrast with other operations used in state-of-the-art normalizing flows,
Woodbury transformations enable (1) high-dimensional interactions, (2)
efficient sampling, and (3) efficient likelihood evaluation. Other similar
operations, such as 1x1 convolutions, emerging convolutions, or periodic
convolutions allow at most two of these three advantages. In our experiments on
multiple image datasets, we find that Woodbury transformations allow learning
of higher-likelihood models than other flow architectures while still enjoying
their efficiency advantages.
</p>
<a href="http://arxiv.org/abs/2002.12229" target="_blank">arXiv:2002.12229</a> [<a href="http://arxiv.org/pdf/2002.12229" target="_blank">pdf</a>]

<h2>CheXclusion: Fairness gaps in deep chest X-ray classifiers. (arXiv:2003.00827v2 [cs.CV] UPDATED)</h2>
<h3>Laleh Seyyed-Kalantari, Guanxiong Liu, Matthew McDermott, Irene Y. Chen, Marzyeh Ghassemi</h3>
<p>Machine learning systems have received much attention recently for their
ability to achieve expert-level performance on clinical tasks, particularly in
medical imaging. Here, we examine the extent to which state-of-the-art deep
learning classifiers trained to yield diagnostic labels from X-ray images are
biased with respect to protected attributes. We train convolution neural
networks to predict 14 diagnostic labels in 3 prominent public chest X-ray
datasets: MIMIC-CXR, Chest-Xray8, CheXpert, as well as a multi-site aggregation
of all those datasets. We evaluate the TPR disparity -- the difference in true
positive rates (TPR) -- among different protected attributes such as patient
sex, age, race, and insurance type as a proxy for socioeconomic status. We
demonstrate that TPR disparities exist in the state-of-the-art classifiers in
all datasets, for all clinical tasks, and all subgroups. A multi-source dataset
corresponds to the smallest disparities, suggesting one way to reduce bias. We
find that TPR disparities are not significantly correlated with a subgroup's
proportional disease burden. As clinical models move from papers to products,
we encourage clinical decision makers to carefully audit for algorithmic
disparities prior to deployment. Our code can be found at,
https://github.com/LalehSeyyed/CheXclusion
</p>
<a href="http://arxiv.org/abs/2003.00827" target="_blank">arXiv:2003.00827</a> [<a href="http://arxiv.org/pdf/2003.00827" target="_blank">pdf</a>]

<h2>A Survey on The Expressive Power of Graph Neural Networks. (arXiv:2003.04078v4 [cs.LG] UPDATED)</h2>
<h3>Ryoma Sato</h3>
<p>Graph neural networks (GNNs) are effective machine learning models for
various graph learning problems. Despite their empirical successes, the
theoretical limitations of GNNs have been revealed recently. Consequently, many
GNN models have been proposed to overcome these limitations. In this survey, we
provide a comprehensive overview of the expressive power of GNNs and provably
powerful variants of GNNs.
</p>
<a href="http://arxiv.org/abs/2003.04078" target="_blank">arXiv:2003.04078</a> [<a href="http://arxiv.org/pdf/2003.04078" target="_blank">pdf</a>]

<h2>LaserFlow: Efficient and Probabilistic Object Detection and Motion Forecasting. (arXiv:2003.05982v4 [cs.CV] UPDATED)</h2>
<h3>Gregory P. Meyer, Jake Charland, Shreyash Pandey, Ankit Laddha, Shivam Gautam, Carlos Vallespi-Gonzalez, Carl K. Wellington</h3>
<p>In this work, we present LaserFlow, an efficient method for 3D object
detection and motion forecasting from LiDAR. Unlike the previous work, our
approach utilizes the native range view representation of the LiDAR, which
enables our method to operate at the full range of the sensor in real-time
without voxelization or compression of the data. We propose a new multi-sweep
fusion architecture, which extracts and merges temporal features directly from
the range images. Furthermore, we propose a novel technique for learning a
probability distribution over future trajectories inspired by curriculum
learning. We evaluate LaserFlow on two autonomous driving datasets and
demonstrate competitive results when compared to the existing state-of-the-art
methods.
</p>
<a href="http://arxiv.org/abs/2003.05982" target="_blank">arXiv:2003.05982</a> [<a href="http://arxiv.org/pdf/2003.05982" target="_blank">pdf</a>]

<h2>Introducing Pose Consistency and Warp-Alignment for Self-Supervised 6D Object Pose Estimation in Color Images. (arXiv:2003.12344v2 [cs.CV] UPDATED)</h2>
<h3>Juil Sock, Guillermo Garcia-Hernando, Anil Armagan, Tae-Kyun Kim</h3>
<p>Most successful approaches to estimate the 6D pose of an object typically
train a neural network by supervising the learning with annotated poses in real
world images. These annotations are generally expensive to obtain and a common
workaround is to generate and train on synthetic scenes, with the drawback of
limited generalisation when the model is deployed in the real world. In this
work, a two-stage 6D object pose estimator framework that can be applied on top
of existing neural-network-based approaches and that does not require pose
annotations on real images is proposed. The first self-supervised stage
enforces the pose consistency between rendered predictions and real input
images, narrowing the gap between the two domains. The second stage fine-tunes
the previously trained model by enforcing the photometric consistency between
pairs of different object views, where one image is warped and aligned to match
the view of the other and thus enabling their comparison. In the absence of
both real image annotations and depth information, applying the proposed
framework on top of two recent approaches results in state-of-the-art
performance when compared to methods trained only on synthetic data, domain
adaptation baselines and a concurrent self-supervised approach on LINEMOD,
LINEMOD OCCLUSION and HomebrewedDB datasets.
</p>
<a href="http://arxiv.org/abs/2003.12344" target="_blank">arXiv:2003.12344</a> [<a href="http://arxiv.org/pdf/2003.12344" target="_blank">pdf</a>]

<h2>CVPR 2019 WAD Challenge on Trajectory Prediction and 3D Perception. (arXiv:2004.05966v2 [cs.CV] UPDATED)</h2>
<h3>Sibo Zhang, Yuexin Ma, Ruigang Yang</h3>
<p>This paper reviews the CVPR 2019 challenge on Autonomous Driving. Baidu's
Robotics and Autonomous Driving Lab (RAL) providing 150 minutes labeled
Trajectory and 3D Perception dataset including about 80k lidar point cloud and
1000km trajectories for urban traffic. The challenge has two tasks in (1)
Trajectory Prediction and (2) 3D Lidar Object Detection. There are more than
200 teams submitted results on Leaderboard and more than 1000 participants
attended the workshop.
</p>
<a href="http://arxiv.org/abs/2004.05966" target="_blank">arXiv:2004.05966</a> [<a href="http://arxiv.org/pdf/2004.05966" target="_blank">pdf</a>]

<h2>How to compare adversarial robustness of classifiers from a global perspective. (arXiv:2004.10882v2 [cs.LG] UPDATED)</h2>
<h3>Niklas Risse, Christina G&#xf6;pfert, Jan Philip G&#xf6;pfert</h3>
<p>Adversarial robustness of machine learning models has attracted considerable
attention over recent years. Adversarial attacks undermine the reliability of
and trust in machine learning models, but the construction of more robust
models hinges on a rigorous understanding of adversarial robustness as a
property of a given model. Point-wise measures for specific threat models are
currently the most popular tool for comparing the robustness of classifiers and
are used in most recent publications on adversarial robustness. In this work,
we use recently proposed robustness curves to show that point-wise measures
fail to capture important global properties that are essential to reliably
compare the robustness of different classifiers. We introduce new ways in which
robustness curves can be used to systematically uncover these properties and
provide concrete recommendations for researchers and practitioners when
assessing and comparing the robustness of trained models. Furthermore, we
characterize scale as a way to distinguish small and large perturbations, and
relate it to inherent properties of data sets, demonstrating that robustness
thresholds must be chosen accordingly. We release code to reproduce all
experiments presented in this paper, which includes a Python module to
calculate robustness curves for arbitrary data sets and classifiers, supporting
a number of frameworks, including TensorFlow, PyTorch and JAX.
</p>
<a href="http://arxiv.org/abs/2004.10882" target="_blank">arXiv:2004.10882</a> [<a href="http://arxiv.org/pdf/2004.10882" target="_blank">pdf</a>]

<h2>Counterfactual Learning of Continuous Stochastic Policies. (arXiv:2004.11722v3 [stat.ML] UPDATED)</h2>
<h3>Houssam Zenati, Alberto Bietti, Matthieu Martin, Eustache Diemert, Julien Mairal</h3>
<p>Counterfactual reasoning from logged data has become increasingly important
for many applications such as web advertising or healthcare. In this paper, we
address the problem of counterfactual risk minimization (CRM) for learning a
stochastic policy with continuous actions. First, we introduce a new modelling
strategy based on a joint kernel embedding of contexts and actions, which
overcomes the shortcomings of previous discretization strategies. Second, we
empirically show that the optimization perspective of CRM is more important
than previously thought, and we demonstrate the benefits of proximal point
algorithms and differentiable estimators. Finally, we propose an evaluation
protocol for offline policies in real-world logged systems, which is
challenging since policies cannot be replayed on test data, and we release a
new large-scale dataset along with multiple synthetic, yet realistic,
evaluation setups.
</p>
<a href="http://arxiv.org/abs/2004.11722" target="_blank">arXiv:2004.11722</a> [<a href="http://arxiv.org/pdf/2004.11722" target="_blank">pdf</a>]

<h2>An Imitation Game for Learning Semantic Parsers from User Interaction. (arXiv:2005.00689v3 [cs.CL] UPDATED)</h2>
<h3>Ziyu Yao, Yiqi Tang, Wen-tau Yih, Huan Sun, Yu Su</h3>
<p>Despite the widely successful applications, bootstrapping and fine-tuning
semantic parsers are still a tedious process with challenges such as costly
data annotation and privacy risks. In this paper, we suggest an alternative,
human-in-the-loop methodology for learning semantic parsers directly from
users. A semantic parser should be introspective of its uncertainties and
prompt for user demonstration when uncertain. In doing so it also gets to
imitate the user behavior and continue improving itself autonomously with the
hope that eventually it may become as good as the user in interpreting their
questions. To combat the sparsity of demonstration, we propose a novel
annotation-efficient imitation learning algorithm, which iteratively collects
new datasets by mixing demonstrated states and confident predictions and
re-trains the semantic parser in a Dataset Aggregation fashion (Ross et al.,
2011). We provide a theoretical analysis of its cost bound and also empirically
demonstrate its promising performance on the text-to-SQL problem. Code will be
available at https://github.com/sunlab-osu/MISP.
</p>
<a href="http://arxiv.org/abs/2005.00689" target="_blank">arXiv:2005.00689</a> [<a href="http://arxiv.org/pdf/2005.00689" target="_blank">pdf</a>]

<h2>A Communication-Efficient Distributed Algorithm for Kernel Principal Component Analysis. (arXiv:2005.02664v2 [cs.LG] UPDATED)</h2>
<h3>Fan Heg, Kexin Lv, Jie Yang, Xiaolin Huan</h3>
<p>Principal Component Analysis (PCA) is a fundamental technology in machine
learning. Nowadays many high-dimension large datasets are acquired in a
distributed manner, which precludes the use of centralized PCA due to the high
communication cost and privacy risk. Thus, many distributed PCA algorithms are
proposed, most of which, however, focus on linear cases. To efficiently extract
non-linear features, this paper proposes a communication-efficient distributed
kernel PCA algorithm, DKPCA, where linear and RBF kernels are applied. The key
is to estimate the global empirical kernel matrix from the eigenvectors of
local kernel matrices. The approximation error of the estimators is
theoretically analyzed for both linear and RBF kernels. The result suggests
that when eigenvalues decay fast, which is common for RBF kernels, the proposed
algorithm gives high quality results with low communication cost. For data
maldistribution cases, we propose a self-adaptive strategy to reduce the
communication cost without compromising the accuracy. Results of simulation
experiments verify our theory analysis and the classification experiments on
GSE2187 dataset show the effectiveness of the proposed algorithm in practice.
</p>
<a href="http://arxiv.org/abs/2005.02664" target="_blank">arXiv:2005.02664</a> [<a href="http://arxiv.org/pdf/2005.02664" target="_blank">pdf</a>]

<h2>Blind Backdoors in Deep Learning Models. (arXiv:2005.03823v3 [cs.CR] UPDATED)</h2>
<h3>Eugene Bagdasaryan, Vitaly Shmatikov</h3>
<p>We investigate a new method for injecting backdoors into machine learning
models, based on poisoning the loss-value computation in the model-training
code. We use it to demonstrate new classes of backdoors strictly more powerful
than those in prior literature: single-pixel and physical backdoors in ImageNet
models, backdoors that switch the model to a covert, privacy-violating task,
and backdoors that do not require inference-time input modifications.

Our attack is \emph{blind}: the attacker cannot modify the training data, nor
observe the execution of his code, nor access the resulting model. Blind
backdoor training uses multi-objective optimization to achieve high accuracy on
both the main and backdoor tasks. Finally, we show how the blind attack can
evade all known defenses, and propose new ones.
</p>
<a href="http://arxiv.org/abs/2005.03823" target="_blank">arXiv:2005.03823</a> [<a href="http://arxiv.org/pdf/2005.03823" target="_blank">pdf</a>]

<h2>A Contrast-Adaptive Method for Simultaneous Whole-Brain and Lesion Segmentation in Multiple Sclerosis. (arXiv:2005.05135v2 [eess.IV] UPDATED)</h2>
<h3>Stefano Cerri, Oula Puonti, Dominik S. Meier, Jens Wuerfel, Mark M&#xfc;hlau, Hartwig R. Siebner, Koen Van Leemput</h3>
<p>Here we present a method for the simultaneous segmentation of white matter
lesions and normal-appearing neuroanatomical structures from multi-contrast
brain MRI scans of multiple sclerosis patients. The method integrates a novel
model for white matter lesions into a previously validated generative model for
whole-brain segmentation. By using separate models for the shape of anatomical
structures and their appearance in MRI, the algorithm can adapt to data
acquired with different scanners and imaging protocols without retraining. We
validate the method using four disparate datasets, showing robust performance
in white matter lesion segmentation while simultaneously segmenting dozens of
other brain structures. We further demonstrate that the contrast-adaptive
method can also be safely applied to MRI scans of healthy controls, and
replicate previously documented atrophy patterns in deep gray matter structures
in MS. The algorithm is publicly available as part of the open-source
neuroimaging package FreeSurfer.
</p>
<a href="http://arxiv.org/abs/2005.05135" target="_blank">arXiv:2005.05135</a> [<a href="http://arxiv.org/pdf/2005.05135" target="_blank">pdf</a>]

<h2>Automatic Discovery of Interpretable Planning Strategies. (arXiv:2005.11730v2 [cs.LG] UPDATED)</h2>
<h3>Julian Skirzynski, Frederic Becker, Falk Lieder</h3>
<p>When making decisions, people often overlook critical information or are
overly swayed by irrelevant information. A common approach to mitigate these
biases is to provide decision-makers, especially professionals such as medical
doctors, with decision aids, such as decision trees and flowcharts. Designing
effective decision aids is a difficult problem. We propose that recently
developed reinforcement learning methods for discovering clever heuristics for
good decision-making can be partially leveraged to assist human experts in this
design process. One of the biggest remaining obstacles to leveraging the
aforementioned methods is that the policies they learn are opaque to people. To
solve this problem, we introduce AI-Interpret: a general method for
transforming idiosyncratic policies into simple and interpretable descriptions.
Our algorithm combines recent advances in imitation learning and program
induction with a new clustering method for identifying a large subset of
demonstrations that can be accurately described by a simple, high-performing
decision rule. We evaluate our new algorithm and employ it to translate
information-acquisition policies discovered through metalevel reinforcement
learning. The results of large behavioral experiments showed that prividing the
decision rules generated by AI-Interpret as flowcharts significantly improved
people's planning strategies and decisions across three diferent classes of
sequential decision problems. Moreover, another experiment revealed that this
approach is significantly more effective than training people by giving them
performance feedback. Finally, a series of ablation studies confirmed that
AI-Interpret is critical to the discovery of interpretable decision rules. We
conclude that the methods and findings presented herein are an important step
towards leveraging automatic strategy discovery to improve human
decision-making.
</p>
<a href="http://arxiv.org/abs/2005.11730" target="_blank">arXiv:2005.11730</a> [<a href="http://arxiv.org/pdf/2005.11730" target="_blank">pdf</a>]

<h2>DarKnight: A Data Privacy Scheme for Training and Inference of Deep Neural Networks. (arXiv:2006.01300v2 [cs.CR] UPDATED)</h2>
<h3>Hanieh Hashemi, Yongqin Wang, Murali Annavaram</h3>
<p>Protecting the privacy of input data is of growing importance as machine
learning methods reach new application domains. In this paper, we provide a
unified training and inference framework for large DNNs while protecting input
privacy and computation integrity. Our approach called DarKnight uses a novel
data blinding strategy using matrix masking to create input obfuscation within
a trusted execution environment (TEE). Our rigorous mathematical proof
demonstrates that our blinding process provides information-theoretic privacy
guarantee by bounding information leakage. The obfuscated data can then be
offloaded to any GPU for accelerating linear operations on blinded data. The
results from linear operations on blinded data are decoded before performing
non-linear operations within the TEE. This cooperative execution allows
DarKnight to exploit the computational power of GPUs to perform linear
operations while exploiting TEEs to protect input privacy. We implement
DarKnight on an Intel SGX TEE augmented with a GPU to evaluate its performance.
</p>
<a href="http://arxiv.org/abs/2006.01300" target="_blank">arXiv:2006.01300</a> [<a href="http://arxiv.org/pdf/2006.01300" target="_blank">pdf</a>]

<h2>Cross-lingual Transfer Learning for COVID-19 Outbreak Alignment. (arXiv:2006.03202v2 [cs.CL] UPDATED)</h2>
<h3>Sharon Levy, William Yang Wang</h3>
<p>The spread of COVID-19 has become a significant and troubling aspect of
society in 2020. With millions of cases reported across countries, new
outbreaks have occurred and followed patterns of previously affected areas.
Many disease detection models do not incorporate the wealth of social media
data that can be utilized for modeling and predicting its spread. In this case,
it is useful to ask, can we utilize this knowledge in one country to model the
outbreak in another? To answer this, we propose the task of cross-lingual
transfer learning for epidemiological alignment. Utilizing both macro and micro
text features, we train on Italy's early COVID-19 outbreak through Twitter and
transfer to several other countries. Our experiments show strong results with
up to 0.85 Spearman correlation in cross-country predictions.
</p>
<a href="http://arxiv.org/abs/2006.03202" target="_blank">arXiv:2006.03202</a> [<a href="http://arxiv.org/pdf/2006.03202" target="_blank">pdf</a>]

<h2>AutoPrivacy: Automated Layer-wise Parameter Selection for Secure Neural Network Inference. (arXiv:2006.04219v2 [cs.CR] UPDATED)</h2>
<h3>Qian Lou, Song Bian, Lei Jiang</h3>
<p>Hybrid Privacy-Preserving Neural Network (HPPNN) implementing linear layers
by Homomorphic Encryption (HE) and nonlinear layers by Garbled Circuit (GC) is
one of the most promising secure solutions to emerging Machine Learning as a
Service (MLaaS). Unfortunately, a HPPNN suffers from long inference latency,
e.g., $\sim100$ seconds per image, which makes MLaaS unsatisfactory. Because
HE-based linear layers of a HPPNN cost $93\%$ inference latency, it is critical
to select a set of HE parameters to minimize computational overhead of linear
layers. Prior HPPNNs over-pessimistically select huge HE parameters to maintain
large noise budgets, since they use the same set of HE parameters for an entire
network and ignore the error tolerance capability of a network.

In this paper, for fast and accurate secure neural network inference, we
propose an automated layer-wise parameter selector, AutoPrivacy, that leverages
deep reinforcement learning to automatically determine a set of HE parameters
for each linear layer in a HPPNN. The learning-based HE parameter selection
policy outperforms conventional rule-based HE parameter selection policy.
Compared to prior HPPNNs, AutoPrivacy-optimized HPPNNs reduce inference latency
by $53\%\sim70\%$ with negligible loss of accuracy.
</p>
<a href="http://arxiv.org/abs/2006.04219" target="_blank">arXiv:2006.04219</a> [<a href="http://arxiv.org/pdf/2006.04219" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning for Electric Transmission Voltage Control. (arXiv:2006.06728v2 [cs.LG] UPDATED)</h2>
<h3>Brandon L. Thayer, Thomas J. Overbye</h3>
<p>Today, human operators primarily perform voltage control of the electric
transmission system. As the complexity of the grid increases, so does its
operation, suggesting additional automation could be beneficial. A subset of
machine learning known as deep reinforcement learning (DRL) has recently shown
promise in performing tasks typically performed by humans. This paper applies
DRL to the transmission voltage control problem, presents open-source DRL
environments for voltage control, proposes a novel modification to the "deep Q
network" (DQN) algorithm, and performs experiments at scale with systems up to
500 buses. The promise of applying DRL to voltage control is demonstrated,
though more research is needed to enable DRL-based techniques to consistently
outperform conventional methods.
</p>
<a href="http://arxiv.org/abs/2006.06728" target="_blank">arXiv:2006.06728</a> [<a href="http://arxiv.org/pdf/2006.06728" target="_blank">pdf</a>]

<h2>Augmented Sliced Wasserstein Distances. (arXiv:2006.08812v3 [cs.LG] UPDATED)</h2>
<h3>Xiongjie Chen, Yongxin Yang, Yunpeng Li</h3>
<p>While theoretically appealing, the application of the Wasserstein distance to
large-scale machine learning problems has been hampered by its prohibitive
computational cost. The sliced Wasserstein distance and its variants improve
the computational efficiency through random projection, yet they suffer from
low projection efficiency because the majority of projections result in
trivially small values. In this work, we propose a new family of distance
metrics, called augmented sliced Wasserstein distances (ASWDs), constructed by
first mapping samples to higher-dimensional hypersurfaces parameterized by
neural networks. It is derived from a key observation that (random) linear
projections of samples residing on these hypersurfaces would translate to much
more flexible projections in the original sample space, so they can capture
complex structures of the data distribution. We show that the hypersurfaces can
be optimized by gradient ascent efficiently. We provide the condition under
which the ASWD is a valid metric and show that this can be obtained by an
injective neural network architecture. Numerical results demonstrate that the
ASWD significantly outperforms other Wasserstein variants for both synthetic
and real-world problems.
</p>
<a href="http://arxiv.org/abs/2006.08812" target="_blank">arXiv:2006.08812</a> [<a href="http://arxiv.org/pdf/2006.08812" target="_blank">pdf</a>]

<h2>DrNAS: Dirichlet Neural Architecture Search. (arXiv:2006.10355v3 [cs.LG] UPDATED)</h2>
<h3>Xiangning Chen, Ruochen Wang, Minhao Cheng, Xiaocheng Tang, Cho-Jui Hsieh</h3>
<p>This paper proposes a novel differentiable architecture search method by
formulating it into a distribution learning problem. We treat the continuously
relaxed architecture mixing weight as random variables, modeled by Dirichlet
distribution. With recently developed pathwise derivatives, the Dirichlet
parameters can be easily optimized with gradient-based optimizer in an
end-to-end manner. This formulation improves the generalization ability and
induces stochasticity that naturally encourages exploration in the search
space. Furthermore, to alleviate the large memory consumption of differentiable
NAS, we propose a simple yet effective progressive learning scheme that enables
searching directly on large-scale tasks, eliminating the gap between search and
evaluation phases. Extensive experiments demonstrate the effectiveness of our
method. Specifically, we obtain a test error of 2.46% for CIFAR-10, 23.7% for
ImageNet under the mobile setting. On NAS-Bench-201, we also achieve
state-of-the-art results on all three datasets and provide insights for the
effective design of neural architecture search algorithms.
</p>
<a href="http://arxiv.org/abs/2006.10355" target="_blank">arXiv:2006.10355</a> [<a href="http://arxiv.org/pdf/2006.10355" target="_blank">pdf</a>]

<h2>Open Ad Hoc Teamwork using Graph-based Policy Learning. (arXiv:2006.10412v2 [cs.LG] UPDATED)</h2>
<h3>Arrasy Rahman, Niklas Hopner, Filippos Christianos, Stefano V. Albrecht</h3>
<p>Ad hoc teamwork is the challenging problem of designing an autonomous agent
which can adapt quickly to collaborate with previously unknown teammates. Prior
work in this area has focused on closed teams in which the number of agents is
fixed. In this work, we consider open teams by allowing agents of varying types
to enter and leave the team without prior notification. Our solution builds on
graph neural networks to learn agent models and joint action-value
decompositions under varying team sizes, which can be trained with
reinforcement learning using a discounted returns objective. We demonstrate
empirically that our approach effectively models the impact of other agents
actions on the controlled agent's returns to produce policies which can
robustly adapt to dynamic team composition and is able to effectively
generalize to larger teams than were seen during training.
</p>
<a href="http://arxiv.org/abs/2006.10412" target="_blank">arXiv:2006.10412</a> [<a href="http://arxiv.org/pdf/2006.10412" target="_blank">pdf</a>]

<h2>Crossmodal Language Grounding in an Embodied Neurocognitive Model. (arXiv:2006.13546v2 [cs.NE] UPDATED)</h2>
<h3>Stefan Heinrich, Yuan Yao, Tobias Hinz, Zhiyuan Liu, Thomas Hummel, Matthias Kerzel, Cornelius Weber, Stefan Wermter</h3>
<p>Human infants are able to acquire natural language seemingly easily at an
early age. Their language learning seems to occur simultaneously with learning
other cognitive functions as well as with playful interactions with the
environment and caregivers. From a neuroscientific perspective, natural
language is embodied, grounded in most, if not all, sensory and sensorimotor
modalities, and acquired by means of crossmodal integration. However,
characterising the underlying mechanisms in the brain is difficult and
explaining the grounding of language in crossmodal perception and action
remains challenging. In this paper, we present a neurocognitive model for
language grounding which reflects bio-inspired mechanisms such as an implicit
adaptation of timescales as well as end-to-end multimodal abstraction. It
addresses developmental robotic interaction and extends its learning
capabilities using larger-scale knowledge-based data. In our scenario, we
utilise the humanoid robot NICO in obtaining the EMIL data collection, in which
the cognitive robot interacts with objects in a children's playground
environment while receiving linguistic labels from a caregiver. The model
analysis shows that crossmodally integrated representations are sufficient for
acquiring language merely from sensory input through interaction with objects
in an environment. The representations self-organise hierarchically and embed
temporal and spatial information through composition and decomposition. This
model can also provide the basis for further crossmodal integration of
perceptually grounded cognitive representations.
</p>
<a href="http://arxiv.org/abs/2006.13546" target="_blank">arXiv:2006.13546</a> [<a href="http://arxiv.org/pdf/2006.13546" target="_blank">pdf</a>]

<h2>Leveraging Subword Embeddings for Multinational Address Parsing. (arXiv:2006.16152v2 [cs.CL] UPDATED)</h2>
<h3>Marouane Yassine, David Beauchemin, Fran&#xe7;ois Laviolette, Luc Lamontagne</h3>
<p>Address parsing consists of identifying the segments that make up an address
such as a street name or a postal code. Because of its importance for tasks
like record linkage, address parsing has been approached with many techniques.
Neural network methods defined a new state-of-the-art for address parsing.
While this approach yielded notable results, previous work has only focused on
applying neural networks to achieve address parsing of addresses from one
source country. We propose an approach in which we employ subword embeddings
and a Recurrent Neural Network architecture to build a single model capable of
learning to parse addresses from multiple countries at the same time while
taking into account the difference in languages and address formatting systems.
We achieved accuracies around 99% on the countries used for training with no
pre-processing nor post-processing needed. We explore the possibility of
transferring the address parsing knowledge obtained by training on some
countries' addresses to others with no further training in a zero-shot transfer
learning setting. We achieve good results for 80% of the countries (33 out of
41), almost 50% of which (20 out of 41) is near state-of-the-art performance.
In addition, we propose an open-source Python implementation of our trained
models.
</p>
<a href="http://arxiv.org/abs/2006.16152" target="_blank">arXiv:2006.16152</a> [<a href="http://arxiv.org/pdf/2006.16152" target="_blank">pdf</a>]

<h2>Fast Bayesian Estimation of Spatial Count Data Models. (arXiv:2007.03681v2 [stat.ME] UPDATED)</h2>
<h3>Prateek Bansal, Rico Krueger, Daniel J. Graham</h3>
<p>Spatial count data models are used to explain and predict the frequency of
phenomena such as traffic accidents in geographically distinct entities such as
census tracts or road segments. These models are typically estimated using
Bayesian Markov chain Monte Carlo (MCMC) simulation methods, which, however,
are computationally expensive and do not scale well to large datasets.
Variational Bayes (VB), a method from machine learning, addresses the
shortcomings of MCMC by casting Bayesian estimation as an optimisation problem
instead of a simulation problem. Considering all these advantages of VB, a VB
method is derived for posterior inference in negative binomial models with
unobserved parameter heterogeneity and spatial dependence. P\'olya-Gamma
augmentation is used to deal with the non-conjugacy of the negative binomial
likelihood and an integrated non-factorised specification of the variational
distribution is adopted to capture posterior dependencies. The benefits of the
proposed approach are demonstrated in a Monte Carlo study and an empirical
application on estimating youth pedestrian injury counts in census tracts of
New York City. The VB approach is around 45 to 50 times faster than MCMC on a
regular eight-core processor in a simulation and an empirical study, while
offering similar estimation and predictive accuracy. Conditional on the
availability of computational resources, the embarrassingly parallel
architecture of the proposed VB method can be exploited to further accelerate
its estimation by up to 20 times.
</p>
<a href="http://arxiv.org/abs/2007.03681" target="_blank">arXiv:2007.03681</a> [<a href="http://arxiv.org/pdf/2007.03681" target="_blank">pdf</a>]

<h2>Optimizing Memory Placement using Evolutionary Graph Reinforcement Learning. (arXiv:2007.07298v2 [cs.LG] UPDATED)</h2>
<h3>Shauharda Khadka, Estelle Aflalo, Mattias Marder, Avrech Ben-David, Santiago Miret, Shie Mannor, Tamir Hazan, Hanlin Tang, Somdeb Majumdar</h3>
<p>For deep neural network accelerators, memory movement is both energetically
expensive and can bound computation. Therefore, optimal mapping of tensors to
memory hierarchies is critical to performance. The growing complexity of neural
networks calls for automated memory mapping instead of manual heuristic
approaches; yet the search space of neural network computational graphs have
previously been prohibitively large. We introduce Evolutionary Graph
Reinforcement Learning (EGRL), a method designed for large search spaces, that
combines graph neural networks, reinforcement learning, and evolutionary
search. A set of fast, stateless policies guide the evolutionary search to
improve its sample-efficiency. We train and validate our approach directly on
the Intel NNP-I chip for inference. EGRL outperforms policy-gradient,
evolutionary search and dynamic programming baselines on BERT, ResNet-101 and
ResNet-50. We additionally achieve 28-78\% speed-up compared to the native
NNP-I compiler on all three workloads.
</p>
<a href="http://arxiv.org/abs/2007.07298" target="_blank">arXiv:2007.07298</a> [<a href="http://arxiv.org/pdf/2007.07298" target="_blank">pdf</a>]

<h2>Toward Agile Maneuvers in Highly Constrained Spaces: Learning from Hallucination. (arXiv:2007.14479v3 [cs.RO] UPDATED)</h2>
<h3>Xuesu Xiao, Bo Liu, Garrett Warnell, Peter Stone</h3>
<p>While classical approaches to autonomous robot navigation currently enable
operation in certain environments, they break down in tightly constrained
spaces, e.g., where the robot needs to engage in agile maneuvers to squeeze
between obstacles. Recent machine learning techniques have the potential to
address this shortcoming, but existing approaches require vast amounts of
navigation experience for training, during which the robot must operate in
close proximity to obstacles and risk collision. In this paper, we propose to
side-step this requirement by introducing a new machine learning paradigm for
autonomous navigation called learning from hallucination (LfH), which can use
training data collected in completely safe environments to compute navigation
controllers that result in fast, smooth, and safe navigation in highly
constrained environments. Our experimental results show that the proposed LfH
system outperforms three autonomous navigation baselines on a real robot,
including those based on both classical and machine learning techniques.
</p>
<a href="http://arxiv.org/abs/2007.14479" target="_blank">arXiv:2007.14479</a> [<a href="http://arxiv.org/pdf/2007.14479" target="_blank">pdf</a>]

<h2>Lifelong Learning for Navigation. (arXiv:2007.14486v3 [cs.RO] UPDATED)</h2>
<h3>Bo Liu, Xuesu Xiao, Peter Stone</h3>
<p>This paper presents a self-improving lifelong learning framework for a mobile
robot navigating in different environments. Classical static navigation methods
require environment-specific in-situ system adjustment, e.g. from human
experts, or may repeat their mistakes regardless of how many times they have
navigated in the same environment. Having the potential to improve with
experience, learning-based navigation is highly dependent on access to training
resources, e.g. sufficient memory and fast computation, and is prone to
forgetting previously learned capability, especially when facing different
environments. In this work, we propose Lifelong Learning for Navigation (LLfN)
which (1) improves a mobile robot's navigation behavior purely based on its own
experience, and (2) retains the robot's capability to navigate in previous
environments after learning in new ones. LLfN is implemented and tested
entirely onboard a physical robot with a limited memory and computation budget.
</p>
<a href="http://arxiv.org/abs/2007.14486" target="_blank">arXiv:2007.14486</a> [<a href="http://arxiv.org/pdf/2007.14486" target="_blank">pdf</a>]

<h2>Projecting to Manifolds via Unsupervised Learning. (arXiv:2008.02200v2 [cs.LG] UPDATED)</h2>
<h3>Howard Heaton, Samy Wu Fung, Alex Tong Lin, Stanley Osher, Wotao Yin</h3>
<p>We present a new mechanism, called adversarial projection, that projects a
given signal onto the intrinsically low dimensional manifold of true data. This
operator can be used for solving inverse problems, which consists of recovering
a signal from a collection of noisy measurements. Rather than attempt to encode
prior knowledge via an analytic regularizer, we leverage available data to
project signals directly onto the (possibly nonlinear) manifold of true data
(i.e., regularize via an indicator function of the manifold). Our approach
avoids the difficult task of forming a direct representation of the manifold.
Instead, we directly learn the projection operator by solving a sequence of
unsupervised learning problems, and we prove our method converges in
probability to the desired projection. This operator can then be directly
incorporated into optimization algorithms in the same manner as Plug-and-Play
methods, but now with robust theoretical guarantees. Numerical examples are
provided.
</p>
<a href="http://arxiv.org/abs/2008.02200" target="_blank">arXiv:2008.02200</a> [<a href="http://arxiv.org/pdf/2008.02200" target="_blank">pdf</a>]

<h2>Energy-Efficient Control Adaptation with Safety Guarantees for Learning-Enabled Cyber-Physical Systems. (arXiv:2008.06162v2 [eess.SY] UPDATED)</h2>
<h3>Yixuan Wang, Chao Huang, Qi Zhu</h3>
<p>Neural networks have been increasingly applied for control in
learning-enabled cyber-physical systems (LE-CPSs) and demonstrated great
promises in improving system performance and efficiency, as well as reducing
the need for complex physical models. However, the lack of safety guarantees
for such neural network based controllers has significantly impeded their
adoption in safety-critical CPSs. In this work, we propose a controller
adaptation approach that automatically switches among multiple controllers,
including neural network controllers, to guarantee system safety and improve
energy efficiency. Our approach includes two key components based on formal
methods and machine learning. First, we approximate each controller with a
Bernstein-polynomial based hybrid system model under bounded disturbance, and
compute a safe invariant set for each controller based on its corresponding
hybrid system. Intuitively, the invariant set of a controller defines the state
space where the system can always remain safe under its control. The union of
the controllers' invariants sets then define a safe adaptation space that is
larger than (or equal to) that of each controller. Second, we develop a deep
reinforcement learning method to learn a controller switching strategy for
reducing the control/actuation energy cost, while with the help of a safety
guard rule, ensuring that the system stays within the safe space. Experiments
on a linear adaptive cruise control system and a non-linear Van der Pol's
oscillator demonstrate the effectiveness of our approach on energy saving and
safety enhancement.
</p>
<a href="http://arxiv.org/abs/2008.06162" target="_blank">arXiv:2008.06162</a> [<a href="http://arxiv.org/pdf/2008.06162" target="_blank">pdf</a>]

<h2>Deep Volumetric Ambient Occlusion. (arXiv:2008.08345v2 [cs.CV] UPDATED)</h2>
<h3>Dominik Engel, Timo Ropinski</h3>
<p>We present a novel deep learning based technique for volumetric ambient
occlusion in the context of direct volume rendering. Our proposed Deep
Volumetric Ambient Occlusion (DVAO) approach can predict per-voxel ambient
occlusion in volumetric data sets, while considering global information
provided through the transfer function. The proposed neural network only needs
to be executed upon change of this global information, and thus supports
real-time volume interaction. Accordingly, we demonstrate DVAOs ability to
predict volumetric ambient occlusion, such that it can be applied interactively
within direct volume rendering. To achieve the best possible results, we
propose and analyze a variety of transfer function representations and
injection strategies for deep neural networks. Based on the obtained results we
also give recommendations applicable in similar volume learning scenarios.
Lastly, we show that DVAO generalizes to a variety of modalities, despite being
trained on computed tomography data only.
</p>
<a href="http://arxiv.org/abs/2008.08345" target="_blank">arXiv:2008.08345</a> [<a href="http://arxiv.org/pdf/2008.08345" target="_blank">pdf</a>]

<h2>Line detection via a lightweight CNN with a Hough Layer. (arXiv:2008.08884v2 [cs.CV] UPDATED)</h2>
<h3>Lev Teplyakov, Kirill Kaymakov, Evgeny Shvets, Dmitry Nikolaev</h3>
<p>Line detection is an important computer vision task traditionally solved by
Hough Transform. With the advance of deep learning, however, trainable
approaches to line detection became popular. In this paper we propose a
lightweight CNN for line detection with an embedded parameter-free Hough layer,
which allows the network neurons to have global strip-like receptive fields. We
argue that traditional convolutional networks have two inherent problems when
applied to the task of line detection and show how insertion of a Hough layer
into the network solves them. Additionally, we point out some major
inconsistencies in the current datasets used for line detection.
</p>
<a href="http://arxiv.org/abs/2008.08884" target="_blank">arXiv:2008.08884</a> [<a href="http://arxiv.org/pdf/2008.08884" target="_blank">pdf</a>]

<h2>Static Neural Compiler Optimization via Deep Reinforcement Learning. (arXiv:2008.08951v3 [cs.LG] UPDATED)</h2>
<h3>Rahim Mammadli, Ali Jannesari, Felix Wolf</h3>
<p>The phase-ordering problem of modern compilers has received a lot of
attention from the research community over the years, yet remains largely
unsolved. Various optimization sequences exposed to the user are manually
designed by compiler developers. In designing such a sequence developers have
to choose the set of optimization passes, their parameters and ordering within
a sequence. Resulting sequences usually fall short of achieving optimal runtime
for a given source code and may sometimes even degrade the performance when
compared to unoptimized version. In this paper, we employ a deep reinforcement
learning approach to the phase-ordering problem. Provided with sub-sequences
constituting LLVM's O3 sequence, our agent learns to outperform the O3 sequence
on the set of source codes used for training and achieves competitive
performance on the validation set, gaining up to 1.32x speedup on
previously-unseen programs. Notably, our approach differs from autotuning
methods by not depending on one or more test runs of the program for making
successful optimization decisions. It has no dependence on any dynamic feature,
but only on the statically-attainable intermediate representation of the source
code. We believe that the models trained using our approach can be integrated
into modern compilers as neural optimization agents, at first to complement,
and eventually replace the hand-crafted optimization sequences.
</p>
<a href="http://arxiv.org/abs/2008.08951" target="_blank">arXiv:2008.08951</a> [<a href="http://arxiv.org/pdf/2008.08951" target="_blank">pdf</a>]

<h2>3D Facial Matching by Spiral Convolutional Metric Learning and a Biometric Fusion-Net of Demographic Properties. (arXiv:2009.04746v2 [cs.CV] UPDATED)</h2>
<h3>Soha Sadat Mahdi (1), Nele Nauwelaers (1), Philip Joris (1), Giorgos Bouritsas (2), Shunwang Gong (2), Sergiy Bokhnyak (3), Susan Walsh (4), Mark D. Shriver (5), Michael Bronstein (2,3,6), Peter Claes (1,7). ((1) KU Leuven, ESAT/PSI - UZ Leuven, MIRC, (2) Imperial College London, Department of Computing, (3) USI Lugano, Institute of Computational Science, (4) Indiana University-Purdue University-Indianapolis, Department of Biology, (5) Penn State University, Department of Anthropology, (6) Twitter, (7) KU Leuven, Department of Human Genetics)</h3>
<p>Face recognition is a widely accepted biometric verification tool, as the
face contains a lot of information about the identity of a person. In this
study, a 2-step neural-based pipeline is presented for matching 3D facial shape
to multiple DNA-related properties (sex, age, BMI and genomic background). The
first step consists of a triplet loss-based metric learner that compresses
facial shape into a lower dimensional embedding while preserving information
about the property of interest. Most studies in the field of metric learning
have only focused on 2D Euclidean data. In this work, geometric deep learning
is employed to learn directly from 3D facial meshes. To this end, spiral
convolutions are used along with a novel mesh-sampling scheme that retains
uniformly sampled 3D points at different levels of resolution. The second step
is a multi-biometric fusion by a fully connected neural network. The network
takes an ensemble of embeddings and property labels as input and returns
genuine and imposter scores. Since embeddings are accepted as an input, there
is no need to train classifiers for the different properties and available data
can be used more efficiently. Results obtained by a 10-fold cross-validation
for biometric verification show that combining multiple properties leads to
stronger biometric systems. Furthermore, the proposed neural-based pipeline
outperforms a linear baseline, which consists of principal component analysis,
followed by classification with linear support vector machines and a Naive
Bayes-based score-fuser.
</p>
<a href="http://arxiv.org/abs/2009.04746" target="_blank">arXiv:2009.04746</a> [<a href="http://arxiv.org/pdf/2009.04746" target="_blank">pdf</a>]

<h2>Boosting Generalization in Bio-Signal Classification by Learning the Phase-Amplitude Coupling. (arXiv:2009.07664v2 [cs.LG] UPDATED)</h2>
<h3>Abdelhak Lemkhenter, Paolo Favaro</h3>
<p>Various hand-crafted features representations of bio-signals rely primarily
on the amplitude or power of the signal in specific frequency bands. The phase
component is often discarded as it is more sample specific, and thus more
sensitive to noise, than the amplitude. However, in general, the phase
component also carries information relevant to the underlying biological
processes. In fact, in this paper we show the benefits of learning the coupling
of both phase and amplitude components of a bio-signal. We do so by introducing
a novel self-supervised learning task, which we call Phase-Swap, that detects
if bio-signals have been obtained by merging the amplitude and phase from
different sources. We show in our evaluation that neural networks trained on
this task generalize better across subjects and recording sessions than their
fully supervised counterpart.
</p>
<a href="http://arxiv.org/abs/2009.07664" target="_blank">arXiv:2009.07664</a> [<a href="http://arxiv.org/pdf/2009.07664" target="_blank">pdf</a>]

<h2>DeepDyve: Dynamic Verification for Deep Neural Networks. (arXiv:2009.09663v2 [cs.LG] UPDATED)</h2>
<h3>Yu Li, Min Li, Bo Luo, Ye Tian, Qiang Xu</h3>
<p>Deep neural networks (DNNs) have become one of the enabling technologies in
many safety-critical applications, e.g., autonomous driving and medical image
analysis. DNN systems, however, suffer from various kinds of threats, such as
adversarial example attacks and fault injection attacks. While there are many
defense methods proposed against maliciously crafted inputs, solutions against
faults presented in the DNN system itself (e.g., parameters and calculations)
are far less explored. In this paper, we develop a novel lightweight
fault-tolerant solution for DNN-based systems, namely DeepDyve, which employs
pre-trained neural networks that are far simpler and smaller than the original
DNN for dynamic verification. The key to enabling such lightweight checking is
that the smaller neural network only needs to produce approximate results for
the initial task without sacrificing fault coverage much. We develop efficient
and effective architecture and task exploration techniques to achieve optimized
risk/overhead trade-off in DeepDyve. Experimental results show that DeepDyve
can reduce 90% of the risks at around 10% overhead.
</p>
<a href="http://arxiv.org/abs/2009.09663" target="_blank">arXiv:2009.09663</a> [<a href="http://arxiv.org/pdf/2009.09663" target="_blank">pdf</a>]

<h2>CMAX++ : Leveraging Experience in Planning and Execution using Inaccurate Models. (arXiv:2009.09942v3 [cs.RO] UPDATED)</h2>
<h3>Anirudh Vemula, J. Andrew Bagnell, Maxim Likhachev</h3>
<p>Given access to accurate dynamical models, modern planning approaches are
effective in computing feasible and optimal plans for repetitive robotic tasks.
However, it is difficult to model the true dynamics of the real world before
execution, especially for tasks requiring interactions with objects whose
parameters are unknown. A recent planning approach, CMAX, tackles this problem
by adapting the planner online during execution to bias the resulting plans
away from inaccurately modeled regions. CMAX, while being provably guaranteed
to reach the goal, requires strong assumptions on the accuracy of the model
used for planning and fails to improve the quality of the solution over
repetitions of the same task. In this paper we propose CMAX++, an approach that
leverages real-world experience to improve the quality of resulting plans over
successive repetitions of a robotic task. CMAX++ achieves this by integrating
model-free learning using acquired experience with model-based planning using
the potentially inaccurate model. We provide provable guarantees on the
completeness and asymptotic convergence of CMAX++ to the optimal path cost as
the number of repetitions increases. CMAX++ is also shown to outperform
baselines in simulated robotic tasks including 3D mobile robot navigation where
the track friction is incorrectly modeled, and a 7D pick-and-place task where
the mass of the object is unknown leading to discrepancy between true and
modeled dynamics.
</p>
<a href="http://arxiv.org/abs/2009.09942" target="_blank">arXiv:2009.09942</a> [<a href="http://arxiv.org/pdf/2009.09942" target="_blank">pdf</a>]

<h2>PennSyn2Real: Training Object Recognition Models without Human Labeling. (arXiv:2009.10292v2 [cs.CV] UPDATED)</h2>
<h3>Ty Nguyen, Ian D. Miller, Avi Cohen, Dinesh Thakur, Shashank Prasad, Camillo J. Taylor, Pratik Chaudrahi, Vijay Kumar</h3>
<p>Scalable training data generation is a critical problem in deep learning. We
propose PennSyn2Real - a photo-realistic synthetic dataset consisting of more
than 100,000 4K images of more than 20 types of micro aerial vehicles (MAVs).
The dataset can be used to generate arbitrary numbers of training images for
high-level computer vision tasks such as MAV detection and classification. Our
data generation framework bootstraps chroma-keying, a mature cinematography
technique with a motion tracking system, providing artifact-free and curated
annotated images where object orientations and lighting are controlled. This
framework is easy to set up and can be applied to a broad range of objects,
reducing the gap between synthetic and real-world data. We show that synthetic
data generated using this framework can be directly used to train CNN models
for common object recognition tasks such as detection and segmentation. We
demonstrate competitive performance in comparison with training using only real
images. Furthermore, bootstrapping the generated synthetic data in few-shot
learning can significantly improve the overall performance, reducing the number
of required training data samples to achieve the desired accuracy.
</p>
<a href="http://arxiv.org/abs/2009.10292" target="_blank">arXiv:2009.10292</a> [<a href="http://arxiv.org/pdf/2009.10292" target="_blank">pdf</a>]

<h2>Learning Visual Voice Activity Detection with an Automatically Annotated Dataset. (arXiv:2009.11204v2 [cs.CV] UPDATED)</h2>
<h3>Sylvain Guy, St&#xe9;phane Lathuili&#xe8;re, Pablo Mesejo, Radu Horaud</h3>
<p>Visual voice activity detection (V-VAD) uses visual features to predict
whether a person is speaking or not. V-VAD is useful whenever audio VAD (A-VAD)
is inefficient either because the acoustic signal is difficult to analyze or
because it is simply missing. We propose two deep architectures for V-VAD, one
based on facial landmarks and one based on optical flow. Moreover, available
datasets, used for learning and for testing V-VAD, lack content variability. We
introduce a novel methodology to automatically create and annotate very large
datasets in-the-wild -- WildVVAD -- based on combining A-VAD with face
detection and tracking. A thorough empirical evaluation shows the advantage of
training the proposed deep V-VAD models with this dataset.
</p>
<a href="http://arxiv.org/abs/2009.11204" target="_blank">arXiv:2009.11204</a> [<a href="http://arxiv.org/pdf/2009.11204" target="_blank">pdf</a>]

<h2>ReLeaSER: A Reinforcement Learning Strategy for Optimizing Utilization Of Ephemeral Cloud Resources. (arXiv:2009.11208v3 [cs.PF] UPDATED)</h2>
<h3>Mohamed Handaoui, Jean-Emile Dartois, Jalil Boukhobza, Olivier Barais, Laurent d&#x27;Orazio</h3>
<p>Cloud data center capacities are over-provisioned to handle demand peaks and
hardware failures which leads to low resources' utilization. One way to improve
resource utilization and thus reduce the total cost of ownership is to offer
unused resources (referred to as ephemeral resources) at a lower price.
However, reselling resources needs to meet the expectations of its customers in
terms of Quality of Service. The goal is so to maximize the amount of reclaimed
resources while avoiding SLA penalties. To achieve that, cloud providers have
to estimate their future utilization to provide availability guarantees. The
prediction should consider a safety margin for resources to react to
unpredictable workloads. The challenge is to find the safety margin that
provides the best trade-off between the amount of resources to reclaim and the
risk of SLA violations. Most state-of-the-art solutions consider a fixed safety
margin for all types of metrics (e.g., CPU, RAM). However, a unique fixed
margin does not consider various workloads variations over time which may lead
to SLA violations or/and poor utilization. In order to tackle these challenges,
we propose ReLeaSER, a Reinforcement Learning strategy for optimizing the
ephemeral resources' utilization in the cloud. ReLeaSER dynamically tunes the
safety margin at the host-level for each resource metric. The strategy learns
from past prediction errors (that caused SLA violations). Our solution reduces
significantly the SLA violation penalties on average by 2.7x and up to 3.4x. It
also improves considerably the CPs' potential savings by 27.6% on average and
up to 43.6%.
</p>
<a href="http://arxiv.org/abs/2009.11208" target="_blank">arXiv:2009.11208</a> [<a href="http://arxiv.org/pdf/2009.11208" target="_blank">pdf</a>]

<h2>ECOVNet: An Ensemble of Deep Convolutional Neural Networks Based on EfficientNet to Detect COVID-19 From Chest X-rays. (arXiv:2009.11850v2 [eess.IV] UPDATED)</h2>
<h3>Nihad Karim Chowdhury, Muhammad Ashad Kabir, Md. Muhtadir Rahman, Noortaz Rezoana</h3>
<p>This paper proposed an ensemble of deep convolutional neural networks (CNN)
based on EfficientNet, named ECOVNet, to detect COVID-19 using a large chest
X-ray data set. At first, the open-access large chest X-ray collection is
augmented, and then ImageNet pre-trained weights for EfficientNet is
transferred with some customized fine-tuning top layers that are trained,
followed by an ensemble of model snapshots to classify chest X-rays
corresponding to COVID-19, normal, and pneumonia. The predictions of the model
snapshots, which are created during a single training, are combined through two
ensemble strategies, i.e., hard ensemble and soft ensemble to ameliorate
classification performance and generalization in the related task of
classifying chest X-rays.
</p>
<a href="http://arxiv.org/abs/2009.11850" target="_blank">arXiv:2009.11850</a> [<a href="http://arxiv.org/pdf/2009.11850" target="_blank">pdf</a>]

<h2>Flexible Performant GEMM Kernels on GPUs. (arXiv:2009.12263v3 [cs.MS] UPDATED)</h2>
<h3>Thomas Faingnaert, Tim Besard, Bjorn De Sutter</h3>
<p>General Matrix Multiplication or GEMM kernels take center place in high
performance computing and machine learning. Recent NVIDIA GPUs include GEMM
accelerators, such as NVIDIA's Tensor Cores. Their exploitation is hampered by
the two-language problem: it requires either low-level programming which
implies low programmer productivity or using libraries that only offer a
limited set of components. Because rephrasing algorithms in terms of
established components often introduces overhead, the libraries' lack of
flexibility limits the freedom to explore new algorithms. Researchers using
GEMMs can hence not enjoy programming productivity, high performance, and
research flexibility at once.

In this paper we solve this problem. We present three sets of abstractions
and interfaces to program GEMMs within the scientific Julia programming
language. The interfaces and abstractions are co-designed for researchers'
needs and Julia's features to achieve sufficient separation of concerns and
flexibility to easily extend basic GEMMs in many different ways without paying
a performance price. Comparing our GEMMs to state-of-the-art libraries cuBLAS
and CUTLASS, we demonstrate that our performance is mostly on par with, and in
some cases even exceeds, the libraries, without having to write a single line
of code in CUDA C++ or assembly, and without facing flexibility limitations.
</p>
<a href="http://arxiv.org/abs/2009.12263" target="_blank">arXiv:2009.12263</a> [<a href="http://arxiv.org/pdf/2009.12263" target="_blank">pdf</a>]

<h2>Deep Transformers with Latent Depth. (arXiv:2009.13102v2 [cs.CL] UPDATED)</h2>
<h3>Xian Li, Asa Cooper Stickland, Yuqing Tang, Xiang Kong</h3>
<p>The Transformer model has achieved state-of-the-art performance in many
sequence modeling tasks. However, how to leverage model capacity with large or
variable depths is still an open challenge. We present a probabilistic
framework to automatically learn which layer(s) to use by learning the
posterior distributions of layer selection. As an extension of this framework,
we propose a novel method to train one shared Transformer network for
multilingual machine translation with different layer selection posteriors for
each language pair. The proposed method alleviates the vanishing gradient issue
and enables stable training of deep Transformers (e.g. 100 layers). We evaluate
on WMT English-German machine translation and masked language modeling tasks,
where our method outperforms existing approaches for training deeper
Transformers. Experiments on multilingual machine translation demonstrate that
this approach can effectively leverage increased model capacity and bring
universal improvement for both many-to-one and one-to-many translation with
diverse language pairs.
</p>
<a href="http://arxiv.org/abs/2009.13102" target="_blank">arXiv:2009.13102</a> [<a href="http://arxiv.org/pdf/2009.13102" target="_blank">pdf</a>]

<h2>Adaptive Sampling for Best Policy Identification in Markov Decision Processes. (arXiv:2009.13405v3 [stat.ML] UPDATED)</h2>
<h3>Aymen Al Marjani, Alexandre Proutiere</h3>
<p>We investigate the problem of best-policy identification in discounted Markov
Decision Processes (MDPs) when the learner has access to a generative model.
The objective is to devise a learning algorithm returning the best policy as
early as possible. We first derive a problem-specific lower bound of the sample
complexity satisfied by any learning algorithm. This lower bound corresponds to
an optimal sample allocation that solves a non-convex program, and hence, is
hard to exploit in the design of efficient algorithms. We then provide a simple
and tight upper bound of the sample complexity lower bound, whose corresponding
nearly-optimal sample allocation becomes explicit. The upper bound depends on
specific functionals of the MDP such as the sub-optimality gaps and the
variance of the next-state value function, and thus really captures the
hardness of the MDP. Finally, we devise KLB-TS (KL Ball Track-and-Stop), an
algorithm tracking this nearly-optimal allocation, and provide asymptotic
guarantees for its sample complexity (both almost surely and in expectation).
The advantages of KLB-TS against state-of-the-art algorithms are discussed and
illustrated numerically.
</p>
<a href="http://arxiv.org/abs/2009.13405" target="_blank">arXiv:2009.13405</a> [<a href="http://arxiv.org/pdf/2009.13405" target="_blank">pdf</a>]

<h2>Time Matters: Time-Aware LSTMs for Predictive Business Process Monitoring. (arXiv:2010.00889v2 [cs.LG] UPDATED)</h2>
<h3>An Nguyen, Srijeet Chatterjee, Sven Weinzierl, Leo Schwinn, Martin Matzner, Bjoern Eskofier</h3>
<p>Predictive business process monitoring (PBPM) aims to predict future process
behavior during ongoing process executions based on event log data. Especially,
techniques for the next activity and timestamp prediction can help to improve
the performance of operational business processes. Recently, many PBPM
solutions based on deep learning were proposed by researchers. Due to the
sequential nature of event log data, a common choice is to apply recurrent
neural networks with long short-term memory (LSTM) cells. We argue, that the
elapsed time between events is informative. However, current PBPM techniques
mainly use 'vanilla' LSTM cells and hand-crafted time-related control flow
features. To better model the time dependencies between events, we propose a
new PBPM technique based on time-aware LSTM (T-LSTM) cells. T-LSTM cells
incorporate the elapsed time between consecutive events inherently to adjust
the cell memory. Furthermore, we introduce cost-sensitive learning to account
for the common class imbalance in event logs. Our experiments on publicly
available benchmark event logs indicate the effectiveness of the introduced
techniques.
</p>
<a href="http://arxiv.org/abs/2010.00889" target="_blank">arXiv:2010.00889</a> [<a href="http://arxiv.org/pdf/2010.00889" target="_blank">pdf</a>]

<h2>Anomaly detection of energy consumption in buildings: A review, current trends and new perspectives. (arXiv:2010.04560v2 [cs.CY] UPDATED)</h2>
<h3>Yassine Himeur, Khalida Ghanem, Abdullah Alsalemi, Faycal Bensaali, Abbes Amira</h3>
<p>Enormous amounts of data are being produced everyday by submeters and smart
sensors installed in different kinds of buildings. If leveraged properly, that
data could assist end-users, energy producers and utility companies in
detecting anomalous power consumption and understanding the causes of each
anomaly. Therefore, anomaly detection could stop a minor problem to become
widespread, costly and time-consuming issue. Moreover, this will help in better
decision-making to reduce wasted energy and promote sustainable and energy
efficiency behavior. In this regard, this paper is proposed to indepthly review
existing frameworks of anomaly detection in power consumption and provide a
critical analysis of existing solutions. Specifically, a comprehensive survey
is introduced, in which a novel taxonomy is introduced to classify existing
algorithms based on different factors adopted in their implementation, such as
the machine learning algorithm, feature extraction approach, detection level,
computing platform, application scenario and privacy preservation. To the best
of the authors' knowledge, this is the first review article that discusses the
anomaly detection in building energy consumption. Moving forward, important
findings along with domain-specific problems, difficulties and challenges that
remain unresolved are thoroughly discussed, including the absence of: (i)
precise definitions of anomalous power consumptions, (ii) annotated datasets,
(iii) unified metrics to assess the performance of existing solutions, and (iv)
platforms for reproducibility. Following, insights about current research
trends that anomaly detection technology needs to target for widespreading its
application and facilitate its implementation are described before deriving a
set of challenging future directions attracting significant research and
development attention.
</p>
<a href="http://arxiv.org/abs/2010.04560" target="_blank">arXiv:2010.04560</a> [<a href="http://arxiv.org/pdf/2010.04560" target="_blank">pdf</a>]

<h2>A Tensor Compiler for Unified Machine Learning Prediction Serving. (arXiv:2010.04804v2 [cs.LG] UPDATED)</h2>
<h3>Supun Nakandala Karla Saur, Gyeong-In Yu, Konstantinos Karanasos, Carlo Curino, Markus Weimer, Matteo Interlandi</h3>
<p>Machine Learning (ML) adoption in the enterprise requires simpler and more
efficient software infrastructure---the bespoke solutions typical in large web
companies are simply untenable. Model scoring, the process of obtaining
predictions from a trained model over new data, is a primary contributor to
infrastructure complexity and cost as models are trained once but used many
times. In this paper we propose HUMMINGBIRD, a novel approach to model scoring,
which compiles featurization operators and traditional ML models (e.g.,
decision trees) into a small set of tensor operations. This approach inherently
reduces infrastructure complexity and directly leverages existing investments
in Neural Network compilers and runtimes to generate efficient computations for
both CPU and hardware accelerators. Our performance results are intriguing:
despite replacing imperative computations (e.g., tree traversals) with tensor
computation abstractions, HUMMINGBIRD is competitive and often outperforms
hand-crafted kernels on micro-benchmarks on both CPU and GPU, while enabling
seamless end-to-end acceleration of ML pipelines. We have released HUMMINGBIRD
as open source.
</p>
<a href="http://arxiv.org/abs/2010.04804" target="_blank">arXiv:2010.04804</a> [<a href="http://arxiv.org/pdf/2010.04804" target="_blank">pdf</a>]

<h2>Multi-layer Residual Sparsifying Transform (MARS) Model for Low-dose CT Image Reconstruction. (arXiv:2010.06144v2 [eess.IV] UPDATED)</h2>
<h3>Xikai Yang, Yong Long, Saiprasad Ravishankar</h3>
<p>Signal models based on sparse representations have received considerable
attention in recent years. On the other hand, deep models consisting of a
cascade of functional layers, commonly known as deep neural networks, have been
highly successful for the task of object classification and have been recently
introduced to image reconstruction. In this work, we develop a new image
reconstruction approach based on a novel multi-layer model learned in an
unsupervised manner by combining both sparse representations and deep models.
The proposed framework extends the classical sparsifying transform model for
images to a Multi-lAyer Residual Sparsifying transform (MARS) model, wherein
the transform domain data are jointly sparsified over layers. We investigate
the application of MARS models learned from limited regular-dose images for
low-dose CT reconstruction using Penalized Weighted Least Squares (PWLS)
optimization. We propose new formulations for multi-layer transform learning
and image reconstruction. We derive an efficient block coordinate descent
algorithm to learn the transforms across layers, in an unsupervised manner from
limited regular-dose images. The learned model is then incorporated into the
low-dose image reconstruction phase. Low-dose CT experimental results with both
the XCAT phantom and Mayo Clinic data show that the MARS model outperforms
conventional methods such as FBP and PWLS methods based on the edge-preserving
(EP) regularizer and the single-layer learned transform (ST) model, especially
in terms of reducing noise and maintaining some subtle details.
</p>
<a href="http://arxiv.org/abs/2010.06144" target="_blank">arXiv:2010.06144</a> [<a href="http://arxiv.org/pdf/2010.06144" target="_blank">pdf</a>]

<h2>PointManifold: Using Manifold Learning for Point Cloud Classification. (arXiv:2010.07215v2 [cs.CV] UPDATED)</h2>
<h3>Dinghao Yang, Wei Gao</h3>
<p>In this paper, we propose a point cloud classification method based on graph
neural network and manifold learning. Different from the conventional point
cloud analysis methods, this paper uses manifold learning algorithms to embed
point cloud features for better considering the geometric continuity on the
surface. Then, the nature of point cloud can be acquired in low dimensional
space, and after being concatenated with features in the original
three-dimensional (3D)space, both the capability of feature representation and
the classification network performance can be improved. We pro-pose two
manifold learning modules, where one is based on locally linear embedding
algorithm, and the other is a non-linear projection method based on neural
network architecture. Both of them can obtain better performances than the
state-of-the-art baseline. Afterwards, the graph model is constructed by using
the k nearest neighbors algorithm, where the edge features are effectively
aggregated for the implementation of point cloud classification. Experiments
show that the proposed point cloud classification methods obtain the mean class
accuracy (mA) of 90.2% and the overall accuracy (oA)of 93.2%, which reach
competitive performances compared with the existing state-of-the-art related
methods.
</p>
<a href="http://arxiv.org/abs/2010.07215" target="_blank">arXiv:2010.07215</a> [<a href="http://arxiv.org/pdf/2010.07215" target="_blank">pdf</a>]

<h2>Knowledge Transfer in Multi-Task Deep Reinforcement Learning for Continuous Control. (arXiv:2010.07494v2 [cs.LG] UPDATED)</h2>
<h3>Zhiyuan Xu, Kun Wu, Zhengping Che, Jian Tang, Jieping Ye</h3>
<p>While Deep Reinforcement Learning (DRL) has emerged as a promising approach
to many complex tasks, it remains challenging to train a single DRL agent that
is capable of undertaking multiple different continuous control tasks. In this
paper, we present a Knowledge Transfer based Multi-task Deep Reinforcement
Learning framework (KTM-DRL) for continuous control, which enables a single DRL
agent to achieve expert-level performance in multiple different tasks by
learning from task-specific teachers. In KTM-DRL, the multi-task agent first
leverages an offline knowledge transfer algorithm designed particularly for the
actor-critic architecture to quickly learn a control policy from the experience
of task-specific teachers, and then it employs an online learning algorithm to
further improve itself by learning from new online transition samples under the
guidance of those teachers. We perform a comprehensive empirical study with two
commonly-used benchmarks in the MuJoCo continuous control task suite. The
experimental results well justify the effectiveness of KTM-DRL and its
knowledge transfer and online learning algorithms, as well as its superiority
over the state-of-the-art by a large margin.
</p>
<a href="http://arxiv.org/abs/2010.07494" target="_blank">arXiv:2010.07494</a> [<a href="http://arxiv.org/pdf/2010.07494" target="_blank">pdf</a>]

<h2>Improved Multi-Source Domain Adaptation by Preservation of Factors. (arXiv:2010.07783v2 [cs.CV] UPDATED)</h2>
<h3>Sebastian Schrom, Stephan Hasler, J&#xfc;rgen Adamy</h3>
<p>Domain Adaptation (DA) is a highly relevant research topic when it comes to
image classification with deep neural networks. Combining multiple source
domains in a sophisticated way to optimize a classification model can improve
the generalization to a target domain. Here, the difference in data
distributions of source and target image datasets plays a major role. In this
paper, we describe based on a theory of visual factors how real-world scenes
appear in images in general and how recent DA datasets are composed of such. We
show that different domains can be described by a set of so called domain
factors, whose values are consistent within a domain, but can change across
domains. Many DA approaches try to remove all domain factors from the feature
representation to be domain invariant. In this paper we show that this can lead
to negative transfer since task-informative factors can get lost as well. To
address this, we propose Factor-Preserving DA (FP-DA), a method to train a deep
adversarial unsupervised DA model, which is able to preserve specific task
relevant factors in a multi-domain scenario. We demonstrate on CORe50, a
dataset with many domains, how such factors can be identified by standard
one-to-one transfer experiments between single domains combined with PCA. By
applying FP-DA, we show that the highest average and minimum performance can be
achieved.
</p>
<a href="http://arxiv.org/abs/2010.07783" target="_blank">arXiv:2010.07783</a> [<a href="http://arxiv.org/pdf/2010.07783" target="_blank">pdf</a>]

<h2>CIMON: Towards High-quality Hash Codes. (arXiv:2010.07804v2 [cs.CV] UPDATED)</h2>
<h3>Xiao Luo, Daqing Wu, Zeyu Ma, Chong Chen, Huasong Zhong, Minghua Deng, Jianqiang Huang, Xian-sheng Hua</h3>
<p>Recently, hashing is widely-used in approximate nearest neighbor search for
its storage and computational efficiency. Due to the lack of labeled data in
practice, many studies focus on unsupervised hashing. Most of the unsupervised
hashing methods learn to map images into semantic similarity-preserving hash
codes by constructing local semantic similarity structure from the pre-trained
model as guiding information, i.e., treating each point pair similar if their
distance is small in feature space. However, due to the inefficient
representation ability of the pre-trained model, many false positives and
negatives in local semantic similarity will be introduced and lead to error
propagation during hash code learning. Moreover, most of hashing methods ignore
the basic characteristics of hash codes such as collisions, which will cause
instability of hash codes to disturbance. In this paper, we propose a new
method named Comprehensive sImilarity Mining and cOnsistency learNing (CIMON).
First, we use global constraint learning and similarity statistical
distribution to obtain reliable and smooth guidance. Second, image augmentation
and consistency learning will be introduced to explore both semantic and
contrastive consistency to derive robust hash codes with fewer collisions.
Extensive experiments on several benchmark datasets show that the proposed
method consistently outperforms a wide range of state-of-the-art methods in
both retrieval performance and robustness.
</p>
<a href="http://arxiv.org/abs/2010.07804" target="_blank">arXiv:2010.07804</a> [<a href="http://arxiv.org/pdf/2010.07804" target="_blank">pdf</a>]

<h2>Bi-level Score Matching for Learning Energy-based Latent Variable Models. (arXiv:2010.07856v2 [cs.LG] UPDATED)</h2>
<h3>Fan Bao, Chongxuan Li, Kun Xu, Hang Su, Jun Zhu, Bo Zhang</h3>
<p>Score matching (SM) provides a compelling approach to learn energy-based
models (EBMs) by avoiding the calculation of partition function. However, it
remains largely open to learn energy-based latent variable models (EBLVMs),
except some special cases. This paper presents a bi-level score matching (BiSM)
method to learn EBLVMs with general structures by reformulating SM as a
bi-level optimization problem. The higher level introduces a variational
posterior of the latent variables and optimizes a modified SM objective, and
the lower level optimizes the variational posterior to fit the true posterior.
To solve BiSM efficiently, we develop a stochastic optimization algorithm with
gradient unrolling. Theoretically, we analyze the consistency of BiSM and the
convergence of the stochastic algorithm. Empirically, we show the promise of
BiSM in Gaussian restricted Boltzmann machines and highly nonstructural EBLVMs
parameterized by deep convolutional neural networks. BiSM is comparable to the
widely adopted contrastive divergence and SM methods when they are applicable;
and can learn complex EBLVMs with intractable posteriors to generate natural
images.
</p>
<a href="http://arxiv.org/abs/2010.07856" target="_blank">arXiv:2010.07856</a> [<a href="http://arxiv.org/pdf/2010.07856" target="_blank">pdf</a>]

<h2>Transfer Meets Hybrid: A Synthetic Approach for Cross-Domain Collaborative Filtering with Text. (arXiv:1901.07199v1 [cs.AI] CROSS LISTED)</h2>
<h3>Guangneng Hu, Yu Zhang, Qiang Yang</h3>
<p>Collaborative filtering (CF) is the key technique for recommender systems
(RSs). CF exploits user-item behavior interactions (e.g., clicks) only and
hence suffers from the data sparsity issue. One research thread is to integrate
auxiliary information such as product reviews and news titles, leading to
hybrid filtering methods. Another thread is to transfer knowledge from other
source domains such as improving the movie recommendation with the knowledge
from the book domain, leading to transfer learning methods. In real-world life,
no single service can satisfy a user's all information needs. Thus it motivates
us to exploit both auxiliary and source information for RSs in this paper. We
propose a novel neural model to smoothly enable Transfer Meeting Hybrid (TMH)
methods for cross-domain recommendation with unstructured text in an end-to-end
manner. TMH attentively extracts useful content from unstructured text via a
memory module and selectively transfers knowledge from a source domain via a
transfer network. On two real-world datasets, TMH shows better performance in
terms of three ranking metrics by comparing with various baselines. We conduct
thorough analyses to understand how the text content and transferred knowledge
help the proposed model.
</p>
<a href="http://arxiv.org/abs/1901.07199" target="_blank">arXiv:1901.07199</a> [<a href="http://arxiv.org/pdf/1901.07199" target="_blank">pdf</a>]

<h2>Online Learning with Vector Costs and Bandits with Knapsacks. (arXiv:2010.07346v1 [cs.LG] CROSS LISTED)</h2>
<h3>Thomas Kesselheim, Sahil Singla</h3>
<p>We introduce online learning with vector costs (\OLVCp) where in each time
step $t \in \{1,\ldots, T\}$, we need to play an action $i \in \{1,\ldots,n\}$
that incurs an unknown vector cost in $[0,1]^{d}$. The goal of the online
algorithm is to minimize the $\ell_p$ norm of the sum of its cost vectors. This
captures the classical online learning setting for $d=1$, and is interesting
for general $d$ because of applications like online scheduling where we want to
balance the load between different machines (dimensions).

We study \OLVCp in both stochastic and adversarial arrival settings, and give
a general procedure to reduce the problem from $d$ dimensions to a single
dimension. This allows us to use classical online learning algorithms in both
full and bandit feedback models to obtain (near) optimal results. In
particular, we obtain a single algorithm (up to the choice of learning rate)
that gives sublinear regret for stochastic arrivals and a tight $O(\min\{p,
\log d\})$ competitive ratio for adversarial arrivals.

The \OLVCp problem also occurs as a natural subproblem when trying to solve
the popular Bandits with Knapsacks (\BwK) problem. This connection allows us to
use our \OLVCp techniques to obtain (near) optimal results for \BwK in both
stochastic and adversarial settings. In particular, we obtain a tight $O(\log d
\cdot \log T)$ competitive ratio algorithm for adversarial \BwK, which improves
over the $O(d \cdot \log T)$ competitive ratio algorithm of Immorlica et al.
[FOCS'19].
</p>
<a href="http://arxiv.org/abs/2010.07346" target="_blank">arXiv:2010.07346</a> [<a href="http://arxiv.org/pdf/2010.07346" target="_blank">pdf</a>]

<h2>Estimation of Discrete Choice Models: A Machine Learning Approach. (arXiv:2010.08016v1 [stat.AP])</h2>
<h3>Nick Doudchenko, Evgeni Drynkin</h3>
<p>In this paper we propose a new method of estimation for discrete choice
demand models when individual level data are available. The method employs a
two-step procedure. Step 1 predicts the choice probabilities as functions of
the observed individual level characteristics. Step 2 estimates the structural
parameters of the model using the estimated choice probabilities at a
particular point of interest and the moment restrictions. In essence, the
method uses nonparametric approximation (followed by) moment estimation. Hence
the name---NAME. We use simulations to compare the performance of NAME with the
standard methodology. We find that our method improves precision as well as
convergence time. We supplement the analysis by providing the large sample
properties of the proposed estimator.
</p>
<a href="http://arxiv.org/abs/2010.08016" target="_blank">arXiv:2010.08016</a> [<a href="http://arxiv.org/pdf/2010.08016" target="_blank">pdf</a>]

<h2>Learning Social Networks from Text Data using Covariate Information. (arXiv:2010.08076v1 [stat.AP])</h2>
<h3>Xiaoyi Yang, Nynke M.D. Niezink, Rebecca Nugent</h3>
<p>Describing and characterizing the impact of historical figures can be
challenging, but unraveling their social structures perhaps even more so.
Historical social network analysis methods can help and may also illuminate
people who have been overlooked by historians but turn out to be influential
social connection points. Text data, such as biographies, can be a useful
source of information about the structure of historical social networks but can
also introduce challenges in identifying links. The Local Poisson Graphical
Lasso model leverages the number of co-mentions in the text to measure
relationships between people and uses a conditional independence structure to
model a social network. This structure will reduce the tendency to overstate
the relationship between "friends of friends", but given the historical high
frequency of common names, without additional distinguishing information, we
can still introduce incorrect links. In this work, we extend the Local Poisson
Graphical Lasso model with a (multiple) penalty structure that incorporates
covariates giving increased link probabilities to people with shared covariate
information. We propose both greedy and Bayesian approaches to estimate the
penalty parameters. We present results on data simulated with characteristics
of historical networks and show that this type of penalty structure can improve
network recovery as measured by precision and recall. We also illustrate the
approach on biographical data of individuals who lived in early modern Britain,
targeting the period from 1500 to 1575.
</p>
<a href="http://arxiv.org/abs/2010.08076" target="_blank">arXiv:2010.08076</a> [<a href="http://arxiv.org/pdf/2010.08076" target="_blank">pdf</a>]

<h2>KrigHedge: GP Surrogates for Delta Hedging. (arXiv:2010.08407v1 [q-fin.CP])</h2>
<h3>Mike Ludkovski, Yuri Saporito</h3>
<p>We investigate a machine learning approach to option Greeks approximation
based on Gaussian process (GP) surrogates. The method takes in noisily observed
option prices, fits a nonparametric input-output map and then analytically
differentiates the latter to obtain the various price sensitivities. Our
motivation is to compute Greeks in cases where direct computation is expensive,
such as in local volatility models, or can only ever be done approximately. We
provide a detailed analysis of numerous aspects of GP surrogates, including
choice of kernel family, simulation design, choice of trend function and impact
of noise.

We further discuss the application to Delta hedging, including a new Lemma
that relates quality of the Delta approximation to discrete-time hedging loss.
Results are illustrated with two extensive case studies that consider
estimation of Delta, Theta and Gamma and benchmark approximation quality and
uncertainty quantification using a variety of statistical metrics. Among our
key take-aways are the recommendation to use Matern kernels, the benefit of
including virtual training points to capture boundary conditions, and the
significant loss of fidelity when training on stock-path-based datasets.
</p>
<a href="http://arxiv.org/abs/2010.08407" target="_blank">arXiv:2010.08407</a> [<a href="http://arxiv.org/pdf/2010.08407" target="_blank">pdf</a>]

