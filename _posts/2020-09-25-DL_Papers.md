---
title: Latest Deep Learning Papers
date: 2020-10-11 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Hybrid Beamforming in 5G mmWave Networks: a Full-stack Perspective. (arXiv:2010.04220v1 [cs.IT])</h2>
<h3>Felipe Gomez-Cuba, Tommaso Zugno, Junseok Kim, Michele Polese, Saewoong Bahk, Michele Zorzi</h3>
<p>This paper studies the cross-layer challenges and performance of Hybrid
Beamforming (HBF) and Multi-User Multiple-Input Multiple-Output (MU-MIMO) in 5G
millimeter wave (mmWave) cellular networks with full-stack TCP/IP traffic and
MAC scheduling. While previous research on HBF and MU-MIMO has focused on
link-level analysis of full-buffer transmissions, this work reveals the
interplay between HBF techniques and the higher layers of the protocol stack.
To this aim, prior work on full stack simulation of mmWave cellular network has
been extended by including the modeling of MU-MIMO and HBF. Our results reveal
novel relations between the networking layers and the HBF MU-MIMO performance
in the physical layer. Particularly, throughput can be increased in 5G networks
by means of Spatial Division Multiple Access (SDMA). However, in order to
achieve such benefits it is necessary to take into account certain trade-offs
and the implementation complexity of a full-stack HBF solution.
</p>
<a href="http://arxiv.org/abs/2010.04220" target="_blank">arXiv:2010.04220</a> [<a href="http://arxiv.org/pdf/2010.04220" target="_blank">pdf</a>]

<h2>Fictitious play in zero-sum stochastic games. (arXiv:2010.04223v1 [cs.GT])</h2>
<h3>Muhammed O. Sayin, Francesca Parise, Asu Ozdaglar</h3>
<p>We present fictitious play dynamics for the general class of stochastic games
and analyze its convergence properties in zero-sum stochastic games. Our
dynamics involves agents forming beliefs on opponent strategy and their own
continuation payoff (Q-function), and playing a myopic best response using
estimated continuation payoffs. Agents update their beliefs at states visited
from observations of opponent actions. A key property of the learning dynamics
is that update of the beliefs on Q-functions occurs at a slower timescale than
update of the beliefs on strategies. We show both in the model-based and
model-free cases (without knowledge of agent payoff functions and state
transition probabilities), the beliefs on strategies converge to a stationary
mixed Nash equilibrium of the zero-sum stochastic game.
</p>
<a href="http://arxiv.org/abs/2010.04223" target="_blank">arXiv:2010.04223</a> [<a href="http://arxiv.org/pdf/2010.04223" target="_blank">pdf</a>]

<h2>A low discrepancy sequence on graphs. (arXiv:2010.04227v1 [cs.LG])</h2>
<h3>A. Cloninger, H. N. Mhaskar</h3>
<p>Many applications such as election forecasting, environmental monitoring,
health policy, and graph based machine learning require taking expectation of
functions defined on the vertices of a graph. We describe a construction of a
sampling scheme analogous to the so called Leja points in complex potential
theory that can be proved to give low discrepancy estimates for the
approximation of the expected value by the impirical expected value based on
these points. In contrast to classical potential theory where the kernel is
fixed and the equilibrium distribution depends upon the kernel, we fix a
probability distribution and construct a kernel (which represents the graph
structure) for which the equilibrium distribution is the given probability
distribution. Our estimates do not depend upon the size of the graph.
</p>
<a href="http://arxiv.org/abs/2010.04227" target="_blank">arXiv:2010.04227</a> [<a href="http://arxiv.org/pdf/2010.04227" target="_blank">pdf</a>]

<h2>Phase Configuration Learning in Wireless Networks with Multiple Reconfigurable Intelligent Surfaces. (arXiv:2010.04376v1 [cs.IT])</h2>
<h3>George C. Alexandropoulos, Sumudu Samarakoon, Mehdi Bennis, Merouane Debbah</h3>
<p>Reconfigurable Intelligent Surfaces (RISs) are recently gaining remarkable
attention as a low-cost, hardware-efficient, and highly scalable technology
capable of offering dynamic control of electro-magnetic wave propagation. Their
envisioned dense deployment over various obstacles of the, otherwise passive,
wireless communication environment has been considered as a revolutionary means
to transform them into network entities with reconfigurable properties,
providing increased environmental intelligence for diverse communication
objectives. One of the major challenges with RIS-empowered wireless
communications is the low-overhead dynamic configuration of multiple RISs,
which according to the current hardware designs have very limited computing and
storage capabilities. In this paper, we consider a typical communication pair
between two nodes that is assisted by a plurality of RISs, and devise
low-complexity supervised learning approaches for the RISs' phase
configurations. By assuming common tunable phases in groups of each RIS's unit
elements, we present multi-layer perceptron Neural Network (NN) architectures
that can be trained either with positioning values or the instantaneous channel
coefficients. We investigate centralized and individual training of the RISs,
as well as their federation, and assess their computational requirements. Our
simulation results, including comparisons with the optimal phase configuration
scheme, showcase the benefits of adopting individual NNs at RISs for the link
budget performance boosting.
</p>
<a href="http://arxiv.org/abs/2010.04376" target="_blank">arXiv:2010.04376</a> [<a href="http://arxiv.org/pdf/2010.04376" target="_blank">pdf</a>]

<h2>Is Standard Deviation the New Standard? Revisiting the Critic in Deep Policy Gradients. (arXiv:2010.04440v1 [cs.LG])</h2>
<h3>Yannis Flet-Berliac, Reda Ouhamma, Odalric-Ambrym Maillard, Philippe Preux</h3>
<p>Policy gradient algorithms have proven to be successful in diverse decision
making and control tasks. However, these methods suffer from high sample
complexity and instability issues. In this paper, we address these challenges
by providing a different approach for training the critic in the actor-critic
framework. Our work builds on recent studies indicating that traditional
actor-critic algorithms do not succeed in fitting the true value function,
calling for the need to identify a better objective for the critic. In our
method, the critic uses a new state-value (resp. state-action-value) function
approximation that learns the relative value of the states (resp. state-action
pairs) rather than their absolute value as in conventional actor-critic. We
prove the theoretical consistency of the new gradient estimator and observe
dramatic empirical improvement across a variety of continuous control tasks and
algorithms. Furthermore, we validate our method in tasks with sparse rewards,
where we provide experimental evidence and theoretical insights.
</p>
<a href="http://arxiv.org/abs/2010.04440" target="_blank">arXiv:2010.04440</a> [<a href="http://arxiv.org/pdf/2010.04440" target="_blank">pdf</a>]

<h2>EpidemiOptim: A Toolbox for the Optimization of Control Policies in Epidemiological Models. (arXiv:2010.04452v1 [cs.LG])</h2>
<h3>C&#xe9;dric Colas, Boris Hejblum, S&#xe9;bastien Rouillon, Rodolphe Thi&#xe9;baut, Pierre-Yves Oudeyer, Cl&#xe9;ment Moulin-Frier, M&#xe9;lanie Prague</h3>
<p>Epidemiologists model the dynamics of epidemics in order to propose control
strategies based on pharmaceutical and non-pharmaceutical interventions
(contact limitation, lock down, vaccination, etc). Hand-designing such
strategies is not trivial because of the number of possible interventions and
the difficulty to predict long-term effects. This task can be cast as an
optimization problem where state-of-the-art machine learning algorithms such as
deep reinforcement learning, might bring significant value. However, the
specificity of each domain -- epidemic modelling or solving optimization
problem -- requires strong collaborations between researchers from different
fields of expertise.

This is why we introduce EpidemiOptim, a Python toolbox that facilitates
collaborations between researchers in epidemiology and optimization.
EpidemiOptim turns epidemiological models and cost functions into optimization
problems via a standard interface commonly used by optimization practitioners
(OpenAI Gym). Reinforcement learning algorithms based on Q-Learning with deep
neural networks (DQN) and evolutionary algorithms (NSGA-II) are already
implemented. We illustrate the use of EpidemiOptim to find optimal policies for
dynamical on-off lock-down control under the optimization of death toll and
economic recess using a Susceptible-Exposed-Infectious-Removed (SEIR) model for
COVID-19. Using EpidemiOptim and its interactive visualization platform in
Jupyter notebooks, epidemiologists, optimization practitioners and others (e.g.
economists) can easily compare epidemiological models, costs functions and
optimization algorithms to address important choices to be made by health
decision-makers.
</p>
<a href="http://arxiv.org/abs/2010.04452" target="_blank">arXiv:2010.04452</a> [<a href="http://arxiv.org/pdf/2010.04452" target="_blank">pdf</a>]

<h2>Approximating smooth functions by deep neural networks with sigmoid activation function. (arXiv:2010.04596v1 [cs.LG])</h2>
<h3>Sophie Langer</h3>
<p>We study the power of deep neural networks (DNNs) with sigmoid activation
function. Recently, it was shown that DNNs approximate any $d$-dimensional,
smooth function on a compact set with a rate of order $W^{-p/d}$, where $W$ is
the number of nonzero weights in the network and $p$ is the smoothness of the
function. Unfortunately, these rates only hold for a special class of sparsely
connected DNNs. We ask ourselves if we can show the same approximation rate for
a simpler and more general class, i.e., DNNs which are only defined by its
width and depth. In this article we show that DNNs with fixed depth and a width
of order $M^d$ achieve an approximation rate of $M^{-2p}$. As a conclusion we
quantitatively characterize the approximation power of DNNs in terms of the
overall weights $W_0$ in the network and show an approximation rate of
$W_0^{-p/d}$. This more general result finally helps us to understand which
network topology guarantees a special target accuracy.
</p>
<a href="http://arxiv.org/abs/2010.04596" target="_blank">arXiv:2010.04596</a> [<a href="http://arxiv.org/pdf/2010.04596" target="_blank">pdf</a>]

<h2>Concurrent Alternating Least Squares for multiple simultaneous Canonical Polyadic Decompositions. (arXiv:2010.04678v1 [cs.MS])</h2>
<h3>Christos Psarras, Lars Karlsson, Paolo Bientinesi</h3>
<p>Tensor decompositions, such as CANDECOMP/PARAFAC (CP), are widely used in a
variety of applications, such as chemometrics, signal processing, and machine
learning. A broadly used method for computing such decompositions relies on the
Alternating Least Squares (ALS) algorithm. When the number of components is
small, regardless of its implementation, ALS exhibits low arithmetic intensity,
which severely hinders its performance and makes GPU offloading ineffective. We
observe that, in practice, experts often have to compute multiple
decompositions of the same tensor, each with a small number of components
(typically fewer than 20), to ultimately find the best ones to use for the
application at hand. In this paper, we illustrate how multiple decompositions
of the same tensor can be fused together at the algorithmic level to increase
the arithmetic intensity. Therefore, it becomes possible to make efficient use
of GPUs for further speedups; at the same time the technique is compatible with
many enhancements typically used in ALS, such as line search, extrapolation,
and non-negativity constraints. We introduce the Concurrent ALS algorithm and
library, which offers an interface to Matlab, and a mechanism to effectively
deal with the issue that decompositions complete at different times.
Experimental results on artificial and real datasets demonstrate a shorter time
to completion due to increased arithmetic intensity.
</p>
<a href="http://arxiv.org/abs/2010.04678" target="_blank">arXiv:2010.04678</a> [<a href="http://arxiv.org/pdf/2010.04678" target="_blank">pdf</a>]

<h2>$L_1$-norm regularized $L_1$-norm best-fit line problem. (arXiv:2010.04684v1 [math.OC])</h2>
<h3>Xiao Ling, J. Paul Brooks</h3>
<p>We develop a sparse and outlier-insensitive method for one-dimensional line
fitting that can be used as the basis for outlier-insensitive machine learning
methods such as principal component analysis. The method is insensitive to
outlier observations by formulating procedures as optimization problems seeking
the $L_1$-norm best-fit line. It is also able to produce a small number of
non-zero principal components with additional penalty term to take sparseness
into account. Our algorithm has a worst-case time complexity of $O{(m^2n \log
n)}$. Computational results demonstrate that this method can provide
outlier-insensitive and sparse solutions. The space required rarely approaches
the worst-case bound.
</p>
<a href="http://arxiv.org/abs/2010.04684" target="_blank">arXiv:2010.04684</a> [<a href="http://arxiv.org/pdf/2010.04684" target="_blank">pdf</a>]

<h2>Gaussian Process (GP)-based Learning Control of Selective Laser Melting Process. (arXiv:2010.04712v1 [math.OC])</h2>
<h3>Farshid Asadi, Alaa A. Olleak, Jingang Yi, Yuebin Guo</h3>
<p>Selective laser melting (SLM) is one of emerging processes for effective
metal additive manufacturing. Due to complex heat exchange and material phase
changes, it is challenging to accurately model the SLM dynamics and design
robust control of SLM process. In this paper, we first present a data-driven
Gaussian process based dynamic model for SLM process and then design a model
predictive control to regulate the melt pool size and temperature. Physical and
process constraints are considered in the controller design. The learning model
and control design are tested and validated with high-fidelity finite element
simulation. The comparison results with other control design are also presented
to demonstrate the efficacy of the control design.
</p>
<a href="http://arxiv.org/abs/2010.04712" target="_blank">arXiv:2010.04712</a> [<a href="http://arxiv.org/pdf/2010.04712" target="_blank">pdf</a>]

<h2>A convex relaxation to compute the nearest structured rank deficient matrix. (arXiv:1904.09661v2 [math.OC] UPDATED)</h2>
<h3>Diego Cifuentes</h3>
<p>Given an affine space of matrices $\mathcal{L}$ and a matrix $\Theta\in
\mathcal{L}$, consider the problem of computing the closest rank deficient
matrix to $\Theta$ on $\mathcal{L}$ with respect to the Frobenius norm. This is
a nonconvex problem with several applications in control theory, computer
algebra, and computer vision. We introduce a novel semidefinite programming
(SDP) relaxation, and prove that it always gives the global minimizer of the
nonconvex problem in the low noise regime, i.e., when $\Theta$ is close to be
rank deficient. Our SDP is the first convex relaxation for this problem with
provable guarantees. We evaluate the performance of our SDP relaxation in
examples from system identification, approximate GCD, triangulation, and camera
resectioning. Our relaxation reliably obtains the global minimizer under
non-adversarial noise, and its noise tolerance is significantly better than
state of the art methods.
</p>
<a href="http://arxiv.org/abs/1904.09661" target="_blank">arXiv:1904.09661</a> [<a href="http://arxiv.org/pdf/1904.09661" target="_blank">pdf</a>]

<h2>Online Mixed-Integer Optimization in Milliseconds. (arXiv:1907.02206v3 [math.OC] UPDATED)</h2>
<h3>Dimitris Bertsimas, Bartolomeo Stellato</h3>
<p>We propose a method to solve online mixed-integer optimization (MIO) problems
at very high speed using machine learning. By exploiting the repetitive nature
of online optimization, we are able to greatly speedup the solution time. Our
approach encodes the optimal solution into a small amount of information
denoted as strategy using the Voice of Optimization framework proposed in
[BS20]. In this way the core part of the optimization algorithm becomes a
multiclass classification problem which can be solved very quickly. In this
work we extend that framework to real-time and high-speed applications focusing
on parametric mixed-integer quadratic optimization (MIQO). We propose an
extremely fast online optimization algorithm consisting of a feedforward neural
network (NN) evaluation and a linear system solution where the matrix has
already been factorized. Therefore, this online approach does not require any
solver nor iterative algorithm. We show the speed of the proposed method both
in terms of total computations required and measured execution time. We
estimate the number of floating point operations (flops) required to completely
recover the optimal solution as a function of the problem dimensions. Compared
to state-of-the-art MIO routines, the online running time of our method is very
predictable and can be lower than a single matrix factorization time. We
benchmark our method against the state-of-the-art solver Gurobi obtaining from
two to three orders of magnitude speedups on examples from fuel cell energy
management, sparse portfolio optimization and motion planning with obstacle
avoidance.
</p>
<a href="http://arxiv.org/abs/1907.02206" target="_blank">arXiv:1907.02206</a> [<a href="http://arxiv.org/pdf/1907.02206" target="_blank">pdf</a>]

<h2>Fast Objective & Duality Gap Convergence for Nonconvex-Strongly-Concave Min-Max Problems. (arXiv:2006.06889v6 [cs.LG] UPDATED)</h2>
<h3>Zhishuai Guo, Zhuoning Yuan, Yan Yan, Tianbao Yang</h3>
<p>This paper focuses on stochastic methods for solving smooth non-convex
strongly-concave min-max problems, which have received increasing attention due
to their potential applications in deep learning (e.g., deep AUC maximization).
However, most of the existing algorithms are slow in practice, and their
analysis revolves around the convergence to a nearly stationary point. We
consider leveraging the Polyak-\L ojasiewicz (PL) condition to design faster
stochastic algorithms with stronger convergence guarantee. Although PL
condition has been utilized for designing many stochastic minimization
algorithms, their applications for non-convex min-max optimization remains
rare. In this paper, we propose and analyze proximal epoch-based methods, and
establish fast convergence in terms of both {\bf the primal objective gap and
the duality gap}. Our analysis is interesting in threefold: (i) it is based on
a novel Lyapunov function that consists of the primal objective gap and the
duality gap of a regularized function; (ii) it only requires a weaker PL
condition for establishing the primal objective convergence than that required
for the duality gap convergence; (iii) it yields the optimal dependence on the
accuracy level $\epsilon$, i.e., $O(1/\epsilon)$. We also make explicit the
dependence on the problem parameters and explore regions of weak convexity
parameter that lead to improved dependence on condition numbers. Experiments on
deep AUC maximization demonstrate the effectiveness of our methods. Our method
(MaxAUC) achieved an AUC of 0.922 on private testing set on {\bf CheXpert
competition}.
</p>
<a href="http://arxiv.org/abs/2006.06889" target="_blank">arXiv:2006.06889</a> [<a href="http://arxiv.org/pdf/2006.06889" target="_blank">pdf</a>]

<h2>A Hybrid Adaptive Educational eLearning Project based on Ontologies Matching and Recommendation System. (arXiv:2007.14771v3 [cs.IR] UPDATED)</h2>
<h3>Vasiliki Demertzi, Konstantinos Demertzis</h3>
<p>The implementation of teaching interventions in learning needs has received
considerable attention, as the provision of the same educational conditions to
all students, is pedagogically ineffective. In contrast, more effectively
considered the pedagogical strategies that adapt to the real individual skills
of the students. An important innovation in this direction is the Adaptive
Educational Systems (AES) that support automatic modeling study and adjust the
teaching content on educational needs and students' skills. Effective
utilization of these educational approaches can be enhanced with Artificial
Intelligence (AI) technologies in order to the substantive content of the web
acquires structure and the published information is perceived by the search
engines. This study proposes a novel Adaptive Educational eLearning System
(AEeLS) that has the capacity to gather and analyze data from learning
repositories and to adapt these to the educational curriculum according to the
student skills and experience. It is a novel hybrid machine learning system
that combines a Semi-Supervised Classification method for ontology matching and
a Recommendation Mechanism that uses a hybrid method from neighborhood-based
collaborative and content-based filtering techniques, in order to provide a
personalized educational environment for each student.
</p>
<a href="http://arxiv.org/abs/2007.14771" target="_blank">arXiv:2007.14771</a> [<a href="http://arxiv.org/pdf/2007.14771" target="_blank">pdf</a>]

<h2>On Information Gain and Regret Bounds in Gaussian Process Bandits. (arXiv:2009.06966v2 [stat.ML] UPDATED)</h2>
<h3>Sattar Vakili, Kia Khezeli, Victor Picheny</h3>
<p>Consider the sequential optimization of an expensive to evaluate and possibly
non-convex objective function $f$ from noisy feedback, that can be considered
as a continuum-armed bandit problem. Upper bounds on the regret performance of
several learning algorithms (GP-UCB, GP-TS, and their variants) are known under
both a Bayesian (when $f$ is a sample from a Gaussian process (GP)) and a
frequentist (when $f$ lives in a reproducing kernel Hilbert space) setting. The
regret bounds often rely on the maximal information gain $\gamma_T$ between $T$
observations and the underlying GP (surrogate) model. We provide general bounds
on $\gamma_T$ based on the decay rate of the eigenvalues of the GP kernel,
whose specialisation for commonly used kernels, improves the existing bounds on
$\gamma_T$, and consequently the regret bounds relying on $\gamma_T$ under
numerous settings. For the Mat\'ern family of kernels, where the lower bounds
on $\gamma_T$, and regret under the frequentist setting, are known, our results
close a huge polynomial in $T$ gap between the upper and lower bounds (up to
logarithmic in $T$ factors).
</p>
<a href="http://arxiv.org/abs/2009.06966" target="_blank">arXiv:2009.06966</a> [<a href="http://arxiv.org/pdf/2009.06966" target="_blank">pdf</a>]

<h2>Characterization of surface motion patterns in highly deformable soft tissue organs from dynamic Magnetic Resonance Imaging. (arXiv:2010.02746v2 [cs.CV] UPDATED)</h2>
<h3>Karim Makki, Amine Bohi, Augustin .C Ogier, Marc Emmanuel Bellemare</h3>
<p>In this work, we present a pipeline for characterization of bladder surface
dynamics during deep respiratory movements from dynamic Magnetic Resonance
Imaging (MRI). Dynamic MRI may capture temporal anatomical changes in soft
tissue organs with high-contrast but the obtained sequences usually suffer from
limited volume coverage which makes the high resolution reconstruction of organ
shape trajectories a major challenge in temporal studies. For a compact shape
representation, the reconstructed temporal data with full volume coverage are
first used to establish a subject-specific dynamical 4D mesh sequences using
the large deformation diffeomorphic metric mapping (LDDMM) framework. Then, we
performed a statistical characterization of organ shape changes from mechanical
parameters such as mesh elongations and distortions. Since shape space is
curved, we have also used the intrinsic curvature changes as metric to quantify
surface evolution. However, the numerical computation of curvature is strongly
dependant on the surface parameterization (i.e. the mesh resolution). To cope
with this dependency, we propose a non-parametric level set method to evaluate
spatio-temporal surface evolution. Independent of parameterization and
minimizing the length of the geodesic curves, it shrinks smoothly the surface
curves towards a sphere by minimizing a Dirichlet energy. An Eulerian PDE
approach is used for evaluation of surface dynamics from the curve-shortening
flow. Results demonstrate the numerical stability of the derived descriptor
throughout smooth continuous-time organ trajectories. Intercorrelations between
individuals' motion patterns from different geometric features are computed
using the Laplace-Beltrami Operator (LBO) eigenfunctions for spherical mapping.
</p>
<a href="http://arxiv.org/abs/2010.02746" target="_blank">arXiv:2010.02746</a> [<a href="http://arxiv.org/pdf/2010.02746" target="_blank">pdf</a>]

<h2>Communication-Efficient Distributed Stochastic AUC Maximization with Deep Neural Networks. (arXiv:2005.02426v2 [cs.DC] CROSS LISTED)</h2>
<h3>Zhishuai Guo, Mingrui Liu, Zhuoning Yuan, Li Shen, Wei Liu, Tianbao Yang</h3>
<p>In this paper, we study distributed algorithms for large-scale AUC
maximization with a deep neural network as a predictive model. Although
distributed learning techniques have been investigated extensively in deep
learning, they are not directly applicable to stochastic AUC maximization with
deep neural networks due to its striking differences from standard loss
minimization problems (e.g., cross-entropy). Towards addressing this challenge,
we propose and analyze a communication-efficient distributed optimization
algorithm based on a {\it non-convex concave} reformulation of the AUC
maximization, in which the communication of both the primal variable and the
dual variable between each worker and the parameter server only occurs after
multiple steps of gradient-based updates in each worker. Compared with the
naive parallel version of an existing algorithm that computes stochastic
gradients at individual machines and averages them for updating the model
parameters, our algorithm requires a much less number of communication rounds
and still achieves a linear speedup in theory. To the best of our knowledge,
this is the \textbf{first} work that solves the {\it non-convex concave
min-max} problem for AUC maximization with deep neural networks in a
communication-efficient distributed manner while still maintaining the linear
speedup property in theory. Our experiments on several benchmark datasets show
the effectiveness of our algorithm and also confirm our theory.
</p>
<a href="http://arxiv.org/abs/2005.02426" target="_blank">arXiv:2005.02426</a> [<a href="http://arxiv.org/pdf/2005.02426" target="_blank">pdf</a>]

<h2>Machine Learning for Gas and Oil Exploration. (arXiv:2010.04186v1 [cs.LG])</h2>
<h3>Vito Alexander Nordloh, Anna Roub&#xed;ckov&#xe1;, Nick Brown</h3>
<p>Drilling boreholes for gas and oil extraction is an expensive process and
profitability strongly depends on characteristics of the subsurface. As
profitability is a key success factor, companies in the industry utilise well
logs to explore the subsurface beforehand. These well logs contain various
characteristics of the rock around the borehole, which allow petrophysicists to
determine the expected amount of contained hydrocarbon. However, these logs are
often incomplete and, as a consequence, the subsequent analyses cannot exploit
the full potential of the well logs.

In this paper we demonstrate that Machine Learning can be applied to
\emph{fill in the gaps} and estimate missing values. We investigate how the
amount of training data influences the accuracy of prediction and how to best
design regression models (Gradient Boosting and neural network) to obtain
optimal results. We then explore the models' predictions both quantitatively,
tracking the prediction error, and qualitatively, capturing the evolution of
the measured and predicted values for a given property with depth. Combining
the findings has enabled us to develop a predictive model that completes the
well logs, increasing their quality and potential commercial value.
</p>
<a href="http://arxiv.org/abs/2010.04186" target="_blank">arXiv:2010.04186</a> [<a href="http://arxiv.org/pdf/2010.04186" target="_blank">pdf</a>]

<h2>MatDRAM: A pure-MATLAB Delayed-Rejection Adaptive Metropolis-Hastings Markov Chain Monte Carlo Sampler. (arXiv:2010.04190v1 [physics.data-an])</h2>
<h3>Shashank Kumbhare, Amir Shahmoradi</h3>
<p>Markov Chain Monte Carlo (MCMC) algorithms are widely used for stochastic
optimization, sampling, and integration of mathematical objective functions, in
particular, in the context of Bayesian inverse problems and parameter
estimation. For decades, the algorithm of choice in MCMC simulations has been
the Metropolis-Hastings (MH) algorithm. An advancement over the traditional
MH-MCMC sampler is the Delayed-Rejection Adaptive Metropolis (DRAM). In this
paper, we present MatDRAM, a stochastic optimization, sampling, and Monte Carlo
integration toolbox in MATLAB which implements a variant of the DRAM algorithm
for exploring the mathematical objective functions of arbitrary-dimensions, in
particular, the posterior distributions of Bayesian models in data science,
Machine Learning, and scientific inference. The design goals of MatDRAM include
nearly-full automation of MCMC simulations, user-friendliness,
fully-deterministic reproducibility, and the restart functionality of
simulations. We also discuss the implementation details of a technique to
automatically monitor and ensure the diminishing adaptation of the proposal
distribution of the DRAM algorithm and a method of efficiently storing the
resulting simulated Markov chains. The MatDRAM library is open-source,
MIT-licensed, and permanently located and maintained as part of the ParaMonte
library at https://github.com/cdslaborg/paramonte.
</p>
<a href="http://arxiv.org/abs/2010.04190" target="_blank">arXiv:2010.04190</a> [<a href="http://arxiv.org/pdf/2010.04190" target="_blank">pdf</a>]

<h2>Towards the Detection of Building Occupancy with Synthetic Environmental Data. (arXiv:2010.04209v1 [cs.LG])</h2>
<h3>Manuel Weber, Christoph Doblander, Peter Mandl</h3>
<p>Information about room-level occupancy is crucial to many building-related
tasks, such as building automation or energy performance simulation. Current
occupancy detection literature focuses on data-driven methods, but is mostly
based on small case studies with few rooms. The necessity to collect
room-specific data for each room of interest impedes applicability of machine
learning, especially data-intensive deep learning approaches, in practice. To
derive accurate predictions from less data, we suggest knowledge transfer from
synthetic data. In this paper, we conduct an experiment with data from a CO$_2$
sensor in an office room, and additional synthetic data obtained from a
simulation. Our contribution includes (a) a simulation method for CO$_2$
dynamics under randomized occupant behavior, (b) a proof of concept for
knowledge transfer from simulated CO$_2$ data, and (c) an outline of future
research implications. From our results, we can conclude that the transfer
approach can effectively reduce the required amount of data for model training.
</p>
<a href="http://arxiv.org/abs/2010.04209" target="_blank">arXiv:2010.04209</a> [<a href="http://arxiv.org/pdf/2010.04209" target="_blank">pdf</a>]

<h2>Provable Fictitious Play for General Mean-Field Games. (arXiv:2010.04211v1 [cs.LG])</h2>
<h3>Qiaomin Xie, Zhuoran Yang, Zhaoran Wang, Andreea Minca</h3>
<p>We propose a reinforcement learning algorithm for stationary mean-field
games, where the goal is to learn a pair of mean-field state and stationary
policy that constitutes the Nash equilibrium. When viewing the mean-field state
and the policy as two players, we propose a fictitious play algorithm which
alternatively updates the mean-field state and the policy via gradient-descent
and proximal policy optimization, respectively. Our algorithm is in stark
contrast with previous literature which solves each single-agent reinforcement
learning problem induced by the iterates mean-field states to the optimum.
Furthermore, we prove that our fictitious play algorithm converges to the Nash
equilibrium at a sublinear rate. To the best of our knowledge, this seems the
first provably convergent single-loop reinforcement learning algorithm for
mean-field games based on iterative updates of both mean-field state and
policy.
</p>
<a href="http://arxiv.org/abs/2010.04211" target="_blank">arXiv:2010.04211</a> [<a href="http://arxiv.org/pdf/2010.04211" target="_blank">pdf</a>]

<h2>Machine Learning Enabled Scalable Performance Prediction of Scientific Codes. (arXiv:2010.04212v1 [cs.PF])</h2>
<h3>Gopinath Chennupati, Nandakishore Santhi, Phill Romero, Stephan Eidenbenz</h3>
<p>We present the Analytical Memory Model with Pipelines (AMMP) of the
Performance Prediction Toolkit (PPT). PPT-AMMP takes high-level source code and
hardware architecture parameters as input, predicts runtime of that code on the
target hardware platform, which is defined in the input parameters. PPT-AMMP
transforms the code to an (architecture-independent) intermediate
representation, then (i) analyzes the basic block structure of the code, (ii)
processes architecture-independent virtual memory access patterns that it uses
to build memory reuse distance distribution models for each basic block, (iii)
runs detailed basic-block level simulations to determine hardware pipeline
usage.

PPT-AMMP uses machine learning and regression techniques to build the
prediction models based on small instances of the input code, then integrates
into a higher-order discrete-event simulation model of PPT running on Simian
PDES engine. We validate PPT-AMMP on four standard computational physics
benchmarks, finally present a use case of hardware parameter sensitivity
analysis to identify bottleneck hardware resources on different code inputs. We
further extend PPT-AMMP to predict the performance of scientific application
(radiation transport), SNAP. We analyze the application of multi-variate
regression models that accurately predict the reuse profiles and the basic
block counts. The predicted runtimes of SNAP when compared to that of actual
times are accurate.
</p>
<a href="http://arxiv.org/abs/2010.04212" target="_blank">arXiv:2010.04212</a> [<a href="http://arxiv.org/pdf/2010.04212" target="_blank">pdf</a>]

<h2>Affine-Invariant Robust Training. (arXiv:2010.04216v1 [cs.LG])</h2>
<h3>Oriol Barbany Mayor</h3>
<p>The field of adversarial robustness has attracted significant attention in
machine learning. Contrary to the common approach of training models that are
accurate in average case, it aims at training models that are accurate for
worst case inputs, hence it yields more robust and reliable models. Put
differently, it tries to prevent an adversary from fooling a model. The study
of adversarial robustness is largely focused on $\ell_p-$bounded adversarial
perturbations, i.e. modifications of the inputs, bounded in some $\ell_p$ norm.
Nevertheless, it has been shown that state-of-the-art models are also
vulnerable to other more natural perturbations such as affine transformations,
which were already considered in machine learning within data augmentation.
This project reviews previous work in spatial robustness methods and proposes
evolution strategies as zeroth order optimization algorithms to find the worst
affine transforms for each input. The proposed method effectively yields robust
models and allows introducing non-parametric adversarial perturbations.
</p>
<a href="http://arxiv.org/abs/2010.04216" target="_blank">arXiv:2010.04216</a> [<a href="http://arxiv.org/pdf/2010.04216" target="_blank">pdf</a>]

<h2>Ensemble Hyperspectral Band Selection for Detecting Nitrogen Status in Grape Leaves. (arXiv:2010.04225v1 [cs.CV])</h2>
<h3>Ryan Omidi, Ali Moghimi, Alireza Pourreza, Mohamed El-Hadedy Aly, Anas Salah Eddin</h3>
<p>The large data size and dimensionality of hyperspectral data demands complex
processing and data analysis. Multispectral data do not suffer the same
limitations, but are normally restricted to blue, green, red, red edge, and
near infrared bands. This study aimed to identify the optimal set of spectral
bands for nitrogen detection in grape leaves using ensemble feature selection
on hyperspectral data from over 3,000 leaves from 150 Flame Seedless table
grapevines. Six machine learning base rankers were included in the ensemble:
random forest, LASSO, SelectKBest, ReliefF, SVM-RFE, and chaotic crow search
algorithm (CCSA). The pipeline identified less than 0.45% of the bands as most
informative about grape nitrogen status. The selected violet, yellow-orange,
and shortwave infrared bands lie outside of the typical blue, green, red, red
edge, and near infrared bands of commercial multispectral cameras, so the
potential improvement in remote sensing of nitrogen in grapevines brought forth
by a customized multispectral sensor centered at the selected bands is
promising and worth further investigation. The proposed pipeline may also be
used for application-specific multispectral sensor design in domains other than
agriculture.
</p>
<a href="http://arxiv.org/abs/2010.04225" target="_blank">arXiv:2010.04225</a> [<a href="http://arxiv.org/pdf/2010.04225" target="_blank">pdf</a>]

<h2>All for One and One for All: Improving Music Separation by Bridging Networks. (arXiv:2010.04228v1 [eess.AS])</h2>
<h3>Ryosuke Sawata, Stefan Uhlich, Shusuke Takahashi, Yuki Mitsufuji</h3>
<p>This paper proposes two novel loss functions, a multi domain loss (MDL) and a
combination loss (CL), for music source separation with deep neural networks
(DNNs). In particular, by using MDL we take advantage of the frequency and time
domain representation of audio signals and by using CL we consider the
relationship among output source instruments, respectively. MDL and CL can
easily be applied to many existing DNN-based methods since they are merely loss
functions which are used during training and which do not affect the inference
step. Experimental results show that the performance of Open-Unmix (UMX), which
is a well-known and state-of-the-art open source library for music source
separation, could be improved by utilizing our two new loss functions MDL and
CL.
</p>
<a href="http://arxiv.org/abs/2010.04228" target="_blank">arXiv:2010.04228</a> [<a href="http://arxiv.org/pdf/2010.04228" target="_blank">pdf</a>]

<h2>Nonstationary Reinforcement Learning with Linear Function Approximation. (arXiv:2010.04244v1 [cs.LG])</h2>
<h3>Huozhi Zhou, Jinglin Chen, Lav R. Varshney, Ashish Jagmohan</h3>
<p>We consider reinforcement learning (RL) in episodic Markov decision processes
(MDPs) with linear function approximation under drifting environment.
Specifically, both the reward and state transition functions can evolve over
time, as long as their respective total variations, quantified by suitable
metrics, do not exceed certain \textit{variation budgets}. We first develop
$\texttt{LSVI-UCB-Restart}$ algorithm, an optimistic modification of
least-squares value iteration combined with periodic restart, and establish its
dynamic regret bound when variation budgets are known. We then propose a
parameter-free algorithm, \texttt{Ada-LSVI-UCB-Restart}, that works without
knowing the variation budgets, but with a slightly worse dynamic regret bound.
We also derive the first minimax dynamic regret lower bound for nonstationary
MDPs to show that our proposed algorithms are near-optimal. As a byproduct, we
establish a minimax regret lower bound for linear MDPs, which is unsolved by
\cite{jin2020provably}. As far as we know, this is the first dynamic regret
analysis in nonstationary reinforcement learning with function approximation.
</p>
<a href="http://arxiv.org/abs/2010.04244" target="_blank">arXiv:2010.04244</a> [<a href="http://arxiv.org/pdf/2010.04244" target="_blank">pdf</a>]

<h2>Dynamic mode decomposition for forecasting and analysis of power grid load data. (arXiv:2010.04248v1 [physics.soc-ph])</h2>
<h3>Daniel Dylewsky, David Barajas-Solano, Tong Ma, Alexandre M. Tartakovsky, J. Nathan Kutz</h3>
<p>Time series forecasting remains a central challenge problem in almost all
scientific disciplines, including load modeling in power systems engineering.
The ability to produce accurate forecasts has major implications for real-time
control, pricing, maintenance, and security decisions. We introduce a novel
load forecasting method in which observed dynamics are modeled as a forced
linear system using Dynamic Mode Decomposition (DMD) in time delay coordinates.
Central to this approach is the insight that grid load, like many observables
on complex real-world systems, has an "almost-periodic" character, i.e., a
continuous Fourier spectrum punctuated by dominant peaks, which capture regular
(e.g., daily or weekly) recurrences in the dynamics. The forecasting method
presented takes advantage of this property by (i) regressing to a deterministic
linear model whose eigenspectrum maps onto those peaks, and (ii) simultaneously
learning a stochastic Gaussian process regression (GPR) process to actuate this
system. Our forecasting algorithm is compared against state-of-the-art
forecasting techniques not using additional explanatory variables and is shown
to produce superior performance. Moreover, its use of linear intrinsic dynamics
offers a number of desirable properties in terms of interpretability and
parsimony.
</p>
<a href="http://arxiv.org/abs/2010.04248" target="_blank">arXiv:2010.04248</a> [<a href="http://arxiv.org/pdf/2010.04248" target="_blank">pdf</a>]

<h2>Evaluating the Effectiveness of Efficient Neural Architecture Search for Sentence-Pair Tasks. (arXiv:2010.04249v1 [cs.CL])</h2>
<h3>Ansel MacLaughlin, Jwala Dhamala, Anoop Kumar, Sriram Venkatapathy, Ragav Venkatesan, Rahul Gupta</h3>
<p>Neural Architecture Search (NAS) methods, which automatically learn entire
neural model or individual neural cell architectures, have recently achieved
competitive or state-of-the-art (SOTA) performance on variety of natural
language processing and computer vision tasks, including language modeling,
natural language inference, and image classification. In this work, we explore
the applicability of a SOTA NAS algorithm, Efficient Neural Architecture Search
(ENAS) (Pham et al., 2018) to two sentence pair tasks, paraphrase detection and
semantic textual similarity. We use ENAS to perform a micro-level search and
learn a task-optimized RNN cell architecture as a drop-in replacement for an
LSTM. We explore the effectiveness of ENAS through experiments on three
datasets (MRPC, SICK, STS-B), with two different models (ESIM, BiLSTM-Max), and
two sets of embeddings (Glove, BERT). In contrast to prior work applying ENAS
to NLP tasks, our results are mixed -- we find that ENAS architectures
sometimes, but not always, outperform LSTMs and perform similarly to random
architecture search.
</p>
<a href="http://arxiv.org/abs/2010.04249" target="_blank">arXiv:2010.04249</a> [<a href="http://arxiv.org/pdf/2010.04249" target="_blank">pdf</a>]

<h2>Exploring Sensitivity of ICF Outputs to Design Parameters in Experiments Using Machine Learning. (arXiv:2010.04254v1 [physics.plasm-ph])</h2>
<h3>Julia B. Nakhleh, M. Giselle Fern&#xe1;ndez-Godino, Michael J. Grosskopf, Brandon M. Wilson, John Kline, Gowri Srinivasan</h3>
<p>Building a sustainable burn platform in inertial confinement fusion (ICF)
requires an understanding of the complex coupling of physical processes and the
effects that key experimental design changes have on implosion performance.
While simulation codes are used to model ICF implosions, incomplete physics and
the need for approximations deteriorate their predictive capability.
Identification of relationships between controllable design inputs and
measurable outcomes can help guide the future design of experiments and
development of simulation codes, which can potentially improve the accuracy of
the computational models used to simulate ICF implosions. In this paper, we
leverage developments in machine learning (ML) and methods for ML feature
importance/sensitivity analysis to identify complex relationships in ways that
are difficult to process using expert judgment alone. We present work using
random forest (RF) regression for prediction of yield, velocity, and other
experimental outcomes given a suite of design parameters, along with an
assessment of important relationships and uncertainties in the prediction
model. We show that RF models are capable of learning and predicting on ICF
experimental data with high accuracy, and we extract feature importance metrics
that provide insight into the physical significance of different controllable
design inputs for various ICF design configurations. These results can be used
to augment expert intuition and simulation results for optimal design of future
ICF experiments.
</p>
<a href="http://arxiv.org/abs/2010.04254" target="_blank">arXiv:2010.04254</a> [<a href="http://arxiv.org/pdf/2010.04254" target="_blank">pdf</a>]

<h2>Unsupervised Joint $k$-node Graph Representations with Compositional Energy-Based Models. (arXiv:2010.04259v1 [cs.LG])</h2>
<h3>Leonardo Cotta, Carlos H. C. Teixeira, Ananthram Swami, Bruno Ribeiro</h3>
<p>Existing Graph Neural Network (GNN) methods that learn inductive unsupervised
graph representations focus on learning node and edge representations by
predicting observed edges in the graph. Although such approaches have shown
advances in downstream node classification tasks, they are ineffective in
jointly representing larger $k$-node sets, $k{&gt;}2$. We propose MHM-GNN, an
inductive unsupervised graph representation approach that combines joint
$k$-node representations with energy-based models (hypergraph Markov networks)
and GNNs. To address the intractability of the loss that arises from this
combination, we endow our optimization with a loss upper bound using a
finite-sample unbiased Markov Chain Monte Carlo estimator. Our experiments show
that the unsupervised MHM-GNN representations of MHM-GNN produce better
unsupervised representations than existing approaches from the literature.
</p>
<a href="http://arxiv.org/abs/2010.04259" target="_blank">arXiv:2010.04259</a> [<a href="http://arxiv.org/pdf/2010.04259" target="_blank">pdf</a>]

<h2>Fake Reviews Detection through Analysis of Linguistic Features. (arXiv:2010.04260v1 [cs.CL])</h2>
<h3>Faranak Abri, Luis Felipe Gutierrez, Akbar Siami Namin, Keith S. Jones, David R. W. Sears</h3>
<p>Online reviews play an integral part for success or failure of businesses.
Prior to purchasing services or goods, customers first review the online
comments submitted by previous customers. However, it is possible to
superficially boost or hinder some businesses through posting counterfeit and
fake reviews. This paper explores a natural language processing approach to
identify fake reviews. We present a detailed analysis of linguistic features
for distinguishing fake and trustworthy online reviews. We study 15 linguistic
features and measure their significance and importance towards the
classification schemes employed in this study. Our results indicate that fake
reviews tend to include more redundant terms and pauses, and generally contain
longer sentences. The application of several machine learning classification
algorithms revealed that we were able to discriminate fake from real reviews
with high accuracy using these linguistic features.
</p>
<a href="http://arxiv.org/abs/2010.04260" target="_blank">arXiv:2010.04260</a> [<a href="http://arxiv.org/pdf/2010.04260" target="_blank">pdf</a>]

<h2>Dissecting Hessian: Understanding Common Structure of Hessian in Neural Networks. (arXiv:2010.04261v1 [cs.LG])</h2>
<h3>Yikai Wu, Xingyu Zhu, Chenwei Wu, Annie Wang, Rong Ge</h3>
<p>Hessian captures important properties of the deep neural network loss
landscape. We observe that eigenvectors and eigenspaces of the layer-wise
Hessian for neural network objective have several interesting structures -- top
eigenspaces for different models have high overlap, and top eigenvectors form
low rank matrices when they are reshaped into the same shape as the
corresponding weight matrix. These structures, as well as the low rank
structure of the Hessian observed in previous studies, can be explained by
approximating the Hessian using Kronecker factorization. Our new understanding
can also explain why some of these structures become weaker when the network is
trained with batch normalization. Finally, we show that the Kronecker
factorization can be combined with PAC-Bayes techniques to get better explicit
generalization bounds.
</p>
<a href="http://arxiv.org/abs/2010.04261" target="_blank">arXiv:2010.04261</a> [<a href="http://arxiv.org/pdf/2010.04261" target="_blank">pdf</a>]

<h2>Trajectory Inspection: A Method for Iterative Clinician-Driven Design of Reinforcement Learning Studies. (arXiv:2010.04279v1 [cs.LG])</h2>
<h3>Christina X. Ji, Michael Oberst, Sanjat Kanjilal, David Sontag</h3>
<p>Treatment policies learned via reinforcement learning (RL) from observational
health data are sensitive to subtle choices in study design. We highlight a
simple approach, trajectory inspection, to bring clinicians into an iterative
design process for model-based RL studies. We inspect trajectories where the
model recommends unexpectedly aggressive treatments or believes its
recommendations would lead to much more positive outcomes. Then, we examine
clinical trajectories simulated with the learned model and policy alongside the
actual hospital course to uncover possible modeling issues. To demonstrate that
this approach yields insights, we apply it to recent work on RL for inpatient
sepsis management. We find that a design choice around maximum trajectory
length leads to a model bias towards discharge, that the RL policy preference
for high vasopressor doses may be linked to small sample sizes, and that the
model has a clinically implausible expectation of discharge without weaning off
vasopressors.
</p>
<a href="http://arxiv.org/abs/2010.04279" target="_blank">arXiv:2010.04279</a> [<a href="http://arxiv.org/pdf/2010.04279" target="_blank">pdf</a>]

<h2>Large Scale Indexing of Generic Medical Image Data using Unbiased Shallow Keypoints and Deep CNN Features. (arXiv:2010.04283v1 [cs.CV])</h2>
<h3>L. Chauvin, M. Ben Lazreg, J.B. Carluer, W. Wells, M. Toews</h3>
<p>We propose a unified appearance model accounting for traditional shallow
(i.e. 3D SIFT keypoints) and deep (i.e. CNN output layers) image feature
representations, encoding respectively specific, localized neuroanatomical
patterns and rich global information into a single indexing and classification
framework. A novel Bayesian model combines shallow and deep features based on
an assumption of conditional independence and validated by experiments indexing
specific family members and general group categories in 3D MRI neuroimage data
of 1010 subjects from the Human Connectome Project, including twins and
non-twin siblings. A novel domain adaptation strategy is presented,
transforming deep CNN vectors elements into binary class-informative
descriptors. A GPU-based implementation of all processing is provided.
State-of-the-art performance is achieved in large-scale neuroimage indexing,
both in terms of computational complexity, accuracy in identifying family
members and sex classification.
</p>
<a href="http://arxiv.org/abs/2010.04283" target="_blank">arXiv:2010.04283</a> [<a href="http://arxiv.org/pdf/2010.04283" target="_blank">pdf</a>]

<h2>Leveraging Unpaired Text Data for Training End-to-End Speech-to-Intent Systems. (arXiv:2010.04284v1 [cs.CL])</h2>
<h3>Yinghui Huang, Hong-Kwang Kuo, Samuel Thomas, Zvi Kons, Kartik Audhkhasi, Brian Kingsbury, Ron Hoory, Michael Picheny</h3>
<p>Training an end-to-end (E2E) neural network speech-to-intent (S2I) system
that directly extracts intents from speech requires large amounts of
intent-labeled speech data, which is time consuming and expensive to collect.
Initializing the S2I model with an ASR model trained on copious speech data can
alleviate data sparsity. In this paper, we attempt to leverage NLU text
resources. We implemented a CTC-based S2I system that matches the performance
of a state-of-the-art, traditional cascaded SLU system. We performed controlled
experiments with varying amounts of speech and text training data. When only a
tenth of the original data is available, intent classification accuracy
degrades by 7.6% absolute. Assuming we have additional text-to-intent data
(without speech) available, we investigated two techniques to improve the S2I
system: (1) transfer learning, in which acoustic embeddings for intent
classification are tied to fine-tuned BERT text embeddings; and (2) data
augmentation, in which the text-to-intent data is converted into
speech-to-intent data using a multi-speaker text-to-speech system. The proposed
approaches recover 80% of performance lost due to using limited intent-labeled
speech.
</p>
<a href="http://arxiv.org/abs/2010.04284" target="_blank">arXiv:2010.04284</a> [<a href="http://arxiv.org/pdf/2010.04284" target="_blank">pdf</a>]

<h2>Deep Learning Meets Projective Clustering. (arXiv:2010.04290v1 [cs.LG])</h2>
<h3>Alaa Maalouf, Harry Lang, Daniela Rus, Dan Feldman</h3>
<p>A common approach for compressing NLP networks is to encode the embedding
layer as a matrix $A\in\mathbb{R}^{n\times d}$, compute its rank-$j$
approximation $A_j$ via SVD, and then factor $A_j$ into a pair of matrices that
correspond to smaller fully-connected layers to replace the original embedding
layer. Geometrically, the rows of $A$ represent points in $\mathbb{R}^d$, and
the rows of $A_j$ represent their projections onto the $j$-dimensional subspace
that minimizes the sum of squared distances ("errors") to the points. In
practice, these rows of $A$ may be spread around $k&gt;1$ subspaces, so factoring
$A$ based on a single subspace may lead to large errors that turn into large
drops in accuracy.

Inspired by \emph{projective clustering} from computational geometry, we
suggest replacing this subspace by a set of $k$ subspaces, each of dimension
$j$, that minimizes the sum of squared distances over every point (row in $A$)
to its \emph{closest} subspace. Based on this approach, we provide a novel
architecture that replaces the original embedding layer by a set of $k$ small
layers that operate in parallel and are then recombined with a single
fully-connected layer.

Extensive experimental results on the GLUE benchmark yield networks that are
both more accurate and smaller compared to the standard matrix factorization
(SVD). For example, we further compress DistilBERT by reducing the size of the
embedding layer by $40\%$ while incurring only a $0.5\%$ average drop in
accuracy over all nine GLUE tasks, compared to a $2.8\%$ drop using the
existing SVD approach. On RoBERTa we achieve $43\%$ compression of the
embedding layer with less than a $0.8\%$ average drop in accuracy as compared
to a $3\%$ drop previously. Open code for reproducing and extending our results
is provided.
</p>
<a href="http://arxiv.org/abs/2010.04290" target="_blank">arXiv:2010.04290</a> [<a href="http://arxiv.org/pdf/2010.04290" target="_blank">pdf</a>]

<h2>comp-syn: Perceptually Grounded Word Embeddings with Color. (arXiv:2010.04292v1 [cs.CL])</h2>
<h3>Bhargav Srinivasa Desikan, Tasker Hull, Ethan O. Nadler, Douglas Guilbeault, Aabir Abubaker Kar, Mark Chu, Donald Ruggiero Lo Sardo</h3>
<p>Popular approaches to natural language processing create word embeddings
based on textual co-occurrence patterns, but often ignore embodied, sensory
aspects of language. Here, we introduce the Python package comp-syn, which
provides grounded word embeddings based on the perceptually uniform color
distributions of Google Image search results. We demonstrate that comp-syn
significantly enriches models of distributional semantics. In particular, we
show that (1) comp-syn predicts human judgments of word concreteness with
greater accuracy and in a more interpretable fashion than word2vec using
low-dimensional word-color embeddings, and (2) comp-syn performs comparably to
word2vec on a metaphorical vs. literal word-pair classification task. comp-syn
is open-source on PyPi and is compatible with mainstream machine-learning
Python packages. Our package release includes word-color embeddings for over
40,000 English words, each associated with crowd-sourced word concreteness
judgments.
</p>
<a href="http://arxiv.org/abs/2010.04292" target="_blank">arXiv:2010.04292</a> [<a href="http://arxiv.org/pdf/2010.04292" target="_blank">pdf</a>]

<h2>Widget Captioning: Generating Natural Language Description for Mobile User Interface Elements. (arXiv:2010.04295v1 [cs.LG])</h2>
<h3>Yang Li, Gang Li, Luheng He, Jingjie Zheng, Hong Li, Zhiwei Guan</h3>
<p>Natural language descriptions of user interface (UI) elements such as
alternative text are crucial for accessibility and language-based interaction
in general. Yet, these descriptions are constantly missing in mobile UIs. We
propose widget captioning, a novel task for automatically generating language
descriptions for UI elements from multimodal input including both the image and
the structural representations of user interfaces. We collected a large-scale
dataset for widget captioning with crowdsourcing. Our dataset contains 162,859
language phrases created by human workers for annotating 61,285 UI elements
across 21,750 unique UI screens. We thoroughly analyze the dataset, and train
and evaluate a set of deep model configurations to investigate how each feature
modality as well as the choice of learning strategies impact the quality of
predicted captions. The task formulation and the dataset as well as our
benchmark models contribute a solid basis for this novel multimodal captioning
task that connects language and user interfaces.
</p>
<a href="http://arxiv.org/abs/2010.04295" target="_blank">arXiv:2010.04295</a> [<a href="http://arxiv.org/pdf/2010.04295" target="_blank">pdf</a>]

<h2>CausalWorld: A Robotic Manipulation Benchmark for Causal Structure and Transfer Learning. (arXiv:2010.04296v1 [cs.RO])</h2>
<h3>Ossama Ahmed, Frederik Tr&#xe4;uble, Anirudh Goyal, Alexander Neitz, Manuel W&#xfc;thrich, Yoshua Bengio, Bernhard Sch&#xf6;lkopf, Stefan Bauer</h3>
<p>Despite recent successes of reinforcement learning (RL), it remains a
challenge for agents to transfer learned skills to related environments. To
facilitate research addressing this problem, we propose CausalWorld, a
benchmark for causal structure and transfer learning in a robotic manipulation
environment. The environment is a simulation of an open-source robotic
platform, hence offering the possibility of sim-to-real transfer. Tasks consist
of constructing 3D shapes from a given set of blocks - inspired by how children
learn to build complex structures. The key strength of CausalWorld is that it
provides a combinatorial family of such tasks with common causal structure and
underlying factors (including, e.g., robot and object masses, colors, sizes).
The user (or the agent) may intervene on all causal variables, which allows for
fine-grained control over how similar different tasks (or task distributions)
are. One can thus easily define training and evaluation distributions of a
desired difficulty level, targeting a specific form of generalization (e.g.,
only changes in appearance or object mass). Further, this common
parametrization facilitates defining curricula by interpolating between an
initial and a target task. While users may define their own task distributions,
we present eight meaningful distributions as concrete benchmarks, ranging from
simple to very challenging, all of which require long-horizon planning as well
as precise low-level motor control. Finally, we provide baseline results for a
subset of these tasks on distinct training curricula and corresponding
evaluation protocols, verifying the feasibility of the tasks in this benchmark.
</p>
<a href="http://arxiv.org/abs/2010.04296" target="_blank">arXiv:2010.04296</a> [<a href="http://arxiv.org/pdf/2010.04296" target="_blank">pdf</a>]

<h2>Learning to Evaluate Translation Beyond English: BLEURT Submissions to the WMT Metrics 2020 Shared Task. (arXiv:2010.04297v1 [cs.CL])</h2>
<h3>Thibault Sellam, Amy Pu, Hyung Won Chung, Sebastian Gehrmann, Qijun Tan, Markus Freitag, Dipanjan Das, Ankur P. Parikh</h3>
<p>The quality of machine translation systems has dramatically improved over the
last decade, and as a result, evaluation has become an increasingly challenging
problem. This paper describes our contribution to the WMT 2020 Metrics Shared
Task, the main benchmark for automatic evaluation of translation. Our
submission is based on BLEURT, a previously published metric based on transfer
learning. We extend the metric beyond English and evaluate it on 12 languages
for which training examples are available, as well as four "zero-shot"
languages, for which we have no fine-tuning data. Additionally, we focus on
English to German and demonstrate how to combine BLEURT's predictions with
those of YiSi and use alternative reference translations to enhance the
performance. Empirical results show that BLEURT achieves competitive results on
the WMT Metrics 2019 Shared Task, indicating its promise for the 2020 edition.
</p>
<a href="http://arxiv.org/abs/2010.04297" target="_blank">arXiv:2010.04297</a> [<a href="http://arxiv.org/pdf/2010.04297" target="_blank">pdf</a>]

<h2>How Can Self-Attention Networks Recognize Dyck-n Languages?. (arXiv:2010.04303v1 [cs.CL])</h2>
<h3>Javid Ebrahimi, Dhruv Gelda, Wei Zhang</h3>
<p>We focus on the recognition of Dyck-n ($\mathcal{D}_n$) languages with
self-attention (SA) networks, which has been deemed to be a difficult task for
these networks. We compare the performance of two variants of SA, one with a
starting symbol (SA$^+$) and one without (SA$^-$). Our results show that SA$^+$
is able to generalize to longer sequences and deeper dependencies. For
$\mathcal{D}_2$, we find that SA$^-$ completely breaks down on long sequences
whereas the accuracy of SA$^+$ is 58.82$\%$. We find attention maps learned by
$\text{SA}{^+}$ to be amenable to interpretation and compatible with a
stack-based language recognizer. Surprisingly, the performance of SA networks
is at par with LSTMs, which provides evidence on the ability of SA to learn
hierarchies without recursion.
</p>
<a href="http://arxiv.org/abs/2010.04303" target="_blank">arXiv:2010.04303</a> [<a href="http://arxiv.org/pdf/2010.04303" target="_blank">pdf</a>]

<h2>Learning to Locomote: Understanding How Environment Design Matters for Deep Reinforcement Learning. (arXiv:2010.04304v1 [cs.LG])</h2>
<h3>Daniele Reda, Tianxin Tao, Michiel van de Panne</h3>
<p>Learning to locomote is one of the most common tasks in physics-based
animation and deep reinforcement learning (RL). A learned policy is the product
of the problem to be solved, as embodied by the RL environment, and the RL
algorithm. While enormous attention has been devoted to RL algorithms, much
less is known about the impact of design choices for the RL environment. In
this paper, we show that environment design matters in significant ways and
document how it can contribute to the brittle nature of many RL results.
Specifically, we examine choices related to state representations, initial
state distributions, reward structure, control frequency, episode termination
procedures, curriculum usage, the action space, and the torque limits. We aim
to stimulate discussion around such choices, which in practice strongly impact
the success of RL when applied to continuous-action control problems of
interest to animation, such as learning to locomote.
</p>
<a href="http://arxiv.org/abs/2010.04304" target="_blank">arXiv:2010.04304</a> [<a href="http://arxiv.org/pdf/2010.04304" target="_blank">pdf</a>]

<h2>Neural Networks as Functional Classifiers. (arXiv:2010.04305v1 [stat.ML])</h2>
<h3>Barinder Thind, Kevin Multani, Jiguo Cao</h3>
<p>In recent years, there has been considerable innovation in the world of
predictive methodologies. This is evident by the relative domination of machine
learning approaches in various classification competitions. While these
algorithms have excelled at multivariate problems, they have remained dormant
in the realm of functional data analysis. We extend notable deep learning
methodologies to the domain of functional data for the purpose of
classification problems. We highlight the effectiveness of our method in a
number of classification applications such as classification of spectrographic
data. Moreover, we demonstrate the performance of our classifier through
simulation studies in which we compare our approach to the functional linear
model and other conventional classification methods.
</p>
<a href="http://arxiv.org/abs/2010.04305" target="_blank">arXiv:2010.04305</a> [<a href="http://arxiv.org/pdf/2010.04305" target="_blank">pdf</a>]

<h2>Addressing the Real-world Class Imbalance Problem in Dermatology. (arXiv:2010.04308v1 [cs.CV])</h2>
<h3>Wei-Hung Weng, Jonathan Deaton, Vivek Natarajan, Gamaleldin F. Elsayed, Yuan Liu</h3>
<p>Class imbalance is a common problem in medical diagnosis, causing a standard
classifier to be biased towards the common classes and perform poorly on the
rare classes. This is especially true for dermatology, a specialty with
thousands of skin conditions but many of which have rare prevalence in the real
world. Motivated by recent advances, we explore few-shot learning methods as
well as conventional class imbalance techniques for the skin condition
recognition problem and propose an evaluation setup to fairly assess the
real-world utility of such approaches. When compared to conventional class
imbalance techniques, we find that few-shot learning methods are not as
performant as those conventional methods, but combining the two approaches
using a novel ensemble leads to improvement in model performance, especially
for rare classes. We conclude that the ensemble can be useful to address the
class imbalance problem, yet progress here can further be accelerated by the
use of real-world evaluation setups for benchmarking new methods.
</p>
<a href="http://arxiv.org/abs/2010.04308" target="_blank">arXiv:2010.04308</a> [<a href="http://arxiv.org/pdf/2010.04308" target="_blank">pdf</a>]

<h2>Dynamic Context Selection for Document-level Neural Machine Translation via Reinforcement Learning. (arXiv:2010.04314v1 [cs.CL])</h2>
<h3>Xiaomian Kang, Yang Zhao, Jiajun Zhang, Chengqing Zong</h3>
<p>Document-level neural machine translation has yielded attractive
improvements. However, majority of existing methods roughly use all context
sentences in a fixed scope. They neglect the fact that different source
sentences need different sizes of context. To address this problem, we propose
an effective approach to select dynamic context so that the document-level
translation model can utilize the more useful selected context sentences to
produce better translations. Specifically, we introduce a selection module that
is independent of the translation module to score each candidate context
sentence. Then, we propose two strategies to explicitly select a variable
number of context sentences and feed them into the translation module. We train
the two modules end-to-end via reinforcement learning. A novel reward is
proposed to encourage the selection and utilization of dynamic context
sentences. Experiments demonstrate that our approach can select adaptive
context sentences for different source sentences, and significantly improves
the performance of document-level translation methods.
</p>
<a href="http://arxiv.org/abs/2010.04314" target="_blank">arXiv:2010.04314</a> [<a href="http://arxiv.org/pdf/2010.04314" target="_blank">pdf</a>]

<h2>Sparse Spectrum Warped Input Measures for Nonstationary Kernel Learning. (arXiv:2010.04315v1 [cs.LG])</h2>
<h3>Anthony Tompkins, Rafael Oliveira, Fabio Ramos</h3>
<p>We establish a general form of explicit, input-dependent, measure-valued
warpings for learning nonstationary kernels. While stationary kernels are
ubiquitous and simple to use, they struggle to adapt to functions that vary in
smoothness with respect to the input. The proposed learning algorithm warps
inputs as conditional Gaussian measures that control the smoothness of a
standard stationary kernel. This construction allows us to capture
non-stationary patterns in the data and provides intuitive inductive bias. The
resulting method is based on sparse spectrum Gaussian processes, enabling
closed-form solutions, and is extensible to a stacked construction to capture
more complex patterns. The method is extensively validated alongside related
algorithms on synthetic and real world datasets. We demonstrate a remarkable
efficiency in the number of parameters of the warping functions in learning
problems with both small and large data regimes.
</p>
<a href="http://arxiv.org/abs/2010.04315" target="_blank">arXiv:2010.04315</a> [<a href="http://arxiv.org/pdf/2010.04315" target="_blank">pdf</a>]

<h2>Deep-Masking Generative Network: A Unified Framework for Background Restoration from Superimposed Images. (arXiv:2010.04324v1 [cs.CV])</h2>
<h3>Xin Feng, Wenjie Pei, Zihui Jia, David Zhang, Guangming Lu</h3>
<p>Restoring the clean background from the superimposed images containing a
noisy layer is the common crux of a classical category of tasks on image
restoration such as image reflection removal, image deraining and image
dehazing. These tasks are typically formulated and tackled individually due to
the diverse and complicated appearance patterns of noise layers within the
image. In this work we present the Deep-Masking Generative Network (DMGN),
which is a unified framework for background restoration from the superimposed
images and is able to cope with different types of noise. Our proposed DMGN
follows a coarse-to-fine generative process: a coarse background image and a
noise image are first generated in parallel, then the noise image is further
leveraged to refine the background image to achieve a higher-quality background
image. In particular, we design the novel Residual Deep-Masking Cell as the
core operating unit for our DMGN to enhance the effective information and
suppress the negative information during image generation via learning a gating
mask to control the information flow. By iteratively employing this Residual
Deep-Masking Cell, our proposed DMGN is able to generate both high-quality
background image and noisy image progressively. Furthermore, we propose a
two-pronged strategy to effectively leverage the generated noise image as
contrasting cues to facilitate the refinement of the background image.
Extensive experiments across three typical tasks for image background
restoration, including image reflection removal, image rain steak removal and
image dehazing, show that our DMGN consistently outperforms state-of-the-art
methods specifically designed for each single task.
</p>
<a href="http://arxiv.org/abs/2010.04324" target="_blank">arXiv:2010.04324</a> [<a href="http://arxiv.org/pdf/2010.04324" target="_blank">pdf</a>]

<h2>Handling Imbalanced Data: A Case Study for Binary Class Problems. (arXiv:2010.04326v1 [stat.ML])</h2>
<h3>Richmond Addo Danquah</h3>
<p>For several years till date, the major issues in terms of solving for
classification problems are the issues of Imbalanced data. Because majority of
the machine learning algorithms by default assumes all data are balanced, the
algorithms do not take into consideration the distribution of the data sample
class. The results tend to be unsatisfactory and skewed towards the majority
sample class distribution. This implies that the consequences as a result of
using a model built using an Imbalanced data without handling for the Imbalance
in the data could be misleading both in practice and theory. Most researchers
have focused on the application of Synthetic Minority Oversampling Technique
(SMOTE) and Adaptive Synthetic (ADASYN) Sampling Approach in handling data
Imbalance independently in their works and have failed to better explain the
algorithms behind these techniques with computed examples. This paper focuses
on both synthetic oversampling techniques and manually computes synthetic data
points to enhance easy comprehension of the algorithms. We analyze the
application of these synthetic oversampling techniques on binary classification
problems with different Imbalanced ratios and sample sizes.
</p>
<a href="http://arxiv.org/abs/2010.04326" target="_blank">arXiv:2010.04326</a> [<a href="http://arxiv.org/pdf/2010.04326" target="_blank">pdf</a>]

<h2>HydroDeep -- A Knowledge Guided Deep Neural Network for Geo-Spatiotemporal Data Analysis. (arXiv:2010.04328v1 [cs.LG])</h2>
<h3>Aishwarya Sarkar, Jien Zhang, Chaoqun Lu, Ali Jannesari</h3>
<p>Floods are one of the major climate-related disasters, leading to substantial
economic loss and social safety issue. However, the confidence in predicting
changes in fluvial floods remains low due to limited evidence and complex
causes of regional climate change. The recent development in machine learning
techniques has the potential to improve traditional hydrological models by
using monitoring data. Although Recurrent Neural Networks (RNN) perform
remarkably with multivariate time series data, these models are blinded to the
underlying mechanisms represented in a process-based model for flood
prediction. While both process-based models and deep learning networks have
their strength, understanding the fundamental mechanisms intrinsic to
geo-spatiotemporal information is crucial to improve the prediction accuracy of
flood occurrence. This paper demonstrates a neural network architecture
(HydroDeep) that couples a process-based hydro-ecological model with a
combination of Deep Convolutional Neural Network (CNN) and Long Short-Term
Memory (LSTM) Network to build a hybrid baseline model. HydroDeep outperforms
the performance of both the independent networks by 4.8% and 31.8% respectively
in Nash-Sutcliffe efficiency. A trained HydroDeep can transfer its knowledge
and can learn the Geo-spatiotemporal features of any new region in minimal
training iterations.
</p>
<a href="http://arxiv.org/abs/2010.04328" target="_blank">arXiv:2010.04328</a> [<a href="http://arxiv.org/pdf/2010.04328" target="_blank">pdf</a>]

<h2>Targeted Attention Attack on Deep Learning Models in Road Sign Recognition. (arXiv:2010.04331v1 [cs.CV])</h2>
<h3>Xinghao Yang, Weifeng Liu, Shengli Zhang, Wei Liu, Dacheng Tao</h3>
<p>Real world traffic sign recognition is an important step towards building
autonomous vehicles, most of which highly dependent on Deep Neural Networks
(DNNs). Recent studies demonstrated that DNNs are surprisingly susceptible to
adversarial examples. Many attack methods have been proposed to understand and
generate adversarial examples, such as gradient based attack, score based
attack, decision based attack, and transfer based attacks. However, most of
these algorithms are ineffective in real-world road sign attack, because (1)
iteratively learning perturbations for each frame is not realistic for a fast
moving car and (2) most optimization algorithms traverse all pixels equally
without considering their diverse contribution. To alleviate these problems,
this paper proposes the targeted attention attack (TAA) method for real world
road sign attack. Specifically, we have made the following contributions: (1)
we leverage the soft attention map to highlight those important pixels and skip
those zero-contributed areas - this also helps to generate natural
perturbations, (2) we design an efficient universal attack that optimizes a
single perturbation/noise based on a set of training images under the guidance
of the pre-trained attention map, (3) we design a simple objective function
that can be easily optimized, (4) we evaluate the effectiveness of TAA on real
world data sets. Experimental results validate that the TAA method improves the
attack successful rate (nearly 10%) and reduces the perturbation loss (about a
quarter) compared with the popular RP2 method. Additionally, our TAA also
provides good properties, e.g., transferability and generalization capability.
We provide code and data to ensure the reproducibility:
https://github.com/AdvAttack/RoadSignAttack.
</p>
<a href="http://arxiv.org/abs/2010.04331" target="_blank">arXiv:2010.04331</a> [<a href="http://arxiv.org/pdf/2010.04331" target="_blank">pdf</a>]

<h2>Langsmith: An Interactive Academic Text Revision System. (arXiv:2010.04332v1 [cs.CL])</h2>
<h3>Takumi Ito, Tatsuki Kuribayashi, Masatoshi Hidaka, Jun Suzuki, Kentaro Inui</h3>
<p>Despite the current diversity and inclusion initiatives in the academic
community, researchers with a non-native command of English still face
significant obstacles when writing papers in English. This paper presents the
Langsmith editor, which assists inexperienced, non-native researchers to write
English papers, especially in the natural language processing (NLP) field. Our
system can suggest fluent, academic-style sentences to writers based on their
rough, incomplete phrases or sentences. The system also encourages interaction
between human writers and the computerized revision system. The experimental
results demonstrated that Langsmith helps non-native English-speaker students
write papers in English. The system is available at https://emnlp-demo.editor.
langsmith.co.jp/.
</p>
<a href="http://arxiv.org/abs/2010.04332" target="_blank">arXiv:2010.04332</a> [<a href="http://arxiv.org/pdf/2010.04332" target="_blank">pdf</a>]

<h2>An ensemble learning approach for software semantic clone detection. (arXiv:2010.04336v1 [cs.SE])</h2>
<h3>Min Fu, Gang Luo, Xi Zheng, Tianyi Zhang, Dongjin Yu, Miryung Kim</h3>
<p>Code clone is a serious problem in software and has the potential to software
defects, maintenance overhead, and licensing violations. Therefore, clone
detection is important for reducing maintenance effort and improving code
quality during software evolution. A variety of clone detection techniques have
been proposed to identify similar code in software. However, few of them can
efficiently detect semantic clones (functionally similar code without any
syntactic resemblance). Recently, several deep learning based clone detectors
are proposed to detect semantic clones. However, these approaches have high
cost in data labelling and model training. In this paper, we propose a novel
approach that leverages word embedding and ensemble learning techniques to
detect semantic clones. Our evaluation on a commonly used clone benchmark,
BigCloneBench, shows that our approach significantly improves the precision and
recall of semantic clone detection, in comparison to a token-based clone
detector, SourcererCC, and another deep learning based clone detector, CDLH.
</p>
<a href="http://arxiv.org/abs/2010.04336" target="_blank">arXiv:2010.04336</a> [<a href="http://arxiv.org/pdf/2010.04336" target="_blank">pdf</a>]

<h2>MMGSD: Multi-Modal Gaussian Shape Descriptors for Correspondence Matching in 1D and 2D Deformable Objects. (arXiv:2010.04339v1 [cs.CV])</h2>
<h3>Aditya Ganapathi, Priya Sundaresan, Brijen Thananjeyan, Ashwin Balakrishna, Daniel Seita, Ryan Hoque, Joseph E. Gonzalez, Ken Goldberg</h3>
<p>We explore learning pixelwise correspondences between images of deformable
objects in different configurations. Traditional correspondence matching
approaches such as SIFT, SURF, and ORB can fail to provide sufficient
contextual information for fine-grained manipulation. We propose Multi-Modal
Gaussian Shape Descriptor (MMGSD), a new visual representation of deformable
objects which extends ideas from dense object descriptors to predict all
symmetric correspondences between different object configurations. MMGSD is
learned in a self-supervised manner from synthetic data and produces
correspondence heatmaps with measurable uncertainty. In simulation, experiments
suggest that MMGSD can achieve an RMSE of 32.4 and 31.3 for square cloth and
braided synthetic nylon rope respectively. The results demonstrate an average
of 47.7% improvement over a provided baseline based on contrastive learning,
symmetric pixel-wise contrastive loss (SPCL), as opposed to MMGSD which
enforces distributional continuity.
</p>
<a href="http://arxiv.org/abs/2010.04339" target="_blank">arXiv:2010.04339</a> [<a href="http://arxiv.org/pdf/2010.04339" target="_blank">pdf</a>]

<h2>Genetic-algorithm-optimized neural networks for gravitational wave classification. (arXiv:2010.04340v1 [gr-qc])</h2>
<h3>Dwyer S. Deighan, Scott E. Field, Collin D. Capano, Gaurav Khanna</h3>
<p>Gravitational-wave detection strategies are based on a signal analysis
technique known as matched filtering. Matched filtering is known to be optimal
under certain conditions, yet in practice, these conditions are only
approximately satisfied while the algorithm is computationally expensive.
Despite the success of matched filtering for signal detection, due to these
limitations, there has been recent interest in developing deep convolutional
neural networks (CNNs) for signal detection. Designing these networks remains a
challenge as most procedures adopt a trial and error strategy to set the
hyperparameter values. We propose and develop a new method for hyperparameter
optimization based on genetic algorithms (GAs). We compare six different GA
variants and explore different choices for the GA-optimized fitness score. We
show that the GA can discover high-quality architectures when the initial
hyperparameter seed values are far from a good solution as well as refining
already good networks. For example, when starting from the architecture
proposed by George and Huerta, the network optimized over the 20-dimensional
hyperparameter space has 78% fewer trainable parameters while obtaining an 11%
increase in accuracy for our test problem. Using genetic algorithm optimization
to refine an existing network should be especially useful if the problem
context (e.g. statistical properties of the noise, signal model, etc) changes
and one needs to rebuild a network. In all of our experiments, we find the GA
discovers significantly less complicated networks as compared to the seed
network, suggesting it can be used to prune wasteful network structures. While
we have restricted our attention to CNN classifiers, GA hyperparameter
optimization can be applied within other machine learning settings, including
alternative architectures for signal classification, parameter inference, or
other tasks.
</p>
<a href="http://arxiv.org/abs/2010.04340" target="_blank">arXiv:2010.04340</a> [<a href="http://arxiv.org/pdf/2010.04340" target="_blank">pdf</a>]

<h2>Connection Pruning for Deep Spiking Neural Networks with On-Chip Learning. (arXiv:2010.04351v1 [cs.NE])</h2>
<h3>Thao N.N. Nguyen, Bharadwaj Veeravalli, Xuanyao Fong</h3>
<p>Long training time hinders the potential of the deep Spiking Neural Network
(SNN) with the online learning capability to be realized on the embedded
systems hardware. Our work proposes a novel connection pruning approach that
can be applied during the online Spike Timing Dependent Plasticity (STDP)-based
learning to optimize the learning time and the network connectivity of the SNN.
Our connection pruning approach was evaluated on a deep SNN with the Time To
First Spike (TTFS) coding and has successfully achieved 2.1x speed-up in the
online learning and reduced the network connectivity by 92.83%. The energy
consumption in the online learning was saved by 64%. Moreover, the connectivity
reduction results in 2.83x speed-up and 78.24% energy saved in the inference.
Meanwhile, the classification accuracy remains the same as our non-pruning
baseline on the Caltech 101 dataset. In addition, we developed an event-driven
hardware architecture on the Field Programmable Gate Array (FPGA) platform that
efficiently incorporates our proposed connection pruning approach while
incurring as little as 0.56% power overhead. Moreover, we performed a
comparison between our work and the existing works on connection pruning for
SNN to highlight the key features of each approach. To the best of our
knowledge, our work is the first to propose a connection pruning algorithm that
can be applied during the online STDP-based learning for a deep SNN with the
TTFS coding.
</p>
<a href="http://arxiv.org/abs/2010.04351" target="_blank">arXiv:2010.04351</a> [<a href="http://arxiv.org/pdf/2010.04351" target="_blank">pdf</a>]

<h2>Style Attuned Pre-training and Parameter Efficient Fine-tuning for Spoken Language Understanding. (arXiv:2010.04355v1 [cs.CL])</h2>
<h3>Jin Cao, Jun Wang, Wael Hamza, Kelly Vanee, Shang-Wen Li</h3>
<p>Neural models have yielded state-of-the-art results in deciphering spoken
language understanding (SLU) problems; however, these models require a
significant amount of domain-specific labeled examples for training, which is
prohibitively expensive. While pre-trained language models like BERT have been
shown to capture a massive amount of knowledge by learning from unlabeled
corpora and solve SLU using fewer labeled examples for adaption, the encoding
of knowledge is implicit and agnostic to downstream tasks. Such encoding
results in model inefficiencies in parameter usage: an entirely new model is
required for every domain. To address these challenges, we introduce a novel
SLU framework, comprising a conversational language modeling (CLM) pre-training
task and a light encoder architecture. The CLM pre-training enables networks to
capture the representation of the language in conversation style with the
presence of ASR errors. The light encoder architecture separates the shared
pre-trained networks from the mappings of generally encoded knowledge to
specific domains of SLU, allowing for the domain adaptation to be performed
solely at the light encoder and thus increasing efficiency. With the framework,
we match the performance of state-of-the-art SLU results on Alexa internal
datasets and on two public ones (ATIS, SNIPS), adding only 4.4% parameters per
task.
</p>
<a href="http://arxiv.org/abs/2010.04355" target="_blank">arXiv:2010.04355</a> [<a href="http://arxiv.org/pdf/2010.04355" target="_blank">pdf</a>]

<h2>Few-shot Learning for Spatial Regression. (arXiv:2010.04360v1 [stat.ML])</h2>
<h3>Tomoharu Iwata, Yusuke Tanaka</h3>
<p>We propose a few-shot learning method for spatial regression. Although
Gaussian processes (GPs) have been successfully used for spatial regression,
they require many observations in the target task to achieve a high predictive
performance. Our model is trained using spatial datasets on various attributes
in various regions, and predicts values on unseen attributes in unseen regions
given a few observed data. With our model, a task representation is inferred
from given small data using a neural network. Then, spatial values are
predicted by neural networks with a GP framework, in which task-specific
properties are controlled by the task representations. The GP framework allows
us to analytically obtain predictions that are adapted to small data. By using
the adapted predictions in the objective function, we can train our model
efficiently and effectively so that the test predictive performance improves
when adapted to newly given small data. In our experiments, we demonstrate that
the proposed method achieves better predictive performance than existing
meta-learning methods using spatial datasets.
</p>
<a href="http://arxiv.org/abs/2010.04360" target="_blank">arXiv:2010.04360</a> [<a href="http://arxiv.org/pdf/2010.04360" target="_blank">pdf</a>]

<h2>Constrained Decoding for Computationally Efficient Named Entity Recognition Taggers. (arXiv:2010.04362v1 [cs.CL])</h2>
<h3>Brian Lester, Daniel Pressel, Amy Hemmeter, Sagnik Ray Choudhury, Srinivas Bangalore</h3>
<p>Current state-of-the-art models for named entity recognition (NER) are neural
models with a conditional random field (CRF) as the final layer. Entities are
represented as per-token labels with a special structure in order to decode
them into spans. Current work eschews prior knowledge of how the span encoding
scheme works and relies on the CRF learning which transitions are illegal and
which are not to facilitate global coherence. We find that by constraining the
output to suppress illegal transitions we can train a tagger with a
cross-entropy loss twice as fast as a CRF with differences in F1 that are
statistically insignificant, effectively eliminating the need for a CRF. We
analyze the dynamics of tag co-occurrence to explain when these constraints are
most effective and provide open source implementations of our tagger in both
PyTorch and TensorFlow.
</p>
<a href="http://arxiv.org/abs/2010.04362" target="_blank">arXiv:2010.04362</a> [<a href="http://arxiv.org/pdf/2010.04362" target="_blank">pdf</a>]

<h2>Deep Learning Superpixel Semantic Segmentation with Transparent Initialization and Sparse Encoder. (arXiv:2010.04363v1 [cs.CV])</h2>
<h3>Zhiwei Xu, Thalaiyasingam Ajanthan, Richard Hartley</h3>
<p>Even though deep learning greatly improves the performance of semantic
segmentation, its success mainly lies on object central areas but without
accurate edges. As superpixel is a popular and effective auxiliary to preserve
object edges, in this paper, we jointly learn semantic segmentation with
trainable superpixels. We achieve it by adding fully-connected layers with
transparent initialization and an efficient logit uniformization with a sparse
encoder. Specifically, the proposed transparent initialization reserves the
effects of learned parameters from pretrained networks, one for semantic
segmentation and the other for superpixel, by a linear data recovery. This
avoids a significant loss increase by using the pretrained networks, which
otherwise can be caused by an inappropriate parameter initialization on the
added layers. Meanwhile, consistent assignments to all pixels in each
superpixel can be guaranteed by the logit uniformization with a sparse encoder.
This sparse encoder with sparse matrix operations substantially improves the
training efficiency by reducing the large computational complexity arising from
indexing pixels by superpixels. We demonstrate the effectiveness of our
proposal by transparent initialization and sparse encoder on semantic
segmentation on PASCAL VOC 2012 dataset with enhanced labeling on the object
edges. Moreover, the proposed transparent initialization can also be used to
jointly finetune multiple or a deeper pretrained network on other tasks.
</p>
<a href="http://arxiv.org/abs/2010.04363" target="_blank">arXiv:2010.04363</a> [<a href="http://arxiv.org/pdf/2010.04363" target="_blank">pdf</a>]

<h2>DeepStreet: A deep learning powered urban street network generation module. (arXiv:2010.04365v1 [cs.CV])</h2>
<h3>Zhou Fang, Tianren Yang, Ying Jin</h3>
<p>In countries experiencing unprecedented waves of urbanization, there is a
need for rapid and high quality urban street design. Our study presents a novel
deep learning powered approach, DeepStreet (DS), for automatic street network
generation that can be applied to the urban street design with local
characteristics. DS is driven by a Convolutional Neural Network (CNN) that
enables the interpolation of streets based on the areas of immediate vicinity.
Specifically, the CNN is firstly trained to detect, recognize and capture the
local features as well as the patterns of the existing street network sourced
from the OpenStreetMap. With the trained CNN, DS is able to predict street
networks' future expansion patterns within the predefined region conditioned on
its surrounding street networks. To test the performance of DS, we apply it to
an area in and around the Eixample area in the City of Barcelona, a well known
example in the fields of urban and transport planning with iconic grid like
street networks in the centre and irregular road alignments farther afield. The
results show that DS can (1) detect and self cluster different types of complex
street patterns in Barcelona; (2) predict both gridiron and irregular street
and road networks. DS proves to have a great potential as a novel tool for
designers to efficiently design the urban street network that well maintains
the consistency across the existing and newly generated urban street network.
Furthermore, the generated networks can serve as a benchmark to guide the local
plan-making especially in rapidly developing cities.
</p>
<a href="http://arxiv.org/abs/2010.04365" target="_blank">arXiv:2010.04365</a> [<a href="http://arxiv.org/pdf/2010.04365" target="_blank">pdf</a>]

<h2>GitEvolve: Predicting the Evolution of GitHub Repositories. (arXiv:2010.04366v1 [cs.SI])</h2>
<h3>Honglu Zhou, Hareesh Ravi, Carlos M. Muniz, Vahid Azizi, Linda Ness, Gerard de Melo, Mubbasir Kapadia</h3>
<p>Software development is becoming increasingly open and collaborative with the
advent of platforms such as GitHub. Given its crucial role, there is a need to
better understand and model the dynamics of GitHub as a social platform.
Previous work has mostly considered the dynamics of traditional social
networking sites like Twitter and Facebook. We propose GitEvolve, a system to
predict the evolution of GitHub repositories and the different ways by which
users interact with them. To this end, we develop an end-to-end multi-task
sequential deep neural network that given some seed events, simultaneously
predicts which user-group is next going to interact with a given repository,
what the type of the interaction is, and when it happens. To facilitate
learning, we use graph based representation learning to encode relationship
between repositories. We map users to groups by modelling common interests to
better predict popularity and to generalize to unseen users during inference.
We introduce an artificial event type to better model varying levels of
activity of repositories in the dataset. The proposed multi-task architecture
is generic and can be extended to model information diffusion in other social
networks. In a series of experiments, we demonstrate the effectiveness of the
proposed model, using multiple metrics and baselines. Qualitative analysis of
the model's ability to predict popularity and forecast trends proves its
applicability.
</p>
<a href="http://arxiv.org/abs/2010.04366" target="_blank">arXiv:2010.04366</a> [<a href="http://arxiv.org/pdf/2010.04366" target="_blank">pdf</a>]

<h2>Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic. (arXiv:2010.04368v1 [cs.CV])</h2>
<h3>Sadegh Aliakbarian</h3>
<p>Video anticipation is the task of predicting one/multiple future
representation(s) given limited, partial observation. This is a challenging
task due to the fact that given limited observation, the future representation
can be highly ambiguous. Based on the nature of the task, video anticipation
can be considered from two viewpoints: the level of details and the level of
determinism in the predicted future. In this research, we start from
anticipating a coarse representation of a deterministic future and then move
towards predicting continuous and fine-grained future representations of a
stochastic process. The example of the former is video action anticipation in
which we are interested in predicting one action label given a partially
observed video and the example of the latter is forecasting multiple diverse
continuations of human motion given partially observed one. In particular, in
this thesis, we make several contributions to the literature of video
anticipation...
</p>
<a href="http://arxiv.org/abs/2010.04368" target="_blank">arXiv:2010.04368</a> [<a href="http://arxiv.org/pdf/2010.04368" target="_blank">pdf</a>]

<h2>Pragmatically Informative Color Generation by Grounding Contextual Modifiers. (arXiv:2010.04372v1 [cs.CL])</h2>
<h3>Zhengxuan Wu, Desmond C. Ong</h3>
<p>Grounding language in contextual information is crucial for fine-grained
natural language understanding. One important task that involves grounding
contextual modifiers is color generation. Given a reference color "green", and
a modifier "bluey", how does one generate a color that could represent "bluey
green"? We propose a computational pragmatics model that formulates this color
generation task as a recursive game between speakers and listeners. In our
model, a pragmatic speaker reasons about the inferences that a listener would
make, and thus generates a modified color that is maximally informative to help
the listener recover the original referents. In this paper, we show that
incorporating pragmatic information provides significant improvements in
performance compared with other state-of-the-art deep learning models where
pragmatic inference and flexibility in representing colors from a large
continuous space are lacking. Our model has an absolute 98% increase in
performance for the test cases where the reference colors are unseen during
training, and an absolute 40% increase in performance for the test cases where
both the reference colors and the modifiers are unseen during training.
</p>
<a href="http://arxiv.org/abs/2010.04372" target="_blank">arXiv:2010.04372</a> [<a href="http://arxiv.org/pdf/2010.04372" target="_blank">pdf</a>]

<h2>Q-learning with Language Model for Edit-based Unsupervised Summarization. (arXiv:2010.04379v1 [cs.CL])</h2>
<h3>Ryosuke Kohita, Akifumi Wachi, Yang Zhao, Ryuki Tachibana</h3>
<p>Unsupervised methods are promising for abstractive text summarization in that
the parallel corpora is not required. However, their performance is still far
from being satisfied, therefore research on promising solutions is on-going. In
this paper, we propose a new approach based on Q-learning with an edit-based
summarization. The method combines two key modules to form an Editorial Agent
and Language Model converter (EALM). The agent predicts edit actions (e.t.,
delete, keep, and replace), and then the LM converter deterministically
generates a summary on the basis of the action signals. Q-learning is leveraged
to train the agent to produce proper edit actions. Experimental results show
that EALM delivered competitive performance compared with the previous
encoder-decoder-based methods, even with truly zero paired data (i.e., no
validation set). Defining the task as Q-learning enables us not only to develop
a competitive method but also to make the latest techniques in reinforcement
learning available for unsupervised summarization. We also conduct qualitative
analysis, providing insights into future study on unsupervised summarizers.
</p>
<a href="http://arxiv.org/abs/2010.04379" target="_blank">arXiv:2010.04379</a> [<a href="http://arxiv.org/pdf/2010.04379" target="_blank">pdf</a>]

<h2>Token-level Adaptive Training for Neural Machine Translation. (arXiv:2010.04380v1 [cs.CL])</h2>
<h3>Shuhao Gu, Jinchao Zhang, Fandong Meng, Yang Feng, Wanying Xie, Jie Zhou, Dong Yu</h3>
<p>There exists a token imbalance phenomenon in natural language as different
tokens appear with different frequencies, which leads to different learning
difficulties for tokens in Neural Machine Translation (NMT). The vanilla NMT
model usually adopts trivial equal-weighted objectives for target tokens with
different frequencies and tends to generate more high-frequency tokens and less
low-frequency tokens compared with the golden token distribution. However,
low-frequency tokens may carry critical semantic information that will affect
the translation quality once they are neglected. In this paper, we explored
target token-level adaptive objectives based on token frequencies to assign
appropriate weights for each target token during training. We aimed that those
meaningful but relatively low-frequency words could be assigned with larger
weights in objectives to encourage the model to pay more attention to these
tokens. Our method yields consistent improvements in translation quality on
ZH-EN, EN-RO, and EN-DE translation tasks, especially on sentences that contain
more low-frequency tokens where we can get 1.68, 1.02, and 0.52 BLEU increases
compared with baseline, respectively. Further analyses show that our method can
also improve the lexical diversity of translation.
</p>
<a href="http://arxiv.org/abs/2010.04380" target="_blank">arXiv:2010.04380</a> [<a href="http://arxiv.org/pdf/2010.04380" target="_blank">pdf</a>]

<h2>Weaponizing Unicodes with Deep Learning -- Identifying Homoglyphs with Weakly Labeled Data. (arXiv:2010.04382v1 [cs.CR])</h2>
<h3>Perry Deng, Cooper Linsky, Matthew Wright</h3>
<p>Visually similar characters, or homoglyphs, can be used to perform social
engineering attacks or to evade spam and plagiarism detectors. It is thus
important to understand the capabilities of an attacker to identify homoglyphs
-- particularly ones that have not been previously spotted -- and leverage them
in attacks. We investigate a deep-learning model using embedding learning,
transfer learning, and augmentation to determine the visual similarity of
characters and thereby identify potential homoglyphs. Our approach uniquely
takes advantage of weak labels that arise from the fact that most characters
are not homoglyphs. Our model drastically outperforms the Normalized
Compression Distance approach on pairwise homoglyph identification, for which
we achieve an average precision of 0.97. We also present the first attempt at
clustering homoglyphs into sets of equivalence classes, which is more efficient
than pairwise information for security practitioners to quickly lookup
homoglyphs or to normalize confusable string encodings. To measure clustering
performance, we propose a metric (mBIOU) building on the classic
Intersection-Over-Union (IOU) metric. Our clustering method achieves 0.592
mBIOU, compared to 0.430 for the naive baseline. We also use our model to
predict over 8,000 previously unknown homoglyphs, and find good early
indications that many of these may be true positives. Source code and list of
predicted homoglyphs are uploaded to Github:
https://github.com/PerryXDeng/weaponizing_unicode
</p>
<a href="http://arxiv.org/abs/2010.04382" target="_blank">arXiv:2010.04382</a> [<a href="http://arxiv.org/pdf/2010.04382" target="_blank">pdf</a>]

<h2>Lightweight, Dynamic Graph Convolutional Networks for AMR-to-Text Generation. (arXiv:2010.04383v1 [cs.CL])</h2>
<h3>Yan Zhang, Zhijiang Guo, Zhiyang Teng, Wei Lu, Shay B. Cohen, Zuozhu Liu, Lidong Bing</h3>
<p>AMR-to-text generation is used to transduce Abstract Meaning Representation
structures (AMR) into text. A key challenge in this task is to efficiently
learn effective graph representations. Previously, Graph Convolution Networks
(GCNs) were used to encode input AMRs, however, vanilla GCNs are not able to
capture non-local information and additionally, they follow a local
(first-order) information aggregation scheme. To account for these issues,
larger and deeper GCN models are required to capture more complex interactions.
In this paper, we introduce a dynamic fusion mechanism, proposing Lightweight
Dynamic Graph Convolutional Networks (LDGCNs) that capture richer non-local
interactions by synthesizing higher order information from the input graphs. We
further develop two novel parameter saving strategies based on the group graph
convolutions and weight tied convolutions to reduce memory usage and model
complexity. With the help of these strategies, we are able to train a model
with fewer parameters while maintaining the model capacity. Experiments
demonstrate that LDGCNs outperform state-of-the-art models on two benchmark
datasets for AMR-to-text generation with significantly fewer parameters.
</p>
<a href="http://arxiv.org/abs/2010.04383" target="_blank">arXiv:2010.04383</a> [<a href="http://arxiv.org/pdf/2010.04383" target="_blank">pdf</a>]

<h2>Learning 3D Face Reconstruction with a Pose Guidance Network. (arXiv:2010.04384v1 [cs.CV])</h2>
<h3>Pengpeng Liu, Xintong Han, Michael Lyu, Irwin King, Jia Xu</h3>
<p>We present a self-supervised learning approach to learning monocular 3D face
reconstruction with a pose guidance network (PGN). First, we unveil the
bottleneck of pose estimation in prior parametric 3D face learning methods, and
propose to utilize 3D face landmarks for estimating pose parameters. With our
specially designed PGN, our model can learn from both faces with fully labeled
3D landmarks and unlimited unlabeled in-the-wild face images. Our network is
further augmented with a self-supervised learning scheme, which exploits face
geometry information embedded in multiple frames of the same person, to
alleviate the ill-posed nature of regressing 3D face geometry from a single
image. These three insights yield a single approach that combines the
complementary strengths of parametric model learning and data-driven learning
techniques. We conduct a rigorous evaluation on the challenging AFLW2000-3D,
Florence and FaceWarehouse datasets, and show that our method outperforms the
state-of-the-art for all metrics.
</p>
<a href="http://arxiv.org/abs/2010.04384" target="_blank">arXiv:2010.04384</a> [<a href="http://arxiv.org/pdf/2010.04384" target="_blank">pdf</a>]

<h2>A Survey of Knowledge-Enhanced Text Generation. (arXiv:2010.04389v1 [cs.CL])</h2>
<h3>Wenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu, Qingyun Wang, Heng Ji, Meng Jiang</h3>
<p>The goal of text generation is to make machines express in human language. It
is one of the most important yet challenging tasks in natural language
processing (NLP). Since 2014, various neural encoder-decoder models pioneered
by Seq2Seq have been proposed to achieve the goal by learning to map input text
to output text. However, the input text alone often provides limited knowledge
to generate the desired output, so the performance of text generation is still
far from satisfaction in many real-world scenarios. To address this issue,
researchers have considered incorporating various forms of knowledge beyond the
input text into the generation models. This research direction is known as
knowledge-enhanced text generation. In this survey, we present a comprehensive
review of the research on knowledge enhanced text generation over the past five
years. The main content includes two parts: (i) general methods and
architectures for integrating knowledge into text generation; (ii) specific
techniques and applications according to different forms of knowledge data.
This survey can have broad audiences, researchers and practitioners, in
academia and industry.
</p>
<a href="http://arxiv.org/abs/2010.04389" target="_blank">arXiv:2010.04389</a> [<a href="http://arxiv.org/pdf/2010.04389" target="_blank">pdf</a>]

<h2>Generating Novel Glyph without Human Data by Learning to Communicate. (arXiv:2010.04402v1 [cs.CV])</h2>
<h3>Seung-won Park</h3>
<p>In this paper, we present Neural Glyph, a system that generates novel glyph
without any training data. The generator and the classifier are trained to
communicate via visual symbols as a medium, which enforces the generator to
come up with a set of distinctive symbols. Our method results in glyphs that
resemble the human-made glyphs, which may imply that the visual appearances of
existing glyphs can be attributed to constraints of communication via writing.
Important tricks that enable this framework is described and the code is made
available.
</p>
<a href="http://arxiv.org/abs/2010.04402" target="_blank">arXiv:2010.04402</a> [<a href="http://arxiv.org/pdf/2010.04402" target="_blank">pdf</a>]

<h2>A Survey of Non-Volatile Main Memory Technologies: State-of-the-Arts, Practices, and Future Directions. (arXiv:2010.04406v1 [cs.DC])</h2>
<h3>Haikun Liu, Di Chen, Hai Jin, Xiaofei Liao, Bingsheng He, Kan Hu, Yu Zhang</h3>
<p>Non-Volatile Main Memories (NVMMs) have recently emerged as promising
technologies for future memory systems. Generally, NVMMs have many desirable
properties such as high density, byte-addressability, non-volatility, low cost,
and energy efficiency, at the expense of high write latency, high write power
consumption and limited write endurance. NVMMs have become a competitive
alternative of Dynamic Random Access Memory (DRAM), and will fundamentally
change the landscape of memory systems. They bring many research opportunities
as well as challenges on system architectural designs, memory management in
operating systems (OSes), and programming models for hybrid memory systems. In
this article, we first revisit the landscape of emerging NVMM technologies, and
then survey the state-of-the-art studies of NVMM technologies. We classify
those studies with a taxonomy according to different dimensions such as memory
architectures, data persistence, performance improvement, energy saving, and
wear leveling. Second, to demonstrate the best practices in building NVMM
systems, we introduce our recent work of hybrid memory system designs from the
dimensions of architectures, systems, and applications. At last, we present our
vision of future research directions of NVMMs and shed some light on design
challenges and opportunities.
</p>
<a href="http://arxiv.org/abs/2010.04406" target="_blank">arXiv:2010.04406</a> [<a href="http://arxiv.org/pdf/2010.04406" target="_blank">pdf</a>]

<h2>Streaming Submodular Maximization with Fairness Constraints. (arXiv:2010.04412v1 [cs.DS])</h2>
<h3>Yanhao Wang, Francesco Fabbri, Michael Mathioudakis</h3>
<p>We study the problem of extracting a small subset of representative items
from a large data stream. Following the convention in many data mining and
machine learning applications such as data summarization, recommender systems,
and social network analysis, the problem is formulated as maximizing a monotone
submodular function subject to a cardinality constraint -- i.e., the size of
the selected subset is restricted to be smaller than or equal to an input
integer $k$. In this paper, we consider the problem with additional
\emph{fairness constraints}, which takes into account the group membership of
data items and limits the number of items selected from each group to a given
number. We propose efficient algorithms for this fairness-aware variant of the
streaming submodular maximization problem. In particular, we first provide a
$(\frac{1}{2}-\varepsilon)$-approximation algorithm that requires
$O(\frac{1}{\varepsilon} \cdot \log \frac{k}{\varepsilon})$ passes over the
stream for any constant $ \varepsilon&gt;0 $. In addition, we design a single-pass
streaming algorithm that has the same $(\frac{1}{2}-\varepsilon)$ approximation
ratio when unlimited buffer size and post-processing time is permitted.
</p>
<a href="http://arxiv.org/abs/2010.04412" target="_blank">arXiv:2010.04412</a> [<a href="http://arxiv.org/pdf/2010.04412" target="_blank">pdf</a>]

<h2>A deep learning based interactive sketching system for fashion images design. (arXiv:2010.04413v1 [cs.CV])</h2>
<h3>Yao Li, Xianggang Yu, Xiaoguang Han, Nianjuan Jiang, Kui Jia, Jiangbo Lu</h3>
<p>In this work, we propose an interactive system to design diverse high-quality
garment images from fashion sketches and the texture information. The major
challenge behind this system is to generate high-quality and detailed texture
according to the user-provided texture information. Prior works mainly use the
texture patch representation and try to map a small texture patch to a whole
garment image, hence unable to generate high-quality details. In contrast,
inspired by intrinsic image decomposition, we decompose this task into texture
synthesis and shading enhancement. In particular, we propose a novel bi-colored
edge texture representation to synthesize textured garment images and a shading
enhancer to render shading based on the grayscale edges. The bi-colored edge
representation provides simple but effective texture cues and color
constraints, so that the details can be better reconstructed. Moreover, with
the rendered shading, the synthesized garment image becomes more vivid.
</p>
<a href="http://arxiv.org/abs/2010.04413" target="_blank">arXiv:2010.04413</a> [<a href="http://arxiv.org/pdf/2010.04413" target="_blank">pdf</a>]

<h2>A Vertex Cut based Framework for Load Balancing and Parallelism Optimization in Multi-core Systems. (arXiv:2010.04414v1 [cs.DC])</h2>
<h3>Guixiang Ma, Yao Xiao, Theodore L. Willke, Nesreen K. Ahmed, Shahin Nazarian, Paul Bogdan</h3>
<p>High-level applications, such as machine learning, are evolving from simple
models based on multilayer perceptrons for simple image recognition to much
deeper and more complex neural networks for self-driving vehicle control
systems.The rapid increase in the consumption of memory and computational
resources by these models demands the use of multi-core parallel systems to
scale the execution of the complex emerging applications that depend on them.
However, parallel programs running on high-performance computers often suffer
from data communication bottlenecks, limited memory bandwidth, and
synchronization overhead due to irregular critical sections. In this paper, we
propose a framework to reduce the data communication and improve the
scalability and performance of these applications in multi-core systems. We
design a vertex cut framework for partitioning LLVM IR graphs into clusters
while taking into consideration the data communication and workload balance
among clusters. First, we construct LLVM graphs by compiling high-level
programs into LLVM IR, instrumenting code to obtain the execution order of
basic blocks and the execution time for each memory operation, and analyze data
dependencies in dynamic LLVM traces. Next, we formulate the problem as Weight
Balanced $p$-way Vertex Cut, and propose a generic and flexible framework,
wherein four different greedy algorithms are proposed for solving this problem.
Lastly, we propose a memory-centric run-time mapping of the linear time
complexity to map clusters generated from the vertex cut algorithms onto a
multi-core platform. We conclude that our best algorithm, WB-Libra, provides
performance improvements of 1.56x and 1.86x over existing state-of-the-art
approaches for 8 and 1024 clusters running on a multi-core platform,
respectively.
</p>
<a href="http://arxiv.org/abs/2010.04414" target="_blank">arXiv:2010.04414</a> [<a href="http://arxiv.org/pdf/2010.04414" target="_blank">pdf</a>]

<h2>Prognosis Prediction in Covid-19 Patients from Lab Tests and X-ray Data through Randomized Decision Trees. (arXiv:2010.04420v1 [cs.LG])</h2>
<h3>Alfonso Emilio Gerevini, Roberto Maroldi, Matteo Olivato, Luca Putelli, Ivan Serina</h3>
<p>AI and Machine Learning can offer powerful tools to help in the fight against
Covid-19. In this paper we present a study and a concrete tool based on machine
learning to predict the prognosis of hospitalised patients with Covid-19. In
particular we address the task of predicting the risk of death of a patient at
different times of the hospitalisation, on the base of some demographic
information, chest X-ray scores and several laboratory findings. Our machine
learning models use ensembles of decision trees trained and tested using data
from more than 2000 patients. An experimental evaluation of the models shows
good performance in solving the addressed task.
</p>
<a href="http://arxiv.org/abs/2010.04420" target="_blank">arXiv:2010.04420</a> [<a href="http://arxiv.org/pdf/2010.04420" target="_blank">pdf</a>]

<h2>WHO 2016 subtyping and automated segmentation of glioma using multi-task deep learning. (arXiv:2010.04425v1 [eess.IV])</h2>
<h3>Sebastian R. van der Voort, Fatih Incekara, Maarten M.J. Wijnenga, Georgios Kapsas, Renske Gahrmann, Joost W. Schouten, Rishi Nandoe Tewarie, Geert J. Lycklama, Philip C. De Witt Hamer, Roelant S. Eijgelaar, Pim J. French, Hendrikus J. Dubbink, Arnaud J.P.E. Vincent, Wiro J. Niessen, Martin J. van den Bent, Marion Smits, Stefan Klein</h3>
<p>Accurate characterization of glioma is crucial for clinical decision making.
A delineation of the tumor is also desirable in the initial decision stages but
is a time-consuming task. Leveraging the latest GPU capabilities, we developed
a single multi-task convolutional neural network that uses the full 3D,
structural, pre-operative MRI scans to can predict the IDH mutation status, the
1p/19q co-deletion status, and the grade of a tumor, while simultaneously
segmenting the tumor. We trained our method using the largest, most diverse
patient cohort to date containing 1508 glioma patients from 16 institutes. We
tested our method on an independent dataset of 240 patients from 13 different
institutes, and achieved an IDH-AUC of 0.90, 1p/19q-AUC of 0.85, grade-AUC of
0.81, and a mean whole tumor DICE score of 0.84. Thus, our method
non-invasively predicts multiple, clinically relevant parameters and
generalizes well to the broader clinical population.
</p>
<a href="http://arxiv.org/abs/2010.04425" target="_blank">arXiv:2010.04425</a> [<a href="http://arxiv.org/pdf/2010.04425" target="_blank">pdf</a>]

<h2>Rethinking the Extraction and Interaction of Multi-Scale Features for Vessel Segmentation. (arXiv:2010.04428v1 [eess.IV])</h2>
<h3>Yicheng Wu, Chengwei Pan, Shuqi Wang, Ming Zhang, Yong Xia, Yizhou Yu</h3>
<p>Analyzing the morphological attributes of blood vessels plays a critical role
in the computer-aided diagnosis of many cardiovascular and ophthalmologic
diseases. Although being extensively studied, segmentation of blood vessels,
particularly thin vessels and capillaries, remains challenging mainly due to
the lack of an effective interaction between local and global features. In this
paper, we propose a novel deep learning model called PC-Net to segment retinal
vessels and major arteries in 2D fundus image and 3D computed tomography
angiography (CTA) scans, respectively. In PC-Net, the pyramid
squeeze-and-excitation (PSE) module introduces spatial information to each
convolutional block, boosting its ability to extract more effective multi-scale
features, and the coarse-to-fine (CF) module replaces the conventional decoder
to enhance the details of thin vessels and process hard-to-classify pixels
again. We evaluated our PC-Net on the Digital Retinal Images for Vessel
Extraction (DRIVE) database and an in-house 3D major artery (3MA) database
against several recent methods. Our results not only demonstrate the
effectiveness of the proposed PSE module and CF module, but also suggest that
our proposed PC-Net sets new state of the art in the segmentation of retinal
vessels (AUC: 98.31%) and major arteries (AUC: 98.35%) on both databases,
respectively.
</p>
<a href="http://arxiv.org/abs/2010.04428" target="_blank">arXiv:2010.04428</a> [<a href="http://arxiv.org/pdf/2010.04428" target="_blank">pdf</a>]

<h2>Large-scale randomized experiment reveals machine learning helps people learn and remember more effectively. (arXiv:2010.04430v1 [cs.LG])</h2>
<h3>Utkarsh Upadhyay, Graham Lancashire, Christoph Moser, Manuel Gomez-Rodriguez</h3>
<p>Machine learning has typically focused on developing models and algorithms
that would ultimately replace humans at tasks where intelligence is required.
In this work, rather than replacing humans, we focus on unveiling the potential
of machine learning to improve how people learn and remember factual material.
To this end, we perform a large-scale randomized controlled trial with
thousands of learners from a popular learning app in the area of mobility.
After controlling for the length and frequency of study, we find that learners
whose study sessions are optimized using machine learning remember the content
over $\sim$67% longer than those whose study sessions are generated using two
alternative heuristics. Our randomized controlled trial also reveals that the
learners whose study sessions are optimized using machine learning are
$\sim$50% more likely to return to the app within 4-7 days.
</p>
<a href="http://arxiv.org/abs/2010.04430" target="_blank">arXiv:2010.04430</a> [<a href="http://arxiv.org/pdf/2010.04430" target="_blank">pdf</a>]

<h2>Tuning Convolutional Spiking Neural Network with Biologically-plausible Reward Propagation. (arXiv:2010.04434v1 [cs.NE])</h2>
<h3>Tielin Zhang, Shuncheng Jia, Xiang Cheng, Bo Xu</h3>
<p>Spiking Neural Networks (SNNs) contain more biology-realistic structures and
biology-inspired learning principles compared with that in standard Artificial
Neural Networks (ANNs). The dynamic neurons in SNNs are non-differential,
containing decayed historical states and generating event-based spikes after
their states reaching the firing threshold. This dynamic characteristic of SNNs
made it hard to be directly trained with standard back propagation (BP) which
is considered not biologically plausible. In this paper, a
Biologically-plausible Reward Propagation (BRP) algorithm is proposed and
applied on a SNN architecture with both spiking-convolution (with both 1D and
2D convolutional kernels) and full-connection layers. Different with standard
BP that propagated the error signals from post to pre synaptic neurons layer by
layer, the BRP propagated the target labels instead of target errors directly
from the output layer to all of the pre hidden layers. This effort was more
consistent with the top-down reward-guiding learning in cortical columns of the
neocortex. Then synaptic modifications with only local gradient differences
were induced with pseudo-BP that might also be replaced with Spike-Timing
Dependent Plasticity (STDP). The performance of the proposed BRP-SNN was
further verified on spatial (including MNIST and Cifar-10) and temporal
(including TIDigits and DvsGesture) tasks. The experimental result showed that
the BRP played roles on convergent learning of SNN, reached higher accuracy
compared with other state-of-the-art SNN algorithms, and saved more than 50%
computational cost compared with that on ANNs. We think the introduction of
biologically-plausible learning rules to the training procedure of
biologically-realistic SNNs might give us more hints and inspirations towards a
better understanding of the intelligent nature of the biological system.
</p>
<a href="http://arxiv.org/abs/2010.04434" target="_blank">arXiv:2010.04434</a> [<a href="http://arxiv.org/pdf/2010.04434" target="_blank">pdf</a>]

<h2>Multichannel Generative Language Model: Learning All Possible Factorizations Within and Across Channels. (arXiv:2010.04438v1 [cs.CL])</h2>
<h3>Harris Chan, Jamie Kiros, William Chan</h3>
<p>A channel corresponds to a viewpoint or transformation of an underlying
meaning. A pair of parallel sentences in English and French express the same
underlying meaning, but through two separate channels corresponding to their
languages. In this work, we present the Multichannel Generative Language Model
(MGLM). MGLM is a generative joint distribution model over channels. MGLM
marginalizes over all possible factorizations within and across all channels.
MGLM endows flexible inference, including unconditional generation, conditional
generation (where 1 channel is observed and other channels are generated), and
partially observed generation (where incomplete observations are spread across
all the channels). We experiment with the Multi30K dataset containing English,
French, Czech, and German. We demonstrate experiments with unconditional,
conditional, and partially conditional generation. We provide qualitative
samples sampled unconditionally from the generative joint distribution. We also
quantitatively analyze the quality-diversity trade-offs and find MGLM
outperforms traditional bilingual discriminative models.
</p>
<a href="http://arxiv.org/abs/2010.04438" target="_blank">arXiv:2010.04438</a> [<a href="http://arxiv.org/pdf/2010.04438" target="_blank">pdf</a>]

<h2>Joint State-Action Embedding for Efficient Reinforcement Learning. (arXiv:2010.04444v1 [cs.LG])</h2>
<h3>Paul J. Pritz, Liang Ma, Kin K. Leung</h3>
<p>While reinforcement learning has achieved considerable successes in recent
years, state-of-the-art models are often still limited by the size of state and
action spaces. Model-free reinforcement learning approaches use some form of
state representations and the latest work has explored embedding techniques for
actions, both with the aim of achieving better generalization and
applicability. However, these approaches consider only states or actions,
ignoring the interaction between them when generating embedded representations.
In this work, we propose a new approach for jointly embedding states and
actions that combines aspects of model-free and model-based reinforcement
learning, which can be applied in both discrete and continuous domains.
Specifically, we use a model of the environment to obtain embeddings for states
and actions and present a generic architecture that uses these to learn a
policy. In this way, the embedded representations obtained via our approach
enable better generalization over both states and actions by capturing
similarities in the embedding spaces. Evaluations of our approach on several
gaming and recommender system environments show it significantly outperforms
state-of-the-art models in discrete domains with large state/action space, thus
confirming the efficacy of joint embedding and its overall superior
performance.
</p>
<a href="http://arxiv.org/abs/2010.04444" target="_blank">arXiv:2010.04444</a> [<a href="http://arxiv.org/pdf/2010.04444" target="_blank">pdf</a>]

<h2>Augmenting Physical Models with Deep Networks for Complex Dynamics Forecasting. (arXiv:2010.04456v1 [stat.ML])</h2>
<h3>Vincent Le Guen, Yuan Yin, J&#xe9;r&#xe9;mie Dona, Ibrahim Ayed, Emmanuel de B&#xe9;zenac, Nicolas Thome, Patrick Gallinari</h3>
<p>Forecasting complex dynamical phenomena in settings where only partial
knowledge of their dynamics is available is a prevalent problem across various
scientific fields. While purely data-driven approaches are arguably
insufficient in this context, standard physical modeling based approaches tend
to be over-simplistic, inducing non-negligible errors. In this work, we
introduce the APHYNITY framework, a principled approach for augmenting
incomplete physical dynamics described by differential equations with deep
data-driven models. It consists in decomposing the dynamics into two
components: a physical component accounting for the dynamics for which we have
some prior knowledge, and a data-driven component accounting for errors of the
physical model. The learning problem is carefully formulated such that the
physical model explains as much of the data as possible, while the data-driven
component only describes information that cannot be captured by the physical
model, no more, no less. This not only provides the existence and uniqueness
for this decomposition, but also ensures interpretability and benefits
generalization. Experiments made on three important use cases, each
representative of a different family of phenomena, i.e. reaction-diffusion
equations, wave equations and the non-linear damped pendulum, show that
APHYNITY can efficiently leverage approximate physical models to accurately
forecast the evolution of the system and correctly identify relevant physical
parameters.
</p>
<a href="http://arxiv.org/abs/2010.04456" target="_blank">arXiv:2010.04456</a> [<a href="http://arxiv.org/pdf/2010.04456" target="_blank">pdf</a>]

<h2>Retrieve and Refine: Exemplar-based Neural Comment Generation. (arXiv:2010.04459v1 [cs.SE])</h2>
<h3>Bolin Wei, Yongmin Li, Ge Li, Xin Xia, Zhi Jin</h3>
<p>Code comment generation which aims to automatically generate natural language
descriptions for source code, is a crucial task in the field of automatic
software development. Traditional comment generation methods use
manually-crafted templates or information retrieval (IR) techniques to generate
summaries for source code. In recent years, neural network-based methods which
leveraged acclaimed encoder-decoder deep learning framework to learn comment
generation patterns from a large-scale parallel code corpus, have achieved
impressive results. However, these emerging methods only take code-related
information as input. Software reuse is common in the process of software
development, meaning that comments of similar code snippets are helpful for
comment generation. Inspired by the IR-based and template-based approaches, in
this paper, we propose a neural comment generation approach where we use the
existing comments of similar code snippets as exemplars to guide comment
generation. Specifically, given a piece of code, we first use an IR technique
to retrieve a similar code snippet and treat its comment as an exemplar. Then
we design a novel seq2seq neural network that takes the given code, its AST,
its similar code, and its exemplar as input, and leverages the information from
the exemplar to assist in the target comment generation based on the semantic
similarity between the source code and the similar code. We evaluate our
approach on a large-scale Java corpus, which contains about 2M samples, and
experimental results demonstrate that our model outperforms the
state-of-the-art methods by a substantial margin.
</p>
<a href="http://arxiv.org/abs/2010.04459" target="_blank">arXiv:2010.04459</a> [<a href="http://arxiv.org/pdf/2010.04459" target="_blank">pdf</a>]

<h2>Bioinspired Bipedal Locomotion Control for Humanoid Robotics Based on EACO. (arXiv:2010.04463v1 [cs.NE])</h2>
<h3>Jingan Yang, Yang Peng</h3>
<p>To construct a robot that can walk as efficiently and steadily as humans or
other legged animals, we develop an enhanced elitist-mutated ant colony
optimization~(EACO) algorithm with genetic and crossover operators in real-time
applications to humanoid robotics or other legged robots. This work presents
promoting global search capability and convergence rate of the EACO applied to
humanoid robots in real-time by estimating the expected convergence rate using
Markov chain. Furthermore, we put a special focus on the EACO algorithm on a
wide range of problems, from ACO, real-coded GAs, GAs with neural
networks~(NNs), particle swarm optimization~(PSO) to complex robotics systems
including gait synthesis, dynamic modeling of parameterizable trajectories and
gait optimization of humanoid robotics. The experimental results illustrate the
capability of this method to discover the premature convergence probability,
tackle successfully inherent stagnation, and promote the convergence rate of
the EACO-based humanoid robotics systems and demonstrated the applicability and
the effectiveness of our strategy for solving sophisticated optimization tasks.
We found reliable and fast walking gaits with a velocity of up to 0.47m/s using
the EACO optimization strategy. These findings have significant implications
for understanding and tackling inherent stagnation and poor convergence rate of
the EACO and provide new insight into the genetic architectures and control
optimization of humanoid robotics.
</p>
<a href="http://arxiv.org/abs/2010.04463" target="_blank">arXiv:2010.04463</a> [<a href="http://arxiv.org/pdf/2010.04463" target="_blank">pdf</a>]

<h2>Learning not to learn: Nature versus nurture in silico. (arXiv:2010.04466v1 [cs.LG])</h2>
<h3>Robert Tjarko Lange, Henning Sprekeler</h3>
<p>Animals are equipped with a rich innate repertoire of sensory, behavioral and
motor skills, which allows them to interact with the world immediately after
birth. At the same time, many behaviors are highly adaptive and can be tailored
to specific environments by means of learning. In this work, we use
mathematical analysis and the framework of meta-learning (or 'learning to
learn') to answer when it is beneficial to learn such an adaptive strategy and
when to hard-code a heuristic behavior. We find that the interplay of
ecological uncertainty, task complexity and the agents' lifetime has crucial
effects on the meta-learned amortized Bayesian inference performed by an agent.
There exist two regimes: One in which meta-learning yields a learning algorithm
that implements task-dependent information-integration and a second regime in
which meta-learning imprints a heuristic or 'hard-coded' behavior. Further
analysis reveals that non-adaptive behaviors are not only optimal for aspects
of the environment that are stable across individuals, but also in situations
where an adaptation to the environment would in fact be highly beneficial, but
could not be done quickly enough to be exploited within the remaining lifetime.
Hard-coded behaviors should hence not only be those that always work, but also
those that are too complex to be learned within a reasonable time frame.
</p>
<a href="http://arxiv.org/abs/2010.04466" target="_blank">arXiv:2010.04466</a> [<a href="http://arxiv.org/pdf/2010.04466" target="_blank">pdf</a>]

<h2>gundapusunil at SemEval-2020 Task 8: Multimodal Memotion Analysis. (arXiv:2010.04470v1 [cs.CV])</h2>
<h3>Sunil Gundapu, Radhika Mamidi</h3>
<p>Recent technological advancements in the Internet and Social media usage have
resulted in the evolution of faster and efficient platforms of communication.
These platforms include visual, textual and speech mediums and have brought a
unique social phenomenon called Internet memes. Internet memes are in the form
of images with witty, catchy, or sarcastic text descriptions. In this paper, we
present a multi-modal sentiment analysis system using deep neural networks
combining Computer Vision and Natural Language Processing. Our aim is different
than the normal sentiment analysis goal of predicting whether a text expresses
positive or negative sentiment; instead, we aim to classify the Internet meme
as a positive, negative, or neutral, identify the type of humor expressed and
quantify the extent to which a particular effect is being expressed. Our system
has been developed using CNN and LSTM and outperformed the baseline score.
</p>
<a href="http://arxiv.org/abs/2010.04470" target="_blank">arXiv:2010.04470</a> [<a href="http://arxiv.org/pdf/2010.04470" target="_blank">pdf</a>]

<h2>Contralaterally Enhanced Networks for Thoracic Disease Detection. (arXiv:2010.04483v1 [cs.CV])</h2>
<h3>Gangming Zhao, Chaowei Fang, Guanbin Li, Licheng Jiao, Yizhou Yu</h3>
<p>Identifying and locating diseases in chest X-rays are very challenging, due
to the low visual contrast between normal and abnormal regions, and distortions
caused by other overlapping tissues. An interesting phenomenon is that there
exist many similar structures in the left and right parts of the chest, such as
ribs, lung fields and bronchial tubes. This kind of similarities can be used to
identify diseases in chest X-rays, according to the experience of
broad-certificated radiologists. Aimed at improving the performance of existing
detection methods, we propose a deep end-to-end module to exploit the
contralateral context information for enhancing feature representations of
disease proposals. First of all, under the guidance of the spine line, the
spatial transformer network is employed to extract local contralateral patches,
which can provide valuable context information for disease proposals. Then, we
build up a specific module, based on both additive and subtractive operations,
to fuse the features of the disease proposal and the contralateral patch. Our
method can be integrated into both fully and weakly supervised disease
detection frameworks. It achieves 33.17 AP50 on a carefully annotated private
chest X-ray dataset which contains 31,000 images. Experiments on the NIH chest
X-ray dataset indicate that our method achieves state-of-the-art performance in
weakly-supervised disease localization.
</p>
<a href="http://arxiv.org/abs/2010.04483" target="_blank">arXiv:2010.04483</a> [<a href="http://arxiv.org/pdf/2010.04483" target="_blank">pdf</a>]

<h2>Top-Rank-Focused Adaptive Vote Collection for the Evaluation of Domain-Specific Semantic Models. (arXiv:2010.04486v1 [cs.CL])</h2>
<h3>Pierangelo Lombardo, Alessio Boiardi, Luca Colombo, Angelo Schiavone, Nicol&#xf2; Tamagnone</h3>
<p>The growth of domain-specific applications of semantic models, boosted by the
recent achievements of unsupervised embedding learning algorithms, demands
domain-specific evaluation datasets. In many cases, content-based recommenders
being a prime example, these models are required to rank words or texts
according to their semantic relatedness to a given concept, with particular
focus on top ranks. In this work, we give a threefold contribution to address
these requirements: (i) we define a protocol for the construction, based on
adaptive pairwise comparisons, of a relatedness-based evaluation dataset
tailored on the available resources and optimized to be particularly accurate
in top-rank evaluation; (ii) we define appropriate metrics, extensions of
well-known ranking correlation coefficients, to evaluate a semantic model via
the aforementioned dataset by taking into account the greater significance of
top ranks. Finally, (iii) we define a stochastic transitivity model to simulate
semantic-driven pairwise comparisons, which confirms the effectiveness of the
proposed dataset construction protocol.
</p>
<a href="http://arxiv.org/abs/2010.04486" target="_blank">arXiv:2010.04486</a> [<a href="http://arxiv.org/pdf/2010.04486" target="_blank">pdf</a>]

<h2>MIMO ILC for Precision SEA robots using Input-weighted Complex-Kernel Regression. (arXiv:2010.04487v1 [eess.SY])</h2>
<h3>Leon Yan, Nathan Banka, Parker Owan, Walter Tony Piaskowy, Joseph Garbini, Santosh Devasia</h3>
<p>This work improves the positioning precision of lightweight robots with
series elastic actuators (SEAs). Lightweight SEA robots, along with
low-impedance control, can maneuver without causing damage in uncertain,
confined spaces such as inside an aircraft wing during aircraft assembly.
Nevertheless, substantial modeling uncertainties in SEA robots reduce the
precision achieved by model-based approaches such as inversion-based
feedforward. Therefore, this article improves the precision of SEA robots
around specified operating points, through a multi-input multi-output (MIMO),
iterative learning control (ILC) approach. The main contributions of this
article are to (i) introduce an input-weighted complex kernel to estimate local
MIMO models using complex Gaussian process regression (c-GPR) (ii) develop
Ger\v{s}gorin-theorem-based conditions on the iteration gains for ensuring ILC
convergence to precision within noise-related limits, even with errors in the
estimated model; and (iii) demonstrate precision positioning with an
experimental SEA robot. Comparative experimental results, with and without ILC,
show around 90% improvement in the positioning precision (close to the
repeatability limit of the robot) and a 10-times increase in the SEA robot's
operating speed with the use of the MIMO ILC.
</p>
<a href="http://arxiv.org/abs/2010.04487" target="_blank">arXiv:2010.04487</a> [<a href="http://arxiv.org/pdf/2010.04487" target="_blank">pdf</a>]

<h2>Linear Mode Connectivity in Multitask and Continual Learning. (arXiv:2010.04495v1 [cs.LG])</h2>
<h3>Seyed Iman Mirzadeh, Mehrdad Farajtabar, Dilan Gorur, Razvan Pascanu, Hassan Ghasemzadeh</h3>
<p>Continual (sequential) training and multitask (simultaneous) training are
often attempting to solve the same overall objective: to find a solution that
performs well on all considered tasks. The main difference is in the training
regimes, where continual learning can only have access to one task at a time,
which for neural networks typically leads to catastrophic forgetting. That is,
the solution found for a subsequent task does not perform well on the previous
ones anymore. However, the relationship between the different minima that the
two training regimes arrive at is not well understood. What sets them apart? Is
there a local structure that could explain the difference in performance
achieved by the two different schemes? Motivated by recent work showing that
different minima of the same task are typically connected by very simple curves
of low error, we investigate whether multitask and continual solutions are
similarly connected. We empirically find that indeed such connectivity can be
reliably achieved and, more interestingly, it can be done by a linear path,
conditioned on having the same initialization for both. We thoroughly analyze
this observation and discuss its significance for the continual learning
process. Furthermore, we exploit this finding to propose an effective algorithm
that constrains the sequentially learned minima to behave as the multitask
solution. We show that our method outperforms several state of the art
continual learning algorithms on various vision benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.04495" target="_blank">arXiv:2010.04495</a> [<a href="http://arxiv.org/pdf/2010.04495" target="_blank">pdf</a>]

<h2>Unemployment Through the Lens of Social Media. (arXiv:2010.04496v1 [cs.CY])</h2>
<h3>Alessandra Urbinati, Kyriaki Kalimeri, Andrea Bonanomi, Alessandro Rosina, Ciro Cattuto, Daniela Paolotti</h3>
<p>Youth unemployment rates are still in alerting levels for many countries,
among which Italy. Direct consequences include poverty, social exclusion, and
criminal behaviours, while negative impact on the future employability and wage
cannot be obscured. In this study, we employ survey data together with social
media data, and in particular likes on Facebook Pages, to analyse personality,
moral values, but also cultural elements of the young unemployed population in
Italy. Our findings show that there are small but significant differences in
personality and moral values, with the unemployed males to be less agreeable
while females more open to new experiences. At the same time, unemployed have a
more collectivist point of view, valuing more in-group loyalty, authority, and
purity foundations. Interestingly, topic modelling analysis did not reveal
major differences in interests and cultural elements of the unemployed.
Utilisation patterns emerged though; the employed seem to use Facebook to
connect with local activities, while the unemployed use it mostly as for
entertainment purposes and as a source of news, making them susceptible to
mis/disinformation. We believe these findings can help policymakers get a
deeper understanding of this population and initiatives that improve both the
hard and the soft skills of this fragile population.
</p>
<a href="http://arxiv.org/abs/2010.04496" target="_blank">arXiv:2010.04496</a> [<a href="http://arxiv.org/pdf/2010.04496" target="_blank">pdf</a>]

<h2>Scalable Many-Objective Pathfinding Benchmark Suite. (arXiv:2010.04501v1 [cs.NE])</h2>
<h3>Jens Weise, Sanaz Mostaghim</h3>
<p>Route planning also known as pathfinding is one of the key elements in
logistics, mobile robotics and other applications, where engineers face many
conflicting objectives. However, most of the current route planning algorithms
consider only up to three objectives. In this paper, we propose a scalable
many-objective benchmark problem covering most of the important features for
routing applications based on real-world data. We define five objective
functions representing distance, traveling time, delays caused by accidents,
and two route specific features such as curvature and elevation. We analyse
several different instances for this test problem and provide their true
Pareto-front to analyse the problem difficulties. We apply three well-known
evolutionary multi-objective algorithms. Since this test benchmark can be
easily transferred to real-world routing problems, we construct a routing
problem from OpenStreetMap data. We evaluate the three optimisation algorithms
and observe that we are able to provide promising results for such a real-world
application. The proposed benchmark represents a scalable many-objective route
planning optimisation problem enabling researchers and engineers to evaluate
their many-objective approaches.
</p>
<a href="http://arxiv.org/abs/2010.04501" target="_blank">arXiv:2010.04501</a> [<a href="http://arxiv.org/pdf/2010.04501" target="_blank">pdf</a>]

<h2>Background Learnable Cascade for Zero-Shot Object Detection. (arXiv:2010.04502v1 [cs.CV])</h2>
<h3>Ye Zheng, Ruoran Huang, Chuanqi Han, Xi Huang, Li Cui</h3>
<p>Zero-shot detection (ZSD) is crucial to large-scale object detection with the
aim of simultaneously localizing and recognizing unseen objects. There remain
several challenges for ZSD, including reducing the ambiguity between background
and unseen objects as well as improving the alignment between visual and
semantic concept. In this work, we propose a novel framework named Background
Learnable Cascade (BLC) to improve ZSD performance. The major contributions for
BLC are as follows: (i) we propose a multi-stage cascade structure named
Cascade Semantic R-CNN to progressively refine the alignment between visual and
semantic of ZSD; (ii) we develop the semantic information flow structure and
directly add it between each stage in Cascade Semantic RCNN to further improve
the semantic feature learning; (iii) we propose the background learnable region
proposal network (BLRPN) to learn an appropriate word vector for background
class and use this learned vector in Cascade Semantic R CNN, this design makes
\Background Learnable" and reduces the confusion between background and unseen
classes. Our extensive experiments show BLC obtains significantly performance
improvements for MS-COCO over state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.04502" target="_blank">arXiv:2010.04502</a> [<a href="http://arxiv.org/pdf/2010.04502" target="_blank">pdf</a>]

<h2>Self-Paced Learning for Neural Machine Translation. (arXiv:2010.04505v1 [cs.CL])</h2>
<h3>Yu Wan, Baosong Yang, Derek F. Wong, Yikai Zhou, Lidia S. Chao, Haibo Zhang, Boxing Chen</h3>
<p>Recent studies have proven that the training of neural machine translation
(NMT) can be facilitated by mimicking the learning process of humans.
Nevertheless, achievements of such kind of curriculum learning rely on the
quality of artificial schedule drawn up with the handcrafted features, e.g.
sentence length or word rarity. We ameliorate this procedure with a more
flexible manner by proposing self-paced learning, where NMT model is allowed to
1) automatically quantify the learning confidence over training examples; and
2) flexibly govern its learning via regulating the loss in each iteration step.
Experimental results over multiple translation tasks demonstrate that the
proposed model yields better performance than strong baselines and those models
trained with human-designed curricula on both translation quality and
convergence speed.
</p>
<a href="http://arxiv.org/abs/2010.04505" target="_blank">arXiv:2010.04505</a> [<a href="http://arxiv.org/pdf/2010.04505" target="_blank">pdf</a>]

<h2>Sickle-cell disease diagnosis support selecting the most appropriate machinelearning method: Towards a general and interpretable approach for cellmorphology analysis from microscopy images. (arXiv:2010.04511v1 [cs.LG])</h2>
<h3>Nata&#x161;a Petrovi&#x107;, Gabriel Moy&#xe0;-Alcover, Antoni Jaume-i-Cap&#xf3;, Manuel Gonz&#xe1;lez-Hidalgo</h3>
<p>In this work we propose an approach to select the classification method and
features, based on the state-of-the-art, with best performance for diagnostic
support through peripheral blood smear images of red blood cells. In our case
we used samples of patients with sickle-cell disease which can be generalized
for other study cases. To trust the behavior of the proposed system, we also
analyzed the interpretability.

We pre-processed and segmented microscopic images, to ensure high feature
quality. We applied the methods used in the literature to extract the features
from blood cells and the machine learning methods to classify their morphology.
Next, we searched for their best parameters from the resulting data in the
feature extraction phase. Then, we found the best parameters for every
classifier using Randomized and Grid search.

For the sake of scientific progress, we published parameters for each
classifier, the implemented code library, the confusion matrices with the raw
data, and we used the public erythrocytesIDB dataset for validation. We also
defined how to select the most important features for classification to
decrease the complexity and the training time, and for interpretability purpose
in opaque models. Finally, comparing the best performing classification methods
with the state-of-the-art, we obtained better results even with interpretable
model classifiers.
</p>
<a href="http://arxiv.org/abs/2010.04511" target="_blank">arXiv:2010.04511</a> [<a href="http://arxiv.org/pdf/2010.04511" target="_blank">pdf</a>]

<h2>Model Exploration with Cost-Aware Learning. (arXiv:2010.04512v1 [cs.LG])</h2>
<h3>Namid Stillman, Igor Balazs, Sabine Hauert</h3>
<p>We present an extension to active learning routines in which non-constant
costs are explicitly considered. This work considers both known and unknown
costs and introduces the term \epsilon-frugal for learners that do not only
consider minimizing total costs but are also able to explore high cost regions
of the sample space. We demonstrate our extension on a well-known machine
learning dataset and find that out \epsilon-frugal learners outperform both
learners with known costs and random sampling.
</p>
<a href="http://arxiv.org/abs/2010.04512" target="_blank">arXiv:2010.04512</a> [<a href="http://arxiv.org/pdf/2010.04512" target="_blank">pdf</a>]

<h2>Be Your Own Best Competitor! Multi-Branched Adversarial Knowledge Transfer. (arXiv:2010.04516v1 [cs.CV])</h2>
<h3>Mahdi Ghorbani, Fahimeh Fooladgar, Shohreh Kasaei</h3>
<p>Deep neural network architectures have attained remarkable improvements in
scene understanding tasks. Utilizing an efficient model is one of the most
important constraints for limited-resource devices. Recently, several
compression methods have been proposed to diminish the heavy computational
burden and memory consumption. Among them, the pruning and quantizing methods
exhibit a critical drop in performances by compressing the model parameters.
While the knowledge distillation methods improve the performance of compact
models by focusing on training lightweight networks with the supervision of
cumbersome networks. In the proposed method, the knowledge distillation has
been performed within the network by constructing multiple branches over the
primary stream of the model, known as the self-distillation method. Therefore,
the ensemble of sub-neural network models has been proposed to transfer the
knowledge among themselves with the knowledge distillation policies as well as
an adversarial learning strategy. Hence, The proposed ensemble of sub-models is
trained against a discriminator model adversarially. Besides, their knowledge
is transferred within the ensemble by four different loss functions. The
proposed method has been devoted to both lightweight image classification and
encoder-decoder architectures to boost the performance of small and compact
models without incurring extra computational overhead at the inference process.
Extensive experimental results on the main challenging datasets show that the
proposed network outperforms the primary model in terms of accuracy at the same
number of parameters and computational cost. The obtained results show that the
proposed model has achieved significant improvement over earlier ideas of
self-distillation methods. The effectiveness of the proposed models has also
been illustrated in the encoder-decoder model.
</p>
<a href="http://arxiv.org/abs/2010.04516" target="_blank">arXiv:2010.04516</a> [<a href="http://arxiv.org/pdf/2010.04516" target="_blank">pdf</a>]

<h2>Multi-Objective Optimisation of Multi-Output Neural Trees. (arXiv:2010.04524v1 [cs.NE])</h2>
<h3>Varun Ojha, Giuseppe Nicosia</h3>
<p>We propose an algorithm and a new method to tackle the classification
problems. We propose a multi-output neural tree (MONT) algorithm, which is an
evolutionary learning algorithm trained by the non-dominated sorting genetic
algorithm (NSGA)-III. Since evolutionary learning is stochastic, a hypothesis
found in the form of MONT is unique for each run of evolutionary learning,
i.e., each hypothesis (tree) generated bears distinct properties compared to
any other hypothesis both in topological space and parameter-space. This leads
to a challenging optimisation problem where the aim is to minimise the
tree-size and maximise the classification accuracy. Therefore, the
Pareto-optimality concerns were met by hypervolume indicator analysis. We used
nine benchmark classification learning problems to evaluate the performance of
the MONT. As a result of our experiments, we obtained MONTs which are able to
tackle the classification problems with high accuracy. The performance of MONT
emerged better over a set of problems tackled in this study compared with a set
of well-known classifiers: multilayer perceptron, reduced-error pruning tree,
naive Bayes classifier, decision tree, and support vector machine. Moreover,
the performances of three versions of MONT's training using genetic
programming, NSGA-II, and NSGA-III suggest that the NSGA-III gives the best
Pareto-optimal solution.
</p>
<a href="http://arxiv.org/abs/2010.04524" target="_blank">arXiv:2010.04524</a> [<a href="http://arxiv.org/pdf/2010.04524" target="_blank">pdf</a>]

<h2>Uncertainty-Aware Few-Shot Image Classification. (arXiv:2010.04525v1 [cs.CV])</h2>
<h3>Zhizheng Zhang, Cuiling Lan, Wenjun Zeng, Zhibo Chen, Shih-Fu Chang</h3>
<p>Few-shot image classification aims to learn to recognize new categories from
limited labelled data. Recently, metric learning based approaches have been
widely investigated which classify a query sample by finding the nearest
prototype from the support set based on the feature similarities. For few-shot
classification, the calculated similarity of a query-support pair depends on
both the query and the support. The network has different
confidences/uncertainty on the calculated similarities of the different pairs
and there are observation noises on the similarity. Understanding and modeling
the uncertainty on the similarity could promote better exploitation of the
limited samples in optimization. However, this is still underexplored in
few-shot learning. In this work, we propose Uncertainty-Aware Few-Shot (UAFS)
image classification by modeling uncertainty of the similarities of
query-support pairs and performing uncertainty-aware optimization.
Particularly, we design a graph-based model to jointly estimate the uncertainty
of similarities between a query and the prototypes in the support set. We
optimize the network based on the modeled uncertainty by converting the
observed similarity to a probabilistic similarity distribution to be robust to
observation noises. Extensive experiments show our proposed method brings
significant improvements on top of a strong baseline and achieves the
state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2010.04525" target="_blank">arXiv:2010.04525</a> [<a href="http://arxiv.org/pdf/2010.04525" target="_blank">pdf</a>]

<h2>What Have We Achieved on Text Summarization?. (arXiv:2010.04529v1 [cs.CL])</h2>
<h3>Dandan Huang, Leyang Cui, Sen Yang, Guangsheng Bao, Kun Wang, Jun Xie, Yue Zhang</h3>
<p>Deep learning has led to significant improvement in text summarization with
various methods investigated and improved ROUGE scores reported over the years.
However, gaps still exist between summaries produced by automatic summarizers
and human professionals. Aiming to gain more understanding of summarization
systems with respect to their strengths and limits on a fine-grained syntactic
and semantic level, we consult the Multidimensional Quality Metric(MQM) and
quantify 8 major sources of errors on 10 representative summarization models
manually. Primarily, we find that 1) under similar settings, extractive
summarizers are in general better than their abstractive counterparts thanks to
strength in faithfulness and factual-consistency; 2) milestone techniques such
as copy, coverage and hybrid extractive/abstractive methods do bring specific
improvements but also demonstrate limitations; 3) pre-training techniques, and
in particular sequence-to-sequence pre-training, are highly effective for
improving text summarization, with BART giving the best results.
</p>
<a href="http://arxiv.org/abs/2010.04529" target="_blank">arXiv:2010.04529</a> [<a href="http://arxiv.org/pdf/2010.04529" target="_blank">pdf</a>]

<h2>Gini in a Bottleneck: Gotta Train Me the Right Way. (arXiv:2010.04535v1 [cs.LG])</h2>
<h3>Ryan Henderson, Djork-Arn&#xe9; Clevert, Floriane Montanari</h3>
<p>Due to the nature of deep learning approaches, it is inherently difficult to
understand which aspects of a molecular graph drive the predictions of the
network. As a mitigation strategy, we constrain certain weights in a multi-task
graph convolutional neural network according to the Gini index to maximize the
"inequality" of the learned representations. We show that this constraint does
not degrade evaluation metrics for some targets, and allows us to combine the
outputs of the graph convolutional operation in a visually interpretable way.
We then perform a proof-of-concept experiment on quantum chemistry targets on
the public QM9 dataset, and a larger experiment on ADMET targets on proprietary
drug-like molecules. Since a benchmark of explainability in the latter case is
difficult, we informally surveyed medicinal chemists within our organization to
check for agreement between regions of the molecule they and the model
identified as relevant to the properties in question.
</p>
<a href="http://arxiv.org/abs/2010.04535" target="_blank">arXiv:2010.04535</a> [<a href="http://arxiv.org/pdf/2010.04535" target="_blank">pdf</a>]

<h2>Incorporating planning intelligence into deep learning: A planning support tool for street network design. (arXiv:2010.04536v1 [cs.CV])</h2>
<h3>Zhou Fang, Ying Jin, Tianren Yang</h3>
<p>Deep learning applications in shaping ad hoc planning proposals are limited
by the difficulty in integrating professional knowledge about cities with
artificial intelligence. We propose a novel, complementary use of deep neural
networks and planning guidance to automate street network generation that can
be context-aware, example-based and user-guided. The model tests suggest that
the incorporation of planning knowledge (e.g., road junctions and neighborhood
types) in the model training leads to a more realistic prediction of street
configurations. Furthermore, the new tool provides both professional and lay
users an opportunity to systematically and intuitively explore benchmark
proposals for comparisons and further evaluations.
</p>
<a href="http://arxiv.org/abs/2010.04536" target="_blank">arXiv:2010.04536</a> [<a href="http://arxiv.org/pdf/2010.04536" target="_blank">pdf</a>]

<h2>Upper Esophageal Sphincter Opening Segmentation with Convolutional Recurrent Neural Networks in High Resolution Cervical Auscultation. (arXiv:2010.04541v1 [eess.IV])</h2>
<h3>Yassin Khalifa, Cara Donohue, James L. Coyle, Ervin Sejdi&#x107;</h3>
<p>Upper esophageal sphincter is an important anatomical landmark of the
swallowing process commonly observed through the kinematic analysis of
radiographic examinations that are vulnerable to subjectivity and clinical
feasibility issues. Acting as the doorway of esophagus, upper esophageal
sphincter allows the transition of ingested materials from pharyngeal into
esophageal stages of swallowing and a reduced duration of opening can lead to
penetration/aspiration and/or pharyngeal residue. Therefore, in this study we
consider a non-invasive high resolution cervical auscultation-based screening
tool to approximate the human ratings of upper esophageal sphincter opening and
closure. Swallows were collected from 116 patients and a deep neural network
was trained to produce a mask that demarcates the duration of upper esophageal
sphincter opening. The proposed method achieved more than 90\% accuracy and
similar values of sensitivity and specificity when compared to human ratings
even when tested over swallows from an independent clinical experiment.
Moreover, the predicted opening and closure moments surprisingly fell within an
inter-human comparable error of their human rated counterparts which
demonstrates the clinical significance of high resolution cervical auscultation
in replacing ionizing radiation-based evaluation of swallowing kinematics.
</p>
<a href="http://arxiv.org/abs/2010.04541" target="_blank">arXiv:2010.04541</a> [<a href="http://arxiv.org/pdf/2010.04541" target="_blank">pdf</a>]

<h2>Study on Leveraging Wind Farm Reactive Power Potential for Uncertain Power System Reactive Power Optimization. (arXiv:2010.04545v1 [eess.SY])</h2>
<h3>Yu Zhou, Zhengshuo Li</h3>
<p>This paper suggests leveraging reactive power potential (RPP) embedded in
wind farms to improve power system operational safety and optimality. First,
three typical RPP provision approaches are analyzed and a two-stage robust
linear optimization based RPP evaluation method is proposed. This approach
yields an RPP range that ensures the security of wind farm operations under any
realization of uncertainty regarding the wind farm. Simplified DistFlow
equations are employed here for a compromise between computational accuracy and
cost. Next, an uncertain RPP-involved reactive power optimization problem is
introduced, through which system operators ensure system-wide security and
optimality regarding the base case and against any possible deviation caused by
uncertain lumped loads and renewable generation. Steady-state models of
automatic generation control and local voltage control are also captured in
this uncertain reactive power optimization, which is then transformed through
Soyster's method into a deterministic optimization problem that is readily
solvable. Case studies have conceptually validated that even with notable
uncertainty, wind farms are still a competent reactive power resource providing
considerable RPP. Also, simulation confirms positive and notable improvement of
leveraging wind-farm RPP on system-wide operational security and optimality,
especially for power systems with high wind penetration.
</p>
<a href="http://arxiv.org/abs/2010.04545" target="_blank">arXiv:2010.04545</a> [<a href="http://arxiv.org/pdf/2010.04545" target="_blank">pdf</a>]

<h2>Deep Learning for Procedural Content Generation. (arXiv:2010.04548v1 [cs.AI])</h2>
<h3>Jialin Liu, Sam Snodgrass, Ahmed Khalifa, Sebastian Risi, Georgios N. Yannakakis, Julian Togelius</h3>
<p>Procedural content generation in video games has a long history. Existing
procedural content generation methods, such as search-based, solver-based,
rule-based and grammar-based methods have been applied to various content types
such as levels, maps, character models, and textures. A research field centered
on content generation in games has existed for more than a decade. More
recently, deep learning has powered a remarkable range of inventions in content
production, which are applicable to games. While some cutting-edge deep
learning methods are applied on their own, others are applied in combination
with more traditional methods, or in an interactive setting. This article
surveys the various deep learning methods that have been applied to generate
game content directly or indirectly, discusses deep learning methods that could
be used for content generation purposes but are rarely used today, and
envisages some limitations and potential future directions of deep learning for
procedural content generation.
</p>
<a href="http://arxiv.org/abs/2010.04548" target="_blank">arXiv:2010.04548</a> [<a href="http://arxiv.org/pdf/2010.04548" target="_blank">pdf</a>]

<h2>AI Centered on Scene Fitting and Dynamic Cognitive Network. (arXiv:2010.04551v1 [cs.AI])</h2>
<h3>Feng Chen</h3>
<p>This paper briefly analyzes the advantages and problems of AI mainstream
technology and puts forward: To achieve stronger Artificial Intelligence, the
end-to-end function calculation must be changed and adopt the technology system
centered on scene fitting. It also discusses the concrete scheme named Dynamic
Cognitive Network model (DC Net). Discussions : The knowledge and data in the
comprehensive domain are uniformly represented by using the rich connection
heterogeneous Dynamic Cognitive Network constructed by conceptualized elements;
A network structure of two dimensions and multi layers is designed to achieve
unified implementation of AI core processing such as combination and
generalization; This paper analyzes the implementation differences of computer
systems in different scenes, such as open domain, closed domain, significant
probability and non-significant probability, and points out that the
implementation in open domain and significant probability scene is the key of
AI, and a cognitive probability model combining bidirectional conditional
probability, probability passing and superposition, probability col-lapse is
designed; An omnidirectional network matching-growth algorithm system driven by
target and probability is designed to realize the integration of parsing,
generating, reasoning, querying, learning and so on; The principle of cognitive
network optimization is proposed, and the basic framework of Cognitive Network
Learning algorithm (CNL) is designed that structure learning is the primary
method and parameter learning is the auxiliary. The logical similarity of
implementation between DC Net model and human intelligence is analyzed in this
paper.
</p>
<a href="http://arxiv.org/abs/2010.04551" target="_blank">arXiv:2010.04551</a> [<a href="http://arxiv.org/pdf/2010.04551" target="_blank">pdf</a>]

<h2>Conditional GAN for Prediction of Glaucoma Progression with Macular Optical Coherence Tomography. (arXiv:2010.04552v1 [eess.IV])</h2>
<h3>Osama N. Hassan, Serhat Sahin, Vahid Mohammadzadeh, Xiaohe Yang, Navid Amini, Apoorva Mylavarapu, Jack Martinyan, Tae Hong, Golnoush Mahmoudinezhad, Daniel Rueckert, Kouros Nouri-Mahdavi, Fabien Scalzo</h3>
<p>The estimation of glaucoma progression is a challenging task as the rate of
disease progression varies among individuals in addition to other factors such
as measurement variability and the lack of standardization in defining
progression. Structural tests, such as thickness measurements of the retinal
nerve fiber layer or the macula with optical coherence tomography (OCT), are
able to detect anatomical changes in glaucomatous eyes. Such changes may be
observed before any functional damage. In this work, we built a generative deep
learning model using the conditional GAN architecture to predict glaucoma
progression over time. The patient's OCT scan is predicted from three or two
prior measurements. The predicted images demonstrate high similarity with the
ground truth images. In addition, our results suggest that OCT scans obtained
from only two prior visits may actually be sufficient to predict the next OCT
scan of the patient after six months.
</p>
<a href="http://arxiv.org/abs/2010.04552" target="_blank">arXiv:2010.04552</a> [<a href="http://arxiv.org/pdf/2010.04552" target="_blank">pdf</a>]

<h2>Audio-Visual Speech Inpainting with Deep Learning. (arXiv:2010.04556v1 [eess.AS])</h2>
<h3>Giovanni Morrone, Daniel Michelsanti, Zheng-Hua Tan, Jesper Jensen</h3>
<p>In this paper, we present a deep-learning-based framework for audio-visual
speech inpainting, i.e., the task of restoring the missing parts of an acoustic
speech signal from reliable audio context and uncorrupted visual information.
Recent work focuses solely on audio-only methods and generally aims at
inpainting music signals, which show highly different structure than speech.
Instead, we inpaint speech signals with gaps ranging from 100 ms to 1600 ms to
investigate the contribution that vision can provide for gaps of different
duration. We also experiment with a multi-task learning approach where a phone
recognition task is learned together with speech inpainting. Results show that
the performance of audio-only speech inpainting approaches degrades rapidly
when gaps get large, while the proposed audio-visual approach is able to
plausibly restore missing information. In addition, we show that multi-task
learning is effective, although the largest contribution to performance comes
from vision.
</p>
<a href="http://arxiv.org/abs/2010.04556" target="_blank">arXiv:2010.04556</a> [<a href="http://arxiv.org/pdf/2010.04556" target="_blank">pdf</a>]

<h2>HyperSAGE: Generalizing Inductive Representation Learning on Hypergraphs. (arXiv:2010.04558v1 [cs.LG])</h2>
<h3>Devanshu Arya, Deepak K. Gupta, Stevan Rudinac, Marcel Worring</h3>
<p>Graphs are the most ubiquitous form of structured data representation used in
machine learning. They model, however, only pairwise relations between nodes
and are not designed for encoding the higher-order relations found in many
real-world datasets. To model such complex relations, hypergraphs have proven
to be a natural representation. Learning the node representations in a
hypergraph is more complex than in a graph as it involves information
propagation at two levels: within every hyperedge and across the hyperedges.
Most current approaches first transform a hypergraph structure to a graph for
use in existing geometric deep learning algorithms. This transformation leads
to information loss, and sub-optimal exploitation of the hypergraph's
expressive power. We present HyperSAGE, a novel hypergraph learning framework
that uses a two-level neural message passing strategy to accurately and
efficiently propagate information through hypergraphs. The flexible design of
HyperSAGE facilitates different ways of aggregating neighborhood information.
Unlike the majority of related work which is transductive, our approach,
inspired by the popular GraphSAGE method, is inductive. Thus, it can also be
used on previously unseen nodes, facilitating deployment in problems such as
evolving or partially observed hypergraphs. Through extensive experimentation,
we show that HyperSAGE outperforms state-of-the-art hypergraph learning methods
on representative benchmark datasets. We also demonstrate that the higher
expressive power of HyperSAGE makes it more stable in learning node
representations as compared to the alternatives.
</p>
<a href="http://arxiv.org/abs/2010.04558" target="_blank">arXiv:2010.04558</a> [<a href="http://arxiv.org/pdf/2010.04558" target="_blank">pdf</a>]

<h2>Anomaly detection of energy consumption in buildings: A review, current trends and new perspectives. (arXiv:2010.04560v1 [cs.CY])</h2>
<h3>Yassine Himeur, Abdullah Alsalemi, Faycal Bensaali, Abbes Amira</h3>
<p>Enormous amounts of data are being produced everyday by submeters and smart
sensors installed in different kinds of buildings. If leveraged properly, that
data could assist end-users, energy producers and utility companies in
detecting anomalous power consumption and understanding the causes of each
anomaly. Therefore, anomaly detection could stop a minor problem to become
widespread, costly and time-consuming issue. Moreover, this will help in better
decision-making to reduce wasted energy and promote sustainable and energy
efficiency behavior. In this regard, this paper is proposed to indepthly review
existing frameworks of anomaly detection in power consumption and provide a
critical analysis of existing solutions. Specifically, a comprehensive survey
is introduced, in which a novel taxonomy is introduced to classify existing
algorithms based on different factors adopted in their implementation, such as
the machine learning algorithm, feature extraction approach, detection level,
computing platform, application scenario and privacy preservation. To the best
of the authors' knowledge, this is the first review article that discusses the
anomaly detection in building energy consumption. Moving forward, important
findings along with domain-specific problems, difficulties and challenges that
remain unresolved are thoroughly discussed, including the absence of: (i)
precise definitions of anomalous power consumptions, (ii) annotated datasets,
(iii) unified metrics to assess the performance of existing solutions, and (iv)
platforms for reproducibility. Following, insights about current research
trends that anomaly detection technology needs to target for widespreading its
application and facilitate its implementation are described before deriving a
set of challenging future directions attracting significant research and
development attention.
</p>
<a href="http://arxiv.org/abs/2010.04560" target="_blank">arXiv:2010.04560</a> [<a href="http://arxiv.org/pdf/2010.04560" target="_blank">pdf</a>]

<h2>Task-Space Control Interface for SoftBank Humanoid Robots and its Human-Robot Interaction Applications. (arXiv:2010.04573v1 [cs.RO])</h2>
<h3>Anastasia Bolotnikova, Pierre Gergondet, Arnaud Tanguy, S&#xe9;bastien Courtois, Abderrahmane Kheddar</h3>
<p>We present an open-source software interface, called mc_naoqi, that allows to
perform whole-body task-space Quadratic Programming based control, implemented
in mc_rtc framework, on the SoftBank Robotics Europe humanoid robots. We
describe the control interface, associated robot description packages, robot
modules and sample whole-body controllers. We demonstrate the use of these
tools in simulation for a robot interacting with a human model. Finally, we
showcase and discuss the use of the developed open-source tools for running the
human-robot close contact interaction experiments with real human subjects
inspired from assistance scenarios.
</p>
<a href="http://arxiv.org/abs/2010.04573" target="_blank">arXiv:2010.04573</a> [<a href="http://arxiv.org/pdf/2010.04573" target="_blank">pdf</a>]

<h2>HENIN: Learning Heterogeneous Neural Interaction Networks for Explainable Cyberbullying Detection on Social Media. (arXiv:2010.04576v1 [cs.CL])</h2>
<h3>Hsin-Yu Chen, Cheng-Te Li</h3>
<p>In the computational detection of cyberbullying, existing work largely
focused on building generic classifiers that rely exclusively on text analysis
of social media sessions. Despite their empirical success, we argue that a
critical missing piece is the model explainability, i.e., why a particular
piece of media session is detected as cyberbullying. In this paper, therefore,
we propose a novel deep model, HEterogeneous Neural Interaction Networks
(HENIN), for explainable cyberbullying detection. HENIN contains the following
components: a comment encoder, a post-comment co-attention sub-network, and
session-session and post-post interaction extractors. Extensive experiments
conducted on real datasets exhibit not only the promising performance of HENIN,
but also highlight evidential comments so that one can understand why a media
session is identified as cyberbullying.
</p>
<a href="http://arxiv.org/abs/2010.04576" target="_blank">arXiv:2010.04576</a> [<a href="http://arxiv.org/pdf/2010.04576" target="_blank">pdf</a>]

<h2>Denoising Multi-Source Weak Supervision for Neural Text Classification. (arXiv:2010.04582v1 [cs.CL])</h2>
<h3>Wendi Ren, Yinghao Li, Hanting Su, David Kartchner, Cassie Mitchell, Chao Zhang</h3>
<p>We study the problem of learning neural text classifiers without using any
labeled data, but only easy-to-provide rules as multiple weak supervision
sources. This problem is challenging because rule-induced weak labels are often
noisy and incomplete. To address these two challenges, we design a label
denoiser, which estimates the source reliability using a conditional soft
attention mechanism and then reduces label noise by aggregating rule-annotated
weak labels. The denoised pseudo labels then supervise a neural classifier to
predicts soft labels for unmatched samples, which address the rule coverage
issue. We evaluate our model on five benchmarks for sentiment, topic, and
relation classifications. The results show that our model outperforms
state-of-the-art weakly-supervised and semi-supervised methods consistently,
and achieves comparable performance with fully-supervised methods even without
any labeled data. Our code can be found at
https://github.com/weakrules/Denoise-multi-weak-sources.
</p>
<a href="http://arxiv.org/abs/2010.04582" target="_blank">arXiv:2010.04582</a> [<a href="http://arxiv.org/pdf/2010.04582" target="_blank">pdf</a>]

<h2>Identifying Risk of Opioid Use Disorder for Patients Taking Opioid Medications with Deep Learning. (arXiv:2010.04589v1 [cs.LG])</h2>
<h3>Xinyu Dong, Jianyuan Deng, Sina Rashidian, Kayley Abell-Hart, Wei Hou, Richard N Rosenthal, Mary Saltz, Joel Saltz, Fusheng Wang</h3>
<p>The United States is experiencing an opioid epidemic, and there were more
than 10 million opioid misusers aged 12 or older each year. Identifying
patients at high risk of Opioid Use Disorder (OUD) can help to make early
clinical interventions to reduce the risk of OUD. Our goal is to predict OUD
patients among opioid prescription users through analyzing electronic health
records with machine learning and deep learning methods. This will help us to
better understand the diagnoses of OUD, providing new insights on opioid
epidemic. Electronic health records of patients who have been prescribed with
medications containing active opioid ingredients were extracted from Cerner
Health Facts database between January 1, 2008 and December 31, 2017. Long
Short-Term Memory (LSTM) models were applied to predict opioid use disorder
risk in the future based on recent five encounters, and compared to Logistic
Regression, Random Forest, Decision Tree and Dense Neural Network. Prediction
performance was assessed using F-1 score, precision, recall, and AUROC. Our
temporal deep learning model provided promising prediction results which
outperformed other methods, with a F1 score of 0.8023 and AUCROC of 0.9369. The
model can identify OUD related medications and vital signs as important
features for the prediction. LSTM based temporal deep learning model is
effective on predicting opioid use disorder using a patient past history of
electronic health records, with minimal domain knowledge. It has potential to
improve clinical decision support for early intervention and prevention to
combat the opioid epidemic.
</p>
<a href="http://arxiv.org/abs/2010.04589" target="_blank">arXiv:2010.04589</a> [<a href="http://arxiv.org/pdf/2010.04589" target="_blank">pdf</a>]

<h2>Contrastive Learning with Hard Negative Samples. (arXiv:2010.04592v1 [cs.LG])</h2>
<h3>Joshua Robinson, Ching-Yao Chuang, Suvrit Sra, Stefanie Jegelka</h3>
<p>We consider the question: how can you sample good negative examples for
contrastive learning? We argue that, as with metric learning, learning
contrastive representations benefits from hard negative samples (i.e., points
that are difficult to distinguish from an anchor point). The key challenge
toward using hard negatives is that contrastive methods must remain
unsupervised, making it infeasible to adopt existing negative sampling
strategies that use label information. In response, we develop a new class of
unsupervised methods for selecting hard negative samples where the user can
control the amount of hardness. A limiting case of this sampling results in a
representation that tightly clusters each class, and pushes different classes
as far apart as possible. The proposed method improves downstream performance
across multiple modalities, requires only few additional lines of code to
implement, and introduces no computational overhead.
</p>
<a href="http://arxiv.org/abs/2010.04592" target="_blank">arXiv:2010.04592</a> [<a href="http://arxiv.org/pdf/2010.04592" target="_blank">pdf</a>]

<h2>GRF: Learning a General Radiance Field for 3D Scene Representation and Rendering. (arXiv:2010.04595v1 [cs.CV])</h2>
<h3>Alex Trevithick, Bo Yang</h3>
<p>We present a simple yet powerful implicit neural function that can represent
and render arbitrarily complex 3D scenes in a single network only from 2D
observations. The function models 3D scenes as a general radiance field, which
takes a set of posed 2D images as input, constructs an internal representation
for each 3D point of the scene, and renders the corresponding appearance and
geometry of any 3D point viewing from an arbitrary angle. The key to our
approach is to explicitly integrate the principle of multi-view geometry to
obtain the internal representations from observed 2D views, guaranteeing the
learned implicit representations meaningful and multi-view consistent. In
addition, we introduce an effective neural module to learn general features for
each pixel in 2D images, allowing the constructed internal 3D representations
to be remarkably general as well. Extensive experiments demonstrate the
superiority of our approach.
</p>
<a href="http://arxiv.org/abs/2010.04595" target="_blank">arXiv:2010.04595</a> [<a href="http://arxiv.org/pdf/2010.04595" target="_blank">pdf</a>]

<h2>Integrating Intrinsic and Extrinsic Explainability: The Relevance of Understanding Neural Networks for Human-Robot Interaction. (arXiv:2010.04602v1 [cs.RO])</h2>
<h3>Tom Weber, Stefan Wermter</h3>
<p>Explainable artificial intelligence (XAI) can help foster trust in and
acceptance of intelligent and autonomous systems. Moreover, understanding the
motivation for an agent's behavior results in better and more successful
collaborations between robots and humans. However, not only can humans benefit
from a robot's explanation but the robot itself can also benefit from
explanations given to him. Currently, most attention is paid to explaining deep
neural networks and black-box models. However, a lot of these approaches are
not applicable to humanoid robots. Therefore, in this position paper, current
problems with adapting XAI methods to explainable neurorobotics are described.
Furthermore, NICO, an open-source humanoid robot platform, is introduced and
how the interaction of intrinsic explanations by the robot itself and extrinsic
explanations provided by the environment enable efficient robotic behavior.
</p>
<a href="http://arxiv.org/abs/2010.04602" target="_blank">arXiv:2010.04602</a> [<a href="http://arxiv.org/pdf/2010.04602" target="_blank">pdf</a>]

<h2>Instance Weighted Incremental Evolution Strategies for Reinforcement Learning in Dynamic Environments. (arXiv:2010.04605v1 [cs.LG])</h2>
<h3>Zhi Wang, Chunlin Chen, Daoyi Dong</h3>
<p>Evolution strategies (ES), as a family of black-box optimization algorithms,
recently emerge as a scalable alternative to reinforcement learning (RL)
approaches such as Q-learning or policy gradient, and are much faster when many
central processing units (CPUs) are available due to better parallelization. In
this paper, we propose a systematic incremental learning method for ES in
dynamic environments. The goal is to adjust previously learned policy to a new
one incrementally whenever the environment changes. We incorporate an instance
weighting mechanism with ES to facilitate its learning adaptation, while
retaining scalability of ES. During parameter updating, higher weights are
assigned to instances that contain more new knowledge, thus encouraging the
search distribution to move towards new promising areas of parameter space. We
propose two easy-to-implement metrics to calculate the weights: instance
novelty and instance quality. Instance novelty measures an instance's
difference from the previous optimum in the original environment, while
instance quality corresponds to how well an instance performs in the new
environment. The resulting algorithm, Instance Weighted Incremental Evolution
Strategies (IW-IES), is verified to achieve significantly improved performance
on a suite of robot navigation tasks. This paper thus introduces a family of
scalable ES algorithms for RL domains that enables rapid learning adaptation to
dynamic environments.
</p>
<a href="http://arxiv.org/abs/2010.04605" target="_blank">arXiv:2010.04605</a> [<a href="http://arxiv.org/pdf/2010.04605" target="_blank">pdf</a>]

<h2>Learning Binary Trees via Sparse Relaxation. (arXiv:2010.04627v1 [cs.LG])</h2>
<h3>Valentina Zantedeschi, Matt J. Kusner, Vlad Niculae</h3>
<p>One of the most classical problems in machine learning is how to learn binary
trees that split data into useful partitions. From classification/regression
via decision trees to hierarchical clustering, binary trees are useful because
they (a) are often easy to visualize; (b) make computationally-efficient
predictions; and (c) allow for flexible partitioning. Because of this there has
been extensive research on how to learn such trees that generally fall into one
of three categories: 1. greedy node-by-node optimization; 2. probabilistic
relaxations for differentiability; 3. mixed-integer programs (MIP). Each of
these have downsides: greedy can myopically choose poor splits, probabilistic
relaxations do not have principled ways to prune trees, MIP methods can be slow
on large problems and may not generalize. In this work we derive a novel sparse
relaxation for binary tree learning. By deriving a new MIP and sparsely
relaxing it, our approach is able to learn tree splits and tree pruning using
argmin differentiation. We demonstrate how our approach is easily visualizable
and is competitive with current tree-based approaches in
classification/regression and hierarchical clustering. Source code is available
at this http URL .
</p>
<a href="http://arxiv.org/abs/2010.04627" target="_blank">arXiv:2010.04627</a> [<a href="http://arxiv.org/pdf/2010.04627" target="_blank">pdf</a>]

<h2>Attaining Real-Time Super-Resolution for Microscopic Images Using GAN. (arXiv:2010.04634v1 [eess.IV])</h2>
<h3>Vibhu Bhatia, Yatender Kumar</h3>
<p>In the last few years, several deep learning models, especially Generative
Adversarial Networks have received a lot of attention for the task of Single
Image Super-Resolution (SISR). These methods focus on building an end-to-end
framework, which produce a high resolution(SR) image from a given low
resolution(LR) image in a single step to achieve state-of-the-art performance.
This paper focuses on improving an existing deep-learning based method to
perform Super-Resolution Microscopy in real-time using a standard GPU. For
this, we first propose a tiling strategy, which takes advantage of parallelism
provided by a GPU to speed up the network training process. Further, we suggest
simple changes to the architecture of the generator and the discriminator of
SRGAN. Subsequently, We compare the quality and the running time for the
outputs produced by our model, opening its applications in different areas like
low-end benchtop and even mobile microscopy. Finally, we explore the
possibility of the trained network to produce High-Resolution HR outputs for
different domains.
</p>
<a href="http://arxiv.org/abs/2010.04634" target="_blank">arXiv:2010.04634</a> [<a href="http://arxiv.org/pdf/2010.04634" target="_blank">pdf</a>]

<h2>Recurrent babbling: evaluating the acquisition of grammar from limited input data. (arXiv:2010.04637v1 [cs.CL])</h2>
<h3>Ludovica Pannitto, Aur&#xe9;lie Herbelot</h3>
<p>Recurrent Neural Networks (RNNs) have been shown to capture various aspects
of syntax from raw linguistic input. In most previous experiments, however,
learning happens over unrealistic corpora, which do not reflect the type and
amount of data a child would be exposed to. This paper remedies this state of
affairs by training a Long Short-Term Memory network (LSTM) over a
realistically sized subset of child-directed input. The behaviour of the
network is analysed over time using a novel methodology which consists in
quantifying the level of grammatical abstraction in the model's generated
output (its "babbling"), compared to the language it has been exposed to. We
show that the LSTM indeed abstracts new structuresas learning proceeds.
</p>
<a href="http://arxiv.org/abs/2010.04637" target="_blank">arXiv:2010.04637</a> [<a href="http://arxiv.org/pdf/2010.04637" target="_blank">pdf</a>]

<h2>Baseline and Triangulation Geometry in a Standard Plenoptic Camera. (arXiv:2010.04638v1 [cs.IR])</h2>
<h3>Christopher Hahne, Amar Aggoun, Vladan Velisavljevic, Susanne Fiebig, Matthias Pesch</h3>
<p>In this paper, we demonstrate light field triangulation to determine depth
distances and baselines in a plenoptic camera. Advances in micro lenses and
image sensors have enabled plenoptic cameras to capture a scene from different
viewpoints with sufficient spatial resolution. While object distances can be
inferred from disparities in a stereo viewpoint pair using triangulation, this
concept remains ambiguous when applied in the case of plenoptic cameras. We
present a geometrical light field model allowing the triangulation to be
applied to a plenoptic camera in order to predict object distances or specify
baselines as desired. It is shown that distance estimates from our novel method
match those of real objects placed in front of the camera. Additional benchmark
tests with an optical design software further validate the model's accuracy
with deviations of less than +-0.33 % for several main lens types and focus
settings. A variety of applications in the automotive and robotics field can
benefit from this estimation model.
</p>
<a href="http://arxiv.org/abs/2010.04638" target="_blank">arXiv:2010.04638</a> [<a href="http://arxiv.org/pdf/2010.04638" target="_blank">pdf</a>]

<h2>High-order Semantic Role Labeling. (arXiv:2010.04641v1 [cs.CL])</h2>
<h3>Zuchao Li, Hai Zhao, Rui Wang, Kevin Parnow</h3>
<p>Semantic role labeling is primarily used to identify predicates, arguments,
and their semantic relationships. Due to the limitations of modeling methods
and the conditions of pre-identified predicates, previous work has focused on
the relationships between predicates and arguments and the correlations between
arguments at most, while the correlations between predicates have been
neglected for a long time. High-order features and structure learning were very
common in modeling such correlations before the neural network era. In this
paper, we introduce a high-order graph structure for the neural semantic role
labeling model, which enables the model to explicitly consider not only the
isolated predicate-argument pairs but also the interaction between the
predicate-argument pairs. Experimental results on 7 languages of the CoNLL-2009
benchmark show that the high-order structural learning techniques are
beneficial to the strong performing SRL models and further boost our baseline
to achieve new state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/2010.04641" target="_blank">arXiv:2010.04641</a> [<a href="http://arxiv.org/pdf/2010.04641" target="_blank">pdf</a>]

<h2>Torch-Points3D: A Modular Multi-Task Frameworkfor Reproducible Deep Learning on 3D Point Clouds. (arXiv:2010.04642v1 [cs.CV])</h2>
<h3>Thomas Chaton, Nicolas Chaulet, Sofiane Horache, Loic Landrieu</h3>
<p>We introduce Torch-Points3D, an open-source framework designed to facilitate
the use of deep networks on3D data. Its modular design, efficient
implementation, and user-friendly interfaces make it a relevant tool for
research and productization alike. Beyond multiple quality-of-life features,
our goal is to standardize a higher level of transparency and reproducibility
in 3D deep learning research, and to lower its barrier to entry. In this paper,
we present the design principles of Torch-Points3D, as well as extensive
benchmarks of multiple state-of-the-art algorithms and inference schemes across
several datasets and tasks. The modularity of Torch-Points3D allows us to
design fair and rigorous experimental protocols in which all methods are
evaluated in the same conditions. The Torch-Points3D repository
:https://github.com/nicolas-chaulet/torch-points3d
</p>
<a href="http://arxiv.org/abs/2010.04642" target="_blank">arXiv:2010.04642</a> [<a href="http://arxiv.org/pdf/2010.04642" target="_blank">pdf</a>]

<h2>Deep RL With Information Constrained Policies: Generalization in Continuous Control. (arXiv:2010.04646v1 [cs.LG])</h2>
<h3>Tyler Malloy, Chris R. Sims, Tim Klinger, Miao Liu, Matthew Riemer, Gerald Tesauro</h3>
<p>Biological agents learn and act intelligently in spite of a highly limited
capacity to process and store information. Many real-world problems involve
continuous control, which represents a difficult task for artificial
intelligence agents. In this paper we explore the potential learning advantages
a natural constraint on information flow might confer onto artificial agents in
continuous control tasks. We focus on the model-free reinforcement learning
(RL) setting and formalize our approach in terms of an information-theoretic
constraint on the complexity of learned policies. We show that our approach
emerges in a principled fashion from the application of rate-distortion theory.
We implement a novel Capacity-Limited Actor-Critic (CLAC) algorithm and situate
it within a broader family of RL algorithms such as the Soft Actor Critic (SAC)
and Mutual Information Reinforcement Learning (MIRL) algorithm. Our experiments
using continuous control tasks show that compared to alternative approaches,
CLAC offers improvements in generalization between training and modified test
environments. This is achieved in the CLAC model while displaying the high
sample efficiency of similar methods.
</p>
<a href="http://arxiv.org/abs/2010.04646" target="_blank">arXiv:2010.04646</a> [<a href="http://arxiv.org/pdf/2010.04646" target="_blank">pdf</a>]

<h2>Learning Invariant Representations and Risks for Semi-supervised Domain Adaptation. (arXiv:2010.04647v1 [cs.LG])</h2>
<h3>Bo Li, Yezhen Wang, Shanghang Zhang, Dongsheng Li, Trevor Darrell, Kurt Keutzer, Han Zhao</h3>
<p>The success of supervised learning hinges on the assumption that the training
and test data come from the same underlying distribution, which is often not
valid in practice due to potential distribution shift. In light of this, most
existing methods for unsupervised domain adaptation focus on achieving
domain-invariant representations and small source domain error. However, recent
works have shown that this is not sufficient to guarantee good generalization
on the target domain, and in fact, is provably detrimental under label
distribution shift. Furthermore, in many real-world applications it is often
feasible to obtain a small amount of labeled data from the target domain and
use them to facilitate model training with source data. Inspired by the above
observations, in this paper we propose the first method that aims to
simultaneously learn invariant representations and risks under the setting of
semi-supervised domain adaptation (Semi-DA). First, we provide a finite sample
bound for both classification and regression problems under Semi-DA. The bound
suggests a principled way to obtain target generalization, i.e. by aligning
both the marginal and conditional distributions across domains in feature
space. Motivated by this, we then introduce the LIRR algorithm for jointly
\textbf{L}earning \textbf{I}nvariant \textbf{R}epresentations and
\textbf{R}isks. Finally, extensive experiments are conducted on both
classification and regression tasks, which demonstrates LIRR consistently
achieves state-of-the-art performance and significant improvements compared
with the methods that only learn invariant representations or invariant risks.
</p>
<a href="http://arxiv.org/abs/2010.04647" target="_blank">arXiv:2010.04647</a> [<a href="http://arxiv.org/pdf/2010.04647" target="_blank">pdf</a>]

<h2>LSTMs Compose (and Learn) Bottom-Up. (arXiv:2010.04650v1 [cs.CL])</h2>
<h3>Naomi Saphra, Adam Lopez</h3>
<p>Recent work in NLP shows that LSTM language models capture hierarchical
structure in language data. In contrast to existing work, we consider the
\textit{learning} process that leads to their compositional behavior. For a
closer look at how an LSTM's sequential representations are composed
hierarchically, we present a related measure of Decompositional Interdependence
(DI) between word meanings in an LSTM, based on their gate interactions. We
connect this measure to syntax with experiments on English language data, where
DI is higher on pairs of words with lower syntactic distance. To explore the
inductive biases that cause these compositional representations to arise during
training, we conduct simple experiments on synthetic data. These synthetic
experiments support a specific hypothesis about how hierarchical structures are
discovered over the course of training: that LSTM constituent representations
are learned bottom-up, relying on effective representations of their shorter
children, rather than learning the longer-range relations independently from
children.
</p>
<a href="http://arxiv.org/abs/2010.04650" target="_blank">arXiv:2010.04650</a> [<a href="http://arxiv.org/pdf/2010.04650" target="_blank">pdf</a>]

<h2>Scaling Systematic Literature Reviews with Machine Learning Pipelines. (arXiv:2010.04665v1 [cs.CL])</h2>
<h3>Seraphina Goldfarb-Tarrant, Alexander Robertson, Jasmina Lazic, Theodora Tsouloufi, Louise Donnison, Karen Smyth</h3>
<p>Systematic reviews, which entail the extraction of data from large numbers of
scientific documents, are an ideal avenue for the application of machine
learning. They are vital to many fields of science and philanthropy, but are
very time-consuming and require experts. Yet the three main stages of a
systematic review are easily done automatically: searching for documents can be
done via APIs and scrapers, selection of relevant documents can be done via
binary classification, and extraction of data can be done via
sequence-labelling classification. Despite the promise of automation for this
field, little research exists that examines the various ways to automate each
of these tasks. We construct a pipeline that automates each of these aspects,
and experiment with many human-time vs. system quality trade-offs. We test the
ability of classifiers to work well on small amounts of data and to generalise
to data from countries not represented in the training data. We test different
types of data extraction with varying difficulty in annotation, and five
different neural architectures to do the extraction. We find that we can get
surprising accuracy and generalisability of the whole pipeline system with only
2 weeks of human-expert annotation, which is only 15% of the time it takes to
do the whole review manually and can be repeated and extended to new data with
no additional effort.
</p>
<a href="http://arxiv.org/abs/2010.04665" target="_blank">arXiv:2010.04665</a> [<a href="http://arxiv.org/pdf/2010.04665" target="_blank">pdf</a>]

<h2>Learning Context-Free Languages with Nondeterministic Stack RNNs. (arXiv:2010.04674v1 [cs.CL])</h2>
<h3>Brian DuSell, David Chiang</h3>
<p>We present a differentiable stack data structure that simultaneously and
tractably encodes an exponential number of stack configurations, based on
Lang's algorithm for simulating nondeterministic pushdown automata. We call the
combination of this data structure with a recurrent neural network (RNN)
controller a Nondeterministic Stack RNN. We compare our model against existing
stack RNNs on various formal languages, demonstrating that our model converges
more reliably to algorithmic behavior on deterministic tasks, and achieves
lower cross-entropy on inherently nondeterministic tasks.
</p>
<a href="http://arxiv.org/abs/2010.04674" target="_blank">arXiv:2010.04674</a> [<a href="http://arxiv.org/pdf/2010.04674" target="_blank">pdf</a>]

<h2>A Clustering-Based Method for Automatic Educational Video Recommendation Using Deep Face-Features of Lecturers. (arXiv:2010.04676v1 [cs.MM])</h2>
<h3>Paulo R. C. Mendes, Eduardo S. Vieira, &#xc1;lan L. V. Guedes, Antonio J. G. Busson, S&#xe9;rgio Colcher</h3>
<p>Discovering and accessing specific content within educational video bases is
a challenging task, mainly because of the abundance of video content and its
diversity. Recommender systems are often used to enhance the ability to find
and select content. But, recommendation mechanisms, especially those based on
textual information, exhibit some limitations, such as being error-prone to
manually created keywords or due to imprecise speech recognition. This paper
presents a method for generating educational video recommendation using deep
face-features of lecturers without identifying them. More precisely, we use an
unsupervised face clustering mechanism to create relations among the videos
based on the lecturer's presence. Then, for a selected educational video taken
as a reference, we recommend the ones where the presence of the same lecturers
is detected. Moreover, we rank these recommended videos based on the amount of
time the referenced lecturers were present. For this task, we achieved a mAP
value of 99.165%.
</p>
<a href="http://arxiv.org/abs/2010.04676" target="_blank">arXiv:2010.04676</a> [<a href="http://arxiv.org/pdf/2010.04676" target="_blank">pdf</a>]

<h2>A Series of Unfortunate Counterfactual Events: the Role of Time in Counterfactual Explanations. (arXiv:2010.04687v1 [cs.AI])</h2>
<h3>Andrea Ferrario, Michele Loi</h3>
<p>Counterfactual explanations are a prominent example of post-hoc
interpretability methods in the explainable Artificial Intelligence research
domain. They provide individuals with alternative scenarios and a set of
recommendations to achieve a sought-after machine learning model outcome.
Recently, the literature has identified desiderata of counterfactual
explanations, such as feasibility, actionability and sparsity that should
support their applicability in real-world contexts. However, we show that the
literature has neglected the problem of the time dependency of counterfactual
explanations. We argue that, due to their time dependency and because of the
provision of recommendations, even feasible, actionable and sparse
counterfactual explanations may not be appropriate in real-world applications.
This is due to the possible emergence of what we call "unfortunate
counterfactual events." These events may occur due to the retraining of machine
learning models whose outcomes have to be explained via counterfactual
explanation. Series of unfortunate counterfactual events frustrate the efforts
of those individuals who successfully implemented the recommendations of
counterfactual explanations. This negatively affects people's trust in the
ability of institutions to provide machine learning-supported decisions
consistently. We introduce an approach to address the problem of the emergence
of unfortunate counterfactual events that makes use of histories of
counterfactual explanations. In the final part of the paper we propose an
ethical analysis of two distinct strategies to cope with the challenge of
unfortunate counterfactual events. We show that they respond to an ethically
responsible imperative to preserve the trustworthiness of credit lending
organizations, the decision models they employ, and the social-economic
function of credit lending.
</p>
<a href="http://arxiv.org/abs/2010.04687" target="_blank">arXiv:2010.04687</a> [<a href="http://arxiv.org/pdf/2010.04687" target="_blank">pdf</a>]

<h2>LaND: Learning to Navigate from Disengagements. (arXiv:2010.04689v1 [cs.RO])</h2>
<h3>Gregory Kahn, Pieter Abbeel, Sergey Levine</h3>
<p>Consistently testing autonomous mobile robots in real world scenarios is a
necessary aspect of developing autonomous navigation systems. Each time the
human safety monitor disengages the robot's autonomy system due to the robot
performing an undesirable maneuver, the autonomy developers gain insight into
how to improve the autonomy system. However, we believe that these
disengagements not only show where the system fails, which is useful for
troubleshooting, but also provide a direct learning signal by which the robot
can learn to navigate. We present a reinforcement learning approach for
learning to navigate from disengagements, or LaND. LaND learns a neural network
model that predicts which actions lead to disengagements given the current
sensory observation, and then at test time plans and executes actions that
avoid disengagements. Our results demonstrate LaND can successfully learn to
navigate in diverse, real world sidewalk environments, outperforming both
imitation learning and reinforcement learning approaches. Videos, code, and
other material are available on our website
https://sites.google.com/view/sidewalk-learning
</p>
<a href="http://arxiv.org/abs/2010.04689" target="_blank">arXiv:2010.04689</a> [<a href="http://arxiv.org/pdf/2010.04689" target="_blank">pdf</a>]

<h2>Uncertainty over Uncertainty: Investigating the Assumptions, Annotations, and Text Measurements of Economic Policy Uncertainty. (arXiv:2010.04706v1 [cs.CL])</h2>
<h3>Katherine A. Keith, Christoph Teichmann, Brendan O&#x27;Connor, Edgar Meij</h3>
<p>Methods and applications are inextricably linked in science, and in
particular in the domain of text-as-data. In this paper, we examine one such
text-as-data application, an established economic index that measures economic
policy uncertainty from keyword occurrences in news. This index, which is shown
to correlate with firm investment, employment, and excess market returns, has
had substantive impact in both the private sector and academia. Yet, as we
revisit and extend the original authors' annotations and text measurements we
find interesting text-as-data methodological research questions: (1) Are
annotator disagreements a reflection of ambiguity in language? (2) Do
alternative text measurements correlate with one another and with measures of
external predictive validity? We find for this application (1) some annotator
disagreements of economic policy uncertainty can be attributed to ambiguity in
language, and (2) switching measurements from keyword-matching to supervised
machine learning classifiers results in low correlation, a concerning
implication for the validity of the index.
</p>
<a href="http://arxiv.org/abs/2010.04706" target="_blank">arXiv:2010.04706</a> [<a href="http://arxiv.org/pdf/2010.04706" target="_blank">pdf</a>]

<h2>PathoNet: Deep learning assisted evaluation of Ki-67 and tumor infiltrating lymphocytes (TILs) as prognostic factors in breast cancer; A large dataset and baseline. (arXiv:2010.04713v1 [eess.IV])</h2>
<h3>Farzin Negahbani, Rasool Sabzi, Bita Pakniyat Jahromi, Fatemeh Movahedi, Mahsa Kohandel Shirazi, Shayan Majidi, Dena Firouzabadi, Amirreza Dehganian</h3>
<p>The nuclear protein Ki-67 and Tumor infiltrating lymphocytes (TILs) have been
introduced as prognostic factors in predicting tumor progression and its
treatment response. The value of the Ki-67 index and TILs in approach to
heterogeneous tumors such as Breast cancer (BC), known as the most common
cancer in women worldwide, has been highlighted in the literature. Due to the
indeterminable and subjective nature of Ki-67 as well as TILs scoring,
automated methods using machine learning, specifically approaches based on deep
learning, have attracted attention. Yet, deep learning methods need
considerable annotated data. In the absence of publicly available benchmarks
for BC Ki-67 stained cell detection and further annotated classification of
cells, we propose SHIDC-BC-Ki-67 as a dataset for the aforementioned purpose.
We also introduce a novel pipeline and a backend, namely PathoNet for Ki-67
immunostained cell detection and classification and simultaneous determination
of intratumoral TILs score. Further, we show that despite facing challenges,
our proposed backend, PathoNet, outperforms the state of the art methods
proposed to date in the harmonic mean measure.
</p>
<a href="http://arxiv.org/abs/2010.04713" target="_blank">arXiv:2010.04713</a> [<a href="http://arxiv.org/pdf/2010.04713" target="_blank">pdf</a>]

<h2>Unsupervised 3D Brain Anomaly Detection. (arXiv:2010.04717v1 [eess.IV])</h2>
<h3>Jaime Simarro Viana, Ezequiel de la Rosa, Thijs Vande Vyvere, David Robben, Diana M. Sima</h3>
<p>Anomaly detection (AD) is the identification of data samples that do not fit
a learned data distribution. As such, AD systems can help physicians to
determine the presence, severity, and extension of a pathology. Deep generative
models, such as Generative Adversarial Networks (GANs), can be exploited to
capture anatomical variability. Consequently, any outlier (i.e., sample falling
outside of the learned distribution) can be detected as an abnormality in an
unsupervised fashion. By using this method, we can not only detect expected or
known lesions, but we can even unveil previously unrecognized biomarkers. To
the best of our knowledge, this study exemplifies the first AD approach that
can efficiently handle volumetric data and detect 3D brain anomalies in one
single model. Our proposal is a volumetric and high-detail extension of the 2D
f-AnoGAN model obtained by combining a state-of-the-art 3D GAN with refinement
training steps. In experiments using non-contrast computed tomography images
from traumatic brain injury (TBI) patients, the model detects and localizes TBI
abnormalities with an area under the ROC curve of ~75%. Moreover, we test the
potential of the method for detecting other anomalies such as low quality
images, preprocessing inaccuracies, artifacts, and even the presence of
post-operative signs (such as a craniectomy or a brain shunt). The method has
potential for rapidly labeling abnormalities in massive imaging datasets, as
well as identifying new biomarkers.
</p>
<a href="http://arxiv.org/abs/2010.04717" target="_blank">arXiv:2010.04717</a> [<a href="http://arxiv.org/pdf/2010.04717" target="_blank">pdf</a>]

<h2>Integer Echo State Networks: Efficient Reservoir Computing for Digital Hardware. (arXiv:1706.00280v3 [cs.NE] UPDATED)</h2>
<h3>Denis Kleyko, E. Paxon Frady, Mansour Kheffache, Evgeny Osipov</h3>
<p>We propose an approximation of Echo State Networks (ESN) that can be
efficiently implemented on digital hardware based on the mathematics of
hyperdimensional computing. The reservoir of the proposed integer Echo State
Network (intESN) is a vector containing only n-bits integers (where n&lt;8 is
normally sufficient for a satisfactory performance). The recurrent matrix
multiplication is replaced with an efficient cyclic shift operation. The
proposed intESN approach is verified with typical tasks in reservoir computing:
memorizing of a sequence of inputs; classifying time-series; learning dynamic
processes. Such architecture results in dramatic improvements in memory
footprint and computational efficiency, with minimal performance loss. The
experiments on a field-programmable gate array confirm that the proposed intESN
approach is much more energy efficient than the conventional ESN.
</p>
<a href="http://arxiv.org/abs/1706.00280" target="_blank">arXiv:1706.00280</a> [<a href="http://arxiv.org/pdf/1706.00280" target="_blank">pdf</a>]

<h2>Hartley Spectral Pooling for Deep Learning. (arXiv:1810.04028v2 [cs.CV] UPDATED)</h2>
<h3>Hao Zhang, Jianwei Ma</h3>
<p>In most convolution neural networks (CNNs), downsampling hidden layers is
adopted for increasing computation efficiency and the receptive field size.
Such operation is commonly so-called pooling. Maximation and averaging over
sliding windows (max/average pooling), and plain downsampling in the form of
strided convolution are popular pooling methods. Since the pooling is a lossy
procedure, a motivation of our work is to design a new pooling approach for
less lossy in the dimensionality reduction. Inspired by the Fourier spectral
pooling(FSP) proposed by Rippel et. al. [1], we present the Hartley transform
based spectral pooling method in CNNs. Compared with FSP, the proposed spectral
pooling avoids the use of complex arithmetic for frequency representation and
reduces the computation. Spectral pooling preserves more structure features for
network's discriminability than max and average pooling. We empirically show
that Hartley spectral pooling gives rise to the convergence of training CNNs on
MNIST and CIFAR-10 datasets.
</p>
<a href="http://arxiv.org/abs/1810.04028" target="_blank">arXiv:1810.04028</a> [<a href="http://arxiv.org/pdf/1810.04028" target="_blank">pdf</a>]

<h2>gpuRIR: A Python Library for Room Impulse Response Simulation with GPU Acceleration. (arXiv:1810.11359v4 [eess.AS] UPDATED)</h2>
<h3>David Diaz-Guerra, Antonio Miguel, Jose R. Beltran</h3>
<p>The Image Source Method (ISM) is one of the most employed techniques to
calculate acoustic Room Impulse Responses (RIRs), however, its computational
complexity grows fast with the reverberation time of the room and its
computation time can be prohibitive for some applications where a huge number
of RIRs are needed. In this paper, we present a new implementation that
dramatically improves the computation speed of the ISM by using Graphic
Processing Units (GPUs) to parallelize both the simulation of multiple RIRs and
the computation of the images inside each RIR. Additional speedups were
achieved by exploiting the mixed precision capabilities of the newer GPUs and
by using lookup tables. We provide a Python library under GNU license that can
be easily used without any knowledge about GPU programming and we show that it
is about 100 times faster than other state of the art CPU libraries. It may
become a powerful tool for many applications that need to perform a large
number of acoustic simulations, such as training machine learning systems for
audio signal processing, or for real-time room acoustics simulations for
immersive multimedia systems, such as augmented or virtual reality.
</p>
<a href="http://arxiv.org/abs/1810.11359" target="_blank">arXiv:1810.11359</a> [<a href="http://arxiv.org/pdf/1810.11359" target="_blank">pdf</a>]

<h2>Soft-Autoencoder and Its Wavelet Shrinkage Interpretation. (arXiv:1812.11675v3 [cs.LG] UPDATED)</h2>
<h3>Fenglei Fan, Mengzhou Li, Yueyang Teng, Ge Wang</h3>
<p>Recently, deep learning becomes the main focus of machine learning research
and has greatly impacted many fields. However, deep learning is criticized for
lack of interpretability. As a successful unsupervised model in deep learning,
the autoencoder embraces a wide spectrum of applications, yet it suffers from
the model opaqueness as well. In this paper, we propose a new type of
convolutional autoencoders, termed as Soft-Autoencoder (Soft-AE), in which the
activation functions of encoding layers are implemented with adaptable
soft-thresholding units while decoding layers are realized with linear units.
Consequently, Soft-AE can be naturally interpreted as a learned cascaded
wavelet shrinkage system. Our denoising experiments demonstrate that Soft-AE
not only is interpretable but also offers a competitive performance relative to
its counterparts. Furthermore, we propose a generalized linear unit (GeLU) and
its truncated variant (tGeLU) to allow autoencoder for more tasks from
denoising to deblurring.
</p>
<a href="http://arxiv.org/abs/1812.11675" target="_blank">arXiv:1812.11675</a> [<a href="http://arxiv.org/pdf/1812.11675" target="_blank">pdf</a>]

<h2>Data-to-Text Generation with Style Imitation. (arXiv:1901.09501v3 [cs.CL] UPDATED)</h2>
<h3>Shuai Lin, Wentao Wang, Zichao Yang, Xiaodan Liang, Frank F. Xu, Eric Xing, Zhiting Hu</h3>
<p>Recent neural approaches to data-to-text generation have mostly focused on
improving content fidelity while lacking explicit control over writing styles
(e.g., word choices, sentence structures). More traditional systems use
templates to determine the realization of text. Yet manual or automatic
construction of high-quality templates is difficult, and a template acting as
hard constraints could harm content fidelity when it does not match the record
perfectly. We study a new way of stylistic control by using existing sentences
as soft templates. That is, the model learns to imitate the writing style of
any given exemplar sentence, with automatic adaptions to faithfully describe
the content record. The problem is challenging due to the lack of parallel
data. We develop a neural approach that includes a hybrid attention-copy
mechanism, learns with weak supervisions, and is enhanced with a new content
coverage constraint. We conduct experiments in restaurants and sports domains.
Results show our approach achieves stronger performance than a range of
comparison methods. Our approach balances well between content fidelity and
style control given exemplars that match the records to varying degrees.
</p>
<a href="http://arxiv.org/abs/1901.09501" target="_blank">arXiv:1901.09501</a> [<a href="http://arxiv.org/pdf/1901.09501" target="_blank">pdf</a>]

<h2>Toward Fast and Accurate Neural Chinese Word Segmentation with Multi-Criteria Learning. (arXiv:1903.04190v2 [cs.CL] UPDATED)</h2>
<h3>Weipeng Huang, Xingyi Cheng, Kunlong Chen, Taifeng Wang, Wei Chu</h3>
<p>The ambiguous annotation criteria lead to divergence of Chinese Word
Segmentation (CWS) datasets in various granularities. Multi-criteria Chinese
word segmentation aims to capture various annotation criteria among datasets
and leverage their common underlying knowledge. In this paper, we propose a
domain adaptive segmenter to exploit diverse criteria of various datasets. Our
model is based on Bidirectional Encoder Representations from Transformers
(BERT), which is responsible for introducing open-domain knowledge. Private and
shared projection layers are proposed to capture domain-specific knowledge and
common knowledge, respectively. We also optimize computational efficiency via
distillation, quantization, and compiler optimization. Experiments show that
our segmenter outperforms the previous state of the art (SOTA) models on 10 CWS
datasets with superior efficiency.
</p>
<a href="http://arxiv.org/abs/1903.04190" target="_blank">arXiv:1903.04190</a> [<a href="http://arxiv.org/pdf/1903.04190" target="_blank">pdf</a>]

<h2>CaseNet: Content-Adaptive Scale Interaction Networks for Scene Parsing. (arXiv:1904.08170v3 [cs.CV] UPDATED)</h2>
<h3>Xin Jin, Cuiling Lan, Wenjun Zeng, Zhizheng Zhang, Zhibo Chen</h3>
<p>Objects at different spatial positions in an image exhibit different scales.
Adaptive receptive fields are expected to capture suitable ranges of context
for accurate pixel level semantic prediction. Recently, atrous convolution with
different dilation rates has been used to generate features of multi-scales
through several branches which are then fused for prediction. However, there is
a lack of explicit interaction among the branches of different scales to
adaptively make full use of the contexts. In this paper, we propose a
Content-Adaptive Scale Interaction Network (CASINet) to exploit the multi-scale
features for scene parsing. We build CASINet based on the classic Atrous
Spatial Pyramid Pooling (ASPP) module, followed by a proposed contextual scale
interaction (CSI) module, and a scale adaptation (SA) module. Specifically, in
the CSI module, for each spatial position of some scale, instead of being
limited by a fixed set of convolutional filters that are shared across
different spatial positions for feature learning, we promote the adaptivity of
the convolutional filters to spatial positions. We achieve this by the context
interaction among the features of different scales. The SA module explicitly
and softly selects the suitable scale for each spatial position and each
channel. Ablation studies demonstrate the effectiveness of the proposed
modules. We achieve state-of-the-art performance on three scene parsing
benchmarks Cityscapes, ADE20K and LIP.
</p>
<a href="http://arxiv.org/abs/1904.08170" target="_blank">arXiv:1904.08170</a> [<a href="http://arxiv.org/pdf/1904.08170" target="_blank">pdf</a>]

<h2>Norm-based generalisation bounds for multi-class convolutional neural networks. (arXiv:1905.12430v4 [cs.LG] UPDATED)</h2>
<h3>Antoine Ledent, Waleed Mustafa, Yunwen Lei, Marius Kloft</h3>
<p>We show generalisation error bounds for deep learning with two main
improvements over the state of the art. (1) Our bounds have no explicit
dependence on the number of classes except for logarithmic factors. This holds
even when formulating the bounds in terms of the $L^2$-norm of the weight
matrices, where previous bounds exhibit at least a square-root dependence on
the number of classes. (2) We adapt the classic Rademacher analysis of DNNs to
incorporate weight sharing---a task of fundamental theoretical importance which
was previously attempted only under very restrictive assumptions. In our
results, each convolutional filter contributes only once to the bound,
regardless of how many times it is applied. Further improvements exploiting
pooling and sparse connections are provided. The presented bounds scale as the
norms of the parameter matrices, rather than the number of parameters. In
particular, contrary to bounds based on parameter counting, they are
asymptotically tight (up to log factors) when the weights approach
initialisation, making them suitable as a basic ingredient in bounds sensitive
to the optimisation procedure. We also show how to adapt the recent technique
of loss function augmentation to our situation to replace spectral norms by
empirical analogues whilst maintaining the advantages of our approach.
</p>
<a href="http://arxiv.org/abs/1905.12430" target="_blank">arXiv:1905.12430</a> [<a href="http://arxiv.org/pdf/1905.12430" target="_blank">pdf</a>]

<h2>Learning Representations by Humans, for Humans. (arXiv:1905.12686v3 [cs.LG] UPDATED)</h2>
<h3>Sophie Hilgard, Nir Rosenfeld, Mahzarin R. Banaji, Jack Cao, David C. Parkes</h3>
<p>The task of optimizing machines to support human decision-making is often
conflated with that of optimizing machines for accuracy even though they are
materially different. Whereas it is typical for learning systems to prescribe
actions through prediction, here we propose an approach in which the role of
machines is to reframe problems in order to directly support human decisions.
Inspired by the success of representation learning in promoting machine
performance, we frame the problem as one of learning representations that are
conducive to good human performance. This "Man Composed with Machine" framework
incorporates a human decision-making model directly into the representation
learning paradigm with optimization achieved through a novel human-in-the-loop
training procedure. We empirically demonstrate on various tasks and
representational forms that the framework is capable of learning
representations that better coincide with human decision-making processes and
can lead to good decisions.
</p>
<a href="http://arxiv.org/abs/1905.12686" target="_blank">arXiv:1905.12686</a> [<a href="http://arxiv.org/pdf/1905.12686" target="_blank">pdf</a>]

<h2>Online Multiple Pedestrians Tracking using Deep Temporal Appearance Matching Association. (arXiv:1907.00831v4 [cs.CV] UPDATED)</h2>
<h3>Young-Chul Yoon, Du Yong Kim, Young-min Song, Kwangjin Yoon, Moongu Jeon</h3>
<p>In online multi-target tracking, modeling of appearance and geometric
similarities between pedestrians visual scenes is of great importance. The
higher dimension of inherent information in the appearance model compared to
the geometric model is problematic in many ways. However, due to the recent
success of deep-learning-based methods, handling of high-dimensional appearance
information becomes feasible. Among many deep neural networks, Siamese network
with triplet loss has been widely adopted as an effective appearance feature
extractor. Since the Siamese network can extract the features of each input
independently, one can update and maintain target-specific features. However,
it is not suitable for multi-target settings that require comparison with other
inputs. To address this issue, we propose a novel track appearance model based
on the joint-inference network. The proposed method enables a comparison of two
inputs to be used for adaptive appearance modeling and contributes to the
disambiguation of target-observation matching and to the consolidation of
identity consistency. Diverse experimental results support the effectiveness of
our method. Our work was recognized as the 3rd-best tracker in BMTT
MOTChallenge 2019, held at CVPR2019. The code is available at
https://github.com/yyc9268/Deep-TAMA.
</p>
<a href="http://arxiv.org/abs/1907.00831" target="_blank">arXiv:1907.00831</a> [<a href="http://arxiv.org/pdf/1907.00831" target="_blank">pdf</a>]

<h2>Modeling question asking using neural program generation. (arXiv:1907.09899v3 [cs.CL] UPDATED)</h2>
<h3>Ziyun Wang, Brenden M. Lake</h3>
<p>People ask questions that are far richer, more informative, and more creative
than current AI systems. We propose a neuro-symbolic framework for modeling
human question asking, which represents questions as formal programs and
generates programs with an encoder-decoder based deep neural network. From
extensive experiments using an information-search game, we show that our method
can ask optimal questions in synthetic settings, and predict which questions
humans are likely to ask in unconstrained settings. We also propose a novel
grammar-based question generation framework trained with reinforcement
learning, which is able to generate creative questions without supervised human
data.
</p>
<a href="http://arxiv.org/abs/1907.09899" target="_blank">arXiv:1907.09899</a> [<a href="http://arxiv.org/pdf/1907.09899" target="_blank">pdf</a>]

<h2>Learning Quintuplet Loss for Large-scale Visual Geo-Localization. (arXiv:1907.11350v2 [cs.CV] UPDATED)</h2>
<h3>Qiang Zhai</h3>
<p>With the maturity of Artificial Intelligence (AI) technology, Large Scale
Visual Geo-Localization (LSVGL) is increasingly important in urban computing,
where the task is to accurately and efficiently recognize the geo-location of a
given query image. The main challenge of LSVGL faced by many experiments due to
the appearance of real-word places may differ in various ways. While
perspective deviation almost inevitably exists between training images and
query images because of the arbitrary perspective. To cope with this situation,
in this paper, we in-depth analyze the limitation of triplet loss which is the
most commonly used metric learning loss in state-of-the-art LSVGL framework,
and propose a new QUInTuplet Loss (QUITLoss) by embedding all the potential
positive samples to the primitive triplet loss. Extensive experiments have been
conducted to verify the effectiveness of the proposed approach and the results
demonstrate that our new loss can enhance various LSVGL methods.
</p>
<a href="http://arxiv.org/abs/1907.11350" target="_blank">arXiv:1907.11350</a> [<a href="http://arxiv.org/pdf/1907.11350" target="_blank">pdf</a>]

<h2>Multi-view Story Characterization from Movie Plot Synopses and Reviews. (arXiv:1908.09083v2 [cs.CL] UPDATED)</h2>
<h3>Sudipta Kar, Gustavo Aguilar, Mirella Lapata, Thamar Solorio</h3>
<p>This paper considers the problem of characterizing stories by inferring
properties such as theme and style using written synopses and reviews of
movies. We experiment with a multi-label dataset of movie synopses and a tagset
representing various attributes of stories (e.g., genre, type of events). Our
proposed multi-view model encodes the synopses and reviews using hierarchical
attention and shows improvement over methods that only use synopses. Finally,
we demonstrate how can we take advantage of such a model to extract a
complementary set of story-attributes from reviews without direct supervision.
We have made our dataset and source code publicly available at
https://ritual.uh.edu/ multiview-tag-2020.
</p>
<a href="http://arxiv.org/abs/1908.09083" target="_blank">arXiv:1908.09083</a> [<a href="http://arxiv.org/pdf/1908.09083" target="_blank">pdf</a>]

<h2>Neural Conversational QA: Learning to Reason v.s. Exploiting Patterns. (arXiv:1909.03759v2 [cs.CL] UPDATED)</h2>
<h3>Nikhil Verma, Abhishek Sharma, Dhiraj Madan, Danish Contractor, Harshit Kumar, Sachindra Joshi</h3>
<p>Neural Conversational QA tasks like ShARC require systems to answer questions
based on the contents of a given passage. On studying recent state-of-the-art
models on the ShARCQA task, we found indications that the models learn spurious
clues/patterns in the dataset. Furthermore, we show that a heuristic-based
program designed to exploit these patterns can have performance comparable to
that of the neural models. In this paper we share our findings about four types
of patterns found in the ShARC corpus and describe how neural models exploit
them. Motivated by the aforementioned findings, we create and share a modified
dataset that has fewer spurious patterns, consequently allowing models to learn
better.
</p>
<a href="http://arxiv.org/abs/1909.03759" target="_blank">arXiv:1909.03759</a> [<a href="http://arxiv.org/pdf/1909.03759" target="_blank">pdf</a>]

<h2>Benchmarking the Performance and Energy Efficiency of AI Accelerators for AI Training. (arXiv:1909.06842v9 [cs.DC] UPDATED)</h2>
<h3>Yuxin Wang, Qiang Wang, Shaohuai Shi, Xin He, Zhenheng Tang, Kaiyong Zhao, Xiaowen Chu</h3>
<p>Deep learning has become widely used in complex AI applications. Yet,
training a deep neural network (DNNs) model requires a considerable amount of
calculations, long running time, and much energy. Nowadays, many-core AI
accelerators (e.g., GPUs and TPUs) are designed to improve the performance of
AI training. However, processors from different vendors perform dissimilarly in
terms of performance and energy consumption. To investigate the differences
among several popular off-the-shelf processors (i.e., Intel CPU, NVIDIA GPU,
AMD GPU, and Google TPU) in training DNNs, we carry out a comprehensive
empirical study on the performance and energy efficiency of these processors by
benchmarking a representative set of deep learning workloads, including
computation-intensive operations, classical convolutional neural networks
(CNNs), recurrent neural networks (LSTM), Deep Speech 2, and Transformer.
Different from the existing end-to-end benchmarks which only present the
training time, We try to investigate the impact of hardware, vendor's software
library, and deep learning framework on the performance and energy consumption
of AI training. Our evaluation methods and results not only provide an
informative guide for end-users to select proper AI accelerators, but also
expose some opportunities for the hardware vendors to improve their software
library.
</p>
<a href="http://arxiv.org/abs/1909.06842" target="_blank">arXiv:1909.06842</a> [<a href="http://arxiv.org/pdf/1909.06842" target="_blank">pdf</a>]

<h2>GraphMix: Improved Training of GNNs for Semi-Supervised Learning. (arXiv:1909.11715v3 [cs.LG] UPDATED)</h2>
<h3>Vikas Verma, Meng Qu, Kenji Kawaguchi, Alex Lamb, Yoshua Bengio, Juho Kannala, Jian Tang</h3>
<p>We present GraphMix, a regularization method for Graph Neural Network based
semi-supervised object classification, whereby we propose to train a
fully-connected network jointly with the graph neural network via parameter
sharing and interpolation-based regularization. Further, we provide a
theoretical analysis of how GraphMix improves the generalization bounds of the
underlying graph neural network, without making any assumptions about the
"aggregation" layer or the depth of the graph neural networks. We
experimentally validate this analysis by applying GraphMix to various
architectures such as Graph Convolutional Networks, Graph Attention Networks
and Graph-U-Net. Despite its simplicity, we demonstrate that GraphMix can
consistently improve or closely match state-of-the-art performance using even
simpler architectures such as Graph Convolutional Networks, across three
established graph benchmarks: Cora, Citeseer and Pubmed citation network
datasets, as well as three newly proposed datasets: Cora-Full, Co-author-CS and
Co-author-Physics.
</p>
<a href="http://arxiv.org/abs/1909.11715" target="_blank">arXiv:1909.11715</a> [<a href="http://arxiv.org/pdf/1909.11715" target="_blank">pdf</a>]

<h2>Nighttime Stereo Depth Estimation using Joint Translation-Stereo Learning: Light Effects and Uninformative Regions. (arXiv:1909.13701v2 [cs.CV] UPDATED)</h2>
<h3>Aashish Sharma, Lionel Heng, Loong-Fah Cheong, Robby T. Tan</h3>
<p>Nighttime stereo depth estimation is still challenging, as assumptions
associated with daytime lighting conditions do not hold any longer. Nighttime
is not only about low-light and dense noise, but also about glow/glare, flares,
non-uniform distribution of light, etc. One of the possible solutions is to
train a network on night stereo images in a fully supervised manner. However,
to obtain proper disparity ground-truths that are dense, independent from
glare/glow, and have sufficiently far depth ranges is extremely intractable. To
address the problem, we introduce a network joining day/night translation and
stereo. In training the network, our method does not require ground-truth
disparities of the night images, or paired day/night images. We utilize a
translation network that can render realistic night stereo images from day
stereo images. We then train a stereo network on the rendered night stereo
images using the available disparity supervision from the corresponding day
stereo images, and simultaneously also train the day/night translation network.
We handle the fake depth problem, which occurs due to the unsupervised/unpaired
translation, for light effects (e.g., glow/glare) and uninformative regions
(e.g., low-light and saturated regions), by adding structure-preservation and
weighted-smoothness constraints. Our experiments show that our method
outperforms the baseline methods on night images.
</p>
<a href="http://arxiv.org/abs/1909.13701" target="_blank">arXiv:1909.13701</a> [<a href="http://arxiv.org/pdf/1909.13701" target="_blank">pdf</a>]

<h2>Unsupervised Domain Adversarial Self-Calibration for Electromyographic-based Gesture Recognition. (arXiv:1912.11037v5 [cs.HC] UPDATED)</h2>
<h3>Ulysse C&#xf4;t&#xe9;-Allard, Gabriel Gagnon-Turcotte, Angkoon Phinyomark, Kyrre Glette, Erik Scheme, Fran&#xe7;ois Laviolette, Benoit Gosselin</h3>
<p>Surface electromyography (sEMG) provides an intuitive and non-invasive
interface from which to control machines. However, preserving the myoelectric
control system's performance over multiple days is challenging, due to the
transient nature of the signals obtained with this recording technique. In
practice, if the system is to remain usable, a time-consuming and periodic
recalibration is necessary. In the case where the sEMG interface is employed
every few days, the user might need to do this recalibration before every use.
Thus, severely limiting the practicality of such a control method.
Consequently, this paper proposes tackling the especially challenging task of
unsupervised adaptation of sEMG signals, when multiple days have elapsed
between each recording, by introducing Self-Calibrating Asynchronous Domain
Adversarial Neural Network (SCADANN). SCADANN is compared with two
state-of-the-art self-calibrating algorithms developed specifically for deep
learning within the context of EMG-based gesture recognition and three
state-of-the-art domain adversarial algorithms. The comparison is made both on
an offline and a dynamic dataset (20 participants per dataset), using two
different deep network architectures with two different input modalities
(temporal-spatial descriptors and spectrograms). Overall, SCADANN is shown to
substantially and systematically improves classification performances over no
recalibration and obtains the highest average accuracy for all tested cases
across all methods.
</p>
<a href="http://arxiv.org/abs/1912.11037" target="_blank">arXiv:1912.11037</a> [<a href="http://arxiv.org/pdf/1912.11037" target="_blank">pdf</a>]

<h2>Driver Gaze Estimation in the Real World: Overcoming the Eyeglass Challenge. (arXiv:2002.02077v4 [cs.CV] UPDATED)</h2>
<h3>Akshay Rangesh, Bowen Zhang, Mohan M. Trivedi</h3>
<p>A driver's gaze is critical for determining the driver's attention level,
state, situational awareness, and readiness to take over control from partially
and fully automated vehicles. Tracking both the head and eyes (pupils) can
provide reliable estimation of a driver's gaze using face images under ideal
conditions. However, the vehicular environment introduces a variety of
challenges that are usually unaccounted for - harsh illumination, nighttime
conditions, and reflective/dark eyeglasses. Unfortunately, relying on head pose
alone under such conditions can prove to be unreliable owing to significant eye
movements. In this study, we offer solutions to address these problems
encountered in the real world. To solve issues with lighting, we demonstrate
that using an infrared camera with suitable equalization and normalization
usually suffices. To handle eyeglasses and their corresponding artifacts, we
adopt the idea of image-to-image translation using generative adversarial
networks (GANs) to pre-process images prior to gaze estimation. To this end, we
propose the Gaze Preserving CycleGAN (GPCycleGAN). As the name suggests, this
network preserves the driver's gaze while removing potential eyeglasses from
infrared face images. GPCycleGAN is based on the well-known CycleGAN approach,
with the addition of a gaze classifier and a gaze consistency loss for
additional supervision. Our approach exhibits improved performance and
robustness on challenging real-world data spanning 13 subjects and a variety of
driving conditions.
</p>
<a href="http://arxiv.org/abs/2002.02077" target="_blank">arXiv:2002.02077</a> [<a href="http://arxiv.org/pdf/2002.02077" target="_blank">pdf</a>]

<h2>Visual Camera Re-Localization from RGB and RGB-D Images Using DSAC. (arXiv:2002.12324v4 [cs.CV] UPDATED)</h2>
<h3>Eric Brachmann, Carsten Rother</h3>
<p>We describe a learning-based system that estimates the camera position and
orientation from a single input image relative to a known environment. The
system is flexible w.r.t. the amount of information available at test and at
training time, catering to different applications. Input images can be RGB-D or
RGB, and a 3D model of the environment can be utilized for training but is not
necessary. In the minimal case, our system requires only RGB images and ground
truth poses at training time, and it requires only a single RGB image at test
time. The framework consists of a deep neural network and fully differentiable
pose optimization. The neural network predicts so called scene coordinates,
i.e. dense correspondences between the input image and 3D scene space of the
environment. The pose optimization implements robust fitting of pose parameters
using differentiable RANSAC (DSAC) to facilitate end-to-end training. The
system, an extension of DSAC++ and referred to as DSAC*, achieves
state-of-the-art accuracy an various public datasets for RGB-based
re-localization, and competitive accuracy for RGB-D-based re-localization.
</p>
<a href="http://arxiv.org/abs/2002.12324" target="_blank">arXiv:2002.12324</a> [<a href="http://arxiv.org/pdf/2002.12324" target="_blank">pdf</a>]

<h2>Physics-informed machine learning for composition-process-property alloy design: shape memory alloy demonstration. (arXiv:2003.01878v3 [cond-mat.mtrl-sci] UPDATED)</h2>
<h3>Sen Liu (1), Branden B. Kappes (1), Behnam Amin-ahmadi (1), Othmane Benafan (2), Xiaoli Zhang (1), Aaron P. Stebner (1,3) ((1) Mechanical Engineering, Colorado School of Mines, Golden (2) Materials and Structures Division, NASA Glenn Research Center (3) Mechanical Engineering and Materials Science and Engineering, Georgia Institute of Technology)</h3>
<p>Machine learning (ML) is shown to predict new alloys and their performances
in a high dimensional, multiple-target-property design space that considers
chemistry, multi-step processing routes, and characterization methodology
variations. A physics-informed featured engineering approach is shown to enable
otherwise poorly performing ML models to perform well with the same data.
Specifically, previously engineered elemental features based on alloy
chemistries are combined with newly engineered heat treatment process features.
The new features result from first transforming the heat treatment parameter
data as it was previously recorded using nonlinear mathematical relationships
known to describe the thermodynamics and kinetics of phase transformations in
alloys. The ability of the ML model to be used for predictive design is
validated using blind predictions. Composition - process - property
relationships for thermal hysteresis of shape memory alloys (SMAs) with complex
microstructures created via multiple
melting-homogenization-solutionization-precipitation processing stage
variations are captured, in addition to the mean transformation temperatures of
the SMAs. The quantitative models of hysteresis exhibited by such highly
processed alloys demonstrate the ability for ML models to design for physical
complexities that have challenged physics-based modeling approaches for
decades.
</p>
<a href="http://arxiv.org/abs/2003.01878" target="_blank">arXiv:2003.01878</a> [<a href="http://arxiv.org/pdf/2003.01878" target="_blank">pdf</a>]

<h2>Challenging the adversarial robustness of DNNs based on error-correcting output codes. (arXiv:2003.11855v2 [cs.CR] UPDATED)</h2>
<h3>Bowen Zhang, Benedetta Tondi, Xixiang Lv, Mauro Barni</h3>
<p>The existence of adversarial examples and the easiness with which they can be
generated raise several security concerns with regard to deep learning systems,
pushing researchers to develop suitable defense mechanisms. The use of networks
adopting error-correcting output codes (ECOC) has recently been proposed to
counter the creation of adversarial examples in a white-box setting. In this
paper, we carry out an in-depth investigation of the adversarial robustness
achieved by the ECOC approach. We do so by proposing a new adversarial attack
specifically designed for multi-label classification architectures, like the
ECOC-based one, and by applying two existing attacks. In contrast to previous
findings, our analysis reveals that ECOC-based networks can be attacked quite
easily by introducing a small adversarial perturbation. Moreover, the
adversarial examples can be generated in such a way to achieve high
probabilities for the predicted target class, hence making it difficult to use
the prediction confidence to detect them. Our findings are proven by means of
experimental results obtained on MNIST, CIFAR-10 and GTSRB classification
tasks.
</p>
<a href="http://arxiv.org/abs/2003.11855" target="_blank">arXiv:2003.11855</a> [<a href="http://arxiv.org/pdf/2003.11855" target="_blank">pdf</a>]

<h2>End-to-end Autonomous Driving Perception with Sequential Latent Representation Learning. (arXiv:2003.12464v2 [cs.CV] UPDATED)</h2>
<h3>Jianyu Chen, Zhuo Xu, Masayoshi Tomizuka</h3>
<p>Current autonomous driving systems are composed of a perception system and a
decision system. Both of them are divided into multiple subsystems built up
with lots of human heuristics. An end-to-end approach might clean up the system
and avoid huge efforts of human engineering, as well as obtain better
performance with increasing data and computation resources. Compared to the
decision system, the perception system is more suitable to be designed in an
end-to-end framework, since it does not require online driving exploration. In
this paper, we propose a novel end-to-end approach for autonomous driving
perception. A latent space is introduced to capture all relevant features
useful for perception, which is learned through sequential latent
representation learning. The learned end-to-end perception model is able to
solve the detection, tracking, localization and mapping problems altogether
with only minimum human engineering efforts and without storing any maps
online. The proposed method is evaluated in a realistic urban driving
simulator, with both camera image and lidar point cloud as sensor inputs. The
codes and videos of this work are available at our github repo and project
website.
</p>
<a href="http://arxiv.org/abs/2003.12464" target="_blank">arXiv:2003.12464</a> [<a href="http://arxiv.org/pdf/2003.12464" target="_blank">pdf</a>]

<h2>Orthogonal Inductive Matrix Completion. (arXiv:2004.01653v4 [cs.LG] UPDATED)</h2>
<h3>Antoine Ledent, Rodrigo Alves, Marius Kloft</h3>
<p>We propose orthogonal inductive matrix completion (OMIC), an interpretable
approach to inductive matrix completion based on a sum of multiple orthonormal
side information terms, together with nuclear-norm regularization. The approach
allows us to inject prior knowledge about the eigenvectors of the ground truth
matrix. We optimize the approach by a provably converging algorithm, which
optimizes all components of the model simultaneously. Our method enjoys
distribution-free learning guarantees that improve with the quality of the
injected knowledge. As a special case of our general framework, we study a
model consisting of a sum of user and item biases (generic behavior), a
non-inductive term (specific behavior), and (optionally) an inductive term
using side information. Our theoretical analysis shows that
$\epsilon$-recovering a ground truth matrix in $\mathbb{R}^{m\times n}$
requires at most $O\left( \frac{n+m+(\sqrt{n}+\sqrt{m})
\sqrt{mnr}C}{\epsilon^2}\right)$ entries, where $r$ (resp. $C$) is the rank
(resp. maximum entry) of the bias-free part of the ground truth matrix. We
analyse the performance of OMIC on several synthetic and real datasets. On
synthetic datasets with a sliding scale of user bias relevance, we show that
OMIC better adapts to different regimes than other methods. On real-life
datasets containing user/items recommendations and relevant side information,
we find that OMIC surpasses the state-of-the-art, with the added benefit of
greater interpretability.
</p>
<a href="http://arxiv.org/abs/2004.01653" target="_blank">arXiv:2004.01653</a> [<a href="http://arxiv.org/pdf/2004.01653" target="_blank">pdf</a>]

<h2>Reference Language based Unsupervised Neural Machine Translation. (arXiv:2004.02127v2 [cs.CL] UPDATED)</h2>
<h3>Zuchao Li, Hai Zhao, Rui Wang, Masao Utiyama, Eiichiro Sumita</h3>
<p>Exploiting a common language as an auxiliary for better translation has a
long tradition in machine translation and lets supervised learning-based
machine translation enjoy the enhancement delivered by the well-used pivot
language in the absence of a source language to target language parallel
corpus. The rise of unsupervised neural machine translation (UNMT) almost
completely relieves the parallel corpus curse, though UNMT is still subject to
unsatisfactory performance due to the vagueness of the clues available for its
core back-translation training. Further enriching the idea of pivot translation
by extending the use of parallel corpora beyond the source-target paradigm, we
propose a new reference language-based framework for UNMT, RUNMT, in which the
reference language only shares a parallel corpus with the source, but this
corpus still indicates a signal clear enough to help the reconstruction
training of UNMT through a proposed reference agreement mechanism. Experimental
results show that our methods improve the quality of UNMT over that of a strong
baseline that uses only one auxiliary language, demonstrating the usefulness of
the proposed reference language-based UNMT and establishing a good start for
the community.
</p>
<a href="http://arxiv.org/abs/2004.02127" target="_blank">arXiv:2004.02127</a> [<a href="http://arxiv.org/pdf/2004.02127" target="_blank">pdf</a>]

<h2>Channel Attention Residual U-Net for Retinal Vessel Segmentation. (arXiv:2004.03702v4 [eess.IV] UPDATED)</h2>
<h3>Changlu Guo, M&#xe1;rton Szemenyei, Yangtao Hu, Wenle Wang, Wei Zhou, Yugen Yi</h3>
<p>Retinal vessel segmentation is a vital step for the diagnosis of many early
eye-related diseases. In this work, we propose a new deep learning model,
namely Channel Attention Residual U-Net (CAR-UNet), to accurately segment
retinal vascular and non-vascular pixels. In this model, we introduced a novel
Modified Efficient Channel Attention (MECA) to enhance the discriminative
ability of the network by considering the interdependence between feature maps.
On the one hand, we apply MECA to the "skip connections" in the traditional
U-shaped networks, instead of simply copying the feature maps of the
contracting path to the corresponding expansive path. On the other hand, we
propose a Channel Attention Double Residual Block (CADRB), which integrates
MECA into a residual structure as a core structure to construct the proposed
CAR-UNet. The results show that our proposed CAR-UNet has reached the
state-of-the-art performance on three publicly available retinal vessel
datasets: DRIVE, CHASE DB1 and STARE.[*Corresponding author This work was
supported by the China Scholarship Council, the Stipendium Hungaricum
Scholarship, the National Natural Science Foundation of China under Grants
62062040, and Chinese Postdoctoral Science Foundation 2019M661117.]
</p>
<a href="http://arxiv.org/abs/2004.03702" target="_blank">arXiv:2004.03702</a> [<a href="http://arxiv.org/pdf/2004.03702" target="_blank">pdf</a>]

<h2>An Application of Deep Reinforcement Learning to Algorithmic Trading. (arXiv:2004.06627v3 [q-fin.TR] UPDATED)</h2>
<h3>Thibaut Th&#xe9;ate, Damien Ernst</h3>
<p>This scientific research paper presents an innovative approach based on deep
reinforcement learning (DRL) to solve the algorithmic trading problem of
determining the optimal trading position at any point in time during a trading
activity in stock markets. It proposes a novel DRL trading strategy so as to
maximise the resulting Sharpe ratio performance indicator on a broad range of
stock markets. Denominated the Trading Deep Q-Network algorithm (TDQN), this
new trading strategy is inspired from the popular DQN algorithm and
significantly adapted to the specific algorithmic trading problem at hand. The
training of the resulting reinforcement learning (RL) agent is entirely based
on the generation of artificial trajectories from a limited set of stock market
historical data. In order to objectively assess the performance of trading
strategies, the research paper also proposes a novel, more rigorous performance
assessment methodology. Following this new performance assessment approach,
promising results are reported for the TDQN strategy.
</p>
<a href="http://arxiv.org/abs/2004.06627" target="_blank">arXiv:2004.06627</a> [<a href="http://arxiv.org/pdf/2004.06627" target="_blank">pdf</a>]

<h2>Counterfactual Off-Policy Training for Neural Response Generation. (arXiv:2004.14507v2 [cs.LG] UPDATED)</h2>
<h3>Qingfu Zhu, Weinan Zhang, Ting Liu, William Yang Wang</h3>
<p>Open-domain dialogue generation suffers from the data insufficiency problem
due to the vast size of potential responses. In this paper, we propose to
explore potential responses by counterfactual reasoning. Given an observed
response, the counterfactual reasoning model automatically infers the outcome
of an alternative policy that could have been taken. The resulting
counterfactual response synthesized in hindsight is of higher quality than the
response synthesized from scratch. Training on the counterfactual responses
under the adversarial learning framework helps to explore the high-reward area
of the potential response space. An empirical study on the DailyDialog dataset
shows that our approach significantly outperforms the HRED model as well as the
conventional adversarial learning approaches.
</p>
<a href="http://arxiv.org/abs/2004.14507" target="_blank">arXiv:2004.14507</a> [<a href="http://arxiv.org/pdf/2004.14507" target="_blank">pdf</a>]

<h2>Asking without Telling: Exploring Latent Ontologies in Contextual Representations. (arXiv:2004.14513v2 [cs.CL] UPDATED)</h2>
<h3>Julian Michael, Jan A. Botha, Ian Tenney</h3>
<p>The success of pretrained contextual encoders, such as ELMo and BERT, has
brought a great deal of interest in what these models learn: do they, without
explicit supervision, learn to encode meaningful notions of linguistic
structure? If so, how is this structure encoded? To investigate this, we
introduce latent subclass learning (LSL): a modification to existing
classifier-based probing methods that induces a latent categorization (or
ontology) of the probe's inputs. Without access to fine-grained gold labels,
LSL extracts emergent structure from input representations in an interpretable
and quantifiable form. In experiments, we find strong evidence of familiar
categories, such as a notion of personhood in ELMo, as well as novel
ontological distinctions, such as a preference for fine-grained semantic roles
on core arguments. Our results provide unique new evidence of emergent
structure in pretrained encoders, including departures from existing
annotations which are inaccessible to earlier methods.
</p>
<a href="http://arxiv.org/abs/2004.14513" target="_blank">arXiv:2004.14513</a> [<a href="http://arxiv.org/pdf/2004.14513" target="_blank">pdf</a>]

<h2>GigaBERT: Zero-shot Transfer Learning from English to Arabic. (arXiv:2004.14519v4 [cs.CL] UPDATED)</h2>
<h3>Wuwei Lan, Yang Chen, Wei Xu, Alan Ritter</h3>
<p>Multilingual pre-trained Transformers, such as mBERT (Devlin et al., 2019)
and XLM-RoBERTa (Conneau et al., 2020a), have been shown to enable the
effective cross-lingual zero-shot transfer. However, their performance on
Arabic information extraction (IE) tasks is not very well studied. In this
paper, we pre-train a customized bilingual BERT, dubbed GigaBERT, that is
designed specifically for Arabic NLP and English-to-Arabic zero-shot transfer
learning. We study GigaBERT's effectiveness on zero-short transfer across four
IE tasks: named entity recognition, part-of-speech tagging, argument role
labeling, and relation extraction. Our best model significantly outperforms
mBERT, XLM-RoBERTa, and AraBERT (Antoun et al., 2020) in both the supervised
and zero-shot transfer settings. We have made our pre-trained models publicly
available at https://github.com/lanwuwei/GigaBERT.
</p>
<a href="http://arxiv.org/abs/2004.14519" target="_blank">arXiv:2004.14519</a> [<a href="http://arxiv.org/pdf/2004.14519" target="_blank">pdf</a>]

<h2>Paraphrasing vs Coreferring: Two Sides of the Same Coin. (arXiv:2004.14979v2 [cs.CL] UPDATED)</h2>
<h3>Yehudit Meged, Avi Caciularu, Vered Shwartz, Ido Dagan</h3>
<p>We study the potential synergy between two different NLP tasks, both
confronting predicate lexical variability: identifying predicate paraphrases,
and event coreference resolution. First, we used annotations from an event
coreference dataset as distant supervision to re-score heuristically-extracted
predicate paraphrases. The new scoring gained more than 18 points in average
precision upon their ranking by the original scoring method. Then, we used the
same re-ranking features as additional inputs to a state-of-the-art event
coreference resolution model, which yielded modest but consistent improvements
to the model's performance. The results suggest a promising direction to
leverage data and models for each of the tasks to the benefit of the other.
</p>
<a href="http://arxiv.org/abs/2004.14979" target="_blank">arXiv:2004.14979</a> [<a href="http://arxiv.org/pdf/2004.14979" target="_blank">pdf</a>]

<h2>TLDR: Extreme Summarization of Scientific Documents. (arXiv:2004.15011v3 [cs.CL] UPDATED)</h2>
<h3>Isabel Cachola, Kyle Lo, Arman Cohan, Daniel S. Weld</h3>
<p>We introduce TLDR generation, a new form of extreme summarization, for
scientific papers. TLDR generation involves high source compression and
requires expert background knowledge and understanding of complex
domain-specific language. To facilitate study on this task, we introduce
SciTLDR, a new multi-target dataset of 5.4K TLDRs over 3.2K papers. SciTLDR
contains both author-written and expert-derived TLDRs, where the latter are
collected using a novel annotation protocol that produces high-quality
summaries while minimizing annotation burden. We propose CATTS, a simple yet
effective learning strategy for generating TLDRs that exploits titles as an
auxiliary training signal. CATTS improves upon strong baselines under both
automated metrics and human evaluations. Data and code are publicly available
at https://github.com/allenai/scitldr.
</p>
<a href="http://arxiv.org/abs/2004.15011" target="_blank">arXiv:2004.15011</a> [<a href="http://arxiv.org/pdf/2004.15011" target="_blank">pdf</a>]

<h2>Does Data Augmentation Improve Generalization in NLP?. (arXiv:2004.15012v2 [cs.CL] UPDATED)</h2>
<h3>Rohan Jha, Charles Lovering, Ellie Pavlick</h3>
<p>Neural models often exploit superficial features to achieve good performance,
rather than deriving more general features. Overcoming this tendency is a
central challenge in areas such as representation learning and ML fairness.
Recent work has proposed using data augmentation, i.e., generating training
examples where the superficial features fail, as a means of encouraging models
to prefer the stronger features. We design a series of toy learning problems to
test the hypothesis that data augmentation leads models to unlearn weaker
heuristics, but not to learn stronger features in their place. We find partial
support for this hypothesis: Data augmentation often hurts before it helps, and
it is less effective when the preferred strong feature is much more difficult
to extract than the competing weak feature.
</p>
<a href="http://arxiv.org/abs/2004.15012" target="_blank">arXiv:2004.15012</a> [<a href="http://arxiv.org/pdf/2004.15012" target="_blank">pdf</a>]

<h2>Generative Adversarial Networks (GANs): Challenges, Solutions, and Future Directions. (arXiv:2005.00065v3 [cs.LG] UPDATED)</h2>
<h3>Divya Saxena, Jiannong Cao</h3>
<p>Generative Adversarial Networks (GANs) is a novel class of deep generative
models which has recently gained significant attention. GANs learns complex and
high-dimensional distributions implicitly over images, audio, and data.
However, there exists major challenges in training of GANs, i.e., mode
collapse, non-convergence and instability, due to inappropriate design of
network architecture, use of objective function and selection of optimization
algorithm. Recently, to address these challenges, several solutions for better
design and optimization of GANs have been investigated based on techniques of
re-engineered network architectures, new objective functions and alternative
optimization algorithms. To the best of our knowledge, there is no existing
survey that has particularly focused on broad and systematic developments of
these solutions. In this study, we perform a comprehensive survey of the
advancements in GANs design and optimization solutions proposed to handle GANs
challenges. We first identify key research issues within each design and
optimization technique and then propose a new taxonomy to structure solutions
by key research issues. In accordance with the taxonomy, we provide a detailed
discussion on different GANs variants proposed within each solution and their
relationships. Finally, based on the insights gained, we present the promising
research directions in this rapidly growing field.
</p>
<a href="http://arxiv.org/abs/2005.00065" target="_blank">arXiv:2005.00065</a> [<a href="http://arxiv.org/pdf/2005.00065" target="_blank">pdf</a>]

<h2>Explaining How Deep Neural Networks Forget by Deep Visualization. (arXiv:2005.01004v2 [cs.LG] UPDATED)</h2>
<h3>Giang Nguyen, Shuan Chen, Tae Joon Jun, Daeyoung Kim</h3>
<p>Explaining the behaviors of deep neural networks, usually considered as black
boxes, is critical especially when they are now being adopted over diverse
aspects of human life. Taking the advantages of interpretable machine learning
(interpretable ML), this paper proposes a novel tool called Catastrophic
Forgetting Dissector (or CFD) to explain catastrophic forgetting in continual
learning settings. We also introduce a new method called Critical Freezing
based on the observations of our tool. Experiments on ResNet articulate how
catastrophic forgetting happens, particularly showing which components of this
famous network are forgetting. Our new continual learning algorithm defeats
various recent techniques by a significant margin, proving the capability of
the investigation. Critical freezing not only attacks catastrophic forgetting
but also exposes explainability.
</p>
<a href="http://arxiv.org/abs/2005.01004" target="_blank">arXiv:2005.01004</a> [<a href="http://arxiv.org/pdf/2005.01004" target="_blank">pdf</a>]

<h2>Heidelberg Colorectal Data Set for Surgical Data Science in the Sensor Operating Room. (arXiv:2005.03501v4 [cs.CV] UPDATED)</h2>
<h3>Lena Maier-Hein, Martin Wagner, Tobias Ross, Annika Reinke, Sebastian Bodenstedt, Peter M. Full, Hellena Hempe, Diana Mindroc-Filimon, Patrick Scholz, Thuy Nuong Tran, Pierangela Bruno, Anna Kisilenko, Benjamin M&#xfc;ller, Tornike Davitashvili, Manuela Capek, Minu Tizabi, Matthias Eisenmann, Tim J. Adler, Janek Gr&#xf6;hl, Melanie Schellenberg, Silvia Seidlitz, T. Y. Emmy Lai, B&#xfc;nyamin Pekdemir, Veith Roethlingshoefer, Fabian Both, Sebastian Bittel, Marc Mengler, Lars M&#xfc;ndermann, Martin Apitz, Stefanie Speidel, Hannes G. Kenngott, Beat P. M&#xfc;ller-Stich</h3>
<p>Image-based tracking of medical instruments is an integral part of many
surgical data science applications. Previous research has addressed the tasks
of detecting, segmenting and tracking medical instruments based on laparoscopic
video data. However, the methods proposed still tend to fail when applied to
challenging images and do not generalize well to data they have not been
trained on. This paper introduces the Heidelberg Colorectal (HeiCo) data set -
the first publicly available data set enabling comprehensive benchmarking of
medical instrument detection and segmentation algorithms with a specific
emphasis on robustness and generalization capabilities of the methods. Our data
set comprises 30 laparoscopic videos and corresponding sensor data from medical
devices in the operating room for three different types of laparoscopic
surgery. Annotations include surgical phase labels for all frames in the videos
as well as instance-wise segmentation masks for surgical instruments in more
than 10,000 individual frames. The data has successfully been used to organize
international competitions in the scope of the Endoscopic Vision Challenges
(EndoVis) 2017 and 2019.
</p>
<a href="http://arxiv.org/abs/2005.03501" target="_blank">arXiv:2005.03501</a> [<a href="http://arxiv.org/pdf/2005.03501" target="_blank">pdf</a>]

<h2>ProSelfLC: Progressive Self Label Correction for Training Robust Deep Neural Networks. (arXiv:2005.03788v5 [cs.LG] UPDATED)</h2>
<h3>Xinshao Wang, Yang Hua, Elyor Kodirov, David A. Clifton, Neil M. Robertson</h3>
<p>To train robust deep neural networks (DNNs), we systematically study several
target modification approaches, which include output regularisation, self and
non-self label correction (LC). Two key issues are discovered: (1) Self LC is
the most appealing as it exploits its own knowledge and requires no extra
models. However, how to automatically decide the trust degree of a learner as
training goes is not well answered in the literature? (2) Some methods penalise
while the others reward low-entropy predictions, prompting us to ask which one
is better?

To resolve the first issue, taking two well-accepted propositions--deep
neural networks learn meaningful patterns before fitting noise (Arpit et al.,
2017) and minimum entropy regularisation principle (Grandvalet &amp; Bengio,
2006)--we propose a novel end-to-end method named ProSelfLC, which is designed
according to learning time and entropy. Specifically, given a data point, we
progressively increase trust in its predicted label distribution versus its
annotated one if a model has been trained for enough time and the prediction is
of low entropy (high confidence). For the second issue, according to ProSelfLC,
we empirically prove that it is better to redefine a meaningful low-entropy
status and optimise the learner toward it. This serves as a defence of entropy
minimisation.

We demonstrate the effectiveness of ProSelfLC through extensive experiments
in both clean and noisy settings.

Keywords: label correction, entropy minimisation, maximum entropy, confidence
penalty, knowledge distillation, regularization, label noise
</p>
<a href="http://arxiv.org/abs/2005.03788" target="_blank">arXiv:2005.03788</a> [<a href="http://arxiv.org/pdf/2005.03788" target="_blank">pdf</a>]

<h2>Many-to-Many Voice Transformer Network. (arXiv:2005.08445v3 [eess.AS] UPDATED)</h2>
<h3>Hirokazu Kameoka, Wen-Chin Huang, Kou Tanaka, Takuhiro Kaneko, Nobukatsu Hojo, Tomoki Toda</h3>
<p>This paper proposes a voice conversion (VC) method based on a
sequence-to-sequence (S2S) learning framework, which enables simultaneous
conversion of the voice characteristics, pitch contour, and duration of input
speech. We previously proposed an S2S-based VC method using a transformer
network architecture called the voice transformer network (VTN). The original
VTN was designed to learn only a mapping of speech feature sequences from one
domain into another. The main idea we propose is an extension of the original
VTN that can simultaneously learn mappings among multiple domains. This
extension called the many-to-many VTN makes it able to fully use available
training data collected from multiple domains by capturing common latent
features that can be shared across different domains. It also allows us to
introduce a training loss called the identity mapping loss to ensure that the
input feature sequence will remain unchanged when it already belongs to the
target domain. Using this particular loss for model training has been found to
be extremely effective in improving the performance of the model at test time.
We conducted speaker identity conversion experiments and found that our model
obtained higher sound quality and speaker similarity than baseline methods. We
also found that our model, with a slight modification to its architecture,
could handle any-to-many conversion tasks reasonably well.
</p>
<a href="http://arxiv.org/abs/2005.08445" target="_blank">arXiv:2005.08445</a> [<a href="http://arxiv.org/pdf/2005.08445" target="_blank">pdf</a>]

<h2>Semi-supervised Embedding Learning for High-dimensional Bayesian Optimization. (arXiv:2005.14601v2 [cs.LG] UPDATED)</h2>
<h3>Jingfan Chen, Guanghui Zhu, Rong Gu, Chunfeng Yuan, Yihua Huang</h3>
<p>Bayesian optimization is a broadly applied methodology to optimize the
expensive black-box function. Despite its success, it still faces the challenge
from the high-dimensional search space. To alleviate this problem, we propose a
novel Bayesian optimization framework (termed SILBO), which finds a
low-dimensional space to perform Bayesian optimization iteratively through
semi-supervised dimension reduction. SILBO incorporates both labeled points and
unlabeled points acquired from the acquisition function to guide the embedding
space learning. To accelerate the learning procedure, we present a randomized
method for generating the projection matrix. Furthermore, to map from the
low-dimensional space to the high-dimensional original space, we propose two
mapping strategies: $\text{SILBO}_{FZ}$ and $\text{SILBO}_{FX}$ according to
the evaluation overhead of the objective function. Experimental results on both
synthetic function and hyperparameter optimization tasks demonstrate that SILBO
outperforms the existing state-of-the-art high-dimensional Bayesian
optimization methods.
</p>
<a href="http://arxiv.org/abs/2005.14601" target="_blank">arXiv:2005.14601</a> [<a href="http://arxiv.org/pdf/2005.14601" target="_blank">pdf</a>]

<h2>Cheetah: Optimizing and Accelerating Homomorphic Encryption for Private Inference. (arXiv:2006.00505v2 [cs.CR] UPDATED)</h2>
<h3>Brandon Reagen, Wooseok Choi, Yeongil Ko, Vincent Lee, Gu-Yeon Wei, Hsien-Hsin S. Lee, David Brooks</h3>
<p>As the application of deep learning continues to grow, so does the amount of
data used to make predictions. While traditionally, big-data deep learning was
constrained by computing performance and off-chip memory bandwidth, a new
constraint has emerged: privacy. One solution is homomorphic encryption (HE).
Applying HE to the client-cloud model allows cloud services to perform
inference directly on the client's encrypted data. While HE can meet privacy
constraints, it introduces enormous computational challenges and remains
impractically slow in current systems.

This paper introduces Cheetah, a set of algorithmic and hardware
optimizations for HE DNN inference to achieve plaintext DNN inference speeds.
Cheetah proposes HE-parameter tuning optimization and operator scheduling
optimizations, which together deliver 79x speedup over the state-of-the-art.
However, this still falls short of plaintext inference speeds by almost four
orders of magnitude. To bridge the remaining performance gap, Cheetah further
proposes an accelerator architecture that, when combined with the algorithmic
optimizations, approaches plaintext DNN inference speeds. We evaluate several
common neural network models (e.g., ResNet50, VGG16, and AlexNet) and show that
plaintext-level HE inference for each is feasible with a custom accelerator
consuming 30W and 545mm^2.
</p>
<a href="http://arxiv.org/abs/2006.00505" target="_blank">arXiv:2006.00505</a> [<a href="http://arxiv.org/pdf/2006.00505" target="_blank">pdf</a>]

<h2>DeepRelativeFusion: Dense Monocular SLAM using Single-Image Relative Depth Prediction. (arXiv:2006.04047v2 [cs.CV] UPDATED)</h2>
<h3>Shing Yan Loo, Syamsiah Mashohor, Sai Hong Tang, Hong Zhang</h3>
<p>In this paper, we propose a dense monocular SLAM system, named
DeepRelativeFusion, that is capable to recover a globally consistent 3D
structure. To this end, we use a visual SLAM algorithm to reliably recover the
camera poses and semi-dense depth maps of the keyframes, and then combine the
keyframe pose-graph with the densified keyframe depth maps to reconstruct the
scene. To improve the semi-dense depth maps, we propose an adaptive filtering
scheme, which is a structure-preserving weighted average smoothing filter that
takes into account the pixel intensity and depth of the neighbouring pixels,
yielding substantial reconstruction accuracy gain in densification. To perform
densification, we introduce two incremental improvements upon the energy
minimization framework proposed by DeepFusion: (1) an improved cost function,
and (2) the use of single-image relative depth prediction. Moreover, we show
that the relative depth maps can be corrected and are sufficiently accurate to
be used as priors for the densification. To demonstrate the generalizability of
relative depth prediction, we illustrate qualitatively the dense reconstruction
on two outdoor sequences. Our system also outperforms the state-of-the-art
dense SLAM systems quantitatively in dense reconstruction accuracy by a large
margin.
</p>
<a href="http://arxiv.org/abs/2006.04047" target="_blank">arXiv:2006.04047</a> [<a href="http://arxiv.org/pdf/2006.04047" target="_blank">pdf</a>]

<h2>Improving Cross-Lingual Transfer Learning for End-to-End Speech Recognition with Speech Translation. (arXiv:2006.05474v2 [eess.AS] UPDATED)</h2>
<h3>Changhan Wang, Juan Pino, Jiatao Gu</h3>
<p>Transfer learning from high-resource languages is known to be an efficient
way to improve end-to-end automatic speech recognition (ASR) for low-resource
languages. Pre-trained or jointly trained encoder-decoder models, however, do
not share the language modeling (decoder) for the same language, which is
likely to be inefficient for distant target languages. We introduce
speech-to-text translation (ST) as an auxiliary task to incorporate additional
knowledge of the target language and enable transferring from that target
language. Specifically, we first translate high-resource ASR transcripts into a
target low-resource language, with which a ST model is trained. Both ST and
target ASR share the same attention-based encoder-decoder architecture and
vocabulary. The former task then provides a fully pre-trained model for the
latter, bringing up to 24.6% word error rate (WER) reduction to the baseline
(direct transfer from high-resource ASR). We show that training ST with human
translations is not necessary. ST trained with machine translation (MT)
pseudo-labels brings consistent gains. It can even outperform those using human
labels when transferred to target ASR by leveraging only 500K MT examples. Even
with pseudo-labels from low-resource MT (200K examples), ST-enhanced transfer
brings up to 8.9% WER reduction to direct transfer.
</p>
<a href="http://arxiv.org/abs/2006.05474" target="_blank">arXiv:2006.05474</a> [<a href="http://arxiv.org/pdf/2006.05474" target="_blank">pdf</a>]

<h2>MatchGAN: A Self-Supervised Semi-Supervised Conditional Generative Adversarial Network. (arXiv:2006.06614v2 [cs.CV] UPDATED)</h2>
<h3>Jiaze Sun, Binod Bhattarai, Tae-Kyun Kim</h3>
<p>We present a novel self-supervised learning approach for conditional
generative adversarial networks (GANs) under a semi-supervised setting. Unlike
prior self-supervised approaches which often involve geometric augmentations on
the image space such as predicting rotation angles, our pretext task leverages
the label space. We perform augmentation by randomly sampling sensible labels
from the label space of the few labelled examples available and assigning them
as target labels to the abundant unlabelled examples from the same distribution
as that of the labelled ones. The images are then translated and grouped into
positive and negative pairs by their target labels, acting as training examples
for our pretext task which involves optimising an auxiliary match loss on the
discriminator's side. We tested our method on two challenging benchmarks,
CelebA and RaFD, and evaluated the results using standard metrics including
Fr\'{e}chet Inception Distance, Inception Score, and Attribute Classification
Rate. Extensive empirical evaluation demonstrates the effectiveness of our
proposed method over competitive baselines and existing arts. In particular,
our method surpasses the baseline with only 20% of the labelled examples used
to train the baseline.
</p>
<a href="http://arxiv.org/abs/2006.06614" target="_blank">arXiv:2006.06614</a> [<a href="http://arxiv.org/pdf/2006.06614" target="_blank">pdf</a>]

<h2>Quantum Robust Fitting. (arXiv:2006.06986v3 [cs.CV] UPDATED)</h2>
<h3>Tat-Jun Chin, David Suter, Shin-Fang Chng, James Quach</h3>
<p>Many computer vision applications need to recover structure from imperfect
measurements of the real world. The task is often solved by robustly fitting a
geometric model onto noisy and outlier-contaminated data. However, recent
theoretical analyses indicate that many commonly used formulations of robust
fitting in computer vision are not amenable to tractable solution and
approximation. In this paper, we explore the usage of quantum computers for
robust fitting. To do so, we examine and establish the practical usefulness of
a robust fitting formulation inspired by Fourier analysis of Boolean functions.
We then investigate a quantum algorithm to solve the formulation and analyse
the computational speed-up possible over the classical algorithm. Our work thus
proposes one of the first quantum treatments of robust fitting for computer
vision.
</p>
<a href="http://arxiv.org/abs/2006.06986" target="_blank">arXiv:2006.06986</a> [<a href="http://arxiv.org/pdf/2006.06986" target="_blank">pdf</a>]

<h2>xOrder: A Model Agnostic Post-Processing Framework for Achieving Ranking Fairness While Maintaining Algorithm Utility. (arXiv:2006.08267v3 [cs.LG] UPDATED)</h2>
<h3>Sen Cui, Weishen Pan, Changshui Zhang, Fei Wang</h3>
<p>Algorithmic fairness has received lots of interests in machine learning
recently. In this paper, we focus on the bipartite ranking scenario, where the
instances come from either the positive or negative class and the goal is to
learn a ranking function that ranks positive instances higher than negative
ones. In an unfair setting, the probabilities of ranking the positives higher
than negatives are different across different protected groups. We propose a
general post-processing framework, xOrder, for achieving fairness in bipartite
ranking while maintaining the algorithm classification performance. In
particular, we optimize a weighted sum of the utility and fairness by directly
adjusting the relative ordering across groups. We formulate this problem as
identifying an optimal warping path across {different} protected groups and
solve it through a dynamic programming process. xOrder is compatible with
various classification models and applicable to a variety of ranking fairness
metrics. We evaluate our proposed algorithm on four benchmark data sets and two
real world patient electronic health record repository. The experimental
results show that our approach can achieve great balance between the algorithm
utility and ranking fairness. Our algorithm can also achieve robust performance
when training and testing ranking score distributions are significantly
different.
</p>
<a href="http://arxiv.org/abs/2006.08267" target="_blank">arXiv:2006.08267</a> [<a href="http://arxiv.org/pdf/2006.08267" target="_blank">pdf</a>]

<h2>Inner Ensemble Networks: Average Ensemble as an Effective Regularizer. (arXiv:2006.08305v2 [cs.LG] UPDATED)</h2>
<h3>Abduallah Mohamed, Muhammed Mohaimin Sadiq, Ehab AlBadawy, Mohamed Elhoseiny, Christian Claudel</h3>
<p>We introduce Inner Ensemble Networks (IENs) which reduce the variance within
the neural network itself without an increase in the model complexity. IENs
utilize ensemble parameters during the training phase to reduce the network
variance. While in the testing phase, these parameters are removed without a
change in the enhanced performance. IENs reduce the variance of an ordinary
deep model by a factor of $1/m^{L-1}$, where $m$ is the number of inner
ensembles and $L$ is the depth of the model. Also, we show empirically and
theoretically that IENs lead to a greater variance reduction in comparison with
other similar approaches such as dropout and maxout. Our results show a
decrease of error rates between 1.7\% and 17.3\% in comparison with an ordinary
deep model. We also show that IEN was preferred by Neural Architecture Search
(NAS) methods over prior approaches. Code is available at
https://github.com/abduallahmohamed/inner_ensemble_nets.
</p>
<a href="http://arxiv.org/abs/2006.08305" target="_blank">arXiv:2006.08305</a> [<a href="http://arxiv.org/pdf/2006.08305" target="_blank">pdf</a>]

<h2>A quantum extension of SVM-perf for training nonlinear SVMs in almost linear time. (arXiv:2006.10299v3 [quant-ph] UPDATED)</h2>
<h3>Jonathan Allcock, Chang-Yu Hsieh</h3>
<p>We propose a quantum algorithm for training nonlinear support vector machines
(SVM) for feature space learning where classical input data is encoded in the
amplitudes of quantum states. Based on the classical SVM-perf algorithm of
Joachims, our algorithm has a running time which scales linearly in the number
of training examples $m$ (up to polylogarithmic factors) and applies to the
standard soft-margin $\ell_1$-SVM model. In contrast, while classical SVM-perf
has demonstrated impressive performance on both linear and nonlinear SVMs, its
efficiency is guaranteed only in certain cases: it achieves linear $m$ scaling
only for linear SVMs, where classification is performed in the original input
data space, or for the special cases of low-rank or shift-invariant kernels.
Similarly, previously proposed quantum algorithms either have super-linear
scaling in $m$, or else apply to different SVM models such as the hard-margin
or least squares $\ell_2$-SVM which lack certain desirable properties of the
soft-margin $\ell_1$-SVM model. We classically simulate our algorithm and give
evidence that it can perform well in practice, and not only for asymptotically
large data sets.
</p>
<a href="http://arxiv.org/abs/2006.10299" target="_blank">arXiv:2006.10299</a> [<a href="http://arxiv.org/pdf/2006.10299" target="_blank">pdf</a>]

<h2>Temporal Graph Networks for Deep Learning on Dynamic Graphs. (arXiv:2006.10637v3 [cs.LG] UPDATED)</h2>
<h3>Emanuele Rossi, Ben Chamberlain, Fabrizio Frasca, Davide Eynard, Federico Monti, Michael Bronstein</h3>
<p>Graph Neural Networks (GNNs) have recently become increasingly popular due to
their ability to learn complex systems of relations or interactions arising in
a broad spectrum of problems ranging from biology and particle physics to
social networks and recommendation systems. Despite the plethora of different
models for deep learning on graphs, few approaches have been proposed thus far
for dealing with graphs that present some sort of dynamic nature (e.g. evolving
features or connectivity over time). In this paper, we present Temporal Graph
Networks (TGNs), a generic, efficient framework for deep learning on dynamic
graphs represented as sequences of timed events. Thanks to a novel combination
of memory modules and graph-based operators, TGNs are able to significantly
outperform previous approaches being at the same time more computationally
efficient. We furthermore show that several previous models for learning on
dynamic graphs can be cast as specific instances of our framework. We perform a
detailed ablation study of different components of our framework and devise the
best configuration that achieves state-of-the-art performance on several
transductive and inductive prediction tasks for dynamic graphs.
</p>
<a href="http://arxiv.org/abs/2006.10637" target="_blank">arXiv:2006.10637</a> [<a href="http://arxiv.org/pdf/2006.10637" target="_blank">pdf</a>]

<h2>Learning Tumor Growth via Follow-Up Volume Prediction for Lung Nodules. (arXiv:2006.13890v2 [eess.IV] UPDATED)</h2>
<h3>Yamin Li, Jiancheng Yang, Yi Xu, Jingwei Xu, Xiaodan Ye, Guangyu Tao, Xueqian Xie, Guixue Liu</h3>
<p>Follow-up serves an important role in the management of pulmonary nodules for
lung cancer. Imaging diagnostic guidelines with expert consensus have been made
to help radiologists make clinical decision for each patient. However, tumor
growth is such a complicated process that it is difficult to stratify high-risk
nodules from low-risk ones based on morphologic characteristics. On the other
hand, recent deep learning studies using convolutional neural networks (CNNs)
to predict the malignancy score of nodules, only provides clinicians with
black-box predictions. To this end, we propose a unified framework, named
Nodule Follow-Up Prediction Network (NoFoNet), which predicts the growth of
pulmonary nodules with high-quality visual appearances and accurate
quantitative results, given any time interval from baseline observations. It is
achieved by predicting future displacement field of each voxel with a WarpNet.
A TextureNet is further developed to refine textural details of WarpNet
outputs. We also introduce techniques including Temporal Encoding Module and
Warp Segmentation Loss to encourage time-aware and shape-aware representation
learning. We build an in-house follow-up dataset from two medical centers to
validate the effectiveness of the proposed method. NoFoNet significantly
outperforms direct prediction by a U-Net in terms of visual quality; more
importantly, it demonstrates accurate differentiating performance between high-
and low-risk nodules. Our promising results suggest the potentials in computer
aided intervention for lung nodule management.
</p>
<a href="http://arxiv.org/abs/2006.13890" target="_blank">arXiv:2006.13890</a> [<a href="http://arxiv.org/pdf/2006.13890" target="_blank">pdf</a>]

<h2>Applying Machine Learning Techniques for Caching in Edge Networks: A Comprehensive Survey. (arXiv:2006.16864v2 [cs.NI] UPDATED)</h2>
<h3>Junaid Shuja, Kashif Bilal, Eisa Alanazi, Waleed Alasmary, Abdulaziz Alashaikh, Albert Y. Zomaya</h3>
<p>Edge networks provide access to a group of proximate users who may have
similar content interests. Caching popular content at the edge networks leads
to lower latencies while reducing the load on backhaul and core networks with
the emergence of high-speed 5G networks. User mobility, preferences, and
content popularity are the dominant dynamic features of the edge networks.
Temporal and social features of content, such as the number of views and likes
are applied to estimate the popularity of content from a global perspective.
However, such estimates may not be mapped to an edge network with particular
social and geographic characteristics. In edge networks, machine learning
techniques can be applied to predict content popularity based on user
preferences, user mobility based on user location history, cluster users based
on similar content interests, and optimize cache placement strategies provided
a set of constraints and predictions about the state of the network. These
applications of machine learning can help identify relevant content for an edge
network to lower latencies and increase cache hits. This article surveys the
application of machine learning techniques for caching content in edge
networks. We survey recent state-of-the-art literature and formulate a
comprehensive taxonomy based on (a) machine learning technique, (b) caching
strategy, and edge network. We further survey supporting concepts for optimal
edge caching decisions that require the application of machine learning. These
supporting concepts are social-awareness, popularity prediction, and community
detection in edge networks. A comparative analysis of the state-of-the-art
literature is presented with respect to the parameters identified in the
taxonomy. Moreover, we debate research challenges and future directions for
optimal caching decisions and the application of machine learning towards
caching in edge networks.
</p>
<a href="http://arxiv.org/abs/2006.16864" target="_blank">arXiv:2006.16864</a> [<a href="http://arxiv.org/pdf/2006.16864" target="_blank">pdf</a>]

<h2>Mapping Flows on Bipartite Networks. (arXiv:2007.01666v2 [cs.SI] UPDATED)</h2>
<h3>Christopher Bl&#xf6;cker, Martin Rosvall</h3>
<p>Mapping network flows provides insight into the organization of networks, but
even though many real-networks are bipartite, no method for mapping flows takes
advantage of the bipartite structure. What do we miss by discarding this
information and how can we use it to understand the structure of bipartite
networks better? The map equation models network flows with a random walk and
exploits the information-theoretic duality between compression and finding
regularities to detect communities in networks. However, it does not use the
fact that random walks in bipartite networks alternate between node types,
information worth 1 bit. To make some or all of this information available to
the map equation, we developed a coding scheme that remembers node types at
different rates. We explored the community landscape of bipartite real-world
networks from no node-type information to full node-type information and found
that using node types at a higher rate generally leads to deeper community
hierarchies and a higher resolution. The corresponding compression of network
flows exceeds the amount of extra information provided. Consequently, taking
advantage of the bipartite structure increases the resolution and reveals more
network regularities.
</p>
<a href="http://arxiv.org/abs/2007.01666" target="_blank">arXiv:2007.01666</a> [<a href="http://arxiv.org/pdf/2007.01666" target="_blank">pdf</a>]

<h2>Deep Partial Updating. (arXiv:2007.03071v2 [cs.LG] UPDATED)</h2>
<h3>Zhongnan Qu, Cong Liu, Junfeng Guo, Lothar Thiele</h3>
<p>Emerging edge intelligence applications require the server to continuously
retrain and update deep neural networks deployed on remote edge nodes in order
to leverage newly collected data samples. Unfortunately, it may be impossible
in practice to continuously send fully updated weights to these edge nodes due
to the highly constrained communication resource. In this paper, we propose the
weight-wise deep partial updating paradigm, which smartly selects only a subset
of weights to update at each server-to-edge communication round, while
achieving a similar performance compared to full updating. Our method is
established through analytically upper-bounding the loss difference between
partial updating and full updating, and only updates the weights which make the
largest contributions to the upper bound. Extensive experimental results
demonstrate the efficacy of our partial updating methodology which achieves a
high inference accuracy while updating a rather small number of weights.
</p>
<a href="http://arxiv.org/abs/2007.03071" target="_blank">arXiv:2007.03071</a> [<a href="http://arxiv.org/pdf/2007.03071" target="_blank">pdf</a>]

<h2>Transfer Learning for Motor Imagery Based Brain-Computer Interfaces: A Complete Pipeline. (arXiv:2007.03746v2 [eess.SP] UPDATED)</h2>
<h3>Dongrui Wu, Ruimin Peng, Jian Huang, Zhigang Zeng</h3>
<p>Transfer learning (TL) has been widely used in motor imagery (MI) based
brain-computer interfaces (BCIs) to reduce the calibration effort for a new
subject, and demonstrated promising performance. After electroencephalogram
(EEG) signal acquisition, a closed-loop MI-based BCI system also includes
signal processing, feature engineering, and classification blocks before
sending out the control signal to an external device, whereas previous
approaches only considered TL in one or two such components. This paper
proposes that TL could be considered in all three components (signal
processing, feature engineering, and classification) of MI-based BCIs.
Furthermore, it is also very important to specifically add a data alignment
component before signal processing to make the data from different subjects
more consistent, and hence to facilitate subsequential TL. Offline calibration
experiments on two MI datasets verified our proposal. Especially, integrating
data alignment and sophisticated TL approaches can significantly improve the
classification performance, and hence greatly reduce the calibration effort.
</p>
<a href="http://arxiv.org/abs/2007.03746" target="_blank">arXiv:2007.03746</a> [<a href="http://arxiv.org/pdf/2007.03746" target="_blank">pdf</a>]

<h2>Contrastive Code Representation Learning. (arXiv:2007.04973v2 [cs.LG] UPDATED)</h2>
<h3>Paras Jain, Ajay Jain, Tianjun Zhang, Pieter Abbeel, Joseph E. Gonzalez, Ion Stoica</h3>
<p>Machine-aided programming tools such as automated type predictors and
autocomplete are increasingly learning-based. However, current approaches
predominantly rely on supervised learning with task-specific datasets. We
propose Contrastive Code Representation Learning (ContraCode), a
self-supervised algorithm for learning task-agnostic semantic representations
of programs via contrastive learning. Our approach uses no human-provided
labels, only the raw text of programs. ContraCode optimizes for a
representation that is invariant to semantic-preserving code transformations.
We develop an automated source-to-source compiler that generates textually
divergent variants of source programs. We then train a neural network to
identify variants of anchor programs within a large batch of non-equivalent
negatives. To solve this task, the network must extract features representing
the functionality, not form, of the program. In experiments, we pre-train
ContraCode with 1.8M unannotated JavaScript methods mined from GitHub, then
transfer to downstream tasks by fine-tuning. Pre-training with ContraCode
consistently improves the F1 score of code summarization baselines by up to 8%
and top-1 accuracy of type inference baselines by up to 13%. Overall,
ContraCode achieves 9% higher top-1 and 40% higher top-5 accuracy than the
current state-of-the-art static type analyzer for TypeScript.
</p>
<a href="http://arxiv.org/abs/2007.04973" target="_blank">arXiv:2007.04973</a> [<a href="http://arxiv.org/pdf/2007.04973" target="_blank">pdf</a>]

<h2>Deep or Simple Models for Semantic Tagging? It Depends on your Data [Experiments]. (arXiv:2007.05651v2 [cs.CL] UPDATED)</h2>
<h3>Jinfeng Li, Yuliang Li, Xiaolan Wang, Wang-Chiew Tan</h3>
<p>Semantic tagging, which has extensive applications in text mining, predicts
whether a given piece of text conveys the meaning of a given semantic tag. The
problem of semantic tagging is largely solved with supervised learning and
today, deep learning models are widely perceived to be better for semantic
tagging. However, there is no comprehensive study supporting the popular
belief. Practitioners often have to train different types of models for each
semantic tagging task to identify the best model. This process is both
expensive and inefficient.

We embark on a systematic study to investigate the following question: Are
deep models the best performing model for all semantic tagging tasks? To answer
this question, we compare deep models against "simple models" over datasets
with varying characteristics. Specifically, we select three prevalent deep
models (i.e. CNN, LSTM, and BERT) and two simple models (i.e. LR and SVM), and
compare their performance on the semantic tagging task over 21 datasets.
Results show that the size, the label ratio, and the label cleanliness of a
dataset significantly impact the quality of semantic tagging. Simple models
achieve similar tagging quality to deep models on large datasets, but the
runtime of simple models is much shorter. Moreover, simple models can achieve
better tagging quality than deep models when targeting datasets show worse
label cleanliness and/or more severe imbalance. Based on these findings, our
study can systematically guide practitioners in selecting the right learning
model for their semantic tagging task.
</p>
<a href="http://arxiv.org/abs/2007.05651" target="_blank">arXiv:2007.05651</a> [<a href="http://arxiv.org/pdf/2007.05651" target="_blank">pdf</a>]

<h2>Artificial GAN Fingerprints: Rooting Deepfake Attribution in Training Data. (arXiv:2007.08457v3 [cs.CR] UPDATED)</h2>
<h3>Ning Yu, Vladislav Skripniuk, Sahar Abdelnabi, Mario Fritz</h3>
<p>Photorealistic image generation is progressing rapidly and has reached a new
level of quality, thanks to the invention and breakthroughs of generative
adversarial networks (GANs). Yet the dark side of such deepfakes, the malicious
use of generated media, never stops raising concerns of visual misinformation.
Existing research works on deepfake detection demonstrate impressive accuracy,
while it is accompanied by adversarial iterations on detection countermeasure
techniques. In order to lead this arms race to the end, we investigate a
fundamental solution on deepfake detection, agnostic to the evolution of GANs
in order to enable a responsible disclosure or regulation of such double-edged
techniques. We propose to embed artificial fingerprints into GAN training data,
and show a surprising discovery on the transferability of such fingerprints
from training data to GAN models, which in turn enables reliable detection and
attribution of deepfakes. Our empirical study shows that our fingerprinting
technique (1) holds for different state-of-the-art GAN configurations, (2)
turns more effective along with the development of GAN techniques, (3) has a
negligible side effect on the generation quality, and (4) stays robust against
image-level and model-level perturbations. When we allocate each GAN publisher
a unique artificial fingerprint, the margins between real data and deepfakes,
and the margins among different deepfake sources are fundamentally guaranteed.
As a result, we are able to evidence accurate deepfake detection/attribution
using our fingerprint decoder, which makes this solution stand out from the
current arms race.
</p>
<a href="http://arxiv.org/abs/2007.08457" target="_blank">arXiv:2007.08457</a> [<a href="http://arxiv.org/pdf/2007.08457" target="_blank">pdf</a>]

<h2>Speech2Video Synthesis with 3D Skeleton Regularization and Expressive Body Poses. (arXiv:2007.09198v5 [cs.CV] UPDATED)</h2>
<h3>Miao Liao, Sibo Zhang, Peng Wang, Hao Zhu, Xinxin Zuo, Ruigang Yang</h3>
<p>In this paper, we propose a novel approach to convert given speech audio to a
photo-realistic speaking video of a specific person, where the output video has
synchronized, realistic, and expressive rich body dynamics. We achieve this by
first generating 3D skeleton movements from the audio sequence using a
recurrent neural network (RNN), and then synthesizing the output video via a
conditional generative adversarial network (GAN). To make the skeleton movement
realistic and expressive, we embed the knowledge of an articulated 3D human
skeleton and a learned dictionary of personal speech iconic gestures into the
generation process in both learning and testing pipelines. The former prevents
the generation of unreasonable body distortion, while the later helps our model
quickly learn meaningful body movement through a few recorded videos. To
produce photo-realistic and high-resolution video with motion details, we
propose to insert part attention mechanisms in the conditional GAN, where each
detailed part, e.g. head and hand, is automatically zoomed in to have their own
discriminators. To validate our approach, we collect a dataset with 20
high-quality videos from 1 male and 1 female model reading various documents
under different topics. Compared with previous SoTA pipelines handling similar
tasks, our approach achieves better results by a user study.
</p>
<a href="http://arxiv.org/abs/2007.09198" target="_blank">arXiv:2007.09198</a> [<a href="http://arxiv.org/pdf/2007.09198" target="_blank">pdf</a>]

<h2>Characterizing drug mentions in COVID-19 Twitter Chatter. (arXiv:2007.10276v2 [cs.IR] UPDATED)</h2>
<h3>Ramya Tekumalla, Juan M. Banda</h3>
<p>Since the classification of COVID-19 as a global pandemic, there have been
many attempts to treat and contain the virus. Although there is no specific
antiviral treatment recommended for COVID-19, there are several drugs that can
potentially help with symptoms. In this work, we mined a large twitter dataset
of 424 million tweets of COVID-19 chatter to identify discourse around drug
mentions. While seemingly a straightforward task, due to the informal nature of
language use in Twitter, we demonstrate the need of machine learning alongside
traditional automated methods to aid in this task. By applying these
complementary methods, we are able to recover almost 15% additional data,
making misspelling handling a needed task as a pre-processing step when dealing
with social media data.
</p>
<a href="http://arxiv.org/abs/2007.10276" target="_blank">arXiv:2007.10276</a> [<a href="http://arxiv.org/pdf/2007.10276" target="_blank">pdf</a>]

<h2>Dynamic Relational Inference in Multi-Agent Trajectories. (arXiv:2007.13524v2 [cs.LG] UPDATED)</h2>
<h3>Ruichao Xiao, Manish Kumar Singh, Rose Yu</h3>
<p>Inferring interactions from multi-agent trajectories has broad applications
in physics, vision and robotics. Neural relational inference (NRI) is a deep
generative model that can reason about relations in complex dynamics without
supervision. In this paper, we take a careful look at this approach for
relational inference in multi-agent trajectories. First, we discover that NRI
can be fundamentally limited without sufficient long-term observations. Its
ability to accurately infer interactions degrades drastically for short output
sequences. Next, we consider a more general setting of relational inference
when interactions are changing overtime. We propose an extension ofNRI, which
we call the DYnamic multi-AgentRelational Inference (DYARI) model that can
reason about dynamic relations. We conduct exhaustive experiments to study the
effect of model architecture, under-lying dynamics and training scheme on the
performance of dynamic relational inference using a simulated physics system.
We also showcase the usage of our model on real-world multi-agent basketball
trajectories.
</p>
<a href="http://arxiv.org/abs/2007.13524" target="_blank">arXiv:2007.13524</a> [<a href="http://arxiv.org/pdf/2007.13524" target="_blank">pdf</a>]

<h2>Meta Continual Learning via Dynamic Programming. (arXiv:2008.02219v2 [cs.LG] UPDATED)</h2>
<h3>R. Krishnan, Prasanna Balaprakash</h3>
<p>Meta continual learning algorithms seek to train a model when faced with
similar tasks observed in a sequential manner. Despite promising methodological
advancements, there is a lack of theoretical frameworks that enable analysis of
learning challenges such as generalization and catastrophic forgetting. To that
end, we develop a new theoretical approach for meta continual learning~(MCL)
where we mathematically model the learning dynamics using dynamic programming,
and we establish conditions of optimality for the MCL problem. Moreover, using
the theoretical framework, we derive a new dynamic-programming-based MCL method
that adopts stochastic-gradient-driven alternating optimization to balance
generalization and catastrophic forgetting. We show that, on MCL benchmark data
sets, our theoretically grounded method achieves accuracy better than or
comparable to that of existing state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2008.02219" target="_blank">arXiv:2008.02219</a> [<a href="http://arxiv.org/pdf/2008.02219" target="_blank">pdf</a>]

<h2>Inductive logic programming at 30: a new introduction. (arXiv:2008.07912v2 [cs.AI] UPDATED)</h2>
<h3>Andrew Cropper, Sebastijan Duman&#x10d;i&#x107;</h3>
<p>Inductive logic programming (ILP) is a form of machine learning. The goal of
ILP is to induce a hypothesis (a set of logical rules) that generalises given
training examples. In contrast to most forms of machine learning, ILP can learn
human-readable hypotheses from small amounts of data. As ILP approaches 30, we
provide a new introduction to the field. We introduce the necessary logical
notation and the main ILP learning settings. We describe the main building
blocks of an ILP system. We compare several ILP systems on several dimensions.
We describe in detail four systems (Aleph, TILDE, ASPAL, and Metagol). We
document some of the main application areas of ILP. Finally, we summarise the
current limitations and outline promising directions for future research.
</p>
<a href="http://arxiv.org/abs/2008.07912" target="_blank">arXiv:2008.07912</a> [<a href="http://arxiv.org/pdf/2008.07912" target="_blank">pdf</a>]

<h2>Towards Class-incremental Object Detection with Nearest Mean of Exemplars. (arXiv:2008.08336v3 [cs.CV] UPDATED)</h2>
<h3>Sheng Ren, Yan He, Neal N. Xiong, Kehua Guo</h3>
<p>Incremental learning is a form of online learning. Incremental learning can
modify the parameters and structure of the deep learning model so that the
model does not forget the old knowledge while learning new knowledge.
Preventing catastrophic forgetting is the most important task of incremental
learning. However, the current incremental learning is often only for one type
of input. For example, if the input images are of the same type, the current
incremental model can learn new knowledge while not forgetting old knowledge.
However, if several categories are added to the input graphics, the current
model will not be able to deal with it correctly, and the accuracy will drop
significantly. Therefore, this paper proposes a kind of incremental method,
which adjusts the parameters of the model by identifying the prototype vector
and increasing the distance of the vector, so that the model can learn new
knowledge without catastrophic forgetting. Experiments show the effectiveness
of our proposed method.
</p>
<a href="http://arxiv.org/abs/2008.08336" target="_blank">arXiv:2008.08336</a> [<a href="http://arxiv.org/pdf/2008.08336" target="_blank">pdf</a>]

<h2>Performance Optimization for Federated Person Re-identification via Benchmark Analysis. (arXiv:2008.11560v2 [cs.CV] UPDATED)</h2>
<h3>Weiming Zhuang, Yonggang Wen, Xuesen Zhang, Xin Gan, Daiying Yin, Dongzhan Zhou, Shuai Zhang, Shuai Yi</h3>
<p>Federated learning is a privacy-preserving machine learning technique that
learns a shared model across decentralized clients. It can alleviate privacy
concerns of personal re-identification, an important computer vision task. In
this work, we implement federated learning to person re-identification
(FedReID) and optimize its performance affected by statistical heterogeneity in
the real-world scenario. We first construct a new benchmark to investigate the
performance of FedReID. This benchmark consists of (1) nine datasets with
different volumes sourced from different domains to simulate the heterogeneous
situation in reality, (2) two federated scenarios, and (3) an enhanced
federated algorithm for FedReID. The benchmark analysis shows that the
client-edge-cloud architecture, represented by the federated-by-dataset
scenario, has better performance than client-server architecture in FedReID. It
also reveals the bottlenecks of FedReID under the real-world scenario,
including poor performance of large datasets caused by unbalanced weights in
model aggregation and challenges in convergence. Then we propose two
optimization methods: (1) To address the unbalanced weight problem, we propose
a new method to dynamically change the weights according to the scale of model
changes in clients in each training round; (2) To facilitate convergence, we
adopt knowledge distillation to refine the server model with knowledge
generated from client models on a public dataset. Experiment results
demonstrate that our strategies can achieve much better convergence with
superior performance on all datasets. We believe that our work will inspire the
community to further explore the implementation of federated learning on more
computer vision tasks in real-world scenarios.
</p>
<a href="http://arxiv.org/abs/2008.11560" target="_blank">arXiv:2008.11560</a> [<a href="http://arxiv.org/pdf/2008.11560" target="_blank">pdf</a>]

<h2>A comparison of deep machine learning algorithms in COVID-19 disease diagnosis. (arXiv:2008.11639v2 [cs.LG] UPDATED)</h2>
<h3>Samir S. Yadav, Jasminder Kaur Sandhu, Mininath R. Bendre, Pratap S. Vikhe, Amandeep Kaur</h3>
<p>The aim of the work is to use deep neural network models for solving the
problem of image recognition. These days, every human being is threatened by a
harmful coronavirus disease, also called COVID-19 disease. The spread of
coronavirus affects the economy of many countries in the world. To find
COVID-19 patients early is very essential to avoid the spread and harm to
society. Pathological tests and Chromatography(CT) scans are helpful for the
diagnosis of COVID-19. However, these tests are having drawbacks such as a
large number of false positives, and cost of these tests are so expensive.
Hence, it requires finding an easy, accurate, and less expensive way for the
detection of the harmful COVID-19 disease. Chest-x-ray can be useful for the
detection of this disease. Therefore, in this work chest, x-ray images are used
for the diagnosis of suspected COVID-19 patients using modern machine learning
techniques. The analysis of the results is carried out and conclusions are made
about the effectiveness of deep machine learning algorithms in image
recognition problems.
</p>
<a href="http://arxiv.org/abs/2008.11639" target="_blank">arXiv:2008.11639</a> [<a href="http://arxiv.org/pdf/2008.11639" target="_blank">pdf</a>]

<h2>Learning to Profile: User Meta-Profile Network for Few-Shot Learning. (arXiv:2008.12258v2 [cs.LG] UPDATED)</h2>
<h3>Hao Gong, Qifang Zhao, Tianyu Li, Derek Cho, DuyKhuong Nguyen</h3>
<p>Meta-learning approaches have shown great success in vision and language
domains. However, few studies discuss the practice of meta-learning for
large-scale industrial applications. Although e-commerce companies have spent
many efforts on learning representations to provide a better user experience,
we argue that such efforts cannot be stopped at this step. In addition to
learning a strong profile, the challenging question about how to effectively
transfer the learned representation is raised simultaneously. This paper
introduces the contributions that we made to address these challenges from
three aspects. 1) Meta-learning model: In the context of representation
learning with e-commerce user behavior data, we propose a meta-learning
framework called the Meta-Profile Network, which extends the ideas of matching
network and relation network for knowledge transfer and fast adaptation; 2)
Encoding strategy: To keep high fidelity of large-scale long-term sequential
behavior data, we propose a time-heatmap encoding strategy that allows the
model to encode data effectively; 3) Deep network architecture: A multi-modal
model combined with multi-task learning architecture is utilized to address the
cross-domain knowledge learning and insufficient label problems. Moreover, we
argue that an industrial model should not only have good performance in terms
of accuracy, but also have better robustness and uncertainty performance under
extreme conditions. We evaluate the performance of our model with extensive
control experiments in various extreme scenarios, i.e. out-of-distribution
detection, data insufficiency and class imbalance scenarios. The Meta-Profile
Network shows significant improvement in the model performance when compared to
baseline models.
</p>
<a href="http://arxiv.org/abs/2008.12258" target="_blank">arXiv:2008.12258</a> [<a href="http://arxiv.org/pdf/2008.12258" target="_blank">pdf</a>]

<h2>A Meta-Learning Control Algorithm with Provable Finite-Time Guarantees. (arXiv:2008.13265v5 [cs.LG] UPDATED)</h2>
<h3>Deepan Muthirayan, Pramod Khargonekar</h3>
<p>In this work we provide provable regret guarantees for an online
meta-learning control algorithm in an iterative control setting, where in each
iteration the system to be controlled is a linear deterministic system that is
different and unknown, the cost for the controller in an iteration is a general
additive cost function and the control input is required to be constrained,
which if violated incurs an additional cost. We prove (i) that the algorithm
achieves a regret for the controller cost and constraint violation that are
$O(T^{3/4})$ for an episode of duration $T$ with respect to the best policy
that satisfies the control input control constraints and (ii) that the average
of the regret for the controller cost and constraint violation with respect to
the same policy vary as $O((1+\log(N)/N)T^{3/4})$ with the number of iterations
$N$, showing that the worst regret for the learning within an iteration
continuously improves with experience of more iterations.
</p>
<a href="http://arxiv.org/abs/2008.13265" target="_blank">arXiv:2008.13265</a> [<a href="http://arxiv.org/pdf/2008.13265" target="_blank">pdf</a>]

<h2>NATS-Bench: Benchmarking NAS algorithms for Architecture Topology and Size. (arXiv:2009.00437v3 [cs.LG] UPDATED)</h2>
<h3>Xuanyi Dong, Lu Liu, Katarzyna Musial, Bogdan Gabrys</h3>
<p>Neural architecture search (NAS) has attracted a lot of attention and has
been illustrated to bring tangible benefits in a large number of applications
in the past few years. Network topology and network size have been regarded as
two of the most important aspects for the performance of deep learning models
and the community has spawned lots of searching algorithms for both aspects of
the neural architectures. However, the performance gain from these searching
algorithms is achieved under different search spaces and training setups. This
makes the overall performance of the algorithms to some extent incomparable and
the improvement from a sub-module of the searching model unclear. In this
paper, we propose NATS-Bench, a unified benchmark on searching for both
topology and size, for (almost) any up-to-date NAS algorithm. NATS-Bench
includes the search space of 15,625 neural cell candidates for architecture
topology and 32,768 for architecture size on three datasets. We analyse the
validity of our benchmark in terms of various criteria and performance
comparison of all candidates in the search space. We also show the versatility
of NATS-Bench by benchmarking 13 recent state-of-the-art NAS algorithms on it.
All logs and diagnostic information trained using the same setup for each
candidate are provided. This facilitates a much larger community of researchers
to focus on developing better NAS algorithms in a more comparable and
computationally cost friendly environment. All codes are publicly available at:
https://xuanyidong.com/assets/projects/NATS-Bench .
</p>
<a href="http://arxiv.org/abs/2009.00437" target="_blank">arXiv:2009.00437</a> [<a href="http://arxiv.org/pdf/2009.00437" target="_blank">pdf</a>]

<h2>Efficient Framework for Learning Code Representations through Semantic-Preserving Program Transformations. (arXiv:2009.02731v2 [cs.SE] UPDATED)</h2>
<h3>Nghi D. Q. Bui</h3>
<p>Recent learning techniques for the representation of code depend mostly on
human-annotated (labeled) data. In this work, we are proposing Corder, a
self-supervised learning system that can learn to represent code without having
to label data. The key innovation is that we train the source code model by
asking it to recognize similar and dissimilar code snippets through a
contrastive learning paradigm. We use a set of semantic-preserving
transformation operators to generate snippets that are syntactically diverse
but semantically equivalent. The contrastive learning objective, at the same
time, maximizes agreement between different views of the same snippets and
minimizes agreement between transformed views of different snippets. We train
different instances of Corder on 3 neural network encoders, which are
Tree-based CNN, ASTNN, and Code2vec over 2.5 million unannotated Java methods
mined from GitHub. Our result shows that the Corder pre-training improves code
classification and method name prediction with large margins. Furthermore, the
code vectors generated by Corder are adapted to code clustering which has been
shown to significantly beat the other baselines.
</p>
<a href="http://arxiv.org/abs/2009.02731" target="_blank">arXiv:2009.02731</a> [<a href="http://arxiv.org/pdf/2009.02731" target="_blank">pdf</a>]

<h2>EfficientSeg: An Efficient Semantic Segmentation Network. (arXiv:2009.06469v2 [cs.CV] UPDATED)</h2>
<h3>Vahit Bugra Yesilkaynak, Yusuf H. Sahin, Gozde Unal</h3>
<p>Deep neural network training without pre-trained weights and few data is
shown to need more training iterations. It is also known that, deeper models
are more successful than their shallow counterparts for semantic segmentation
task. Thus, we introduce EfficientSeg architecture, a modified and scalable
version of U-Net, which can be efficiently trained despite its depth. We
evaluated EfficientSeg architecture on Minicity dataset and outperformed U-Net
baseline score (40% mIoU) using the same parameter count (51.5% mIoU). Our most
successful model obtained 58.1% mIoU score and got the fourth place in semantic
segmentation track of ECCV 2020 VIPriors challenge.
</p>
<a href="http://arxiv.org/abs/2009.06469" target="_blank">arXiv:2009.06469</a> [<a href="http://arxiv.org/pdf/2009.06469" target="_blank">pdf</a>]

<h2>An Algorithm to Attack Neural Network Encoder-based Out-Of-Distribution Sample Detector. (arXiv:2009.08016v2 [cs.CV] UPDATED)</h2>
<h3>Liang Liang, Linhai Ma, Linchen Qian, Jiasong Chen</h3>
<p>Deep neural network (DNN), especially convolutional neural network, has
achieved superior performance on image classification tasks. However, such
performance is only guaranteed if the input to a trained model is similar to
the training samples, i.e., the input follows the probability distribution of
the training set. Out-Of-Distribution (OOD) samples do not follow the
distribution of training set, and therefore the predicted class labels on OOD
samples become meaningless. Classification-based methods have been proposed for
OOD detection; however, in this study we show that this type of method is
theoretically ineffective and practically breakable because of dimensionality
reduction in the model. We also show that Glow likelihood-based OOD detection
is ineffective as well. Our analysis is demonstrated on five open datasets,
including a COVID-19 CT dataset. At last, we present a simple theoretical
solution with guaranteed performance for OOD detection.
</p>
<a href="http://arxiv.org/abs/2009.08016" target="_blank">arXiv:2009.08016</a> [<a href="http://arxiv.org/pdf/2009.08016" target="_blank">pdf</a>]

<h2>MARS: Mixed Virtual and Real Wearable Sensors for Human Activity Recognition with Multi-Domain Deep Learning Model. (arXiv:2009.09404v2 [cs.CV] UPDATED)</h2>
<h3>Ling Pei, Songpengcheng Xia, Lei Chu, Fanyi Xiao, Qi Wu, Wenxian Yu, Robert Qiu</h3>
<p>Together with the rapid development of the Internet of Things (IoT), human
activity recognition (HAR) using wearable Inertial Measurement Units (IMUs)
becomes a promising technology for many research areas. Recently, deep
learning-based methods pave a new way of understanding and performing analysis
of the complex data in the HAR system. However, the performance of these
methods is mostly based on the quality and quantity of the collected data. In
this paper, we innovatively propose to build a large database based on virtual
IMUs and then address technical issues by introducing a multiple-domain deep
learning framework consisting of three technical parts. In the first part, we
propose to learn the single-frame human activity from the noisy IMU data with
hybrid convolutional neural networks (CNNs) in the semi-supervised form. For
the second part, the extracted data features are fused according to the
principle of uncertainty-aware consistency, which reduces the uncertainty by
weighting the importance of the features. The transfer learning is performed in
the last part based on the newly released Archive of Motion Capture as Surface
Shapes (AMASS) dataset, containing abundant synthetic human poses, which
enhances the variety and diversity of the training dataset and is beneficial
for the process of training and feature transfer in the proposed method. The
efficiency and effectiveness of the proposed method have been demonstrated in
the real deep inertial poser (DIP) dataset. The experimental results show that
the proposed methods can surprisingly converge within a few iterations and
outperform all competing methods.
</p>
<a href="http://arxiv.org/abs/2009.09404" target="_blank">arXiv:2009.09404</a> [<a href="http://arxiv.org/pdf/2009.09404" target="_blank">pdf</a>]

<h2>Model-Centric and Data-Centric Aspects of Active Learning for Neural Network Models. (arXiv:2009.10835v2 [cs.LG] UPDATED)</h2>
<h3>John Daniel Boss&#xe9;r, Erik S&#xf6;rstadius, Morteza Haghir Chehreghani</h3>
<p>We study different data-centric and model-centric aspects of active learning
with neural network models. i) We investigate incremental and cumulative
training modes that specify how the currently labeled data are used for
training. ii) Neural networks are models with a large capacity. Thus, we study
how active learning depends on the number of epochs and neurons as well as the
choice of batch size. iii) We analyze in detail the behavior of query
strategies and their corresponding informativeness measures and accordingly
propose more efficient querying and active learning paradigms. iv) We perform
statistical analyses, e.g., on actively learned classes and test error
estimation, that reveal several insights about active learning.
</p>
<a href="http://arxiv.org/abs/2009.10835" target="_blank">arXiv:2009.10835</a> [<a href="http://arxiv.org/pdf/2009.10835" target="_blank">pdf</a>]

<h2>Learning in a Small/Big World. (arXiv:2009.11917v3 [econ.TH] UPDATED)</h2>
<h3>Benson Tsz Kin Leung</h3>
<p>Savage (1972) lays down the foundation of Bayesian decision theory, but
asserts that it is not applicable in big worlds where the environment is
complex. Using the theory of finite automaton to model belief formation, this
paper studies the characteristics of optimal learning behavior in small and big
worlds, where the complexity of the environment is low and high, respectively,
relative to the cognitive ability of the decision maker. Confirming Savage's
claim, optimal learning behavior is closed to Bayesian in small worlds but
significantly different in big worlds. In addition, I show that in big worlds,
the optimal learning behavior could exhibit a wide range of well-documented
non-Bayesian learning behavior, including the use of heuristic, correlation
neglect, persistent over-confidence, inattentive learning, and other behaviors
of model simplification or misspecification. These results establish a clear
and testable relationship between the prominence of non-Bayesian learning
behavior, complexity and cognitive ability.
</p>
<a href="http://arxiv.org/abs/2009.11917" target="_blank">arXiv:2009.11917</a> [<a href="http://arxiv.org/pdf/2009.11917" target="_blank">pdf</a>]

<h2>Association Learning Between the COVID-19 Infections and Global Demographic Characteristics Using the Class Rule Mining and Pattern Matching. (arXiv:2009.12923v2 [cs.LG] UPDATED)</h2>
<h3>Wasiq Khan, Abir Hussain, Sohail Ahmed Khan, Mohammed Al-Jumailey, Raheel Nawaz</h3>
<p>Over 26 million cases have been confirmed worldwide (by 20 August 2020) since
the Coronavirus disease (COIVD_19) outbreak in December 2019. Research studies
have been addressing diverse aspects in relation to COVID_19 including
potential symptoms, predictive tools and specifically, correlations with
various demographic attributes. However, very limited work is performed towards
the modelling of complex associations between the combined demographic
attributes and varying nature of the COVID_19 infections across the globe.
Investigating the underlying disease associations with the combined
demographical characteristics might help in comprehensive analysis this
devastating disease as well as contribute to its effective management. In this
study, we present an intelligent model to investigate the multi-dimensional
associations between the potentially relevant demographic attributes and the
COVID_19 severity levels across the globe. We gather multiple demographic
attributes and COVID_19 infection data (by 20 August 2020) from various
reliable sources, which is then fed-into pattern matching algorithms that
include self-organizing maps, class association rules and statistical
approaches, to identify the significant associations within the processed
dataset. Statistical results and the experts report indicate strong
associations between the COVID_19 severity levels and measures of certain
demographic attributes such as female smokers, when combined together with
other attributes. These results strongly suggest that the mechanism underlying
COVID_19 infection severity is associated to distribution of the certain
demographic attributes within different regions of the world. The outcomes will
aid the understanding of the dynamics of disease spread and its progression
that might in turn help the policy makers and the society, in better
understanding and management of the disease.
</p>
<a href="http://arxiv.org/abs/2009.12923" target="_blank">arXiv:2009.12923</a> [<a href="http://arxiv.org/pdf/2009.12923" target="_blank">pdf</a>]

<h2>AI Progress in Skin Lesion Analysis. (arXiv:2009.13323v2 [eess.IV] UPDATED)</h2>
<h3>Philippe M. Burlina, William Paul, Phil A. Mathew, Neil J. Joshi, Alison W. Rebman, John N. Aucott</h3>
<p>We examine progress in the use of AI for detecting skin lesions, with
particular emphasis on the erythema migrans rash of acute Lyme disease, and
other lesions, such as those from conditions like herpes zoster (shingles),
tinea corporis, erythema multiforme, cellulitis, insect bites, or tick bites.
We discuss important challenges for these applications, in particular the
problems of AI bias regarding the lack of skin images in dark skinned
individuals, being able to accurately detect, delineate, and segment lesions or
regions of interest compared to normal skin in images, and low shot learning
(addressing classification with a paucity of training images). Solving these
problems ranges from being highly desirable requirements -- e.g. for
delineation, which may be useful to disambiguate between similar types of
lesions, and perform improved diagnostics -- or required, as is the case for AI
de-biasing, to allow for the deployment of fair AI techniques in the clinic for
skin lesion analysis. For the problem of low shot learning in particular, we
report skin analysis algorithms that gracefully degrade and still perform well
at low shots, when compared to baseline algorithms: when using a little as 10
training exemplars per class, the baseline DL algorithm performance
significantly degrades, with accuracy of 56.41%, close to chance, whereas the
best performing low shot algorithm yields an accuracy of 85.26%.
</p>
<a href="http://arxiv.org/abs/2009.13323" target="_blank">arXiv:2009.13323</a> [<a href="http://arxiv.org/pdf/2009.13323" target="_blank">pdf</a>]

<h2>Current Time Series Anomaly Detection Benchmarks are Flawed and are Creating the Illusion of Progress. (arXiv:2009.13807v3 [cs.LG] UPDATED)</h2>
<h3>Renjie Wu, Eamonn J. Keogh</h3>
<p>Time series anomaly detection has been a perennially important topic in data
science, with papers dating back to the 1950s. However, in recent years there
has been an explosion of interest in this topic, much of it driven by the
success of deep learning in other domains and for other time series tasks. Most
of these papers test on one or more of a handful of popular benchmark datasets,
created by Yahoo, Numenta, NASA, etc. In this work we make a surprising claim.
The majority of the individual exemplars in these datasets suffer from one or
more of four flaws. Because of these four flaws, we believe that many published
comparisons of anomaly detection algorithms may be unreliable, and more
importantly, much of the apparent progress in recent years may be illusionary.
In addition to demonstrating these claims, with this paper we introduce the UCR
Time Series Anomaly Datasets. We believe that this resource will perform a
similar role as the UCR Time Series Classification Archive, by providing the
community with a benchmark that allows meaningful comparisons between
approaches and a meaningful gauge of overall progress.
</p>
<a href="http://arxiv.org/abs/2009.13807" target="_blank">arXiv:2009.13807</a> [<a href="http://arxiv.org/pdf/2009.13807" target="_blank">pdf</a>]

<h2>Deep Equals Shallow for ReLU Networks in Kernel Regimes. (arXiv:2009.14397v2 [stat.ML] UPDATED)</h2>
<h3>Alberto Bietti, Francis Bach</h3>
<p>Deep networks are often considered to be more expressive than shallow ones in
terms of approximation. Indeed, certain functions can be approximated by deep
networks provably more efficiently than by shallow ones, however, no tractable
algorithms are known for learning such deep models. Separately, a recent line
of work has shown that deep networks trained with gradient descent may behave
like (tractable) kernel methods in a certain over-parameterized regime, where
the kernel is determined by the architecture and initialization, and this paper
focuses on approximation for such kernels. We show that for ReLU activations,
the kernels derived from deep fully-connected networks have essentially the
same approximation properties as their shallow two-layer counterpart, namely
the same eigenvalue decay for the corresponding integral operator. This
highlights the limitations of the kernel framework for understanding the
benefits of such deep architectures. Our main theoretical result relies on
characterizing such eigenvalue decays through differentiability properties of
the kernel function, which also easily applies to the study of other kernels
defined on the sphere.
</p>
<a href="http://arxiv.org/abs/2009.14397" target="_blank">arXiv:2009.14397</a> [<a href="http://arxiv.org/pdf/2009.14397" target="_blank">pdf</a>]

<h2>Phonemer at WNUT-2020 Task 2: Sequence Classification Using COVID Twitter BERT and Bagging Ensemble Technique based on Plurality Voting. (arXiv:2010.00294v2 [cs.CL] UPDATED)</h2>
<h3>Anshul Wadhawan</h3>
<p>This paper presents the approach that we employed to tackle the EMNLP
WNUT-2020 Shared Task 2 : Identification of informative COVID-19 English
Tweets. The task is to develop a system that automatically identifies whether
an English Tweet related to the novel coronavirus (COVID-19) is informative or
not. We solve the task in three stages. The first stage involves pre-processing
the dataset by filtering only relevant information. This is followed by
experimenting with multiple deep learning models like CNNs, RNNs and
Transformer based models. In the last stage, we propose an ensemble of the best
model trained on different subsets of the provided dataset. Our final approach
achieved an F1-score of 0.9037 and we were ranked sixth overall with F1-score
as the evaluation criteria.
</p>
<a href="http://arxiv.org/abs/2010.00294" target="_blank">arXiv:2010.00294</a> [<a href="http://arxiv.org/pdf/2010.00294" target="_blank">pdf</a>]

<h2>Neighbourhood Distillation: On the benefits of non end-to-end distillation. (arXiv:2010.01189v2 [cs.LG] UPDATED)</h2>
<h3>La&#xeb;titia Shao, Max Moroz, Elad Eban, Yair Movshovitz-Attias</h3>
<p>End-to-end training with back propagation is the standard method for training
deep neural networks. However, as networks become deeper and bigger, end-to-end
training becomes more challenging: highly non-convex models gets stuck easily
in local optima, gradients signals are prone to vanish or explode during
back-propagation, training requires computational resources and time. In this
work, we propose to break away from the end-to-end paradigm in the context of
Knowledge Distillation. Instead of distilling a model end-to-end, we propose to
split it into smaller sub-networks - also called neighbourhoods - that are then
trained independently. We empirically show that distilling networks in a non
end-to-end fashion can be beneficial in a diverse range of use cases. First, we
show that it speeds up Knowledge Distillation by exploiting parallelism and
training on smaller networks. Second, we show that independently distilled
neighbourhoods may be efficiently re-used for Neural Architecture Search.
Finally, because smaller networks model simpler functions, we show that they
are easier to train with synthetic data than their deeper counterparts.
</p>
<a href="http://arxiv.org/abs/2010.01189" target="_blank">arXiv:2010.01189</a> [<a href="http://arxiv.org/pdf/2010.01189" target="_blank">pdf</a>]

<h2>RANP: Resource Aware Neuron Pruning at Initialization for 3D CNNs. (arXiv:2010.02488v2 [cs.CV] UPDATED)</h2>
<h3>Zhiwei Xu, Thalaiyasingam Ajanthan, Vibhav Vineet, Richard Hartley</h3>
<p>Although 3D Convolutional Neural Networks (CNNs) are essential for most
learning based applications involving dense 3D data, their applicability is
limited due to excessive memory and computational requirements. Compressing
such networks by pruning therefore becomes highly desirable. However, pruning
3D CNNs is largely unexplored possibly because of the complex nature of typical
pruning algorithms that embeds pruning into an iterative optimization paradigm.
In this work, we introduce a Resource Aware Neuron Pruning (RANP) algorithm
that prunes 3D CNNs at initialization to high sparsity levels. Specifically,
the core idea is to obtain an importance score for each neuron based on their
sensitivity to the loss function. This neuron importance is then reweighted
according to the neuron resource consumption related to FLOPs or memory. We
demonstrate the effectiveness of our pruning method on 3D semantic segmentation
with widely used 3D-UNets on ShapeNet and BraTS'18 as well as on video
classification with MobileNetV2 and I3D on UCF101 dataset. In these
experiments, our RANP leads to roughly 50-95 reduction in FLOPs and 35-80
reduction in memory with negligible loss in accuracy compared to the unpruned
networks. This significantly reduces the computational resources required to
train 3D CNNs. The pruned network obtained by our algorithm can also be easily
scaled up and transferred to another dataset for training.
</p>
<a href="http://arxiv.org/abs/2010.02488" target="_blank">arXiv:2010.02488</a> [<a href="http://arxiv.org/pdf/2010.02488" target="_blank">pdf</a>]

<h2>Joint Turn and Dialogue level User Satisfaction Estimation on Multi-Domain Conversations. (arXiv:2010.02495v2 [cs.CL] UPDATED)</h2>
<h3>Praveen Kumar Bodigutla, Aditya Tiwari, Josep Valls Vargas, Lazaros Polymenakos, Spyros Matsoukas</h3>
<p>Dialogue level quality estimation is vital for optimizing data driven
dialogue management. Current automated methods to estimate turn and dialogue
level user satisfaction employ hand-crafted features and rely on complex
annotation schemes, which reduce the generalizability of the trained models. We
propose a novel user satisfaction estimation approach which minimizes an
adaptive multi-task loss function in order to jointly predict turn-level
Response Quality labels provided by experts and explicit dialogue-level ratings
provided by end users. The proposed BiLSTM based deep neural net model
automatically weighs each turn's contribution towards the estimated
dialogue-level rating, implicitly encodes temporal dependencies, and removes
the need to hand-craft features.

On dialogues sampled from 28 Alexa domains, two dialogue systems and three
user groups, the joint dialogue-level satisfaction estimation model achieved up
to an absolute 27% (0.43-&gt;0.70) and 7% (0.63-&gt;0.70) improvement in linear
correlation performance over baseline deep neural net and benchmark Gradient
boosting regression models, respectively.
</p>
<a href="http://arxiv.org/abs/2010.02495" target="_blank">arXiv:2010.02495</a> [<a href="http://arxiv.org/pdf/2010.02495" target="_blank">pdf</a>]

<h2>Optimizing Deep Neural Networks via Discretization of Finite-Time Convergent Flows. (arXiv:2010.02990v2 [cs.LG] UPDATED)</h2>
<h3>Mouhacine Benosman, Orlando Romero, Anoop Cherian</h3>
<p>In this paper, we investigate in the context of deep neural networks, the
performance of several discretization algorithms for two first-order
finite-time optimization flows. These flows are, namely, the rescaled-gradient
flow (RGF) and the signed-gradient flow (SGF), and consist of non-Lipscthiz or
discontinuous dynamical systems that converge locally in finite time to the
minima of gradient-dominated functions. We introduce three discretization
methods for these first-order finite-time flows, and provide convergence
guarantees. We then apply the proposed algorithms in training neural networks
and empirically test their performances on three standard datasets, namely,
CIFAR10, SVHN, and MNIST. Our results show that our schemes demonstrate faster
convergences against standard optimization alternatives, while achieving
equivalent or better accuracy.
</p>
<a href="http://arxiv.org/abs/2010.02990" target="_blank">arXiv:2010.02990</a> [<a href="http://arxiv.org/pdf/2010.02990" target="_blank">pdf</a>]

<h2>Conditional Generative Modeling via Learning the Latent Space. (arXiv:2010.03132v2 [cs.LG] UPDATED)</h2>
<h3>Sameera Ramasinghe, Kanchana Ranasinghe, Salman Khan, Nick Barnes, Stephen Gould</h3>
<p>Although deep learning has achieved appealing results on several machine
learning tasks, most of the models are deterministic at inference, limiting
their application to single-modal settings. We propose a novel general-purpose
framework for conditional generation in multimodal spaces, that uses latent
variables to model generalizable learning patterns while minimizing a family of
regression cost functions. At inference, the latent variables are optimized to
find optimal solutions corresponding to multiple output modes. Compared to
existing generative solutions, in multimodal spaces, our approach demonstrates
faster and stable convergence, and can learn better representations for
downstream tasks. Importantly, it provides a simple generic model that can beat
highly engineered pipelines tailored using domain expertise on a variety of
tasks, while generating diverse outputs. Our codes will be released.
</p>
<a href="http://arxiv.org/abs/2010.03132" target="_blank">arXiv:2010.03132</a> [<a href="http://arxiv.org/pdf/2010.03132" target="_blank">pdf</a>]

<h2>Probabilistic Case-based Reasoning for Open-World Knowledge Graph Completion. (arXiv:2010.03548v2 [cs.CL] UPDATED)</h2>
<h3>Rajarshi Das, Ameya Godbole, Nicholas Monath, Manzil Zaheer, Andrew McCallum</h3>
<p>A case-based reasoning (CBR) system solves a new problem by retrieving
`cases' that are similar to the given problem. If such a system can achieve
high accuracy, it is appealing owing to its simplicity, interpretability, and
scalability. In this paper, we demonstrate that such a system is achievable for
reasoning in knowledge-bases (KBs). Our approach predicts attributes for an
entity by gathering reasoning paths from similar entities in the KB. Our
probabilistic model estimates the likelihood that a path is effective at
answering a query about the given entity. The parameters of our model can be
efficiently computed using simple path statistics and require no iterative
optimization. Our model is non-parametric, growing dynamically as new entities
and relations are added to the KB. On several benchmark datasets our approach
significantly outperforms other rule learning approaches and performs
comparably to state-of-the-art embedding-based approaches. Furthermore, we
demonstrate the effectiveness of our model in an "open-world" setting where new
entities arrive in an online fashion, significantly outperforming
state-of-the-art approaches and nearly matching the best offline method. Code
available at https://github.com/ameyagodbole/Prob-CBR
</p>
<a href="http://arxiv.org/abs/2010.03548" target="_blank">arXiv:2010.03548</a> [<a href="http://arxiv.org/pdf/2010.03548" target="_blank">pdf</a>]

<h2>Learning Intrinsic Symbolic Rewards in Reinforcement Learning. (arXiv:2010.03694v2 [cs.LG] UPDATED)</h2>
<h3>Hassam Sheikh, Shauharda Khadka, Santiago Miret, Somdeb Majumdar</h3>
<p>Learning effective policies for sparse objectives is a key challenge in Deep
Reinforcement Learning (RL). A common approach is to design task-related dense
rewards to improve task learnability. While such rewards are easily
interpreted, they rely on heuristics and domain expertise. Alternate approaches
that train neural networks to discover dense surrogate rewards avoid
heuristics, but are high-dimensional, black-box solutions offering little
interpretability. In this paper, we present a method that discovers dense
rewards in the form of low-dimensional symbolic trees - thus making them more
tractable for analysis. The trees use simple functional operators to map an
agent's observations to a scalar reward, which then supervises the policy
gradient learning of a neural network policy. We test our method on continuous
action spaces in Mujoco and discrete action spaces in Atari and Pygame
environments. We show that the discovered dense rewards are an effective signal
for an RL policy to solve the benchmark tasks. Notably, we significantly
outperform a widely used, contemporary neural-network based reward-discovery
algorithm in all environments considered.
</p>
<a href="http://arxiv.org/abs/2010.03694" target="_blank">arXiv:2010.03694</a> [<a href="http://arxiv.org/pdf/2010.03694" target="_blank">pdf</a>]

<h2>Improved Techniques for Model Inversion Attacks. (arXiv:2010.04092v2 [cs.LG] UPDATED)</h2>
<h3>Si Chen, Ruoxi Jia, Guo-Jun Qi</h3>
<p>Model inversion (MI) attacks in the whitebox setting are aimed at
reconstructing training data from model parameters. Such attacks have triggered
increasing concerns about privacy, especially given a growing number of online
model repositories. However, existing MI attacks against deep neural networks
(DNNs) have large room for performance improvement. A natural question is
whether the underperformance is because the target model does not memorize much
about its training data or it is simply an artifact of imperfect attack
algorithm design? This paper shows that it is the latter. We present a variety
of new techniques that can significantly boost the performance of MI attacks
against DNNs. Recent advances to attack DNNs are largely attributed to the idea
of training a general generative adversarial network (GAN) with potential
public data and using it to regularize the search space for reconstructed
images. We propose to customize the training of a GAN to the inversion task so
as to better distill knowledge useful for performing attacks from public data.
Moreover, unlike previous work that directly searches for a single data point
to represent a target class, we propose to model private data distribution in
order to better reconstruct representative data points. Our experiments show
that the combination of these techniques can lead to state-of-the-art attack
performance on a variety of datasets and models, even when the public data has
a large distributional shift from the private data.
</p>
<a href="http://arxiv.org/abs/2010.04092" target="_blank">arXiv:2010.04092</a> [<a href="http://arxiv.org/pdf/2010.04092" target="_blank">pdf</a>]

<h2>Encoding Physical Constraints in Differentiable Newton-Euler Algorithm. (arXiv:2001.08861v4 [cs.RO] CROSS LISTED)</h2>
<h3>Giovanni Sutanto, Austin S. Wang, Yixin Lin, Mustafa Mukadam, Gaurav S. Sukhatme, Akshara Rai, Franziska Meier</h3>
<p>The recursive Newton-Euler Algorithm (RNEA) is a popular technique for
computing the dynamics of robots. RNEA can be framed as a differentiable
computational graph, enabling the dynamics parameters of the robot to be
learned from data via modern auto-differentiation toolboxes. However, the
dynamics parameters learned in this manner can be physically implausible. In
this work, we incorporate physical constraints in the learning by adding
structure to the learned parameters. This results in a framework that can learn
physically plausible dynamics via gradient descent, improving the training
speed as well as generalization of the learned dynamics models. We evaluate our
method on real-time inverse dynamics control tasks on a 7 degree of freedom
robot arm, both in simulation and on the real robot. Our experiments study a
spectrum of structure added to the parameters of the differentiable RNEA
algorithm, and compare their performance and generalization.
</p>
<a href="http://arxiv.org/abs/2001.08861" target="_blank">arXiv:2001.08861</a> [<a href="http://arxiv.org/pdf/2001.08861" target="_blank">pdf</a>]

<h2>Deep Just-In-Time Inconsistency Detection Between Comments and Source Code. (arXiv:2010.01625v1 [cs.SE] CROSS LISTED)</h2>
<h3>Sheena Panthaplackel, Junyi Jessy Li, Milos Gligoric, Raymond J. Mooney</h3>
<p>Natural language comments convey key aspects of source code such as
implementation, usage, and pre- and post-conditions. Failure to update comments
accordingly when the corresponding code is modified introduces inconsistencies,
which is known to lead to confusion and software bugs. In this paper, we aim to
detect whether a comment becomes inconsistent as a result of changes to the
corresponding body of code, in order to catch potential inconsistencies
just-in-time, i.e., before they are committed to a version control system. To
achieve this, we develop a deep-learning approach that learns to correlate a
comment with code changes. By evaluating on a large corpus of comment/code
pairs spanning various comment types, we show that our model outperforms
multiple baselines by significant margins. For extrinsic evaluation, we show
the usefulness of our approach by combining it with a comment update model to
build a more comprehensive automatic comment maintenance system which can both
detect and resolve inconsistent comments based on code changes.
</p>
<a href="http://arxiv.org/abs/2010.01625" target="_blank">arXiv:2010.01625</a> [<a href="http://arxiv.org/pdf/2010.01625" target="_blank">pdf</a>]

<h2>Wildfire Smoke and Air Quality: How Machine Learning Can Guide Forest Management. (arXiv:2010.04651v1 [stat.AP])</h2>
<h3>Lorenzo Tomaselli, Coty Jen, Ann B. Lee</h3>
<p>Prescribed burns are currently the most effective method of reducing the risk
of widespread wildfires, but a largely missing component in forest management
is knowing which fuels one can safely burn to minimize exposure to toxic smoke.
Here we show how machine learning, such as spectral clustering and manifold
learning, can provide interpretable representations and powerful tools for
differentiating between smoke types, hence providing forest managers with vital
information on effective strategies to reduce climate-induced wildfires while
minimizing production of harmful smoke.
</p>
<a href="http://arxiv.org/abs/2010.04651" target="_blank">arXiv:2010.04651</a> [<a href="http://arxiv.org/pdf/2010.04651" target="_blank">pdf</a>]

