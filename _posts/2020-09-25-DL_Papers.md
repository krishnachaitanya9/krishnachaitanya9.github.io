---
title: Latest Deep Learning Papers
date: 2020-11-04 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>A Scalable Approach for Privacy-Preserving Collaborative Machine Learning. (arXiv:2011.01963v1 [cs.LG])</h2>
<h3>Jinhyun So, Basak Guler, A. Salman Avestimehr</h3>
<p>We consider a collaborative learning scenario in which multiple data-owners
wish to jointly train a logistic regression model, while keeping their
individual datasets private from the other parties. We propose COPML, a
fully-decentralized training framework that achieves scalability and
privacy-protection simultaneously. The key idea of COPML is to securely encode
the individual datasets to distribute the computation load effectively across
many parties and to perform the training computations as well as the model
updates in a distributed manner on the securely encoded data. We provide the
privacy analysis of COPML and prove its convergence. Furthermore, we
experimentally demonstrate that COPML can achieve significant speedup in
training over the benchmark protocols. Our protocol provides strong statistical
privacy guarantees against colluding parties (adversaries) with unbounded
computational power, while achieving up to $16\times$ speedup in the training
time against the benchmark protocols.
</p>
<a href="http://arxiv.org/abs/2011.01963" target="_blank">arXiv:2011.01963</a> [<a href="http://arxiv.org/pdf/2011.01963" target="_blank">pdf</a>]

<h2>AdaDGS: An adaptive black-box optimization method with a nonlocal directional Gaussian smoothing gradient. (arXiv:2011.02009v1 [cs.LG])</h2>
<h3>Hoang Tran, Guannan Zhang</h3>
<p>The local gradient points to the direction of the steepest slope in an
infinitesimal neighborhood. An optimizer guided by the local gradient is often
trapped in local optima when the loss landscape is multi-modal. A directional
Gaussian smoothing (DGS) approach was recently proposed in (Zhang et al., 2020)
and used to define a truly nonlocal gradient, referred to as the DGS gradient,
for high-dimensional black-box optimization. Promising results show that
replacing the traditional local gradient with the DGS gradient can
significantly improve the performance of gradient-based methods in optimizing
highly multi-modal loss functions. However, the optimal performance of the DGS
gradient may rely on fine tuning of two important hyper-parameters, i.e., the
smoothing radius and the learning rate. In this paper, we present a simple, yet
ingenious and efficient adaptive approach for optimization with the DGS
gradient, which removes the need of hyper-parameter fine tuning. Since the DGS
gradient generally points to a good search direction, we perform a line search
along the DGS direction to determine the step size at each iteration. The
learned step size in turn will inform us of the scale of function landscape in
the surrounding area, based on which we adjust the smoothing radius accordingly
for the next iteration. We present experimental results on high-dimensional
benchmark functions, an airfoil design problem and a game content generation
problem. The AdaDGS method has shown superior performance over several the
state-of-the-art black-box optimization methods.
</p>
<a href="http://arxiv.org/abs/2011.02009" target="_blank">arXiv:2011.02009</a> [<a href="http://arxiv.org/pdf/2011.02009" target="_blank">pdf</a>]

<h2>Reduced-order modelling of flutter oscillations using normal forms and scientific machine learning. (arXiv:2011.02041v1 [math.DS])</h2>
<h3>K.H. Lee D.A.W. Barton, L. Renson</h3>
<p>This paper introduces a machine learning approach to take a nonlinear
differential-equation model that exhibits qualitative agreement with a physical
experiment over a range of parameter values and produce a hybrid model that
also exhibits quantitative agreement. The underpinning idea is that the
bifurcation experiment structure of an experiment can be revealed using
techniques such as control-based continuation and then used to generate a
simplified normal-form-like model. A machine learning approach is then used to
learn a coordinate transform from the normal-form-like model to the physical
coordinates of the experiment. This approach is demonstrated on a mathematical
model of aero-elastic flutter, where good agreement at the level of the
bifurcation diagrams is shown between the hybrid model and the underlying
ground truth. Moreover, individual phase portraits and time series are also
reproduced accurately, even in regions away from training data. As such, the
approach holds significant promise for producing quantitatively accurate models
that exhibit the correct nonlinear behaviour over a range of parameter values.
</p>
<a href="http://arxiv.org/abs/2011.02041" target="_blank">arXiv:2011.02041</a> [<a href="http://arxiv.org/pdf/2011.02041" target="_blank">pdf</a>]

<h2>Two-timescale Beamforming Optimization for Intelligent Reflecting Surface Aided Multiuser Communication with QoS Constraints. (arXiv:2011.02237v1 [cs.IT])</h2>
<h3>Ming-Min Zhao, An Liu, Yubo Wan, Rui Zhang</h3>
<p>Intelligent reflecting surface (IRS) is an emerging technology that is able
to reconfigure the wireless channel via tunable passive signal reflection and
thereby enhance the spectral and energy efficiency of wireless networks
cost-effectively. In this paper, we study an IRS-aided multiuser multiple-input
single-output (MISO) wireless system and adopt the two-timescale (TTS)
transmission to reduce the signal processing complexity and channel training
overhead as compared to the existing schemes based on the instantaneous channel
state information (I-CSI), and at the same time, exploit the multiuser channel
diversity in transmission scheduling. Specifically, the long-term passive
beamforming is designed based on the statistical CSI (S-CSI) of all links,
while the short-term active beamforming is designed to cater to the I-CSI of
all users' reconfigured channels with optimized IRS phase shifts. We aim to
minimize the average transmit power at the access point (AP), subject to the
users' individual quality of service (QoS) constraints. The formulated
stochastic optimization problem is non-convex and difficult to solve since the
long-term and short-term design variables are complicatedly coupled in the QoS
constraints. To tackle this problem, we propose an efficient algorithm, called
the primal-dual decomposition based TTS joint active and passive beamforming
(PDD-TJAPB), where the original problem is decomposed into a long-term problem
and a family of short-term problems, and the deep unfolding technique is
employed to extract gradient information from the short-term problems to
construct a convex surrogate problem for the long-term problem. The proposed
algorithm is proved to converge to a stationary solution of the original
problem almost surely. Simulation results are presented which demonstrate the
advantages and effectiveness of the proposed algorithm as compared to benchmark
schemes.
</p>
<a href="http://arxiv.org/abs/2011.02237" target="_blank">arXiv:2011.02237</a> [<a href="http://arxiv.org/pdf/2011.02237" target="_blank">pdf</a>]

<h2>Cooperative Multi-Beam Routing for Multi-IRS Aided Massive MIMO. (arXiv:2011.02354v1 [cs.IT])</h2>
<h3>Weidong Mei, Rui Zhang</h3>
<p>Intelligent reflecting surface (IRS) is envisioned to play a significant role
in future wireless communication systems thanks to its powerful capability of
enabling smart and reconfigurable radio environment. In this paper, we study
the multi-IRS aided downlink communication in a massive multiple-input
multiple-output (MIMO) system, where a multi-antenna BS simultaneously serves
multiple remote single-antenna users with orthogonal beams reflected by
multiple IRSs. By exploiting the line-of-sight (LoS) link between each pair of
selected IRSs, a multi-hop cascaded LoS link can be established between the BS
and each user via their cooperative beam routing. Under this setup, we optimize
the selected IRSs and their beam routing path for each user, along with the
BS/IRS active/passive beamforming such that the minimum received signal power
among all users is maximized, subject to a new multi-beam routing path
separation constraint for avoiding the inter-user/route interference. To tackle
this problem, we first derive the optimal BS/IRS active/passive beamforming in
closed-form for any given beam routes and show the beam routing optimization is
NP-complete by recasting it as an equivalent graph-optimization problem. To
solve this challenging problem, we then propose an efficient recursive
algorithm to partially enumerate the feasible solutions, which effectively
balances the performance-complexity trade-off by tuning its design parameter.
Numerical results demonstrate that the proposed algorithm can achieve
near-optimal performance with low enumeration complexity and also outperform
other benchmark schemes.
</p>
<a href="http://arxiv.org/abs/2011.02354" target="_blank">arXiv:2011.02354</a> [<a href="http://arxiv.org/pdf/2011.02354" target="_blank">pdf</a>]

<h2>Federated Knowledge Distillation. (arXiv:2011.02367v1 [cs.LG])</h2>
<h3>Hyowoon Seo, Jihong Park, Seungeun Oh, Mehdi Bennis, Seong-Lyun Kim</h3>
<p>Distributed learning frameworks often rely on exchanging model parameters
across workers, instead of revealing their raw data. A prime example is
federated learning that exchanges the gradients or weights of each neural
network model. Under limited communication resources, however, such a method
becomes extremely costly particularly for modern deep neural networks having a
huge number of model parameters. In this regard, federated distillation (FD) is
a compelling distributed learning solution that only exchanges the model
outputs whose dimensions are commonly much smaller than the model sizes (e.g.,
10 labels in the MNIST dataset). The goal of this chapter is to provide a deep
understanding of FD while demonstrating its communication efficiency and
applicability to a variety of tasks. To this end, towards demystifying the
operational principle of FD, the first part of this chapter provides a novel
asymptotic analysis for two foundational algorithms of FD, namely knowledge
distillation (KD) and co-distillation (CD), by exploiting the theory of neural
tangent kernel (NTK). Next, the second part elaborates on a baseline
implementation of FD for a classification task, and illustrates its performance
in terms of accuracy and communication efficiency compared to FL. Lastly, to
demonstrate the applicability of FD to various distributed learning tasks and
environments, the third part presents two selected applications, namely FD over
asymmetric uplink-and-downlink wireless channels and FD for reinforcement
learning.
</p>
<a href="http://arxiv.org/abs/2011.02367" target="_blank">arXiv:2011.02367</a> [<a href="http://arxiv.org/pdf/2011.02367" target="_blank">pdf</a>]

<h2>Diagonal complexes for surfaces of finite type and surfaces with involution. (arXiv:1802.09336v3 [math.GT] UPDATED)</h2>
<h3>Joseph Gordon, Gaiane Panina</h3>
<p>Two related constructions are studied: (1) The diagonal complex $\mathcal{D}$
and its barycentric subdivision $\mathcal{BD}$ related to a \textit{punctured}
oriented surface $F$ equipped with a number of labeled marked points. (2) The
symmetric diagonal complex $\mathcal{D}^{inv}$ and its barycentric subdivision
$\mathcal{BD}^{inv}$ related to a symmetric (=with an involution) oriented
surface $F$ equipped with a number of (symmetrically placed) labeled marked
points. Eliminating a puncture gives rise to a bundle whose fibers are
homeomorphic to a surgery of the surface $F$. The bundle can be viewed as the
"universal curve with holes". The symmetric complex is shown to be homotopy
equivalent to the complex of a punctured surface obtained by a surgery of the
initial symmetric surface.
</p>
<a href="http://arxiv.org/abs/1802.09336" target="_blank">arXiv:1802.09336</a> [<a href="http://arxiv.org/pdf/1802.09336" target="_blank">pdf</a>]

<h2>The Variational Deficiency Bottleneck. (arXiv:1810.11677v3 [cs.IT] UPDATED)</h2>
<h3>Pradeep Kr. Banerjee, Guido Mont&#xfa;far</h3>
<p>We introduce a bottleneck method for learning data representations based on
information deficiency, rather than the more traditional information
sufficiency. A variational upper bound allows us to implement this method
efficiently. The bound itself is bounded above by the variational information
bottleneck objective, and the two methods coincide in the regime of single-shot
Monte Carlo approximations. The notion of deficiency provides a principled way
of approximating complicated channels by relatively simpler ones. We show that
the deficiency of one channel with respect to another has an operational
interpretation in terms of the optimal risk gap of decision problems, capturing
classification as a special case. Experiments demonstrate that the deficiency
bottleneck can provide advantages in terms of minimal sufficiency as measured
by information bottleneck curves, while retaining robust test performance in
classification tasks.
</p>
<a href="http://arxiv.org/abs/1810.11677" target="_blank">arXiv:1810.11677</a> [<a href="http://arxiv.org/pdf/1810.11677" target="_blank">pdf</a>]

<h2>Structure-adaptive manifold estimation. (arXiv:1906.05014v4 [math.ST] UPDATED)</h2>
<h3>Nikita Puchkin, Vladimir Spokoiny</h3>
<p>We consider a problem of manifold estimation from noisy observations. Many
manifold learning procedures locally approximate a manifold by a weighted
average over a small neighborhood. However, in the presence of large noise, the
assigned weights become so corrupted that the averaged estimate shows very poor
performance. We suggest a novel computationally efficient structure-adaptive
procedure which simultaneously reconstructs a smooth manifold and estimates
projections of the point cloud onto this manifold. The proposed approach
iteratively refines the weights on each step, using the structural information
obtained at previous steps. After several iterations, we obtain nearly "oracle"
weights, so that the final estimates are nearly efficient even in the presence
of relatively large noise. In our theoretical study we establish tight lower
and upper bounds proving asymptotic optimality of the method for manifold
estimation under the Hausdorff loss, provided that the noise degrades to zero
fast enough.
</p>
<a href="http://arxiv.org/abs/1906.05014" target="_blank">arXiv:1906.05014</a> [<a href="http://arxiv.org/pdf/1906.05014" target="_blank">pdf</a>]

<h2>Efficient Evaluation of Natural Stochastic Policies in Offline Reinforcement Learning. (arXiv:2006.03886v2 [cs.LG] UPDATED)</h2>
<h3>Nathan Kallus, Masatoshi Uehara</h3>
<p>We study the efficient off-policy evaluation of natural stochastic policies,
which are defined in terms of deviations from the behavior policy. This is a
departure from the literature on off-policy evaluation where most work consider
the evaluation of explicitly specified policies. Crucially, offline
reinforcement learning with natural stochastic policies can help alleviate
issues of weak overlap, lead to policies that build upon current practice, and
improve policies' implementability in practice. Compared with the classic case
of a pre-specified evaluation policy, when evaluating natural stochastic
policies, the efficiency bound, which measures the best-achievable estimation
error, is inflated since the evaluation policy itself is unknown. In this
paper, we derive the efficiency bounds of two major types of natural stochastic
policies: tilting policies and modified treatment policies. We then propose
efficient nonparametric estimators that attain the efficiency bounds under very
lax conditions. These also enjoy a (partial) double robustness property.
</p>
<a href="http://arxiv.org/abs/2006.03886" target="_blank">arXiv:2006.03886</a> [<a href="http://arxiv.org/pdf/2006.03886" target="_blank">pdf</a>]

<h2>Pseudo-Sylvester domains and skew Laurent polynomials over firs. (arXiv:2006.08454v2 [math.RA] UPDATED)</h2>
<h3>Fabian Henneke, Diego L&#xf3;pez-&#xc1;lvarez</h3>
<p>Building on recent work of Jaikin-Zapirain, we provide a homological
criterion for a ring to be a pseudo-Sylvester domain, that is, to admit a
division ring of fractions over which all stably full matrices become
invertible. We use the criterion to study skew Laurent polynomial rings over
free ideal rings (firs). As an application of our methods, we prove that
crossed products of division rings with free-by-{infinite cyclic} and surface
groups are pseudo-Sylvester domains unconditionally and Sylvester domains if
and only if they admit stably free cancellation. This relies on the recent
proof of the Farrell--Jones conjecture for normally poly-free groups and
extends previous results of Linnell--L\"uck and Jaikin-Zapirain on universal
localizations and universal fields of fractions of such crossed products.
</p>
<a href="http://arxiv.org/abs/2006.08454" target="_blank">arXiv:2006.08454</a> [<a href="http://arxiv.org/pdf/2006.08454" target="_blank">pdf</a>]

<h2>Coupling-based Invertible Neural Networks Are Universal Diffeomorphism Approximators. (arXiv:2006.11469v2 [cs.LG] UPDATED)</h2>
<h3>Takeshi Teshima, Isao Ishikawa, Koichi Tojo, Kenta Oono, Masahiro Ikeda, Masashi Sugiyama</h3>
<p>Invertible neural networks based on coupling flows (CF-INNs) have various
machine learning applications such as image synthesis and representation
learning. However, their desirable characteristics such as analytic
invertibility come at the cost of restricting the functional forms. This poses
a question on their representation power: are CF-INNs universal approximators
for invertible functions? Without a universality, there could be a well-behaved
invertible transformation that the CF-INN can never approximate, hence it would
render the model class unreliable. We answer this question by showing a
convenient criterion: a CF-INN is universal if its layers contain affine
coupling and invertible linear functions as special cases. As its corollary, we
can affirmatively resolve a previously unsolved problem: whether normalizing
flow models based on affine coupling can be universal distributional
approximators. In the course of proving the universality, we prove a general
theorem to show the equivalence of the universality for certain diffeomorphism
classes, a theoretical insight that is of interest by itself.
</p>
<a href="http://arxiv.org/abs/2006.11469" target="_blank">arXiv:2006.11469</a> [<a href="http://arxiv.org/pdf/2006.11469" target="_blank">pdf</a>]

<h2>Understanding the Role of Momentum in Non-Convex Optimization: Practical Insights from a Lyapunov Analysis. (arXiv:2010.00406v2 [cs.LG] UPDATED)</h2>
<h3>Aaron Defazio</h3>
<p>Momentum methods are now used pervasively within the machine learning
community for training non-convex models such as deep neural networks.
Empirically, they out perform traditional stochastic gradient descent (SGD)
approaches. In this work we develop a Lyapunov analysis of SGD with momentum
(SGD+M), by utilizing a equivalent rewriting of the method known as the
stochastic primal averaging (SPA) form. This analysis is much tighter than
previous theory in the non-convex case, and due to this we are able to give
precise insights into when SGD+M may out-perform SGD, and what hyper-parameter
schedules will work and why.
</p>
<a href="http://arxiv.org/abs/2010.00406" target="_blank">arXiv:2010.00406</a> [<a href="http://arxiv.org/pdf/2010.00406" target="_blank">pdf</a>]

<h2>Power of data in quantum machine learning. (arXiv:2011.01938v1 [quant-ph])</h2>
<h3>Hsin-Yuan Huang, Michael Broughton, Masoud Mohseni, Ryan Babbush, Sergio Boixo, Hartmut Neven, Jarrod R. McClean</h3>
<p>The use of quantum computing for machine learning is among the most exciting
prospective applications of quantum technologies. At the crux of excitement is
the potential for quantum computers to perform some computations exponentially
faster than their classical counterparts. However, a machine learning task
where some data is provided can be considerably different than more commonly
studied computational tasks. In this work, we show that some problems that are
classically hard to compute can be predicted easily with classical machines
that learn from data. We find that classical machines can often compete or
outperform existing quantum models even on data sets generated by quantum
evolution, especially at large system sizes. Using rigorous prediction error
bounds as a foundation, we develop a methodology for assessing the potential
for quantum advantage in prediction on learning tasks. We show how the use of
exponentially large quantum Hilbert space in existing quantum models can result
in significantly inferior prediction performance compared to classical
machines. To circumvent the observed setbacks, we propose an improvement by
projecting all quantum states to an approximate classical representation. The
projected quantum model provides a simple and rigorous quantum speed-up for a
recently proposed learning problem in the fault-tolerant regime. For more
near-term quantum models, the projected versions demonstrate a significant
prediction advantage over some classical models on engineered data sets in one
of the largest numerical tests for gate-based quantum machine learning to date,
up to 30 qubits.
</p>
<a href="http://arxiv.org/abs/2011.01938" target="_blank">arXiv:2011.01938</a> [<a href="http://arxiv.org/pdf/2011.01938" target="_blank">pdf</a>]

<h2>Insights into Fairness through Trust: Multi-scale Trust Quantification for Financial Deep Learning. (arXiv:2011.01961v1 [cs.LG])</h2>
<h3>Alexander Wong, Andrew Hryniowski, Xiao Yu Wang</h3>
<p>The success of deep learning in recent years have led to a significant
increase in interest and prevalence for its adoption to tackle financial
services tasks. One particular question that often arises as a barrier to
adopting deep learning for financial services is whether the developed
financial deep learning models are fair in their predictions, particularly in
light of strong governance and regulatory compliance requirements in the
financial services industry. A fundamental aspect of fairness that has not been
explored in financial deep learning is the concept of trust, whose variations
may point to an egocentric view of fairness and thus provide insights into the
fairness of models. In this study we explore the feasibility and utility of a
multi-scale trust quantification strategy to gain insights into the fairness of
a financial deep learning model, particularly under different scenarios at
different scales. More specifically, we conduct multi-scale trust
quantification on a deep neural network for the purpose of credit card default
prediction to study: 1) the overall trustworthiness of the model 2) the trust
level under all possible prediction-truth relationships, 3) the trust level
across the spectrum of possible predictions, 4) the trust level across
different demographic groups (e.g., age, gender, and education), and 5)
distribution of overall trust for an individual prediction scenario. The
insights for this proof-of-concept study demonstrate that such a multi-scale
trust quantification strategy may be helpful for data scientists and regulators
in financial services as part of the verification and certification of
financial deep learning solutions to gain insights into fairness and trust of
these solutions.
</p>
<a href="http://arxiv.org/abs/2011.01961" target="_blank">arXiv:2011.01961</a> [<a href="http://arxiv.org/pdf/2011.01961" target="_blank">pdf</a>]

<h2>Learning 3D Dynamic Scene Representations for Robot Manipulation. (arXiv:2011.01968v1 [cs.RO])</h2>
<h3>Zhenjia Xu, Zhanpeng He, Jiajun Wu, Shuran Song</h3>
<p>3D scene representation for robot manipulation should capture three key
object properties: permanency -- objects that become occluded over time
continue to exist; amodal completeness -- objects have 3D occupancy, even if
only partial observations are available; spatiotemporal continuity -- the
movement of each object is continuous over space and time. In this paper, we
introduce 3D Dynamic Scene Representation (DSR), a 3D volumetric scene
representation that simultaneously discovers, tracks, reconstructs objects, and
predicts their dynamics while capturing all three properties. We further
propose DSR-Net, which learns to aggregate visual observations over multiple
interactions to gradually build and refine DSR. Our model achieves
state-of-the-art performance in modeling 3D scene dynamics with DSR on both
simulated and real data. Combined with model predictive control, DSR-Net
enables accurate planning in downstream robotic manipulation tasks such as
planar pushing. Video is available at https://youtu.be/GQjYG3nQJ80.
</p>
<a href="http://arxiv.org/abs/2011.01968" target="_blank">arXiv:2011.01968</a> [<a href="http://arxiv.org/pdf/2011.01968" target="_blank">pdf</a>]

<h2>Mixing Consistent Deep Clustering. (arXiv:2011.01977v1 [cs.LG])</h2>
<h3>Daniel Lutscher, Ali el Hassouni, Maarten Stol, Mark Hoogendoorn</h3>
<p>Finding well-defined clusters in data represents a fundamental challenge for
many data-driven applications, and largely depends on good data representation.
Drawing on literature regarding representation learning, studies suggest that
one key characteristic of good latent representations is the ability to produce
semantically mixed outputs when decoding linear interpolations of two latent
representations. We propose the Mixing Consistent Deep Clustering method which
encourages interpolations to appear realistic while adding the constraint that
interpolations of two data points must look like one of the two inputs. By
applying this training method to various clustering (non-)specific autoencoder
models we found that using the proposed training method systematically changed
the structure of learned representations of a model and it improved clustering
performance for the tested ACAI, IDEC, and VAE models on the MNIST, SVHN, and
CIFAR-10 datasets. These outcomes have practical implications for numerous
real-world clustering tasks, as it shows that the proposed method can be added
to existing autoencoders to further improve clustering performance.
</p>
<a href="http://arxiv.org/abs/2011.01977" target="_blank">arXiv:2011.01977</a> [<a href="http://arxiv.org/pdf/2011.01977" target="_blank">pdf</a>]

<h2>Unsupervised Pattern Discovery from Thematic Speech Archives Based on Multilingual Bottleneck Features. (arXiv:2011.01986v1 [eess.AS])</h2>
<h3>Man-Ling Sung, Siyuan Feng, Tan Lee</h3>
<p>The present study tackles the problem of automatically discovering spoken
keywords from untranscribed audio archives without requiring word-by-word
speech transcription by automatic speech recognition (ASR) technology. The
problem is of practical significance in many applications of speech analytics,
including those concerning low-resource languages, and large amount of
multilingual and multi-genre data. We propose a two-stage approach, which
comprises unsupervised acoustic modeling and decoding, followed by pattern
mining in acoustic unit sequences. The whole process starts by deriving and
modeling a set of subword-level speech units with untranscribed data. With the
unsupervisedly trained acoustic models, a given audio archive is represented by
a pseudo transcription, from which spoken keywords can be discovered by string
mining algorithms. For unsupervised acoustic modeling, a deep neural network
trained by multilingual speech corpora is used to generate speech segmentation
and compute bottleneck features for segment clustering. Experimental results
show that the proposed system is able to effectively extract topic-related
words and phrases from the lecture recordings on MIT OpenCourseWare.
</p>
<a href="http://arxiv.org/abs/2011.01986" target="_blank">arXiv:2011.01986</a> [<a href="http://arxiv.org/pdf/2011.01986" target="_blank">pdf</a>]

<h2>Internal Language Model Estimation for Domain-Adaptive End-to-End Speech Recognition. (arXiv:2011.01991v1 [eess.AS])</h2>
<h3>Zhong Meng, Sarangarajan Parthasarathy, Eric Sun, Yashesh Gaur, Naoyuki Kanda, Liang Lu, Xie Chen, Rui Zhao, Jinyu Li, Yifan Gong</h3>
<p>The external language models (LM) integration remains a challenging task for
end-to-end (E2E) automatic speech recognition (ASR) which has no clear division
between acoustic and language models. In this work, we propose an internal LM
estimation (ILME) method to facilitate a more effective integration of the
external LM with all pre-existing E2E models with no additional model training,
including the most popular recurrent neural network transducer (RNN-T) and
attention-based encoder-decoder (AED) models. Trained with audio-transcript
pairs, an E2E model implicitly learns an internal LM that characterizes the
training data in the source domain. With ILME, the internal LM scores of an E2E
model are estimated and subtracted from the log-linear interpolation between
the scores of the E2E model and the external LM. The internal LM scores are
approximated as the output of an E2E model when eliminating its acoustic
components. ILME can alleviate the domain mismatch between training and
testing, or improve the multi-domain E2E ASR. Experimented with 30K-hour
trained RNN-T and AED models, ILME achieves up to 15.5% and 6.8% relative word
error rate reductions from Shallow Fusion on out-of-domain LibriSpeech and
in-domain Microsoft production test sets, respectively.
</p>
<a href="http://arxiv.org/abs/2011.01991" target="_blank">arXiv:2011.01991</a> [<a href="http://arxiv.org/pdf/2011.01991" target="_blank">pdf</a>]

<h2>Autonomous Wall Building with a UGV-UAV Team at MBZIRC 2020. (arXiv:2011.01999v1 [cs.RO])</h2>
<h3>Christian Lenz, Max Schwarz, Andre Rochow, Jan Razlaw, Arul Selvam Periyasamy, Michael Schreiber, Sven Behnke</h3>
<p>Constructing large structures with robots is a challenging task with many
potential applications that requires mobile manipulation capabilities. We
present two systems for autonomous wall building that we developed for the
Mohamed Bin Zayed International Robotics Challenge 2020. Both systems
autonomously perceive their environment, find bricks, and build a predefined
wall structure. While the UGV uses a 3D LiDAR-based perception system which
measures brick poses with high precision, the UAV employs a real-time
camera-based system for visual servoing. We report results and insights from
our successful participation at the MBZIRC 2020 Finals, additional lab
experiments, and discuss the lessons learned from the competition.
</p>
<a href="http://arxiv.org/abs/2011.01999" target="_blank">arXiv:2011.01999</a> [<a href="http://arxiv.org/pdf/2011.01999" target="_blank">pdf</a>]

<h2>The upgrade of EAST Safety and Interlock system. (arXiv:2011.02028v1 [physics.ins-det])</h2>
<h3>Z.C. Zhang, B.J. Xiao, Z.S. Ji, Y. Wang, F. Xia, Z.H. Xu</h3>
<p>The Experimental Advanced Superconducting Tokamak (EAST), a nation-level
large-scale scientific project of China, plays a key role for the research of
peaceful utilizations of fusion energy. The safety and interlock system (SIS)
is in charge of the supervision and control of all the EAST components involved
in the protection of human and tokamak from potential accidents. With the
development of physical experiment, the SIS had come close to reaching its
limits for expandability. Therefore, a prototype for upgrading EAST SIS has
been designed, and a fast architecture based on COTS FPGA is absorbed into the
new SIS. This paper presents EAST machine and human protection mechanism and
the architecture of the upgrading safety and interlock system.
</p>
<a href="http://arxiv.org/abs/2011.02028" target="_blank">arXiv:2011.02028</a> [<a href="http://arxiv.org/pdf/2011.02028" target="_blank">pdf</a>]

<h2>PyLightcurve-torch: a transit modelling package for deep learning applications in PyTorch. (arXiv:2011.02030v1 [astro-ph.EP])</h2>
<h3>Mario Morvan, Angelos Tsiaras, Nikolaos Nikolaou, Ingo P. Waldmann</h3>
<p>We present a new open source python package, based on PyLightcurve and
PyTorch, tailored for efficient computation and automatic differentiation of
exoplanetary transits. The classes and functions implemented are fully
vectorised, natively GPU-compatible and differentiable with respect to the
stellar and planetary parameters. This makes PyLightcurve-torch suitable for
traditional forward computation of transits, but also extends the range of
possible applications with inference and optimisation algorithms requiring
access to the gradients of the physical model. This endeavour is aimed at
fostering the use of deep learning in exoplanets research, motivated by an ever
increasing amount of stellar light curves data and various incentives for the
improvement of detection and characterisation techniques.
</p>
<a href="http://arxiv.org/abs/2011.02030" target="_blank">arXiv:2011.02030</a> [<a href="http://arxiv.org/pdf/2011.02030" target="_blank">pdf</a>]

<h2>(Un)fairness in Post-operative Complication Prediction Models. (arXiv:2011.02036v1 [cs.LG])</h2>
<h3>Sandhya Tripathi, Bradley A. Fritz, Mohamed Abdelhack, Michael S. Avidan, Yixin Chen, Christopher R. King</h3>
<p>With the current ongoing debate about fairness, explainability and
transparency of machine learning models, their application in high-impact
clinical decision-making systems must be scrutinized. We consider a real-life
example of risk estimation before surgery and investigate the potential for
bias or unfairness of a variety of algorithms. Our approach creates transparent
documentation of potential bias so that the users can apply the model
carefully. We augment a model-card like analysis using propensity scores with a
decision-tree based guide for clinicians that would identify predictable
shortcomings of the model. In addition to functioning as a guide for users, we
propose that it can guide the algorithm development and informatics team to
focus on data sources and structures that can address these shortcomings.
</p>
<a href="http://arxiv.org/abs/2011.02036" target="_blank">arXiv:2011.02036</a> [<a href="http://arxiv.org/pdf/2011.02036" target="_blank">pdf</a>]

<h2>Integrating Deep-Learning-Based Image Completion and Motion Planning to Expedite Indoor Mapping. (arXiv:2011.02043v1 [cs.LG])</h2>
<h3>Shmuel Y. Hayoun, Elchanan Zwecher, Eran Iceland, Ahavatya Revivo, Sean R. Levy, Ariel Barel</h3>
<p>The challenge of autonomous indoor mapping is addressed. The goal is to
minimize the time required to achieve a predefined percentage of coverage with
some desired level of certainty. The use of a pre-trained generative deep
neural network, acting as a map predictor, in both the motion planning and the
map construction is proposed in order to expedite the mapping process. The
issue of planning under partial observability is tackled by maintaining a
belief map of the floorplan, generated by a deep neural network. This allows
the agent to shorten the mapping duration, as well as enabling it to make
better-informed decisions. This method is examined in combination with several
motion planners for two distinct floorplan datasets. Simulations are run for
several configurations of the integrated map predictor, the results of which
reveal that by utilizing the prediction a significant reduction in mapping time
is possible. When the prediction is integrated in both motion planning and map
construction processes it is shown that the mapping time may in some cases be
cut by over 50%.
</p>
<a href="http://arxiv.org/abs/2011.02043" target="_blank">arXiv:2011.02043</a> [<a href="http://arxiv.org/pdf/2011.02043" target="_blank">pdf</a>]

<h2>Generating Synthetic Data for Task-Oriented Semantic Parsing with Hierarchical Representations. (arXiv:2011.02050v1 [cs.CL])</h2>
<h3>Ke Tran, Ming Tan</h3>
<p>Modern conversational AI systems support natural language understanding for a
wide variety of capabilities. While a majority of these tasks can be
accomplished using a simple and flat representation of intents and slots, more
sophisticated capabilities require complex hierarchical representations
supported by semantic parsing. State-of-the-art semantic parsers are trained
using supervised learning with data labeled according to a hierarchical schema
which might be costly to obtain or not readily available for a new domain. In
this work, we explore the possibility of generating synthetic data for neural
semantic parsing using a pretrained denoising sequence-to-sequence model (i.e.,
BART). Specifically, we first extract masked templates from the existing
labeled utterances, and then fine-tune BART to generate synthetic utterances
conditioning on the extracted templates. Finally, we use an auxiliary parser
(AP) to filter the generated utterances. The AP guarantees the quality of the
generated data. We show the potential of our approach when evaluating on the
Facebook TOP dataset for navigation domain.
</p>
<a href="http://arxiv.org/abs/2011.02050" target="_blank">arXiv:2011.02050</a> [<a href="http://arxiv.org/pdf/2011.02050" target="_blank">pdf</a>]

<h2>Self-Adaptively Learning to Demoire from Focused and Defocused Image Pairs. (arXiv:2011.02055v1 [eess.IV])</h2>
<h3>Lin Liu, Shanxin Yuan, Jianzhuang Liu, Liping Bao, Gregory Slabaugh, Qi Tian</h3>
<p>Moire artifacts are common in digital photography, resulting from the
interference between high-frequency scene content and the color filter array of
the camera. Existing deep learning-based demoireing methods trained on large
scale datasets are limited in handling various complex moire patterns, and
mainly focus on demoireing of photos taken of digital displays. Moreover,
obtaining moire-free ground-truth in natural scenes is difficult but needed for
training. In this paper, we propose a self-adaptive learning method for
demoireing a high-frequency image, with the help of an additional defocused
moire-free blur image. Given an image degraded with moire artifacts and a
moire-free blur image, our network predicts a moire-free clean image and a blur
kernel with a self-adaptive strategy that does not require an explicit training
stage, instead performing test-time adaptation. Our model has two sub-networks
and works iteratively. During each iteration, one sub-network takes the moire
image as input, removing moire patterns and restoring image details, and the
other sub-network estimates the blur kernel from the blur image. The two
sub-networks are jointly optimized. Extensive experiments demonstrate that our
method outperforms state-of-the-art methods and can produce high-quality
demoired results. It can generalize well to the task of removing moire
artifacts caused by display screens. In addition, we build a new moire dataset,
including images with screen and texture moire artifacts. As far as we know,
this is the first dataset with real texture moire patterns.
</p>
<a href="http://arxiv.org/abs/2011.02055" target="_blank">arXiv:2011.02055</a> [<a href="http://arxiv.org/pdf/2011.02055" target="_blank">pdf</a>]

<h2>Online Observer-Based Inverse Reinforcement Learning. (arXiv:2011.02057v1 [eess.SY])</h2>
<h3>Ryan Self, Kevin Coleman, He Bai, Rushikesh Kamalapurkar</h3>
<p>In this paper, a novel approach to the output-feedback inverse reinforcement
learning (IRL) problem is developed by casting the IRL problem, for linear
systems with quadratic cost functions, as a state estimation problem. Two
observer-based techniques for IRL are developed, including a novel observer
method that re-uses previous state estimates via history stacks. Theoretical
guarantees for convergence and robustness are established under appropriate
excitation conditions. Simulations demonstrate the performance of the developed
observers and filters under noisy and noise-free measurements.
</p>
<a href="http://arxiv.org/abs/2011.02057" target="_blank">arXiv:2011.02057</a> [<a href="http://arxiv.org/pdf/2011.02057" target="_blank">pdf</a>]

<h2>Uncertainty Estimation in Medical Image Localization: Towards Robust Anterior Thalamus Targeting for Deep Brain Stimulation. (arXiv:2011.02067v1 [eess.IV])</h2>
<h3>Han Liu, Can Cui, Dario J. Englot, Benoit M. Dawant</h3>
<p>Atlas-based methods are the standard approaches for automatic targeting of
the Anterior Nucleus of the Thalamus (ANT) for Deep Brain Stimulation (DBS),
but these are known to lack robustness when anatomic differences between
atlases and subjects are large. To improve the localization robustness, we
propose a novel two-stage deep learning (DL) framework, where the first stage
identifies and crops the thalamus regions from the whole brain MRI and the
second stage performs per-voxel regression on the cropped volume to localize
the targets at the finest resolution scale. To address the issue of data
scarcity, we train the models with the pseudo labels which are created based on
the available labeled data using multi-atlas registration. To assess the
performance of the proposed framework, we validate two sampling-based
uncertainty estimation techniques namely Monte Carlo Dropout (MCDO) and
Test-Time Augmentation (TTA) on the second-stage localization network.
Moreover, we propose a novel uncertainty estimation metric called maximum
activation dispersion (MAD) to estimate the image-wise uncertainty for
localization tasks. Our results show that the proposed method achieved more
robust localization performance than the traditional multi-atlas method and TTA
could further improve the robustness. Moreover, the epistemic and hybrid
uncertainty estimated by MAD could be used to detect the unreliable
localizations and the magnitude of the uncertainty estimated by MAD could
reflect the degree of unreliability for the rejected predictions.
</p>
<a href="http://arxiv.org/abs/2011.02067" target="_blank">arXiv:2011.02067</a> [<a href="http://arxiv.org/pdf/2011.02067" target="_blank">pdf</a>]

<h2>MBVI: Model-Based Value Initialization for Reinforcement Learning. (arXiv:2011.02073v1 [cs.RO])</h2>
<h3>Xubo Lyu, Site Li, Seth Siriya, Ye Pu, Mo Chen</h3>
<p>Model-free reinforcement learning (RL) is capable of learning control
policies for high-dimensional, complex robotic tasks, but tends to be data
inefficient. Model-based RL and optimal control have been proven to be much
more data-efficient if an accurate model of the system and environment is
known, but can be difficult to scale to expressive models for high-dimensional
problems. In this paper, we propose a novel approach to alleviate data
inefficiency of model-free RL by warm-starting the learning process using
model-based solutions. We do so by initializing a high-dimensional value
function via supervision from a low-dimensional value function obtained by
applying model-based techniques on a low-dimensional problem featuring an
approximate system model. Therefore, our approach exploits the model priors
from a simplified problem space implicitly and avoids the direct use of
high-dimensional, expressive models. We demonstrate our approach on two
representative robotic learning tasks and observe significant improvements in
performance and efficiency, and analyze our method empirically with a third
task.
</p>
<a href="http://arxiv.org/abs/2011.02073" target="_blank">arXiv:2011.02073</a> [<a href="http://arxiv.org/pdf/2011.02073" target="_blank">pdf</a>]

<h2>A deep learning classifier for local ancestry inference. (arXiv:2011.02081v1 [q-bio.GN])</h2>
<h3>Matthew Aguirre, Jan Sokol, Guhan Venkataraman, Alexander Ioannidis</h3>
<p>Local ancestry inference (LAI) identifies the ancestry of each segment of an
individual's genome and is an important step in medical and population genetic
studies of diverse cohorts. Several techniques have been used for LAI,
including Hidden Markov Models and Random Forests. Here, we formulate the LAI
task as an image segmentation problem and develop a new LAI tool using a deep
convolutional neural network with an encoder-decoder architecture. We train our
model using complete genome sequences from 982 unadmixed individuals from each
of five continental ancestry groups, and we evaluate it using simulated admixed
data derived from an additional 279 individuals selected from the same
populations. We show that our model is able to learn admixture as a zero-shot
task, yielding ancestry assignments that are nearly as accurate as those from
the existing gold standard tool, RFMix.
</p>
<a href="http://arxiv.org/abs/2011.02081" target="_blank">arXiv:2011.02081</a> [<a href="http://arxiv.org/pdf/2011.02081" target="_blank">pdf</a>]

<h2>DeepReach: A Deep Learning Approach to High-Dimensional Reachability. (arXiv:2011.02082v1 [cs.RO])</h2>
<h3>Somil Bansal, Claire Tomlin</h3>
<p>Hamilton-Jacobi (HJ) reachability analysis is an important formal
verification method for guaranteeing performance and safety properties of
dynamical control systems. Its advantages include compatibility with general
nonlinear system dynamics, formal treatment of bounded disturbances, and the
ability to deal with state and input constraints. However, it involves solving
a PDE, whose computational and memory complexity scales exponentially with
respect to the number of state variables, limiting its direct use to
small-scale systems. We propose DeepReach, a method that leverages new
developments in sinusoidal networks to develop a neural PDE solver for
high-dimensional reachability problems. The computational requirements of
DeepReach do not scale directly with the state dimension, but rather with the
complexity of the underlying reachable tube. DeepReach achieves comparable
results to the state-of-the-art reachability methods, does not require any
explicit supervision for the PDE solution, can easily handle external
disturbances, adversarial inputs, and system constraints, and also provides a
safety controller for the system. We demonstrate DeepReach on a 9D
multi-vehicle collision problem, and a 10D narrow passage problem, motivated by
autonomous driving applications.
</p>
<a href="http://arxiv.org/abs/2011.02082" target="_blank">arXiv:2011.02082</a> [<a href="http://arxiv.org/pdf/2011.02082" target="_blank">pdf</a>]

<h2>Understanding Capacity-Driven Scale-Out Neural Recommendation Inference. (arXiv:2011.02084v1 [cs.DC])</h2>
<h3>Michael Lui (1 and 2), Yavuz Yetim (2), &#xd6;zg&#xfc;r &#xd6;zkan (2), Zhuoran Zhao (2), Shin-Yeh Tsai (2), Carole-Jean Wu (2), Mark Hempstead (3 and 2) ((1) Drexel University, (2) Facebook, (3) Tufts University)</h3>
<p>Deep learning recommendation models have grown to the terabyte scale.
Traditional serving schemes--that load entire models to a single server--are
unable to support this scale. One approach to support this scale is with
distributed serving, or distributed inference, which divides the memory
requirements of a single large model across multiple servers.

This work is a first-step for the systems research community to develop novel
model-serving solutions, given the huge system design space. Large-scale deep
recommender systems are a novel workload and vital to study, as they consume up
to 79% of all inference cycles in the data center. To that end, this work
describes and characterizes scale-out deep learning recommendation inference
using data-center serving infrastructure. This work specifically explores
latency-bounded inference systems, compared to the throughput-oriented training
systems of other recent works. We find that the latency and compute overheads
of distributed inference are largely a result of a model's static embedding
table distribution and sparsity of input inference requests. We further
evaluate three embedding table mapping strategies of three DLRM-like models and
specify challenging design trade-offs in terms of end-to-end latency, compute
overhead, and resource efficiency. Overall, we observe only a marginal latency
overhead when the data-center scale recommendation models are served with the
distributed inference manner--P99 latency is increased by only 1% in the best
case configuration. The latency overheads are largely a result of the commodity
infrastructure used and the sparsity of embedding tables. Even more
encouragingly, we also show how distributed inference can account for
efficiency improvements in data-center scale recommendation serving.
</p>
<a href="http://arxiv.org/abs/2011.02084" target="_blank">arXiv:2011.02084</a> [<a href="http://arxiv.org/pdf/2011.02084" target="_blank">pdf</a>]

<h2>Residual Likelihood Forests. (arXiv:2011.02086v1 [stat.ML])</h2>
<h3>Yan Zuo, Tom Drummond</h3>
<p>This paper presents a novel ensemble learning approach called Residual
Likelihood Forests (RLF). Our weak learners produce conditional likelihoods
that are sequentially optimized using global loss in the context of previous
learners within a boosting-like framework (rather than probability
distributions that are measured from observed data) and are combined
multiplicatively (rather than additively). This increases the efficiency of our
strong classifier, allowing for the design of classifiers which are more
compact in terms of model capacity. We apply our method to several machine
learning classification tasks, showing significant improvements in performance.
When compared against several ensemble approaches including Random Forests and
Gradient Boosted Trees, RLFs offer a significant improvement in performance
whilst concurrently reducing the required model size.
</p>
<a href="http://arxiv.org/abs/2011.02086" target="_blank">arXiv:2011.02086</a> [<a href="http://arxiv.org/pdf/2011.02086" target="_blank">pdf</a>]

<h2>Learning to Rank with Missing Data via Generative Adversarial Networks. (arXiv:2011.02089v1 [stat.ML])</h2>
<h3>Grace Deng, Cuize Han, David S. Matteson</h3>
<p>We explore the role of Conditional Generative Adversarial Networks (GAN) in
imputing missing data and apply GAN imputation on a novel use case in
e-commerce: a learning-to-rank problem with incomplete training data.
Conventional imputation methods often make assumptions regarding the underlying
distribution of the missing data, while GANs offer an alternative framework to
sidestep approximating intractable distributions. First, we prove that GAN
imputation offers theoretical guarantees beyond the naive Missing Completely At
Random (MCAR) scenario. Next, we show that empirically, the Conditional GAN
structure is well suited for data with heterogeneous distributions and across
unbalanced classes, improving performance metrics such as RMSE. Using an Amazon
Search ranking dataset, we produce standard ranking models trained on
GAN-imputed data that are comparable to training on ground-truth data based on
standard ranking quality metrics NDCG and MRR. We also highlight how different
neural net features such as convolution and dropout layers can improve
performance given different missing value settings.
</p>
<a href="http://arxiv.org/abs/2011.02089" target="_blank">arXiv:2011.02089</a> [<a href="http://arxiv.org/pdf/2011.02089" target="_blank">pdf</a>]

<h2>Augmenting Images for ASR and TTS through Single-loop and Dual-loop Multimodal Chain Framework. (arXiv:2011.02099v1 [cs.CL])</h2>
<h3>Johanes Effendi, Andros Tjandra, Sakriani Sakti, Satoshi Nakamura</h3>
<p>Previous research has proposed a machine speech chain to enable automatic
speech recognition (ASR) and text-to-speech synthesis (TTS) to assist each
other in semi-supervised learning and to avoid the need for a large amount of
paired speech and text data. However, that framework still requires a large
amount of unpaired (speech or text) data. A prototype multimodal machine chain
was then explored to further reduce the need for a large amount of unpaired
data, which could improve ASR or TTS even when no more speech or text data were
available. Unfortunately, this framework relied on the image retrieval (IR)
model, and thus it was limited to handling only those images that were already
known during training. Furthermore, the performance of this framework was only
investigated with single-speaker artificial speech data. In this study, we
revamp the multimodal machine chain framework with image generation (IG) and
investigate the possibility of augmenting image data for ASR and TTS using
single-loop and dual-loop architectures on multispeaker natural speech data.
Experimental results revealed that both single-loop and dual-loop multimodal
chain frameworks enabled ASR and TTS to improve their performance using an
image-only dataset.
</p>
<a href="http://arxiv.org/abs/2011.02099" target="_blank">arXiv:2011.02099</a> [<a href="http://arxiv.org/pdf/2011.02099" target="_blank">pdf</a>]

<h2>Can We Trust Deep Speech Prior?. (arXiv:2011.02110v1 [cs.SD])</h2>
<h3>Ying Shi, Haolin Chen, Zhiyuan Tang, Lantian Li, Dong Wang, Jiqing Han</h3>
<p>Recently, speech enhancement (SE) based on deep speech prior has attracted
much attention, such as the variational auto-encoder with non-negative matrix
factorization (VAE-NMF) architecture. Compared to conventional approaches that
represent clean speech by shallow models such as Gaussians with a low-rank
covariance, the new approach employs deep generative models to represent the
clean speech, which often provides a better prior. Despite the clear advantage
in theory, we argue that deep priors must be used with much caution, since the
likelihood produced by a deep generative model does not always coincide with
the speech quality. We designed a comprehensive study on this issue and
demonstrated that based on deep speech priors, a reasonable SE performance can
be achieved, but the results might be suboptimal. A careful analysis showed
that this problem is deeply rooted in the disharmony between the flexibility of
deep generative models and the nature of the maximum-likelihood (ML) training.
</p>
<a href="http://arxiv.org/abs/2011.02110" target="_blank">arXiv:2011.02110</a> [<a href="http://arxiv.org/pdf/2011.02110" target="_blank">pdf</a>]

<h2>Toward Force Estimation in Robot-Assisted Surgery using Deep Learning with Vision and Robot State. (arXiv:2011.02112v1 [cs.RO])</h2>
<h3>Zonghe Chua, Anthony M. Jarc, Allison M. Okamura</h3>
<p>Knowledge of interaction forces during teleoperated robot-assisted surgery
could be used to enable force feedback to human operators and evaluate tissue
handling skill. However, direct force sensing at the end-effector is
challenging because it requires biocompatible, sterilizable, and cost-effective
sensors. Vision-based deep learning using convolutional neural networks is a
promising approach for providing useful force estimates, though questions
remain about generalization to new scenarios and real-time inference. We
present a force estimation neural network that uses RGB images and robot state
as inputs. Using a self-collected dataset, we compared the network to variants
that included only a single input type, and evaluated how they generalized to
new viewpoints, workspace positions, materials, and tools. We found that
vision-based networks were sensitive to shifts in viewpoints, while state-only
networks were robust to changes in workspace. The network with both state and
vision inputs had the highest accuracy for an unseen tool, and was moderately
robust to changes in viewpoints. Through feature removal studies, we found that
using only position features produced better accuracy than using only force
features as input. The network with both state and vision inputs outperformed a
physics-based baseline model in accuracy. It showed comparable accuracy but
faster computation times than a baseline recurrent neural network, making it
better suited for real-time applications.
</p>
<a href="http://arxiv.org/abs/2011.02112" target="_blank">arXiv:2011.02112</a> [<a href="http://arxiv.org/pdf/2011.02112" target="_blank">pdf</a>]

<h2>Realtime CNN-based Keypoint Detector with Sobel Filter and CNN-based Descriptor Trained with Keypoint Candidates. (arXiv:2011.02119v1 [cs.CV])</h2>
<h3>Xun Yuan, Ke Hu, Song Chen</h3>
<p>The local feature detector and descriptor are essential in many computer
vision tasks, such as SLAM and 3D reconstruction. In this paper, we introduce
two separate CNNs, lightweight SobelNet and DesNet, to detect key points and to
compute dense local descriptors. The detector and the descriptor work in
parallel. Sobel filter provides the edge structure of the input images as the
input of CNN. The locations of key points will be obtained after exerting the
non-maximum suppression (NMS) process on the output map of the CNN. We design
Gaussian loss for the training process of SobelNet to detect corner points as
keypoints. At the same time, the input of DesNet is the original grayscale
image, and circle loss is used to train DesNet. Besides, output maps of
SobelNet are needed while training DesNet. We have evaluated our method on
several benchmarks including HPatches benchmark, ETH benchmark, and FM-Bench.
SobelNet achieves better or comparable performance with less computation
compared with SOTA methods in recent years. The inference time of an image of
640x480 is 7.59ms and 1.09ms for SobelNet and DesNet respectively on RTX 2070
SUPER.
</p>
<a href="http://arxiv.org/abs/2011.02119" target="_blank">arXiv:2011.02119</a> [<a href="http://arxiv.org/pdf/2011.02119" target="_blank">pdf</a>]

<h2>Learning Discriminative Representations for Fine-Grained Diabetic Retinopathy Grading. (arXiv:2011.02120v1 [cs.CV])</h2>
<h3>Li Tian, Liyan Ma, Zhijie Wen, Shaorong Xie, Yupeng Xu</h3>
<p>Diabetic retinopathy (DR) is one of the leading causes of blindness. However,
no specific symptoms of early DR lead to a delayed diagnosis, which results in
disease progression in patients. To determine the disease severity levels,
ophthalmologists need to focus on the discriminative parts of the fundus
images. In recent years, deep learning has achieved great success in medical
image analysis. However, most works directly employ algorithms based on
convolutional neural networks (CNNs), which ignore the fact that the difference
among classes is subtle and gradual. Hence, we consider automatic image grading
of DR as a fine-grained classification task, and construct a bilinear model to
identify the pathologically discriminative areas. In order to leverage the
ordinal information among classes, we use an ordinal regression method to
obtain the soft labels. In addition, other than only using a categorical loss
to train our network, we also introduce the metric loss to learn a more
discriminative feature space. Experimental results demonstrate the superior
performance of the proposed method on two public IDRiD and DeepDR datasets.
</p>
<a href="http://arxiv.org/abs/2011.02120" target="_blank">arXiv:2011.02120</a> [<a href="http://arxiv.org/pdf/2011.02120" target="_blank">pdf</a>]

<h2>Analysing Long Short Term Memory Models for Cricket Match Outcome Prediction. (arXiv:2011.02122v1 [cs.LG])</h2>
<h3>Rahul Chakwate, Madhan R A</h3>
<p>As the technology advances, an ample amount of data is collected in sports
with the help of advanced sensors. Sports Analytics is the study of this data
to provide a constructive advantage to the team and its players. The game of
international cricket is popular all across the globe. Recently, various
machine learning techniques have been used to analyse the cricket match data
and predict the match outcome as win or lose. Generally these models make use
of the overall match level statistics such as teams, venue, average run rate,
win margin, etc to predict the match results before the beginning of the match.
However, very few works provide insights based on the ball-by-ball level
statistics. Here we propose a novel Recurrent Neural Network model which can
predict the win probability of a match at regular intervals given the
ball-by-ball statistics. The Long Short Term Memory (LSTM) Model takes as input
the ball wise features as well as the match level details available from the
training dataset. It gives a prediction of winning the match at any time stamp
during the match. This level of insight will help the team to predict the
probability of them winning the match after every ball and help them determine
the critical in-game changes they should make in their game strategies.
</p>
<a href="http://arxiv.org/abs/2011.02122" target="_blank">arXiv:2011.02122</a> [<a href="http://arxiv.org/pdf/2011.02122" target="_blank">pdf</a>]

<h2>Incremental Machine Speech Chain Towards Enabling Listening while Speaking in Real-time. (arXiv:2011.02126v1 [cs.CL])</h2>
<h3>Sashi Novitasari, Andros Tjandra, Tomoya Yanagita, Sakriani Sakti, Satoshi Nakamura</h3>
<p>Inspired by a human speech chain mechanism, a machine speech chain framework
based on deep learning was recently proposed for the semi-supervised
development of automatic speech recognition (ASR) and text-to-speech synthesis
TTS) systems. However, the mechanism to listen while speaking can be done only
after receiving entire input sequences. Thus, there is a significant delay when
encountering long utterances. By contrast, humans can listen to what hey speak
in real-time, and if there is a delay in hearing, they won't be able to
continue speaking. In this work, we propose an incremental machine speech chain
towards enabling machine to listen while speaking in real-time. Specifically,
we construct incremental ASR (ISR) and incremental TTS (ITTS) by letting both
systems improve together through a short-term loop. Our experimental results
reveal that our proposed framework is able to reduce delays due to long
utterances while keeping a comparable performance to the non-incremental basic
machine speech chain.
</p>
<a href="http://arxiv.org/abs/2011.02126" target="_blank">arXiv:2011.02126</a> [<a href="http://arxiv.org/pdf/2011.02126" target="_blank">pdf</a>]

<h2>Sequence-to-Sequence Learning via Attention Transfer for Incremental Speech Recognition. (arXiv:2011.02127v1 [cs.CL])</h2>
<h3>Sashi Novitasari, Andros Tjandra, Sakriani Sakti, Satoshi Nakamura</h3>
<p>Attention-based sequence-to-sequence automatic speech recognition (ASR)
requires a significant delay to recognize long utterances because the output is
generated after receiving entire input sequences. Although several studies
recently proposed sequence mechanisms for incremental speech recognition (ISR),
using different frameworks and learning algorithms is more complicated than the
standard ASR model. One main reason is because the model needs to decide the
incremental steps and learn the transcription that aligns with the current
short speech segment. In this work, we investigate whether it is possible to
employ the original architecture of attention-based ASR for ISR tasks by
treating a full-utterance ASR as the teacher model and the ISR as the student
model. We design an alternative student network that, instead of using a
thinner or a shallower model, keeps the original architecture of the teacher
model but with shorter sequences (few encoder and decoder states). Using
attention transfer, the student network learns to mimic the same alignment
between the current input short speech segments and the transcription. Our
experiments show that by delaying the starting time of recognition process with
about 1.7 sec, we can achieve comparable performance to one that needs to wait
until the end.
</p>
<a href="http://arxiv.org/abs/2011.02127" target="_blank">arXiv:2011.02127</a> [<a href="http://arxiv.org/pdf/2011.02127" target="_blank">pdf</a>]

<h2>Cross-Lingual Machine Speech Chain for Javanese, Sundanese, Balinese, and Bataks Speech Recognition and Synthesis. (arXiv:2011.02128v1 [cs.CL])</h2>
<h3>Sashi Novitasari, Andros Tjandra, Sakriani Sakti, Satoshi Nakamura</h3>
<p>Even though over seven hundred ethnic languages are spoken in Indonesia, the
available technology remains limited that could support communication within
indigenous communities as well as with people outside the villages. As a
result, indigenous communities still face isolation due to cultural barriers;
languages continue to disappear. To accelerate communication, speech-to-speech
translation (S2ST) technology is one approach that can overcome language
barriers. However, S2ST systems require machine translation (MT), speech
recognition (ASR), and synthesis (TTS) that rely heavily on supervised training
and a broad set of language resources that can be difficult to collect from
ethnic communities. Recently, a machine speech chain mechanism was proposed to
enable ASR and TTS to assist each other in semi-supervised learning. The
framework was initially implemented only for monolingual languages. In this
study, we focus on developing speech recognition and synthesis for these
Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. We
first separately train ASR and TTS of standard Indonesian in supervised
training. We then develop ASR and TTS of ethnic languages by utilizing
Indonesian ASR and TTS in a cross-lingual machine speech chain framework with
only text or only speech data removing the need for paired speech-text data of
those ethnic languages.
</p>
<a href="http://arxiv.org/abs/2011.02128" target="_blank">arXiv:2011.02128</a> [<a href="http://arxiv.org/pdf/2011.02128" target="_blank">pdf</a>]

<h2>DESNet: A Multi-channel Network for Simultaneous Speech Dereverberation, Enhancement and Separation. (arXiv:2011.02131v1 [cs.SD])</h2>
<h3>Yihui Fu, Jian Wu, Yanxin Hu, Mengtao Xing, Lei Xie</h3>
<p>In this paper, we propose a multi-channel network for simultaneous speech
dereverberation, enhancement and separation (DESNet). To enable gradient
propagation and joint optimization, we adopt the attentional selection
mechanism of the multi-channel features, which is originally proposed in
end-to-end unmixing, fixed-beamforming and extraction (E2E-UFE) structure.
Furthermore, the novel deep complex convolutional recurrent network (DCCRN) is
used as the structure of the speech unmixing and the neural network based
weighted prediction error (WPE) is cascaded beforehand for speech
dereverberation. We also introduce the staged SNR strategy and symphonic loss
for the training of the network to further improve the final performance.
Experiments show that in non-dereverberated case, the proposed DESNet
outperforms DCCRN and most state-of-the-art structures in speech enhancement
and separation, while in dereverberated scenario, DESNet also shows
improvements over the cascaded WPE-DCCRN networks.
</p>
<a href="http://arxiv.org/abs/2011.02131" target="_blank">arXiv:2011.02131</a> [<a href="http://arxiv.org/pdf/2011.02131" target="_blank">pdf</a>]

<h2>Interpretable Representation Learning for Speech and Audio Signals Based on Relevance Weighting. (arXiv:2011.02136v1 [eess.AS])</h2>
<h3>Purvi Agrawal, Sriram Ganapathy</h3>
<p>The learning of interpretable representations from raw data presents
significant challenges for time series data like speech. In this work, we
propose a relevance weighting scheme that allows the interpretation of the
speech representations during the forward propagation of the model itself. The
relevance weighting is achieved using a sub-network approach that performs the
task of feature selection. A relevance sub-network, applied on the output of
first layer of a convolutional neural network model operating on raw speech
signals, acts as an acoustic filterbank (FB) layer with relevance weighting. A
similar relevance sub-network applied on the second convolutional layer
performs modulation filterbank learning with relevance weighting. The full
acoustic model consisting of relevance sub-networks, convolutional layers and
feed-forward layers is trained for a speech recognition task on noisy and
reverberant speech in the Aurora-4, CHiME-3 and VOiCES datasets. The proposed
representation learning framework is also applied for the task of sound
classification in the UrbanSound8K dataset. A detailed analysis of the
relevance weights learned by the model reveals that the relevance weights
capture information regarding the underlying speech/audio content. In addition,
speech recognition and sound classification experiments reveal that the
incorporation of relevance weighting in the neural network architecture
improves the performance significantly.
</p>
<a href="http://arxiv.org/abs/2011.02136" target="_blank">arXiv:2011.02136</a> [<a href="http://arxiv.org/pdf/2011.02136" target="_blank">pdf</a>]

<h2>Control with adaptive Q-learning. (arXiv:2011.02141v1 [cs.LG])</h2>
<h3>Jo&#xe3;o Pedro Ara&#xfa;jo, M&#xe1;rio A. T. Figueiredo, Miguel Ayala Botto</h3>
<p>This paper evaluates adaptive Q-learning (AQL) and single-partition adaptive
Q-learning (SPAQL), two algorithms for efficient model-free episodic
reinforcement learning (RL), in two classical control problems (Pendulum and
Cartpole). AQL adaptively partitions the state-action space of a Markov
decision process (MDP), while learning the control policy, i. e., the mapping
from states to actions. The main difference between AQL and SPAQL is that the
latter learns time-invariant policies, where the mapping from states to actions
does not depend explicitly on the time step. This paper also proposes the SPAQL
with terminal state (SPAQL-TS), an improved version of SPAQL tailored for the
design of regulators for control problems. The time-invariant policies are
shown to result in a better performance than the time-variant ones in both
problems studied. These algorithms are particularly fitted to RL problems where
the action space is finite, as is the case with the Cartpole problem. SPAQL-TS
solves the OpenAI Gym Cartpole problem, while also displaying a higher sample
efficiency than trust region policy optimization (TRPO), a standard RL
algorithm for solving control tasks. Moreover, the policies learned by SPAQL
are interpretable, while TRPO policies are typically encoded as neural
networks, and therefore hard to interpret. Yielding interpretable policies
while being sample-efficient are the major advantages of SPAQL.
</p>
<a href="http://arxiv.org/abs/2011.02141" target="_blank">arXiv:2011.02141</a> [<a href="http://arxiv.org/pdf/2011.02141" target="_blank">pdf</a>]

<h2>Conditioned Text Generation with Transfer for Closed-Domain Dialogue Systems. (arXiv:2011.02143v1 [cs.CL])</h2>
<h3>St&#xe9;phane d&#x27;Ascoli, Alice Coucke, Francesco Caltagirone, Alexandre Caulier, Marc Lelarge</h3>
<p>Scarcity of training data for task-oriented dialogue systems is a well known
problem that is usually tackled with costly and time-consuming manual data
annotation. An alternative solution is to rely on automatic text generation
which, although less accurate than human supervision, has the advantage of
being cheap and fast. Our contribution is twofold. First we show how to
optimally train and control the generation of intent-specific sentences using a
conditional variational autoencoder. Then we introduce a new protocol called
query transfer that allows to leverage a large unlabelled dataset, possibly
containing irrelevant queries, to extract relevant information. Comparison with
two different baselines shows that this method, in the appropriate regime,
consistently improves the diversity of the generated queries without
compromising their quality. We also demonstrate the effectiveness of our
generation method as a data augmentation technique for language modelling
tasks.
</p>
<a href="http://arxiv.org/abs/2011.02143" target="_blank">arXiv:2011.02143</a> [<a href="http://arxiv.org/pdf/2011.02143" target="_blank">pdf</a>]

<h2>Deep Image Compositing. (arXiv:2011.02146v1 [cs.CV])</h2>
<h3>He Zhang, Jianming Zhang, Federico Perazzi, Zhe Lin, Vishal M. Patel</h3>
<p>Image compositing is a task of combining regions from different images to
compose a new image. A common use case is background replacement of portrait
images. To obtain high quality composites, professionals typically manually
perform multiple editing steps such as segmentation, matting and foreground
color decontamination, which is very time consuming even with sophisticated
photo editing tools. In this paper, we propose a new method which can
automatically generate high-quality image compositing without any user input.
Our method can be trained end-to-end to optimize exploitation of contextual and
color information of both foreground and background images, where the
compositing quality is considered in the optimization. Specifically, inspired
by Laplacian pyramid blending, a dense-connected multi-stream fusion network is
proposed to effectively fuse the information from the foreground and background
images at different scales. In addition, we introduce a self-taught strategy to
progressively train from easy to complex cases to mitigate the lack of training
data. Experiments show that the proposed method can automatically generate
high-quality composites and outperforms existing methods both qualitatively and
quantitatively.
</p>
<a href="http://arxiv.org/abs/2011.02146" target="_blank">arXiv:2011.02146</a> [<a href="http://arxiv.org/pdf/2011.02146" target="_blank">pdf</a>]

<h2>HypperSteer: Hypothetical Steering and Data Perturbation in Sequence Prediction with Deep Learning. (arXiv:2011.02149v1 [cs.LG])</h2>
<h3>Chuan Wang, Kwan-Liu Ma</h3>
<p>Deep Recurrent Neural Networks (RNN) continues to find success in predictive
decision-making with temporal event sequences. Recent studies have shown the
importance and practicality of visual analytics in interpreting deep learning
models for real-world applications. However, very limited work enables
interactions with deep learning models and guides practitioners to form
hypotheticals towards the desired prediction outcomes, especially for sequence
prediction. Specifically, no existing work has addressed the what-if analysis
and value perturbation along different time-steps for sequence outcome
prediction. We present a model-agnostic visual analytics tool, HypperSteer,
that steers hypothetical testing and allows users to perturb data for sequence
predictions interactively. We showcase how HypperSteer helps in steering
patient data to achieve desired treatment outcomes and discuss how HypperSteer
can serve as a comprehensive solution for other practical scenarios.
</p>
<a href="http://arxiv.org/abs/2011.02149" target="_blank">arXiv:2011.02149</a> [<a href="http://arxiv.org/pdf/2011.02149" target="_blank">pdf</a>]

<h2>EAdam Optimizer: How $\epsilon$ Impact Adam. (arXiv:2011.02150v1 [cs.LG])</h2>
<h3>Wei Yuan, Kai-Xin Gao</h3>
<p>Many adaptive optimization methods have been proposed and used in deep
learning, in which Adam is regarded as the default algorithm and widely used in
many deep learning frameworks. Recently, many variants of Adam, such as
Adabound, RAdam and Adabelief, have been proposed and show better performance
than Adam. However, these variants mainly focus on changing the stepsize by
making differences on the gradient or the square of it. Motivated by the fact
that suitable damping is important for the success of powerful second-order
optimizers, we discuss the impact of the constant $\epsilon$ for Adam in this
paper. Surprisingly, we can obtain better performance than Adam simply changing
the position of $\epsilon$. Based on this finding, we propose a new variant of
Adam called EAdam, which doesn't need extra hyper-parameters or computational
costs. We also discuss the relationships and differences between our method and
Adam. Finally, we conduct extensive experiments on various popular tasks and
models. Experimental results show that our method can bring significant
improvement compared with Adam. Our code is available at
https://github.com/yuanwei2019/EAdam-optimizer.
</p>
<a href="http://arxiv.org/abs/2011.02150" target="_blank">arXiv:2011.02150</a> [<a href="http://arxiv.org/pdf/2011.02150" target="_blank">pdf</a>]

<h2>Do Noises Bother Human and Neural Networks In the Same Way? A Medical Image Analysis Perspective. (arXiv:2011.02155v1 [eess.IV])</h2>
<h3>Shao-Cheng Wen, Yu-Jen Chen, Zihao Liu, Wujie Wen, Xiaowei Xu, Yiyu Shi, Tsung-Yi Ho, Qianjun Jia, Meiping Huang, Jian Zhuang</h3>
<p>Deep learning had already demonstrated its power in medical images, including
denoising, classification, segmentation, etc. All these applications are
proposed to automatically analyze medical images beforehand, which brings more
information to radiologists during clinical assessment for accuracy
improvement. Recently, many medical denoising methods had shown their
significant artifact reduction result and noise removal both quantitatively and
qualitatively. However, those existing methods are developed around
human-vision, i.e., they are designed to minimize the noise effect that can be
perceived by human eyes. In this paper, we introduce an application-guided
denoising framework, which focuses on denoising for the following neural
networks. In our experiments, we apply the proposed framework to different
datasets, models, and use cases. Experimental results show that our proposed
framework can achieve a better result than human-vision denoising network.
</p>
<a href="http://arxiv.org/abs/2011.02155" target="_blank">arXiv:2011.02155</a> [<a href="http://arxiv.org/pdf/2011.02155" target="_blank">pdf</a>]

<h2>Reverse engineering learned optimizers reveals known and novel mechanisms. (arXiv:2011.02159v1 [cs.LG])</h2>
<h3>Niru Maheswaranathan, David Sussillo, Luke Metz, Ruoxi Sun, Jascha Sohl-Dickstein</h3>
<p>Learned optimizers are algorithms that can themselves be trained to solve
optimization problems. In contrast to baseline optimizers (such as momentum or
Adam) that use simple update rules derived from theoretical principles, learned
optimizers use flexible, high-dimensional, nonlinear parameterizations.
Although this can lead to better performance in certain settings, their inner
workings remain a mystery. How is a learned optimizer able to outperform a well
tuned baseline? Has it learned a sophisticated combination of existing
optimization techniques, or is it implementing completely new behavior? In this
work, we address these questions by careful analysis and visualization of
learned optimizers. We study learned optimizers trained from scratch on three
disparate tasks, and discover that they have learned interpretable mechanisms,
including: momentum, gradient clipping, learning rate schedules, and a new form
of learning rate adaptation. Moreover, we show how the dynamics of learned
optimizers enables these behaviors. Our results help elucidate the previously
murky understanding of how learned optimizers work, and establish tools for
interpreting future learned optimizers.
</p>
<a href="http://arxiv.org/abs/2011.02159" target="_blank">arXiv:2011.02159</a> [<a href="http://arxiv.org/pdf/2011.02159" target="_blank">pdf</a>]

<h2>DAIS: Automatic Channel Pruning via Differentiable Annealing Indicator Search. (arXiv:2011.02166v1 [cs.CV])</h2>
<h3>Yushuo Guan, Ning Liu, Pengyu Zhao, Zhengping Che, Kaigui Bian, Yanzhi Wang, Jian Tang</h3>
<p>The convolutional neural network has achieved great success in fulfilling
computer vision tasks despite large computation overhead against efficient
deployment. Structured (channel) pruning is usually applied to reduce the model
redundancy while preserving the network structure, such that the pruned network
can be easily deployed in practice. However, existing structured pruning
methods require hand-crafted rules which may lead to tremendous pruning space.
In this paper, we introduce Differentiable Annealing Indicator Search (DAIS)
that leverages the strength of neural architecture search in the channel
pruning and automatically searches for the effective pruned model with given
constraints on computation overhead. Specifically, DAIS relaxes the binarized
channel indicators to be continuous and then jointly learns both indicators and
model parameters via bi-level optimization. To bridge the non-negligible
discrepancy between the continuous model and the target binarized model, DAIS
proposes an annealing-based procedure to steer the indicator convergence
towards binarized states. Moreover, DAIS designs various regularizations based
on a priori structural knowledge to control the pruning sparsity and to improve
model performance. Experimental results show that DAIS outperforms
state-of-the-art pruning methods on CIFAR-10, CIFAR-100, and ImageNet.
</p>
<a href="http://arxiv.org/abs/2011.02166" target="_blank">arXiv:2011.02166</a> [<a href="http://arxiv.org/pdf/2011.02166" target="_blank">pdf</a>]

<h2>BaFFLe: Backdoor detection via Feedback-based Federated Learning. (arXiv:2011.02167v1 [cs.CR])</h2>
<h3>Sebastien Andreina, Giorgia Azzurra Marson, Helen M&#xf6;llering, Ghassan Karame</h3>
<p>Recent studies have shown that federated learning (FL) is vulnerable to
poisoning attacks which aim at injecting a backdoor into the global model.
These attacks are effective, even when performed by a single client, and
undetectable by most existing defensive techniques. In this paper, we propose a
novel defense, dubbed BaFFLe---Backdoor detection via Feedback-based Federated
Learning---to secure FL against backdoor attacks. The core idea behind BaFFLe
is to leverage data of multiple clients not only for training but also for
uncovering model poisoning. Namely, we exploit the availability of multiple,
rich datasets at the various clients by incorporating a feedback loop into the
FL process to integrate the views of those clients when deciding whether a
given model update is genuine or not. We show that this powerful construct can
achieve very high detection rates against state-of-the-art backdoor attacks,
even when relying on straightforward methods to validate the model. Namely, we
show by means of evaluation using the CIFAR-10 and FEMNIST datasets that, by
combining the feedback loop with a method that suspects poisoning attempts by
assessing the per-class classification performance of the updated model, BaFFLe
reliably detects state-of-the-art semantic-backdoor attacks with a detection
accuracy of 100% and a false-positive rate below 5%. Moreover, we show that our
solution can detect an adaptive attack which is tuned to bypass the defense.
</p>
<a href="http://arxiv.org/abs/2011.02167" target="_blank">arXiv:2011.02167</a> [<a href="http://arxiv.org/pdf/2011.02167" target="_blank">pdf</a>]

<h2>Diversity Aware Relevance Learning for Argument Search. (arXiv:2011.02177v1 [cs.IR])</h2>
<h3>Michael Fromm, Max Berrendor, Sandra Obermeier, Thomas Seidl, Evgeniy Faerman</h3>
<p>In this work, we focus on the problem of retrieving relevant arguments for a
query claim covering diverse aspects. State-of-the-art methods rely on explicit
mappings between claims and premises, and thus are unable to utilize large
available collections of premises without laborious and costly manual
annotation. Their diversity approach relies on removing duplicates via
clustering which does not directly ensure that the selected premises cover all
aspects. This work introduces a new multi-step approach for the argument
retrieval problem. Rather than relying on ground-truth assignments, our
approach employs a machine learning model to capture semantic relationships
between arguments. Beyond that, it aims to cover diverse facets of the query,
instead of trying to identify duplicates explicitly. Our empirical evaluation
demonstrates that our approach leads to a significant improvement in the
argument retrieval task even though it requires less data.
</p>
<a href="http://arxiv.org/abs/2011.02177" target="_blank">arXiv:2011.02177</a> [<a href="http://arxiv.org/pdf/2011.02177" target="_blank">pdf</a>]

<h2>Node-Centric Graph Learning from Data for Brain State Identification. (arXiv:2011.02179v1 [cs.LG])</h2>
<h3>Nafiseh Ghoroghchian, David M. Groppe, Roman Genov, Taufik A. Valiante, Stark C. Draper</h3>
<p>Data-driven graph learning models a network by determining the strength of
connections between its nodes. The data refers to a graph signal which
associates a value with each graph node. Existing graph learning methods either
use simplified models for the graph signal, or they are prohibitively expensive
in terms of computational and memory requirements. This is particularly true
when the number of nodes is high or there are temporal changes in the network.
In order to consider richer models with a reasonable computational
tractability, we introduce a graph learning method based on representation
learning on graphs. Representation learning generates an embedding for each
graph node, taking the information from neighbouring nodes into account. Our
graph learning method further modifies the embeddings to compute the graph
similarity matrix. In this work, graph learning is used to examine brain
networks for brain state identification. We infer time-varying brain graphs
from an extensive dataset of intracranial electroencephalographic (iEEG)
signals from ten patients. We then apply the graphs as input to a classifier to
distinguish seizure vs. non-seizure brain states. Using the binary
classification metric of area under the receiver operating characteristic curve
(AUC), this approach yields an average of 9.13 percent improvement when
compared to two widely used brain network modeling methods.
</p>
<a href="http://arxiv.org/abs/2011.02179" target="_blank">arXiv:2011.02179</a> [<a href="http://arxiv.org/pdf/2011.02179" target="_blank">pdf</a>]

<h2>Hyperspectral classification of blood-like substances using machine learning methods combined with genetic algorithms in transductive and inductive scenarios. (arXiv:2011.02188v1 [cs.CV])</h2>
<h3>Filip Pa&#x142;ka, Wojciech Ksi&#x105;&#x17c;ek, Pawe&#x142; P&#x142;awiak, Micha&#x142; Romaszewski, Kamil Ksi&#x105;&#x17c;ek</h3>
<p>This study is focused on applying genetic algorithms (GA) to model and band
selection in hyperspectral image classification. We use a forensic-inspired
data set of seven hyperspectral images with blood and five visually similar
substances to test GA-optimised classifiers in two scenarios: when the training
and test data come from the same image and when they come from different
images, which is a more challenging task due to significant spectra
differences. In our experiments we compare GA with a classic model optimisation
through grid search. Our results show that GA-based model optimisation can
reduce the number of bands and create an accurate classifier that outperforms
the GS-based reference models, provided that during model optimisation it has
access to examples similar to test data. We illustrate this with experiment
highlighting the importance of a validation set.
</p>
<a href="http://arxiv.org/abs/2011.02188" target="_blank">arXiv:2011.02188</a> [<a href="http://arxiv.org/pdf/2011.02188" target="_blank">pdf</a>]

<h2>Weed Density and Distribution Estimation for Precision Agriculture using Semi-Supervised Learning. (arXiv:2011.02193v1 [cs.CV])</h2>
<h3>Shantam Shorewala, Armaan Ashfaque, Sidharth R, Ujjwal Verma</h3>
<p>Uncontrolled growth of weeds can severely affect the crop yield and quality.
Unrestricted use of herbicide for weed removal alters biodiversity and cause
environmental pollution. Instead, identifying weed-infested regions can aid
selective chemical treatment of these regions. Advances in analyzing farm
images have resulted in solutions to identify weed plants. However, a majority
of these approaches are based on supervised learning methods which requires
huge amount of manually annotated images. As a result, these supervised
approaches are economically infeasible for the individual farmer because of the
wide variety of plant species being cultivated. In this paper, we propose a
deep learning-based semi-supervised approach for robust estimation of weed
density and distribution across farmlands using only limited color images
acquired from autonomous robots. This weed density and distribution can be
useful in a site-specific weed management system for selective treatment of
infected areas using autonomous robots. In this work, the foreground vegetation
pixels containing crops and weeds are first identified using a Convolutional
Neural Network (CNN) based unsupervised segmentation. Subsequently, the weed
infected regions are identified using a fine-tuned CNN, eliminating the need
for designing hand-crafted features. The approach is validated on two datasets
of different crop/weed species (1) Crop Weed Field Image Dataset (CWFID), which
consists of carrot plant images and the (2) Sugar Beets dataset. The proposed
method is able to localize weed-infested regions a maximum recall of 0.99 and
estimate weed density with a maximum accuracy of 82.13%. Hence, the proposed
approach is shown to generalize to different plant species without the need for
extensive labeled data.
</p>
<a href="http://arxiv.org/abs/2011.02193" target="_blank">arXiv:2011.02193</a> [<a href="http://arxiv.org/pdf/2011.02193" target="_blank">pdf</a>]

<h2>Correlation based Multi-phasal models for improved imagined speech EEG recognition. (arXiv:2011.02195v1 [eess.SP])</h2>
<h3>Rini A Sharon, Hema A Murthy</h3>
<p>Translation of imagined speech electroencephalogram(EEG) into human
understandable commands greatly facilitates the design of naturalistic brain
computer interfaces. To achieve improved imagined speech unit classification,
this work aims to profit from the parallel information contained in
multi-phasal EEG data recorded while speaking, imagining and performing
articulatory movements corresponding to specific speech units. A bi-phase
common representation learning module using neural networks is designed to
model the correlation and reproducibility between an analysis phase and a
support phase. The trained Correlation Network is then employed to extract
discriminative features of the analysis phase. These features are further
classified into five binary phonological categories using machine learning
models such as Gaussian mixture based hidden Markov model and deep neural
networks. The proposed approach further handles the non-availability of
multi-phasal data during decoding. Topographic visualizations along with
result-based inferences suggest that the multi-phasal correlation modelling
approach proposed in the paper enhances imagined-speech EEG recognition
performance.
</p>
<a href="http://arxiv.org/abs/2011.02195" target="_blank">arXiv:2011.02195</a> [<a href="http://arxiv.org/pdf/2011.02195" target="_blank">pdf</a>]

<h2>IEEE SLT 2021 Alpha-mini Speech Challenge: Open Datasets, Tracks, Rules and Baselines. (arXiv:2011.02198v1 [cs.SD])</h2>
<h3>Yihui Fu, Zhuoyuan Yao, Weipeng He, Jian Wu, Xiong Wang, Zhanheng Yang, Shimin Zhang, Lei Xie, Dongyan Huang, Hui Bu, Petr Motlicek, Jean-Marc Odobez</h3>
<p>The IEEE Spoken Language Technology Workshop (SLT) 2021 Alpha-mini Speech
Challenge (ASC) is intended to improve research on keyword spotting (KWS) and
sound source location (SSL) on humanoid robots. Many publications report
significant improvements in deep learning based KWS and SSL on open source
datasets in recent years. For deep learning model training, it is necessary to
expand the data coverage to improve the robustness of model. Thus, simulating
multi-channel noisy and reverberant data from single-channel speech, noise,
echo and room impulsive response (RIR) is widely adopted. However, this
approach may generate mismatch between simulated data and recorded data in real
application scenarios, especially echo data. In this challenge, we open source
a sizable speech, keyword, echo and noise corpus for promoting data-driven
methods, particularly deep-learning approaches on KWS and SSL. We also choose
Alpha-mini, a humanoid robot produced by UBTECH equipped with a built-in
four-microphone array on its head, to record development and evaluation sets
under the actual Alpha-mini robot application scenario, including noise as well
as echo and mechanical noise generated by the robot itself for model
evaluation. Furthermore, we illustrate the rules, evaluation methods and
baselines for researchers to quickly assess their achievements and optimize
their models.
</p>
<a href="http://arxiv.org/abs/2011.02198" target="_blank">arXiv:2011.02198</a> [<a href="http://arxiv.org/pdf/2011.02198" target="_blank">pdf</a>]

<h2>Latent Causal Invariant Model. (arXiv:2011.02203v1 [cs.LG])</h2>
<h3>Xinwei Sun, Botong Wu, Chang Liu, Xiangyu Zheng, Wei Chen, Tao Qin, Tie-yan Liu</h3>
<p>Current supervised learning can learn spurious correlation during the
data-fitting process, imposing issues regarding interpretability,
out-of-distribution (OOD) generalization, and robustness. To avoid spurious
correlation, we propose a Latent Causal Invariance Model (LaCIM) which pursues
causal prediction. Specifically, we introduce latent variables that are
separated into (a) output-causative factors and (b) others that are spuriously
correlated to the output via confounders, to model the underlying causal
factors. We further assume the generating mechanisms from latent space to
observed data to be causally invariant. We give the identifiable claim of such
invariance, particularly the disentanglement of output-causative factors from
others, as a theoretical guarantee for precise inference and avoiding spurious
correlation. We propose a Variational-Bayesian-based method for estimation and
to optimize over the latent space for prediction. The utility of our approach
is verified by improved interpretability, prediction power on various OOD
scenarios (including healthcare) and robustness on security.
</p>
<a href="http://arxiv.org/abs/2011.02203" target="_blank">arXiv:2011.02203</a> [<a href="http://arxiv.org/pdf/2011.02203" target="_blank">pdf</a>]

<h2>Few-Shot Font Generation with Deep Metric Learning. (arXiv:2011.02206v1 [cs.CV])</h2>
<h3>Haruka Aoki, Koki Tsubota, Hikaru Ikuta, Kiyoharu Aizawa</h3>
<p>Designing fonts for languages with a large number of characters, such as
Japanese and Chinese, is an extremely labor-intensive and time-consuming task.
In this study, we addressed the problem of automatically generating Japanese
typographic fonts from only a few font samples, where the synthesized glyphs
are expected to have coherent characteristics, such as skeletons, contours, and
serifs. Existing methods often fail to generate fine glyph images when the
number of style reference glyphs is extremely limited. Herein, we proposed a
simple but powerful framework for extracting better style features. This
framework introduces deep metric learning to style encoders. We performed
experiments using black-and-white and shape-distinctive font datasets and
demonstrated the effectiveness of the proposed framework.
</p>
<a href="http://arxiv.org/abs/2011.02206" target="_blank">arXiv:2011.02206</a> [<a href="http://arxiv.org/pdf/2011.02206" target="_blank">pdf</a>]

<h2>Extracting Chemical-Protein Interactions via Calibrated Deep Neural Network and Self-training. (arXiv:2011.02207v1 [cs.CL])</h2>
<h3>Dongha Choi, Hyunju Lee</h3>
<p>The extraction of interactions between chemicals and proteins from several
biomedical articles is important in many fields of biomedical research such as
drug development and prediction of drug side effects. Several natural language
processing methods, including deep neural network (DNN) models, have been
applied to address this problem. However, these methods were trained with
hard-labeled data, which tend to become over-confident, leading to degradation
of the model reliability. To estimate the data uncertainty and improve the
reliability, "calibration" techniques have been applied to deep learning
models. In this study, to extract chemical--protein interactions, we propose a
DNN-based approach incorporating uncertainty information and calibration
techniques. Our model first encodes the input sequence using a pre-trained
language-understanding model, following which it is trained using two
calibration methods: mixup training and addition of a confidence penalty loss.
Finally, the model is re-trained with augmented data that are extracted using
the estimated uncertainties. Our approach has achieved state-of-the-art
performance with regard to the Biocreative VI ChemProt task, while preserving
higher calibration abilities than those of previous approaches. Furthermore,
our approach also presents the possibilities of using uncertainty estimation
for performance improvement.
</p>
<a href="http://arxiv.org/abs/2011.02207" target="_blank">arXiv:2011.02207</a> [<a href="http://arxiv.org/pdf/2011.02207" target="_blank">pdf</a>]

<h2>Low cost enhanced security face recognition with stereo cameras. (arXiv:2011.02222v1 [cs.CV])</h2>
<h3>Biel Tura Vecino, Mart&#xed; Cobos, Philippe Salembier</h3>
<p>This article explores a face recognition alternative which seeks to
contribute to resolve current security vulnerabilities in most recognition
architectures. Current low cost facial authentication software in the market
can be fooled by a printed picture of a face due to the lack of depth
information. The presented software creates a depth map of the face with the
help of a stereo setup, offering a higher level of security than traditional
recognition programs. Analysis of the person's identity and facial depth map
are processed through deep convolutional neural networks, providing a secure
low cost real-time face authentication method.
</p>
<a href="http://arxiv.org/abs/2011.02222" target="_blank">arXiv:2011.02222</a> [<a href="http://arxiv.org/pdf/2011.02222" target="_blank">pdf</a>]

<h2>Registration Loss Learning for Deep Probabilistic Point Set Registration. (arXiv:2011.02229v1 [cs.CV])</h2>
<h3>Felix J&#xe4;remo Lawin, Per-Erik Forss&#xe9;n</h3>
<p>Probabilistic methods for point set registration have interesting theoretical
properties, such as linear complexity in the number of used points, and they
easily generalize to joint registration of multiple point sets. In this work,
we improve their recognition performance to match state of the art. This is
done by incorporating learned features, by adding a von Mises-Fisher feature
model in each mixture component, and by using learned attention weights. We
learn these jointly using a registration loss learning strategy (RLL) that
directly uses the registration error as a loss, by back-propagating through the
registration iterations. This is possible as the probabilistic registration is
fully differentiable, and the result is a learning framework that is truly
end-to-end. We perform extensive experiments on the 3DMatch and Kitti datasets.
The experiments demonstrate that our approach benefits significantly from the
integration of the learned features and our learning strategy, outperforming
the state-of-the-art on Kitti. Code is available at
https://github.com/felja633/RLLReg.
</p>
<a href="http://arxiv.org/abs/2011.02229" target="_blank">arXiv:2011.02229</a> [<a href="http://arxiv.org/pdf/2011.02229" target="_blank">pdf</a>]

<h2>Hybrid Supervised Reinforced Model for Dialogue Systems. (arXiv:2011.02243v1 [cs.CL])</h2>
<h3>Carlos Miranda, Yacine Kessaci</h3>
<p>This paper presents a recurrent hybrid model and training procedure for
task-oriented dialogue systems based on Deep Recurrent Q-Networks (DRQN). The
model copes with both tasks required for Dialogue Management: State Tracking
and Decision Making. It is based on modeling Human-Machine interaction into a
latent representation embedding an interaction context to guide the discussion.
The model achieves greater performance, learning speed and robustness than a
non-recurrent baseline. Moreover, results allow interpreting and validating the
policy evolution and the latent representations information-wise.
</p>
<a href="http://arxiv.org/abs/2011.02243" target="_blank">arXiv:2011.02243</a> [<a href="http://arxiv.org/pdf/2011.02243" target="_blank">pdf</a>]

<h2>Generative Inverse Deep Reinforcement Learning for Online Recommendation. (arXiv:2011.02248v1 [cs.IR])</h2>
<h3>Xiaocong Chen, Lina Yao, Aixin Sun, Xianzhi Wang, Xiwei Xu, Liming Zhu</h3>
<p>Deep reinforcement learning enables an agent to capture user's interest
through interactions with the environment dynamically. It has attracted great
interest in the recommendation research. Deep reinforcement learning uses a
reward function to learn user's interest and to control the learning process.
However, most reward functions are manually designed; they are either
unrealistic or imprecise to reflect the high variety, dimensionality, and
non-linearity properties of the recommendation problem. That makes it difficult
for the agent to learn an optimal policy to generate the most satisfactory
recommendations. To address the above issue, we propose a novel generative
inverse reinforcement learning approach, namely InvRec, which extracts the
reward function from user's behaviors automatically, for online recommendation.
We conduct experiments on an online platform, VirtualTB, and compare with
several state-of-the-art methods to demonstrate the feasibility and
effectiveness of our proposed approach.
</p>
<a href="http://arxiv.org/abs/2011.02248" target="_blank">arXiv:2011.02248</a> [<a href="http://arxiv.org/pdf/2011.02248" target="_blank">pdf</a>]

<h2>Video Generative Adversarial Networks: A Review. (arXiv:2011.02250v1 [cs.CV])</h2>
<h3>Nuha Aldausari, Arcot Sowmya, Nadine Marcus, Gelareh Mohammadi</h3>
<p>With the increasing interest in the content creation field in multiple
sectors such as media, education, and entertainment, there is an increasing
trend in the papers that uses AI algorithms to generate content such as images,
videos, audio, and text. Generative Adversarial Networks (GANs) in one of the
promising models that synthesizes data samples that are similar to real data
samples. While the variations of GANs models, in general, have been covered to
some extent in several survey papers, to the best of our knowledge, this is
among the first survey papers that reviews the state-of-the-art video GANs
models. This paper first categorized GANs review papers into general GANs
review papers, image GANs review papers, and special field GANs review papers
such as anomaly detection, medical imaging, or cybersecurity. The paper then
summarizes the main improvements in GANs frameworks that are not initially
developed for the video domain but have been adopted in multiple video GANs
variations. Then, a comprehensive review of video GANs models is provided under
two main divisions according to the presence or non-presence of a condition.
The conditional models then further grouped according to the type of condition
into audio, text, video, and image. The paper is concluded by highlighting the
main challenges and limitations of the current video GANs models. A
comprehensive list of datasets, applied loss functions, and evaluation metrics
is provided in the supplementary material.
</p>
<a href="http://arxiv.org/abs/2011.02250" target="_blank">arXiv:2011.02250</a> [<a href="http://arxiv.org/pdf/2011.02250" target="_blank">pdf</a>]

<h2>Prosodic Representation Learning and Contextual Sampling for Neural Text-to-Speech. (arXiv:2011.02252v1 [eess.AS])</h2>
<h3>Sri Karlapati, Ammar Abbas, Zack Hodari, Alexis Moinet, Arnaud Joly, Penny Karanasou, Thomas Drugman</h3>
<p>In this paper, we introduce Kathaka, a model trained with a novel two-stage
training process for neural speech synthesis with contextually appropriate
prosody. In Stage I, we learn a prosodic distribution at the sentence level
from mel-spectrograms available during training. In Stage II, we propose a
novel method to sample from this learnt prosodic distribution using the
contextual information available in text. To do this, we use BERT on text, and
graph-attention networks on parse trees extracted from text. We show a
statistically significant relative improvement of $13.2\%$ in naturalness over
a strong baseline when compared to recordings. We also conduct an ablation
study on variations of our sampling technique, and show a statistically
significant improvement over the baseline in each case.
</p>
<a href="http://arxiv.org/abs/2011.02252" target="_blank">arXiv:2011.02252</a> [<a href="http://arxiv.org/pdf/2011.02252" target="_blank">pdf</a>]

<h2>On Self-Distilling Graph Neural Network. (arXiv:2011.02255v1 [cs.LG])</h2>
<h3>Yuzhao Chen, Yatao Bian, Xi Xiao, Yu Rong, Tingyang Xu, Junzhou Huang</h3>
<p>Recently, the teacher-student knowledge distillation framework has
demonstrated its potential in training Graph Neural Networks (GNNs). However,
due to the difficulty of training deep and wide GNN models, one can not always
obtain a satisfactory teacher model for distillation. Furthermore, the
inefficient training process of teacher-student knowledge distillation also
impedes its applications in GNN models. In this paper, we propose the first
teacher-free knowledge distillation framework for GNNs, termed GNN
Self-Distillation (GNN-SD), that serves as a drop-in replacement for improving
the training process of GNNs.We design three knowledge sources for GNN-SD:
neighborhood discrepancy rate (NDR), compact graph embedding and intermediate
logits. Notably, serving as a metric of the non-smoothness of the embedded
graph, NDR empowers the transferability of knowledge that maintains high
neighborhood discrepancy by enforcing consistency between consecutive GNN
layers. We conduct exploring analysis to verify that our framework could
improve the training dynamics and embedding quality of GNNs. Extensive
experiments on various popular GNN models and datasets demonstrate that our
approach obtains consistent and considerable performance enhancement, proving
its effectiveness and generalization ability.
</p>
<a href="http://arxiv.org/abs/2011.02255" target="_blank">arXiv:2011.02255</a> [<a href="http://arxiv.org/pdf/2011.02255" target="_blank">pdf</a>]

<h2>Advantage of Deep Neural Networks for Estimating Functions with Singularity on Curves. (arXiv:2011.02256v1 [stat.ML])</h2>
<h3>Masaaki Imaizumi, Kenji Fukumizu</h3>
<p>We develop a theory to elucidate the reason that deep neural networks (DNNs)
perform better than other methods. In terms of the nonparametric regression
problem, it is well known that many standard methods attain the minimax optimal
rate of estimation errors for smooth functions, and thus, it is not
straightforward to identify the theoretical advantages of DNNs. This study
fills this gap by considering the estimation for a class of non-smooth
functions with singularities on smooth curves. Our findings are as follows: (i)
We derive the generalization error of a DNN estimator and prove that its
convergence rate is almost optimal. (ii) We reveal that a certain class of
common models are sub-optimal, including linear estimators and other harmonic
analysis methods such as wavelets and curvelets. This advantage of DNNs comes
from a fact that a shape of singularity can be successfully handled by their
multi-layered structure.
</p>
<a href="http://arxiv.org/abs/2011.02256" target="_blank">arXiv:2011.02256</a> [<a href="http://arxiv.org/pdf/2011.02256" target="_blank">pdf</a>]

<h2>Graph Neural Networks in Recommender Systems: A Survey. (arXiv:2011.02260v1 [cs.IR])</h2>
<h3>Shiwen Wu, Wentao Zhang, Fei Sun, Bin Cui</h3>
<p>With the explosive growth of online information, recommender systems play a
key role to alleviate such information overload. Due to the important
application value of recommender system, there have always been emerging works
in this field. In recent years, graph neural network (GNN) techniques have
gained considerable interests which can naturally integrate node information
and topological structure. Owing to the outperformance of GNN in learning on
graph data, GNN methods have been widely applied in many fields. In recommender
systems, the main challenge is to learn the efficient user/item embeddings from
their interactions and side information if available. Since most of the
information essentially has graph structure and GNNs have superiority in
representation learning, the field of utilizing graph neural network in
recommender systems is flourishing. This article aims to provide a
comprehensive review of recent research efforts on graph neural network based
recommender systems. Specifically, we provide a taxonomy of graph neural
network based recommendation models and state new perspectives pertaining to
the development of this field.
</p>
<a href="http://arxiv.org/abs/2011.02260" target="_blank">arXiv:2011.02260</a> [<a href="http://arxiv.org/pdf/2011.02260" target="_blank">pdf</a>]

<h2>Handwriting Classification for the Analysis of Art-Historical Documents. (arXiv:2011.02264v1 [cs.CV])</h2>
<h3>Christian Bartz, Hendrik R&#xe4;tz, Christoph Meinel</h3>
<p>Digitized archives contain and preserve the knowledge of generations of
scholars in millions of documents. The size of these archives calls for
automatic analysis since a manual analysis by specialists is often too
expensive. In this paper, we focus on the analysis of handwriting in scanned
documents from the art-historic archive of the WPI. Since the archive consists
of documents written in several languages and lacks annotated training data for
the creation of recognition models, we propose the task of handwriting
classification as a new step for a handwriting OCR pipeline. We propose a
handwriting classification model that labels extracted text fragments, eg,
numbers, dates, or words, based on their visual structure. Such a
classification supports historians by highlighting documents that contain a
specific class of text without the need to read the entire content. To this
end, we develop and compare several deep learning-based models for text
classification. In extensive experiments, we show the advantages and
disadvantages of our proposed approach and discuss possible usage scenarios on
a real-world dataset.
</p>
<a href="http://arxiv.org/abs/2011.02264" target="_blank">arXiv:2011.02264</a> [<a href="http://arxiv.org/pdf/2011.02264" target="_blank">pdf</a>]

<h2>Causal Autoregressive Flows. (arXiv:2011.02268v1 [stat.ML])</h2>
<h3>Ilyes Khemakhem, Ricardo Pio Monti, Robert Leech, Aapo Hyv&#xe4;rinen</h3>
<p>Two apparently unrelated fields -- normalizing flows and causality -- have
recently received considerable attention in the machine learning community. In
this work, we highlight an intrinsic correspondence between a simple family of
flows and identifiable causal models. We exploit the fact that autoregressive
flow architectures define an ordering over variables, analogous to a causal
ordering, to show that they are well-suited to performing a range of causal
inference tasks. First, we show that causal models derived from both affine and
additive flows are identifiable. This provides a generalization of the additive
noise model well-known in causal discovery. Second, we derive a bivariate
measure of causal direction based on likelihood ratios, leveraging the fact
that flow models estimate normalized log-densities of data. Such likelihood
ratios have well-known optimality properties in finite-sample inference. Third,
we demonstrate that the invertibility of flows naturally allows for direct
evaluation of both interventional and counterfactual queries. Finally,
throughout a series of experiments on synthetic and real data, the proposed
method is shown to outperform current approaches for causal discovery as well
as making accurate interventional and counterfactual predictions.
</p>
<a href="http://arxiv.org/abs/2011.02268" target="_blank">arXiv:2011.02268</a> [<a href="http://arxiv.org/pdf/2011.02268" target="_blank">pdf</a>]

<h2>Trustworthy AI. (arXiv:2011.02272v1 [cs.CY])</h2>
<h3>Richa Singh, Mayank Vatsa, Nalini Ratha</h3>
<p>Modern AI systems are reaping the advantage of novel learning methods. With
their increasing usage, we are realizing the limitations and shortfalls of
these systems. Brittleness to minor adversarial changes in the input data,
ability to explain the decisions, address the bias in their training data, high
opacity in terms of revealing the lineage of the system, how they were trained
and tested, and under which parameters and conditions they can reliably
guarantee a certain level of performance, are some of the most prominent
limitations. Ensuring the privacy and security of the data, assigning
appropriate credits to data sources, and delivering decent outputs are also
required features of an AI system. We propose the tutorial on Trustworthy AI to
address six critical issues in enhancing user and public trust in AI systems,
namely: (i) bias and fairness, (ii) explainability, (iii) robust mitigation of
adversarial attacks, (iv) improved privacy and security in model building, (v)
being decent, and (vi) model attribution, including the right level of credit
assignment to the data sources, model architectures, and transparency in
lineage.
</p>
<a href="http://arxiv.org/abs/2011.02272" target="_blank">arXiv:2011.02272</a> [<a href="http://arxiv.org/pdf/2011.02272" target="_blank">pdf</a>]

<h2>VLEngagement: A Dataset of Scientific Video Lectures for Evaluating Population-based Engagement. (arXiv:2011.02273v1 [cs.CY])</h2>
<h3>Sahan Bulathwela, Maria Perez-Ortiz, Emine Yilmaz, John Shawe-Taylor</h3>
<p>With the emergence of e-learning and personalised education, the production
and distribution of digital educational resources have boomed. Video lectures
have now become one of the primary modalities to impart knowledge to masses in
the current digital age. The rapid creation of video lecture content challenges
the currently established human-centred moderation and quality assurance
pipeline, demanding for more efficient, scalable and automatic solutions for
managing learning resources. Although a few datasets related to engagement with
educational videos exist, there is still an important need for data and
research aimed at understanding learner engagement with scientific video
lectures. This paper introduces VLEngagement, a novel dataset that consists of
content-based and video-specific features extracted from publicly available
scientific video lectures and several metrics related to user engagement. We
introduce several novel tasks related to predicting and understanding
context-agnostic engagement in video lectures, providing preliminary baselines.
This is the largest and most diverse publicly available dataset to our
knowledge that deals with such tasks. The extraction of Wikipedia topic-based
features also allows associating more sophisticated Wikipedia based features to
the dataset to improve the performance in these tasks. The dataset, helper
tools and example code snippets are available publicly at
https://github.com/sahanbull/context-agnostic-engagement
</p>
<a href="http://arxiv.org/abs/2011.02273" target="_blank">arXiv:2011.02273</a> [<a href="http://arxiv.org/pdf/2011.02273" target="_blank">pdf</a>]

<h2>Physics-Informed Echo State Networks. (arXiv:2011.02280v1 [cs.LG])</h2>
<h3>Nguyen Anh Khoa Doan, Wolfgang Polifke, Luca Magri</h3>
<p>We propose a physics-informed Echo State Network (ESN) to predict the
evolution of chaotic systems. Compared to conventional ESNs, the
physics-informed ESNs are trained to solve supervised learning tasks while
ensuring that their predictions do not violate physical laws. This is achieved
by introducing an additional loss function during the training, which is based
on the system's governing equations. The additional loss function penalizes
non-physical predictions without the need of any additional training data. This
approach is demonstrated on a chaotic Lorenz system and a truncation of the
Charney-DeVore system. Compared to the conventional ESNs, the physics-informed
ESNs improve the predictability horizon by about two Lyapunov times. This
approach is also shown to be robust with regard to noise. The proposed
framework shows the potential of using machine learning combined with prior
physical knowledge to improve the time-accurate prediction of chaotic dynamical
systems.
</p>
<a href="http://arxiv.org/abs/2011.02280" target="_blank">arXiv:2011.02280</a> [<a href="http://arxiv.org/pdf/2011.02280" target="_blank">pdf</a>]

<h2>Surgical Data Science -- from Concepts to Clinical Translation. (arXiv:2011.02284v1 [cs.CY])</h2>
<h3>Lena Maier-Hein, Matthias Eisenmann, Duygu Sarikaya, Keno M&#xe4;rz, Toby Collins, Anand Malpani, Johannes Fallert, Hubertus Feussner, Stamatia Giannarou, Pietro Mascagni, Hirenkumar Nakawala, Adrian Park, Carla Pugh, Danail Stoyanov, Swaroop S. Vedula, Beat Peter M&#xfc;ller, Kevin Cleary, Gabor Fichtinger, Germain Forestier, Bernard Gibaud, Teodor Grantcharov, Makoto Hashizume, Hannes Kenngott, Ron Kikinis, Lars M&#xfc;ndermann, Nassir Navab, Sinan Onogur, Raphael Sznitman, Russell Taylor, Minu Dietlinde Tizabi, Martin Wagner, Gregory D. Hager, Thomas Neumuth, Nicolas Padoy, Pierre Jannin, Stefanie Speidel</h3>
<p>Recent developments in data science in general and machine learning in
particular have transformed the way experts envision the future of surgery.
Surgical data science is a new research field that aims to improve the quality
of interventional healthcare through the capture, organization, analysis and
modeling of data. While an increasing number of data-driven approaches and
clinical applications have been studied in the fields of radiological and
clinical data science, translational success stories are still lacking in
surgery. In this publication, we shed light on the underlying reasons and
provide a roadmap for future advances in the field. Based on an international
workshop involving leading researchers in the field of surgical data science,
we review current practice, key achievements and initiatives as well as
available standards and tools for a number of topics relevant to the field,
namely (1) technical infrastructure for data acquisition, storage and access in
the presence of regulatory constraints, (2) data annotation and sharing and (3)
data analytics. Drawing from this extensive review, we present current
challenges for technology development and (4) describe a roadmap for faster
clinical translation and exploitation of the full potential of surgical data
science.
</p>
<a href="http://arxiv.org/abs/2011.02284" target="_blank">arXiv:2011.02284</a> [<a href="http://arxiv.org/pdf/2011.02284" target="_blank">pdf</a>]

<h2>Personalized Multimorbidity Management for Patients with Type 2 Diabetes Using Reinforcement Learning of Electronic Health Records. (arXiv:2011.02287v1 [cs.CY])</h2>
<h3>Hua Zheng, Ilya O. Ryzhov, Wei Xie, Judy Zhong</h3>
<p>Comorbid chronic conditions are common among people with type 2 diabetes. We
developed an Artificial Intelligence algorithm, based on Reinforcement Learning
(RL), for personalized diabetes and multi-morbidity management with strong
potential to improve health outcomes relative to current clinical practice. In
this paper, we modeled glycemia, blood pressure and cardiovascular disease
(CVD) risk as health outcomes using a retrospective cohort of 16,665 patients
with type 2 diabetes from New York University Langone Health ambulatory care
electronic health records in 2009 to 2017. We trained a RL prescription
algorithm that recommends a treatment regimen optimizing patients' cumulative
health outcomes using their individual characteristics and medical history at
each encounter. The RL recommendations were evaluated on an independent subset
of patients. The results demonstrate that the proposed personalized
reinforcement learning prescriptive framework for type 2 diabetes yielded high
concordance with clinicians' prescriptions and substantial improvements in
glycemia, blood pressure, cardiovascular disease risk outcomes.
</p>
<a href="http://arxiv.org/abs/2011.02287" target="_blank">arXiv:2011.02287</a> [<a href="http://arxiv.org/pdf/2011.02287" target="_blank">pdf</a>]

<h2>Pixel-wise Dense Detector for Image Inpainting. (arXiv:2011.02293v1 [cs.CV])</h2>
<h3>Ruisong Zhang, Weize Quan, Baoyuan Wu, Zhifeng Li, Dong-Ming Yan</h3>
<p>Recent GAN-based image inpainting approaches adopt an average strategy to
discriminate the generated image and output a scalar, which inevitably lose the
position information of visual artifacts. Moreover, the adversarial loss and
reconstruction loss (e.g., l1 loss) are combined with tradeoff weights, which
are also difficult to tune. In this paper, we propose a novel detection-based
generative framework for image inpainting, which adopts the min-max strategy in
an adversarial process. The generator follows an encoder-decoder architecture
to fill the missing regions, and the detector using weakly supervised learning
localizes the position of artifacts in a pixel-wise manner. Such position
information makes the generator pay attention to artifacts and further enhance
them. More importantly, we explicitly insert the output of the detector into
the reconstruction loss with a weighting criterion, which balances the weight
of the adversarial loss and reconstruction loss automatically rather than
manual operation. Experiments on multiple public datasets show the superior
performance of the proposed framework. The source code is available at
https://github.com/Evergrow/GDN_Inpainting.
</p>
<a href="http://arxiv.org/abs/2011.02293" target="_blank">arXiv:2011.02293</a> [<a href="http://arxiv.org/pdf/2011.02293" target="_blank">pdf</a>]

<h2>Opportunities and Challenges in Code Search Tools. (arXiv:2011.02297v1 [cs.SE])</h2>
<h3>Chao Liu, Xin Xia, David Lo, Cuiyun Gao, Xiaohu Yang, John Grundy</h3>
<p>Code search is a core software engineering task. Effective code search tools
can help developers substantially improve their software development efficiency
and effectiveness. In recent years, many code search studies have leveraged
different techniques, such as deep learning and information retrieval
approaches, to retrieve expected code from a large-scale codebase. However,
there is a lack of a comprehensive comparative summary of existing code search
approaches. To understand the research trends in existing code search studies,
we systematically reviewed 81 relevant studies. We investigated the publication
trends of code search studies, analyzed key components, such as codebase,
query, and modeling technique used to build code search tools, and classified
existing tools into focusing on supporting seven different search tasks. Based
on our findings, we identified a set of outstanding challenges in existing
studies and a research roadmap for future code search research.
</p>
<a href="http://arxiv.org/abs/2011.02297" target="_blank">arXiv:2011.02297</a> [<a href="http://arxiv.org/pdf/2011.02297" target="_blank">pdf</a>]

<h2>Effective Fusion Factor in FPN for Tiny Object Detection. (arXiv:2011.02298v1 [cs.CV])</h2>
<h3>Yuqi Gong, Xuehui Yu, Yao Ding, Xiaoke Peng, Jian Zhao, Zhenjun Han</h3>
<p>FPN-based detectors have made significant progress in general object
detection, e.g., MS COCO and PASCAL VOC. However, these detectors fail in
certain application scenarios, e.g., tiny object detection. In this paper, we
argue that the top-down connections between adjacent layers in FPN bring
two-side influences for tiny object detection, not only positive. We propose a
novel concept, fusion factor, to control information that deep layers deliver
to shallow layers, for adapting FPN to tiny object detection. After series of
experiments and analysis, we explore how to estimate an effective value of
fusion factor for a particular dataset by a statistical method. The estimation
is dependent on the number of objects distributed in each layer. Comprehensive
experiments are conducted on tiny object detection datasets, e.g., TinyPerson
and Tiny CityPersons. Our results show that when configuring FPN with a proper
fusion factor, the network is able to achieve significant performance gains
over the baseline on tiny object detection datasets. Codes and models will be
released.
</p>
<a href="http://arxiv.org/abs/2011.02298" target="_blank">arXiv:2011.02298</a> [<a href="http://arxiv.org/pdf/2011.02298" target="_blank">pdf</a>]

<h2>FDRN: A Fast Deformable Registration Network for Medical Images. (arXiv:2011.02307v1 [cs.CV])</h2>
<h3>Kaicong Sun, Sven Simon</h3>
<p>Deformable image registration is a fundamental task in medical imaging. Due
to the large computational complexity of deformable registration of volumetric
images, conventional iterative methods usually face the tradeoff between the
registration accuracy and the computation time in practice. In order to boost
the registration performance in both accuracy and runtime, we propose a fast
unsupervised convolutional neural network for deformable image registration.
Specially, the proposed FDRN possesses a compact encoder-decoder structure and
exploits deep supervision, additive forwarding and residual learning. We
conducted comparison with the existing state-of-the-art registration methods on
the LPBA40 brain MRI dataset. Experimental results demonstrate that our FDRN
performs better than the investigated methods qualitatively and quantitatively
in Dice score and normalized cross correlation (NCC). Besides, FDRN is a
generalized framework for image registration which is not confined to a
particular type of medical images or anatomy. It can also be applied to other
anatomical structures or CT images.
</p>
<a href="http://arxiv.org/abs/2011.02307" target="_blank">arXiv:2011.02307</a> [<a href="http://arxiv.org/pdf/2011.02307" target="_blank">pdf</a>]

<h2>Fast Data-Driven Learning of MRI Sampling Pattern for Large Scale Problems. (arXiv:2011.02322v1 [eess.SP])</h2>
<h3>Marcelo V. W. Zibetti, Gabor T. Herman, Ravinder R. Regatte</h3>
<p>Purpose: A fast data-driven optimization approach, named bias-accelerated
subset selection (BASS), is proposed for learning efficacious sampling patterns
(SPs) with the purpose of reducing scan time in large-dimensional parallel MRI.
Methods: BASS is applicable when Cartesian fully-sampled k-space data of
specific anatomy is available for training and the reconstruction method is
specified, learning which k-space points are more relevant for the specific
anatomy and reconstruction in recovering the non-sampled points. BASS was
tested with four reconstruction methods for parallel MRI based on low-rankness
and sparsity that allow a free choice of the SP. Two datasets were tested, one
of the brain images for high-resolution imaging and another of knee images for
quantitative mapping of the cartilage. Results: BASS, with its low
computational cost and fast convergence, obtained SPs 100 times faster than the
current best greedy approaches. Reconstruction quality increased up to 45\%
with our learned SP over that provided by variable density and Poisson disk
SPs, considering the same scan time. Optionally, the scan time can be nearly
halved without loss of reconstruction quality. Conclusion: Compared with
current approaches, BASS can be used to rapidly learn effective SPs for various
reconstruction methods, using larger SP and larger datasets. This enables a
better selection of efficacious sampling-reconstruction pairs for specific MRI
problems.
</p>
<a href="http://arxiv.org/abs/2011.02322" target="_blank">arXiv:2011.02322</a> [<a href="http://arxiv.org/pdf/2011.02322" target="_blank">pdf</a>]

<h2>No more 996: Understanding Deep Learning Inference Serving with an Automatic Benchmarking system. (arXiv:2011.02327v1 [cs.LG])</h2>
<h3>Huaizheng Zhang, Yizheng Huang, Yonggang Wen, Jianxiong Yin, Kyle Guan</h3>
<p>Deep learning (DL) models have become core modules for many applications.
However, deploying these models without careful performance benchmarking that
considers both hardware and software's impact often leads to poor service and
costly operational expenditure. To facilitate DL models' deployment, we
implement an automatic and comprehensive benchmark system for DL developers. To
accomplish benchmark-related tasks, the developers only need to prepare a
configuration file consisting of a few lines of code. Our system, deployed to a
leader server in DL clusters, will dispatch users' benchmark jobs to follower
workers. Next, the corresponding requests, workload, and even models can be
generated automatically by the system to conduct DL serving benchmarks.
Finally, developers can leverage many analysis tools and models in our system
to gain insights into the trade-offs of different system configurations. In
addition, a two-tier scheduler is incorporated to avoid unnecessary
interference and improve average job compilation time by up to 1.43x
(equivalent of 30\% reduction). Our system design follows the best practice in
DL clusters operations to expedite day-to-day DL service evaluation efforts by
the developers. We conduct many benchmark experiments to provide in-depth and
comprehensive evaluations. We believe these results are of great values as
guidelines for DL service configuration and resource allocation.
</p>
<a href="http://arxiv.org/abs/2011.02327" target="_blank">arXiv:2011.02327</a> [<a href="http://arxiv.org/pdf/2011.02327" target="_blank">pdf</a>]

<h2>Localization in Terahertz-Operating Energy Harvesting Software-Defined Metamaterials. (arXiv:2011.02335v1 [eess.SP])</h2>
<h3>Filip Lemic, Sergi Abadal, Chong Han, Johann Marquez-Barja, Eduard Alarc&#xf3;n, Jeroen Famaey</h3>
<p>Software-Defined Metamaterials (SDMs) show a strong potential for advancing
the engineered control of electromagnetic waves. As such, they are envisioned
to enable a variety of exciting applications, among others in the domains of
smart textiles, high-resolution structural monitoring, and sensing in
challenging environments. Many of the applications envisage deformations of the
SDM structure, such as its bending, stretching or rolling, which implies that
the locations of metamaterial elements will be changing relative to one
another. In this paper, we argue that, if this change of relative locations
would be quantifiable, i.e., if the metamaterial elements would be accurately
localizable, this location information could potentially be utilized for
enabling novel SDM applications, as well as for optimizing the control of the
metamaterial elements themselves. The question if it is possible, as well as
how to perform such localization is, however, yet to spark in the community. In
this work, we assume that the metamaterial elements are controlled wirelessly
through a Terahertz (THz)-operating nanonetwork. Moreover, we consider the
elements to be energy-constrained, with their sole powering option being to
harvest environmental energy. For such a setup, we demonstrate sub-millimeter
accuracy of the two-way Time of Flight (ToF)-based localization, as well as
high availability of the service (i.e., consistently more than 80% of the
time), which is a result of the low energy consumed in the localization. We do
that for an exhaustive set of system parameters, among other the operational
frequency, bandwidth, harvesting rate, as well as their energy harvesting and
consumption patterns. Finally, we qualitatively characterize the effects of the
mentioned system parameters on the latency of the proposed localization
service, as well as outline several challenges and future research directions.
</p>
<a href="http://arxiv.org/abs/2011.02335" target="_blank">arXiv:2011.02335</a> [<a href="http://arxiv.org/pdf/2011.02335" target="_blank">pdf</a>]

<h2>Fault Detection for Covered Conductors With High-Frequency Voltage Signals: From Local Patterns to Global Features. (arXiv:2011.02336v1 [eess.SP])</h2>
<h3>Kunjin Chen, Tom&#xe1;&#x161; Vantuch, Yu Zhang, Jun Hu, Jinliang He</h3>
<p>The detection and characterization of partial discharge (PD) are crucial for
the insulation diagnosis of overhead lines with covered conductors. With the
release of a large dataset containing thousands of naturally obtained
high-frequency voltage signals, data-driven analysis of fault-related PD
patterns on an unprecedented scale becomes viable. The high diversity of PD
patterns and background noise interferences motivates us to design an
innovative pulse shape characterization method based on clustering techniques,
which can dynamically identify a set of representative PD-related pulses.
Capitalizing on those pulses as referential patterns, we construct insightful
features and develop a novel machine learning model with a superior detection
performance for early-stage covered conductor faults. The presented model
outperforms the winning model in a Kaggle competition and provides the
state-of-the-art solution to detect real-time disturbances in the field.
</p>
<a href="http://arxiv.org/abs/2011.02336" target="_blank">arXiv:2011.02336</a> [<a href="http://arxiv.org/pdf/2011.02336" target="_blank">pdf</a>]

<h2>The Limits of Differential Privacy (and its Misuse in Data Release and Machine Learning). (arXiv:2011.02352v1 [cs.CR])</h2>
<h3>Josep Domingo-Ferrer, David S&#xe1;nchez, Alberto Blanco-Justicia</h3>
<p>Differential privacy (DP) is a neat privacy definition that can co-exist with
certain well-defined data uses in the context of interactive queries. However,
DP is neither a silver bullet for all privacy problems nor a replacement for
all previous privacy models. In fact, extreme care should be exercised when
trying to extend its use beyond the setting it was designed for. This paper
reviews the limitations of DP and its misuse for individual data collection,
individual data release, and machine learning.
</p>
<a href="http://arxiv.org/abs/2011.02352" target="_blank">arXiv:2011.02352</a> [<a href="http://arxiv.org/pdf/2011.02352" target="_blank">pdf</a>]

<h2>Deep Multimodality Learning for UAV Video Aesthetic Quality Assessment. (arXiv:2011.02356v1 [cs.CV])</h2>
<h3>Qi Kuang, Xin Jin, Qinping Zhao, Bin Zhou</h3>
<p>Despite the growing number of unmanned aerial vehicles (UAVs) and aerial
videos, there is a paucity of studies focusing on the aesthetics of aerial
videos that can provide valuable information for improving the aesthetic
quality of aerial photography. In this article, we present a method of deep
multimodality learning for UAV video aesthetic quality assessment. More
specifically, a multistream framework is designed to exploit aesthetic
attributes from multiple modalities, including spatial appearance, drone camera
motion, and scene structure. A novel specially designed motion stream network
is proposed for this new multistream framework. We construct a dataset with
6,000 UAV video shots captured by drone cameras. Our model can judge whether a
UAV video was shot by professional photographers or amateurs together with the
scene type classification. The experimental results reveal that our method
outperforms the video classification methods and traditional SVM-based methods
for video aesthetics. In addition, we present three application examples of UAV
video grading, professional segment detection and aesthetic-based UAV path
planning using the proposed method.
</p>
<a href="http://arxiv.org/abs/2011.02356" target="_blank">arXiv:2011.02356</a> [<a href="http://arxiv.org/pdf/2011.02356" target="_blank">pdf</a>]

<h2>SD-Measure: A Social Distancing Detector. (arXiv:2011.02365v1 [cs.CV])</h2>
<h3>Savyasachi Gupta, Rudraksh Kapil, Goutham Kanahasabai, Shreyas Srinivas Joshi, Aniruddha Srinivas Joshi</h3>
<p>The practice of social distancing is imperative to curbing the spread of
contagious diseases and has been globally adopted as a non-pharmaceutical
prevention measure during the COVID-19 pandemic. This work proposes a novel
framework named SD-Measure for detecting social distancing from video footages.
The proposed framework leverages the Mask R-CNN deep neural network to detect
people in a video frame. To consistently identify whether social distancing is
practiced during the interaction between people, a centroid tracking algorithm
is utilised to track the subjects over the course of the footage. With the aid
of authentic algorithms for approximating the distance of people from the
camera and between themselves, we determine whether the social distancing
guidelines are being adhered to. The framework attained a high accuracy value
in conjunction with a low false alarm rate when tested on Custom Video Footage
Dataset (CVFD) and Custom Personal Images Dataset (CPID), where it manifested
its effectiveness in determining whether social distancing guidelines were
practiced.
</p>
<a href="http://arxiv.org/abs/2011.02365" target="_blank">arXiv:2011.02365</a> [<a href="http://arxiv.org/pdf/2011.02365" target="_blank">pdf</a>]

<h2>Deep Learning Framework to Detect Face Masks from Video Footage. (arXiv:2011.02371v1 [cs.CV])</h2>
<h3>Aniruddha Srinivas Joshi, Shreyas Srinivas Joshi, Goutham Kanahasabai, Rudraksh Kapil, Savyasachi Gupta</h3>
<p>The use of facial masks in public spaces has become a social obligation since
the wake of the COVID-19 global pandemic and the identification of facial masks
can be imperative to ensure public safety. Detection of facial masks in video
footages is a challenging task primarily due to the fact that the masks
themselves behave as occlusions to face detection algorithms due to the absence
of facial landmarks in the masked regions. In this work, we propose an approach
for detecting facial masks in videos using deep learning. The proposed
framework capitalizes on the MTCNN face detection model to identify the faces
and their corresponding facial landmarks present in the video frame. These
facial images and cues are then processed by a neoteric classifier that
utilises the MobileNetV2 architecture as an object detector for identifying
masked regions. The proposed framework was tested on a dataset which is a
collection of videos capturing the movement of people in public spaces while
complying with COVID-19 safety protocols. The proposed methodology demonstrated
its effectiveness in detecting facial masks by achieving high precision,
recall, and accuracy.
</p>
<a href="http://arxiv.org/abs/2011.02371" target="_blank">arXiv:2011.02371</a> [<a href="http://arxiv.org/pdf/2011.02371" target="_blank">pdf</a>]

<h2>Moving Forward in Formation: A Decentralized Hierarchical Learning Approach to Multi-Agent Moving Together. (arXiv:2011.02373v1 [cs.RO])</h2>
<h3>Shanqi Liu, Licheng Wen, Jinhao Cui, Xuemeng Yang, Junjie Cao, Yong Liu</h3>
<p>Multi-agent path finding in formation has many potential real-world
applications like mobile warehouse robots. However, previous multi-agent path
finding (MAPF) methods hardly take formation into consideration. Furthermore,
they are usually centralized planners and require the whole state of the
environment. Other decentralized partially observable approaches to MAPF are
reinforcement learning (RL) methods. However, these RL methods encounter
difficulties when learning path finding and formation problem at the same time.
In this paper, we propose a novel decentralized partially observable RL
algorithm that uses a hierarchical structure to decompose the multi objective
task into unrelated ones. It also calculates a theoretical weight that makes
every task reward has equal influence on the final RL value function.
Additionally, we introduce a communication method that helps agents cooperate
with each other. Experiments in simulation show that our method outperforms
other end-to-end RL methods and our method can naturally scale to large world
sizes where centralized planner struggles. We also deploy and validate our
method in a real world scenario.
</p>
<a href="http://arxiv.org/abs/2011.02373" target="_blank">arXiv:2011.02373</a> [<a href="http://arxiv.org/pdf/2011.02373" target="_blank">pdf</a>]

<h2>Filter Pruning using Hierarchical Group Sparse Regularization for Deep Convolutional Neural Networks. (arXiv:2011.02389v1 [cs.CV])</h2>
<h3>Kakeru Mitsuno, Takio Kurita</h3>
<p>Since the convolutional neural networks are often trained with redundant
parameters, it is possible to reduce redundant kernels or filters to obtain a
compact network without dropping the classification accuracy. In this paper, we
propose a filter pruning method using the hierarchical group sparse
regularization. It is shown in our previous work that the hierarchical group
sparse regularization is effective in obtaining sparse networks in which
filters connected to unnecessary channels are automatically close to zero.
After training the convolutional neural network with the hierarchical group
sparse regularization, the unnecessary filters are selected based on the
increase of the classification loss of the randomly selected training samples
to obtain a compact network. It is shown that the proposed method can reduce
more than 50% parameters of ResNet for CIFAR-10 with only 0.3% decrease in the
accuracy of test samples. Also, 34% parameters of ResNet are reduced for
TinyImageNet-200 with higher accuracy than the baseline network.
</p>
<a href="http://arxiv.org/abs/2011.02389" target="_blank">arXiv:2011.02389</a> [<a href="http://arxiv.org/pdf/2011.02389" target="_blank">pdf</a>]

<h2>Channel Planting for Deep Neural Networks using Knowledge Distillation. (arXiv:2011.02390v1 [cs.CV])</h2>
<h3>Kakeru Mitsuno, Yuichiro Nomura, Takio Kurita</h3>
<p>In recent years, deeper and wider neural networks have shown excellent
performance in computer vision tasks, while their enormous amount of parameters
results in increased computational cost and overfitting. Several methods have
been proposed to compress the size of the networks without reducing network
performance. Network pruning can reduce redundant and unnecessary parameters
from a network. Knowledge distillation can transfer the knowledge of deeper and
wider networks to smaller networks. The performance of the smaller network
obtained by these methods is bounded by the predefined network. Neural
architecture search has been proposed, which can search automatically the
architecture of the networks to break the structure limitation. Also, there is
a dynamic configuration method to train networks incrementally as sub-networks.
In this paper, we present a novel incremental training algorithm for deep
neural networks called planting. Our planting can search the optimal network
architecture with smaller number of parameters for improving the network
performance by augmenting channels incrementally to layers of the initial
networks while keeping the earlier trained parameters fixed. Also, we propose
using the knowledge distillation method for training the channels planted. By
transferring the knowledge of deeper and wider networks, we can grow the
networks effectively and efficiently. We evaluate the effectiveness of the
proposed method on different datasets such as CIFAR-10/100 and STL-10. For the
STL-10 dataset, we show that we are able to achieve comparable performance with
only 7% parameters compared to the larger network and reduce the overfitting
caused by a small amount of the data.
</p>
<a href="http://arxiv.org/abs/2011.02390" target="_blank">arXiv:2011.02390</a> [<a href="http://arxiv.org/pdf/2011.02390" target="_blank">pdf</a>]

<h2>Fairness in Biometrics: a figure of merit to assess biometric verification systems. (arXiv:2011.02395v1 [cs.CV])</h2>
<h3>Tiago de Freitas Pereira, S&#xe9;bastien Marcel</h3>
<p>Machine learning-based (ML) systems are being largely deployed since the last
decade in a myriad of scenarios impacting several instances in our daily lives.
With this vast sort of applications, aspects of fairness start to rise in the
spotlight due to the social impact that this can get in minorities. In this
work aspects of fairness in biometrics are addressed. First, we introduce the
first figure of merit that is able to evaluate and compare fairness aspects
between multiple biometric verification systems, the so-called Fairness
Discrepancy Rate (FDR). A use case with two synthetic biometric systems is
introduced and demonstrates the potential of this figure of merit in extreme
cases of fair and unfair behavior. Second, a use case using face biometrics is
presented where several systems are evaluated compared with this new figure of
merit using three public datasets exploring gender and race demographics.
</p>
<a href="http://arxiv.org/abs/2011.02395" target="_blank">arXiv:2011.02395</a> [<a href="http://arxiv.org/pdf/2011.02395" target="_blank">pdf</a>]

<h2>A Modular Robotic Arm Control Stack for Research: Franka-Interface and FrankaPy. (arXiv:2011.02398v1 [cs.RO])</h2>
<h3>Kevin Zhang, Mohit Sharma, Jacky Liang, Oliver Kroemer</h3>
<p>We designed a modular robotic control stack that provides a customizable and
accessible interface to the Franka Emika Panda Research robot. This framework
abstracts high-level robot control commands as skills, which are decomposed
into combinations of trajectory generators, feedback controllers, and
termination handlers. Low-level control is implemented in C++ and runs at
$1$kHz, and high-level commands are exposed in Python. In addition, external
sensor feedback, like estimated object poses, can be streamed to the low-level
controllers in real time. This modular approach allows us to quickly prototype
new control methods, which is essential for research applications. We have
applied this framework across a variety of real-world robot tasks in more than
$5$ published research papers. The framework is currently shared internally
with other robotics labs at Carnegie Mellon University, and we plan for a
public release in the near future.
</p>
<a href="http://arxiv.org/abs/2011.02398" target="_blank">arXiv:2011.02398</a> [<a href="http://arxiv.org/pdf/2011.02398" target="_blank">pdf</a>]

<h2>IDE-Net: Interactive Driving Event and Pattern Extraction from Human Data. (arXiv:2011.02403v1 [cs.AI])</h2>
<h3>Xiaosong Jia, Liting Sun, Masayoshi Tomizuka, Wei Zhan</h3>
<p>Autonomous vehicles (AVs) need to share the road with multiple, heterogeneous
road users in a variety of driving scenarios. It is overwhelming and
unnecessary to carefully interact with all observed agents, and AVs need to
determine whether and when to interact with each surrounding agent. In order to
facilitate the design and testing of prediction and planning modules of AVs,
in-depth understanding of interactive behavior is expected with proper
representation, and events in behavior data need to be extracted and
categorized automatically. Answers to what are the essential patterns of
interactions are also crucial for these motivations in addition to answering
whether and when. Thus, learning to extract interactive driving events and
patterns from human data for tackling the whether-when-what tasks is of
critical importance for AVs. There is, however, no clear definition and
taxonomy of interactive behavior, and most of the existing works are based on
either manual labelling or hand-crafted rules and features. In this paper, we
propose the Interactive Driving event and pattern Extraction Network (IDE-Net),
which is a deep learning framework to automatically extract interaction events
and patterns directly from vehicle trajectories. In IDE-Net, we leverage the
power of multi-task learning and proposed three auxiliary tasks to assist the
pattern extraction in an unsupervised fashion. We also design a unique
spatial-temporal block to encode the trajectory data. Experimental results on
the INTERACTION dataset verified the effectiveness of such designs in terms of
better generalizability and effective pattern extraction. We find three
interpretable patterns of interactions, bringing insights for driver behavior
representation, modeling and comprehension. Both objective and subjective
evaluation metrics are adopted in our analysis of the learned patterns.
</p>
<a href="http://arxiv.org/abs/2011.02403" target="_blank">arXiv:2011.02403</a> [<a href="http://arxiv.org/pdf/2011.02403" target="_blank">pdf</a>]

<h2>Dynamics Randomization Revisited:A Case Study for Quadrupedal Locomotion. (arXiv:2011.02404v1 [cs.RO])</h2>
<h3>Zhaoming Xie, Xingye Da, Michiel van de Panne, Buck Babich, Animesh Garg</h3>
<p>Understanding the gap between simulation andreality is critical for
reinforcement learning with legged robots,which are largely trained in
simulation. However, recent workhas resulted in sometimes conflicting
conclusions with regardto which factors are important for success, including
therole of dynamics randomization. In this paper, we aim toprovide clarity and
understanding on the role of dynamicsrandomization in learning robust
locomotion policies for theLaikago quadruped robot. Surprisingly, in contrast
to priorwork with the same robot model, we find that direct sim-to-real
transfer is possible without dynamics randomizationor on-robot adaptation
schemes. We conduct extensive abla-tion studies in a sim-to-sim setting to
understand the keyissues underlying successful policy transfer, including
otherdesign decisions that can impact policy robustness. We furtherground our
conclusions via sim-to-real experiments with variousgaits, speeds, and stepping
frequencies. Additional Details:
https://www.pair.toronto.edu/understanding-dr/.
</p>
<a href="http://arxiv.org/abs/2011.02404" target="_blank">arXiv:2011.02404</a> [<a href="http://arxiv.org/pdf/2011.02404" target="_blank">pdf</a>]

<h2>Probabilistic Bisimulation for Parameterized Systems (Technical Report). (arXiv:2011.02413v1 [cs.SE])</h2>
<h3>Chih-Duo Hong, Anthony W. Lin, Rupak Majumdar, Philipp R&#xfc;mmer</h3>
<p>Probabilistic bisimulation is a fundamental notion of process equivalence for
probabilistic systems. Among others, it has important applications including
formalizing the anonymity property of several communication protocols. There is
a lot of work on verifying probabilistic bisimulation for finite systems. This
is however not the case for parameterized systems, where the problem is in
general undecidable. In this paper we provide a generic framework for reasoning
about probabilistic bisimulation for parameterized systems. Our approach is in
the spirit of software verification, wherein we encode proof rules for
probabilistic bisimulation and use a decidable first-order theory to specify
systems and candidate bisimulation relations, which can then be checked
automatically against the proof rules. As a case study, we show that our
framework is sufficiently expressive for proving the anonymity property of the
parameterized dining cryptographers protocol and the parameterized grades
protocol, when supplied with a candidate regular bisimulation relation. Both of
these protocols hitherto could not be verified by existing automatic methods.
Moreover, with the help of standard automata learning algorithms, we show that
the candidate relations can be synthesized fully automatically, making the
verification fully automated.
</p>
<a href="http://arxiv.org/abs/2011.02413" target="_blank">arXiv:2011.02413</a> [<a href="http://arxiv.org/pdf/2011.02413" target="_blank">pdf</a>]

<h2>A Neuro-Symbolic Method for Solving Differential and Functional Equations. (arXiv:2011.02415v1 [cs.LG])</h2>
<h3>Maysum Panju, Ali Ghodsi</h3>
<p>When neural networks are used to solve differential equations, they usually
produce solutions in the form of black-box functions that are not directly
mathematically interpretable. We introduce a method for generating symbolic
expressions to solve differential equations while leveraging deep learning
training methods. Unlike existing methods, our system does not require learning
a language model over symbolic mathematics, making it scalable, compact, and
easily adaptable for a variety of tasks and configurations. As part of the
method, we propose a novel neural architecture for learning mathematical
expressions to optimize a customizable objective. The system is designed to
always return a valid symbolic formula, generating a useful approximation when
an exact analytic solution to a differential equation is not or cannot be
found. We demonstrate through examples how our method can be applied on a
number of differential equations, often obtaining symbolic approximations that
are useful or insightful. Furthermore, we show how the system can be
effortlessly generalized to find symbolic solutions to other mathematical
tasks, including integration and functional equations.
</p>
<a href="http://arxiv.org/abs/2011.02415" target="_blank">arXiv:2011.02415</a> [<a href="http://arxiv.org/pdf/2011.02415" target="_blank">pdf</a>]

<h2>Investigating Novel Verb Learning in BERT: Selectional Preference Classes and Alternation-Based Syntactic Generalization. (arXiv:2011.02417v1 [cs.CL])</h2>
<h3>Tristan Thrush, Ethan Wilcox, Roger Levy</h3>
<p>Previous studies investigating the syntactic abilities of deep learning
models have not targeted the relationship between the strength of the
grammatical generalization and the amount of evidence to which the model is
exposed during training. We address this issue by deploying a novel
word-learning paradigm to test BERT's few-shot learning capabilities for two
aspects of English verbs: alternations and classes of selectional preferences.
For the former, we fine-tune BERT on a single frame in a verbal-alternation
pair and ask whether the model expects the novel verb to occur in its sister
frame. For the latter, we fine-tune BERT on an incomplete selectional network
of verbal objects and ask whether it expects unattested but plausible
verb/object pairs. We find that BERT makes robust grammatical generalizations
after just one or two instances of a novel word in fine-tuning. For the verbal
alternation tests, we find that the model displays behavior that is consistent
with a transitivity bias: verbs seen few times are expected to take direct
objects, but verbs seen with direct objects are not expected to occur
intransitively.
</p>
<a href="http://arxiv.org/abs/2011.02417" target="_blank">arXiv:2011.02417</a> [<a href="http://arxiv.org/pdf/2011.02417" target="_blank">pdf</a>]

<h2>Branchy-GNN: a Device-Edge Co-Inference Framework for Efficient Point Cloud Processing. (arXiv:2011.02422v1 [cs.DC])</h2>
<h3>Jiawei Shao, Haowei Zhang, Yuyi Mao, Jun Zhang</h3>
<p>The recent advancements of three-dimensional (3D) data acquisition devices
have spurred a new breed of applications that rely on point cloud data
processing. However, processing a large volume of point cloud data brings a
significant workload on resource-constrained mobile devices, prohibiting from
unleashing their full potentials. Built upon the emerging paradigm of
device-edge co-inference, where an edge device extracts and transmits the
intermediate feature to an edge server for further processing, we propose
Branchy-GNN for efficient graph neural network (GNN) based point cloud
processing by leveraging edge computing platforms. In order to reduce the
on-device computational cost, the Branchy-GNN adds branch networks for early
exiting. Besides, it employs learning-based joint source-channel coding (JSCC)
for the intermediate feature compression to reduce the communication overhead.
Our experimental results demonstrate that the proposed Branchy-GNN secures a
significant latency reduction compared with several benchmark methods.
</p>
<a href="http://arxiv.org/abs/2011.02422" target="_blank">arXiv:2011.02422</a> [<a href="http://arxiv.org/pdf/2011.02422" target="_blank">pdf</a>]

<h2>Rank Based Pseudoinverse Computation in Extreme Learning Machine for Large Datasets. (arXiv:2011.02436v1 [cs.LG])</h2>
<h3>Ramesh Ragala, Bharadwaja kumar</h3>
<p>Extreme Learning Machine (ELM) is an efficient and effective
least-square-based learning algorithm for classification, regression problems
based on single hidden layer feed-forward neural network (SLFN). It has been
shown in the literature that it has faster convergence and good generalization
ability for moderate datasets. But, there is great deal of challenge involved
in computing the pseudoinverse when there are large numbers of hidden nodes or
for large number of instances to train complex pattern recognition problems. To
address this problem, a few approaches such as EM-ELM, DF-ELM have been
proposed in the literature. In this paper, a new rank-based matrix
decomposition of the hidden layer matrix is introduced to have the optimal
training time and reduce the computational complexity for a large number of
hidden nodes in the hidden layer. The results show that it has constant
training time which is closer towards the minimal training time and very far
from worst-case training time of the DF-ELM algorithm that has been shown
efficient in the recent literature.
</p>
<a href="http://arxiv.org/abs/2011.02436" target="_blank">arXiv:2011.02436</a> [<a href="http://arxiv.org/pdf/2011.02436" target="_blank">pdf</a>]

<h2>Muti-view Mouse Social Behaviour Recognition with Deep Graphical Model. (arXiv:2011.02451v1 [cs.CV])</h2>
<h3>Zheheng Jiang, Feixiang Zhou, Aite Zhao, Xin Li, Ling Li, Dacheng Tao, Xuelong Li, Huiyu Zhou</h3>
<p>Home-cage social behaviour analysis of mice is an invaluable tool to assess
therapeutic efficacy of neurodegenerative diseases. Despite tremendous efforts
made within the research community, single-camera video recordings are mainly
used for such analysis. Because of the potential to create rich descriptions of
mouse social behaviors, the use of multi-view video recordings for rodent
observations is increasingly receiving much attention. However, identifying
social behaviours from various views is still challenging due to the lack of
correspondence across data sources. To address this problem, we here propose a
novel multiview latent-attention and dynamic discriminative model that jointly
learns view-specific and view-shared sub-structures, where the former captures
unique dynamics of each view whilst the latter encodes the interaction between
the views. Furthermore, a novel multi-view latent-attention variational
autoencoder model is introduced in learning the acquired features, enabling us
to learn discriminative features in each view. Experimental results on the
standard CRMI13 and our multi-view Parkinson's Disease Mouse Behaviour (PDMB)
datasets demonstrate that our model outperforms the other state of the arts
technologies and effectively deals with the imbalanced data problem.
</p>
<a href="http://arxiv.org/abs/2011.02451" target="_blank">arXiv:2011.02451</a> [<a href="http://arxiv.org/pdf/2011.02451" target="_blank">pdf</a>]

<h2>Towards Robotic Assembly by Predicting Robust, Precise and Task-oriented Grasps. (arXiv:2011.02462v1 [cs.RO])</h2>
<h3>Jialiang Zhao, Daniel Troniak, Oliver Kroemer</h3>
<p>Robust task-oriented grasp planning is vital for autonomous robotic precision
assembly tasks. Knowledge of the objects' geometry and preconditions of the
target task should be incorporated when determining the proper grasp to
execute. However, several factors contribute to the challenges of realizing
these grasps such as noise when controlling the robot, unknown object
properties, and difficulties modeling complex object-object interactions. We
propose a method that decomposes this problem and optimizes for grasp
robustness, precision, and task performance by learning three cascaded
networks. We evaluate our method in simulation on three common assembly tasks:
inserting gears onto pegs, aligning brackets into corners, and inserting shapes
into slots. Our policies are trained using a curriculum based on large-scale
self-supervised grasp simulations with procedurally generated objects. Finally,
we evaluate the performance of the first two tasks with a real robot where our
method achieves 4.28mm error for bracket insertion and 1.44mm error for gear
insertion.
</p>
<a href="http://arxiv.org/abs/2011.02462" target="_blank">arXiv:2011.02462</a> [<a href="http://arxiv.org/pdf/2011.02462" target="_blank">pdf</a>]

<h2>Visual Localization Under Appearance Change: Filtering Approaches. (arXiv:1811.08063v4 [cs.CV] UPDATED)</h2>
<h3>Anh-Dzung Doan, Yasir Latif, Tat-Jun Chin, Yu Liu, Shin-Fang Ch&#x27;ng, Thanh-Toan Do, Ian Reid</h3>
<p>A major focus of current research on place recognition is visual localization
for autonomous driving. In this scenario, as cameras will be operating
continuously, it is realistic to expect videos as an input to visual
localization algorithms, as opposed to the single-image querying approach used
in other visual localization works. In this paper, we show that exploiting
temporal continuity in the testing sequence significantly improves visual
localization - qualitatively and quantitatively. Although intuitive, this idea
has not been fully explored in recent works. To this end, we propose two
filtering approaches to exploit the temporal smoothness of image sequences: i)
filtering on discrete domain with Hidden Markov Model, and ii) filtering on
continuous domain with Monte Carlo-based visual localization. Our approaches
rely on local features with an encoding technique to represent an image as a
single vector. The experimental results on synthetic and real datasets show
that our proposed methods achieve better results than state of the art (i.e.,
deep learning-based pose regression approaches) for the task on visual
localization under significant appearance change. Our synthetic dataset and
source code are made publicly available at
https://sites.google.com/view/g2d-software/home and
https://github.com/dadung/Visual-Localization-Filtering.
</p>
<a href="http://arxiv.org/abs/1811.08063" target="_blank">arXiv:1811.08063</a> [<a href="http://arxiv.org/pdf/1811.08063" target="_blank">pdf</a>]

<h2>LiDARTag: A Real-Time Fiducial Tag for Point Clouds. (arXiv:1908.10349v2 [cs.RO] UPDATED)</h2>
<h3>Jiunn-Kai Huang, Shoutian Wang, Maani Ghaffari, Jessy W. Grizzle</h3>
<p>Image-based fiducial markers are useful in problems such as object tracking
in cluttered or textureless environments, camera (and multi-sensor) calibration
tasks, and vision-based simultaneous localization and mapping (SLAM). The
state-of-the-art fiducial marker detection algorithms rely on the consistency
of the ambient lighting. This paper introduces LiDARTag, a novel fiducial tag
design and detection algorithm suitable for light detection and ranging (LiDAR)
point clouds. The proposed method runs in real-time and can process data at 100
Hz, which is faster than the currently available LiDAR sensor frequencies.
Because of the LiDAR sensors' nature, rapidly changing ambient lighting will
not affect the detection of a LiDARTag; hence, the proposed fiducial marker can
operate in a completely dark environment. In addition, the LiDARTag nicely
complements and is compatible with existing visual fiducial markers, such as
AprilTags, allowing for efficient multi-sensor fusion and calibration tasks. We
further propose a concept of minimizing a fitting error between a point cloud
and the marker's template to estimate the marker's pose. The proposed method
achieves millimeter error in translation and a few degrees in rotation. Due to
LiDAR returns' sparsity, the point cloud is lifted to a continuous function in
a reproducing kernel Hilbert space where the inner product can be used to
determine a marker's ID. The experimental results, verified by a motion capture
system, confirm that the proposed method can reliably provide a tag's pose and
unique ID code. The rejection of false positives is validated on the Google
Cartographer indoor dataset and the Honda H3D outdoor dataset. All
implementations are coded in C++ and are available at:
https://github.com/UMich-BipedLab/LiDARTag.
</p>
<a href="http://arxiv.org/abs/1908.10349" target="_blank">arXiv:1908.10349</a> [<a href="http://arxiv.org/pdf/1908.10349" target="_blank">pdf</a>]

<h2>Segmentation of Defective Skulls from CT Data for Tissue Modelling. (arXiv:1911.08805v2 [eess.IV] UPDATED)</h2>
<h3>Old&#x159;ich Kodym, Michal &#x160;pan&#x11b;l, Adam Herout</h3>
<p>In this work we present a method of automatic segmentation of defective
skulls for custom cranial implant design and 3D printing purposes. Since such
tissue models are usually required in patient cases with complex anatomical
defects and variety of external objects present in the acquired data, most deep
learning-based approaches fall short because it is not possible to create a
sufficient training dataset that would encompass the spectrum of all possible
structures. Because CNN segmentation experiments in this application domain
have been so far limited to simple patch-based CNN architectures, we first show
how the usage of the encoder-decoder architecture can substantially improve the
segmentation accuracy. Then, we show how the number of segmentation artifacts,
which usually require manual corrections, can be further reduced by adding a
boundary term to CNN training and by globally optimizing the segmentation with
graph-cut. Finally, we show that using the proposed method, 3D segmentation
accurate enough for clinical application can be achieved with 2D CNN
architectures as well as their 3D counterparts.
</p>
<a href="http://arxiv.org/abs/1911.08805" target="_blank">arXiv:1911.08805</a> [<a href="http://arxiv.org/pdf/1911.08805" target="_blank">pdf</a>]

<h2>Deep Efficient End-to-end Reconstruction (DEER) Network for Few-view Breast CT Image Reconstruction. (arXiv:1912.04278v3 [eess.IV] UPDATED)</h2>
<h3>Huidong Xie, Hongming Shan, Wenxiang Cong, Chi Liu, Xiaohua Zhang, Shaohua Liu, Ruola Ning, Ge Wang</h3>
<p>Breast CT provides image volumes with isotropic resolution in high contrast,
enabling detection of small calcification (down to a few hundred microns in
size) and subtle density differences. Since breast is sensitive to x-ray
radiation, dose reduction of breast CT is an important topic, and for this
purpose, few-view scanning is a main approach. In this article, we propose a
Deep Efficient End-to-end Reconstruction (DEER) network for few-view breast CT
image reconstruction. The major merits of our network include high dose
efficiency, excellent image quality, and low model complexity. By the design,
the proposed network can learn the reconstruction process with as few as O(N)
parameters, where N is the side length of an image to be reconstructed, which
represents orders of magnitude improvements relative to the state-of-the-art
deep-learning-based reconstruction methods that map raw data to tomographic
images directly. Also, validated on a cone-beam breast CT dataset prepared by
Koning Corporation on a commercial scanner, our method demonstrates a
competitive performance over the state-of-the-art reconstruction networks in
terms of image quality. The source code of this paper is available at:
https://github.com/HuidongXie/DEER.
</p>
<a href="http://arxiv.org/abs/1912.04278" target="_blank">arXiv:1912.04278</a> [<a href="http://arxiv.org/pdf/1912.04278" target="_blank">pdf</a>]

<h2>Making Sense of Reinforcement Learning and Probabilistic Inference. (arXiv:2001.00805v3 [cs.LG] UPDATED)</h2>
<h3>Brendan O&#x27;Donoghue, Ian Osband, Catalin Ionescu</h3>
<p>Reinforcement learning (RL) combines a control problem with statistical
estimation: The system dynamics are not known to the agent, but can be learned
through experience. A recent line of research casts `RL as inference' and
suggests a particular framework to generalize the RL problem as probabilistic
inference. Our paper surfaces a key shortcoming in that approach, and clarifies
the sense in which RL can be coherently cast as an inference problem. In
particular, an RL agent must consider the effects of its actions upon future
rewards and observations: The exploration-exploitation tradeoff. In all but the
most simple settings, the resulting inference is computationally intractable so
that practical RL algorithms must resort to approximation. We demonstrate that
the popular `RL as inference' approximation can perform poorly in even very
basic problems. However, we show that with a small modification the framework
does yield algorithms that can provably perform well, and we show that the
resulting algorithm is equivalent to the recently proposed K-learning, which we
further connect with Thompson sampling.
</p>
<a href="http://arxiv.org/abs/2001.00805" target="_blank">arXiv:2001.00805</a> [<a href="http://arxiv.org/pdf/2001.00805" target="_blank">pdf</a>]

<h2>Unsupervised Anomaly Detection for X-Ray Images. (arXiv:2001.10883v2 [eess.IV] UPDATED)</h2>
<h3>Diana Davletshina, Valentyn Melnychuk, Viet Tran, Hitansh Singla, Max Berrendorf, Evgeniy Faerman, Michael Fromm, Matthias Schubert</h3>
<p>Obtaining labels for medical (image) data requires scarce and expensive
experts. Moreover, due to ambiguous symptoms, single images rarely suffice to
correctly diagnose a medical condition. Instead, it often requires to take
additional background information such as the patient's medical history or test
results into account. Hence, instead of focusing on uninterpretable black-box
systems delivering an uncertain final diagnosis in an end-to-end-fashion, we
investigate how unsupervised methods trained on images without anomalies can be
used to assist doctors in evaluating X-ray images of hands. Our method
increases the efficiency of making a diagnosis and reduces the risk of missing
important regions. Therefore, we adopt state-of-the-art approaches for
unsupervised learning to detect anomalies and show how the outputs of these
methods can be explained. To reduce the effect of noise, which often can be
mistaken for an anomaly, we introduce a powerful preprocessing pipeline. We
provide an extensive evaluation of different approaches and demonstrate
empirically that even without labels it is possible to achieve satisfying
results on a real-world dataset of X-ray images of hands. We also evaluate the
importance of preprocessing and one of our main findings is that without it,
most of our approaches perform not better than random. To foster
reproducibility and accelerate research we make our code publicly available at
https://github.com/Valentyn1997/xray
</p>
<a href="http://arxiv.org/abs/2001.10883" target="_blank">arXiv:2001.10883</a> [<a href="http://arxiv.org/pdf/2001.10883" target="_blank">pdf</a>]

<h2>Fractional Underdamped Langevin Dynamics: Retargeting SGD with Momentum under Heavy-Tailed Gradient Noise. (arXiv:2002.05685v2 [stat.ML] UPDATED)</h2>
<h3>Umut &#x15e;im&#x15f;ekli, Lingjiong Zhu, Yee Whye Teh, Mert G&#xfc;rb&#xfc;zbalaban</h3>
<p>Stochastic gradient descent with momentum (SGDm) is one of the most popular
optimization algorithms in deep learning. While there is a rich theory of SGDm
for convex problems, the theory is considerably less developed in the context
of deep learning where the problem is non-convex and the gradient noise might
exhibit a heavy-tailed behavior, as empirically observed in recent studies. In
this study, we consider a \emph{continuous-time} variant of SGDm, known as the
underdamped Langevin dynamics (ULD), and investigate its asymptotic properties
under heavy-tailed perturbations. Supported by recent studies from statistical
physics, we argue both theoretically and empirically that the heavy-tails of
such perturbations can result in a bias even when the step-size is small, in
the sense that \emph{the optima of stationary distribution} of the dynamics
might not match \emph{the optima of the cost function to be optimized}. As a
remedy, we develop a novel framework, which we coin as \emph{fractional} ULD
(FULD), and prove that FULD targets the so-called Gibbs distribution, whose
optima exactly match the optima of the original cost. We observe that the Euler
discretization of FULD has noteworthy algorithmic similarities with
\emph{natural gradient} methods and \emph{gradient clipping}, bringing a new
perspective on understanding their role in deep learning. We support our theory
with experiments conducted on a synthetic model and neural networks.
</p>
<a href="http://arxiv.org/abs/2002.05685" target="_blank">arXiv:2002.05685</a> [<a href="http://arxiv.org/pdf/2002.05685" target="_blank">pdf</a>]

<h2>Task-space Synergies for Reaching using Upper-limb Prostheses. (arXiv:2002.08018v2 [cs.RO] UPDATED)</h2>
<h3>Ricardo Garcia-Rosas, Denny Oetomo, Chris Manzie, Ying Tan, Peter Choong</h3>
<p>Synergistic prostheses enable the coordinated movement of the
human-prosthetic arm, as required by activities of daily living. This is
achieved by coupling the motion of the prosthesis to the human command, such as
the residual limb movement in motion-based interfaces. Previous studies
demonstrated that developing human-prosthetic synergies in joint-space must
consider individual motor behaviour and the intended task to be performed,
requiring personalisation and task calibration. In this work, an alternative
synergy-based strategy, utilising a synergistic relationship expressed in
task-space, is proposed. This task-space synergy has the potential to replace
the need for personalisation and task calibration with a model-based approach
requiring knowledge of the individual user's arm kinematics, the anticipated
hand motion during the task and voluntary information from the prosthetic user.
The proposed method is compared with surface electromyography-based and
joint-space synergy-based prosthetic interfaces in a study of motor behaviour
and task performance on able-bodied subjects using a VR-based transhumeral
prosthesis. Experimental results showed that for a set of forward reaching
tasks the proposed task-space synergy achieves comparable performance to
joint-space synergies without the need to rely on time-consuming calibration
processes or human motor learning. Case study results with an amputee subject
motivate the further development of the proposed task-space synergy method.
</p>
<a href="http://arxiv.org/abs/2002.08018" target="_blank">arXiv:2002.08018</a> [<a href="http://arxiv.org/pdf/2002.08018" target="_blank">pdf</a>]

<h2>On the Search for Feedback in Reinforcement Learning. (arXiv:2002.09478v3 [cs.LG] UPDATED)</h2>
<h3>Ran Wang, Karthikeya S. Parunandi, Aayushman Sharma, Suman Chakravorty, Dileep Kalathil</h3>
<p>This paper addresses the problem of learning the optimal feedback policy for
a nonlinear stochastic dynamical system. Feedback policies typically need a
high dimensional parametrization, which makes Reinforcement Learning (RL)
algorithms that search for an optimum in this large parameter space, sample
inefficient and subject to high variance. We propose a "decoupling" principle
that drastically reduces the feedback parameter space while still remaining
locally optimal. A corollary of this result is a decoupled data-based control
(D2C) algorithm for RL: first, an open-loop deterministic trajectory
optimization problem is solved using a black-box simulation model of the
dynamical system. Then, a linear closed-loop control is developed around this
nominal trajectory using the simulation model. Empirical evidence suggests
highly significant reduction in training time, as well as the training
variance, without compromising on performance, compared to state of the art RL
algorithms.
</p>
<a href="http://arxiv.org/abs/2002.09478" target="_blank">arXiv:2002.09478</a> [<a href="http://arxiv.org/pdf/2002.09478" target="_blank">pdf</a>]

<h2>Towards Data Auctions with Externalities. (arXiv:2003.08345v2 [cs.GT] UPDATED)</h2>
<h3>Anish Agarwal, Munther Dahleh, Thibaut Horel, Maryann Rui</h3>
<p>The design of data markets has gained importance as firms increasingly use
predictions from machine learning models to streamline operations, yet need to
externally acquire training data to fit such models. One aspect that has
received limited consideration is the externality a firm faces when data is
allocated to competing firms. Towards this, we consider the setting of $n$
competing firms and a monopolistic data seller. We demonstrate how modeling
utility solely through increases in prediction accuracy reduces the
combinatorial problem of allocating and pricing multiple datasets to a single
digital good auction. We find the welfare and revenue maximizing mechanisms,
highlighting how the form of firms' private information -- whether they know
the externalities they exert on others or vice-versa -- affects their overall
structures. In all cases, the optimal allocation rule is a single threshold
(one per firm), where either all data is allocated or none is.
</p>
<a href="http://arxiv.org/abs/2003.08345" target="_blank">arXiv:2003.08345</a> [<a href="http://arxiv.org/pdf/2003.08345" target="_blank">pdf</a>]

<h2>Automatic Identification of Types of Alterations in Historical Manuscripts. (arXiv:2003.09136v3 [cs.LG] UPDATED)</h2>
<h3>David Lassner (TUB), Anne Baillot (3L.AM), Sergej Dogadov (TUB), Klaus-Robert M&#xfc;ller (TUB), Shinichi Nakajima (TUB)</h3>
<p>Alterations in historical manuscripts such as letters represent a promising
field of research. On the one hand, they help understand the construction of
text. On the other hand, topics that are being considered sensitive at the time
of the manuscript gain coherence and contextuality when taking alterations into
account, especially in the case of deletions. The analysis of alterations in
manuscripts, though, is a traditionally very tedious work. In this paper, we
present a machine learning-based approach to help categorize alterations in
documents. In particular, we present a new probabilistic model (Alteration
Latent Dirichlet Allocation, alterLDA in the following) that categorizes
content-related alterations. The method proposed here is developed based on
experiments carried out on the digital scholarly edition Berlin Intellectuals,
for which alterLDA achieves high performance in the recognition of alterations
on labelled data. On unlabelled data, applying alterLDA leads to interesting
new insights into the alteration behavior of authors, editors and other
manuscript contributors, as well as insights into sensitive topics in the
correspondence of Berlin intellectuals around 1800. In addition to the findings
based on the digital scholarly edition Berlin Intellectuals, we present a
general framework for the analysis of text genesis that can be used in the
context of other digital resources representing document variants. To that end,
we present in detail the methodological steps that are to be followed in order
to achieve such results, giving thereby a prime example of an Machine Learning
application the Digital Humanities.
</p>
<a href="http://arxiv.org/abs/2003.09136" target="_blank">arXiv:2003.09136</a> [<a href="http://arxiv.org/pdf/2003.09136" target="_blank">pdf</a>]

<h2>Rectified Linear Postsynaptic Potential Function for Backpropagation in Deep Spiking Neural Networks. (arXiv:2003.11837v2 [cs.NE] UPDATED)</h2>
<h3>Malu Zhang, Jiadong Wang, Burin Amornpaisannon, Zhixuan Zhang, VPK Miriyala, Ammar Belatreche, Hong Qu, Jibin Wu, Yansong Chua, Trevor E. Carlson, Haizhou Li</h3>
<p>Spiking Neural Networks (SNNs) use spatio-temporal spike patterns to
represent and transmit information, which is not only biologically realistic
but also suitable for ultra-low-power event-driven neuromorphic implementation.
Motivated by the success of deep learning, the study of Deep Spiking Neural
Networks (DeepSNNs) provides promising directions for artificial intelligence
applications. However, training of DeepSNNs is not straightforward because the
well-studied error back-propagation (BP) algorithm is not directly applicable.
In this paper, we first establish an understanding as to why error
back-propagation does not work well in DeepSNNs. To address this problem, we
propose a simple yet efficient Rectified Linear Postsynaptic Potential function
(ReL-PSP) for spiking neurons and propose a Spike-Timing-Dependent
Back-Propagation (STDBP) learning algorithm for DeepSNNs. In STDBP algorithm,
the timing of individual spikes is used to convey information (temporal
coding), and learning (back-propagation) is performed based on spike timing in
an event-driven manner. Our experimental results show that the proposed
learning algorithm achieves state-of-the-art classification accuracy in single
spike time based learning algorithms of DeepSNNs. Furthermore, by utilizing the
trained model parameters obtained from the proposed STDBP learning algorithm,
we demonstrate the ultra-low-power inference operations on a recently proposed
neuromorphic inference accelerator. Experimental results show that the
neuromorphic hardware consumes 0.751~mW of the total power consumption and
achieves a low latency of 47.71~ms to classify an image from the MNIST dataset.
Overall, this work investigates the contribution of spike timing dynamics to
information encoding, synaptic plasticity and decision making, providing a new
perspective to design of future DeepSNNs and neuromorphic hardware systems.
</p>
<a href="http://arxiv.org/abs/2003.11837" target="_blank">arXiv:2003.11837</a> [<a href="http://arxiv.org/pdf/2003.11837" target="_blank">pdf</a>]

<h2>Scalable Gaussian Processes, with Guarantees: Kernel Approximations and Deep Feature Extraction. (arXiv:2004.01584v4 [stat.ML] UPDATED)</h2>
<h3>Constantinos Daskalakis, Petros Dellaportas, Aristeidis Panos</h3>
<p>We provide approximation guarantees for a linear-time inferential framework
for Gaussian processes, using two low-rank kernel approximations based on
random Fourier features and truncation of Mercer expansions. In particular, we
bound the Kullback-Leibler divergence between the idealized Gaussian process
and the one resulting from a low-rank approximation to its kernel.
Additionally, we present strong evidence that these two approximations,
enhanced by an initial automatic feature extraction through deep neural
networks, outperform a broad range of state-of-the-art methods in terms of time
efficiency, negative log-predictive density, and root mean squared error.
</p>
<a href="http://arxiv.org/abs/2004.01584" target="_blank">arXiv:2004.01584</a> [<a href="http://arxiv.org/pdf/2004.01584" target="_blank">pdf</a>]

<h2>From Generalized zero-shot learning to long-tail with class descriptors. (arXiv:2004.02235v4 [cs.LG] UPDATED)</h2>
<h3>Dvir Samuel, Yuval Atzmon, Gal Chechik</h3>
<p>Real-world data is predominantly unbalanced and long-tailed, but deep models
struggle to recognize rare classes in the presence of frequent classes. Often,
classes can be accompanied by side information like textual descriptions, but
it is not fully clear how to use them for learning with unbalanced long-tail
data. Such descriptions have been mostly used in (Generalized) Zero-shot
learning (ZSL), suggesting that ZSL with class descriptions may also be useful
for long-tail distributions. We describe DRAGON, a late-fusion architecture for
long-tail learning with class descriptors. It learns to (1) correct the bias
towards head classes on a sample-by-sample basis; and (2) fuse information from
class-descriptions to improve the tail-class accuracy. We also introduce new
benchmarks CUB-LT, SUN-LT, AWA-LT for long-tail learning with
class-descriptions, building on existing learning-with-attributes datasets and
a version of Imagenet-LT with class descriptors. DRAGON outperforms
state-of-the-art models on the new benchmark. It is also a new SoTA on existing
benchmarks for GFSL with class descriptors (GFSL-d) and standard (vision-only)
long-tailed learning ImageNet-LT, CIFAR-10, 100, and Places365.
</p>
<a href="http://arxiv.org/abs/2004.02235" target="_blank">arXiv:2004.02235</a> [<a href="http://arxiv.org/pdf/2004.02235" target="_blank">pdf</a>]

<h2>SR2CNN: Zero-Shot Learning for Signal Recognition. (arXiv:2004.04892v6 [cs.LG] UPDATED)</h2>
<h3>Yihong Dong, Xiaohan Jiang, Huaji Zhou, Yun Lin, Qingjiang Shi</h3>
<p>Signal recognition is one of significant and challenging tasks in the signal
processing and communications field. It is often a common situation that
there's no training data accessible for some signal classes to perform a
recognition task. Hence, as widely-used in image processing field, zero-shot
learning (ZSL) is also very important for signal recognition. Unfortunately,
ZSL regarding this field has hardly been studied due to inexplicable signal
semantics. This paper proposes a ZSL framework, signal recognition and
reconstruction convolutional neural networks (SR2CNN), to address relevant
problems in this situation. The key idea behind SR2CNN is to learn the
representation of signal semantic feature space by introducing a proper
combination of cross entropy loss, center loss and autoencoder loss, as well as
adopting a suitable distance metric space such that semantic features have
greater minimal inter-class distance than maximal intra-class distance. The
proposed SR2CNN can discriminate signals even if no training data is available
for some signal class. Moreover, SR2CNN can gradually improve itself in the aid
of signal detection, because of constantly refined class center vectors in
semantic feature space. These merits are all verified by extensive experiments.
</p>
<a href="http://arxiv.org/abs/2004.04892" target="_blank">arXiv:2004.04892</a> [<a href="http://arxiv.org/pdf/2004.04892" target="_blank">pdf</a>]

<h2>SIGN: Scalable Inception Graph Neural Networks. (arXiv:2004.11198v3 [cs.LG] UPDATED)</h2>
<h3>Fabrizio Frasca, Emanuele Rossi, Davide Eynard, Ben Chamberlain, Michael Bronstein, Federico Monti</h3>
<p>Graph representation learning has recently been applied to a broad spectrum
of problems ranging from computer graphics and chemistry to high energy physics
and social media. The popularity of graph neural networks has sparked interest,
both in academia and in industry, in developing methods that scale to very
large graphs such as Facebook or Twitter social networks. In most of these
approaches, the computational cost is alleviated by a sampling strategy
retaining a subset of node neighbors or subgraphs at training time. In this
paper we propose a new, efficient and scalable graph deep learning architecture
which sidesteps the need for graph sampling by using graph convolutional
filters of different size that are amenable to efficient precomputation,
allowing extremely fast training and inference. Our architecture allows using
different local graph operators (e.g. motif-induced adjacency matrices or
Personalized Page Rank diffusion matrix) to best suit the task at hand. We
conduct extensive experimental evaluation on various open benchmarks and show
that our approach is competitive with other state-of-the-art architectures,
while requiring a fraction of the training and inference time. Moreover, we
obtain state-of-the-art results on ogbn-papers100M, the largest public graph
dataset, with over 110 million nodes and 1.5 billion edges.
</p>
<a href="http://arxiv.org/abs/2004.11198" target="_blank">arXiv:2004.11198</a> [<a href="http://arxiv.org/pdf/2004.11198" target="_blank">pdf</a>]

<h2>RAIN: A Simple Approach for Robust and Accurate Image Classification Networks. (arXiv:2004.14798v4 [cs.CR] UPDATED)</h2>
<h3>Jiawei Du, Hanshu Yan, Vincent Y. F. Tan, Joey Tianyi Zhou, Rick Siow Mong Goh, Jiashi Feng</h3>
<p>It has been shown that the majority of existing adversarial defense methods
achieve robustness at the cost of sacrificing prediction accuracy. The
undesirable severe drop in accuracy adversely affects the reliability of
machine learning algorithms and prohibits their deployment in realistic
applications. This paper aims to address this dilemma by proposing a novel
preprocessing framework, which we term Robust and Accurate Image
classificatioN(RAIN), to improve the robustness of given CNN classifiers and,
at the same time, preserve their high prediction accuracies. RAIN introduces a
new randomization-enhancement scheme. It applies randomization over inputs to
break the ties between the model forward prediction path and the backward
gradient path, thus improving the model robustness. However, similar to
existing preprocessing-based methods, the randomized process will degrade the
prediction accuracy. To understand why this is the case, we compare the
difference between original and processed images, and find it is the loss of
high-frequency components in the input image that leads to accuracy drop of the
classifier. Based on this finding, RAIN enhances the input's high-frequency
details to retain the CNN's high prediction accuracy. Concretely, RAIN consists
of two novel randomization modules: randomized small circular shift (RdmSCS)
and randomized down-upsampling (RdmDU). The RdmDU module randomly downsamples
the input image, and then the RdmSCS module circularly shifts the input image
along a randomly chosen direction by a small but random number of pixels.
Finally, the RdmDU module performs upsampling with a detail-enhancement model,
such as deep super-resolution networks. We conduct extensive experiments on the
STL10 and ImageNet datasets to verify the effectiveness of RAIN against various
types of adversarial attacks.
</p>
<a href="http://arxiv.org/abs/2004.14798" target="_blank">arXiv:2004.14798</a> [<a href="http://arxiv.org/pdf/2004.14798" target="_blank">pdf</a>]

<h2>Robust Spatial-spread Deep Neural Image Watermarking. (arXiv:2005.11735v2 [cs.MM] UPDATED)</h2>
<h3>Marcin Plata, Piotr Syga</h3>
<p>Watermarking is an operation of embedding an information into an image in a
way that allows to identify ownership of the image despite applying some
distortions on it. In this paper, we presented a novel end-to-end solution for
embedding and recovering the watermark in the digital image using convolutional
neural networks. The method is based on spreading the message over the spatial
domain of the image, hence reducing the "local bits per pixel" capacity. To
obtain the model we used adversarial training and applied noiser layers between
the encoder and the decoder. Moreover, we broadened the spectrum of typically
considered attacks on the watermark and by grouping the attacks according to
their scope, we achieved high general robustness, most notably against JPEG
compression, Gaussian blurring, subsampling or resizing. To help us in the
models training we also proposed a precise differentiable approximation of
JPEG.
</p>
<a href="http://arxiv.org/abs/2005.11735" target="_blank">arXiv:2005.11735</a> [<a href="http://arxiv.org/pdf/2005.11735" target="_blank">pdf</a>]

<h2>CoAID: COVID-19 Healthcare Misinformation Dataset. (arXiv:2006.00885v3 [cs.SI] UPDATED)</h2>
<h3>Limeng Cui, Dongwon Lee</h3>
<p>As the COVID-19 virus quickly spreads around the world, unfortunately,
misinformation related to COVID-19 also gets created and spreads like wild
fire. Such misinformation has caused confusion among people, disruptions in
society, and even deadly consequences in health problems. To be able to
understand, detect, and mitigate such COVID-19 misinformation, therefore, has
not only deep intellectual values but also huge societal impacts. To help
researchers combat COVID-19 health misinformation, therefore, we present CoAID
(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare
misinformation, including fake news on websites and social platforms, along
with users' social engagement about such news. CoAID includes 4,251 news,
296,000 related user engagements, 926 social platform posts about COVID-19, and
ground truth labels. The dataset is available at:
https://github.com/cuilimeng/CoAID.
</p>
<a href="http://arxiv.org/abs/2006.00885" target="_blank">arXiv:2006.00885</a> [<a href="http://arxiv.org/pdf/2006.00885" target="_blank">pdf</a>]

<h2>Path Sample-Analytic Gradient Estimators for Stochastic Binary Networks. (arXiv:2006.03143v2 [stat.ML] UPDATED)</h2>
<h3>Alexander Shekhovtsov, Viktor Yanush, Boris Flach</h3>
<p>In neural networks with binary activations and or binary weights the training
by gradient descent is complicated as the model has piecewise constant
response. We consider stochastic binary networks, obtained by adding noises in
front of activations. The expected model response becomes a smooth function of
parameters, its gradient is well defined but it is challenging to estimate it
accurately. We propose a new method for this estimation problem combining
sampling and analytic approximation steps. The method has a significantly
reduced variance at the price of a small bias which gives a very practical
tradeoff in comparison with existing unbiased and biased estimators. We further
show that one extra linearization step leads to a deep straight-through
estimator previously known only as an ad-hoc heuristic. We experimentally show
higher accuracy in gradient estimation and demonstrate a more stable and better
performing training in deep convolutional models with both proposed methods.
</p>
<a href="http://arxiv.org/abs/2006.03143" target="_blank">arXiv:2006.03143</a> [<a href="http://arxiv.org/pdf/2006.03143" target="_blank">pdf</a>]

<h2>Ansor : Generating High-Performance Tensor Programs for Deep Learning. (arXiv:2006.06762v4 [cs.LG] UPDATED)</h2>
<h3>Lianmin Zheng, Chengfan Jia, Minmin Sun, Zhao Wu, Cody Hao Yu, Ameer Haj-Ali, Yida Wang, Jun Yang, Danyang Zhuo, Koushik Sen, Joseph E. Gonzalez, Ion Stoica</h3>
<p>High-performance tensor programs are crucial to guarantee efficient execution
of deep neural networks. However, obtaining performant tensor programs for
different operators on various hardware platforms is notoriously challenging.
Currently, deep learning systems rely on vendor-provided kernel libraries or
various search strategies to get performant tensor programs. These approaches
either require significant engineering effort to develop platform-specific
optimization code or fall short of finding high-performance programs due to
restricted search space and ineffective exploration strategy.

We present Ansor, a tensor program generation framework for deep learning
applications. Compared with existing search strategies, Ansor explores many
more optimization combinations by sampling programs from a hierarchical
representation of the search space. Ansor then fine-tunes the sampled programs
with evolutionary search and a learned cost model to identify the best
programs. Ansor can find high-performance programs that are outside the search
space of existing state-of-the-art approaches. In addition, Ansor utilizes a
task scheduler to simultaneously optimize multiple subgraphs in deep neural
networks. We show that Ansor improves the execution performance of deep neural
networks relative to the state-of-the-art on the Intel CPU, ARM CPU, and NVIDIA
GPU by up to $3.8\times$, $2.6\times$, and $1.7\times$, respectively.
</p>
<a href="http://arxiv.org/abs/2006.06762" target="_blank">arXiv:2006.06762</a> [<a href="http://arxiv.org/pdf/2006.06762" target="_blank">pdf</a>]

<h2>Evaluation of Neural Architectures Trained with Square Loss vs Cross-Entropy in Classification Tasks. (arXiv:2006.07322v3 [cs.LG] UPDATED)</h2>
<h3>Like Hui, Mikhail Belkin</h3>
<p>Modern neural architectures for classification tasks are trained using the
cross-entropy loss, which is widely believed to be empirically superior to the
square loss. In this work we provide evidence indicating that this belief may
not be well-founded. We explore several major neural architectures and a range
of standard benchmark datasets for NLP, automatic speech recognition (ASR) and
computer vision tasks to show that these architectures, with the same
hyper-parameter settings as reported in the literature, perform comparably or
better when trained with the square loss, even after equalizing computational
resources. Indeed, we observe that the square loss produces better results in
the dominant majority of NLP and ASR experiments. Cross-entropy appears to have
a slight edge on computer vision tasks.

We argue that there is little compelling empirical or theoretical evidence
indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our
experiments, performance on nearly all non-vision tasks can be improved,
sometimes significantly, by switching to the square loss. Furthermore, training
with square loss appears to be less sensitive to the randomness in
initialization. We posit that training using the square loss for classification
needs to be a part of best practices of modern deep learning on equal footing
with cross-entropy.
</p>
<a href="http://arxiv.org/abs/2006.07322" target="_blank">arXiv:2006.07322</a> [<a href="http://arxiv.org/pdf/2006.07322" target="_blank">pdf</a>]

<h2>Layer-wise Learning of Kernel Dependence Networks. (arXiv:2006.08539v2 [stat.ML] UPDATED)</h2>
<h3>Chieh Wu, Aria Masoomi, Arthur Gretton, Jennifer Dy</h3>
<p>Due to recent debate over the biological plausibility of backpropagation
(BP), finding an alternative network optimization strategy has become an active
area of interest. We design a new type of kernel network, that is solved
greedily, to theoretically answer several questions of interest. First, if BP
is difficult to simulate in the brain, are there instead \textit{trivial
network weights} (requiring minimum computation) that allow a greedily trained
network to classify any pattern. Second, can a greedily trained network
converge to a kernel? What kernel will it converge to? Third, is this trivial
solution optimal? How is the optimal solution related to generalization?
Lastly, can we theoretically identify the network width and depth without a
grid search? We prove that the kernel embedding is the trivial solution that
compels the greedy procedure to converge to a kernel with Universal property.
Yet, this trivial solution is not even optimal. By obtaining the optimal
solution spectrally, it provides insight into the generalization of the network
while informing us of the network width and depth.
</p>
<a href="http://arxiv.org/abs/2006.08539" target="_blank">arXiv:2006.08539</a> [<a href="http://arxiv.org/pdf/2006.08539" target="_blank">pdf</a>]

<h2>Explaining Local, Global, And Higher-Order Interactions In Deep Learning. (arXiv:2006.08601v2 [cs.LG] UPDATED)</h2>
<h3>Samuel Lerman, Chenliang Xu, Charles Venuto, Henry Kautz</h3>
<p>We present a simple yet highly generalizable method for explaining
interacting parts within a neural network's reasoning process. First, we design
an algorithm based on cross derivatives for computing statistical interaction
effects between individual features, which is generalized to both 2-way and
higher-order (3-way or more) interactions. We present results side by side with
a weight-based attribution technique, corroborating that cross derivatives are
a superior metric for both 2-way and higher-order interaction detection.
Moreover, we extend the use of cross derivatives as an explanatory device in
neural networks to the computer vision setting by expanding Grad-CAM, a popular
gradient-based explanatory tool in computer vision, to the higher order. While
Grad-CAM can only explain the importance of individual objects in images, our
method, which we call TaylorCAM, can explain a neural network's relational
reasoning across multiple objects. We show the success of our explanations both
qualitatively and quantitatively with a human study. Code for all experiments,
fully reproducible, may be found at
https://www.github.com/slerman12/ExplainingInteractions.
</p>
<a href="http://arxiv.org/abs/2006.08601" target="_blank">arXiv:2006.08601</a> [<a href="http://arxiv.org/pdf/2006.08601" target="_blank">pdf</a>]

<h2>SatImNet: Structured and Harmonised Training Data for Enhanced Satellite Imagery Classification. (arXiv:2006.10623v2 [cs.CV] UPDATED)</h2>
<h3>Vasileios Syrris, Ondrej Pesek, Pierre Soille</h3>
<p>Automatic supervised classification with complex modelling such as deep
neural networks requires the availability of representative training data sets.
While there exists a plethora of data sets that can be used for this purpose,
they are usually very heterogeneous and not interoperable. In this context, the
present work has a twofold objective: i) to describe procedures of open-source
training data management, integration, and data retrieval, and ii) to
demonstrate the practical use of varying source training data for remote
sensing image classification. For the former, we propose SatImNet, a collection
of open training data, structured and harmonized according to specific rules.
For the latter, two modelling approaches based on convolutional neural networks
have been designed and configured to deal with satellite image classification
and segmentation.
</p>
<a href="http://arxiv.org/abs/2006.10623" target="_blank">arXiv:2006.10623</a> [<a href="http://arxiv.org/pdf/2006.10623" target="_blank">pdf</a>]

<h2>Erdos Goes Neural: an Unsupervised Learning Framework for Combinatorial Optimization on Graphs. (arXiv:2006.10643v3 [cs.LG] UPDATED)</h2>
<h3>Nikolaos Karalias, Andreas Loukas</h3>
<p>Combinatorial optimization problems are notoriously challenging for neural
networks, especially in the absence of labeled instances. This work proposes an
unsupervised learning framework for CO problems on graphs that can provide
integral solutions of certified quality. Inspired by Erdos' probabilistic
method, we use a neural network to parametrize a probability distribution over
sets. Crucially, we show that when the network is optimized w.r.t. a suitably
chosen loss, the learned distribution contains, with controlled probability, a
low-cost integral solution that obeys the constraints of the combinatorial
problem. The probabilistic proof of existence is then derandomized to decode
the desired solutions. We demonstrate the efficacy of this approach to obtain
valid solutions to the maximum clique problem and to perform local graph
clustering. Our method achieves competitive results on both real datasets and
synthetic hard instances.
</p>
<a href="http://arxiv.org/abs/2006.10643" target="_blank">arXiv:2006.10643</a> [<a href="http://arxiv.org/pdf/2006.10643" target="_blank">pdf</a>]

<h2>P3GM: Private High-Dimensional Data Release via Privacy Preserving Phased Generative Model. (arXiv:2006.12101v3 [cs.LG] UPDATED)</h2>
<h3>Shun Takagi, Tsubasa Takahashi, Yang Cao, Masatoshi Yoshikawa</h3>
<p>How can we release a massive volume of sensitive data while mitigating
privacy risks? Privacy-preserving data synthesis enables the data holder to
outsource analytical tasks to an untrusted third party. The state-of-the-art
approach for this problem is to build a generative model under differential
privacy, which offers a rigorous privacy guarantee. However, the existing
method cannot adequately handle high dimensional data. In particular, when the
input dataset contains a large number of features, the existing techniques
require injecting a prohibitive amount of noise to satisfy differential
privacy, which results in the outsourced data analysis meaningless. To address
the above issue, this paper proposes privacy-preserving phased generative model
(P3GM), which is a differentially private generative model for releasing such
sensitive data. P3GM employs the two-phase learning process to make it robust
against the noise, and to increase learning efficiency (e.g., easy to
converge). We give theoretical analyses about the learning complexity and
privacy loss in P3GM. We further experimentally evaluate our proposed method
and demonstrate that P3GM significantly outperforms existing solutions.
Compared with the state-of-the-art methods, our generated samples look fewer
noises and closer to the original data in terms of data diversity. Besides, in
several data mining tasks with synthesized data, our model outperforms the
competitors in terms of accuracy.
</p>
<a href="http://arxiv.org/abs/2006.12101" target="_blank">arXiv:2006.12101</a> [<a href="http://arxiv.org/pdf/2006.12101" target="_blank">pdf</a>]

<h2>Learning Disentangled Representations of Video with Missing Data. (arXiv:2006.13391v2 [cs.LG] UPDATED)</h2>
<h3>Armand Comas-Massagu&#xe9;, Chi Zhang, Zlatan Feric, Octavia Camps, Rose Yu</h3>
<p>Missing data poses significant challenges while learning representations of
video sequences. We present Disentangled Imputed Video autoEncoder (DIVE), a
deep generative model that imputes and predicts future video frames in the
presence of missing data. Specifically, DIVE introduces a missingness latent
variable, disentangles the hidden video representations into static and dynamic
appearance, pose, and missingness factors for each object. DIVE imputes each
object's trajectory where data is missing. On a moving MNIST dataset with
various missing scenarios, DIVE outperforms the state of the art baselines by a
substantial margin. We also present comparisons for real-world MOTSChallenge
pedestrian dataset, which demonstrates the practical value of our method in a
more realistic setting. Our code and data can be found at
https://github.com/Rose-STL-Lab/DIVE.
</p>
<a href="http://arxiv.org/abs/2006.13391" target="_blank">arXiv:2006.13391</a> [<a href="http://arxiv.org/pdf/2006.13391" target="_blank">pdf</a>]

<h2>Learning Sparse Prototypes for Text Generation. (arXiv:2006.16336v2 [cs.CL] UPDATED)</h2>
<h3>Junxian He, Taylor Berg-Kirkpatrick, Graham Neubig</h3>
<p>Prototype-driven text generation uses non-parametric models that first choose
from a library of sentence "prototypes" and then modify the prototype to
generate the output text. While effective, these methods are inefficient at
test time as a result of needing to store and index the entire training corpus.
Further, existing methods often require heuristics to identify which prototypes
to reference at training time. In this paper, we propose a novel generative
model that automatically learns a sparse prototype support set that,
nonetheless, achieves strong language modeling performance. This is achieved by
(1) imposing a sparsity-inducing prior on the prototype selection distribution,
and (2) utilizing amortized variational inference to learn a prototype
retrieval function. In experiments, our model outperforms previous
prototype-driven language models while achieving up to a 1000x memory
reduction, as well as a 1000x speed-up at test time. More interestingly, we
show that the learned prototypes are able to capture semantics and syntax at
different granularity as we vary the sparsity of prototype selection, and that
certain sentence attributes can be controlled by specifying the prototype for
generation.
</p>
<a href="http://arxiv.org/abs/2006.16336" target="_blank">arXiv:2006.16336</a> [<a href="http://arxiv.org/pdf/2006.16336" target="_blank">pdf</a>]

<h2>NeuMiss networks: differentiable programming for supervised learning with missing values. (arXiv:2007.01627v4 [cs.LG] UPDATED)</h2>
<h3>Marine Le Morvan (PARIETAL, IJCLab), Julie Josse (CMAP, XPOP), Thomas Moreau (PARIETAL), Erwan Scornet (CMAP), Ga&#xeb;l Varoquaux (PARIETAL, MILA)</h3>
<p>The presence of missing values makes supervised learning much more
challenging. Indeed, previous work has shown that even when the response is a
linear function of the complete data, the optimal predictor is a complex
function of the observed entries and the missingness indicator. As a result,
the computational or sample complexities of consistent approaches depend on the
number of missing patterns, which can be exponential in the number of
dimensions. In this work, we derive the analytical form of the optimal
predictor under a linearity assumption and various missing data mechanisms
including Missing at Random (MAR) and self-masking (Missing Not At Random).
Based on a Neumann-series approximation of the optimal predictor, we propose a
new principled architecture, named NeuMiss networks. Their originality and
strength come from the use of a new type of non-linearity: the multiplication
by the missingness indicator. We provide an upper bound on the Bayes risk of
NeuMiss networks, and show that they have good predictive accuracy with both a
number of parameters and a computational complexity independent of the number
of missing data patterns. As a result they scale well to problems with many
features, and remain statistically efficient for medium-sized samples.
Moreover, we show that, contrary to procedures using EM or imputation, they are
robust to the missing data mechanism, including difficult MNAR settings such as
self-masking.
</p>
<a href="http://arxiv.org/abs/2007.01627" target="_blank">arXiv:2007.01627</a> [<a href="http://arxiv.org/pdf/2007.01627" target="_blank">pdf</a>]

<h2>Differentiable Causal Discovery from Interventional Data. (arXiv:2007.01754v2 [cs.LG] UPDATED)</h2>
<h3>Philippe Brouillard, S&#xe9;bastien Lachapelle, Alexandre Lacoste, Simon Lacoste-Julien, Alexandre Drouin</h3>
<p>Learning a causal directed acyclic graph from data is a challenging task that
involves solving a combinatorial problem for which the solution is not always
identifiable. A new line of work reformulates this problem as a continuous
constrained optimization one, which is solved via the augmented Lagrangian
method. However, most methods based on this idea do not make use of
interventional data, which can significantly alleviate identifiability issues.
This work constitutes a new step in this direction by proposing a
theoretically-grounded method based on neural networks that can leverage
interventional data. We illustrate the flexibility of the
continuous-constrained framework by taking advantage of expressive neural
architectures such as normalizing flows. We show that our approach compares
favorably to the state of the art in a variety of settings, including perfect
and imperfect interventions for which the targeted nodes may even be unknown.
</p>
<a href="http://arxiv.org/abs/2007.01754" target="_blank">arXiv:2007.01754</a> [<a href="http://arxiv.org/pdf/2007.01754" target="_blank">pdf</a>]

<h2>Meta-Learning Requires Meta-Augmentation. (arXiv:2007.05549v2 [cs.LG] UPDATED)</h2>
<h3>Janarthanan Rajendran, Alex Irpan, Eric Jang</h3>
<p>Meta-learning algorithms aim to learn two components: a model that predicts
targets for a task, and a base learner that quickly updates that model when
given examples from a new task. This additional level of learning can be
powerful, but it also creates another potential source for overfitting, since
we can now overfit in either the model or the base learner. We describe both of
these forms of metalearning overfitting, and demonstrate that they appear
experimentally in common meta-learning benchmarks. We then use an
information-theoretic framework to discuss meta-augmentation, a way to add
randomness that discourages the base learner and model from learning trivial
solutions that do not generalize to new tasks. We demonstrate that
meta-augmentation produces large complementary benefits to recently proposed
meta-regularization techniques.
</p>
<a href="http://arxiv.org/abs/2007.05549" target="_blank">arXiv:2007.05549</a> [<a href="http://arxiv.org/pdf/2007.05549" target="_blank">pdf</a>]

<h2>Ensuring Fairness Beyond the Training Data. (arXiv:2007.06029v2 [cs.LG] UPDATED)</h2>
<h3>Debmalya Mandal, Samuel Deng, Suman Jana, Jeannette M. Wing, Daniel Hsu</h3>
<p>We initiate the study of fair classifiers that are robust to perturbations in
the training distribution. Despite recent progress, the literature on fairness
has largely ignored the design of fair and robust classifiers. In this work, we
develop classifiers that are fair not only with respect to the training
distribution, but also for a class of distributions that are weighted
perturbations of the training samples. We formulate a min-max objective
function whose goal is to minimize a distributionally robust training loss, and
at the same time, find a classifier that is fair with respect to a class of
distributions. We first reduce this problem to finding a fair classifier that
is robust with respect to the class of distributions. Based on online learning
algorithm, we develop an iterative algorithm that provably converges to such a
fair and robust solution. Experiments on standard machine learning fairness
datasets suggest that, compared to the state-of-the-art fair classifiers, our
classifier retains fairness guarantees and test accuracy for a large class of
perturbations on the test set. Furthermore, our experiments show that there is
an inherent trade-off between fairness robustness and accuracy of such
classifiers.
</p>
<a href="http://arxiv.org/abs/2007.06029" target="_blank">arXiv:2007.06029</a> [<a href="http://arxiv.org/pdf/2007.06029" target="_blank">pdf</a>]

<h2>Deep Transformer based Data Augmentation with Subword Units for Morphologically Rich Online ASR. (arXiv:2007.06949v3 [eess.AS] UPDATED)</h2>
<h3>Bal&#xe1;zs Tarj&#xe1;n, Gy&#xf6;rgy Szasz&#xe1;k, Tibor Fegy&#xf3;, P&#xe9;ter Mihajlik</h3>
<p>Recently Deep Transformer models have proven to be particularly powerful in
language modeling tasks for ASR. Their high complexity, however, makes them
very difficult to apply in the first (single) pass of an online system. Recent
studies showed that a considerable part of the knowledge of neural network
Language Models (LM) can be transferred to traditional n-grams by using neural
text generation based data augmentation. In our paper, we pre-train a GPT-2
Transformer LM on a general text corpus and fine-tune it on our Hungarian
conversational call center ASR task. We show that although data augmentation
with Transformer-generated text works well for isolating languages, it causes a
vocabulary explosion in a morphologically rich language. Therefore, we propose
a new method called subword-based neural text augmentation, where we retokenize
the generated text into statistically derived subwords. We compare Morfessor
and BPE statistical subword tokenizers and show that both methods can
significantly improve the WER while greatly reducing vocabulary size and memory
requirements. Finally, we also demonstrate that subword-based neural text
augmentation outperforms the word-based approach not only in terms of overall
WER but also in recognition of OOV words.
</p>
<a href="http://arxiv.org/abs/2007.06949" target="_blank">arXiv:2007.06949</a> [<a href="http://arxiv.org/pdf/2007.06949" target="_blank">pdf</a>]

<h2>Verbal Focus-of-Attention System for Learning-from-Observation. (arXiv:2007.08705v3 [cs.RO] UPDATED)</h2>
<h3>Naoki Wake, Iori Yanokura, Kazuhiro Sasabuchi, Katsushi Ikeuchi</h3>
<p>The learning-from-observation (LfO) framework aims to map human
demonstrations to a robot to reduce programming effort. To this end, an LfO
system encodes a human demonstration into a series of execution units for a
robot, which are referred to as task models. Although previous research has
proposed successful task-model encoders, there has been little discussion on
how to guide a task-model encoder in a scene with spatio-temporal noises, such
as cluttered objects or unrelated human body movements. Inspired by the
function of verbal instructions guiding an observer's visual attention, we
propose a verbal focus-of-attention (FoA) system (i.e., spatio-temporal
filters) to guide a task-model encoder. For object manipulation, the system
first recognizes the name of a target object and its attributes from verbal
instructions. The information serves as a where-to-look FoA filter to confine
the areas in which the target object existed in the demonstration. The system
then detects the timing of grasp and release that occurs in the filtered area.
The timings serve as a when-to-look FoA filter to confine the period of object
manipulation. Finally, a task-model encoder recognizes the task models by
employing FoA filters. We demonstrate the robustness of the verbal FoA in
attenuating spatio-temporal noises by comparing it with an existing action
localization network. The contributions of this study are as follows: (1) to
propose a verbal FoA for LfO, (2) to design an algorithm to calculate FoA
filters from verbal input, and (3) to demonstrate the effectiveness of a verbal
FoA in localizing an action by comparing it with a state-of-the-art vision
system.
</p>
<a href="http://arxiv.org/abs/2007.08705" target="_blank">arXiv:2007.08705</a> [<a href="http://arxiv.org/pdf/2007.08705" target="_blank">pdf</a>]

<h2>MLJ: A Julia package for composable machine learning. (arXiv:2007.12285v2 [cs.LG] UPDATED)</h2>
<h3>Anthony D. Blaom, Franz Kiraly, Thibaut Lienart, Yiannis Simillides, Diego Arenas, Sebastian J. Vollmer</h3>
<p>MLJ (Machine Learing in Julia) is an open source software package providing a
common interface for interacting with machine learning models written in Julia
and other languages. It provides tools and meta-algorithms for selecting,
tuning, evaluating, composing and comparing those models, with a focus on
flexible model composition. In this design overview we detail chief novelties
of the framework, together with the clear benefits of Julia over the dominant
multi-language alternatives.
</p>
<a href="http://arxiv.org/abs/2007.12285" target="_blank">arXiv:2007.12285</a> [<a href="http://arxiv.org/pdf/2007.12285" target="_blank">pdf</a>]

<h2>Munchausen Reinforcement Learning. (arXiv:2007.14430v3 [cs.LG] UPDATED)</h2>
<h3>Nino Vieillard, Olivier Pietquin, Matthieu Geist</h3>
<p>Bootstrapping is a core mechanism in Reinforcement Learning (RL). Most
algorithms, based on temporal differences, replace the true value of a
transiting state by their current estimate of this value. Yet, another estimate
could be leveraged to bootstrap RL: the current policy. Our core contribution
stands in a very simple idea: adding the scaled log-policy to the immediate
reward. We show that slightly modifying Deep Q-Network (DQN) in that way
provides an agent that is competitive with distributional methods on Atari
games, without making use of distributional RL, n-step returns or prioritized
replay. To demonstrate the versatility of this idea, we also use it together
with an Implicit Quantile Network (IQN). The resulting agent outperforms
Rainbow on Atari, installing a new State of the Art with very little
modifications to the original algorithm. To add to this empirical study, we
provide strong theoretical insights on what happens under the hood -- implicit
Kullback-Leibler regularization and increase of the action-gap.
</p>
<a href="http://arxiv.org/abs/2007.14430" target="_blank">arXiv:2007.14430</a> [<a href="http://arxiv.org/pdf/2007.14430" target="_blank">pdf</a>]

<h2>Depressive, Drug Abusive, or Informative: Knowledge-aware Study of News Exposure during COVID-19 Outbreak. (arXiv:2007.15209v3 [cs.SI] UPDATED)</h2>
<h3>Amanuel Alambo, Manas Gaur, Krishnaprasad Thirunarayan</h3>
<p>The COVID-19 pandemic is having a serious adverse impact on the lives of
people across the world. COVID-19 has exacerbated community-wide depression,
and has led to increased drug abuse brought about by isolation of individuals
as a result of lockdown. Further, apart from providing informative content to
the public, the incessant media coverage of COVID-19 crisis in terms of news
broadcasts, published articles and sharing of information on social media have
had the undesired snowballing effect on stress levels (further elevating
depression and drug use) due to uncertain future. In this position paper, we
propose a novel framework for assessing the spatio-temporal-thematic
progression of depression, drug abuse, and informativeness of the underlying
news content across the different states in the United States. Our framework
employs an attention-based transfer learning technique to apply knowledge
learned on a social media domain to a target domain of media exposure. To
extract news articles that are related to COVID-19 communications from the
streaming news content on the web, we use neural semantic parsing, and
background knowledge bases in a sequence of steps called semantic filtering. We
achieve promising preliminary results on three variations of Bidirectional
Encoder Representations from Transformers (BERT) model. We compare our findings
against a report from Mental Health America and the results show that our
fine-tuned BERT models perform better than vanilla BERT. Our study can benefit
epidemiologists by offering actionable insights on COVID-19 and its regional
impact. Further, our solution can be integrated into end-user applications to
tailor news for users based on their emotional tone measured on the scale of
depressiveness, drug abusiveness, and informativeness.
</p>
<a href="http://arxiv.org/abs/2007.15209" target="_blank">arXiv:2007.15209</a> [<a href="http://arxiv.org/pdf/2007.15209" target="_blank">pdf</a>]

<h2>An artificial intelligence system for predicting the deterioration of COVID-19 patients in the emergency department. (arXiv:2008.01774v2 [cs.LG] UPDATED)</h2>
<h3>Farah E. Shamout, Yiqiu Shen, Nan Wu, Aakash Kaku, Jungkyu Park, Taro Makino, Stanis&#x142;aw Jastrz&#x119;bski, Duo Wang, Ben Zhang, Siddhant Dogra, Meng Cao, Narges Razavian, David Kudlowitz, Lea Azour, William Moore, Yvonne W. Lui, Yindalon Aphinyanaphongs, Carlos Fernandez-Granda, Krzysztof J. Geras</h3>
<p>During the coronavirus disease 2019 (COVID-19) pandemic, rapid and accurate
triage of patients at the emergency department is critical to inform
decision-making. We propose a data-driven approach for automatic prediction of
deterioration risk using a deep neural network that learns from chest X-ray
images and a gradient boosting model that learns from routine clinical
variables. Our AI prognosis system, trained using data from 3,661 patients,
achieves an area under the receiver operating characteristic curve (AUC) of
0.786 (95% CI: 0.745-0.830) when predicting deterioration within 96 hours. The
deep neural network extracts informative areas of chest X-ray images to assist
clinicians in interpreting the predictions and performs comparably to two
radiologists in a reader study. In order to verify performance in a real
clinical setting, we silently deployed a preliminary version of the deep neural
network at New York University Langone Health during the first wave of the
pandemic, which produced accurate predictions in real-time. In summary, our
findings demonstrate the potential of the proposed system for assisting
front-line physicians in the triage of COVID-19 patients.
</p>
<a href="http://arxiv.org/abs/2008.01774" target="_blank">arXiv:2008.01774</a> [<a href="http://arxiv.org/pdf/2008.01774" target="_blank">pdf</a>]

<h2>The Emergence of Adversarial Communication in Multi-Agent Reinforcement Learning. (arXiv:2008.02616v2 [cs.RO] UPDATED)</h2>
<h3>Jan Blumenkamp, Amanda Prorok</h3>
<p>Many real-world problems require the coordination of multiple autonomous
agents. Recent work has shown the promise of Graph Neural Networks (GNNs) to
learn explicit communication strategies that enable complex multi-agent
coordination. These works use models of cooperative multi-agent systems whereby
agents strive to achieve a shared global goal. When considering agents with
self-interested local objectives, the standard design choice is to model these
as separate learning systems (albeit sharing the same environment). Such a
design choice, however, precludes the existence of a single, differentiable
communication channel, and consequently prohibits the learning of inter-agent
communication strategies. In this work, we address this gap by presenting a
learning model that accommodates individual non-shared rewards and a
differentiable communication channel that is common among all agents. We focus
on the case where agents have self-interested objectives, and develop a
learning algorithm that elicits the emergence of adversarial communications. We
perform experiments on multi-agent coverage and path planning problems, and
employ a post-hoc interpretability technique to visualize the messages that
agents communicate to each other. We show how a single self-interested agent is
capable of learning highly manipulative communication strategies that allows it
to significantly outperform a cooperative team of agents.
</p>
<a href="http://arxiv.org/abs/2008.02616" target="_blank">arXiv:2008.02616</a> [<a href="http://arxiv.org/pdf/2008.02616" target="_blank">pdf</a>]

<h2>A Differentially Private Framework in Spatial Crowdsourcing with Historical Data Learning. (arXiv:2008.03475v2 [cs.CR] UPDATED)</h2>
<h3>Shun Zhang, Benfei Duan, Zhili Chen, Hong Zhong, Qizhi Yu</h3>
<p>Spatial crowdsourcing (SC) is an increasing popular category of crowdsourcing
in the era of mobile Internet and sharing economy. It requires workers to
arrive at a particular location for task fulfillment. Effective protection of
location privacy is essential for workers' enthusiasm and valid task
assignment. However, existing SC models with differential privacy usually
perturb real-time location data for both partition and data publication. Such a
way may produce large perturbations to counting queries that affect assignment
success rate and allocation accuracy. This paper proposes a framework (R-HT)
for protecting location privacy of workers taking advantage of both real-time
and historical data. We simulate locations by sampling the probability
distribution learned from historical data, use them for grid partition, and
then publish real-time data under this partitioning with differential privacy.
This realizes that most privacy budget is allocated to the worker count of each
cell and yields an improved Private Spatial Decomposition approach. Moreover,
we introduce some strategies for geocast region construction, including quality
scoring function and local maximum geocast radius. A series of experimental
results on real-world datasets shows that R-HT attains a stable success rate of
task assignment, saves performance overhead and fits for dynamic assignment on
crowdsourcing platforms.
</p>
<a href="http://arxiv.org/abs/2008.03475" target="_blank">arXiv:2008.03475</a> [<a href="http://arxiv.org/pdf/2008.03475" target="_blank">pdf</a>]

<h2>Pose2Mesh: Graph Convolutional Network for 3D Human Pose and Mesh Recovery from a 2D Human Pose. (arXiv:2008.09047v2 [cs.CV] UPDATED)</h2>
<h3>Hongsuk Choi, Gyeongsik Moon, Kyoung Mu Lee</h3>
<p>Most of the recent deep learning-based 3D human pose and mesh estimation
methods regress the pose and shape parameters of human mesh models, such as
SMPL and MANO, from an input image. The first weakness of these methods is an
appearance domain gap problem, due to different image appearance between train
data from controlled environments, such as a laboratory, and test data from
in-the-wild environments. The second weakness is that the estimation of the
pose parameters is quite challenging owing to the representation issues of 3D
rotations. To overcome the above weaknesses, we propose Pose2Mesh, a novel
graph convolutional neural network (GraphCNN)-based system that estimates the
3D coordinates of human mesh vertices directly from the 2D human pose. The 2D
human pose as input provides essential human body articulation information,
while having a relatively homogeneous geometric property between the two
domains. Also, the proposed system avoids the representation issues, while
fully exploiting the mesh topology using a GraphCNN in a coarse-to-fine manner.
We show that our Pose2Mesh outperforms the previous 3D human pose and mesh
estimation methods on various benchmark datasets. The codes are publicly
available https://github.com/hongsukchoi/Pose2Mesh_RELEASE.
</p>
<a href="http://arxiv.org/abs/2008.09047" target="_blank">arXiv:2008.09047</a> [<a href="http://arxiv.org/pdf/2008.09047" target="_blank">pdf</a>]

<h2>SSGP: Sparse Spatial Guided Propagation for Robust and Generic Interpolation. (arXiv:2008.09346v2 [cs.CV] UPDATED)</h2>
<h3>Ren&#xe9; Schuster, Oliver Wasenm&#xfc;ller, Christian Unger, Didier Stricker</h3>
<p>Interpolation of sparse pixel information towards a dense target resolution
finds its application across multiple disciplines in computer vision.
State-of-the-art interpolation of motion fields applies model-based
interpolation that makes use of edge information extracted from the target
image. For depth completion, data-driven learning approaches are widespread.
Our work is inspired by latest trends in depth completion that tackle the
problem of dense guidance for sparse information. We extend these ideas and
create a generic cross-domain architecture that can be applied for a multitude
of interpolation problems like optical flow, scene flow, or depth completion.
In our experiments, we show that our proposed concept of Sparse Spatial Guided
Propagation (SSGP) achieves improvements to robustness, accuracy, or speed
compared to specialized algorithms.
</p>
<a href="http://arxiv.org/abs/2008.09346" target="_blank">arXiv:2008.09346</a> [<a href="http://arxiv.org/pdf/2008.09346" target="_blank">pdf</a>]

<h2>Improved anomaly detection by training an autoencoder with skip connections on images corrupted with Stain-shaped noise. (arXiv:2008.12977v2 [eess.IV] UPDATED)</h2>
<h3>Anne-Sophie Collin, Christophe De Vleeschouwer</h3>
<p>In industrial vision, the anomaly detection problem can be addressed with an
autoencoder trained to map an arbitrary image, i.e. with or without any defect,
to a clean image, i.e. without any defect. In this approach, anomaly detection
relies conventionally on the reconstruction residual or, alternatively, on the
reconstruction uncertainty. To improve the sharpness of the reconstruction, we
consider an autoencoder architecture with skip connections. In the common
scenario where only clean images are available for training, we propose to
corrupt them with a synthetic noise model to prevent the convergence of the
network towards the identity mapping, and introduce an original Stain noise
model for that purpose. We show that this model favors the reconstruction of
clean images from arbitrary real-world images, regardless of the actual defects
appearance. In addition to demonstrating the relevance of our approach, our
validation provides the first consistent assessment of reconstruction-based
methods, by comparing their performance over the MVTec AD dataset, both for
pixel- and image-wise anomaly detection.
</p>
<a href="http://arxiv.org/abs/2008.12977" target="_blank">arXiv:2008.12977</a> [<a href="http://arxiv.org/pdf/2008.12977" target="_blank">pdf</a>]

<h2>The Dark (and Bright) Side of IoT: Attacks and Countermeasures for Identifying Smart Home Devices and Services. (arXiv:2009.07672v3 [cs.CR] UPDATED)</h2>
<h3>Ahmed Mohamed Hussain, Gabriele Oligeri, Thiemo Voigt</h3>
<p>We present a new machine learning-based attack that exploits network patterns
to detect the presence of smart IoT devices and running services in the WiFi
radio spectrum. We perform an extensive measurement campaign of data
collection, and we build up a model describing the traffic patterns
characterizing three popular IoT smart home devices, i.e., Google Nest Mini,
Amazon Echo, and Amazon Echo Dot. We prove that it is possible to detect and
identify with overwhelming probability their presence and the services running
by the aforementioned devices in a crowded WiFi scenario. This work proves that
standard encryption techniques alone are not sufficient to protect the privacy
of the end-user, since the network traffic itself exposes the presence of both
the device and the associated service. While more work is required to prevent
non-trusted third parties to detect and identify the user's devices, we
introduce Eclipse, a technique to mitigate these types of attacks, which
reshapes the traffic making the identification of the devices and the
associated services similar to the random classification baseline.
</p>
<a href="http://arxiv.org/abs/2009.07672" target="_blank">arXiv:2009.07672</a> [<a href="http://arxiv.org/pdf/2009.07672" target="_blank">pdf</a>]

<h2>A Principle of Least Action for the Training of Neural Networks. (arXiv:2009.08372v3 [stat.ML] UPDATED)</h2>
<h3>Skander Karkar, Ibrahim Ayed, Emmanuel de B&#xe9;zenac, Patrick Gallinari</h3>
<p>Neural networks have been achieving high generalization performance on many
tasks despite being highly over-parameterized. Since classical statistical
learning theory struggles to explain this behavior, much effort has recently
been focused on uncovering the mechanisms behind it, in the hope of developing
a more adequate theoretical framework and having a better control over the
trained models. In this work, we adopt an alternate perspective, viewing the
neural network as a dynamical system displacing input particles over time. We
conduct a series of experiments and, by analyzing the network's behavior
through its displacements, we show the presence of a low kinetic energy
displacement bias in the transport map of the network, and link this bias with
generalization performance. From this observation, we reformulate the learning
problem as follows: finding neural networks which solve the task while
transporting the data as efficiently as possible. This offers a novel
formulation of the learning problem which allows us to provide regularity
results for the solution network, based on Optimal Transport theory. From a
practical viewpoint, this allows us to propose a new learning algorithm, which
automatically adapts to the complexity of the given task, and leads to networks
with a high generalization ability even in low data regimes.
</p>
<a href="http://arxiv.org/abs/2009.08372" target="_blank">arXiv:2009.08372</a> [<a href="http://arxiv.org/pdf/2009.08372" target="_blank">pdf</a>]

<h2>The Ultimate DataFlow for Ultimate SuperComputers-on-a-Chips. (arXiv:2009.10593v3 [cs.DC] UPDATED)</h2>
<h3>Veljko Milutinovic, Milos Kotlar, Ivan Ratkovic, Nenad Korolija, Miljan Djordjevic, Kristy Yoshimot, Mateo Valero</h3>
<p>This article starts from the assumption that near future 100BTransistor
SuperComputers-on-a-Chip will include N big multi-core processors, 1000N small
many-core processors, a TPU-like fixed-structure systolic array accelerator for
the most frequently used Machine Learning algorithms needed in bandwidth-bound
applications and a flexible-structure reprogrammable accelerator for less
frequently used Machine Learning algorithms needed in latency-critical
applications.
</p>
<a href="http://arxiv.org/abs/2009.10593" target="_blank">arXiv:2009.10593</a> [<a href="http://arxiv.org/pdf/2009.10593" target="_blank">pdf</a>]

<h2>Automatic identification of fossils and abiotic grains during carbonate microfacies analysis using deep convolutional neural networks. (arXiv:2009.11429v2 [cs.CV] UPDATED)</h2>
<h3>Xiaokang Liu, Haijun Song</h3>
<p>Petrographic analysis based on microfacies identification in thin sections is
widely used in sedimentary environment interpretation and paleoecological
reconstruction. Fossil recognition from microfacies is an essential procedure
for petrographers to complete this task. Distinguishing the morphological and
microstructural diversity of skeletal fragments requires extensive prior
knowledge of fossil morphotypes in microfacies and long training sessions under
the microscope. This requirement engenders certain challenges for
sedimentologists and paleontologists, especially novices. However, a machine
classifier can help address this challenge. In this study, we collected a
microfacies image dataset comprising both public data from 1,149 references and
our own materials (including 30,815 images of 22 fossil and abiotic grain
groups). We employed a high-performance workstation to implement four classic
deep convolutional neural networks (DCNNs), which have proven to be highly
efficient in computer vision over the last several years. Our framework uses a
transfer learning technique, which reuses the pre-trained parameters that are
trained on a larger ImageNet dataset as initialization for the network to
achieve high accuracy with low computing costs. We obtained up to 95% of the
top one and 99% of the top three test accuracies in the Inception ResNet v2
architecture. The machine classifier exhibited 0.99 precision on minerals, such
as dolomite and pyrite. Although it had some difficulty on samples having
similar morphologies, such as the bivalve, brachiopod, and ostracod, it
nevertheless obtained 0.88 precision. Our machine learning framework
demonstrated high accuracy with reproducibility and bias avoidance that was
comparable to those of human classifiers. Its application can thus eliminate
much of the tedious, manually intensive efforts by human experts conducting
routine identification.
</p>
<a href="http://arxiv.org/abs/2009.11429" target="_blank">arXiv:2009.11429</a> [<a href="http://arxiv.org/pdf/2009.11429" target="_blank">pdf</a>]

<h2>Projection Mapping Implementation: Enabling Direct Externalization of Perception Results and Action Intent to Improve Robot Explainability. (arXiv:2010.02263v3 [cs.RO] UPDATED)</h2>
<h3>Zhao Han, Alexander Wilkinson, Jenna Parrillo, Jordan Allspaw, Holly A. Yanco</h3>
<p>Existing research on non-verbal cues, e.g., eye gaze or arm movement, may not
accurately present a robot's internal states such as perception results and
action intent. Projecting the states directly onto a robot's operating
environment has the advantages of being direct, accurate, and more salient,
eliminating mental inference about the robot's intention. However, there is a
lack of tools for projection mapping in robotics, compared to established
motion planning libraries (e.g., MoveIt). In this paper, we detail the
implementation of projection mapping to enable researchers and practitioners to
push the boundaries for better interaction between robots and humans. We also
provide practical documentation and code for a sample manipulation projection
mapping on GitHub: https://github.com/uml-robotics/projection_mapping.
</p>
<a href="http://arxiv.org/abs/2010.02263" target="_blank">arXiv:2010.02263</a> [<a href="http://arxiv.org/pdf/2010.02263" target="_blank">pdf</a>]

<h2>Collaborative Training of GANs in Continuous and Discrete Spaces for Text Generation. (arXiv:2010.08213v2 [cs.CL] UPDATED)</h2>
<h3>Yanghoon Kim, Seungpil Won, Seunghyun Yoon, Kyomin Jung</h3>
<p>Applying generative adversarial networks (GANs) to text-related tasks is
challenging due to the discrete nature of language. One line of research
resolves this issue by employing reinforcement learning (RL) and optimizing the
next-word sampling policy directly in a discrete action space. Such methods
compute the rewards from complete sentences and avoid error accumulation due to
exposure bias. Other approaches employ approximation techniques that map the
text to continuous representation in order to circumvent the non-differentiable
discrete process. Particularly, autoencoder-based methods effectively produce
robust representations that can model complex discrete structures. In this
paper, we propose a novel text GAN architecture that promotes the collaborative
training of the continuous-space and discrete-space methods. Our method employs
an autoencoder to learn an implicit data manifold, providing a learning
objective for adversarial training in a continuous space. Furthermore, the
complete textual output is directly evaluated and updated via RL in a discrete
space. The collaborative interplay between the two adversarial trainings
effectively regularize the text representations in different spaces. The
experimental results on three standard benchmark datasets show that our model
substantially outperforms state-of-the-art text GANs with respect to quality,
diversity, and global consistency.
</p>
<a href="http://arxiv.org/abs/2010.08213" target="_blank">arXiv:2010.08213</a> [<a href="http://arxiv.org/pdf/2010.08213" target="_blank">pdf</a>]

<h2>Where Is the Normative Proof? Assumptions and Contradictions in ML Fairness Research. (arXiv:2010.10407v3 [cs.CY] UPDATED)</h2>
<h3>A. Feder Cooper</h3>
<p>Across machine learning (ML) sub-disciplines researchers make mathematical
assumptions to facilitate proof-writing. While such assumptions are necessary
for providing mathematical guarantees for how algorithms behave, they also
necessarily limit the applicability of these algorithms to different problem
settings. This practice is known--in fact, obvious--and accepted in ML
research. However, similar attention is not paid to the normative assumptions
that ground this work. I argue such assumptions are equally as important,
especially in areas of ML with clear social impact, such as fairness. This is
because, similar to how mathematical assumptions constrain applicability,
normative assumptions also limit algorithm applicability to certain problem
domains. I show that, in existing papers published in top venues, once
normative assumptions are clarified, it is often possible to get unclear or
contradictory results. While the mathematical assumptions and results are
sound, the implicit normative assumptions and accompanying normative results
contraindicate using these methods in practical fairness applications.
</p>
<a href="http://arxiv.org/abs/2010.10407" target="_blank">arXiv:2010.10407</a> [<a href="http://arxiv.org/pdf/2010.10407" target="_blank">pdf</a>]

<h2>Defense-guided Transferable Adversarial Attacks. (arXiv:2010.11535v2 [cs.LG] UPDATED)</h2>
<h3>Zifei Zhang, Kai Qiao, Jian Chen, Ningning Liang</h3>
<p>Though deep neural networks perform challenging tasks excellently, they are
susceptible to adversarial examples, which mislead classifiers by applying
human-imperceptible perturbations on clean inputs. Under the query-free
black-box scenario, adversarial examples are hard to transfer to unknown
models, and several methods have been proposed with the low transferability. To
settle such issue, we design a max-min framework inspired by input
transformations, which are benificial to both the adversarial attack and
defense. Explicitly, we decrease loss values with inputs' affline
transformations as a defense in the minimum procedure, and then increase loss
values with the momentum iterative algorithm as an attack in the maximum
procedure. To further promote transferability, we determine transformed values
with the max-min theory. Extensive experiments on Imagenet demonstrate that our
defense-guided transferable attacks achieve impressive increase on
transferability. Experimentally, we show that our ASR of adversarial attack
reaches to 58.38% on average, which outperforms the state-of-the-art method by
12.1% on the normally trained models and by 11.13% on the adversarially trained
models. Additionally, we provide elucidative insights on the improvement of
transferability, and our method is expected to be a benchmark for assessing the
robustness of deep models.
</p>
<a href="http://arxiv.org/abs/2010.11535" target="_blank">arXiv:2010.11535</a> [<a href="http://arxiv.org/pdf/2010.11535" target="_blank">pdf</a>]

<h2>Global Image Segmentation Process using Machine Learning algorithm & Convolution Neural Network method for Self- Driving Vehicles. (arXiv:2010.13294v2 [cs.CV] UPDATED)</h2>
<h3>Tirumalapudi Raviteja, Rajay Vedaraj .I.S</h3>
<p>In autonomous Vehicles technology Image segmentation was a major problem in
visual perception. This image segmentation process is mainly used in medical
applications. Here we adopted an image segmentation process to visual
perception tasks for predicting the agents on the surrounding environment,
identifying the road boundaries and tracking the line markings. Main objective
of the paper is to divide the input images using the image segmentation process
and Convolution Neural Network method for efficient results of visual
perception. For Sampling assume a local city data-set samples and validation
process done in Jupyter Notebook using Python language. We proposed this image
segmentation method planning to standard and further the development of
state-of-the art methods for visual inspection system understanding. The
experimental results achieves 73% mean IOU. Our method also achieves 90 FPS
inference speed and using a NVDIA GeForce GTX 1050 GPU.
</p>
<a href="http://arxiv.org/abs/2010.13294" target="_blank">arXiv:2010.13294</a> [<a href="http://arxiv.org/pdf/2010.13294" target="_blank">pdf</a>]

<h2>$\mu$NAS: Constrained Neural Architecture Search for Microcontrollers. (arXiv:2010.14246v2 [cs.LG] UPDATED)</h2>
<h3>Edgar Liberis, &#x141;ukasz Dudziak, Nicholas D. Lane</h3>
<p>IoT devices are powered by microcontroller units (MCUs) which are extremely
resource-scarce: a typical MCU may have an underpowered processor and around 64
KB of memory and persistent storage, which is orders of magnitude fewer
computational resources than is typically required for deep learning. Designing
neural networks for such a platform requires an intricate balance between
keeping high predictive performance (accuracy) while achieving low memory and
storage usage and inference latency. This is extremely challenging to achieve
manually, so in this work, we build a neural architecture search (NAS) system,
called $\mu$NAS, to automate the design of such small-yet-powerful MCU-level
networks. $\mu$NAS explicitly targets the three primary aspects of resource
scarcity of MCUs: the size of RAM, persistent storage and processor speed.
$\mu$NAS represents a significant advance in resource-efficient models,
especially for "mid-tier" MCUs with memory requirements ranging from 0.5 KB to
64 KB. We show that on a variety of image classification datasets $\mu$NAS is
able to (a) improve top-1 classification accuracy by up to 4.8%, or (b) reduce
memory footprint by 4--13x, or (c) reduce the number of multiply-accumulate
operations by $\approx$900x, compared to existing MCU specialist literature and
resource-efficient models.
</p>
<a href="http://arxiv.org/abs/2010.14246" target="_blank">arXiv:2010.14246</a> [<a href="http://arxiv.org/pdf/2010.14246" target="_blank">pdf</a>]

<h2>Generalized Nonlinear and Finsler Geometry for Robotics. (arXiv:2010.14745v2 [cs.RO] UPDATED)</h2>
<h3>Nathan D. Ratliff, Karl Van Wyk, Mandy Xie, Anqi Li, Asif Muhammad Rana</h3>
<p>Robotics research has found numerous important applications of Riemannian
geometry. Despite that, the concept remain challenging to many roboticists
because the background material is complex and strikingly foreign. Beyond
Riemannian geometry, there are many natural generalizations in the mathematical
literature---areas such as Finsler geometry and spray geometry---but those
generalizations are largely inaccessible, and as a result there remain few
applications within robotics. This paper presents a re-derivation of spray and
Finsler geometries, critical for the development of our recent work on
geometric fabrics, which builds the ideas from familiar concepts in advanced
calculus and the calculus of variations. We focus on the pragmatic and
calculable results, avoiding the use of tensor notation to appeal to a broader
audience and emphasizing geometric path consistency over ideas around
connections and curvature. It is our hope that they will contribute to an
increased understanding generalized nonlinear, and even classical Riemannian,
geometry within the robotics community and inspire future research into new
applications.
</p>
<a href="http://arxiv.org/abs/2010.14745" target="_blank">arXiv:2010.14745</a> [<a href="http://arxiv.org/pdf/2010.14745" target="_blank">pdf</a>]

<h2>AudVowelConsNet: A Phoneme-Level Based Deep CNN Architecture for Clinical Depression Diagnosis. (arXiv:2010.16201v2 [cs.SD] UPDATED)</h2>
<h3>Muhammad Muzammel, Hanan Salam, Yann Hoffmann, Mohamed Chetouani, Alice Othmani</h3>
<p>Depression is a common and serious mood disorder that negatively affects the
patient's capacity of functioning normally in daily tasks. Speech is proven to
be a vigorous tool in depression diagnosis. Research in psychiatry concentrated
on performing fine-grained analysis on word-level speech components
contributing to the manifestation of depression in speech and revealed
significant variations at the phoneme-level in depressed speech. On the other
hand, research in Machine Learning-based automatic recognition of depression
from speech focused on the exploration of various acoustic features for the
detection of depression and its severity level. Few have focused on
incorporating phoneme-level speech components in automatic assessment systems.
In this paper, we propose an Artificial Intelligence (AI) based application for
clinical depression recognition and assessment from speech. We investigate the
acoustic characteristics of phoneme units, specifically vowels and consonants
for depression recognition via Deep Learning. We present and compare three
spectrogram-based Deep Neural Network architectures, trained on phoneme
consonant and vowel units and their fusion respectively. Our experiments show
that the deep learned consonant-based acoustic characteristics lead to better
recognition results than vowel-based ones. The fusion of vowel and consonant
speech characteristics through a deep network significantly outperforms the
single space networks as well as the state-of-art deep learning approaches on
the DAIC-WOZ database.
</p>
<a href="http://arxiv.org/abs/2010.16201" target="_blank">arXiv:2010.16201</a> [<a href="http://arxiv.org/pdf/2010.16201" target="_blank">pdf</a>]

<h2>Capture the Bot: Using Adversarial Examples to Improve CAPTCHA Robustness to Bot Attacks. (arXiv:2010.16204v2 [cs.CR] UPDATED)</h2>
<h3>Dorjan Hitaj, Briland Hitaj, Sushil Jajodia, Luigi V. Mancini</h3>
<p>To this date, CAPTCHAs have served as the first line of defense preventing
unauthorized access by (malicious) bots to web-based services, while at the
same time maintaining a trouble-free experience for human visitors. However,
recent work in the literature has provided evidence of sophisticated bots that
make use of advancements in machine learning (ML) to easily bypass existing
CAPTCHA-based defenses. In this work, we take the first step to address this
problem. We introduce CAPTURE, a novel CAPTCHA scheme based on adversarial
examples. While typically adversarial examples are used to lead an ML model
astray, with CAPTURE, we attempt to make a "good use" of such mechanisms. Our
empirical evaluations show that CAPTURE can produce CAPTCHAs that are easy to
solve by humans while at the same time, effectively thwarting ML-based bot
solvers.
</p>
<a href="http://arxiv.org/abs/2010.16204" target="_blank">arXiv:2010.16204</a> [<a href="http://arxiv.org/pdf/2010.16204" target="_blank">pdf</a>]

<h2>Identifying Exoplanets with Deep Learning. IV. Removing Stellar Activity Signals from Radial Velocity Measurements Using Neural Networks. (arXiv:2011.00003v2 [astro-ph.EP] UPDATED)</h2>
<h3>Zoe L. de Beurs, Andrew Vanderburg, Christopher J. Shallue, Xavier Dumusque, Andrew Collier Cameron, Lars A. Buchhave, Rosario Cosentino, Adriano Ghedina, Rapha&#xeb;lle D. Haywood, Nicholas Langellier, David W. Latham, Mercedes L&#xf3;pez-Morales, Michel Mayor, Giusi Micela, Timothy W. Milbourne, Annelies Mortier, Emilio Molinari, Francesco Pepe, David F. Phillips, Matteo Pinamonti, Giampaolo Piotto, Ken Rice, Dimitar Sasselov, Alessandro Sozzetti, St&#xe9;phane Udry, Christopher A. Watson</h3>
<p>Exoplanet detection with precise radial velocity (RV) observations is
currently limited by spurious RV signals introduced by stellar activity. We
show that machine learning techniques such as linear regression and neural
networks can effectively remove the activity signals (due to starspots/faculae)
from RV observations. Previous efforts focused on carefully filtering out
activity signals in time using modeling techniques like Gaussian Process
regression (e.g. Haywood et al. 2014). Instead, we systematically remove
activity signals using only changes to the average shape of spectral lines, and
no information about when the observations were collected. We trained our
machine learning models on both simulated data (generated with the SOAP 2.0
software; Dumusque et al. 2014) and observations of the Sun from the HARPS-N
Solar Telescope (Dumusque et al. 2015; Phillips et al. 2016; Collier Cameron et
al. 2019). We find that these techniques can predict and remove stellar
activity from both simulated data (improving RV scatter from 82 cm/s to 3 cm/s)
and from more than 600 real observations taken nearly daily over three years
with the HARPS-N Solar Telescope (improving the RV scatter from 1.47 m/s to
0.78 m/s, a factor of ~ 1.9 improvement). In the future, these or similar
techniques could remove activity signals from observations of stars outside our
solar system and eventually help detect habitable-zone Earth-mass exoplanets
around Sun-like stars.
</p>
<a href="http://arxiv.org/abs/2011.00003" target="_blank">arXiv:2011.00003</a> [<a href="http://arxiv.org/pdf/2011.00003" target="_blank">pdf</a>]

<h2>A Secure Two-Party Computation Protocol for Intersection Detection between Two Convex Hulls. (arXiv:2011.00319v2 [cs.CG] UPDATED)</h2>
<h3>Amirahmad Chapnevis, Babak Sadeghiyan</h3>
<p>Intersection detection between three-dimensional bodies has various
applications in computer graphics, video game development, robotics as well as
military industries. In some respects, entities do not want to disclose
sensitive information about themselves, including their location. In this
paper, we present a secure two-party protocol to determine the existence of an
intersection between entities. The protocol presented in this paper allows for
intersection detection in three-dimensional spaces in geometry. Our approach is
to use an intersecting plane between two spaces to determine their separation
or intersection. For this purpose, we introduce a computational geometry
protocol to determine the existence of an intersecting plane. In this paper, we
first use the Minkowski difference to reduce the two-space problem into
one-space. Then, the separating set is obtained and the separation of two
shapes is determined based on the inclusion of the center point. We then secure
the protocol by modifying the separating set computation method as a
privacy-preserver and changing the Minkowski difference method to achieve this
goal. The proposed protocol applies to any form of convex three-dimensional
shape. The experiments successfully found a secure protocol for intersection
detection between two convex hulls in geometrical shapes such as the pyramid
and cuboid.
</p>
<a href="http://arxiv.org/abs/2011.00319" target="_blank">arXiv:2011.00319</a> [<a href="http://arxiv.org/pdf/2011.00319" target="_blank">pdf</a>]

<h2>DL-Reg: A Deep Learning Regularization Technique using Linear Regression. (arXiv:2011.00368v2 [cs.LG] UPDATED)</h2>
<h3>Maryam Dialameh, Ali Hamzeh, Hossein Rahmani</h3>
<p>Regularization plays a vital role in the context of deep learning by
preventing deep neural networks from the danger of overfitting. This paper
proposes a novel deep learning regularization method named as DL-Reg, which
carefully reduces the nonlinearity of deep networks to a certain extent by
explicitly enforcing the network to behave as much linear as possible. The key
idea is to add a linear constraint to the objective function of the deep neural
networks, which is simply the error of a linear mapping from the inputs to the
outputs of the model. More precisely, the proposed DL-Reg carefully forces the
network to behave in a linear manner. This linear constraint, which is further
adjusted by a regularization factor, prevents the network from the risk of
overfitting. The performance of DL-Reg is evaluated by training
state-of-the-art deep network models on several benchmark datasets. The
experimental results show that the proposed regularization method: 1) gives
major improvements over the existing regularization techniques, and 2)
significantly improves the performance of deep neural networks, especially in
the case of small-sized training datasets.
</p>
<a href="http://arxiv.org/abs/2011.00368" target="_blank">arXiv:2011.00368</a> [<a href="http://arxiv.org/pdf/2011.00368" target="_blank">pdf</a>]

<h2>Transparent Interpretation with Knockouts. (arXiv:2011.00639v2 [cs.LG] UPDATED)</h2>
<h3>Xing Han</h3>
<p>How can we find a subset of training samples that are most responsible for a
complicated black-box machine learning model prediction? More generally, how
can we explain the model decision to end-users in a transparent way? We propose
a new model-agnostic algorithm to identify a minimum number of training samples
that are indispensable for a given model decision at a particular test point,
as the model decision would otherwise change upon the removal of these training
samples. In line with the counterfactual explanation, our algorithm identifies
such a set of indispensable samples iteratively by solving a constrained
optimization problem. Further, we efficiently speed up the algorithm through
approximation. To demonstrate the effectiveness of the algorithm, we apply it
to a variety of tasks including data poisoning detection, training set
debugging, and understanding loan decisions. Results show that our algorithm is
an effective and easy to comprehend tool to help better understand local model
behaviors and therefore facilitate the application of machine learning in
domains where such understanding is a requisite and where end-users do not have
a machine learning background.
</p>
<a href="http://arxiv.org/abs/2011.00639" target="_blank">arXiv:2011.00639</a> [<a href="http://arxiv.org/pdf/2011.00639" target="_blank">pdf</a>]

<h2>A Variant of the Wang-Foster-Kakade Lower Bound for the Discounted Setting. (arXiv:2011.01075v2 [cs.LG] UPDATED)</h2>
<h3>Philip Amortila, Nan Jiang, Tengyang Xie</h3>
<p>Recently, Wang et al. (2020) showed a highly intriguing hardness result for
batch reinforcement learning (RL) with linearly realizable value function and
good feature coverage in the finite-horizon case. In this note we show that
once adapted to the discounted setting, the construction can be simplified to a
2-state MDP with 1-dimensional features, such that learning is impossible even
with an infinite amount of data.
</p>
<a href="http://arxiv.org/abs/2011.01075" target="_blank">arXiv:2011.01075</a> [<a href="http://arxiv.org/pdf/2011.01075" target="_blank">pdf</a>]

<h2>Estimating County-Level COVID-19 Exponential Growth Rates Using Generalized Random Forests. (arXiv:2011.01219v2 [cs.LG] UPDATED)</h2>
<h3>Zhaowei She, Zilong Wang, Turgay Ayer, Asmae Toumi, Jagpreet Chhatwal</h3>
<p>Rapid and accurate detection of community outbreaks is critical to address
the threat of resurgent waves of COVID-19. A practical challenge in outbreak
detection is balancing accuracy vs. speed. In particular, while accuracy
improves with estimations based on longer fitting windows, speed degrades. This
paper presents a machine learning framework to balance this tradeoff using
generalized random forests (GRF), and applies it to detect county level
COVID-19 outbreaks. This algorithm chooses an adaptive fitting window size for
each county based on relevant features affecting the disease spread, such as
changes in social distancing policies. Experiment results show that our method
outperforms any non-adaptive window size choices in 7-day ahead COVID-19
outbreak case number predictions.
</p>
<a href="http://arxiv.org/abs/2011.01219" target="_blank">arXiv:2011.01219</a> [<a href="http://arxiv.org/pdf/2011.01219" target="_blank">pdf</a>]

<h2>VEGA: Towards an End-to-End Configurable AutoML Pipeline. (arXiv:2011.01507v2 [cs.CV] UPDATED)</h2>
<h3>Bochao Wang, Hang Xu, Jiajin Zhang, Chen Chen, Xiaozhi Fang, Ning Kang, Lanqing Hong, Wei Zhang, Yong Li, Zhicheng Liu, Zhenguo Li, Wenzhi Liu, Tong Zhang</h3>
<p>Automated Machine Learning (AutoML) is an important industrial solution for
automatic discovery and deployment of the machine learning models. However,
designing an integrated AutoML system faces four great challenges of
configurability, scalability, integrability, and platform diversity. In this
work, we present VEGA, an efficient and comprehensive AutoML framework that is
compatible and optimized for multiple hardware platforms. a) The VEGA pipeline
integrates various modules of AutoML, including Neural Architecture Search
(NAS), Hyperparameter Optimization (HPO), Auto Data Augmentation, Model
Compression, and Fully Train. b) To support a variety of search algorithms and
tasks, we design a novel fine-grained search space and its description language
to enable easy adaptation to different search algorithms and tasks. c) We
abstract the common components of deep learning frameworks into a unified
interface. VEGA can be executed with multiple back-ends and hardwares.
Extensive benchmark experiments on multiple tasks demonstrate that VEGA can
improve the existing AutoML algorithms and discover new high-performance models
against SOTA methods, e.g. the searched DNet model zoo for Ascend 10x faster
than EfficientNet-B5 and 9.2x faster than RegNetX-32GF on ImageNet. VEGA is
open-sourced at https://github.com/huawei-noah/vega.
</p>
<a href="http://arxiv.org/abs/2011.01507" target="_blank">arXiv:2011.01507</a> [<a href="http://arxiv.org/pdf/2011.01507" target="_blank">pdf</a>]

<h2>TransQuest: Translation Quality Estimation with Cross-lingual Transformers. (arXiv:2011.01536v2 [cs.CL] UPDATED)</h2>
<h3>Tharindu Ranasinghe, Constantin Orasan, Ruslan Mitkov</h3>
<p>Recent years have seen big advances in the field of sentence-level quality
estimation (QE), largely as a result of using neural-based architectures.
However, the majority of these methods work only on the language pair they are
trained on and need retraining for new language pairs. This process can prove
difficult from a technical point of view and is usually computationally
expensive. In this paper we propose a simple QE framework based on
cross-lingual transformers, and we use it to implement and evaluate two
different neural architectures. Our evaluation shows that the proposed methods
achieve state-of-the-art results outperforming current open-source quality
estimation frameworks when trained on datasets from WMT. In addition, the
framework proves very useful in transfer learning settings, especially when
dealing with low-resourced languages, allowing us to obtain very competitive
results.
</p>
<a href="http://arxiv.org/abs/2011.01536" target="_blank">arXiv:2011.01536</a> [<a href="http://arxiv.org/pdf/2011.01536" target="_blank">pdf</a>]

<h2>Experiencers, Stimuli, or Targets: Which Semantic Roles Enable Machine Learning to Infer the Emotions?. (arXiv:2011.01599v2 [cs.CL] UPDATED)</h2>
<h3>Laura Oberl&#xe4;nder, Kevin Reich, Roman Klinger</h3>
<p>Emotion recognition is predominantly formulated as text classification in
which textual units are assigned to an emotion from a predefined inventory
(e.g., fear, joy, anger, disgust, sadness, surprise, trust, anticipation). More
recently, semantic role labeling approaches have been developed to extract
structures from the text to answer questions like: "who is described to feel
the emotion?" (experiencer), "what causes this emotion?" (stimulus), and at
which entity is it directed?" (target). Though it has been shown that jointly
modeling stimulus and emotion category prediction is beneficial for both
subtasks, it remains unclear which of these semantic roles enables a classifier
to infer the emotion. Is it the experiencer, because the identity of a person
is biased towards a particular emotion (X is always happy)? Is it a particular
target (everybody loves X) or a stimulus (doing X makes everybody sad)? We
answer these questions by training emotion classification models on five
available datasets annotated with at least one semantic role by masking the
fillers of these roles in the text in a controlled manner and find that across
multiple corpora, stimuli and targets carry emotion information, while the
experiencer might be considered a confounder. Further, we analyze if informing
the model about the position of the role improves the classification decision.
Particularly on literature corpora we find that the role information improves
the emotion classification.
</p>
<a href="http://arxiv.org/abs/2011.01599" target="_blank">arXiv:2011.01599</a> [<a href="http://arxiv.org/pdf/2011.01599" target="_blank">pdf</a>]

<h2>A Deep Temporal Fusion Framework for Scene Flow Using a Learnable Motion Model and Occlusions. (arXiv:2011.01603v2 [cs.CV] UPDATED)</h2>
<h3>Ren&#xe9; Schuster, Christian Unger, Didier Stricker</h3>
<p>Motion estimation is one of the core challenges in computer vision. With
traditional dual-frame approaches, occlusions and out-of-view motions are a
limiting factor, especially in the context of environmental perception for
vehicles due to the large (ego-) motion of objects. Our work proposes a novel
data-driven approach for temporal fusion of scene flow estimates in a
multi-frame setup to overcome the issue of occlusion. Contrary to most previous
methods, we do not rely on a constant motion model, but instead learn a generic
temporal relation of motion from data. In a second step, a neural network
combines bi-directional scene flow estimates from a common reference frame,
yielding a refined estimate and a natural byproduct of occlusion masks. This
way, our approach provides a fast multi-frame extension for a variety of scene
flow estimators, which outperforms the underlying dual-frame approaches.
</p>
<a href="http://arxiv.org/abs/2011.01603" target="_blank">arXiv:2011.01603</a> [<a href="http://arxiv.org/pdf/2011.01603" target="_blank">pdf</a>]

<h2>An Efficiency-boosting Client Selection Scheme for Federated Learning with Fairness Guarantee. (arXiv:2011.01783v2 [cs.LG] UPDATED)</h2>
<h3>Tiansheng Huang, Weiwei Lin, Wentai Wu, Ligang He, Keqin Li, Albert Y.Zomaya</h3>
<p>The issue of potential privacy leakage during centralized AI's model training
has drawn intensive concern from the public. A Parallel and Distributed
Computing (or PDC) scheme, termed Federated Learning (FL), has emerged as a new
paradigm to cope with the privacy issue by allowing clients to perform model
training locally, without the necessity to upload their personal sensitive
data. In FL, the number of clients could be sufficiently large, but the
bandwidth available for model distribution and re-upload is quite limited,
making it sensible to only involve part of the volunteers to participate in the
training process. The client selection policy is critical to an FL process in
terms of training efficiency, the final model's quality as well as fairness. In
this paper, we will model the fairness guaranteed client selection as a
Lyapunov optimization problem and then a C2MAB-based method is proposed for
estimation of the model exchange time between each client and the server, based
on which we design a fairness guaranteed algorithm termed RBCS-F for
problem-solving. The regret of RBCS-F is strictly bounded by a finite constant,
justifying its theoretical feasibility. Barring the theoretical results, more
empirical data can be derived from our real training experiments on public
datasets.
</p>
<a href="http://arxiv.org/abs/2011.01783" target="_blank">arXiv:2011.01783</a> [<a href="http://arxiv.org/pdf/2011.01783" target="_blank">pdf</a>]

<h2>Semi-supervised Facial Action Unit Intensity Estimation with Contrastive Learning. (arXiv:2011.01864v2 [cs.CV] UPDATED)</h2>
<h3>Enrique Sanchez, Adrian Bulat, Anestis Zaganidis, Georgios Tzimiropoulos</h3>
<p>This paper tackles the challenging problem of estimating the intensity of
Facial Action Units with few labeled images. Contrary to previous works, our
method does not require to manually select key frames, and produces
state-of-the-art results with as little as $2\%$ of annotated frames, which are
\textit{randomly chosen}. To this end, we propose a semi-supervised learning
approach where a spatio-temporal model combining a feature extractor and a
temporal module are learned in two stages. The first stage uses datasets of
unlabeled videos to learn a strong spatio-temporal representation of facial
behavior dynamics based on contrastive learning. To our knowledge we are the
first to build upon this framework for modeling facial behavior in an
unsupervised manner. The second stage uses another dataset of randomly chosen
labeled frames to train a regressor on top of our spatio-temporal model for
estimating the AU intensity. We show that although backpropagation through time
is applied only with respect to the output of the network for extremely sparse
and randomly chosen labeled frames, our model can be effectively trained to
estimate AU intensity accurately, thanks to the unsupervised pre-training of
the first stage. We experimentally validate that our method outperforms
existing methods when working with as little as $2\%$ of randomly chosen data
for both DISFA and BP4D datasets, without a careful choice of labeled frames, a
time-consuming task still required in previous approaches.
</p>
<a href="http://arxiv.org/abs/2011.01864" target="_blank">arXiv:2011.01864</a> [<a href="http://arxiv.org/pdf/2011.01864" target="_blank">pdf</a>]

<h2>Learning Visual Representations for Transfer Learning by Suppressing Texture. (arXiv:2011.01901v2 [cs.CV] UPDATED)</h2>
<h3>Shlok Mishra, Anshul Shah, Ankan Bansal, Jonghyun Choi, Abhinav Shrivastava, Abhishek Sharma, David Jacobs</h3>
<p>Recent literature has shown that features obtained from supervised training
of CNNs may over-emphasize texture rather than encoding high-level information.
In self-supervised learning in particular, texture as a low-level cue may
provide shortcuts that prevent the network from learning higher level
representations. To address these problems we propose to use classic methods
based on anisotropic diffusion to augment training using images with suppressed
texture. This simple method helps retain important edge information and
suppress texture at the same time. We empirically show that our method achieves
state-of-the-art results on object detection and image classification with
eight diverse datasets in either supervised or self-supervised learning tasks
such as MoCoV2 and Jigsaw. Our method is particularly effective for transfer
learning tasks and we observed improved performance on five standard transfer
learning datasets. The large improvements (up to 11.49\%) on the
Sketch-ImageNet dataset, DTD dataset and additional visual analyses with
saliency maps suggest that our approach helps in learning better
representations that better transfer.
</p>
<a href="http://arxiv.org/abs/2011.01901" target="_blank">arXiv:2011.01901</a> [<a href="http://arxiv.org/pdf/2011.01901" target="_blank">pdf</a>]

<h2>Implementing version control with Git and GitHub as a learning objective in statistics and data science courses. (arXiv:2001.01988v3 [stat.CO] UPDATED)</h2>
<h3>Matthew D. Beckman, Mine &#xc7;etinkaya-Rundel, Nicholas J. Horton, Colin W. Rundel, Adam J. Sullivan, Maria Tackett</h3>
<p>A version control system records changes to a file or set of files over time
so that changes can be tracked and specific versions of a file can be recalled
later. As such, it is an essential element of a reproducible workflow that
deserves due consideration among the learning objectives of statistics and data
science courses. This paper describes experiences and implementation decisions
of four contributing faculty who are teaching different courses at a variety of
institutions. Each of these faculty have set version control as a learning
objective and successfully integrated one such system (Git) into one or more
statistics courses. The various approaches described in the paper span
different implementation strategies to suit student background, course type,
software choices, and assessment practices. By presenting a wide range of
approaches to teaching Git, the paper aims to serve as a resource for
statistics and data science instructors teaching courses at any level within an
undergraduate or graduate curriculum.
</p>
<a href="http://arxiv.org/abs/2001.01988" target="_blank">arXiv:2001.01988</a> [<a href="http://arxiv.org/pdf/2001.01988" target="_blank">pdf</a>]

<h2>Machine learning of solvent effects on molecular spectra and reactions. (arXiv:2010.14942v2 [physics.chem-ph] UPDATED)</h2>
<h3>Michael Gastegger, Kristof T. Sch&#xfc;tt, Klaus-Robert M&#xfc;ller</h3>
<p>Fast and accurate simulation of complex chemical systems in environments such
as solutions is a long standing challenge in theoretical chemistry. In recent
years, machine learning has extended the boundaries of quantum chemistry by
providing highly accurate and efficient surrogate models of electronic
structure theory, which previously have been out of reach for conventional
approaches. Those models have long been restricted to closed molecular systems
without accounting for environmental influences, such as external electric and
magnetic fields or solvent effects. Here, we introduce the deep neural network
FieldSchNet for modeling the interaction of molecules with arbitrary external
fields. FieldSchNet offers access to a wealth of molecular response properties,
enabling it to simulate a wide range of molecular spectra, such as infrared,
Raman and nuclear magnetic resonance. Beyond that, it is able to describe
implicit and explicit molecular environments, operating as a polarizable
continuum model for solvation or in a quantum mechanics / molecular mechanics
setup. We employ FieldSchNet to study the influence of solvent effects on
molecular spectra and a Claisen rearrangement reaction. Based on these results,
we use FieldSchNet to design an external environment capable of lowering the
activation barrier of the rearrangement reaction significantly, demonstrating
promising venues for inverse chemical design.
</p>
<a href="http://arxiv.org/abs/2010.14942" target="_blank">arXiv:2010.14942</a> [<a href="http://arxiv.org/pdf/2010.14942" target="_blank">pdf</a>]

