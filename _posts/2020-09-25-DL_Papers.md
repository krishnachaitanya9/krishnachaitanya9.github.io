---
title: Latest Deep Learning Papers
date: 2021-01-10 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (103 Articles)</h1>
<h2>The Distracting Control Suite -- A Challenging Benchmark for Reinforcement Learning from Pixels. (arXiv:2101.02722v1 [cs.RO])</h2>
<h3>Austin Stone, Oscar Ramirez, Kurt Konolige, Rico Jonschkowski</h3>
<p>Robots have to face challenging perceptual settings, including changes in
viewpoint, lighting, and background. Current simulated reinforcement learning
(RL) benchmarks such as DM Control provide visual input without such
complexity, which limits the transfer of well-performing methods to the real
world. In this paper, we extend DM Control with three kinds of visual
distractions (variations in background, color, and camera pose) to produce a
new challenging benchmark for vision-based control, and we analyze state of the
art RL algorithms in these settings. Our experiments show that current RL
methods for vision-based control perform poorly under distractions, and that
their performance decreases with increasing distraction complexity, showing
that new methods are needed to cope with the visual complexities of the real
world. We also find that combinations of multiple distraction types are more
difficult than a mere combination of their individual effects.
</p>
<a href="http://arxiv.org/abs/2101.02722" target="_blank">arXiv:2101.02722</a> [<a href="http://arxiv.org/pdf/2101.02722" target="_blank">pdf</a>]

<h2>Interpreting Contact Interactions to Overcome Failure in Robot Assembly Tasks. (arXiv:2101.02725v1 [cs.RO])</h2>
<h3>Peter A. Zachares, Michelle A. Lee, Wenzhao Lian, Jeannette Bohg</h3>
<p>A key challenge towards the goal of multi-part assembly tasks is finding
robust sensorimotor control methods in the presence of uncertainty. In contrast
to previous works that rely on a priori knowledge on whether two parts match,
we aim to learn this through physical interaction. We propose a hierachical
approach that enables a robot to autonomously assemble parts while being
uncertain about part types and positions. In particular, our probabilistic
approach learns a set of differentiable filters that leverage the tactile
sensorimotor trace from failed assembly attempts to update its belief about
part position and type. This enables a robot to overcome assembly failure. We
demonstrate the effectiveness of our approach on a set of object fitting tasks.
The experimental results indicate that our proposed approach achieves higher
precision in object position and type estimation, and accomplishes object
fitting tasks faster than baselines.
</p>
<a href="http://arxiv.org/abs/2101.02725" target="_blank">arXiv:2101.02725</a> [<a href="http://arxiv.org/pdf/2101.02725" target="_blank">pdf</a>]

<h2>A Novel Regression Loss for Non-Parametric Uncertainty Optimization. (arXiv:2101.02726v1 [cs.LG])</h2>
<h3>Joachim Sicking, Maram Akila, Maximilian Pintz, Tim Wirtz, Asja Fischer, Stefan Wrobel</h3>
<p>Quantification of uncertainty is one of the most promising approaches to
establish safe machine learning. Despite its importance, it is far from being
generally solved, especially for neural networks. One of the most commonly used
approaches so far is Monte Carlo dropout, which is computationally cheap and
easy to apply in practice. However, it can underestimate the uncertainty. We
propose a new objective, referred to as second-moment loss (SML), to address
this issue. While the full network is encouraged to model the mean, the dropout
networks are explicitly used to optimize the model variance. We intensively
study the performance of the new objective on various UCI regression datasets.
Comparing to the state-of-the-art of deep ensembles, SML leads to comparable
prediction accuracies and uncertainty estimates while only requiring a single
model. Under distribution shift, we observe moderate improvements. As a side
result, we introduce an intuitive Wasserstein distance-based uncertainty
measure that is non-saturating and thus allows to resolve quality differences
between any two uncertainty estimates.
</p>
<a href="http://arxiv.org/abs/2101.02726" target="_blank">arXiv:2101.02726</a> [<a href="http://arxiv.org/pdf/2101.02726" target="_blank">pdf</a>]

<h2>Neural Storage: A New Paradigm of Elastic Memory. (arXiv:2101.02729v1 [cs.AI])</h2>
<h3>Prabuddha Chakraborty, Swarup Bhunia</h3>
<p>Storage and retrieval of data in a computer memory plays a major role in
system performance. Traditionally, computer memory organization is static -
i.e., they do not change based on the application-specific characteristics in
memory access behaviour during system operation. Specifically, the association
of a data block with a search pattern (or cues) as well as the granularity of a
stored data do not evolve. Such a static nature of computer memory, we observe,
not only limits the amount of data we can store in a given physical storage,
but it also misses the opportunity for dramatic performance improvement in
various applications. On the contrary, human memory is characterized by
seemingly infinite plasticity in storing and retrieving data - as well as
dynamically creating/updating the associations between data and corresponding
cues. In this paper, we introduce Neural Storage (NS), a brain-inspired
learning memory paradigm that organizes the memory as a flexible neural memory
network. In NS, the network structure, strength of associations, and
granularity of the data adjust continuously during system operation, providing
unprecedented plasticity and performance benefits. We present the associated
storage/retrieval/retention algorithms in NS, which integrate a formalized
learning process. Using a full-blown operational model, we demonstrate that NS
achieves an order of magnitude improvement in memory access performance for two
representative applications when compared to traditional content-based memory.
</p>
<a href="http://arxiv.org/abs/2101.02729" target="_blank">arXiv:2101.02729</a> [<a href="http://arxiv.org/pdf/2101.02729" target="_blank">pdf</a>]

<h2>Heatmap-based 2D Landmark Detection with a Varying Number of Landmarks. (arXiv:2101.02737v1 [cs.CV])</h2>
<h3>Antonia Stern, Lalith Sharan, Gabriele Romano, Sven Koehler, Matthias Karck, Raffaele De Simone, Ivo Wolf, Sandy Engelhardt</h3>
<p>Mitral valve repair is a surgery to restore the function of the mitral valve.
To achieve this, a prosthetic ring is sewed onto the mitral annulus. Analyzing
the sutures, which are punctured through the annulus for ring implantation, can
be useful in surgical skill assessment, for quantitative surgery and for
positioning a virtual prosthetic ring model in the scene via augmented reality.
This work presents a neural network approach which detects the sutures in
endoscopic images of mitral valve repair and therefore solves a landmark
detection problem with varying amount of landmarks, as opposed to most other
existing deep learning-based landmark detection approaches. The neural network
is trained separately on two data collections from different domains with the
same architecture and hyperparameter settings. The datasets consist of more
than 1,300 stereo frame pairs each, with a total over 60,000 annotated
landmarks. The proposed heatmap-based neural network achieves a mean positive
predictive value (PPV) of 66.68$\pm$4.67% and a mean true positive rate (TPR)
of 24.45$\pm$5.06% on the intraoperative test dataset and a mean PPV of
81.50\pm5.77\% and a mean TPR of 61.60$\pm$6.11% on a dataset recorded during
surgical simulation. The best detection results are achieved when the camera is
positioned above the mitral valve with good illumination. A detection from a
sideward view is also possible if the mitral valve is well perceptible.
</p>
<a href="http://arxiv.org/abs/2101.02737" target="_blank">arXiv:2101.02737</a> [<a href="http://arxiv.org/pdf/2101.02737" target="_blank">pdf</a>]

<h2>Deep Generative Model for Efficient 3D Airfoil Parameterization and Generation. (arXiv:2101.02744v1 [cs.LG])</h2>
<h3>Wei Chen, Arun Ramamurthy</h3>
<p>In aerodynamic shape optimization, the convergence and computational cost are
greatly affected by the representation capacity and compactness of the design
space. Previous research has demonstrated that using a deep generative model to
parameterize two-dimensional (2D) airfoils achieves high representation
capacity/compactness, which significantly benefits shape optimization. In this
paper, we propose a deep generative model, Free-Form Deformation Generative
Adversarial Networks (FFD-GAN), that provides an efficient parameterization for
three-dimensional (3D) aerodynamic/hydrodynamic shapes like aircraft wings,
turbine blades, car bodies, and hulls. The learned model maps a compact set of
design variables to 3D surface points representing the shape. We ensure the
surface smoothness and continuity of generated geometries by incorporating an
FFD layer into the generative model. We demonstrate FFD-GAN's performance using
a wing shape design example. The results show that FFD-GAN can generate
realistic designs and form a reasonable parameterization. We further
demonstrate FFD-GAN's high representation compactness and capacity by testing
its design space coverage, the feasibility ratio of the design space, and its
performance in design optimization. We demonstrate that over 94% feasibility
ratio is achieved among wings randomly generated by the FFD-GAN, while FFD and
B-spline only achieve less than 31%. We also show that the FFD-GAN leads to an
order of magnitude faster convergence in a wing shape optimization problem,
compared to the FFD and the B-spline parameterizations.
</p>
<a href="http://arxiv.org/abs/2101.02744" target="_blank">arXiv:2101.02744</a> [<a href="http://arxiv.org/pdf/2101.02744" target="_blank">pdf</a>]

<h2>Assistive arm and hand manipulation: How does current research intersect with actual healthcare needs?. (arXiv:2101.02750v1 [cs.RO])</h2>
<h3>Laura Petrich, Jun Jin, Masood Dehghan, Martin Jagersand</h3>
<p>Human assistive robotics have the potential to help the elderly and
individuals living with disabilities with their Activities of Daily Living
(ADL). Robotics researchers present bottom up solutions using various control
methods for different types of movements. Health research on the other hand
focuses on clinical assessment and rehabilitation leaving arguably important
differences between the two domains. In particular, little is known
quantitatively on what ADLs humans perform in their everyday environment - at
home, work etc. This information can help guide development and prioritization
of robotic technology for in-home assistive robotic deployment. This study
targets several lifelogging databases, where we compute (i) ADL task frequency
from long-term low sampling frequency video and Internet of Things (IoT) sensor
data, and (ii) short term arm and hand movement data from 30 fps video data of
domestic tasks. Robotics and health care communities have different terms and
taxonomies for representing tasks and motions. We derive and discuss a
robotics-relevant taxonomy from this quantitative ADL task and ICF motion data
in attempt to ameliorate these taxonomic differences. Our statistics quantify
that humans reach, open drawers, doors, and retrieve and use objects hundreds
of times a day. Commercial wheelchair mounted robot arms can help 150,000 upper
body disabled in the USA alone, but only a few hundred robots are deployed.
Better user interfaces, and more capable robots can increase the potential user
base and number of ADL tasks solved significantly.
</p>
<a href="http://arxiv.org/abs/2101.02750" target="_blank">arXiv:2101.02750</a> [<a href="http://arxiv.org/pdf/2101.02750" target="_blank">pdf</a>]

<h2>Transfer Learning Between Different Architectures Via Weights Injection. (arXiv:2101.02757v1 [cs.LG])</h2>
<h3>Maciej A. Czyzewski</h3>
<p>This work presents a naive algorithm for parameter transfer between different
architectures with a computationally cheap injection technique (which does not
require data). The primary objective is to speed up the training of neural
networks from scratch. It was found in this study that transferring knowledge
from any architecture was superior to Kaiming and Xavier for initialization. In
conclusion, the method presented is found to converge faster, which makes it a
drop-in replacement for classical methods. The method involves: 1) matching:
the layers of the pre-trained model with the targeted model; 2) injection: the
tensor is transformed into a desired shape. This work provides a comparison of
similarity between the current SOTA architectures (ImageNet), by utilising TLI
(Transfer Learning by Injection) score.
</p>
<a href="http://arxiv.org/abs/2101.02757" target="_blank">arXiv:2101.02757</a> [<a href="http://arxiv.org/pdf/2101.02757" target="_blank">pdf</a>]

<h2>Active Screening for Recurrent Diseases: A Reinforcement Learning Approach. (arXiv:2101.02766v1 [cs.LG])</h2>
<h3>Han-Ching Ou, Haipeng Chen, Shahin Jabbari, Milind Tambe</h3>
<p>Active screening is a common approach in controlling the spread of recurring
infectious diseases such as tuberculosis and influenza. In this approach,
health workers periodically select a subset of population for screening.
However, given the limited number of health workers, only a small subset of the
population can be visited in any given time period. Given the recurrent nature
of the disease and rapid spreading, the goal is to minimize the number of
infections over a long time horizon. Active screening can be formalized as a
sequential combinatorial optimization over the network of people and their
connections. The main computational challenges in this formalization arise from
i) the combinatorial nature of the problem, ii) the need of sequential planning
and iii) the uncertainties in the infectiousness states of the population.

Previous works on active screening fail to scale to large time horizon while
fully considering the future effect of current interventions. In this paper, we
propose a novel reinforcement learning (RL) approach based on Deep Q-Networks
(DQN), with several innovative adaptations that are designed to address the
above challenges. First, we use graph convolutional networks (GCNs) to
represent the Q-function that exploit the node correlations of the underlying
contact network. Second, to avoid solving a combinatorial optimization problem
in each time period, we decompose the node set selection as a sub-sequence of
decisions, and further design a two-level RL framework that solves the problem
in a hierarchical way. Finally, to speed-up the slow convergence of RL which
arises from reward sparseness, we incorporate ideas from curriculum learning
into our hierarchical RL approach. We evaluate our RL algorithm on several
real-world networks.
</p>
<a href="http://arxiv.org/abs/2101.02766" target="_blank">arXiv:2101.02766</a> [<a href="http://arxiv.org/pdf/2101.02766" target="_blank">pdf</a>]

<h2>Combining pretrained CNN feature extractors to enhance clustering of complex natural images. (arXiv:2101.02767v1 [cs.CV])</h2>
<h3>Joris Guerin, Stephane Thiery, Eric Nyiri, Olivier Gibaru, Byron Boots</h3>
<p>Recently, a common starting point for solving complex unsupervised image
classification tasks is to use generic features, extracted with deep
Convolutional Neural Networks (CNN) pretrained on a large and versatile dataset
(ImageNet). However, in most research, the CNN architecture for feature
extraction is chosen arbitrarily, without justification. This paper aims at
providing insight on the use of pretrained CNN features for image clustering
(IC). First, extensive experiments are conducted and show that, for a given
dataset, the choice of the CNN architecture for feature extraction has a huge
impact on the final clustering. These experiments also demonstrate that proper
extractor selection for a given IC task is difficult. To solve this issue, we
propose to rephrase the IC problem as a multi-view clustering (MVC) problem
that considers features extracted from different architectures as different
"views" of the same data. This approach is based on the assumption that
information contained in the different CNN may be complementary, even when
pretrained on the same data. We then propose a multi-input neural network
architecture that is trained end-to-end to solve the MVC problem effectively.
This approach is tested on nine natural image datasets, and produces
state-of-the-art results for IC.
</p>
<a href="http://arxiv.org/abs/2101.02767" target="_blank">arXiv:2101.02767</a> [<a href="http://arxiv.org/pdf/2101.02767" target="_blank">pdf</a>]

<h2>Learning Grammar of Complex Activities via Deep Neural Networks. (arXiv:2101.02774v1 [cs.CV])</h2>
<h3>Becky Mashaido</h3>
<p>Motivated by the growing amount of publicly available video data on online
streaming services and an increased interest in applications that analyze
continuous video streams such as autonomous driving, this technical report
provides a theoretical insight into deep neural networks for video learning,
under label constraints. I build upon previous work in video learning for
computer vision, make observations on model performance and propose further
mechanisms to help improve our observations.
</p>
<a href="http://arxiv.org/abs/2101.02774" target="_blank">arXiv:2101.02774</a> [<a href="http://arxiv.org/pdf/2101.02774" target="_blank">pdf</a>]

<h2>Ferrofluidic Manipulator: Automatic Manipulation of Non-magnetic Microparticles at Air-Ferrofluid Interface. (arXiv:2101.02782v1 [cs.RO])</h2>
<h3>Zoran Cenev, P.A. Diluka Harischandra, Seppo Nurmi, Mika Latikka, Ville Hynninen, Robin H. A. Ras, Jaakko V. I. Timonen, Quan Zhou</h3>
<p>Manipulation of small-scale matter is a fundamental topic in micro- and
nanorobotics. Numerous magnetic robotic systems have been developed for the
manipulation of microparticles in an ambient environment, liquid as well as on
the air-liquid interface. Those systems move intrinsically magnetic or
magnetically tagged objects by inducing a magnetic torque or force. However,
most of the materials found in nature are non-magnetic. Here, we report a novel
ferrofluidic manipulator for automatic two-dimensional manipulation of
non-magnetic objects floating on top of a ferrofluid. The manipulation system
employs eight centimeter-scale solenoids, which can move non-magnetic particles
floating on the air-liquid interface by deforming the air-ferrofluid interface.
Using linear programming, we can control the motion of non-magnetic particles
with a predefined trajectory of a line, square, and circle with a precision of
57.4+/-33.6 um, 74+/-44.4 um, and 67.2+/-38.6 um, respectively. The
ferrofluidic manipulator is versatile with the materials and the shapes of the
objects under manipulation. We have successfully manipulated particles made of
polyethylene, polystyrene, a silicon chip, and poppy and sesame seeds.
</p>
<a href="http://arxiv.org/abs/2101.02782" target="_blank">arXiv:2101.02782</a> [<a href="http://arxiv.org/pdf/2101.02782" target="_blank">pdf</a>]

<h2>A Cable-Driven Parallel Robot with Full-Circle End-Effector Rotations. (arXiv:2101.02783v1 [cs.RO])</h2>
<h3>Marceau M&#xe9;tillon (RoMas, LS2N, CNRS), Philippe Cardou (ULaval), K&#xe9;vin Subrin (RoMas, UN), Camilo Charron (PACCE, LS2N), St&#xe9;phane Caro (LS2N, CNRS, RoMas)</h3>
<p>Cable-Driven Parallel Robots (CDPRs) offer high payload capacities, large
translational workspace and high dynamic performances. The rigid base frame of
the CDPR is connected in parallel to the moving platform using cables. However,
their orientation workspace is usually limited due to cable/cable and
cable/moving platform collisions. This paper deals with the design, modelling
and prototyping of a hybrid robot. This robot, which is composed of a CDPR
mounted in series with a Parallel Spherical Wrist (PSW), has both a large
translational workspace and an unlimited orientation workspace. It should be
noted that the six degrees of freedom (DOF) motions of the moving platform of
the CDPR, namely, the base of the PSW, and the three-DOF motion of the PSW are
actuated by means of eight actuators fixed to the base. As a consequence, the
overall system is underactuated and its total mass and inertia in motion is
reduced.
</p>
<a href="http://arxiv.org/abs/2101.02783" target="_blank">arXiv:2101.02783</a> [<a href="http://arxiv.org/pdf/2101.02783" target="_blank">pdf</a>]

<h2>A Framework for Deep Constrained Clustering. (arXiv:2101.02792v1 [cs.LG])</h2>
<h3>Hongjing Zhang, Tianyang Zhan, Sugato Basu, Ian Davidson</h3>
<p>The area of constrained clustering has been extensively explored by
researchers and used by practitioners. Constrained clustering formulations
exist for popular algorithms such as k-means, mixture models, and spectral
clustering but have several limitations. A fundamental strength of deep
learning is its flexibility, and here we explore a deep learning framework for
constrained clustering and in particular explore how it can extend the field of
constrained clustering. We show that our framework can not only handle standard
together/apart constraints (without the well documented negative effects
reported earlier) generated from labeled side information but more complex
constraints generated from new types of side information such as continuous
values and high-level domain knowledge. Furthermore, we propose an efficient
training paradigm that is generally applicable to these four types of
constraints. We validate the effectiveness of our approach by empirical results
on both image and text datasets. We also study the robustness of our framework
when learning with noisy constraints and show how different components of our
framework contribute to the final performance. Our source code is available at
$\href{https://github.com/blueocean92/deep_constrained_clustering}{\text{URL}}$.
</p>
<a href="http://arxiv.org/abs/2101.02792" target="_blank">arXiv:2101.02792</a> [<a href="http://arxiv.org/pdf/2101.02792" target="_blank">pdf</a>]

<h2>Off-Line Arabic Handwritten Words Segmentation using Morphological Operators. (arXiv:2101.02797v1 [cs.CV])</h2>
<h3>Nisreen AbdAllah, Serestina Viriri</h3>
<p>The main aim of this study is the assessment and discussion of a model for
hand-written Arabic through segmentation. The framework is proposed based on
three steps: pre-processing, segmentation, and evaluation. In the
pre-processing step, morphological operators are applied for Connecting Gaps
(CGs) in written words. Gaps happen when pen lifting-off during writing,
scanning documents, or while converting images to binary type. In the
segmentation step, first removed the small diacritics then bounded a connected
component to segment offline words. Huge data was utilized in the proposed
model for applying a variety of handwriting styles so that to be more
compatible with real-life applications. Consequently, on the automatic
evaluation stage, selected randomly 1,131 images from the IESK-ArDB database,
and then segmented into sub-words. After small gaps been connected, the model
performance evaluation had been reached 88% against the standard ground truth
of the database. The proposed model achieved the highest accuracy when compared
with the related works.
</p>
<a href="http://arxiv.org/abs/2101.02797" target="_blank">arXiv:2101.02797</a> [<a href="http://arxiv.org/pdf/2101.02797" target="_blank">pdf</a>]

<h2>Average-Reward Off-Policy Policy Evaluation with Function Approximation. (arXiv:2101.02808v1 [cs.LG])</h2>
<h3>Shangtong Zhang, Yi Wan, Richard S. Sutton, Shimon Whiteson</h3>
<p>We consider off-policy policy evaluation with function approximation (FA) in
average-reward MDPs, where the goal is to estimate both the reward rate and the
differential value function. For this problem, bootstrapping is necessary and,
along with off-policy learning and FA, results in the deadly triad (Sutton &amp;
Barto, 2018). To address the deadly triad, we propose two novel algorithms,
reproducing the celebrated success of Gradient TD algorithms in the
average-reward setting. In terms of estimating the differential value function,
the algorithms are the first convergent off-policy linear function
approximation algorithms. In terms of estimating the reward rate, the
algorithms are the first convergent off-policy linear function approximation
algorithms that do not require estimating the density ratio. We demonstrate
empirically the advantage of the proposed algorithms, as well as their
nonlinear variants, over a competitive density-ratio-based approach, in a
simple domain as well as challenging robot simulation tasks.
</p>
<a href="http://arxiv.org/abs/2101.02808" target="_blank">arXiv:2101.02808</a> [<a href="http://arxiv.org/pdf/2101.02808" target="_blank">pdf</a>]

<h2>Long Horizon Forecasting With Temporal Point Processes. (arXiv:2101.02815v1 [cs.LG])</h2>
<h3>Prathamesh Deshpande, Kamlesh Marathe, Abir De, Sunita Sarawagi</h3>
<p>In recent years, marked temporal point processes (MTPPs) have emerged as a
powerful modeling machinery to characterize asynchronous events in a wide
variety of applications. MTPPs have demonstrated significant potential in
predicting event-timings, especially for events arriving in near future.
However, due to current design choices, MTPPs often show poor predictive
performance at forecasting event arrivals in distant future. To ameliorate this
limitation, in this paper, we design DualTPP which is specifically well-suited
to long horizon event forecasting. DualTPP has two components. The first
component is an intensity free MTPP model, which captures microscopic or
granular level signals of the event dynamics by modeling the time of future
events. The second component takes a different dual perspective of modeling
aggregated counts of events in a given time-window, thus encapsulating
macroscopic event dynamics. Then we develop a novel inference framework jointly
over the two models % for efficiently forecasting long horizon events by
solving a sequence of constrained quadratic optimization problems. Experiments
with a diverse set of real datasets show that DualTPP outperforms existing MTPP
methods on long horizon forecasting by substantial margins, achieving almost an
order of magnitude reduction in Wasserstein distance between actual events and
forecasts.
</p>
<a href="http://arxiv.org/abs/2101.02815" target="_blank">arXiv:2101.02815</a> [<a href="http://arxiv.org/pdf/2101.02815" target="_blank">pdf</a>]

<h2>A Tale of Fairness Revisited: Beyond Adversarial Learning for Deep Neural Network Fairness. (arXiv:2101.02831v1 [cs.LG])</h2>
<h3>Becky Mashaido, Winston Moh Tangongho</h3>
<p>Motivated by the need for fair algorithmic decision making in the age of
automation and artificially-intelligent technology, this technical report
provides a theoretical insight into adversarial training for fairness in deep
learning. We build upon previous work in adversarial fairness, show the
persistent tradeoff between fair predictions and model performance, and explore
further mechanisms that help in offsetting this tradeoff.
</p>
<a href="http://arxiv.org/abs/2101.02831" target="_blank">arXiv:2101.02831</a> [<a href="http://arxiv.org/pdf/2101.02831" target="_blank">pdf</a>]

<h2>Shallow Bayesian Meta Learning for Real-World Few-Shot Recognition. (arXiv:2101.02833v1 [cs.LG])</h2>
<h3>Xueting Zhang, Debin Meng, Henry Gouk, Timothy Hospedales</h3>
<p>Current state-of-the-art few-shot learners focus on developing effective
training procedures for feature representations, before using simple, e.g.
nearest centroid, classifiers. In this paper we take an orthogonal approach
that is agnostic to the features used, and focus exclusively on meta-learning
the actual classifier layer. Specifically, we introduce MetaQDA, a Bayesian
meta-learning generalisation of the classic quadratic discriminant analysis.
This setup has several benefits of interest to practitioners: meta-learning is
fast and memory efficient, without the need to fine-tune features. It is
agnostic to the off-the-shelf features chosen, and thus will continue to
benefit from advances in feature representations. Empirically, it leads to
robust performance in cross-domain few-shot learning and, crucially for
real-world applications, it leads to better uncertainty calibration in
predictions.
</p>
<a href="http://arxiv.org/abs/2101.02833" target="_blank">arXiv:2101.02833</a> [<a href="http://arxiv.org/pdf/2101.02833" target="_blank">pdf</a>]

<h2>Unsupervised Domain Adaptation of Black-Box Source Models. (arXiv:2101.02839v1 [cs.LG])</h2>
<h3>Haojian Zhang, Yabin Zhang, Kui Jia, Lei Zhang</h3>
<p>Unsupervised domain adaptation (UDA) aims to learn a model for unlabeled data
on a target domain by transferring knowledge from a labeled source domain. In
the traditional UDA setting, labeled source data are assumed to be available
for the use of model adaptation. Due to the increasing concerns for data
privacy, source-free UDA is highly appreciated as a new UDA setting, where only
a trained source model is assumed to be available, while the labeled source
data remain private. However, exposing details of the trained source model for
UDA use is prone to easily committed white-box attacks, which brings severe
risks to the source tasks themselves. To address this issue, we advocate
studying a subtly different setting, named Black-Box Unsupervised Domain
Adaptation (B2UDA), where only the input-output interface of the source model
is accessible in UDA; in other words, the source model itself is kept as a
black-box one. To tackle the B2UDA task, we propose a simple yet effective
method, termed Iterative Noisy Label Learning (IterNLL). IterNLL starts with
getting noisy labels of the unlabeled target data from the black-box source
model. It then alternates between learning improved target models from the
target subset with more reliable labels and updating the noisy target labels.
Experiments on benchmark datasets confirm the efficacy of our proposed method.
Notably, IterNLL performs comparably with methods of the traditional UDA
setting where the labeled source data are fully available.
</p>
<a href="http://arxiv.org/abs/2101.02839" target="_blank">arXiv:2101.02839</a> [<a href="http://arxiv.org/pdf/2101.02839" target="_blank">pdf</a>]

<h2>Grasp and Motion Planning for Dexterous Manipulation for the Real Robot Challenge. (arXiv:2101.02842v1 [cs.RO])</h2>
<h3>Takuma Yoneda, Charles Schaff, Takahiro Maeda, Matthew Walter</h3>
<p>This report describes our winning submission to the Real Robot Challenge
(https://real-robot-challenge.com/). The Real Robot Challenge is a three-phase
dexterous manipulation competition that involves manipulating various
rectangular objects with the TriFinger Platform. Our approach combines motion
planning with several motion primitives to manipulate the object. For Phases 1
and 2, we additionally learn a residual policy in simulation that applies
corrective actions on top of our controller. Our approach won first place in
Phase 2 and Phase 3 of the competition. We were anonymously known as
`ardentstork' on the competition leaderboard
(https://real-robot-challenge.com/leader-board). Videos and our code can be
found at https://github.com/ripl-ttic/real-robot-challenge.
</p>
<a href="http://arxiv.org/abs/2101.02842" target="_blank">arXiv:2101.02842</a> [<a href="http://arxiv.org/pdf/2101.02842" target="_blank">pdf</a>]

<h2>Probabilistic Graph Attention Network with Conditional Kernels for Pixel-Wise Prediction. (arXiv:2101.02843v1 [cs.CV])</h2>
<h3>Dan Xu, Xavier Alameda-Pineda, Wanli Ouyang, Elisa Ricci, Xiaogang Wang, Nicu Sebe</h3>
<p>Multi-scale representations deeply learned via convolutional neural networks
have shown tremendous importance for various pixel-level prediction problems.
In this paper we present a novel approach that advances the state of the art on
pixel-level prediction in a fundamental aspect, i.e. structured multi-scale
features learning and fusion. In contrast to previous works directly
considering multi-scale feature maps obtained from the inner layers of a
primary CNN architecture, and simply fusing the features with weighted
averaging or concatenation, we propose a probabilistic graph attention network
structure based on a novel Attention-Gated Conditional Random Fields (AG-CRFs)
model for learning and fusing multi-scale representations in a principled
manner. In order to further improve the learning capacity of the network
structure, we propose to exploit feature dependant conditional kernels within
the deep probabilistic framework. Extensive experiments are conducted on four
publicly available datasets (i.e. BSDS500, NYUD-V2, KITTI, and Pascal-Context)
and on three challenging pixel-wise prediction problems involving both discrete
and continuous labels (i.e. monocular depth estimation, object contour
prediction, and semantic segmentation). Quantitative and qualitative results
demonstrate the effectiveness of the proposed latent AG-CRF model and the
overall probabilistic graph attention network with feature conditional kernels
for structured feature learning and pixel-wise prediction.
</p>
<a href="http://arxiv.org/abs/2101.02843" target="_blank">arXiv:2101.02843</a> [<a href="http://arxiv.org/pdf/2101.02843" target="_blank">pdf</a>]

<h2>Exploring Fault-Energy Trade-offs in Approximate DNN Hardware Accelerators. (arXiv:2101.02860v1 [cs.LG])</h2>
<h3>Ayesha Siddique, Kanad Basu, Khaza Anuarul Hoque</h3>
<p>Systolic array-based deep neural network (DNN) accelerators have recently
gained prominence for their low computational cost. However, their high energy
consumption poses a bottleneck to their deployment in energy-constrained
devices. To address this problem, approximate computing can be employed at the
cost of some tolerable accuracy loss. However, such small accuracy variations
may increase the sensitivity of DNNs towards undesired subtle disturbances,
such as permanent faults. The impact of permanent faults in accurate DNNs has
been thoroughly investigated in the literature. Conversely, the impact of
permanent faults in approximate DNN accelerators (AxDNNs) is yet
under-explored. The impact of such faults may vary with the fault bit
positions, activation functions and approximation errors in AxDNN layers. Such
dynamacity poses a considerable challenge to exploring the trade-off between
their energy efficiency and fault resilience in AxDNNs. Towards this, we
present an extensive layer-wise and bit-wise fault resilience and energy
analysis of different AxDNNs, using the state-of-the-art Evoapprox8b signed
multipliers. In particular, we vary the stuck-at-0, stuck-at-1 fault-bit
positions, and activation functions to study their impact using the most widely
used MNIST and Fashion-MNIST datasets. Our quantitative analysis shows that the
permanent faults exacerbate the accuracy loss in AxDNNs when compared to the
accurate DNN accelerators. For instance, a permanent fault in AxDNNs can lead
up to 66\% accuracy loss, whereas the same faulty bit can lead to only 9\%
accuracy loss in an accurate DNN accelerator. Our results demonstrate that the
fault resilience in AxDNNs is orthogonal to the energy efficiency.
</p>
<a href="http://arxiv.org/abs/2101.02860" target="_blank">arXiv:2101.02860</a> [<a href="http://arxiv.org/pdf/2101.02860" target="_blank">pdf</a>]

<h2>ADiag: Graph Neural Network Based Diagnosis of Alzheimer's Disease. (arXiv:2101.02870v1 [cs.LG])</h2>
<h3>Vishnu Ram Sampathkumar</h3>
<p>Alzheimer's Disease (AD) is the most widespread neurodegenerative disease,
affecting over 50 million people across the world. While its progression cannot
be stopped, early and accurate diagnostic testing can drastically improve
quality of life in patients. Currently, only qualitative means of testing are
employed in the form of scoring performance on a battery of cognitive tests.
The inherent disadvantage of this method is that the burden of an accurate
diagnosis falls on the clinician's competence. Quantitative methods like MRI
scan assessment are inaccurate at best,due to the elusive nature of visually
observable changes in the brain. In lieu of these disadvantages to extant
methods of AD diagnosis, we have developed ADiag, a novel quantitative method
to diagnose AD through GraphSAGE Network and Dense Differentiable Pooling (DDP)
analysis of large graphs based on thickness difference between different
structural regions of the cortex. Preliminary tests of ADiag have revealed a
robust accuracy of 83%, vastly outperforming other qualitative and quantitative
diagnostic techniques.
</p>
<a href="http://arxiv.org/abs/2101.02870" target="_blank">arXiv:2101.02870</a> [<a href="http://arxiv.org/pdf/2101.02870" target="_blank">pdf</a>]

<h2>A general framework for modeling and dynamic simulation of multibody systems using factor graphs. (arXiv:2101.02874v1 [cs.RO])</h2>
<h3>Jos&#xe9;-Luis Blanco-Claraco, Antonio Leanza, Giulio Reina</h3>
<p>In this paper, we present a novel general framework grounded in the factor
graph theory to solve kinematic and dynamic problems for multi-body systems.
Although the motion of multi-body systems is considered to be a well-studied
problem and various methods have been proposed for its solution, a unified
approach providing an intuitive interpretation is still pursued. We describe
how to build factor graphs to model and simulate multibody systems using both,
independent and dependent coordinates. Then, batch optimization or a
fixed-lag-smoother can be applied to solve the underlying optimization problem
that results in a highly-sparse nonlinear minimization problem. The proposed
framework has been tested in extensive simulations and validated against a
commercial multibody software. We release a reference implementation as an
open-source C++ library, based on the GTSAM framework, a well-known estimation
library. Simulations of forward and inverse dynamics are presented, showing
comparable accuracy with classical approaches. The proposed factor graph-based
framework has the potential to be integrated into applications related with
motion estimation and parameter identification of complex mechanical systems,
ranging from mechanisms to vehicles, or robot manipulators.
</p>
<a href="http://arxiv.org/abs/2101.02874" target="_blank">arXiv:2101.02874</a> [<a href="http://arxiv.org/pdf/2101.02874" target="_blank">pdf</a>]

<h2>HIVE-Net: Centerline-Aware HIerarchical View-Ensemble Convolutional Network for Mitochondria Segmentation in EM Images. (arXiv:2101.02877v1 [cs.CV])</h2>
<h3>Zhimin Yuan, Xiaofen Ma, Jiajin Yi, Zhengrong Luo, Jialin Peng</h3>
<p>Semantic segmentation of electron microscopy (EM) is an essential step to
efficiently obtain reliable morphological statistics. Despite the great success
achieved using deep convolutional neural networks (CNNs), they still produce
coarse segmentations with lots of discontinuities and false positives for
mitochondria segmentation. In this study, we introduce a centerline-aware
multitask network by utilizing centerline as an intrinsic shape cue of
mitochondria to regularize the segmentation. Since the application of 3D CNNs
on large medical volumes is usually hindered by their substantial computational
cost and storage overhead, we introduce a novel hierarchical view-ensemble
convolution (HVEC), a simple alternative of 3D convolution to learn 3D spatial
contexts using more efficient 2D convolutions. The HVEC enables both
decomposing and sharing multi-view information, leading to increased learning
capacity. Extensive validation results on two challenging benchmarks show that,
the proposed method performs favorably against the state-of-the-art methods in
accuracy and visual quality but with a greatly reduced model size. Moreover,
the proposed model also shows significantly improved generalization ability,
especially when training with quite limited amount of training data.
</p>
<a href="http://arxiv.org/abs/2101.02877" target="_blank">arXiv:2101.02877</a> [<a href="http://arxiv.org/pdf/2101.02877" target="_blank">pdf</a>]

<h2>An Information-theoretic Progressive Framework for Interpretation. (arXiv:2101.02879v1 [cs.AI])</h2>
<h3>Zhengqi He, Taro Toyoizumi</h3>
<p>Both brain science and the deep learning communities have the problem of
interpreting neural activity. For deep learning, even though we can access all
neurons' activity data, interpretation of how the deep network solves the task
is still challenging. Although a large amount of effort has been devoted to
interpreting a deep network, there is still no consensus of what interpretation
is. This paper tries to push the discussion in this direction and proposes an
information-theoretic progressive framework to synthesize interpretation.
Firstly, we discuss intuitions of interpretation: interpretation is
meta-information; interpretation should be at the right level; inducing
independence is helpful to interpretation; interpretation is naturally
progressive; interpretation doesn't have to involve a human. Then, we build the
framework with an information map splitting idea and implement it with the
variational information bottleneck technique. After that, we test the framework
with the CLEVR dataset. The framework is shown to be able to split information
maps and synthesize interpretation in the form of meta-information.
</p>
<a href="http://arxiv.org/abs/2101.02879" target="_blank">arXiv:2101.02879</a> [<a href="http://arxiv.org/pdf/2101.02879" target="_blank">pdf</a>]

<h2>Octave Mix: Data augmentation using frequency decomposition for activity recognition. (arXiv:2101.02882v1 [cs.CV])</h2>
<h3>Tatsuhito Hasegawa</h3>
<p>In the research field of activity recognition, although it is difficult to
collect a large amount of measured sensor data, there has not been much
discussion about data augmentation (DA). In this study, I propose Octave Mix as
a new synthetic-style DA method for sensor-based activity recognition. Octave
Mix is a simple DA method that combines two types of waveforms by intersecting
low and high frequency waveforms using frequency decomposition. In addition, I
propose a DA ensemble model and its training algorithm to acquire robustness to
the original sensor data while remaining a wide variety of feature
representation. I conducted experiments to evaluate the effectiveness of my
proposed method using four different benchmark datasets of sensing-based
activity recognition. As a result, my proposed method achieved the best
estimation accuracy. Furthermore, I found that ensembling two DA strategies:
Octave Mix with rotation and mixup with rotation, make it possible to achieve
higher accuracy.
</p>
<a href="http://arxiv.org/abs/2101.02882" target="_blank">arXiv:2101.02882</a> [<a href="http://arxiv.org/pdf/2101.02882" target="_blank">pdf</a>]

<h2>Practical Control for Multicopters to Avoid Non-Cooperative Moving Obstacles. (arXiv:2101.02889v1 [cs.RO])</h2>
<h3>Quan Quan, Rao Fu, Kai-Yuan Cai</h3>
<p>Unmanned Aerial Vehicles (UAVs) are now becoming increasingly accessible to
amateur and commercial users alike. The main task for UAVs is to keep a
prescribed separation with obstacles in the air. In this paper, a
collision-avoidance control method for non-cooperative moving obstacles is
proposed for a multicopter with the altitude hold mode by using a Lyapunov-like
barrier function. Lyapunov-like functions are designed elaborately, based on
which formal analysis and proofs of the proposed control are made to show that
the collision-avoidance control problem can be solved if the moving obstacle is
slower than the multicopter. The result can be extended to some cases of
multiple obstacles. What is more, by the proposed control, a multicopter can
keep away from obstacles as soon as possible, once obstacles enter into the
safety area of the multicopter accidentally, and converge to the waypoint.
Simulations and experiments are given to show the effectiveness of the proposed
method by showing the distance between UAV and waypoint, obstacles
respectively.
</p>
<a href="http://arxiv.org/abs/2101.02889" target="_blank">arXiv:2101.02889</a> [<a href="http://arxiv.org/pdf/2101.02889" target="_blank">pdf</a>]

<h2>Sequential Naive Learning. (arXiv:2101.02897v1 [cs.LG])</h2>
<h3>Itai Arieli, Yakov Babichenko, Manuel Mueller-Frank</h3>
<p>We analyze boundedly rational updating from aggregate statistics in a model
with binary actions and binary states. Agents each take an irreversible action
in sequence after observing the unordered set of previous actions. Each agent
first forms her prior based on the aggregate statistic, then incorporates her
signal with the prior based on Bayes rule, and finally applies a decision rule
that assigns a (mixed) action to each belief. If priors are formed according to
a discretized DeGroot rule, then actions converge to the state (in
probability), i.e., \emph{asymptotic learning}, in any informative information
structure if and only if the decision rule satisfies probability matching. This
result generalizes to unspecified information settings where information
structures differ across agents and agents know only the information structure
generating their own signal. Also, the main result extends to the case of $n$
states and $n$ actions.
</p>
<a href="http://arxiv.org/abs/2101.02897" target="_blank">arXiv:2101.02897</a> [<a href="http://arxiv.org/pdf/2101.02897" target="_blank">pdf</a>]

<h2>Adversarial Attack Attribution: Discovering Attributable Signals in Adversarial ML Attacks. (arXiv:2101.02899v1 [cs.LG])</h2>
<h3>Marissa Dotter, Sherry Xie, Keith Manville, Josh Harguess, Colin Busho, Mikel Rodriguez</h3>
<p>Machine Learning (ML) models are known to be vulnerable to adversarial inputs
and researchers have demonstrated that even production systems, such as
self-driving cars and ML-as-a-service offerings, are susceptible. These systems
represent a target for bad actors. Their disruption can cause real physical and
economic harm. When attacks on production ML systems occur, the ability to
attribute the attack to the responsible threat group is a critical step in
formulating a response and holding the attackers accountable. We pose the
following question: can adversarially perturbed inputs be attributed to the
particular methods used to generate the attack? In other words, is there a way
to find a signal in these attacks that exposes the attack algorithm, model
architecture, or hyperparameters used in the attack? We introduce the concept
of adversarial attack attribution and create a simple supervised learning
experimental framework to examine the feasibility of discovering attributable
signals in adversarial attacks. We find that it is possible to differentiate
attacks generated with different attack algorithms, models, and hyperparameters
on both the CIFAR-10 and MNIST datasets.
</p>
<a href="http://arxiv.org/abs/2101.02899" target="_blank">arXiv:2101.02899</a> [<a href="http://arxiv.org/pdf/2101.02899" target="_blank">pdf</a>]

<h2>NVAE-GAN Based Approach for Unsupervised Time Series Anomaly Detection. (arXiv:2101.02908v1 [cs.LG])</h2>
<h3>Liang Xu, Liying Zheng, Weijun Li, Zhenbo Chen, Weishun Song, Yue Deng, Yongzhe Chang, Jing Xiao, Bo Yuan</h3>
<p>In recent studies, Lots of work has been done to solve time series anomaly
detection by applying Variational Auto-Encoders (VAEs). Time series anomaly
detection is a very common but challenging task in many industries, which plays
an important role in network monitoring, facility maintenance, information
security, and so on. However, it is very difficult to detect anomalies in time
series with high accuracy, due to noisy data collected from real world, and
complicated abnormal patterns. From recent studies, we are inspired by Nouveau
VAE (NVAE) and propose our anomaly detection model: Time series to Image VAE
(T2IVAE), an unsupervised model based on NVAE for univariate series,
transforming 1D time series to 2D image as input, and adopting the
reconstruction error to detect anomalies. Besides, we also apply the Generative
Adversarial Networks based techniques to T2IVAE training strategy, aiming to
reduce the overfitting. We evaluate our model performance on three datasets,
and compare it with other several popular models using F1 score. T2IVAE
achieves 0.639 on Numenta Anomaly Benchmark, 0.651 on public dataset from NASA,
and 0.504 on our dataset collected from real-world scenario, outperforms other
comparison models.
</p>
<a href="http://arxiv.org/abs/2101.02908" target="_blank">arXiv:2101.02908</a> [<a href="http://arxiv.org/pdf/2101.02908" target="_blank">pdf</a>]

<h2>Towards Accelerating Training of Batch Normalization: A Manifold Perspective. (arXiv:2101.02916v1 [cs.LG])</h2>
<h3>Mingyang Yi, Qi Meng, Wei Chen, Zhi-Ming Ma</h3>
<p>Batch normalization (BN) has become a crucial component across diverse deep
neural networks. The network with BN is invariant to positively linear
re-scaling of weights, which makes there exist infinite functionally equivalent
networks with various scales of weights. However, optimizing these equivalent
networks with the first-order method such as stochastic gradient descent will
converge to different local optima owing to different gradients across
training. To alleviate this, we propose a quotient manifold \emph{PSI
manifold}, in which all the equivalent weights of the network with BN are
regarded as the same one element. Then, gradient descent and stochastic
gradient descent on the PSI manifold are also constructed. The two algorithms
guarantee that every group of equivalent weights (caused by positively
re-scaling) converge to the equivalent optima. Besides that, we give the
convergence rate of the proposed algorithms on PSI manifold and justify that
they accelerate training compared with the algorithms on the Euclidean weight
space. Empirical studies show that our algorithms can consistently achieve
better performances over various experimental settings.
</p>
<a href="http://arxiv.org/abs/2101.02916" target="_blank">arXiv:2101.02916</a> [<a href="http://arxiv.org/pdf/2101.02916" target="_blank">pdf</a>]

<h2>BN-invariant sharpness regularizes the training model to better generalization. (arXiv:2101.02944v1 [cs.LG])</h2>
<h3>Mingyang Yi, Huishuai Zhang, Wei Chen, Zhi-Ming Ma, Tie-Yan Liu</h3>
<p>It is arguably believed that flatter minima can generalize better. However,
it has been pointed out that the usual definitions of sharpness, which consider
either the maxima or the integral of loss over a $\delta$ ball of parameters
around minima, cannot give consistent measurement for scale invariant neural
networks, e.g., networks with batch normalization layer. In this paper, we
first propose a measure of sharpness, BN-Sharpness, which gives consistent
value for equivalent networks under BN. It achieves the property of scale
invariance by connecting the integral diameter with the scale of parameter.
Then we present a computation-efficient way to calculate the BN-sharpness
approximately i.e., one dimensional integral along the "sharpest" direction.
Furthermore, we use the BN-sharpness to regularize the training and design an
algorithm to minimize the new regularized objective. Our algorithm achieves
considerably better performance than vanilla SGD over various experiment
settings.
</p>
<a href="http://arxiv.org/abs/2101.02944" target="_blank">arXiv:2101.02944</a> [<a href="http://arxiv.org/pdf/2101.02944" target="_blank">pdf</a>]

<h2>Geometry Aware NMPC Scheme for Morphing Quadrotor Navigation in Restricted Entrances. (arXiv:2101.02965v1 [cs.RO])</h2>
<h3>Andreas Papadimitriou, Sina Sharif Mansouri, Christoforos Kanellakis, George Nikolakopoulos</h3>
<p>Geometry-morphing Micro Aerial Vehicles (MAVs) are gaining more and more
attention lately, since their ability to modify their geometric morphology
in-flight increases their versatility, while expanding their application range.
In this novel research field, most of the works focus on the platform design
and on the low-level control part for maintaining stability after the
deformation. Nevertheless, another aspect of geometry morphing MAVs is the
association of the deformation with respect to the shape and structure of the
environment. In this article, we propose a novel Nonlinear Model Predictive
Control (NMPC) structure that modifies the morphology of a quadrotor based on
the environmental entrances geometrical shape. The proposed method considers
restricted entrances as a constraint in the NMPC and modifies the arm
configuration of the MAV to provide a collision free path from the initial
position to the desired goal, while passing through the entrance. To the
authors' best knowledge, this work is the first to connect the in-flight
morphology with the characteristics of environmental shapes. Multiple
simulation results depict the performance and efficiency of the proposed scheme
in scenarios where the quadrotor is commanded to pass through restricted areas.
</p>
<a href="http://arxiv.org/abs/2101.02965" target="_blank">arXiv:2101.02965</a> [<a href="http://arxiv.org/pdf/2101.02965" target="_blank">pdf</a>]

<h2>Infinite-dimensional Folded-in-time Deep Neural Networks. (arXiv:2101.02966v1 [cs.LG])</h2>
<h3>Florian Stelzer (1 and 2), Serhiy Yanchuk (1) ((1) Institute of Mathematics, Technische Universit&#xe4;t Berlin, Germany, (2) Department of Mathematics, Humboldt-Universit&#xe4;t zu Berlin, Germany)</h3>
<p>The method recently introduced in arXiv:2011.10115 realizes a deep neural
network with just a single nonlinear element and delayed feedback. It is
applicable for the description of physically implemented neural networks. In
this work, we present an infinite-dimensional generalization, which allows for
a more rigorous mathematical analysis and a higher flexibility in choosing the
weight functions. Precisely speaking, the weights are described by Lebesgue
integrable functions instead of step functions. We also provide a functional
backpropagation algorithm, which enables gradient descent training of the
weights. In addition, with a slight modification, our concept realizes
recurrent neural networks.
</p>
<a href="http://arxiv.org/abs/2101.02966" target="_blank">arXiv:2101.02966</a> [<a href="http://arxiv.org/pdf/2101.02966" target="_blank">pdf</a>]

<h2>From Black-box to White-box: Examining Confidence Calibration under different Conditions. (arXiv:2101.02971v1 [cs.CV])</h2>
<h3>Franziska Schwaiger, Maximilian Henne, Fabian K&#xfc;ppers, Felippe Schmoeller Roza, Karsten Roscher, Anselm Haselhoff</h3>
<p>Confidence calibration is a major concern when applying artificial neural
networks in safety-critical applications. Since most research in this area has
focused on classification in the past, confidence calibration in the scope of
object detection has gained more attention only recently. Based on previous
work, we study the miscalibration of object detection models with respect to
image location and box scale. Our main contribution is to additionally consider
the impact of box selection methods like non-maximum suppression to
calibration. We investigate the default intrinsic calibration of object
detection models and how it is affected by these post-processing techniques.
For this purpose, we distinguish between black-box calibration with non-maximum
suppression and white-box calibration with raw network outputs. Our experiments
reveal that post-processing highly affects confidence calibration. We show that
non-maximum suppression has the potential to degrade initially well-calibrated
predictions, leading to overconfident and thus miscalibrated models.
</p>
<a href="http://arxiv.org/abs/2101.02971" target="_blank">arXiv:2101.02971</a> [<a href="http://arxiv.org/pdf/2101.02971" target="_blank">pdf</a>]

<h2>Approaching Neural Network Uncertainty Realism. (arXiv:2101.02974v1 [cs.LG])</h2>
<h3>Joachim Sicking, Alexander Kister, Matthias Fahrland, Stefan Eickeler, Fabian H&#xfc;ger, Stefan R&#xfc;ping, Peter Schlicht, Tim Wirtz</h3>
<p>Statistical models are inherently uncertain. Quantifying or at least
upper-bounding their uncertainties is vital for safety-critical systems such as
autonomous vehicles. While standard neural networks do not report this
information, several approaches exist to integrate uncertainty estimates into
them. Assessing the quality of these uncertainty estimates is not
straightforward, as no direct ground truth labels are available. Instead,
implicit statistical assessments are required. For regression, we propose to
evaluate uncertainty realism -- a strict quality criterion -- with a
Mahalanobis distance-based statistical test. An empirical evaluation reveals
the need for uncertainty measures that are appropriate to upper-bound
heavy-tailed empirical errors. Alongside, we transfer the variational U-Net
classification architecture to standard supervised image-to-image tasks. We
adopt it to the automotive domain and show that it significantly improves
uncertainty realism compared to a plain encoder-decoder model.
</p>
<a href="http://arxiv.org/abs/2101.02974" target="_blank">arXiv:2101.02974</a> [<a href="http://arxiv.org/pdf/2101.02974" target="_blank">pdf</a>]

<h2>Artificial Intelligence enabled Smart Learning. (arXiv:2101.02991v1 [cs.AI])</h2>
<h3>Faisal Khan, Debdeep Bose</h3>
<p>Artificial Intelligence (AI) is a discipline of computer science that deals
with machine intelligence. It is essential to bring AI into the context of
learning because it helps in analysing the enormous amounts of data that is
collected from individual students, teachers and academic staff. The major
priorities of implementing AI in education are making innovative use of
existing digital technologies for learning, and teaching practices that
significantly improve traditional educational methods. The main problem with
traditional learning is that it cannot be suited to every student in class.
Some students may grasp the concepts well, while some may have difficulties in
understanding them and some may be more auditory or visual learners. The World
Bank report on education has indicated that the learning gap created by this
problem causes many students to drop out (World Development Report, 2018).
Personalised learning has been able to solve this grave problem.
</p>
<a href="http://arxiv.org/abs/2101.02991" target="_blank">arXiv:2101.02991</a> [<a href="http://arxiv.org/pdf/2101.02991" target="_blank">pdf</a>]

<h2>Differentially Private Federated Learning for Cancer Prediction. (arXiv:2101.02997v1 [stat.ML])</h2>
<h3>Constance Beguier, Jean Ogier du Terrail, Iqraa Meah, Mathieu Andreux, Eric W. Tramel</h3>
<p>Since 2014, the NIH funded iDASH (integrating Data for Analysis,
Anonymization, SHaring) National Center for Biomedical Computing has hosted
yearly competitions on the topic of private computing for genomic data. For one
track of the 2020 iteration of this competition, participants were challenged
to produce an approach to federated learning (FL) training of genomic cancer
prediction models using differential privacy (DP), with submissions ranked
according to held-out test accuracy for a given set of DP budgets. More
precisely, in this track, we are tasked with training a supervised model for
the prediction of breast cancer occurrence from genomic data split between two
virtual centers while ensuring data privacy with respect to model transfer via
DP. In this article, we present our 3rd place submission to this competition.
During the competition, we encountered two main challenges discussed in this
article: i) ensuring correctness of the privacy budget evaluation and ii)
achieving an acceptable trade-off between prediction performance and privacy
budget.
</p>
<a href="http://arxiv.org/abs/2101.02997" target="_blank">arXiv:2101.02997</a> [<a href="http://arxiv.org/pdf/2101.02997" target="_blank">pdf</a>]

<h2>On the Turnpike to Design of Deep Neural Nets: Explicit Depth Bounds. (arXiv:2101.03000v1 [cs.LG])</h2>
<h3>Timm Faulwasser, Arne-Jens Hempel, Stefan Streif</h3>
<p>It is well-known that the training of Deep Neural Networks (DNN) can be
formalized in the language of optimal control. In this context, this paper
leverages classical turnpike properties of optimal control problems to attempt
a quantifiable answer to the question of how many layers should be considered
in a DNN. The underlying assumption is that the number of neurons per layer --
i.e., the width of the DNN -- is kept constant. Pursuing a different route than
the classical analysis of approximation properties of sigmoidal functions, we
prove explicit bounds on the required depths of DNNs based on asymptotic
reachability assumptions and a dissipativity-inducing choice of the
regularization terms in the training problem. Numerical results obtained for
the two spiral task data set for classification indicate that the proposed
estimates can provide non-conservative depth bounds.
</p>
<a href="http://arxiv.org/abs/2101.03000" target="_blank">arXiv:2101.03000</a> [<a href="http://arxiv.org/pdf/2101.03000" target="_blank">pdf</a>]

<h2>Residual networks classify inputs based on their neural transient dynamics. (arXiv:2101.03009v1 [cs.CV])</h2>
<h3>Fereshteh Lagzi</h3>
<p>In this study, we analyze the input-output behavior of residual networks from
a dynamical system point of view by disentangling the residual dynamics from
the output activities before the classification stage. For a network with
simple skip connections between every successive layer, and for logistic
activation function, and shared weights between layers, we show analytically
that there is a cooperation and competition dynamics between residuals
corresponding to each input dimension. Interpreting these kind of networks as
nonlinear filters, the steady state value of the residuals in the case of
attractor networks are indicative of the common features between different
input dimensions that the network has observed during training, and has encoded
in those components. In cases where residuals do not converge to an attractor
state, their internal dynamics are separable for each input class, and the
network can reliably approximate the output. We bring analytical and empirical
evidence that residual networks classify inputs based on the integration of the
transient dynamics of the residuals, and will show how the network responds to
input perturbations. We compare the network dynamics for a ResNet and a
Multi-Layer Perceptron and show that the internal dynamics, and the noise
evolution are fundamentally different in these networks, and ResNets are more
robust to noisy inputs. Based on these findings, we also develop a new method
to adjust the depth for residual networks during training. As it turns out,
after pruning the depth of a ResNet using this algorithm,the network is still
capable of classifying inputs with a high accuracy.
</p>
<a href="http://arxiv.org/abs/2101.03009" target="_blank">arXiv:2101.03009</a> [<a href="http://arxiv.org/pdf/2101.03009" target="_blank">pdf</a>]

<h2>Multistage BiCross Encoder: Team GATE Entry for MLIA Multilingual Semantic Search Task 2. (arXiv:2101.03013v1 [cs.AI])</h2>
<h3>Iknoor Singh, Carolina Scarton, Kalina Bontcheva</h3>
<p>The Coronavirus (COVID-19) pandemic has led to a rapidly growing `infodemic'
online. Thus, the accurate retrieval of reliable relevant data from millions of
documents about COVID-19 has become urgently needed for the general public as
well as for other stakeholders. The COVID-19 Multilingual Information Access
(MLIA) initiative is a joint effort to ameliorate exchange of COVID-19 related
information by developing applications and services through research and
community participation. In this work, we present a search system called
Multistage BiCross Encoder, developed by team GATE for the MLIA task 2
Multilingual Semantic Search. Multistage BiCross-Encoder is a sequential three
stage pipeline which uses the Okapi BM25 algorithm and a transformer based
bi-encoder and cross-encoder to effectively rank the documents with respect to
the query. The results of round 1 show that our models achieve state-of-the-art
performance for all ranking metrics for both monolingual and bilingual runs.
</p>
<a href="http://arxiv.org/abs/2101.03013" target="_blank">arXiv:2101.03013</a> [<a href="http://arxiv.org/pdf/2101.03013" target="_blank">pdf</a>]

<h2>Contextual Non-Local Alignment over Full-Scale Representation for Text-Based Person Search. (arXiv:2101.03036v1 [cs.CV])</h2>
<h3>Chenyang Gao, Guanyu Cai, Xinyang Jiang, Feng Zheng, Jun Zhang, Yifei Gong, Pai Peng, Xiaowei Guo, Xing Sun</h3>
<p>Text-based person search aims at retrieving target person in an image gallery
using a descriptive sentence of that person. It is very challenging since modal
gap makes effectively extracting discriminative features more difficult.
Moreover, the inter-class variance of both pedestrian images and descriptions
is small. So comprehensive information is needed to align visual and textual
clues across all scales. Most existing methods merely consider the local
alignment between images and texts within a single scale (e.g. only global
scale or only partial scale) then simply construct alignment at each scale
separately. To address this problem, we propose a method that is able to
adaptively align image and textual features across all scales, called NAFS
(i.e.Non-local Alignment over Full-Scale representations). Firstly, a novel
staircase network structure is proposed to extract full-scale image features
with better locality. Secondly, a BERT with locality-constrained attention is
proposed to obtain representations of descriptions at different scales. Then,
instead of separately aligning features at each scale, a novel contextual
non-local attention mechanism is applied to simultaneously discover latent
alignments across all scales. The experimental results show that our method
outperforms the state-of-the-art methods by 5.53% in terms of top-1 and 5.35%
in terms of top-5 on text-based person search dataset. The code is available at
https://github.com/TencentYoutuResearch/PersonReID-NAFS
</p>
<a href="http://arxiv.org/abs/2101.03036" target="_blank">arXiv:2101.03036</a> [<a href="http://arxiv.org/pdf/2101.03036" target="_blank">pdf</a>]

<h2>Towards a Robust and Trustworthy Machine Learning System Development. (arXiv:2101.03042v1 [cs.LG])</h2>
<h3>Pulei Xiong, Scott Buffett, Shahrear Iqbal, Philippe Lamontagne, Mohammad Mamun, Heather Molyneaux</h3>
<p>Machine Learning (ML) technologies have been widely adopted in many mission
critical fields, such as cyber security, autonomous vehicle control,
healthcare, etc. to support intelligent decision-making. While ML has
demonstrated impressive performance over conventional methods in these
applications, concerns arose with respect to system resilience against
ML-specific security attacks and privacy breaches as well as the trust that
users have in these systems. In this article, firstly we present our recent
systematic and comprehensive survey on the state-of-the-art ML robustness and
trustworthiness technologies from a security engineering perspective, which
covers all aspects of secure ML system development including threat modeling,
common offensive and defensive technologies, privacy-preserving machine
learning, user trust in the context of machine learning, and empirical
evaluation for ML model robustness. Secondly, we then push our studies forward
above and beyond a survey by describing a metamodel we created that represents
the body of knowledge in a standard and visualized way for ML practitioners. We
further illustrate how to leverage the metamodel to guide a systematic threat
analysis and security design process in a context of generic ML system
development, which extends and scales up the classic process. Thirdly, we
propose future research directions motivated by our findings to advance the
development of robust and trustworthy ML systems. Our work differs from
existing surveys in this area in that, to the best of our knowledge, it is the
first of its kind of engineering effort to (i) explore the fundamental
principles and best practices to support robust and trustworthy ML system
development; and (ii) study the interplay of robustness and user trust in the
context of ML systems.
</p>
<a href="http://arxiv.org/abs/2101.03042" target="_blank">arXiv:2101.03042</a> [<a href="http://arxiv.org/pdf/2101.03042" target="_blank">pdf</a>]

<h2>InMoDeGAN: Interpretable Motion Decomposition Generative Adversarial Network for Video Generation. (arXiv:2101.03049v1 [cs.CV])</h2>
<h3>Yaohui Wang, Francois Bremond, Antitza Dantcheva</h3>
<p>In this work, we introduce an unconditional video generative model,
InMoDeGAN, targeted to (a) generate high quality videos, as well as to (b)
allow for interpretation of the latent space. For the latter, we place emphasis
on interpreting and manipulating motion. Towards this, we decompose motion into
semantic sub-spaces, which allow for control of generated samples. We design
the architecture of InMoDeGAN-generator in accordance to proposed Linear Motion
Decomposition, which carries the assumption that motion can be represented by a
dictionary, with related vectors forming an orthogonal basis in the latent
space. Each vector in the basis represents a semantic sub-space. In addition, a
Temporal Pyramid Discriminator analyzes videos at different temporal
resolutions. Extensive quantitative and qualitative analysis shows that our
model systematically and significantly outperforms state-of-the-art methods on
the VoxCeleb2-mini and BAIR-robot datasets w.r.t. video quality related to (a).
Towards (b) we present experimental results, confirming that decomposed
sub-spaces are interpretable and moreover, generated motion is controllable.
</p>
<a href="http://arxiv.org/abs/2101.03049" target="_blank">arXiv:2101.03049</a> [<a href="http://arxiv.org/pdf/2101.03049" target="_blank">pdf</a>]

<h2>Contextual Classification Using Self-Supervised Auxiliary Models for Deep Neural Networks. (arXiv:2101.03057v1 [cs.LG])</h2>
<h3>Sebastian Palacio, Philipp Engler, J&#xf6;rn Hees, Andreas Dengel</h3>
<p>Classification problems solved with deep neural networks (DNNs) typically
rely on a closed world paradigm, and optimize over a single objective (e.g.,
minimization of the cross-entropy loss). This setup dismisses all kinds of
supporting signals that can be used to reinforce the existence or absence of a
particular pattern. The increasing need for models that are interpretable by
design makes the inclusion of said contextual signals a crucial necessity. To
this end, we introduce the notion of Self-Supervised Autogenous Learning (SSAL)
models. A SSAL objective is realized through one or more additional targets
that are derived from the original supervised classification task, following
architectural principles found in multi-task learning. SSAL branches impose
low-level priors into the optimization process (e.g., grouping). The ability of
using SSAL branches during inference, allow models to converge faster, focusing
on a richer set of class-relevant features. We show that SSAL models
consistently outperform the state-of-the-art while also providing structured
predictions that are more interpretable.
</p>
<a href="http://arxiv.org/abs/2101.03057" target="_blank">arXiv:2101.03057</a> [<a href="http://arxiv.org/pdf/2101.03057" target="_blank">pdf</a>]

<h2>One-Class Classification: A Survey. (arXiv:2101.03064v1 [cs.CV])</h2>
<h3>Pramuditha Perera, Poojan Oza, Vishal M. Patel</h3>
<p>One-Class Classification (OCC) is a special case of multi-class
classification, where data observed during training is from a single positive
class. The goal of OCC is to learn a representation and/or a classifier that
enables recognition of positively labeled queries during inference. This topic
has received considerable amount of interest in the computer vision, machine
learning and biometrics communities in recent years. In this article, we
provide a survey of classical statistical and recent deep learning-based OCC
methods for visual recognition. We discuss the merits and drawbacks of existing
OCC approaches and identify promising avenues for research in this field. In
addition, we present a discussion of commonly used datasets and evaluation
metrics for OCC.
</p>
<a href="http://arxiv.org/abs/2101.03064" target="_blank">arXiv:2101.03064</a> [<a href="http://arxiv.org/pdf/2101.03064" target="_blank">pdf</a>]

<h2>Learning non-Gaussian graphical models via Hessian scores and triangular transport. (arXiv:2101.03093v1 [stat.ML])</h2>
<h3>Ricardo Baptista, Youssef Marzouk, Rebecca E. Morrison, Olivier Zahm</h3>
<p>Undirected probabilistic graphical models represent the conditional
dependencies, or Markov properties, of a collection of random variables.
Knowing the sparsity of such a graphical model is valuable for modeling
multivariate distributions and for efficiently performing inference. While the
problem of learning graph structure from data has been studied extensively for
certain parametric families of distributions, most existing methods fail to
consistently recover the graph structure for non-Gaussian data. Here we propose
an algorithm for learning the Markov structure of continuous and non-Gaussian
distributions. To characterize conditional independence, we introduce a score
based on integrated Hessian information from the joint log-density, and we
prove that this score upper bounds the conditional mutual information for a
general class of distributions. To compute the score, our algorithm SING
estimates the density using a deterministic coupling, induced by a triangular
transport map, and iteratively exploits sparse structure in the map to reveal
sparsity in the graph. For certain non-Gaussian datasets, we show that our
algorithm recovers the graph structure even with a biased approximation to the
density. Among other examples, we apply sing to learn the dependencies between
the states of a chaotic dynamical system with local interactions.
</p>
<a href="http://arxiv.org/abs/2101.03093" target="_blank">arXiv:2101.03093</a> [<a href="http://arxiv.org/pdf/2101.03093" target="_blank">pdf</a>]

<h2>An Efficient K-means Clustering Algorithm for Analysing COVID-19. (arXiv:2101.03140v1 [cs.LG])</h2>
<h3>Md. Zubair, MD.Asif Iqbal, Avijeet Shil, Enamul Haque, Mohammed Moshiul Hoque, Iqbal H. Sarker</h3>
<p>COVID-19 hits the world like a storm by arising pandemic situations for most
of the countries around the world. The whole world is trying to overcome this
pandemic situation. A better health care quality may help a country to tackle
the pandemic. Making clusters of countries with similar types of health care
quality provides an insight into the quality of health care in different
countries. In the area of machine learning and data science, the K-means
clustering algorithm is typically used to create clusters based on similarity.
In this paper, we propose an efficient K-means clustering method that
determines the initial centroids of the clusters efficiently. Based on this
proposed method, we have determined health care quality clusters of countries
utilizing the COVID-19 datasets. Experimental results show that our proposed
method reduces the number of iterations and execution time to analyze COVID-19
while comparing with the traditional k-means clustering algorithm.
</p>
<a href="http://arxiv.org/abs/2101.03140" target="_blank">arXiv:2101.03140</a> [<a href="http://arxiv.org/pdf/2101.03140" target="_blank">pdf</a>]

<h2>An Isolation Forest Learning Based Outlier Detection Approach for Effectively Classifying Cyber Anomalies. (arXiv:2101.03141v1 [cs.LG])</h2>
<h3>Rony Chowdhury Ripan, Iqbal H. Sarker, Md Musfique Anwar, Md. Hasan Furhad, Fazle Rahat, Mohammed Moshiul Hoque, Muhammad Sarfraz</h3>
<p>Cybersecurity has recently gained considerable interest in today's security
issues because of the popularity of the Internet-of-Things (IoT), the
considerable growth of mobile networks, and many related apps. Therefore,
detecting numerous cyber-attacks in a network and creating an effective
intrusion detection system plays a vital role in today's security. In this
paper, we present an Isolation Forest Learning-Based Outlier Detection Model
for effectively classifying cyber anomalies. In order to evaluate the efficacy
of the resulting Outlier Detection model, we also use several conventional
machine learning approaches, such as Logistic Regression (LR), Support Vector
Machine (SVM), AdaBoost Classifier (ABC), Naive Bayes (NB), and K-Nearest
Neighbor (KNN). The effectiveness of our proposed Outlier Detection model is
evaluated by conducting experiments on Network Intrusion Dataset with
evaluation metrics such as precision, recall, F1-score, and accuracy.
Experimental results show that the classification accuracy of cyber anomalies
has been improved after removing outliers.
</p>
<a href="http://arxiv.org/abs/2101.03141" target="_blank">arXiv:2101.03141</a> [<a href="http://arxiv.org/pdf/2101.03141" target="_blank">pdf</a>]

<h2>VisualVoice: Audio-Visual Speech Separation with Cross-Modal Consistency. (arXiv:2101.03149v1 [cs.CV])</h2>
<h3>Ruohan Gao, Kristen Grauman</h3>
<p>We introduce a new approach for audio-visual speech separation. Given a
video, the goal is to extract the speech associated with a face in spite of
simultaneous background sounds and/or other human speakers. Whereas existing
methods focus on learning the alignment between the speaker's lip movements and
the sounds they generate, we propose to leverage the speaker's face appearance
as an additional prior to isolate the corresponding vocal qualities they are
likely to produce. Our approach jointly learns audio-visual speech separation
and cross-modal speaker embeddings from unlabeled video. It yields
state-of-the-art results on five benchmark datasets for audio-visual speech
separation and enhancement, and generalizes well to challenging real-world
videos of diverse scenarios. Our video results and code:
this http URL
</p>
<a href="http://arxiv.org/abs/2101.03149" target="_blank">arXiv:2101.03149</a> [<a href="http://arxiv.org/pdf/2101.03149" target="_blank">pdf</a>]

<h2>Quantum Tensor Network in Machine Learning: An Application to Tiny Object Classification. (arXiv:2101.03154v1 [cs.CV])</h2>
<h3>Fanjie Kong, Xiao-yang Liu, Ricardo Henao</h3>
<p>Tiny object classification problem exists in many machine learning
applications like medical imaging or remote sensing, where the object of
interest usually occupies a small region of the whole image. It is challenging
to design an efficient machine learning model with respect to tiny object of
interest. Current neural network structures are unable to deal with tiny object
efficiently because they are mainly developed for images featured by large
scale objects. However, in quantum physics, there is a great theoretical
foundation guiding us to analyze the target function for image classification
regarding to specific objects size ratio. In our work, we apply Tensor Networks
to solve this arising tough machine learning problem. First, we summarize the
previous work that connects quantum spin model to image classification and
bring the theory into the scenario of tiny object classification. Second, we
propose using 2D multi-scale entanglement renormalization ansatz (MERA) to
classify tiny objects in image. In the end, our experimental results indicate
that tensor network models are effective for tiny object classification problem
and potentially will beat state-of-the-art. Our codes will be available online
https://github.com/timqqt/MERA_Image_Classification.
</p>
<a href="http://arxiv.org/abs/2101.03154" target="_blank">arXiv:2101.03154</a> [<a href="http://arxiv.org/pdf/2101.03154" target="_blank">pdf</a>]

<h2>Ontology Reasoning with Deep Neural Networks. (arXiv:1808.07980v4 [cs.AI] UPDATED)</h2>
<h3>Patrick Hohenecker, Thomas Lukasiewicz</h3>
<p>The ability to conduct logical reasoning is a fundamental aspect of
intelligent human behavior, and thus an important problem along the way to
human-level artificial intelligence. Traditionally, logic-based symbolic
methods from the field of knowledge representation and reasoning have been used
to equip agents with capabilities that resemble human logical reasoning
qualities. More recently, however, there has been an increasing interest in
using machine learning rather than logic-based symbolic formalisms to tackle
these tasks. In this paper, we employ state-of-the-art methods for training
deep neural networks to devise a novel model that is able to learn how to
effectively perform logical reasoning in the form of basic ontology reasoning.
This is an important and at the same time very natural logical reasoning task,
which is why the presented approach is applicable to a plethora of important
real-world problems. We present the outcomes of several experiments, which show
that our model is able to learn to perform highly accurate ontology reasoning
on very large, diverse, and challenging benchmarks. Furthermore, it turned out
that the suggested approach suffers much less from different obstacles that
prohibit logic-based symbolic reasoning, and, at the same time, is surprisingly
plausible from a biological point of view.
</p>
<a href="http://arxiv.org/abs/1808.07980" target="_blank">arXiv:1808.07980</a> [<a href="http://arxiv.org/pdf/1808.07980" target="_blank">pdf</a>]

<h2>Semi-Unsupervised Learning: Clustering and Classifying using Ultra-Sparse Labels. (arXiv:1901.08560v3 [stat.ML] UPDATED)</h2>
<h3>Matthew Willetts, Stephen J Roberts, Christopher C Holmes</h3>
<p>In semi-supervised learning for classification, it is assumed that every
ground truth class of data is present in the small labelled dataset. Many
real-world sparsely-labelled datasets are plausibly not of this type. It could
easily be the case that some classes of data are found only in the unlabelled
dataset -- perhaps the labelling process was biased -- so we do not have any
labelled examples to train on for some classes. We call this learning regime
$\textit{semi-unsupervised learning}$, an extreme case of semi-supervised
learning, where some classes have no labelled exemplars in the training set.
First, we outline the pitfalls associated with trying to apply deep generative
model (DGM)-based semi-supervised learning algorithms to datasets of this type.
We then show how a combination of clustering and semi-supervised learning,
using DGMs, can be brought to bear on this problem. We study several different
datasets, showing how one can still learn effectively when half of the ground
truth classes are entirely unlabelled and the other half are sparsely labelled.
</p>
<a href="http://arxiv.org/abs/1901.08560" target="_blank">arXiv:1901.08560</a> [<a href="http://arxiv.org/pdf/1901.08560" target="_blank">pdf</a>]

<h2>An Abstraction-Free Method for Multi-Robot Temporal Logic Optimal Control Synthesis. (arXiv:1909.00526v3 [cs.RO] UPDATED)</h2>
<h3>Xusheng Luo, Yiannis Kantaros, Michael M. Zavlanos</h3>
<p>The majority of existing Linear Temporal Logic (LTL) planning methods rely on
the construction of a discrete product automaton, that combines a discrete
abstraction of robot mobility and a B$\ddot{\text{u}}$chi automaton that
captures the LTL specification. Representing this product automaton as a graph
and using graph search techniques, optimal plans that satisfy the LTL task can
be synthesized. However, constructing expressive discrete abstractions makes
the synthesis problem computationally intractable. In this paper, we propose a
new sampling-based LTL planning algorithm that does not require any discrete
abstraction of robot mobility. Instead, it incrementally builds trees that
explore the product state-space, until a maximum number of iterations is
reached or a feasible plan is found. The use of trees makes data storage and
graph search tractable, which significantly increases the scalability of our
algorithm. To accelerate the construction of feasible plans, we introduce bias
in the sampling process which is guided by transitions in the
B$\ddot{\text{u}}$chi automaton that belong to the shortest path to the
accepting states. We show that our planning algorithm, with and without bias,
is probabilistically complete and asymptotically optimal. Finally, we present
numerical experiments showing that our method outperforms relevant temporal
logic planning methods.
</p>
<a href="http://arxiv.org/abs/1909.00526" target="_blank">arXiv:1909.00526</a> [<a href="http://arxiv.org/pdf/1909.00526" target="_blank">pdf</a>]

<h2>Coarse-scale PDEs from fine-scale observations via machine learning. (arXiv:1909.05707v2 [cs.LG] UPDATED)</h2>
<h3>Seungjoon Lee, Mahdi Kooshkbaghi, Konstantinos Spiliotis, Constantinos I. Siettos, Ioannis G. Kevrekidis</h3>
<p>Complex spatiotemporal dynamics of physicochemical processes are often
modeled at a microscopic level (through e.g. atomistic, agent-based or lattice
models) based on first principles. Some of these processes can also be
successfully modeled at the macroscopic level using e.g. partial differential
equations (PDEs) describing the evolution of the right few macroscopic
observables (e.g. concentration and momentum fields). Deriving good macroscopic
descriptions (the so-called "closure problem") is often a time-consuming
process requiring deep understanding/intuition about the system of interest.
Recent developments in data science provide alternative ways to effectively
extract/learn accurate macroscopic descriptions approximating the underlying
microscopic observations. In this paper, we introduce a data-driven framework
for the identification of unavailable coarse-scale PDEs from microscopic
observations via machine learning algorithms. Specifically, using Gaussian
Processes, Artificial Neural Networks, and/or Diffusion Maps, the proposed
framework uncovers the relation between the relevant macroscopic space fields
and their time evolution (the right-hand-side of the explicitly unavailable
macroscopic PDE). Interestingly, several choices equally representative of the
data can be discovered. The framework will be illustrated through the
data-driven discovery of macroscopic, concentration-level PDEs resulting from a
fine-scale, Lattice Boltzmann level model of a reaction/transport process. Once
the coarse evolution law is identified, it can be simulated to produce
long-term macroscopic predictions. Different features (pros as well as cons) of
alternative machine learning algorithms for performing this task (Gaussian
Processes and Artificial Neural Networks), are presented and discussed.
</p>
<a href="http://arxiv.org/abs/1909.05707" target="_blank">arXiv:1909.05707</a> [<a href="http://arxiv.org/pdf/1909.05707" target="_blank">pdf</a>]

<h2>A Formal Proof of PAC Learnability for Decision Stumps. (arXiv:1911.00385v3 [cs.LG] UPDATED)</h2>
<h3>Joseph Tassarotti, Koundinya Vajjha, Anindya Banerjee, Jean-Baptiste Tristan</h3>
<p>We present a formal proof in Lean of probably approximately correct (PAC)
learnability of the concept class of decision stumps. This classic result in
machine learning theory derives a bound on error probabilities for a simple
type of classifier. Though such a proof appears simple on paper, analytic and
measure-theoretic subtleties arise when carrying it out fully formally. Our
proof is structured so as to separate reasoning about deterministic properties
of a learning function from proofs of measurability and analysis of
probabilities.
</p>
<a href="http://arxiv.org/abs/1911.00385" target="_blank">arXiv:1911.00385</a> [<a href="http://arxiv.org/pdf/1911.00385" target="_blank">pdf</a>]

<h2>Abstract Argumentation and the Rational Man. (arXiv:1911.13024v6 [cs.AI] UPDATED)</h2>
<h3>Timotheus Kampik, Juan Carlos Nieves</h3>
<p>Abstract argumentation has emerged as a method for non-monotonic reasoning
that has gained popularity in the symbolic artificial intelligence community.
In the literature, the different approaches to abstract argumentation that were
refined over the years are typically evaluated from a formal logics
perspective; an analysis that is based on models of economically rational
decision-making does not exist. In this paper, we work towards addressing this
issue by analyzing abstract argumentation from the perspective of the rational
man paradigm in microeconomic theory. To assess under which conditions abstract
argumentation-based decision-making can be considered economically rational, we
derive reference independence as a non-monotonic inference property from a
formal model of economic rationality and create a new argumentation principle
that ensures compliance with this property. We then compare the reference
independence principle with other reasoning principles, in particular with
cautious monotony and rational monotony. We show that the argumentation
semantics as proposed in Dung's seminal paper, as well as other semantics we
evaluate -- with the exception of naive semantics and the SCC-recursive CF2
semantics -- violate the reference independence principle. Consequently, we
investigate how structural properties of argumentation frameworks impact the
reference independence principle, and identify cyclic expansions (both even and
odd cycles) as the root of the problem. Finally, we put reference independence
into the context of preference-based argumentation and show that for this
argumentation variant, which explicitly models preferences, reference
independence cannot be ensured in a straight-forward manner.
</p>
<a href="http://arxiv.org/abs/1911.13024" target="_blank">arXiv:1911.13024</a> [<a href="http://arxiv.org/pdf/1911.13024" target="_blank">pdf</a>]

<h2>On the distance between two neural networks and the stability of learning. (arXiv:2002.03432v3 [cs.LG] UPDATED)</h2>
<h3>Jeremy Bernstein, Arash Vahdat, Yisong Yue, Ming-Yu Liu</h3>
<p>This paper relates parameter distance to gradient breakdown for a broad class
of nonlinear compositional functions. The analysis leads to a new distance
function called deep relative trust and a descent lemma for neural networks.
Since the resulting learning rule seems to require little to no learning rate
tuning, it may unlock a simpler workflow for training deeper and more complex
neural networks. The Python code used in this paper is here:
https://github.com/jxbz/fromage.
</p>
<a href="http://arxiv.org/abs/2002.03432" target="_blank">arXiv:2002.03432</a> [<a href="http://arxiv.org/pdf/2002.03432" target="_blank">pdf</a>]

<h2>A Measure-Theoretic Approach to Kernel Conditional Mean Embeddings. (arXiv:2002.03689v8 [cs.LG] UPDATED)</h2>
<h3>Junhyung Park, Krikamol Muandet</h3>
<p>We present an operator-free, measure-theoretic approach to the conditional
mean embedding (CME) as a random variable taking values in a reproducing kernel
Hilbert space. While the kernel mean embedding of unconditional distributions
has been defined rigorously, the existing operator-based approach of the
conditional version depends on stringent assumptions that hinder its analysis.
We overcome this limitation via a measure-theoretic treatment of CMEs. We
derive a natural regression interpretation to obtain empirical estimates, and
provide a thorough theoretical analysis thereof, including universal
consistency. As natural by-products, we obtain the conditional analogues of the
maximum mean discrepancy and Hilbert-Schmidt independence criterion, and
demonstrate their behaviour via simulations.
</p>
<a href="http://arxiv.org/abs/2002.03689" target="_blank">arXiv:2002.03689</a> [<a href="http://arxiv.org/pdf/2002.03689" target="_blank">pdf</a>]

<h2>Online Optimization with Memory and Competitive Control. (arXiv:2002.05318v3 [cs.LG] UPDATED)</h2>
<h3>Guanya Shi, Yiheng Lin, Soon-Jo Chung, Yisong Yue, Adam Wierman</h3>
<p>This paper presents competitive algorithms for a novel class of online
optimization problems with memory. We consider a setting where the learner
seeks to minimize the sum of a hitting cost and a switching cost that depends
on the previous $p$ decisions. This setting generalizes Smoothed Online Convex
Optimization. The proposed approach, Optimistic Regularized Online Balanced
Descent, achieves a constant, dimension-free competitive ratio. Further, we
show a connection between online optimization with memory and online control
with adversarial disturbances. This connection, in turn, leads to a new
constant-competitive policy for a rich class of online control problems.
</p>
<a href="http://arxiv.org/abs/2002.05318" target="_blank">arXiv:2002.05318</a> [<a href="http://arxiv.org/pdf/2002.05318" target="_blank">pdf</a>]

<h2>(De)Randomized Smoothing for Certifiable Defense against Patch Attacks. (arXiv:2002.10733v3 [cs.LG] UPDATED)</h2>
<h3>Alexander Levine, Soheil Feizi</h3>
<p>Patch adversarial attacks on images, in which the attacker can distort pixels
within a region of bounded size, are an important threat model since they
provide a quantitative model for physical adversarial attacks. In this paper,
we introduce a certifiable defense against patch attacks that guarantees for a
given image and patch attack size, no patch adversarial examples exist. Our
method is related to the broad class of randomized smoothing robustness schemes
which provide high-confidence probabilistic robustness certificates. By
exploiting the fact that patch attacks are more constrained than general sparse
attacks, we derive meaningfully large robustness certificates against them.
Additionally, in contrast to smoothing-based defenses against L_p and sparse
attacks, our defense method against patch attacks is de-randomized, yielding
improved, deterministic certificates. Compared to the existing patch
certification method proposed by Chiang et al. (2020), which relies on interval
bound propagation, our method can be trained significantly faster, achieves
high clean and certified robust accuracy on CIFAR-10, and provides certificates
at ImageNet scale. For example, for a 5-by-5 patch attack on CIFAR-10, our
method achieves up to around 57.6% certified accuracy (with a classifier with
around 83.8% clean accuracy), compared to at most 30.3% certified accuracy for
the existing method (with a classifier with around 47.8% clean accuracy). Our
results effectively establish a new state-of-the-art of certifiable defense
against patch attacks on CIFAR-10 and ImageNet. Code is available at
https://github.com/alevine0/patchSmoothing.
</p>
<a href="http://arxiv.org/abs/2002.10733" target="_blank">arXiv:2002.10733</a> [<a href="http://arxiv.org/pdf/2002.10733" target="_blank">pdf</a>]

<h2>TxSim:Modeling Training of Deep Neural Networks on Resistive Crossbar Systems. (arXiv:2002.11151v3 [cs.LG] UPDATED)</h2>
<h3>Sourjya Roy, Shrihari Sridharan, Shubham Jain, Anand Raghunathan</h3>
<p>Resistive crossbars have attracted significant interest in the design of Deep
Neural Network (DNN) accelerators due to their ability to natively execute
massively parallel vector-matrix multiplications within dense memory arrays.
However, crossbar-based computations face a major challenge due to a variety of
device and circuit-level non-idealities, which manifest as errors in the
vector-matrix multiplications and eventually degrade DNN accuracy. To address
this challenge, there is a need for tools that can model the functional impact
of non-idealities on DNN training and inference. Existing efforts towards this
goal are either limited to inference, or are too slow to be used for
large-scale DNN training. We propose TxSim, a fast and customizable modeling
framework to functionally evaluate DNN training on crossbar-based hardware
considering the impact of non-idealities. The key features of TxSim that
differentiate it from prior efforts are: (i) It comprehensively models
non-idealities during all training operations (forward propagation, backward
propagation, and weight update) and (ii) it achieves computational efficiency
by mapping crossbar evaluations to well-optimized BLAS routines and
incorporates speedup techniques to further reduce simulation time with minimal
impact on accuracy. TxSim achieves orders-of-magnitude improvement in
simulation speed over prior works, and thereby makes it feasible to evaluate
training of large-scale DNNs on crossbars. Our experiments using TxSim reveal
that the accuracy degradation in DNN training due to non-idealities can be
substantial (3%-10%) for large-scale DNNs, underscoring the need for further
research in mitigation techniques. We also analyze the impact of various device
and circuit-level parameters and the associated non-idealities to provide key
insights that can guide the design of crossbar-based DNN training accelerators.
</p>
<a href="http://arxiv.org/abs/2002.11151" target="_blank">arXiv:2002.11151</a> [<a href="http://arxiv.org/pdf/2002.11151" target="_blank">pdf</a>]

<h2>A general framework for ensemble distribution distillation. (arXiv:2002.11531v2 [stat.ML] UPDATED)</h2>
<h3>Jakob Lindqvist, Amanda Olmin, Fredrik Lindsten, Lennart Svensson</h3>
<p>Ensembles of neural networks have been shown to give better performance than
single networks, both in terms of predictions and uncertainty estimation.
Additionally, ensembles allow the uncertainty to be decomposed into aleatoric
(data) and epistemic (model) components, giving a more complete picture of the
predictive uncertainty. Ensemble distillation is the process of compressing an
ensemble into a single model, often resulting in a leaner model that still
outperforms the individual ensemble members. Unfortunately, standard
distillation erases the natural uncertainty decomposition of the ensemble. We
present a general framework for distilling both regression and classification
ensembles in a way that preserves the decomposition. We demonstrate the desired
behaviour of our framework and show that its predictive performance is on par
with standard distillation.
</p>
<a href="http://arxiv.org/abs/2002.11531" target="_blank">arXiv:2002.11531</a> [<a href="http://arxiv.org/pdf/2002.11531" target="_blank">pdf</a>]

<h2>Woodbury Transformations for Deep Generative Flows. (arXiv:2002.12229v3 [cs.LG] UPDATED)</h2>
<h3>You Lu, Bert Huang</h3>
<p>Normalizing flows are deep generative models that allow efficient likelihood
calculation and sampling. The core requirement for this advantage is that they
are constructed using functions that can be efficiently inverted and for which
the determinant of the function's Jacobian can be efficiently computed.
Researchers have introduced various such flow operations, but few of these
allow rich interactions among variables without incurring significant
computational costs. In this paper, we introduce Woodbury transformations,
which achieve efficient invertibility via the Woodbury matrix identity and
efficient determinant calculation via Sylvester's determinant identity. In
contrast with other operations used in state-of-the-art normalizing flows,
Woodbury transformations enable (1) high-dimensional interactions, (2)
efficient sampling, and (3) efficient likelihood evaluation. Other similar
operations, such as 1x1 convolutions, emerging convolutions, or periodic
convolutions allow at most two of these three advantages. In our experiments on
multiple image datasets, we find that Woodbury transformations allow learning
of higher-likelihood models than other flow architectures while still enjoying
their efficiency advantages.
</p>
<a href="http://arxiv.org/abs/2002.12229" target="_blank">arXiv:2002.12229</a> [<a href="http://arxiv.org/pdf/2002.12229" target="_blank">pdf</a>]

<h2>Spatial Information Guided Convolution for Real-Time RGBD Semantic Segmentation. (arXiv:2004.04534v2 [cs.CV] UPDATED)</h2>
<h3>Lin-Zhuo Chen, Zheng Lin, Ziqin Wang, Yong-Liang Yang, Ming-Ming Cheng</h3>
<p>3D spatial information is known to be beneficial to the semantic segmentation
task. Most existing methods take 3D spatial data as an additional input,
leading to a two-stream segmentation network that processes RGB and 3D spatial
information separately. This solution greatly increases the inference time and
severely limits its scope for real-time applications. To solve this problem, we
propose Spatial information guided Convolution (S-Conv), which allows efficient
RGB feature and 3D spatial information integration. S-Conv is competent to
infer the sampling offset of the convolution kernel guided by the 3D spatial
information, helping the convolutional layer adjust the receptive field and
adapt to geometric transformations. S-Conv also incorporates geometric
information into the feature learning process by generating spatially adaptive
convolutional weights. The capability of perceiving geometry is largely
enhanced without much affecting the amount of parameters and computational
cost. We further embed S-Conv into a semantic segmentation network, called
Spatial information Guided convolutional Network (SGNet), resulting in
real-time inference and state-of-the-art performance on NYUDv2 and SUNRGBD
datasets.
</p>
<a href="http://arxiv.org/abs/2004.04534" target="_blank">arXiv:2004.04534</a> [<a href="http://arxiv.org/pdf/2004.04534" target="_blank">pdf</a>]

<h2>Uncertainty-Aware Consistency Regularization for Cross-Domain Semantic Segmentation. (arXiv:2004.08878v3 [cs.CV] UPDATED)</h2>
<h3>Qianyu Zhou, Zhengyang Feng, Qiqi Gu, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma</h3>
<p>Unsupervised domain adaptation (UDA) aims to adapt existing models of the
source domain to a new target domain with only unlabeled data. Many
adversarial-based UDA methods involve high-instability training and have to
carefully tune the optimization procedure. Some non-adversarial UDA methods
employ a consistency regularization on the target predictions of a student
model and a teacher model under different perturbations, where the teacher
shares the same architecture with the student and is updated by the exponential
moving average of the student. However, these methods suffer from noticeable
negative transfer resulting from either the error-prone discriminator network
or the unreasonable teacher model. In this paper, we propose an
uncertainty-aware consistency regularization method for cross-domain semantic
segmentation. By exploiting the latent uncertainty information of the target
samples, more meaningful and reliable knowledge from the teacher model can be
transferred to the student model. In addition, we further reveal the reason why
the current consistency regularization is often unstable in minimizing the
distribution discrepancy. We also show that our method can effectively ease
this issue by mining the most reliable and meaningful samples with a dynamic
weighting scheme of consistency loss. Experiments demonstrate that the proposed
method outperforms the state-of-the-art methods on two domain adaptation
benchmarks, $i.e.,$ GTAV $\rightarrow $ Cityscapes and SYNTHIA $\rightarrow $
Cityscapes.
</p>
<a href="http://arxiv.org/abs/2004.08878" target="_blank">arXiv:2004.08878</a> [<a href="http://arxiv.org/pdf/2004.08878" target="_blank">pdf</a>]

<h2>Continual Deep Learning by Functional Regularisation of Memorable Past. (arXiv:2004.14070v4 [stat.ML] UPDATED)</h2>
<h3>Pingbo Pan, Siddharth Swaroop, Alexander Immer, Runa Eschenhagen, Richard E. Turner, Mohammad Emtiyaz Khan</h3>
<p>Continually learning new skills is important for intelligent systems, yet
standard deep learning methods suffer from catastrophic forgetting of the past.
Recent works address this with weight regularisation. Functional
regularisation, although computationally expensive, is expected to perform
better, but rarely does so in practice. In this paper, we fix this issue by
using a new functional-regularisation approach that utilises a few memorable
past examples crucial to avoid forgetting. By using a Gaussian Process
formulation of deep networks, our approach enables training in weight-space
while identifying both the memorable past and a functional prior. Our method
achieves state-of-the-art performance on standard benchmarks and opens a new
direction for life-long learning where regularisation and memory-based methods
are naturally combined.
</p>
<a href="http://arxiv.org/abs/2004.14070" target="_blank">arXiv:2004.14070</a> [<a href="http://arxiv.org/pdf/2004.14070" target="_blank">pdf</a>]

<h2>Ontology and Cognitive Outcomes. (arXiv:2005.08078v3 [cs.AI] UPDATED)</h2>
<h3>David Limbaugh, Jobst Landgrebe, David Kasmier, Ronald Rudnicki, James Llinas, Barry Smith</h3>
<p>Here we understand 'intelligence' as referring to items of knowledge
collected for the sake of assessing and maintaining national security. The
intelligence community (IC) of the United States (US) is a community of
organizations that collaborate in collecting and processing intelligence for
the US. The IC relies on human-machine-based analytic strategies that 1) access
and integrate vast amounts of information from disparate sources, 2)
continuously process this information, so that, 3) a maximally comprehensive
understanding of world actors and their behaviors can be developed and updated.
Herein we describe an approach to utilizing outcomes-based learning (OBL) to
support these efforts that is based on an ontology of the cognitive processes
performed by intelligence analysts. Of particular importance to the Cognitive
Process Ontology is the class Representation that is Warranted. Such a
representation is descriptive in nature and deserving of trust in its
veridicality. The latter is because a Representation that is Warranted is
always produced by a process that was vetted (or successfully designed) to
reliably produce veridical representations. As such, Representations that are
Warranted are what in other contexts we might refer to as 'items of knowledge'.
</p>
<a href="http://arxiv.org/abs/2005.08078" target="_blank">arXiv:2005.08078</a> [<a href="http://arxiv.org/pdf/2005.08078" target="_blank">pdf</a>]

<h2>Fast Unbalanced Optimal Transport on a Tree. (arXiv:2006.02703v3 [cs.LG] UPDATED)</h2>
<h3>Ryoma Sato, Makoto Yamada, Hisashi Kashima</h3>
<p>This study examines the time complexities of the unbalanced optimal transport
problems from an algorithmic perspective for the first time. We reveal which
problems in unbalanced optimal transport can/cannot be solved efficiently.
Specifically, we prove that the Kantorovich Rubinstein distance and optimal
partial transport in the Euclidean metric cannot be computed in strongly
subquadratic time under the strong exponential time hypothesis. Then, we
propose an algorithm that solves a more general unbalanced optimal transport
problem exactly in quasi-linear time on a tree metric. The proposed algorithm
processes a tree with one million nodes in less than one second. Our analysis
forms a foundation for the theoretical study of unbalanced optimal transport
algorithms and opens the door to the applications of unbalanced optimal
transport to million-scale datasets.
</p>
<a href="http://arxiv.org/abs/2006.02703" target="_blank">arXiv:2006.02703</a> [<a href="http://arxiv.org/pdf/2006.02703" target="_blank">pdf</a>]

<h2>Consistency Regularization for Certified Robustness of Smoothed Classifiers. (arXiv:2006.04062v4 [cs.LG] UPDATED)</h2>
<h3>Jongheon Jeong, Jinwoo Shin</h3>
<p>A recent technique of randomized smoothing has shown that the worst-case
(adversarial) $\ell_2$-robustness can be transformed into the average-case
Gaussian-robustness by "smoothing" a classifier, i.e., by considering the
averaged prediction over Gaussian noise. In this paradigm, one should rethink
the notion of adversarial robustness in terms of generalization ability of a
classifier under noisy observations. We found that the trade-off between
accuracy and certified robustness of smoothed classifiers can be greatly
controlled by simply regularizing the prediction consistency over noise. This
relationship allows us to design a robust training objective without
approximating a non-existing smoothed classifier, e.g., via soft smoothing. Our
experiments under various deep neural network architectures and datasets show
that the "certified" $\ell_2$-robustness can be dramatically improved with the
proposed regularization, even achieving better or comparable results to the
state-of-the-art approaches with significantly less training costs and
hyperparameters.
</p>
<a href="http://arxiv.org/abs/2006.04062" target="_blank">arXiv:2006.04062</a> [<a href="http://arxiv.org/pdf/2006.04062" target="_blank">pdf</a>]

<h2>Practical Quasi-Newton Methods for Training Deep Neural Networks. (arXiv:2006.08877v3 [cs.LG] UPDATED)</h2>
<h3>Donald Goldfarb, Yi Ren, Achraf Bahamou</h3>
<p>We consider the development of practical stochastic quasi-Newton, and in
particular Kronecker-factored block-diagonal BFGS and L-BFGS methods, for
training deep neural networks (DNNs). In DNN training, the number of variables
and components of the gradient $n$ is often of the order of tens of millions
and the Hessian has $n^2$ elements. Consequently, computing and storing a full
$n \times n$ BFGS approximation or storing a modest number of (step, change in
gradient) vector pairs for use in an L-BFGS implementation is out of the
question. In our proposed methods, we approximate the Hessian by a
block-diagonal matrix and use the structure of the gradient and Hessian to
further approximate these blocks, each of which corresponds to a layer, as the
Kronecker product of two much smaller matrices. This is analogous to the
approach in KFAC, which computes a Kronecker-factored block-diagonal
approximation to the Fisher matrix in a stochastic natural gradient method.
Because the indefinite and highly variable nature of the Hessian in a DNN, we
also propose a new damping approach to keep the upper as well as the lower
bounds of the BFGS and L-BFGS approximations bounded. In tests on autoencoder
feed-forward neural network models with either nine or thirteen layers applied
to three datasets, our methods outperformed or performed comparably to KFAC and
state-of-the-art first-order stochastic methods.
</p>
<a href="http://arxiv.org/abs/2006.08877" target="_blank">arXiv:2006.08877</a> [<a href="http://arxiv.org/pdf/2006.08877" target="_blank">pdf</a>]

<h2>Unsupervised Learning of Visual Features by Contrasting Cluster Assignments. (arXiv:2006.09882v5 [cs.CV] UPDATED)</h2>
<h3>Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, Armand Joulin</h3>
<p>Unsupervised image representations have significantly reduced the gap with
supervised pretraining, notably with the recent achievements of contrastive
learning methods. These contrastive methods typically work online and rely on a
large number of explicit pairwise feature comparisons, which is computationally
challenging. In this paper, we propose an online algorithm, SwAV, that takes
advantage of contrastive methods without requiring to compute pairwise
comparisons. Specifically, our method simultaneously clusters the data while
enforcing consistency between cluster assignments produced for different
augmentations (or views) of the same image, instead of comparing features
directly as in contrastive learning. Simply put, we use a swapped prediction
mechanism where we predict the cluster assignment of a view from the
representation of another view. Our method can be trained with large and small
batches and can scale to unlimited amounts of data. Compared to previous
contrastive methods, our method is more memory efficient since it does not
require a large memory bank or a special momentum network. In addition, we also
propose a new data augmentation strategy, multi-crop, that uses a mix of views
with different resolutions in place of two full-resolution views, without
increasing the memory or compute requirements much. We validate our findings by
achieving 75.3% top-1 accuracy on ImageNet with ResNet-50, as well as
surpassing supervised pretraining on all the considered transfer tasks.
</p>
<a href="http://arxiv.org/abs/2006.09882" target="_blank">arXiv:2006.09882</a> [<a href="http://arxiv.org/pdf/2006.09882" target="_blank">pdf</a>]

<h2>Hyperparameter Ensembles for Robustness and Uncertainty Quantification. (arXiv:2006.13570v3 [cs.LG] UPDATED)</h2>
<h3>Florian Wenzel, Jasper Snoek, Dustin Tran, Rodolphe Jenatton</h3>
<p>Ensembles over neural network weights trained from different random
initialization, known as deep ensembles, achieve state-of-the-art accuracy and
calibration. The recently introduced batch ensembles provide a drop-in
replacement that is more parameter efficient. In this paper, we design
ensembles not only over weights, but over hyperparameters to improve the state
of the art in both settings. For best performance independent of budget, we
propose hyper-deep ensembles, a simple procedure that involves a random search
over different hyperparameters, themselves stratified across multiple random
initializations. Its strong performance highlights the benefit of combining
models with both weight and hyperparameter diversity. We further propose a
parameter efficient version, hyper-batch ensembles, which builds on the layer
structure of batch ensembles and self-tuning networks. The computational and
memory costs of our method are notably lower than typical ensembles. On image
classification tasks, with MLP, LeNet, ResNet 20 and Wide ResNet 28-10
architectures, we improve upon both deep and batch ensembles.
</p>
<a href="http://arxiv.org/abs/2006.13570" target="_blank">arXiv:2006.13570</a> [<a href="http://arxiv.org/pdf/2006.13570" target="_blank">pdf</a>]

<h2>AvE: Assistance via Empowerment. (arXiv:2006.14796v5 [cs.AI] UPDATED)</h2>
<h3>Yuqing Du, Stas Tiomkin, Emre Kiciman, Daniel Polani, Pieter Abbeel, Anca Dragan</h3>
<p>One difficulty in using artificial agents for human-assistive applications
lies in the challenge of accurately assisting with a person's goal(s). Existing
methods tend to rely on inferring the human's goal, which is challenging when
there are many potential goals or when the set of candidate goals is difficult
to identify. We propose a new paradigm for assistance by instead increasing the
human's ability to control their environment, and formalize this approach by
augmenting reinforcement learning with human empowerment. This task-agnostic
objective preserves the person's autonomy and ability to achieve any eventual
state. We test our approach against assistance based on goal inference,
highlighting scenarios where our method overcomes failure modes stemming from
goal ambiguity or misspecification. As existing methods for estimating
empowerment in continuous domains are computationally hard, precluding its use
in real time learned assistance, we also propose an efficient
empowerment-inspired proxy metric. Using this, we are able to successfully
demonstrate our method in a shared autonomy user study for a challenging
simulated teleoperation task with human-in-the-loop training.
</p>
<a href="http://arxiv.org/abs/2006.14796" target="_blank">arXiv:2006.14796</a> [<a href="http://arxiv.org/pdf/2006.14796" target="_blank">pdf</a>]

<h2>Learning intuitive physics and one-shot imitation using state-action-prediction self-organizing maps. (arXiv:2007.01647v2 [cs.AI] UPDATED)</h2>
<h3>Martin Stetter, Elmar W. Lang</h3>
<p>Human learning and intelligence work differently from the supervised pattern
recognition approach adopted in most deep learning architectures. Humans seem
to learn rich representations by exploration and imitation, build causal models
of the world, and use both to flexibly solve new tasks. We suggest a simple but
effective unsupervised model which develops such characteristics. The agent
learns to represent the dynamical physical properties of its environment by
intrinsically motivated exploration, and performs inference on this
representation to reach goals. For this, a set of self-organizing maps which
represent state-action pairs is combined with a causal model for sequence
prediction. The proposed system is evaluated in the cartpole environment. After
an initial phase of playful exploration, the agent can execute kinematic
simulations of the environment's future, and use those for action planning. We
demonstrate its performance on a set of several related, but different one-shot
imitation tasks, which the agent flexibly solves in an active inference style.
</p>
<a href="http://arxiv.org/abs/2007.01647" target="_blank">arXiv:2007.01647</a> [<a href="http://arxiv.org/pdf/2007.01647" target="_blank">pdf</a>]

<h2>NVAE: A Deep Hierarchical Variational Autoencoder. (arXiv:2007.03898v3 [stat.ML] UPDATED)</h2>
<h3>Arash Vahdat, Jan Kautz</h3>
<p>Normalizing flows, autoregressive models, variational autoencoders (VAEs),
and deep energy-based models are among competing likelihood-based frameworks
for deep generative learning. Among them, VAEs have the advantage of fast and
tractable sampling and easy-to-access encoding networks. However, they are
currently outperformed by other models such as normalizing flows and
autoregressive models. While the majority of the research in VAEs is focused on
the statistical challenges, we explore the orthogonal direction of carefully
designing neural architectures for hierarchical VAEs. We propose Nouveau VAE
(NVAE), a deep hierarchical VAE built for image generation using depth-wise
separable convolutions and batch normalization. NVAE is equipped with a
residual parameterization of Normal distributions and its training is
stabilized by spectral regularization. We show that NVAE achieves
state-of-the-art results among non-autoregressive likelihood-based models on
the MNIST, CIFAR-10, CelebA 64, and CelebA HQ datasets and it provides a strong
baseline on FFHQ. For example, on CIFAR-10, NVAE pushes the state-of-the-art
from 2.98 to 2.91 bits per dimension, and it produces high-quality images on
CelebA HQ. To the best of our knowledge, NVAE is the first successful VAE
applied to natural images as large as 256$\times$256 pixels. The source code is
available at https://github.com/NVlabs/NVAE .
</p>
<a href="http://arxiv.org/abs/2007.03898" target="_blank">arXiv:2007.03898</a> [<a href="http://arxiv.org/pdf/2007.03898" target="_blank">pdf</a>]

<h2>Statistical post-processing of wind speed forecasts using convolutional neural networks. (arXiv:2007.04005v2 [stat.ML] UPDATED)</h2>
<h3>Simon Veldkamp, Kirien Whan, Sjoerd Dirksen, Maurice Schmeits</h3>
<p>Current statistical post-processing methods for probabilistic weather
forecasting are not capable of using full spatial patterns from the numerical
weather prediction (NWP) model. In this paper we incorporate spatial wind speed
information by using convolutional neural networks (CNNs) and obtain
probabilistic wind speed forecasts in the Netherlands for 48 hours ahead, based
on KNMI's deterministic Harmonie-Arome NWP model. The probabilistic forecasts
from the CNNs are shown to have higher Brier skill scores for medium to higher
wind speeds, as well as a better continuous ranked probability score (CRPS) and
logarithmic score, than the forecasts from fully connected neural networks and
quantile regression forests. As a secondary result, we have compared the CNNs
using 3 different density estimation methods (quantized softmax (QS), kernel
mixture networks, and fitting a truncated normal distribution), and found the
probabilistic forecasts based on the QS method to be best.
</p>
<a href="http://arxiv.org/abs/2007.04005" target="_blank">arXiv:2007.04005</a> [<a href="http://arxiv.org/pdf/2007.04005" target="_blank">pdf</a>]

<h2>TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning. (arXiv:2007.11622v4 [cs.CV] UPDATED)</h2>
<h3>Han Cai, Chuang Gan, Ligeng Zhu, Song Han</h3>
<p>On-device learning enables edge devices to continually adapt the AI models to
new data, which requires a small memory footprint to fit the tight memory
constraint of edge devices. Existing work solves this problem by reducing the
number of trainable parameters. However, this doesn't directly translate to
memory saving since the major bottleneck is the activations, not parameters. In
this work, we present Tiny-Transfer-Learning (TinyTL) for memory-efficient
on-device learning. TinyTL freezes the weights while only learns the bias
modules, thus no need to store the intermediate activations. To maintain the
adaptation capacity, we introduce a new memory-efficient bias module, the lite
residual module, to refine the feature extractor by learning small residual
feature maps adding only 3.8% memory overhead. Extensive experiments show that
TinyTL significantly saves the memory (up to 6.5x) with little accuracy loss
compared to fine-tuning the full network. Compared to fine-tuning the last
layer, TinyTL provides significant accuracy improvements (up to 34.1%) with
little memory overhead. Furthermore, combined with feature extractor
adaptation, TinyTL provides 7.3-12.9x memory saving without sacrificing
accuracy compared to fine-tuning the full Inception-V3.
</p>
<a href="http://arxiv.org/abs/2007.11622" target="_blank">arXiv:2007.11622</a> [<a href="http://arxiv.org/pdf/2007.11622" target="_blank">pdf</a>]

<h2>Approximation Benefits of Policy Gradient Methods with Aggregated States. (arXiv:2007.11684v2 [cs.LG] UPDATED)</h2>
<h3>Daniel Russo</h3>
<p>Folklore suggests that policy gradient can be more robust to misspecification
than its relative, approximate policy iteration. This paper studies the case of
state-aggregation, where the state space is partitioned and either the policy
or value function approximation is held constant over partitions. This paper
shows a policy gradient method converges to a policy whose regret per-period is
bounded by $\epsilon$, the largest difference between two elements of the
state-action value function belonging to a common partition. With the same
representation, both approximate policy iteration and approximate value
iteration can produce policies whose per-period regret scales as
$\epsilon/(1-\gamma)$, where $\gamma$ is a discount factor. Theoretical results
synthesize recent analysis of policy gradient methods with insights of Van Roy
(2006) into the critical role of state-relevance weights in approximate dynamic
programming.
</p>
<a href="http://arxiv.org/abs/2007.11684" target="_blank">arXiv:2007.11684</a> [<a href="http://arxiv.org/pdf/2007.11684" target="_blank">pdf</a>]

<h2>T-BFA: Targeted Bit-Flip Adversarial Weight Attack. (arXiv:2007.12336v3 [cs.LG] UPDATED)</h2>
<h3>Adnan Siraj Rakin, Zhezhi He, Jingtao Li, Fan Yao, Chaitali Chakrabarti, Deliang Fan</h3>
<p>Traditional Deep Neural Network (DNN) security is mostly related to the
well-known adversarial input example attack. Recently, another dimension of
adversarial attack, namely, attack on DNN weight parameters, has been shown to
be very powerful. As a representative one, the Bit-Flip-based adversarial
weight Attack (BFA) injects an extremely small amount of faults into weight
parameters to hijack the executing DNN function. Prior works of BFA focus on
un-targeted attack that can hack all inputs into a random output class by
flipping a very small number of weight bits stored in computer memory. This
paper proposes the first work of targeted BFA based (T-BFA) adversarial weight
attack on DNNs, which can intentionally mislead selected inputs to a target
output class. The objective is achieved by identifying the weight bits that are
highly associated with classification of a targeted output through a
class-dependent weight bit ranking algorithm. Our proposed T-BFA performance is
successfully demonstrated on multiple DNN architectures for image
classification tasks. For example, by merely flipping 27 out of 88 million
weight bits of ResNet-18, our T-BFA can misclassify all the images from 'Hen'
class into 'Goose' class (i.e., 100 % attack success rate) in ImageNet dataset,
while maintaining 59.35 % validation accuracy. Moreover, we successfully
demonstrate our T-BFA attack in a real computer prototype system running DNN
computation, with Ivy Bridge-based Intel i7 CPU and 8GB DDR3 memory.
</p>
<a href="http://arxiv.org/abs/2007.12336" target="_blank">arXiv:2007.12336</a> [<a href="http://arxiv.org/pdf/2007.12336" target="_blank">pdf</a>]

<h2>Big Bird: Transformers for Longer Sequences. (arXiv:2007.14062v2 [cs.LG] UPDATED)</h2>
<h3>Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed</h3>
<p>Transformers-based models, such as BERT, have been one of the most successful
deep learning models for NLP. Unfortunately, one of their core limitations is
the quadratic dependency (mainly in terms of memory) on the sequence length due
to their full attention mechanism. To remedy this, we propose, BigBird, a
sparse attention mechanism that reduces this quadratic dependency to linear. We
show that BigBird is a universal approximator of sequence functions and is
Turing complete, thereby preserving these properties of the quadratic, full
attention model. Along the way, our theoretical analysis reveals some of the
benefits of having $O(1)$ global tokens (such as CLS), that attend to the
entire sequence as part of the sparse attention mechanism. The proposed sparse
attention can handle sequences of length up to 8x of what was previously
possible using similar hardware. As a consequence of the capability to handle
longer context, BigBird drastically improves performance on various NLP tasks
such as question answering and summarization. We also propose novel
applications to genomics data.
</p>
<a href="http://arxiv.org/abs/2007.14062" target="_blank">arXiv:2007.14062</a> [<a href="http://arxiv.org/pdf/2007.14062" target="_blank">pdf</a>]

<h2>Associating Uncertainty to Extended Poses for on Lie Group IMU Preintegration with Rotating Earth. (arXiv:2007.14097v2 [cs.RO] UPDATED)</h2>
<h3>Martin Brossard (CAOR), Axel Barrau, Paul Chauchat (ISAE-SUPAERO), Silv&#xe8;re Bonnabel (ISEA)</h3>
<p>The recently introduced matrix group SE2(3) provides a 5x5 matrix
representation for the orientation, velocity and position of an object in the
3-D space, a triplet we call "extended pose". In this paper we build on this
group to develop a theory to associate uncertainty with extended poses
represented by 5x5 matrices. Our approach is particularly suited to describe
how uncertainty propagates when the extended pose represents the state of an
Inertial Measurement Unit (IMU). In particular it allows revisiting the theory
of IMU preintegration on manifold and reaching a further theoretic level in
this field. Exact preintegration formulas that account for rotating Earth, that
is, centrifugal force and Coriolis force, are derived as a byproduct, and the
factors are shown to be more accurate. The approach is validated through
extensive simulations and applied to sensor-fusion where a loosely-coupled
fixed-lag smoother fuses IMU and LiDAR on one hour long experiments using our
experimental car. It shows how handling rotating Earth may be beneficial for
long-term navigation within incremental smoothing algorithms.
</p>
<a href="http://arxiv.org/abs/2007.14097" target="_blank">arXiv:2007.14097</a> [<a href="http://arxiv.org/pdf/2007.14097" target="_blank">pdf</a>]

<h2>Flood Extent Mapping based on High Resolution Aerial Imagery and DEM: A Hidden Markov Tree Approach. (arXiv:2008.11230v2 [cs.CV] UPDATED)</h2>
<h3>Zhe Jiang, Arpan Man Sainju</h3>
<p>Flood extent mapping plays a crucial role in disaster management and national
water forecasting. In recent years, high-resolution optical imagery becomes
increasingly available with the deployment of numerous small satellites and
drones. However, analyzing such imagery data to extract flood extent poses
unique challenges due to the rich noise and shadows, obstacles (e.g., tree
canopies, clouds), and spectral confusion between pixel classes (flood, dry)
due to spatial heterogeneity. Existing machine learning techniques often focus
on spectral and spatial features from raster images without fully incorporating
the geographic terrain within classification models. In contrast, we recently
proposed a novel machine learning model called geographical hidden Markov tree
that integrates spectral features of pixels and topographic constraints from
Digital Elevation Model (DEM) data (i.e., water flow directions) in a holistic
manner. This paper evaluates the model through case studies on high-resolution
aerial imagery from the National Oceanic and Atmospheric Administration (NOAA)
National Geodetic Survey together with DEM. Three scenes are selected in
heavily vegetated floodplains near the cities of Grimesland and Kinston in
North Carolina during Hurricane Matthew floods in 2016. Results show that the
proposed hidden Markov tree model outperforms several state of the art machine
learning algorithms (e.g., random forests, gradient boosted model) by an
improvement of F-score (the harmonic mean of the user's accuracy and producer's
accuracy) from around 70% to 80% to over 95% on our datasets.
</p>
<a href="http://arxiv.org/abs/2008.11230" target="_blank">arXiv:2008.11230</a> [<a href="http://arxiv.org/pdf/2008.11230" target="_blank">pdf</a>]

<h2>A Density-Aware PointRCNN for 3D Object Detection in Point Clouds. (arXiv:2009.05307v2 [cs.CV] UPDATED)</h2>
<h3>Jie Li, Yu Hu</h3>
<p>We present an improved version of PointRCNN for 3D object detection, in which
a multi-branch backbone network is adopted to handle the non-uniform density of
point clouds. An uncertainty-based sampling policy is proposed to deal with the
distribution differences of different point clouds. The new model can achieve
about 0.8 AP higher performance than the baseline PointRCNN on KITTI val set.
In addition, a simplified model using a single scale grouping for each
set-abstraction layer can achieve competitive performance with less
computational cost.
</p>
<a href="http://arxiv.org/abs/2009.05307" target="_blank">arXiv:2009.05307</a> [<a href="http://arxiv.org/pdf/2009.05307" target="_blank">pdf</a>]

<h2>Invertible DenseNets. (arXiv:2010.02125v3 [cs.LG] UPDATED)</h2>
<h3>Yura Perugachi-Diaz, Jakub M. Tomczak, Sandjai Bhulai</h3>
<p>We introduce Invertible Dense Networks (i-DenseNets), a more parameter
efficient alternative to Residual Flows. The method relies on an analysis of
the Lipschitz continuity of the concatenation in DenseNets, where we enforce
the invertibility of the network by satisfying the Lipschitz constraint.
Additionally, we extend this method by proposing a learnable concatenation,
which not only improves the model performance but also indicates the importance
of the concatenated representation. We demonstrate the performance of
i-DenseNets and Residual Flows on toy, MNIST, and CIFAR10 data. Both
i-DenseNets outperform Residual Flows evaluated in negative log-likelihood, on
all considered datasets under an equal parameter budget.
</p>
<a href="http://arxiv.org/abs/2010.02125" target="_blank">arXiv:2010.02125</a> [<a href="http://arxiv.org/pdf/2010.02125" target="_blank">pdf</a>]

<h2>Multi-path Neural Networks for On-device Multi-domain Visual Classification. (arXiv:2010.04904v2 [cs.CV] UPDATED)</h2>
<h3>Qifei Wang, Junjie Ke, Joshua Greaves, Grace Chu, Gabriel Bender, Luciano Sbaiz, Alec Go, Andrew Howard, Feng Yang, Ming-Hsuan Yang, Jeff Gilbert, Peyman Milanfar</h3>
<p>Learning multiple domains/tasks with a single model is important for
improving data efficiency and lowering inference cost for numerous vision
tasks, especially on resource-constrained mobile devices. However,
hand-crafting a multi-domain/task model can be both tedious and challenging.
This paper proposes a novel approach to automatically learn a multi-path
network for multi-domain visual classification on mobile devices. The proposed
multi-path network is learned from neural architecture search by applying one
reinforcement learning controller for each domain to select the best path in
the super-network created from a MobileNetV3-like search space. An adaptive
balanced domain prioritization algorithm is proposed to balance optimizing the
joint model on multiple domains simultaneously. The determined multi-path model
selectively shares parameters across domains in shared nodes while keeping
domain-specific parameters within non-shared nodes in individual domain paths.
This approach effectively reduces the total number of parameters and FLOPS,
encouraging positive knowledge transfer while mitigating negative interference
across domains. Extensive evaluations on the Visual Decathlon dataset
demonstrate that the proposed multi-path model achieves state-of-the-art
performance in terms of accuracy, model size, and FLOPS against other
approaches using MobileNetV3-like architectures. Furthermore, the proposed
method improves average accuracy over learning single-domain models
individually, and reduces the total number of parameters and FLOPS by 78% and
32% respectively, compared to the approach that simply bundles single-domain
models for multi-domain learning.
</p>
<a href="http://arxiv.org/abs/2010.04904" target="_blank">arXiv:2010.04904</a> [<a href="http://arxiv.org/pdf/2010.04904" target="_blank">pdf</a>]

<h2>FedGroup: Accurate Federated Learning via Decomposed Similarity-Based Clustering. (arXiv:2010.06870v3 [cs.LG] UPDATED)</h2>
<h3>Moming Duan, Duo Liu, Xinyuan Ji, Renping Liu, Liang Liang, Xianzhang Chen, Yujuan Tan</h3>
<p>Federated Learning (FL) enables the multiple participating devices to
collaboratively contribute to a global neural network model while keeping the
training data locally. Unlike the centralized training setting, the non-IID and
imbalanced (statistical heterogeneity) training data of FL is distributed in
the federated network, which will increase the divergences between the local
models and global model, further degrading performance. In this paper, we
propose a novel clustered federated learning (CFL) framework FedGroup based on
a similarity-based client clustering strategy, in which we 1) group the
training of clients based on the similarities between the clients' optimize
directions for high training performance; 2) reduce the complexity of client
clustering algorithm by decomposing the high-dimension low-sample size (HDLSS)
direction vectors. 3) implement a newcomer device cold start mechanism based on
the auxiliary global model for framework scalability and practicality.

FedGroup can achieve improvements by dividing joint optimization into groups
of sub-optimization, and can be combined with FedProx, the state-of-the-art
federated optimization algorithm. We evaluate FedGroup and FedGrouProx
(combined with FedProx) on several open datasets. The experimental results show
that our proposed frameworks significantly improving absolute test accuracy by
+14.7% on FEMNIST compared to FedAvg, +5.4% on Sentiment140 compared to
FedProx.
</p>
<a href="http://arxiv.org/abs/2010.06870" target="_blank">arXiv:2010.06870</a> [<a href="http://arxiv.org/pdf/2010.06870" target="_blank">pdf</a>]

<h2>Faithful Euclidean Distance Field from Log-Gaussian Process Implicit Surfaces. (arXiv:2010.11487v2 [cs.RO] UPDATED)</h2>
<h3>Lan Wu, Ki Myung Brian Lee, Liyang Liu, Teresa Vidal-Calleja</h3>
<p>In this letter, we introduce the Log-Gaussian Process Implicit Surface
(Log-GPIS), a novel continuous and probabilistic mapping representation
suitable for surface reconstruction and local navigation. Our key contribution
is the realisation that the regularised Eikonal equation can be simply solved
by applying the logarithmic transformation to a GPIS formulation to recover the
accurate Euclidean distance field (EDF) and, at the same time, the implicit
surface. To derive the proposed representation, Varadhan's formula is exploited
to approximate the non-linear Eikonal partial differential equation (PDE) of
the EDF by the logarithm of a linear PDE. We show that members of the Matern
covariance family directly satisfy this linear PDE. The proposed approach does
not require post-processing steps to recover the EDF. Moreover, unlike
sampling-based methods, Log-GPIS does not use sample points inside and outside
the surface as the derivative of the covariance allow direct estimation of the
surface normals and distance gradients. We benchmarked the proposed method on
simulated and real data against state-of-the-art mapping frameworks that also
aim at recovering both the surface and a distance field. Our experiments show
that Log-GPIS produces the most accurate results for the EDF and comparable
results for surface reconstruction and its computation time still allows online
operations.
</p>
<a href="http://arxiv.org/abs/2010.11487" target="_blank">arXiv:2010.11487</a> [<a href="http://arxiv.org/pdf/2010.11487" target="_blank">pdf</a>]

<h2>Byzantine Resilient Distributed Multi-Task Learning. (arXiv:2010.13032v2 [cs.LG] UPDATED)</h2>
<h3>Jiani Li, Waseem Abbas, Xenofon Koutsoukos</h3>
<p>Distributed multi-task learning provides significant advantages in
multi-agent networks with heterogeneous data sources where agents aim to learn
distinct but correlated models simultaneously.However, distributed algorithms
for learning relatedness among tasks are not resilient in the presence of
Byzantine agents. In this paper, we present an approach for Byzantine resilient
distributed multi-task learning. We propose an efficient online weight
assignment rule by measuring the accumulated loss using an agent's data and its
neighbors' models. A small accumulated loss indicates a large similarity
between the two tasks. In order to ensure the Byzantine resilience of the
aggregation at a normal agent, we introduce a step for filtering out larger
losses. We analyze the approach for convex models and show that normal agents
converge resiliently towards the global minimum.Further, aggregation with the
proposed weight assignment rule always results in an improved expected regret
than the non-cooperative case. Finally, we demonstrate the approach using three
case studies, including regression and classification problems, and show that
our method exhibits good empirical performance for non-convex models, such as
convolutional neural networks.
</p>
<a href="http://arxiv.org/abs/2010.13032" target="_blank">arXiv:2010.13032</a> [<a href="http://arxiv.org/pdf/2010.13032" target="_blank">pdf</a>]

<h2>Active and Interactive Mapping with Dynamic Gaussian Process Implicit Surfaces for Mobile Manipulators. (arXiv:2010.13108v2 [cs.RO] UPDATED)</h2>
<h3>Liyang Liu, Simon Fryc, Lan Wu, Thanh Vu, Gavin Paul, Teresa Vidal-Calleja</h3>
<p>In this letter, we present an interactive probabilistic mapping framework for
a mobile manipulator picking objects from a pile. The aim is to map the scene,
actively decide where to go next and which object to pick, make changes to the
scene by picking the chosen object, and then map these changes alongside. The
proposed framework uses a novel dynamic Gaussian Process (GP) Implicit Surface
method to incrementally build and update the scene map that reflects
environment changes. Actively the framework provides the next-best-view,
balancing the need for picking object reachability with map information gain
(IG). To enforce a priority of visiting boundary segments over unknown regions,
the IG formulation includes an uncertainty gradient-based frontier score by
exploiting the GP kernel derivative. This leads to an efficient strategy that
addresses the often conflicting requirement of unknown environment exploration
and object picking exploitation given a limited execution horizon. We
demonstrate the effectiveness of our framework with software simulation and
real-life experiments.
</p>
<a href="http://arxiv.org/abs/2010.13108" target="_blank">arXiv:2010.13108</a> [<a href="http://arxiv.org/pdf/2010.13108" target="_blank">pdf</a>]

<h2>Probabilistic Load Forecasting Based on Adaptive Online Learning. (arXiv:2011.14721v2 [cs.LG] UPDATED)</h2>
<h3>Ver&#xf3;nica &#xc1;lvarez, Santiago Mazuelas, Jos&#xe9; A. Lozano</h3>
<p>Load forecasting is crucial for multiple energy management tasks such as
scheduling generation capacity, planning supply and demand, and minimizing
energy trade costs. Such relevance has increased even more in recent years due
to the integration of renewable energies, electric cars, and microgrids.
Conventional load forecasting techniques obtain single-value load forecasts by
exploiting consumption patterns of past load demand. However, such techniques
cannot assess intrinsic uncertainties in load demand, and cannot capture
dynamic changes in consumption patterns. To address these problems, this paper
presents a method for probabilistic load forecasting based on the adaptive
online learning of hidden Markov models. We propose learning and forecasting
techniques with theoretical guarantees, and experimentally assess their
performance in multiple scenarios. In particular, we develop adaptive online
learning techniques that update model parameters recursively, and sequential
prediction techniques that obtain probabilistic forecasts using the most recent
parameters. The performance of the method is evaluated using multiple datasets
corresponding with regions that have different sizes and display assorted
time-varying consumption patterns. The results show that the proposed method
can significantly improve the performance of existing techniques for a wide
range of scenarios.
</p>
<a href="http://arxiv.org/abs/2011.14721" target="_blank">arXiv:2011.14721</a> [<a href="http://arxiv.org/pdf/2011.14721" target="_blank">pdf</a>]

<h2>How Many Annotators Do We Need? -- A Study on the Influence of Inter-Observer Variability on the Reliability of Automatic Mitotic Figure Assessment. (arXiv:2012.02495v2 [cs.CV] UPDATED)</h2>
<h3>Frauke Wilm, Christof A. Bertram, Christian Marzahl, Alexander Bartel, Taryn A. Donovan, Charles-Antoine Assenmacher, Kathrin Becker, Mark Bennett, Sarah Corner, Brieuc Cossic, Daniela Denk, Martina Dettwiler, Beatriz Garcia Gonzalez, Corinne Gurtner, Annika Lehmbecker, Sophie Merz, Stephanie Plog, Anja Schmidt, Rebecca C. Smedley, Marco Tecilla, Tuddow Thaiwong, Katharina Breininger, Matti Kiupel, Andreas Maier, Robert Klopfleisch, Marc Aubreville</h3>
<p>Density of mitotic figures in histologic sections is a prognostically
relevant characteristic for many tumours. Due to high inter-pathologist
variability, deep learning-based algorithms are a promising solution to improve
tumour prognostication. Pathologists are the gold standard for database
development, however, labelling errors may hamper development of accurate
algorithms. In the present work we evaluated the benefit of multi-expert
consensus (n = 3, 5, 7, 9, 11) on algorithmic performance. While training with
individual databases resulted in highly variable F$_1$ scores, performance was
notably increased and more consistent when using the consensus of three
annotators. Adding more annotators only resulted in minor improvements. We
conclude that databases by few pathologists and high label accuracy may be the
best compromise between high algorithmic performance and time investment.
</p>
<a href="http://arxiv.org/abs/2012.02495" target="_blank">arXiv:2012.02495</a> [<a href="http://arxiv.org/pdf/2012.02495" target="_blank">pdf</a>]

<h2>Fair for All: Best-effort Fairness Guarantees for Classification. (arXiv:2012.10216v3 [cs.LG] UPDATED)</h2>
<h3>Anilesh K. Krishnaswamy, Zhihao Jiang, Kangning Wang, Yu Cheng, Kamesh Munagala</h3>
<p>Standard approaches to group-based notions of fairness, such as \emph{parity}
and \emph{equalized odds}, try to equalize absolute measures of performance
across known groups (based on race, gender, etc.). Consequently, a group that
is inherently harder to classify may hold back the performance on other groups;
and no guarantees can be provided for unforeseen groups. Instead, we propose a
fairness notion whose guarantee, on each group $g$ in a class $\mathcal{G}$, is
relative to the performance of the best classifier on $g$. We apply this notion
to broad classes of groups, in particular, where (a) $\mathcal{G}$ consists of
all possible groups (subsets) in the data, and (b) $\mathcal{G}$ is more
streamlined.

For the first setting, which is akin to groups being completely unknown, we
devise the {\sc PF} (Proportional Fairness) classifier, which guarantees, on
any possible group $g$, an accuracy that is proportional to that of the optimal
classifier for $g$, scaled by the relative size of $g$ in the data set. Due to
including all possible groups, some of which could be too complex to be
relevant, the worst-case theoretical guarantees here have to be proportionally
weaker for smaller subsets.

For the second setting, we devise the {\sc BeFair} (Best-effort Fair)
framework which seeks an accuracy, on every $g \in \mathcal{G}$, which
approximates that of the optimal classifier on $g$, independent of the size of
$g$. Aiming for such a guarantee results in a non-convex problem, and we design
novel techniques to get around this difficulty when $\mathcal{G}$ is the set of
linear hypotheses. We test our algorithms on real-world data sets, and present
interesting comparative insights on their performance.
</p>
<a href="http://arxiv.org/abs/2012.10216" target="_blank">arXiv:2012.10216</a> [<a href="http://arxiv.org/pdf/2012.10216" target="_blank">pdf</a>]

<h2>Learning Geometry-Disentangled Representation for Complementary Understanding of 3D Object Point Cloud. (arXiv:2012.10921v2 [cs.CV] UPDATED)</h2>
<h3>Mutian Xu, Junhao Zhang, Zhipeng Zhou, Mingye Xu, Xiaojuan Qi, Yu Qiao</h3>
<p>In 2D image processing, some attempts decompose images into high and low
frequency components for describing edge and smooth parts respectively.
Similarly, the contour and flat area of 3D objects, such as the boundary and
seat area of a chair, describe different but also complementary geometries.
However, such investigation is lost in previous deep networks that understand
point clouds by directly treating all points or local patches equally. To solve
this problem, we propose Geometry-Disentangled Attention Network (GDANet).
GDANet introduces Geometry-Disentangle Module to dynamically disentangle point
clouds into the contour and flat part of 3D objects, respectively denoted by
sharp and gentle variation components. Then GDANet exploits Sharp-Gentle
Complementary Attention Module that regards the features from sharp and gentle
variation components as two holistic representations, and pays different
attentions to them while fusing them respectively with original point cloud
features. In this way, our method captures and refines the holistic and
complementary 3D geometric semantics from two distinct disentangled components
to supplement the local information. Extensive experiments on 3D object
classification and segmentation benchmarks demonstrate that GDANet achieves the
state-of-the-arts with fewer parameters.
</p>
<a href="http://arxiv.org/abs/2012.10921" target="_blank">arXiv:2012.10921</a> [<a href="http://arxiv.org/pdf/2012.10921" target="_blank">pdf</a>]

<h2>End-to-End Deep Structured Models for Drawing Crosswalks. (arXiv:2012.11585v2 [cs.CV] UPDATED)</h2>
<h3>Justin Liang, Raquel Urtasun</h3>
<p>In this paper we address the problem of detecting crosswalks from LiDAR and
camera imagery. Towards this goal, given multiple LiDAR sweeps and the
corresponding imagery, we project both inputs onto the ground surface to
produce a top down view of the scene. We then leverage convolutional neural
networks to extract semantic cues about the location of the crosswalks. These
are then used in combination with road centerlines from freely available maps
(e.g., OpenStreetMaps) to solve a structured optimization problem which draws
the final crosswalk boundaries. Our experiments over crosswalks in a large city
area show that 96.6% automation can be achieved.
</p>
<a href="http://arxiv.org/abs/2012.11585" target="_blank">arXiv:2012.11585</a> [<a href="http://arxiv.org/pdf/2012.11585" target="_blank">pdf</a>]

<h2>Robust Kernel-based Feature Representation for 3D Point Cloud Analysis via Circular Graph Convolutional Network. (arXiv:2012.12215v3 [cs.CV] UPDATED)</h2>
<h3>Seung Hwan Jung, Yeong-Gil Shin, Minyoung Chung</h3>
<p>Feature descriptor of the point cloud is used in many applications such as
registration and part segmentation from 3D point clouds. Discriminative
representations of the local geometric features is unquestionably the most
important task for accurate point cloud analyses. However, it is challenging to
develop rotation or scale invariant descriptors. Most of the previous works
have either ignored rotations or empirically studied optimal scale parameters,
which hinder the applicability of the methods for real-world datasets. In this
paper, we present a new local feature description method that is robust to
rotation, density, and scales. Moreover, to improve representations of the
local descriptors, we propose a global aggregation method. First, we place
kernels aligned around each point regarding the normal direction. To avoid the
sign problem of the normal vector, we use symmetric kernel point distribution
regarding the tangent plane. From each kernel point, we first projected the
points from the spatial space to the feature space, which is robust to
multiscale and rotation, based on angles and distances. Subsequently, we
perform graph convolutions by considering local kernel point structures and
long-ranged global context, obtained by a global aggregation method. We
experimented with our proposed descriptors on the benchmark datasets (i.e.,
ModelNet40 and ShapeNetPart) to evaluate the performance of registration,
classification, and part segmentation on 3D point clouds. Our methods showed
superior performances compared to the state-of-the-art methods by reducing
70$\%$ of the rotation and translation errors in the registration task. Our
method also showed comparable performance in the classification and part
segmentation tasks without any external data augmentations.
</p>
<a href="http://arxiv.org/abs/2012.12215" target="_blank">arXiv:2012.12215</a> [<a href="http://arxiv.org/pdf/2012.12215" target="_blank">pdf</a>]

<h2>Variational Determinant Estimation with Spherical Normalizing Flows. (arXiv:2012.13311v3 [cs.LG] UPDATED)</h2>
<h3>Simon Passenheim, Emiel Hoogeboom</h3>
<p>This paper introduces the Variational Determinant Estimator (VDE), a
variational extension of the recently proposed determinant estimator discovered
by arXiv:2005.06553v2. Our estimator significantly reduces the variance even
for low sample sizes by combining (importance-weighted) variational inference
and a family of normalizing flows which allow density estimation on
hyperspheres. In the ideal case of a tight variational bound, the VDE becomes a
zero variance estimator, and a single sample is sufficient for an exact (log)
determinant estimate.
</p>
<a href="http://arxiv.org/abs/2012.13311" target="_blank">arXiv:2012.13311</a> [<a href="http://arxiv.org/pdf/2012.13311" target="_blank">pdf</a>]

<h2>Identity-aware Facial Expression Recognition in Compressed Video. (arXiv:2101.00317v2 [cs.CV] UPDATED)</h2>
<h3>Xiaofeng Liu, Linghao Jin, Xu Han, Jun Lu, Jane You, Lingsheng Kong</h3>
<p>This paper targets to explore the inter-subject variations eliminated facial
expression representation in the compressed video domain. Most of the previous
methods process the RGB images of a sequence, while the off-the-shelf and
valuable expression-related muscle movement already embedded in the compression
format. In the up to two orders of magnitude compressed domain, we can
explicitly infer the expression from the residual frames and possible to
extract identity factors from the I frame with a pre-trained face recognition
network. By enforcing the marginal independent of them, the expression feature
is expected to be purer for the expression and be robust to identity shifts. We
do not need the identity label or multiple expression samples from the same
person for identity elimination. Moreover, when the apex frame is annotated in
the dataset, the complementary constraint can be further added to regularize
the feature-level game. In testing, only the compressed residual frames are
required to achieve expression prediction. Our solution can achieve comparable
or better performance than the recent decoded image based methods on the
typical FER benchmarks with about 3$\times$ faster inference with compressed
data.
</p>
<a href="http://arxiv.org/abs/2101.00317" target="_blank">arXiv:2101.00317</a> [<a href="http://arxiv.org/pdf/2101.00317" target="_blank">pdf</a>]

<h2>Transformer for Image Quality Assessment. (arXiv:2101.01097v2 [cs.CV] UPDATED)</h2>
<h3>Junyong You, Jari Korhonen</h3>
<p>Transformer has become the new standard method in natural language processing
(NLP), and it also attracts research interests in computer vision area. In this
paper we investigate the application of Transformer in Image Quality (TRIQ)
assessment. Following the original Transformer encoder employed in Vision
Transformer (ViT), we propose an architecture of using a shallow Transformer
encoder on the top of a feature map extracted by convolution neural networks
(CNN). Adaptive positional embedding is employed in the Transformer encoder to
handle images with arbitrary resolutions. Different settings of Transformer
architectures have been investigated on publicly available image quality
databases. We have found that the proposed TRIQ architecture achieves
outstanding performance. The implementation of TRIQ is published on Github
(https://github.com/junyongyou/triq).
</p>
<a href="http://arxiv.org/abs/2101.01097" target="_blank">arXiv:2101.01097</a> [<a href="http://arxiv.org/pdf/2101.01097" target="_blank">pdf</a>]

<h2>Object Detection for Understanding Assembly Instruction Using Context-aware Data Augmentation and Cascade Mask R-CNN. (arXiv:2101.02509v2 [cs.RO] UPDATED)</h2>
<h3>Joosoon Lee, Seongju Lee, Seunghyeok Back, Sungho Shin, Kyoobin Lee</h3>
<p>Understanding assembly instruction has the potential to enhance the robot s
task planning ability and enables advanced robotic applications. To recognize
the key components from the 2D assembly instruction image, We mainly focus on
segmenting the speech bubble area, which contains lots of information about
instructions. For this, We applied Cascade Mask R-CNN and developed a
context-aware data augmentation scheme for speech bubble segmentation, which
randomly combines images cuts by considering the context of assembly
instructions. We showed that the proposed augmentation scheme achieves a better
segmentation performance compared to the existing augmentation algorithm by
increasing the diversity of trainable data while considering the distribution
of components locations. Also, we showed that deep learning can be useful to
understand assembly instruction by detecting the essential objects in the
assembly instruction, such as tools and parts.
</p>
<a href="http://arxiv.org/abs/2101.02509" target="_blank">arXiv:2101.02509</a> [<a href="http://arxiv.org/pdf/2101.02509" target="_blank">pdf</a>]

<h2>Neural Spectrahedra and Semidefinite Lifts: Global Convex Optimization of Polynomial Activation Neural Networks in Fully Polynomial-Time. (arXiv:2101.02429v1 [cs.LG] CROSS LISTED)</h2>
<h3>Burak Bartan, Mert Pilanci</h3>
<p>The training of two-layer neural networks with nonlinear activation functions
is an important non-convex optimization problem with numerous applications and
promising performance in layerwise deep learning. In this paper, we develop
exact convex optimization formulations for two-layer neural networks with
second degree polynomial activations based on semidefinite programming.
Remarkably, we show that semidefinite lifting is always exact and therefore
computational complexity for global optimization is polynomial in the input
dimension and sample size for all input data. The developed convex formulations
are proven to achieve the same global optimal solution set as their non-convex
counterparts. More specifically, the globally optimal two-layer neural network
with polynomial activations can be found by solving a semidefinite program
(SDP) and decomposing the solution using a procedure we call Neural
Decomposition. Moreover, the choice of regularizers plays a crucial role in the
computational tractability of neural network training. We show that the
standard weight decay regularization formulation is NP-hard, whereas other
simple convex penalties render the problem tractable in polynomial time via
convex programming. We extend the results beyond the fully connected
architecture to different neural network architectures including networks with
vector outputs and convolutional architectures with pooling. We provide
extensive numerical simulations showing that the standard backpropagation
approach often fails to achieve the global optimum of the training loss. The
proposed approach is significantly faster to obtain better test accuracy
compared to the standard backpropagation procedure.
</p>
<a href="http://arxiv.org/abs/2101.02429" target="_blank">arXiv:2101.02429</a> [<a href="http://arxiv.org/pdf/2101.02429" target="_blank">pdf</a>]

