---
title: Latest Deep Learning Papers
date: 2021-02-07 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (165 Articles)</h1>
<h2>Scattering Networks on the Sphere for Scalable and Rotationally Equivariant Spherical CNNs. (arXiv:2102.02828v1 [cs.CV])</h2>
<h3>Jason D. McEwen, Christopher G. R. Wallis, Augustine N. Mavor-Parker</h3>
<p>Convolutional neural networks (CNNs) constructed natively on the sphere have
been developed recently and shown to be highly effective for the analysis of
spherical data. While an efficient framework has been formulated, spherical
CNNs are nevertheless highly computationally demanding; typically they cannot
scale beyond spherical signals of thousands of pixels. We develop scattering
networks constructed natively on the sphere that provide a powerful
representational space for spherical data. Spherical scattering networks are
computationally scalable and exhibit rotational equivariance, while their
representational space is invariant to isometries and provides efficient and
stable signal representations. By integrating scattering networks as an
additional type of layer in the generalized spherical CNN framework, we show
how they can be leveraged to scale spherical CNNs to the high resolution data
typical of many practical applications, with spherical signals of many tens of
megapixels and beyond.
</p>
<a href="http://arxiv.org/abs/2102.02828" target="_blank">arXiv:2102.02828</a> [<a href="http://arxiv.org/pdf/2102.02828" target="_blank">pdf</a>]

<h2>Escaping Saddle Points for Nonsmooth Weakly Convex Functions via Perturbed Proximal Algorithms. (arXiv:2102.02837v1 [cs.LG])</h2>
<h3>Minhui Huang</h3>
<p>We propose perturbed proximal algorithms that can provably escape strict
saddles for nonsmooth weakly convex functions. The main results are based on a
novel characterization of $\epsilon$-approximate local minimum for nonsmooth
functions, and recent developments on perturbed gradient methods for escaping
saddle points for smooth problems. Specifically, we show that under standard
assumptions, the perturbed proximal point, perturbed proximal gradient and
perturbed proximal linear algorithms find $\epsilon$-approximate local minimum
for nonsmooth weakly convex functions in $O(\epsilon^{-2}\log(d)^4)$
iterations, where $d$ is the dimension of the problem.
</p>
<a href="http://arxiv.org/abs/2102.02837" target="_blank">arXiv:2102.02837</a> [<a href="http://arxiv.org/pdf/2102.02837" target="_blank">pdf</a>]

<h2>The EpiBench Platform to Propel AI/ML-based Epidemic Forecasting: A Prototype Demonstration Reaching Human Expert-level Performance. (arXiv:2102.02842v1 [cs.LG])</h2>
<h3>Ajitesh Srivastava, Tianjian Xu, Viktor K. Prasanna</h3>
<p>During the COVID-19 pandemic, a significant effort has gone into developing
ML-driven epidemic forecasting techniques. However, benchmarks do not exist to
claim if a new AI/ML technique is better than the existing ones. The
"covid-forecast-hub" is a collection of more than 30 teams, including us, that
submit their forecasts weekly to the CDC. It is not possible to declare whether
one method is better than the other using those forecasts because each team's
submission may correspond to different techniques over the period and involve
human interventions as the teams are continuously changing/tuning their
approach. Such forecasts may be considered "human-expert" forecasts and do not
qualify as AI/ML approaches, although they can be used as an indicator of human
expert performance. We are interested in supporting AI/ML research in epidemic
forecasting which can lead to scalable forecasting without human intervention.
Which modeling technique, learning strategy, and data pre-processing technique
work well for epidemic forecasting is still an open problem. To help advance
the state-of-the-art AI/ML applied to epidemiology, a benchmark with a
collection of performance points is needed and the current "state-of-the-art"
techniques need to be identified. We propose EpiBench a platform consisting of
community-driven benchmarks for AI/ML applied to epidemic forecasting to
standardize the challenge with a uniform evaluation protocol. In this paper, we
introduce a prototype of EpiBench which is currently running and accepting
submissions for the task of forecasting COVID-19 cases and deaths in the US
states and We demonstrate that we can utilize the prototype to develop an
ensemble relying on fully automated epidemic forecasts (no human intervention)
that reaches human-expert level ensemble currently being used by the CDC.
</p>
<a href="http://arxiv.org/abs/2102.02842" target="_blank">arXiv:2102.02842</a> [<a href="http://arxiv.org/pdf/2102.02842" target="_blank">pdf</a>]

<h2>Semi-Synchronous Federated Learning. (arXiv:2102.02849v1 [cs.LG])</h2>
<h3>Dimitris Stripelis, Jose Luis Ambite</h3>
<p>There are situations where data relevant to a machine learning problem are
distributed among multiple locations that cannot share the data due to
regulatory, competitiveness, or privacy reasons. For example, data present in
users' cellphones, manufacturing data of companies in a given industrial
sector, or medical records located at different hospitals. Federated Learning
(FL) provides an approach to learn a joint model over all the available data
across silos. In many cases, participating sites have different data
distributions and computational capabilities. In these heterogeneous
environments previous approaches exhibit poor performance: synchronous FL
protocols are communication efficient, but have slow learning convergence;
conversely, asynchronous FL protocols have faster convergence, but at a higher
communication cost. Here we introduce a novel Semi-Synchronous Federated
Learning protocol that mixes local models periodically with minimal idle time
and fast convergence. We show through extensive experiments that our approach
significantly outperforms previous work in data and computationally
heterogeneous environments.
</p>
<a href="http://arxiv.org/abs/2102.02849" target="_blank">arXiv:2102.02849</a> [<a href="http://arxiv.org/pdf/2102.02849" target="_blank">pdf</a>]

<h2>Undecidability of Underfitting in Learning Algorithms. (arXiv:2102.02850v1 [cs.LG])</h2>
<h3>Sonia Sehra, David Flores, George D. Montanez</h3>
<p>Using recent machine learning results that present an information-theoretic
perspective on underfitting and overfitting, we prove that deciding whether an
encodable learning algorithm will always underfit a dataset, even if given
unlimited training time, is undecidable. We discuss the importance of this
result and potential topics for further research, including
information-theoretic and probabilistic strategies for bounding learning
algorithm fit.
</p>
<a href="http://arxiv.org/abs/2102.02850" target="_blank">arXiv:2102.02850</a> [<a href="http://arxiv.org/pdf/2102.02850" target="_blank">pdf</a>]

<h2>Learning the Update Operator for 2D/3D Image Registration. (arXiv:2102.02861v1 [cs.CV])</h2>
<h3>Srikrishna Jaganathan, Jian Wang, Anja Borsdorf, Andreas Maier</h3>
<p>Image guidance in minimally invasive interventions is usually provided using
live 2D X-ray imaging. To enhance the information available during the
intervention, the preoperative volume can be overlaid over the 2D images using
2D/3D image registration. Recently, deep learning-based 2D/3D registration
methods have shown promising results by improving computational efficiency and
robustness. However, there is still a gap in terms of registration accuracy
compared to traditional optimization-based methods. We aim to address this gap
by incorporating traditional methods in deep neural networks using known
operator learning. As an initial step in this direction, we propose to learn
the update step of an iterative 2D/3D registration framework based on the
Point-to-Plane Correspondence model. We embed the Point-to-Plane Correspondence
model as a known operator in our deep neural network and learn the update step
for the iterative registration. We show an improvement of 1.8 times in terms of
registration accuracy for the update step prediction compared to learning
without the known operator.
</p>
<a href="http://arxiv.org/abs/2102.02861" target="_blank">arXiv:2102.02861</a> [<a href="http://arxiv.org/pdf/2102.02861" target="_blank">pdf</a>]

<h2>ChainCQG: Flow-Aware Conversational Question Generation. (arXiv:2102.02864v1 [cs.AI])</h2>
<h3>Jing Gu, Mostafa Mirshekari, Zhou Yu, Aaron Sisto</h3>
<p>Conversational systems enable numerous valuable applications, and
question-answering is an important component underlying many of these. However,
conversational question-answering remains challenging due to the lack of
realistic, domain-specific training data. Inspired by this bottleneck, we focus
on conversational question generation as a means to generate synthetic
conversations for training and evaluation purposes. We present a number of
novel strategies to improve conversational flow and accommodate varying
question types and overall fluidity. Specifically, we design ChainCQG as a
two-stage architecture that learns question-answer representations across
multiple dialogue turns using a flow propagation training strategy.ChainCQG
significantly outperforms both answer-aware and answer-unaware SOTA baselines
(e.g., up to 48% BLEU-1 improvement). Additionally, our model is able to
generate different types of questions, with improved fluidity and coreference
alignment.
</p>
<a href="http://arxiv.org/abs/2102.02864" target="_blank">arXiv:2102.02864</a> [<a href="http://arxiv.org/pdf/2102.02864" target="_blank">pdf</a>]

<h2>Feedback in Imitation Learning: Confusion on Causality and Covariate Shift. (arXiv:2102.02872v1 [cs.LG])</h2>
<h3>Jonathan Spencer, Sanjiban Choudhury, Arun Venkatraman, Brian Ziebart, J. Andrew Bagnell</h3>
<p>Imitation learning practitioners have often noted that conditioning policies
on previous actions leads to a dramatic divergence between "held out" error and
performance of the learner in situ. Interactive approaches can provably address
this divergence but require repeated querying of a demonstrator. Recent work
identifies this divergence as stemming from a "causal confound" in predicting
the current action, and seek to ablate causal aspects of current state using
tools from causal inference. In this work, we argue instead that this
divergence is simply another manifestation of covariate shift, exacerbated
particularly by settings of feedback between decisions and input features. The
learner often comes to rely on features that are strongly predictive of
decisions, but are subject to strong covariate shift.

Our work demonstrates a broad class of problems where this shift can be
mitigated, both theoretically and practically, by taking advantage of a
simulator but without any further querying of expert demonstration. We analyze
existing benchmarks used to test imitation learning approaches and find that
these benchmarks are realizable and simple and thus insufficient for capturing
the harder regimes of error compounding seen in real-world decision making
problems. We find, in a surprising contrast with previous literature, but
consistent with our theory, that naive behavioral cloning provides excellent
results. We detail the need for new standardized benchmarks that capture the
phenomena seen in robotics problems.
</p>
<a href="http://arxiv.org/abs/2102.02872" target="_blank">arXiv:2102.02872</a> [<a href="http://arxiv.org/pdf/2102.02872" target="_blank">pdf</a>]

<h2>Nonlinear Independent Component Analysis for Continuous-Time Signals. (arXiv:2102.02876v1 [stat.ML])</h2>
<h3>Harald Oberhauser, Alexander Schell</h3>
<p>We study the classical problem of recovering a multidimensional source
process from observations of nonlinear mixtures of this process. Assuming
statistical independence of the coordinate processes of the source, we show
that this recovery is possible for many popular models of stochastic processes
(up to order and monotone scaling of their coordinates) if the mixture is given
by a sufficiently differentiable, invertible function. Key to our approach is
the combination of tools from stochastic analysis and recent contrastive
learning approaches to nonlinear ICA. This yields a scalable method with widely
applicable theoretical guarantees for which our experiments indicate good
performance.
</p>
<a href="http://arxiv.org/abs/2102.02876" target="_blank">arXiv:2102.02876</a> [<a href="http://arxiv.org/pdf/2102.02876" target="_blank">pdf</a>]

<h2>Aggregating Bipolar Opinions (With Appendix). (arXiv:2102.02881v1 [cs.AI])</h2>
<h3>Stefan Lauren, Francesco Belardinelli, Francesca Toni</h3>
<p>We introduce a novel method to aggregate Bipolar Argumentation (BA)
Frameworks expressing opinions by different parties in debates. We use Bipolar
Assumption-based Argumentation (ABA) as an all-encompassing formalism for BA
under different semantics. By leveraging on recent results on judgement
aggregation in Social Choice Theory, we prove several preservation results,
both positive and negative, for relevant properties of Bipolar ABA.
</p>
<a href="http://arxiv.org/abs/2102.02881" target="_blank">arXiv:2102.02881</a> [<a href="http://arxiv.org/pdf/2102.02881" target="_blank">pdf</a>]

<h2>Ivy: Templated Deep Learning for Inter-Framework Portability. (arXiv:2102.02886v1 [cs.LG])</h2>
<h3>Daniel Lenton, Fabio Pardo, Fabian Falck, Stephen James, Ronald Clark</h3>
<p>We introduce Ivy, a templated Deep Learning (DL) framework which abstracts
existing DL frameworks such that their core functions all exhibit consistent
call signatures, syntax and input-output behaviour. Ivy allows high-level
framework-agnostic functions to be implemented through the use of framework
templates. The framework templates act as placeholders for the specific
framework at development time, which are then determined at runtime. The
portability of Ivy functions enables their use in projects of any supported
framework. Ivy currently supports TensorFlow, PyTorch, MXNet, Jax and NumPy.
Alongside Ivy, we release four pure-Ivy libraries for mechanics, 3D vision,
robotics, and differentiable environments. Through our evaluations, we show
that Ivy can significantly reduce lines of code with a runtime overhead of less
than 1% in most cases. We welcome developers to join the Ivy community by
writing their own functions, layers and libraries in Ivy, maximizing their
audience and helping to accelerate DL research through the creation of lifelong
inter-framework codebases. More information can be found at ivy-dl.org.
</p>
<a href="http://arxiv.org/abs/2102.02886" target="_blank">arXiv:2102.02886</a> [<a href="http://arxiv.org/pdf/2102.02886" target="_blank">pdf</a>]

<h2>Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training. (arXiv:2102.02887v1 [cs.LG])</h2>
<h3>Shiwei Liu, Lu Yin, Decebal Constantin Mocanu, Mykola Pechenizkiy</h3>
<p>In this paper, we introduce a new perspective on training deep neural
networks capable of state-of-the-art performance without the need for the
expensive over-parameterization by proposing the concept of In-Time
Over-Parameterization (ITOP) in sparse training. By starting from a random
sparse network and continuously exploring sparse connectivities during
training, we can perform an Over-Parameterization in the space-time manifold,
closing the gap in the expressibility between sparse training and dense
training. We further use ITOP to understand the underlying mechanism of Dynamic
Sparse Training (DST) and indicate that the benefits of DST come from its
ability to consider across time all possible parameters when searching for the
optimal sparse connectivity. As long as there are sufficient parameters that
have been reliably explored during training, DST can outperform the dense
neural network by a large margin. We present a series of experiments to support
our conjecture and achieve the state-of-the-art sparse training performance
with ResNet-50 on ImageNet. More impressively, our method achieves dominant
performance over the overparameterization-based sparse methods at extreme
sparsity levels. When trained on CIFAR-100, our method can match the
performance of the dense model even at an extreme sparsity (98%).
</p>
<a href="http://arxiv.org/abs/2102.02887" target="_blank">arXiv:2102.02887</a> [<a href="http://arxiv.org/pdf/2102.02887" target="_blank">pdf</a>]

<h2>1-bit Adam: Communication Efficient Large-Scale Training with Adam's Convergence Speed. (arXiv:2102.02888v1 [cs.LG])</h2>
<h3>Hanlin Tang, Shaoduo Gan, Ammar Ahmad Awan, Samyam Rajbhandari, Conglong Li, Xiangru Lian, Ji Liu, Ce Zhang, Yuxiong He</h3>
<p>Scalable training of large models (like BERT and GPT-3) requires careful
optimization rooted in model design, architecture, and system capabilities.
From a system standpoint, communication has become a major bottleneck,
especially on commodity systems with standard TCP interconnects that offer
limited network bandwidth. Communication compression is an important technique
to reduce training time on such systems. One of the most effective methods is
error-compensated compression, which offers robust convergence speed even under
1-bit compression. However, state-of-the-art error compensation techniques only
work with basic optimizers like SGD and momentum SGD, which are linearly
dependent on the gradients. They do not work with non-linear gradient-based
optimizers like Adam, which offer state-of-the-art convergence efficiency and
accuracy for models like BERT. In this paper, we propose 1-bit Adam that
reduces the communication volume by up to $5\times$, offers much better
scalability, and provides the same convergence speed as uncompressed Adam. Our
key finding is that Adam's variance (non-linear term) becomes stable (after a
warmup phase) and can be used as a fixed precondition for the rest of the
training (compression phase). Experiments on up to 256 GPUs show that 1-bit
Adam enables up to $3.3\times$ higher throughput for BERT-Large pre-training
and up to $2.9\times$ higher throughput for SQuAD fine-tuning. In addition, we
provide theoretical analysis for our proposed work.
</p>
<a href="http://arxiv.org/abs/2102.02888" target="_blank">arXiv:2102.02888</a> [<a href="http://arxiv.org/pdf/2102.02888" target="_blank">pdf</a>]

<h2>Using Long Short-Term Memory (LSTM) and Internet of Things (IoT) for localized surface temperature forecasting in an urban environment. (arXiv:2102.02892v1 [cs.LG])</h2>
<h3>Manzhu Yu, Fangcao Xu, Weiming Hu, Jian Sun, Guido Cervone</h3>
<p>The rising temperature is one of the key indicators of a warming climate, and
it can cause extensive stress to biological systems as well as built
structures. Due to the heat island effect, it is most severe in urban
environments compared to other landscapes due to the decrease in vegetation
associated with a dense human-built environment. It is essential to adequately
monitor the local temperature dynamics to mitigate risks associated with
increasing temperatures, which can include short term strategy to protect
people and animals, to long term strategy to how to build a new structure and
cope with extreme events. Observed temperature is also a very important input
for atmospheric models, and accurate data can lead to better future forecasts.

Ambient temperature collected at ground level can have a higher variability
when compared to regional weather forecasts, which fail to capture the local
dynamics. There remains a clear need for an accurate air temperature prediction
at the sub-urban scale at high temporal and spatial resolution. This research
proposed a framework based on Long Short-Term Memory (LSTM) deep learning
network to generate day-ahead hourly temperature forecast with high spatial
resolution. A case study is shown which uses historical in-situ observations
and Internet of Things (IoT) observations for New York City, USA. By leveraging
the historical air temperature data from in-situ observations, the LSTM model
can be exposed to more historical patterns that might not be present in the IoT
observations. Meanwhile, by using IoT observations, the spatial resolution of
air temperature predictions is significantly improved.
</p>
<a href="http://arxiv.org/abs/2102.02892" target="_blank">arXiv:2102.02892</a> [<a href="http://arxiv.org/pdf/2102.02892" target="_blank">pdf</a>]

<h2>Deep reinforcement learning-based image classification achieves perfect testing set accuracy for MRI brain tumors with a training set of only 30 images. (arXiv:2102.02895v1 [cs.CV])</h2>
<h3>Joseph Stember, Hrithwik Shalu</h3>
<p>Purpose: Image classification may be the fundamental task in imaging
artificial intelligence. We have recently shown that reinforcement learning can
achieve high accuracy for lesion localization and segmentation even with
minuscule training sets. Here, we introduce reinforcement learning for image
classification. In particular, we apply the approach to normal vs.
tumor-containing 2D MRI brain images.

Materials and Methods: We applied multi-step image classification to allow
for combined Deep Q learning and TD(0) Q learning. We trained on a set of 30
images (15 normal and 15 tumor-containing). We tested on a separate set of 30
images (15 normal and 15 tumor-containing). For comparison, we also trained and
tested a supervised deep-learning classification network on the same set of
training and testing images.

Results: Whereas the supervised approach quickly overfit the training data
and as expected performed poorly on the testing set (57% accuracy, just over
random guessing), the reinforcement learning approach achieved an accuracy of
100%.

Conclusion: We have shown a proof-of-principle application of reinforcement
learning to the classification of brain tumors. We achieved perfect testing set
accuracy with a training set of merely 30 images.
</p>
<a href="http://arxiv.org/abs/2102.02895" target="_blank">arXiv:2102.02895</a> [<a href="http://arxiv.org/pdf/2102.02895" target="_blank">pdf</a>]

<h2>Compressed Object Detection. (arXiv:2102.02896v1 [cs.CV])</h2>
<h3>Gedeon Muhawenayo, Georgia Gkioxari</h3>
<p>Deep learning approaches have achieved unprecedented performance in visual
recognition tasks such as object detection and pose estimation. However,
state-of-the-art models have millions of parameters represented as floats which
make them computationally expensive and constrain their deployment on hardware
such as mobile phones and IoT nodes. Most commonly, activations of deep neural
networks tend to be sparse thus proving that models are over parametrized with
redundant neurons. Model compression techniques, such as pruning and
quantization, have recently shown promising results by improving model
complexity with little loss in performance. In this work, we extended pruning,
a compression technique that discards unnecessary model connections, and weight
sharing techniques for the task of object detection. With our approach, we are
able to compress a state-of-the-art object detection model by 30.0% without a
loss in performance. We also show that our compressed model can be easily
initialized with existing pre-trained weights, and thus is able to fully
utilize published state-of-the-art model zoos.
</p>
<a href="http://arxiv.org/abs/2102.02896" target="_blank">arXiv:2102.02896</a> [<a href="http://arxiv.org/pdf/2102.02896" target="_blank">pdf</a>]

<h2>Automated Rip Current Detection with Region based Convolutional Neural Networks. (arXiv:2102.02902v1 [cs.CV])</h2>
<h3>Akila de Silva, Issei Mori, Gregory Dusek, James Davis, Alex Pang</h3>
<p>This paper presents a machine learning approach for the automatic
identification of rip currents with breaking waves. Rip currents are dangerous
fast moving currents of water that result in many deaths by sweeping people out
to sea. Most people do not know how to recognize rip currents in order to avoid
them. Furthermore, efforts to forecast rip currents are hindered by lack of
observations to help train and validate hazard models. The presence of web cams
and smart phones have made video and still imagery of the coast ubiquitous and
provide a potential source of rip current observations. These same devices
could aid public awareness of the presence of rip currents. What is lacking is
a method to detect the presence or absence of rip currents from coastal
imagery. This paper provides expert labeled training and test data sets for rip
currents. We use Faster-RCNN and a custom temporal aggregation stage to make
detections from still images or videos with higher measured accuracy than both
humans and other methods of rip current detection previously reported in the
literature.
</p>
<a href="http://arxiv.org/abs/2102.02902" target="_blank">arXiv:2102.02902</a> [<a href="http://arxiv.org/pdf/2102.02902" target="_blank">pdf</a>]

<h2>Incorporating Kinematic Wave Theory into a Deep Learning Method for High-Resolution Traffic Speed Estimation. (arXiv:2102.02906v1 [cs.LG])</h2>
<h3>Bilal Thonnam Thodi, Zaid Saeed Khan, Saif Eddin Jabari, Monica Menendez</h3>
<p>We propose a kinematic wave based Deep Convolutional Neural Network (Deep
CNN) to estimate high resolution traffic speed dynamics from sparse probe
vehicle trajectories. To that end, we introduce two key approaches that allow
us to incorporate kinematic wave theory principles to improve the robustness of
existing learning-based estimation methods. First, we use an anisotropic
traffic-based kernel for the CNN. This kernel is designed to explicitly take
forward and backward traffic wave propagation characteristics into account
during reconstruction in the space-time domain. Second, we use simulated data
for training the CNN. This implicitly imposes physical constraints on the
patterns learned by the CNN, providing an alternate, unrestricted way to
integrate complex traffic behaviors into learning models. We present the speed
fields estimated using the anisotropic kernel and highlight its advantages over
its isotropic counterpart in terms of predicting shockwave dynamics.
Furthermore, we test the transferability of the trained model to real traffic
by using two datasets: the Next Generation Simulation (NGSIM) program and the
Highway Drone (HighD) dataset. Finally, we present an ensemble version of the
CNN that allows us to handle multiple (and unknown) probe vehicle penetration
rates. The results demonstrate that anisotropic kernels can reduce model
complexity while improving the correctness of the estimation, and that
simulation-based training is a viable alternative to model fitting using
real-world data. This suggests that exploiting prior traffic knowledge adds
value to learning-based estimation methods, and that there is great potential
in exploring broader approaches to do so.
</p>
<a href="http://arxiv.org/abs/2102.02906" target="_blank">arXiv:2102.02906</a> [<a href="http://arxiv.org/pdf/2102.02906" target="_blank">pdf</a>]

<h2>Progressive Neural Image Compression with Nested Quantization and Latent Ordering. (arXiv:2102.02913v1 [cs.LG])</h2>
<h3>Yadong Lu, Yinhao Zhu, Yang Yang, Amir Said, Taco S Cohen</h3>
<p>We present PLONQ, a progressive neural image compression scheme which pushes
the boundary of variable bitrate compression by allowing quality scalable
coding with a single bitstream. In contrast to existing learned variable
bitrate solutions which produce separate bitstreams for each quality, it
enables easier rate-control and requires less storage. Leveraging the latent
scaling based variable bitrate solution, we introduce nested quantization, a
method that defines multiple quantization levels with nested quantization
grids, and progressively refines all latents from the coarsest to the finest
quantization level. To achieve finer progressiveness in between any two
quantization levels, latent elements are incrementally refined with an
importance ordering defined in the rate-distortion sense. To the best of our
knowledge, PLONQ is the first learning-based progressive image coding scheme
and it outperforms SPIHT, a well-known wavelet-based progressive image codec.
</p>
<a href="http://arxiv.org/abs/2102.02913" target="_blank">arXiv:2102.02913</a> [<a href="http://arxiv.org/pdf/2102.02913" target="_blank">pdf</a>]

<h2>How to Train Your Robot with Deep Reinforcement Learning; Lessons We've Learned. (arXiv:2102.02915v1 [cs.RO])</h2>
<h3>Julian Ibarz, Jie Tan, Chelsea Finn, Mrinal Kalakrishnan, Peter Pastor, Sergey Levine</h3>
<p>Deep reinforcement learning (RL) has emerged as a promising approach for
autonomously acquiring complex behaviors from low level sensor observations.
Although a large portion of deep RL research has focused on applications in
video games and simulated control, which does not connect with the constraints
of learning in real environments, deep RL has also demonstrated promise in
enabling physical robots to learn complex skills in the real world. At the same
time,real world robotics provides an appealing domain for evaluating such
algorithms, as it connects directly to how humans learn; as an embodied agent
in the real world. Learning to perceive and move in the real world presents
numerous challenges, some of which are easier to address than others, and some
of which are often not considered in RL research that focuses only on simulated
domains. In this review article, we present a number of case studies involving
robotic deep RL. Building off of these case studies, we discuss commonly
perceived challenges in deep RL and how they have been addressed in these
works. We also provide an overview of other outstanding challenges, many of
which are unique to the real-world robotics setting and are not often the focus
of mainstream RL research. Our goal is to provide a resource both for
roboticists and machine learning researchers who are interested in furthering
the progress of deep RL in the real world.
</p>
<a href="http://arxiv.org/abs/2102.02915" target="_blank">arXiv:2102.02915</a> [<a href="http://arxiv.org/pdf/2102.02915" target="_blank">pdf</a>]

<h2>Alchemy: A structured task distribution for meta-reinforcement learning. (arXiv:2102.02926v1 [cs.LG])</h2>
<h3>Jane X. Wang, Michael King, Nicolas Porcel, Zeb Kurth-Nelson, Tina Zhu, Charlie Deck, Peter Choy, Mary Cassin, Malcolm Reynolds, Francis Song, Gavin Buttimore, David P. Reichert, Neil Rabinowitz, Loic Matthey, Demis Hassabis, Alexander Lerchner, Matthew Botvinick</h3>
<p>There has been rapidly growing interest in meta-learning as a method for
increasing the flexibility and sample efficiency of reinforcement learning. One
problem in this area of research, however, has been a scarcity of adequate
benchmark tasks. In general, the structure underlying past benchmarks has
either been too simple to be inherently interesting, or too ill-defined to
support principled analysis. In the present work, we introduce a new benchmark
for meta-RL research, which combines structural richness with structural
transparency. Alchemy is a 3D video game, implemented in Unity, which involves
a latent causal structure that is resampled procedurally from episode to
episode, affording structure learning, online inference, hypothesis testing and
action sequencing based on abstract domain knowledge. We evaluate a pair of
powerful RL agents on Alchemy and present an in-depth analysis of one of these
agents. Results clearly indicate a frank and specific failure of meta-learning,
providing validation for Alchemy as a challenging benchmark for meta-RL.
Concurrent with this report, we are releasing Alchemy as public resource,
together with a suite of analysis tools and sample agent trajectories.
</p>
<a href="http://arxiv.org/abs/2102.02926" target="_blank">arXiv:2102.02926</a> [<a href="http://arxiv.org/pdf/2102.02926" target="_blank">pdf</a>]

<h2>BAXTER: Bi-modal Aerial-Terrestrial Hybrid Vehicle for Long-endurance Versatile Mobility: Preprint Version. (arXiv:2102.02942v1 [cs.RO])</h2>
<h3>Hyungho Chris Choi, Inhwan Wee, Micah Corah, Sahand Sabet, Taeyeon Kim, Thomas Touma, David Hyunchul Shim, Ali-akbar Agha-mohammadi</h3>
<p>Unmanned aerial vehicles are rapidly evolving within the field of robotics.
However, their performance is often limited by payload capacity, operational
time, and robustness to impact and collision. These limitations of aerial
vehicles become more acute for missions in challenging environments such as
subterranean structures which may require extended autonomous operation in
confined spaces. While software solutions for aerial robots are developing
rapidly, improvements to hardware are critical to applying advanced planners
and algorithms in large and dangerous environments where the short range and
high susceptibility to collisions of most modern aerial robots make
applications in realistic subterranean missions infeasible. To provide such
hardware capabilities, one needs to design and implement a hardware solution
that takes into the account the Size, Weight, and Power (SWaP) constraints.
This work focuses on providing a robust and versatile hybrid platform that
improves payload capacity, operation time, endurance, and versatility. The
Bi-modal Aerial and Terrestrial hybrid vehicle (BAXTER) is a solution that
provides two modes of operation, aerial and terrestrial. BAXTER employs two
novel hardware mechanisms: the M-Suspension and the Decoupled Transmission
which together provide resilience during landing and crashes and efficient
terrestrial operation. Extensive flight tests were conducted to characterize
the vehicle's capabilities, including robustness and endurance. Additionally,
we propose Agile Mode Transfer (AMT), a transition from aerial to terrestrial
operation that seeks to minimize impulses during impact to the ground which is
a quick and simple transition process that exploits BAXTER's resilience to
impact.
</p>
<a href="http://arxiv.org/abs/2102.02942" target="_blank">arXiv:2102.02942</a> [<a href="http://arxiv.org/pdf/2102.02942" target="_blank">pdf</a>]

<h2>Adversarial Training Makes Weight Loss Landscape Sharper in Logistic Regression. (arXiv:2102.02950v1 [stat.ML])</h2>
<h3>Masanori Yamada, Sekitoshi Kanai, Tomoharu Iwata, Tomokatsu Takahashi, Yuki Yamanaka, Hiroshi Takahashi, Atsutoshi Kumagai</h3>
<p>Adversarial training is actively studied for learning robust models against
adversarial examples. A recent study finds that adversarially trained models
degenerate generalization performance on adversarial examples when their weight
loss landscape, which is loss changes with respect to weights, is sharp.
Unfortunately, it has been experimentally shown that adversarial training
sharpens the weight loss landscape, but this phenomenon has not been
theoretically clarified. Therefore, we theoretically analyze this phenomenon in
this paper. As a first step, this paper proves that adversarial training with
the L2 norm constraints sharpens the weight loss landscape in the linear
logistic regression model. Our analysis reveals that the sharpness of the
weight loss landscape is caused by the noise aligned in the direction of
increasing the loss, which is used in adversarial training. We theoretically
and experimentally confirm that the weight loss landscape becomes sharper as
the magnitude of the noise of adversarial training increases in the linear
logistic regression model. Moreover, we experimentally confirm the same
phenomena in ResNet18 with softmax as a more general case.
</p>
<a href="http://arxiv.org/abs/2102.02950" target="_blank">arXiv:2102.02950</a> [<a href="http://arxiv.org/pdf/2102.02950" target="_blank">pdf</a>]

<h2>Robust Adaptive Filtering Based on Exponential Functional Link Network. (arXiv:2102.02952v1 [cs.LG])</h2>
<h3>T. Yu, W. Li, Y. Yu, R. C. de Lamare</h3>
<p>The exponential functional link network (EFLN) has been recently investigated
and applied to nonlinear filtering. This brief proposes an adaptive EFLN
filtering algorithm based on a novel inverse square root (ISR) cost function,
called the EFLN-ISR algorithm, whose learning capability is robust under
impulsive interference. The steady-state performance of EFLN-ISR is rigorously
derived and then confirmed by numerical simulations. Moreover, the validity of
the proposed EFLN-ISR algorithm is justified by the actually experimental
results with the application to hysteretic nonlinear system identification.
</p>
<a href="http://arxiv.org/abs/2102.02952" target="_blank">arXiv:2102.02952</a> [<a href="http://arxiv.org/pdf/2102.02952" target="_blank">pdf</a>]

<h2>DetectorGuard: Provably Securing Object Detectors against Localized Patch Hiding Attacks. (arXiv:2102.02956v1 [cs.CV])</h2>
<h3>Chong Xiang, Prateek Mittal</h3>
<p>State-of-the-art object detectors are vulnerable to localized patch hiding
attacks where an adversary introduces a small adversarial patch to make
detectors miss the detection of salient objects. In this paper, we propose the
first general framework for building provably robust detectors against the
localized patch hiding attack called DetectorGuard. To start with, we propose a
general approach for transferring the robustness from image classifiers to
object detectors, which builds a bridge between robust image classification and
robust object detection. We apply a provably robust image classifier to a
sliding window over the image and aggregates robust window classifications at
different locations for a robust object detection. Second, in order to mitigate
the notorious trade-off between clean performance and provable robustness, we
use a prediction pipeline in which we compare the outputs of a conventional
detector and a robust detector for catching an ongoing attack. When no attack
is detected, DetectorGuard outputs the precise bounding boxes predicted by the
conventional detector to achieve a high clean performance; otherwise,
DetectorGuard triggers an attack alert for security. Notably, our prediction
strategy ensures that the robust detector incorrectly missing objects will not
hurt the clean performance of DetectorGuard. Moreover, our approach allows us
to formally prove the robustness of DetectorGuard on certified objects, i.e.,
it either detects the object or triggers an alert, against any patch hiding
attacker. Our evaluation on the PASCAL VOC and MS COCO datasets shows that
DetectorGuard has the almost same clean performance as conventional detectors,
and more importantly, that DetectorGuard achieves the first provable robustness
against localized patch hiding attacks.
</p>
<a href="http://arxiv.org/abs/2102.02956" target="_blank">arXiv:2102.02956</a> [<a href="http://arxiv.org/pdf/2102.02956" target="_blank">pdf</a>]

<h2>Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text Reports Using Deep Learning. (arXiv:2102.02959v1 [cs.AI])</h2>
<h3>Vincent M. D&#x27;Anniballe, Fakrul I. Tushar, Khrystyna Faryna, Songyue Han, Maciej A. Mazurowski, Geoffrey D. Rubin, Joseph Y. Lo</h3>
<p>To develop a high throughput multi-label annotator for body Computed
Tomography (CT) reports that can be applied to a variety of diseases, organs,
and cases. First, we used a dictionary approach to develop a rule-based
algorithm (RBA) for extraction of disease labels from radiology text reports.
We targeted three organ systems (lungs/pleura, liver/gallbladder,
kidneys/ureters) with four diseases per system based on their prevalence in our
dataset. To expand the algorithm beyond pre-defined keywords, an
attention-guided recurrent neural network (RNN) was trained using the
RBA-extracted labels to classify the reports as being positive for one or more
diseases or normal for each organ system. Confounding effects on model
performance were evaluated using random or pre-trained embedding as well as
different sizes of training datasets. Performance was evaluated using the
receiver operating characteristic (ROC) area under the curve (AUC) against
2,158 manually obtained labels. Our model extracted disease labels from 261,229
radiology reports of 112,501 unique subjects. Pre-trained models outperformed
random embedding across all diseases. As the training dataset size was reduced,
performance was robust except for a few diseases with relatively small number
of cases. Pre-trained Classification AUCs achieved &gt; 0.95 for all five disease
outcomes across all three organ systems. Our label-extracting pipeline was able
to encompass a variety of cases and diseases by generalizing beyond strict
rules with exceptional accuracy. As a framework, this model can be easily
adapted to enable automated labeling of hospital-scale medical data sets for
training image-based disease classifiers.
</p>
<a href="http://arxiv.org/abs/2102.02959" target="_blank">arXiv:2102.02959</a> [<a href="http://arxiv.org/pdf/2102.02959" target="_blank">pdf</a>]

<h2>Commonsense Knowledge Aware Concept Selection For Diverse and Informative Visual Storytelling. (arXiv:2102.02963v1 [cs.CV])</h2>
<h3>Hong Chen, Yifei Huang, Hiroya Takamura, Hideki Nakayama</h3>
<p>Visual storytelling is a task of generating relevant and interesting stories
for given image sequences. In this work we aim at increasing the diversity of
the generated stories while preserving the informative content from the images.
We propose to foster the diversity and informativeness of a generated story by
using a concept selection module that suggests a set of concept candidates.
Then, we utilize a large scale pre-trained model to convert concepts and images
into full stories. To enrich the candidate concepts, a commonsense knowledge
graph is created for each image sequence from which the concept candidates are
proposed. To obtain appropriate concepts from the graph, we propose two novel
modules that consider the correlation among candidate concepts and the
image-concept correlation. Extensive automatic and human evaluation results
demonstrate that our model can produce reasonable concepts. This enables our
model to outperform the previous models by a large margin on the diversity and
informativeness of the story, while retaining the relevance of the story to the
image sequence.
</p>
<a href="http://arxiv.org/abs/2102.02963" target="_blank">arXiv:2102.02963</a> [<a href="http://arxiv.org/pdf/2102.02963" target="_blank">pdf</a>]

<h2>Implicit Regularization of Sub-Gradient Method in Robust Matrix Recovery: Don't be Afraid of Outliers. (arXiv:2102.02969v1 [cs.LG])</h2>
<h3>Jianhao Ma, Salar Fattahi</h3>
<p>It is well-known that simple short-sighted algorithms, such as gradient
descent, generalize well in the over-parameterized learning tasks, due to their
implicit regularization. However, it is unknown whether the implicit
regularization of these algorithms can be extended to robust learning tasks,
where a subset of samples may be grossly corrupted with noise. In this work, we
provide a positive answer to this question in the context of robust matrix
recovery problem. In particular, we consider the problem of recovering a
low-rank matrix from a number of linear measurements, where a subset of
measurements are corrupted with large noise. We show that a simple sub-gradient
method converges to the true low-rank solution efficiently, when it is applied
to the over-parameterized l1-loss function without any explicit regularization
or rank constraint. Moreover, by building upon a new notion of restricted
isometry property, called sign-RIP, we prove the robustness of the sub-gradient
method against outliers in the over-parameterized regime. In particular, we
show that, with Gaussian measurements, the sub-gradient method is guaranteed to
converge to the true low-rank solution, even if an arbitrary fraction of the
measurements are grossly corrupted with noise.
</p>
<a href="http://arxiv.org/abs/2102.02969" target="_blank">arXiv:2102.02969</a> [<a href="http://arxiv.org/pdf/2102.02969" target="_blank">pdf</a>]

<h2>Metaknowledge Extraction Based on Multi-Modal Documents. (arXiv:2102.02971v1 [cs.CV])</h2>
<h3>Shukan Liu, Ruilin Xu, Boying Geng, Qiao Sun, Li Duan, Yiming Liu</h3>
<p>The triple-based knowledge in large-scale knowledge bases is most likely
lacking in structural logic and problematic of conducting knowledge hierarchy.
In this paper, we introduce the concept of metaknowledge to knowledge
engineering research for the purpose of structural knowledge construction.
Therefore, the Metaknowledge Extraction Framework and Document Structure Tree
model are presented to extract and organize metaknowledge elements (titles,
authors, abstracts, sections, paragraphs, etc.), so that it is feasible to
extract the structural knowledge from multi-modal documents. Experiment results
have proved the effectiveness of metaknowledge elements extraction by our
framework. Meanwhile, detailed examples are given to demonstrate what exactly
metaknowledge is and how to generate it. At the end of this paper, we propose
and analyze the task flow of metaknowledge applications and the associations
between knowledge and metaknowledge.
</p>
<a href="http://arxiv.org/abs/2102.02971" target="_blank">arXiv:2102.02971</a> [<a href="http://arxiv.org/pdf/2102.02971" target="_blank">pdf</a>]

<h2>Structure-aware Person Image Generation with Pose Decomposition and Semantic Correlation. (arXiv:2102.02972v1 [cs.CV])</h2>
<h3>Jilin Tang, Yi Yuan, Tianjia Shao, Yong Liu, Mengmeng Wang, Kun Zhou</h3>
<p>In this paper we tackle the problem of pose guided person image generation,
which aims to transfer a person image from the source pose to a novel target
pose while maintaining the source appearance. Given the inefficiency of
standard CNNs in handling large spatial transformation, we propose a
structure-aware flow based method for high-quality person image generation.
Specifically, instead of learning the complex overall pose changes of human
body, we decompose the human body into different semantic parts (e.g., head,
torso, and legs) and apply different networks to predict the flow fields for
these parts separately. Moreover, we carefully design the network modules to
effectively capture the local and global semantic correlations of features
within and among the human parts respectively. Extensive experimental results
show that our method can generate high-quality results under large pose
discrepancy and outperforms state-of-the-art methods in both qualitative and
quantitative comparisons.
</p>
<a href="http://arxiv.org/abs/2102.02972" target="_blank">arXiv:2102.02972</a> [<a href="http://arxiv.org/pdf/2102.02972" target="_blank">pdf</a>]

<h2>Show, Attend and Distill:Knowledge Distillation via Attention-based Feature Matching. (arXiv:2102.02973v1 [cs.LG])</h2>
<h3>Mingi Ji, Byeongho Heo, Sungrae Park</h3>
<p>Knowledge distillation extracts general knowledge from a pre-trained teacher
network and provides guidance to a target student network. Most studies
manually tie intermediate features of the teacher and student, and transfer
knowledge through pre-defined links. However, manual selection often constructs
ineffective links that limit the improvement from the distillation. There has
been an attempt to address the problem, but it is still challenging to identify
effective links under practical scenarios. In this paper, we introduce an
effective and efficient feature distillation method utilizing all the feature
levels of the teacher without manually selecting the links. Specifically, our
method utilizes an attention-based meta-network that learns relative
similarities between features, and applies identified similarities to control
distillation intensities of all possible pairs. As a result, our method
determines competent links more efficiently than the previous approach and
provides better performance on model compression and transfer learning tasks.
Further qualitative analyses and ablative studies describe how our method
contributes to better distillation. The implementation code is available at
github.com/clovaai/attention-feature-distillation.
</p>
<a href="http://arxiv.org/abs/2102.02973" target="_blank">arXiv:2102.02973</a> [<a href="http://arxiv.org/pdf/2102.02973" target="_blank">pdf</a>]

<h2>Learning While Dissipating Information: Understanding the Generalization Capability of SGLD. (arXiv:2102.02976v1 [stat.ML])</h2>
<h3>Hao Wang, Yizhe Huang, Rui Gao, Flavio P. Calmon</h3>
<p>Understanding the generalization capability of learning algorithms is at the
heart of statistical learning theory. In this paper, we investigate the
generalization gap of stochastic gradient Langevin dynamics (SGLD), a widely
used optimizer for training deep neural networks (DNNs). We derive an
algorithm-dependent generalization bound by analyzing SGLD through an
information-theoretic lens. Our analysis reveals an intricate trade-off between
learning and information dissipation: SGLD learns from data by updating
parameters at each iteration while dissipating information from early training
stages. Our bound also involves the variance of gradients which captures a
particular kind of "sharpness" of the loss landscape. The main proof techniques
in this paper rely on strong data processing inequalities -- a fundamental
concept in information theory -- and Otto-Villani's HWI inequality. Finally, we
demonstrate our bound through numerical experiments, showing that it can
predict the behavior of the true generalization gap.
</p>
<a href="http://arxiv.org/abs/2102.02976" target="_blank">arXiv:2102.02976</a> [<a href="http://arxiv.org/pdf/2102.02976" target="_blank">pdf</a>]

<h2>The Fourier Loss Function. (arXiv:2102.02979v1 [stat.ML])</h2>
<h3>Auricchio Gennaro, Codegoni Andrea, Gualandi Stefano, Zambon Lorenzo</h3>
<p>This paper introduces a new loss function induced by the Fourier-based
Metric. This metric is equivalent to the Wasserstein distance but is computed
very efficiently using the Fast Fourier Transform algorithm. We prove that the
Fourier loss function is twice differentiable, and we provide the explicit
formula for both its gradient and its Hessian matrix. More importantly, we show
that minimising the Fourier loss function is equivalent to maximising the
likelihood of the data under a Gaussian noise in the space of frequencies. We
apply our loss function to a multi-class classification task using MNIST,
Fashion-MNIST, and CIFAR10 datasets. The computational results show that, while
its accuracy is competitive with other state-of-the-art loss functions, the
Fourier loss function is significantly more robust to noisy data.
</p>
<a href="http://arxiv.org/abs/2102.02979" target="_blank">arXiv:2102.02979</a> [<a href="http://arxiv.org/pdf/2102.02979" target="_blank">pdf</a>]

<h2>Finite Sample Analysis of Minimax Offline Reinforcement Learning: Completeness, Fast Rates and First-Order Efficiency. (arXiv:2102.02981v1 [cs.LG])</h2>
<h3>Masatoshi Uehara, Masaaki Imaizumi, Nan Jiang, Nathan Kallus, Wen Sun, Tengyang Xie</h3>
<p>We offer a theoretical characterization of off-policy evaluation (OPE) in
reinforcement learning using function approximation for marginal importance
weights and $q$-functions when these are estimated using recent minimax
methods. Under various combinations of realizability and completeness
assumptions, we show that the minimax approach enables us to achieve a fast
rate of convergence for weights and quality functions, characterized by the
critical inequality \citep{bartlett2005}. Based on this result, we analyze
convergence rates for OPE. In particular, we introduce novel alternative
completeness conditions under which OPE is feasible and we present the first
finite-sample result with first-order efficiency in non-tabular environments,
i.e., having the minimal coefficient in the leading term.
</p>
<a href="http://arxiv.org/abs/2102.02981" target="_blank">arXiv:2102.02981</a> [<a href="http://arxiv.org/pdf/2102.02981" target="_blank">pdf</a>]

<h2>Machine Learning-Based Automated Design Space Exploration for Autonomous Aerial Robots. (arXiv:2102.02988v1 [cs.RO])</h2>
<h3>Srivatsan Krishnan, Zishen Wan, Kshitij Bharadwaj, Paul Whatmough, Aleksandra Faust, Sabrina Neuman, Gu-Yeon Wei, David Brooks, Vijay Janapa Reddi</h3>
<p>Building domain-specific architectures for autonomous aerial robots is
challenging due to a lack of systematic methodology for designing onboard
compute. We introduce a novel performance model called the F-1 roofline to help
architects understand how to build a balanced computing system for autonomous
aerial robots considering both its cyber (sensor rate, compute performance) and
physical components (body-dynamics) that affect the performance of the machine.
We use F-1 to characterize commonly used learning-based autonomy algorithms
with onboard platforms to demonstrate the need for cyber-physical co-design. To
navigate the cyber-physical design space automatically, we subsequently
introduce AutoPilot. This push-button framework automates the co-design of
cyber-physical components for aerial robots from a high-level specification
guided by the F-1 model. AutoPilot uses Bayesian optimization to automatically
co-design the autonomy algorithm and hardware accelerator while considering
various cyber-physical parameters to generate an optimal design under different
task level complexities for different robots and sensor framerates. As a
result, designs generated by AutoPilot, on average, lower mission time up to 2x
over baseline approaches, conserving battery energy.
</p>
<a href="http://arxiv.org/abs/2102.02988" target="_blank">arXiv:2102.02988</a> [<a href="http://arxiv.org/pdf/2102.02988" target="_blank">pdf</a>]

<h2>Learning High DimensionalWasserstein Geodesics. (arXiv:2102.02992v1 [cs.LG])</h2>
<h3>Shu Liu, Shaojun Ma, Yongxin Chen, Hongyuan Zha, Haomin Zhou</h3>
<p>We propose a new formulation and learning strategy for computing the
Wasserstein geodesic between two probability distributions in high dimensions.
By applying the method of Lagrange multipliers to the dynamic formulation of
the optimal transport (OT) problem, we derive a minimax problem whose saddle
point is the Wasserstein geodesic. We then parametrize the functions by deep
neural networks and design a sample based bidirectional learning algorithm for
training. The trained networks enable sampling from the Wasserstein geodesic.
As by-products, the algorithm also computes the Wasserstein distance and OT map
between the marginal distributions. We demonstrate the performance of our
algorithms through a series of experiments with both synthetic and realistic
data.
</p>
<a href="http://arxiv.org/abs/2102.02992" target="_blank">arXiv:2102.02992</a> [<a href="http://arxiv.org/pdf/2102.02992" target="_blank">pdf</a>]

<h2>Deep Texture-Aware Features for Camouflaged Object Detection. (arXiv:2102.02996v1 [cs.CV])</h2>
<h3>Jingjing Ren, Xiaowei Hu, Lei Zhu, Xuemiao Xu, Yangyang Xu, Weiming Wang, Zijun Deng, Pheng-Ann Heng</h3>
<p>Camouflaged object detection is a challenging task that aims to identify
objects having similar texture to the surroundings. This paper presents to
amplify the subtle texture difference between camouflaged objects and the
background for camouflaged object detection by formulating multiple
texture-aware refinement modules to learn the texture-aware features in a deep
convolutional neural network. The texture-aware refinement module computes the
covariance matrices of feature responses to extract the texture information,
designs an affinity loss to learn a set of parameter maps that help to separate
the texture between camouflaged objects and the background, and adopts a
boundary-consistency loss to explore the object detail structures.We evaluate
our network on the benchmark dataset for camouflaged object detection both
qualitatively and quantitatively. Experimental results show that our approach
outperforms various state-of-the-art methods by a large margin.
</p>
<a href="http://arxiv.org/abs/2102.02996" target="_blank">arXiv:2102.02996</a> [<a href="http://arxiv.org/pdf/2102.02996" target="_blank">pdf</a>]

<h2>Zero Training Overhead Portfolios for Learning to Solve Combinatorial Problems. (arXiv:2102.03002v1 [cs.AI])</h2>
<h3>Yiwei Bai, Wenting Zhao, Carla P. Gomes</h3>
<p>There has been an increasing interest in harnessing deep learning to tackle
combinatorial optimization (CO) problems in recent years. Typical CO deep
learning approaches leverage the problem structure in the model architecture.
Nevertheless, the model selection is still mainly based on the conventional
machine learning setting. Due to the discrete nature of CO problems, a single
model is unlikely to learn the problem entirely. We introduce ZTop, which
stands for Zero Training Overhead Portfolio, a simple yet effective model
selection and ensemble mechanism for learning to solve combinatorial problems.
ZTop is inspired by algorithm portfolios, a popular CO ensembling strategy,
particularly restart portfolios, which periodically restart a randomized CO
algorithm, de facto exploring the search space with different heuristics. We
have observed that well-trained models acquired in the same training
trajectory, with similar top validation performance, perform well on very
different validation instances. Following this observation, ZTop ensembles a
set of well-trained models, each providing a unique heuristic with zero
training overhead, and applies them, sequentially or in parallel, to solve the
test instances. We show how ZTopping, i.e., using a ZTop ensemble strategy with
a given deep learning approach, can significantly improve the performance of
the current state-of-the-art deep learning approaches on three prototypical CO
domains, the hardest unique-solution Sudoku instances, challenging routing
problems, and the graph maximum cut problem, as well as on multi-label
classification, a machine learning task with a large combinatorial label space.
</p>
<a href="http://arxiv.org/abs/2102.03002" target="_blank">arXiv:2102.03002</a> [<a href="http://arxiv.org/pdf/2102.03002" target="_blank">pdf</a>]

<h2>Sampling Based Scene-Space Video Processing. (arXiv:2102.03011v1 [cs.CV])</h2>
<h3>Felix Klose, Oliver Wang, Jean-Charles Bazin, Marcus Magnor, Alexander Sorkine-Hornung</h3>
<p>Many compelling video processing effects can be achieved if per-pixel depth
information and 3D camera calibrations are known. However, the success of such
methods is highly dependent on the accuracy of this "scene-space" information.
We present a novel, sampling-based framework for processing video that enables
high-quality scene-space video effects in the presence of inevitable errors in
depth and camera pose estimation. Instead of trying to improve the explicit 3D
scene representation, the key idea of our method is to exploit the high
redundancy of approximate scene information that arises due to most scene
points being visible multiple times across many frames of video. Based on this
observation, we propose a novel pixel gathering and filtering approach. The
gathering step is general and collects pixel samples in scene-space, while the
filtering step is application-specific and computes a desired output video from
the gathered sample sets. Our approach is easily parallelizable and has been
implemented on GPU, allowing us to take full advantage of large volumes of
video data and facilitating practical runtimes on HD video using a standard
desktop computer. Our generic scene-space formulation is able to
comprehensively describe a multitude of video processing applications such as
denoising, deblurring, super resolution, object removal, computational shutter
functions, and other scene-space camera effects. We present results for various
casually captured, hand-held, moving, compressed, monocular videos depicting
challenging scenes recorded in uncontrolled environments.
</p>
<a href="http://arxiv.org/abs/2102.03011" target="_blank">arXiv:2102.03011</a> [<a href="http://arxiv.org/pdf/2102.03011" target="_blank">pdf</a>]

<h2>Fast and Memory Efficient Differentially Private-SGD via JL Projections. (arXiv:2102.03013v1 [cs.LG])</h2>
<h3>Zhiqi Bu, Sivakanth Gopi, Janardhan Kulkarni, Yin Tat Lee, Judy Hanwen Shen, Uthaipon Tantipongpipat</h3>
<p>Differentially Private-SGD (DP-SGD) of Abadi et al. (2016) and its variations
are the only known algorithms for private training of large scale neural
networks. This algorithm requires computation of per-sample gradients norms
which is extremely slow and memory intensive in practice. In this paper, we
present a new framework to design differentially private optimizers called
DP-SGD-JL and DP-Adam-JL. Our approach uses Johnson-Lindenstrauss (JL)
projections to quickly approximate the per-sample gradient norms without
exactly computing them, thus making the training time and memory requirements
of our optimizers closer to that of their non-DP versions.

Unlike previous attempts to make DP-SGD faster which work only on a subset of
network architectures or use compiler techniques, we propose an algorithmic
solution which works for any network in a black-box manner which is the main
contribution of this paper. To illustrate this, on IMDb dataset, we train a
Recurrent Neural Network (RNN) to achieve good privacy-vs-accuracy tradeoff,
while being significantly faster than DP-SGD and with a similar memory
footprint as non-private SGD. The privacy analysis of our algorithms is more
involved than DP-SGD, we use the recently proposed f-DP framework of Dong et
al. (2019) to prove privacy.
</p>
<a href="http://arxiv.org/abs/2102.03013" target="_blank">arXiv:2102.03013</a> [<a href="http://arxiv.org/pdf/2102.03013" target="_blank">pdf</a>]

<h2>A Variational Information Bottleneck Approach to Multi-Omics Data Integration. (arXiv:2102.03014v1 [cs.LG])</h2>
<h3>Changhee Lee, Mihaela van der Schaar</h3>
<p>Integration of data from multiple omics techniques is becoming increasingly
important in biomedical research. Due to non-uniformity and technical
limitations in omics platforms, such integrative analyses on multiple omics,
which we refer to as views, involve learning from incomplete observations with
various view-missing patterns. This is challenging because i) complex
interactions within and across observed views need to be properly addressed for
optimal predictive power and ii) observations with various view-missing
patterns need to be flexibly integrated. To address such challenges, we propose
a deep variational information bottleneck (IB) approach for incomplete
multi-view observations. Our method applies the IB framework on marginal and
joint representations of the observed views to focus on intra-view and
inter-view interactions that are relevant for the target. Most importantly, by
modeling the joint representations as a product of marginal representations, we
can efficiently learn from observed views with various view-missing patterns.
Experiments on real-world datasets show that our method consistently achieves
gain from data integration and outperforms state-of-the-art benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.03014" target="_blank">arXiv:2102.03014</a> [<a href="http://arxiv.org/pdf/2102.03014" target="_blank">pdf</a>]

<h2>Evaluating Deep Learning in SystemML using Layer-wise Adaptive Rate Scaling(LARS) Optimizer. (arXiv:2102.03018v1 [cs.LG])</h2>
<h3>Kanchan Chowdhury, Ankita Sharma, Arun Deepak Chandrasekar</h3>
<p>Increasing the batch size of a deep learning model is a challenging task.
Although it might help in utilizing full available system memory during
training phase of a model, it results in significant loss of test accuracy most
often. LARS solved this issue by introducing an adaptive learning rate for each
layer of a deep learning model. However, there are doubts on how popular
distributed machine learning systems such as SystemML or MLlib will perform
with this optimizer. In this work, we apply LARS optimizer to a deep learning
model implemented using SystemML.We perform experiments with various batch
sizes and compare the performance of LARS optimizer with \textit{Stochastic
Gradient Descent}. Our experimental results show that LARS optimizer performs
significantly better than Stochastic Gradient Descent for large batch sizes
even with the distributed machine learning framework, SystemML.
</p>
<a href="http://arxiv.org/abs/2102.03018" target="_blank">arXiv:2102.03018</a> [<a href="http://arxiv.org/pdf/2102.03018" target="_blank">pdf</a>]

<h2>Deceptive Reinforcement Learning for Privacy-Preserving Planning. (arXiv:2102.03022v1 [cs.LG])</h2>
<h3>Zhengshang Liu, Yue Yang, Tim Miller, Peta Masters</h3>
<p>In this paper, we study the problem of deceptive reinforcement learning to
preserve the privacy of a reward function. Reinforcement learning is the
problem of finding a behaviour policy based on rewards received from
exploratory behaviour. A key ingredient in reinforcement learning is a reward
function, which determines how much reward (negative or positive) is given and
when. However, in some situations, we may want to keep a reward function
private; that is, to make it difficult for an observer to determine the reward
function used. We define the problem of privacy-preserving reinforcement
learning, and present two models for solving it. These models are based on
dissimulation -- a form of deception that `hides the truth'. We evaluate our
models both computationally and via human behavioural experiments. Results show
that the resulting policies are indeed deceptive, and that participants can
determine the true reward function less reliably than that of an honest agent.
</p>
<a href="http://arxiv.org/abs/2102.03022" target="_blank">arXiv:2102.03022</a> [<a href="http://arxiv.org/pdf/2102.03022" target="_blank">pdf</a>]

<h2>Instance and Panoptic Segmentation Using Conditional Convolutions. (arXiv:2102.03026v1 [cs.CV])</h2>
<h3>Zhi Tian, Bowen Zhang, Hao Chen, Chunhua Shen</h3>
<p>We propose a simple yet effective framework for instance and panoptic
segmentation, termed CondInst (conditional convolutions for instance and
panoptic segmentation). In the literature, top-performing instance segmentation
methods typically follow the paradigm of Mask R-CNN and rely on ROI operations
(typically ROIAlign) to attend to each instance. In contrast, we propose to
attend to the instances with dynamic conditional convolutions. Instead of using
instance-wise ROIs as inputs to the instance mask head of fixed weights, we
design dynamic instance-aware mask heads, conditioned on the instances to be
predicted. CondInst enjoys three advantages: 1.) Instance and panoptic
segmentation are unified into a fully convolutional network, eliminating the
need for ROI cropping and feature alignment. 2.) The elimination of the ROI
cropping also significantly improves the output instance mask resolution. 3.)
Due to the much improved capacity of dynamically-generated conditional
convolutions, the mask head can be very compact (e.g., 3 conv. layers, each
having only 8 channels), leading to significantly faster inference time per
instance and making the overall inference time almost constant, irrelevant to
the number of instances. We demonstrate a simpler method that can achieve
improved accuracy and inference speed on both instance and panoptic
segmentation tasks. On the COCO dataset, we outperform a few state-of-the-art
methods. We hope that CondInst can be a strong baseline for instance and
panoptic segmentation. Code is available at: https://git.io/AdelaiDet
</p>
<a href="http://arxiv.org/abs/2102.03026" target="_blank">arXiv:2102.03026</a> [<a href="http://arxiv.org/pdf/2102.03026" target="_blank">pdf</a>]

<h2>Hyperparameter Optimization Is Deceiving Us, and How to Stop It. (arXiv:2102.03034v1 [cs.LG])</h2>
<h3>A. Feder Cooper, Yucheng Lu, Christopher De Sa</h3>
<p>While hyperparameter optimization (HPO) is known to greatly impact learning
algorithm performance, it is often treated as an empirical afterthought. Recent
empirical works have highlighted the risk of this second-rate treatment of HPO.
They show that inconsistent performance results, based on choice of
hyperparameter subspace to search, are a widespread problem in ML research.
When comparing two algorithms, J and K searching one subspace can yield the
conclusion that J outperforms K, whereas searching another can entail the
opposite result. In short, your choice of hyperparameters can deceive you. We
provide a theoretical complement to this prior work: We analytically
characterize this problem, which we term hyperparameter deception, and show
that grid search is inherently deceptive. We prove a defense with guarantees
against deception, and demonstrate a defense in practice.
</p>
<a href="http://arxiv.org/abs/2102.03034" target="_blank">arXiv:2102.03034</a> [<a href="http://arxiv.org/pdf/2102.03034" target="_blank">pdf</a>]

<h2>DEAL: Decremental Energy-Aware Learning in a Federated System. (arXiv:2102.03051v1 [cs.LG])</h2>
<h3>Wenting Zou, Li Li, Zichen Xu, Chengzhong Xu</h3>
<p>Federated learning struggles with their heavy energy footprint on
battery-powered devices. The learning process keeps all devices awake while
draining expensive battery power to train a shared model collaboratively, yet
it may still leak sensitive personal information. Traditional energy management
techniques in system kernel mode can force the training device entering low
power states, but it may violate the SLO of the collaborative learning. To
address the conflict between learning SLO and energy efficiency, we propose
DEAL, an energy efficient learning system that saves energy and preserves
privacy with a decremental learning design. DEAL reduces the energy footprint
from two layers: 1) an optimization layer that selects a subset of workers with
sufficient capacity and maximum rewards. 2) a specified decremental learning
algorithm that actively provides a decremental and incremental update
functions, which allows kernel to correctly tune the local DVFS. We prototyped
DEAL in containerized services with modern smartphone profiles and evaluated it
with several learning benchmarks with realistic traces. We observed that DEAL
achieves 75.6%-82.4% less energy footprint in different datasets, compared to
the traditional methods. All learning processes are faster than
state-of-the-practice FL frameworks up to 2-4X in model convergence.
</p>
<a href="http://arxiv.org/abs/2102.03051" target="_blank">arXiv:2102.03051</a> [<a href="http://arxiv.org/pdf/2102.03051" target="_blank">pdf</a>]

<h2>Risk-Constrained Interactive Safety under Behavior Uncertainty for Autonomous Driving. (arXiv:2102.03053v1 [cs.AI])</h2>
<h3>Julian Bernhard, Alois Knoll</h3>
<p>Balancing safety and efficiency when planning in dense traffic is
challenging. Interactive behavior planners incorporate prediction uncertainty
and interactivity inherent to these traffic situations. Yet, their use of
single-objective optimality impedes interpretability of the resulting safety
goal. Safety envelopes which restrict the allowed planning region yield
interpretable safety under the presence of behavior uncertainty, yet, they
sacrifice efficiency in dense traffic due to conservative driving. Studies show
that humans balance safety and efficiency in dense traffic by accepting a
probabilistic risk of violating the safety envelope. In this work, we adopt
this safety objective for interactive planning. Specifically, we formalize this
safety objective, present the Risk-Constrained Robust Stochastic Bayesian Game
modeling interactive decisions satisfying a maximum risk of violating a safety
envelope under uncertainty of other traffic participants' behavior and solve it
using our variant of Multi-Agent Monte Carlo Tree Search. We demonstrate in
simulation that our approach outperforms baselines approaches, and by reaching
the specified violation risk level over driven simulation time, provides an
interpretable and tunable safety objective for interactive planning.
</p>
<a href="http://arxiv.org/abs/2102.03053" target="_blank">arXiv:2102.03053</a> [<a href="http://arxiv.org/pdf/2102.03053" target="_blank">pdf</a>]

<h2>Removing biased data to improve fairness and accuracy. (arXiv:2102.03054v1 [cs.LG])</h2>
<h3>Sahil Verma, Michael Ernst, Rene Just</h3>
<p>Machine learning systems are often trained using data collected from
historical decisions. If past decisions were biased, then automated systems
that learn from historical data will also be biased. We propose a black-box
approach to identify and remove biased training data. Machine learning models
trained on such debiased data (a subset of the original training data) have low
individual discrimination, often 0%. These models also have greater accuracy
and lower statistical disparity than models trained on the full historical
data. We evaluated our methodology in experiments using 6 real-world datasets.
Our approach outperformed seven previous approaches in terms of individual
discrimination and accuracy.
</p>
<a href="http://arxiv.org/abs/2102.03054" target="_blank">arXiv:2102.03054</a> [<a href="http://arxiv.org/pdf/2102.03054" target="_blank">pdf</a>]

<h2>Sparse Normal Means Estimation with Sublinear Communication. (arXiv:2102.03060v1 [stat.ML])</h2>
<h3>Chen Amiraz, Robert Krauthgamer, Boaz Nadler</h3>
<p>We consider the problem of sparse normal means estimation in a distributed
setting with communication constraints. We assume there are $M$ machines, each
holding a $d$-dimensional observation of a $K$-sparse vector $\mu$ corrupted by
additive Gaussian noise. A central fusion machine is connected to the $M$
machines in a star topology, and its goal is to estimate the vector $\mu$ with
a low communication budget. Previous works have shown that to achieve the
centralized minimax rate for the $\ell_2$ risk, the total communication must be
high - at least linear in the dimension $d$. This phenomenon occurs, however,
at very weak signals. We show that once the signal-to-noise ratio (SNR) is
slightly higher, the support of $\mu$ can be correctly recovered with much less
communication. Specifically, we present two algorithms for the distributed
sparse normal means problem, and prove that above a certain SNR threshold, with
high probability, they recover the correct support with total communication
that is sublinear in the dimension $d$. Furthermore, the communication
decreases exponentially as a function of signal strength. If in addition $KM\ll
d$, then with an additional round of sublinear communication, our algorithms
achieve the centralized rate for the $\ell_2$ risk. Finally, we present
simulations that illustrate the performance of our algorithms in different
parameter regimes.
</p>
<a href="http://arxiv.org/abs/2102.03060" target="_blank">arXiv:2102.03060</a> [<a href="http://arxiv.org/pdf/2102.03060" target="_blank">pdf</a>]

<h2>Understanding Emails and Drafting Responses -- An Approach Using GPT-3. (arXiv:2102.03062v1 [cs.AI])</h2>
<h3>Jonas Thiergart, Stefan Huber, Thomas &#xdc;bellacker</h3>
<p>Providing computer systems with the ability to understand and generate
natural language has long been a challenge of engineers. Recent progress in
natural language processing (NLP), like the GPT-3 language model released by
OpenAI, has made both possible to an extent. In this paper, we explore the
possibility of rationalising email communication using GPT-3. First, we
demonstrate the technical feasibility of understanding incoming emails and
generating responses, drawing on literature from the disciplines of software
engineering as well as data science. Second, we apply knowledge from both
business studies and, again, software engineering to identify ways to tackle
challenges we encountered. Third, we argue for the economic viability of such a
solution by analysing costs and market demand. We conclude that applying GPT-3
to rationalising email communication is feasible both technically and
economically.
</p>
<a href="http://arxiv.org/abs/2102.03062" target="_blank">arXiv:2102.03062</a> [<a href="http://arxiv.org/pdf/2102.03062" target="_blank">pdf</a>]

<h2>"I Don't Think So": Disagreement-Based Policy Summaries for Comparing Agents. (arXiv:2102.03064v1 [cs.AI])</h2>
<h3>Yotam Amitai, Ofra Amir</h3>
<p>With Artificial Intelligence on the rise, human interaction with autonomous
agents becomes more frequent. Effective human-agent collaboration requires that
the human understands the agent's behavior, as failing to do so may lead to
reduced productiveness, misuse, frustration and even danger. Agent strategy
summarization methods are used to describe the strategy of an agent to its
destined user through demonstration. The summary's purpose is to maximize the
user's understanding of the agent's aptitude by showcasing its behaviour in a
set of world states, chosen by some importance criteria. While shown to be
useful, we show that these methods are limited in supporting the task of
comparing agent behavior, as they independently generate a summary for each
agent. In this paper, we propose a novel method for generating contrastive
summaries that highlight the differences between agent's policies by
identifying and ranking states in which the agents disagree on the best course
of action. We conduct a user study in which participants face an agent
selection task. Our results show that the novel disagreement-based summaries
lead to improved user performance compared to summaries generated using
HIGHLIGHTS, a previous strategy summarization algorithm.
</p>
<a href="http://arxiv.org/abs/2102.03064" target="_blank">arXiv:2102.03064</a> [<a href="http://arxiv.org/pdf/2102.03064" target="_blank">pdf</a>]

<h2>Co-Mixup: Saliency Guided Joint Mixup with Supermodular Diversity. (arXiv:2102.03065v1 [cs.LG])</h2>
<h3>Jang-Hyun Kim, Wonho Choo, Hosan Jeong, Hyun Oh Song</h3>
<p>While deep neural networks show great performance on fitting to the training
distribution, improving the networks' generalization performance to the test
distribution and robustness to the sensitivity to input perturbations still
remain as a challenge. Although a number of mixup based augmentation strategies
have been proposed to partially address them, it remains unclear as to how to
best utilize the supervisory signal within each input data for mixup from the
optimization perspective. We propose a new perspective on batch mixup and
formulate the optimal construction of a batch of mixup data maximizing the data
saliency measure of each individual mixup data and encouraging the supermodular
diversity among the constructed mixup data. This leads to a novel discrete
optimization problem minimizing the difference between submodular functions. We
also propose an efficient modular approximation based iterative submodular
minimization algorithm for efficient mixup computation per each minibatch
suitable for minibatch based neural network training. Our experiments show the
proposed method achieves the state of the art generalization, calibration, and
weakly supervised localization results compared to other mixup methods. The
source code is available at https://github.com/snu-mllab/Co-Mixup.
</p>
<a href="http://arxiv.org/abs/2102.03065" target="_blank">arXiv:2102.03065</a> [<a href="http://arxiv.org/pdf/2102.03065" target="_blank">pdf</a>]

<h2>Achieving Explainability for Plant Disease Classification with Disentangled Variational Autoencoders. (arXiv:2102.03082v1 [cs.CV])</h2>
<h3>Harshana Habaragamuwa, Yu Oishi, Kenichi Tanaka</h3>
<p>Agricultural image recognition tasks are becoming increasingly dependent on
deep learning (DL). Despite its excellent performance, it is difficult to
comprehend what type of logic or features DL uses in its decision making. This
has become a roadblock for the implementation and development of DL-based image
recognition methods because knowing the logic or features used in decision
making, such as in a classification task, is very important for verification,
algorithm improvement, training data improvement, knowledge extraction, etc. To
mitigate such problems, we developed a classification method based on a
variational autoencoder architecture that can show not only the location of the
most important features but also what variations of that particular feature are
used. Using the PlantVillage dataset, we achieved an acceptable level of
explainability without sacrificing the accuracy of the classification. Although
the proposed method was tested for disease diagnosis in some crops, the method
can be extended to other crops as well as other image classification tasks. In
the future, we hope to use this explainable artificial intelligence algorithm
in disease identification tasks, such as the identification of potato blackleg
disease and potato virus Y (PVY), and other image classification tasks.
</p>
<a href="http://arxiv.org/abs/2102.03082" target="_blank">arXiv:2102.03082</a> [<a href="http://arxiv.org/pdf/2102.03082" target="_blank">pdf</a>]

<h2>Boost AI Power: Data Augmentation Strategies with unlabelled Data and Conformal Prediction, a Case in Alternative Herbal Medicine Discrimination with Electronic Nose. (arXiv:2102.03088v1 [cs.LG])</h2>
<h3>Li Liu, Xianghao Zhan, Rumeng Wu, Xiaoqing Guan, Zhan Wang, Wei Zhang, You Wang, Zhiyuan Luo, Guang Li</h3>
<p>Electronic nose proves its effectiveness in alternativeherbal medicine
classification, but due to the supervised learn-ing nature, previous research
relies on the labelled training data,which are time-costly and labor-intensive
to collect. Consideringthe training data inadequacy in real-world applications,
this studyaims to improve classification accuracy via data
augmentationstrategies. We stimulated two scenarios to investigate the
effective-ness of five data augmentation strategies under different
trainingdata inadequacy: in the noise-free scenario, different availability
ofunlabelled data were simulated, and in the noisy scenario, differentlevels of
Gaussian noises and translational shifts were added tosimulate sensor drifts.
The augmentation strategies: noise-addingdata augmentation, semi-supervised
learning, classifier-based online learning, inductive conformal prediction
(ICP) onlinelearning and the novel ensemble ICP online learning proposed in
this study, were compared against supervised learningbaseline, with Linear
Discriminant Analysis (LDA) and Support Vector Machine (SVM) as the
classifiers. We found thatat least one strategies significantly improved the
classification accuracy with LDA(p&lt;=0.05) and showed
non-decreasingclassification accuracy with SVM in each tasks. Moreover, our
novel strategy: ensemble ICP online learning outperformedthe others by showing
non-decreasing classification accuracy on all tasks and significant improvement
on most tasks(25/36 tasks,p&lt;=0.05). This study provides a systematic analysis
over augmentation strategies, and we provided userswith recommended strategies
under specific circumstances. Furthermore, our newly proposed strategy showed
botheffectiveness and robustness in boosting the classification model
generalizability, which can also be further employed inother machine learning
applications.
</p>
<a href="http://arxiv.org/abs/2102.03088" target="_blank">arXiv:2102.03088</a> [<a href="http://arxiv.org/pdf/2102.03088" target="_blank">pdf</a>]

<h2>Bidirectional Multi-scale Attention Networks for Semantic Segmentation of Oblique UAV Imagery. (arXiv:2102.03099v1 [cs.CV])</h2>
<h3>Ye Lyu, George Vosselman, Gui-Song Xia, Michael Ying Yang</h3>
<p>Semantic segmentation for aerial platforms has been one of the fundamental
scene understanding task for the earth observation. Most of the semantic
segmentation research focused on scenes captured in nadir view, in which
objects have relatively smaller scale variation compared with scenes captured
in oblique view. The huge scale variation of objects in oblique images limits
the performance of deep neural networks (DNN) that process images in a single
scale fashion. In order to tackle the scale variation issue, in this paper, we
propose the novel bidirectional multi-scale attention networks, which fuse
features from multiple scales bidirectionally for more adaptive and effective
feature extraction. The experiments are conducted on the UAVid2020 dataset and
have shown the effectiveness of our method. Our model achieved the
state-of-the-art (SOTA) result with a mean intersection over union (mIoU) score
of 70.80%.
</p>
<a href="http://arxiv.org/abs/2102.03099" target="_blank">arXiv:2102.03099</a> [<a href="http://arxiv.org/pdf/2102.03099" target="_blank">pdf</a>]

<h2>DeepReduce: A Sparse-tensor Communication Framework for Distributed Deep Learning. (arXiv:2102.03112v1 [cs.LG])</h2>
<h3>Kelly Kostopoulou, Hang Xu, Aritra Dutta, Xin Li, Alexandros Ntoulas, Panos Kalnis</h3>
<p>Sparse tensors appear frequently in distributed deep learning, either as a
direct artifact of the deep neural network's gradients, or as a result of an
explicit sparsification process. Existing communication primitives are agnostic
to the peculiarities of deep learning; consequently, they impose unnecessary
communication overhead. This paper introduces DeepReduce, a versatile framework
for the compressed communication of sparse tensors, tailored for distributed
deep learning. DeepReduce decomposes sparse tensors in two sets, values and
indices, and allows both independent and combined compression of these sets. We
support a variety of common compressors, such as Deflate for values, or
run-length encoding for indices. We also propose two novel compression schemes
that achieve superior results: curve fitting-based for values and bloom
filter-based for indices. DeepReduce is orthogonal to existing gradient
sparsifiers and can be applied in conjunction with them, transparently to the
end-user, to significantly lower the communication overhead. As proof of
concept, we implement our approach on Tensorflow and PyTorch. Our experiments
with large real models demonstrate that DeepReduce transmits fewer data and
imposes lower computational overhead than existing methods, without affecting
the training accuracy.
</p>
<a href="http://arxiv.org/abs/2102.03112" target="_blank">arXiv:2102.03112</a> [<a href="http://arxiv.org/pdf/2102.03112" target="_blank">pdf</a>]

<h2>Real-World Super-Resolution of Face-Images from Surveillance Cameras. (arXiv:2102.03113v1 [cs.CV])</h2>
<h3>Andreas Aakerberg, Kamal Nasrollahi, Thomas B. Moeslund</h3>
<p>Most existing face image Super-Resolution (SR) methods assume that the
Low-Resolution (LR) images were artificially downsampled from High-Resolution
(HR) images with bicubic interpolation. This operation changes the natural
image characteristics and reduces noise. Hence, SR methods trained on such data
most often fail to produce good results when applied to real LR images. To
solve this problem, we propose a novel framework for generation of realistic
LR/HR training pairs. Our framework estimates realistic blur kernels, noise
distributions, and JPEG compression artifacts to generate LR images with
similar image characteristics as the ones in the source domain. This allows us
to train a SR model using high quality face images as Ground-Truth (GT). For
better perceptual quality we use a Generative Adversarial Network (GAN) based
SR model where we have exchanged the commonly used VGG-loss [24] with
LPIPS-loss [52]. Experimental results on both real and artificially corrupted
face images show that our method results in more detailed reconstructions with
less noise compared to existing State-of-the-Art (SoTA) methods. In addition,
we show that the traditional non-reference Image Quality Assessment (IQA)
methods fail to capture this improvement and demonstrate that the more recent
NIMA metric [16] correlates better with human perception via Mean Opinion Rank
(MOR).
</p>
<a href="http://arxiv.org/abs/2102.03113" target="_blank">arXiv:2102.03113</a> [<a href="http://arxiv.org/pdf/2102.03113" target="_blank">pdf</a>]

<h2>Multispectral Object Detection with Deep Learning. (arXiv:2102.03115v1 [cs.CV])</h2>
<h3>Md Osman Gani, Somenath Kuiry, Alaka Das, Mita Nasipuri, Nibaran Das</h3>
<p>Object detection in natural scenes can be a challenging task. In many
real-life situations, the visible spectrum is not suitable for traditional
computer vision tasks. Moving outside the visible spectrum range, such as the
thermal spectrum or the near-infrared (NIR) images, is much more beneficial in
low visibility conditions, NIR images are very helpful for understanding the
object's material quality. In this work, we have taken images with both the
Thermal and NIR spectrum for the object detection task. As multi-spectral data
with both Thermal and NIR is not available for the detection task, we needed to
collect data ourselves. Data collection is a time-consuming process, and we
faced many obstacles that we had to overcome. We train the YOLO v3 network from
scratch to detect an object from multi-spectral images. Also, to avoid
overfitting, we have done data augmentation and tune hyperparameters.
</p>
<a href="http://arxiv.org/abs/2102.03115" target="_blank">arXiv:2102.03115</a> [<a href="http://arxiv.org/pdf/2102.03115" target="_blank">pdf</a>]

<h2>Addressing Inherent Uncertainty: Risk-Sensitive Behavior Generation for Automated Driving using Distributional Reinforcement Learning. (arXiv:2102.03119v1 [cs.AI])</h2>
<h3>Julian Bernhard, Stefan Pollok, Alois Knoll</h3>
<p>For highly automated driving above SAE level~3, behavior generation
algorithms must reliably consider the inherent uncertainties of the traffic
environment, e.g. arising from the variety of human driving styles. Such
uncertainties can generate ambiguous decisions, requiring the algorithm to
appropriately balance low-probability hazardous events, e.g. collisions, and
high-probability beneficial events, e.g. quickly crossing the intersection.
State-of-the-art behavior generation algorithms lack a distributional treatment
of decision outcome. This impedes a proper risk evaluation in ambiguous
situations, often encouraging either unsafe or conservative behavior. Thus, we
propose a two-step approach for risk-sensitive behavior generation combining
offline distribution learning with online risk assessment. Specifically, we
first learn an optimal policy in an uncertain environment with Deep
Distributional Reinforcement Learning. During execution, the optimal
risk-sensitive action is selected by applying established risk criteria, such
as the Conditional Value at Risk, to the learned state-action return
distributions. In intersection crossing scenarios, we evaluate different risk
criteria and demonstrate that our approach increases safety, while maintaining
an active driving style. Our approach shall encourage further studies about the
benefits of risk-sensitive approaches for self-driving vehicles.
</p>
<a href="http://arxiv.org/abs/2102.03119" target="_blank">arXiv:2102.03119</a> [<a href="http://arxiv.org/pdf/2102.03119" target="_blank">pdf</a>]

<h2>Experience-Based Heuristic Search: Robust Motion Planning with Deep Q-Learning. (arXiv:2102.03127v1 [cs.RO])</h2>
<h3>Julian Bernhard, Robert Gieselmann, Klemens Esterle, Alois Knoll</h3>
<p>Interaction-aware planning for autonomous driving requires an exploration of
a combinatorial solution space when using conventional search- or
optimization-based motion planners. With Deep Reinforcement Learning, optimal
driving strategies for such problems can be derived also for higher-dimensional
problems. However, these methods guarantee optimality of the resulting policy
only in a statistical sense, which impedes their usage in safety critical
systems, such as autonomous vehicles. Thus, we propose the
Experience-Based-Heuristic-Search algorithm, which overcomes the statistical
failure rate of a Deep-reinforcement-learning-based planner and still benefits
computationally from the pre-learned optimal policy. Specifically, we show how
experiences in the form of a Deep Q-Network can be integrated as heuristic into
a heuristic search algorithm. We benchmark our algorithm in the field of path
planning in semi-structured valet parking scenarios. There, we analyze the
accuracy of such estimates and demonstrate the computational advantages and
robustness of our method. Our method may encourage further investigation of the
applicability of reinforcement-learning-based planning in the field of
self-driving vehicles.
</p>
<a href="http://arxiv.org/abs/2102.03127" target="_blank">arXiv:2102.03127</a> [<a href="http://arxiv.org/pdf/2102.03127" target="_blank">pdf</a>]

<h2>Integer Programming for Causal Structure Learning in the Presence of Latent Variables. (arXiv:2102.03129v1 [cs.LG])</h2>
<h3>Rui Chen, Sanjeeb Dash, Tian Gao</h3>
<p>The problem of finding an ancestral acyclic directed mixed graph (ADMG) that
represents the causal relationships between a set of variables is an important
area of research for causal inference. However, most of existing score-based
structure learning methods focus on learning the directed acyclic graph (DAG)
without latent variables. A number of score-based methods have recently been
proposed for the ADMG learning, yet they are heuristic in nature and do not
guarantee an optimal solution. We propose a novel exact score-based method that
solves an integer programming (IP) formulation and returns a score-maximizing
ancestral ADMG for a set of continuous variables. In particular, we generalize
the state-of-the-art IP model for DAG learning problems and derive new classes
of valid inequalities to formalize the IP-based ADMG learning model.
Empirically our model can be solved efficiently for medium-sized problems and
achieves better accuracy than state-of-the-art score-based methods as well as
benchmark constraint-based methods.
</p>
<a href="http://arxiv.org/abs/2102.03129" target="_blank">arXiv:2102.03129</a> [<a href="http://arxiv.org/pdf/2102.03129" target="_blank">pdf</a>]

<h2>Zero-shot Learning with Deep Neural Networks for Object Recognition. (arXiv:2102.03137v1 [cs.CV])</h2>
<h3>Yannick Le Cacheux, Herv&#xe9; Le Borgne, Michel Crucianu</h3>
<p>Zero-shot learning deals with the ability to recognize objects without any
visual training sample. To counterbalance this lack of visual data, each class
to recognize is associated with a semantic prototype that reflects the
essential features of the object. The general approach is to learn a mapping
from visual data to semantic prototypes, then use it at inference to classify
visual samples from the class prototypes only. Different settings of this
general configuration can be considered depending on the use case of interest,
in particular whether one only wants to classify objects that have not been
employed to learn the mapping or whether one can use unlabelled visual examples
to learn the mapping. This chapter presents a review of the approaches based on
deep neural networks to tackle the ZSL problem. We highlight findings that had
a large impact on the evolution of this domain and list its current challenges.
</p>
<a href="http://arxiv.org/abs/2102.03137" target="_blank">arXiv:2102.03137</a> [<a href="http://arxiv.org/pdf/2102.03137" target="_blank">pdf</a>]

<h2>An advantage actor-critic algorithm for robotic motion planning in dense and dynamic scenarios. (arXiv:2102.03138v1 [cs.RO])</h2>
<h3>Chengmin Zhou, Bingding Huang, Pasi Fr&#xe4;nti</h3>
<p>Intelligent robots provide a new insight into efficiency improvement in
industrial and service scenarios to replace human labor. However, these
scenarios include dense and dynamic obstacles that make motion planning of
robots challenging. Traditional algorithms like A* can plan collision-free
trajectories in static environment, but their performance degrades and
computational cost increases steeply in dense and dynamic scenarios.
Optimal-value reinforcement learning algorithms (RL) can address these problems
but suffer slow speed and instability in network convergence. Network of policy
gradient RL converge fast in Atari games where action is discrete and finite,
but few works have been done to address problems where continuous actions and
large action space are required. In this paper, we modify existing advantage
actor-critic algorithm and suit it to complex motion planning, therefore
optimal speeds and directions of robot are generated. Experimental results
demonstrate that our algorithm converges faster and stable than optimal-value
RL. It achieves higher success rate in motion planning with lesser processing
time for robot to reach its goal.
</p>
<a href="http://arxiv.org/abs/2102.03138" target="_blank">arXiv:2102.03138</a> [<a href="http://arxiv.org/pdf/2102.03138" target="_blank">pdf</a>]

<h2>CharacterGAN: Few-Shot Keypoint Character Animation and Reposing. (arXiv:2102.03141v1 [cs.CV])</h2>
<h3>Tobias Hinz, Matthew Fisher, Oliver Wang, Eli Shechtman, Stefan Wermter</h3>
<p>We introduce CharacterGAN, a generative model that can be trained on only a
few samples (8 - 15) of a given character. Our model generates novel poses
based on keypoint locations, which can be modified in real time while providing
interactive feedback, allowing for intuitive reposing and animation. Since we
only have very limited training samples, one of the key challenges lies in how
to address (dis)occlusions, e.g. when a hand moves behind or in front of a
body. To address this, we introduce a novel layering approach which explicitly
splits the input keypoints into different layers which are processed
independently. These layers represent different parts of the character and
provide a strong implicit bias that helps to obtain realistic results even with
strong (dis)occlusions. To combine the features of individual layers we use an
adaptive scaling approach conditioned on all keypoints. Finally, we introduce a
mask connectivity constraint to reduce distortion artifacts that occur with
extreme out-of-distribution poses at test time. We show that our approach
outperforms recent baselines and creates realistic animations for diverse
characters. We also show that our model can handle discrete state changes, for
example a profile facing left or right, that the different layers do indeed
learn features specific for the respective keypoints in those layers, and that
our model scales to larger datasets when more data is available.
</p>
<a href="http://arxiv.org/abs/2102.03141" target="_blank">arXiv:2102.03141</a> [<a href="http://arxiv.org/pdf/2102.03141" target="_blank">pdf</a>]

<h2>Graph Joint Attention Networks. (arXiv:2102.03147v1 [cs.LG])</h2>
<h3>Tiantian He, Lu Bai, Yew-Soon Ong</h3>
<p>Graph attention networks (GATs) have been recognized as powerful tools for
learning in graph structured data. However, how to enable the attention
mechanisms in GATs to smoothly consider both structural and feature information
is still very challenging. In this paper, we propose Graph Joint Attention
Networks (JATs) to address the aforementioned challenge. Different from
previous attention-based graph neural networks (GNNs), JATs adopt novel joint
attention mechanisms which can automatically determine the relative
significance between node features and structural coefficients learned from
graph topology, when computing the attention scores. Therefore, representations
concerning more structural properties can be inferred by JATs. Besides, we
theoretically analyze the expressive power of JATs and further propose an
improved strategy for the joint attention mechanisms that enables JATs to reach
the upper bound of expressive power which every message-passing GNN can
ultimately achieve, i.e., 1-WL test. JATs can thereby be seen as most powerful
message-passing GNNs. The proposed neural architecture has been extensively
tested on widely used benchmarking datasets, and has been compared with
state-of-the-art GNNs for various downstream predictive tasks. Experimental
results show that JATs achieve state-of-the-art performance on all the testing
datasets.
</p>
<a href="http://arxiv.org/abs/2102.03147" target="_blank">arXiv:2102.03147</a> [<a href="http://arxiv.org/pdf/2102.03147" target="_blank">pdf</a>]

<h2>Securing emergent behaviour in swarm robotics. (arXiv:2102.03148v1 [cs.RO])</h2>
<h3>Liqun Chen, Siaw-Lynn Ng</h3>
<p>Swarm robotics is the study of how a large number of relatively simple robots
can be designed so that a desired collective behaviour emerges from the local
interactions among robots and between the robots and their environment. While
many aspects of a swarm may be modelled as various types of ad hoc networks,
and accordingly many aspects of security of the swarm may be achieved by
conventional means, here we will focus on swarm emergent behaviour as something
that most distinguishes swarm robotics from ad hoc networks. We discuss the
challenges emergent behaviour poses on communications security, and by
classifying a swarm by types of robots, types of communication channels, and
types of adversaries, we examine what classes may be secured by traditional
methods and focus on aspects that are most relevant to allowing emergent
behaviour. We will examine how this can be secured by ensuring that
communication is secure. We propose a simple solution using hash chains, and by
modelling swarm communications using a series of random graphs, we show that
this allows us to identify rogue robots with a high probability.
</p>
<a href="http://arxiv.org/abs/2102.03148" target="_blank">arXiv:2102.03148</a> [<a href="http://arxiv.org/pdf/2102.03148" target="_blank">pdf</a>]

<h2>Equivariant message passing for the prediction of tensorial properties and molecular spectra. (arXiv:2102.03150v1 [cs.LG])</h2>
<h3>Kristof T. Sch&#xfc;tt, Oliver T. Unke, Michael Gastegger</h3>
<p>Message passing neural networks have become a method of choice for learning
on graphs, in particular the prediction of chemical properties and the
acceleration of molecular dynamics studies. While they readily scale to large
training data sets, previous approaches have proven to be less data efficient
than kernel methods. We identify limitations of invariant representations as a
major reason and extend the message passing formulation to rotationally
equivariant representations. On this basis, we propose the polarizable atom
interaction neural network (PaiNN) and improve on common molecule benchmarks
over previous networks, while reducing model size and inference time. We
leverage the equivariant atomwise representations obtained by PaiNN for the
prediction of tensorial properties. Finally, we apply this to the simulation of
molecular spectra, achieving speedups of 4-5 orders of magnitude compared to
the electronic structure reference.
</p>
<a href="http://arxiv.org/abs/2102.03150" target="_blank">arXiv:2102.03150</a> [<a href="http://arxiv.org/pdf/2102.03150" target="_blank">pdf</a>]

<h2>Reducing the Amortization Gap in Variational Autoencoders: A Bayesian Random Function Approach. (arXiv:2102.03151v1 [cs.LG])</h2>
<h3>Minyoung Kim, Vladimir Pavlovic</h3>
<p>Variational autoencoder (VAE) is a very successful generative model whose key
element is the so called amortized inference network, which can perform test
time inference using a single feed forward pass. Unfortunately, this comes at
the cost of degraded accuracy in posterior approximation, often underperforming
the instance-wise variational optimization. Although the latest semi-amortized
approaches mitigate the issue by performing a few variational optimization
updates starting from the VAE's amortized inference output, they inherently
suffer from computational overhead for inference at test time. In this paper,
we address the problem in a completely different way by considering a random
inference model, where we model the mean and variance functions of the
variational posterior as random Gaussian processes (GP). The motivation is that
the deviation of the VAE's amortized posterior distribution from the true
posterior can be regarded as random noise, which allows us to take into account
the uncertainty in posterior approximation in a principled manner. In
particular, our model can quantify the difficulty in posterior approximation by
a Gaussian variational density. Inference in our GP model is done by a single
feed forward pass through the network, significantly faster than semi-amortized
methods. We show that our approach attains higher test data likelihood than the
state-of-the-arts on several benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2102.03151" target="_blank">arXiv:2102.03151</a> [<a href="http://arxiv.org/pdf/2102.03151" target="_blank">pdf</a>]

<h2>Optimal Transport as a Defense Against Adversarial Attacks. (arXiv:2102.03156v1 [cs.LG])</h2>
<h3>Quentin Bouniot, Romaric Audigier, Ang&#xe9;lique Loesch</h3>
<p>Deep learning classifiers are now known to have flaws in the representations
of their class. Adversarial attacks can find a human-imperceptible perturbation
for a given image that will mislead a trained model. The most effective methods
to defend against such attacks trains on generated adversarial examples to
learn their distribution. Previous work aimed to align original and adversarial
image representations in the same way as domain adaptation to improve
robustness. Yet, they partially align the representations using approaches that
do not reflect the geometry of space and distribution. In addition, it is
difficult to accurately compare robustness between defended models. Until now,
they have been evaluated using a fixed perturbation size. However, defended
models may react differently to variations of this perturbation size. In this
paper, the analogy of domain adaptation is taken a step further by exploiting
optimal transport theory. We propose to use a loss between distributions that
faithfully reflect the ground distance. This leads to SAT (Sinkhorn Adversarial
Training), a more robust defense against adversarial attacks. Then, we propose
to quantify more precisely the robustness of a model to adversarial attacks
over a wide range of perturbation sizes using a different metric, the Area
Under the Accuracy Curve (AUAC). We perform extensive experiments on both
CIFAR-10 and CIFAR-100 datasets and show that our defense is globally more
robust than the state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2102.03156" target="_blank">arXiv:2102.03156</a> [<a href="http://arxiv.org/pdf/2102.03156" target="_blank">pdf</a>]

<h2>Active Slices for Sliced Stein Discrepancy. (arXiv:2102.03159v1 [cs.LG])</h2>
<h3>Wenbo Gong, Kaibo Zhang, Yingzhen Li, Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</h3>
<p>Sliced Stein discrepancy (SSD) and its kernelized variants have demonstrated
promising successes in goodness-of-fit tests and model learning in high
dimensions. Despite their theoretical elegance, their empirical performance
depends crucially on the search of optimal slicing directions to discriminate
between two distributions. Unfortunately, previous gradient-based optimisation
approaches for this task return sub-optimal results: they are computationally
expensive, sensitive to initialization, and they lack theoretical guarantees
for convergence. We address these issues in two steps. First, we provide
theoretical results stating that the requirement of using optimal slicing
directions in the kernelized version of SSD can be relaxed, validating the
resulting discrepancy with finite random slicing directions. Second, given that
good slicing directions are crucial for practical performance, we propose a
fast algorithm for finding such slicing directions based on ideas of active
sub-space construction and spectral decomposition. Experiments on
goodness-of-fit tests and model learning show that our approach achieves both
improved performance and faster convergence. Especially, we demonstrate a
14-80x speed-up in goodness-of-fit tests when comparing with gradient-based
alternatives.
</p>
<a href="http://arxiv.org/abs/2102.03159" target="_blank">arXiv:2102.03159</a> [<a href="http://arxiv.org/pdf/2102.03159" target="_blank">pdf</a>]

<h2>PipeTransformer: Automated Elastic Pipelining for Distributed Training of Transformers. (arXiv:2102.03161v1 [cs.LG])</h2>
<h3>Chaoyang He, Shen Li, Mahdi Soltanolkotabi, Salman Avestimehr</h3>
<p>The size of Transformer models is growing at an unprecedented pace. It has
only taken less than one year to reach trillion-level parameters after the
release of GPT-3 (175B). Training such models requires both substantial
engineering efforts and enormous computing resources, which are luxuries most
research teams cannot afford. In this paper, we propose PipeTransformer, which
leverages automated and elastic pipelining and data parallelism for efficient
distributed training of Transformer models. PipeTransformer automatically
adjusts the pipelining and data parallelism by identifying and freezing some
layers during the training, and instead allocates resources for training of the
remaining active layers. More specifically, PipeTransformer dynamically
excludes converged layers from the pipeline, packs active layers into fewer
GPUs, and forks more replicas to increase data-parallel width. We evaluate
PipeTransformer using Vision Transformer (ViT) on ImageNet and BERT on GLUE and
SQuAD datasets. Our results show that PipeTransformer attains a 2.4 fold
speedup compared to the state-of-the-art baseline. We also provide various
performance analyses for a more comprehensive understanding of our algorithmic
and system-wise design. We also develop open-sourced flexible APIs for
PipeTransformer, which offer a clean separation among the freeze algorithm,
model definitions, and training accelerations, hence allowing it to be applied
to other algorithms that require similar freezing strategies.
</p>
<a href="http://arxiv.org/abs/2102.03161" target="_blank">arXiv:2102.03161</a> [<a href="http://arxiv.org/pdf/2102.03161" target="_blank">pdf</a>]

<h2>Bayesian multiscale deep generative model for the solution of high-dimensional inverse problems. (arXiv:2102.03169v1 [stat.ML])</h2>
<h3>Yingzhi Xia, Nicholas Zabaras</h3>
<p>Estimation of spatially-varying parameters for computationally expensive
forward models governed by partial differential equations is addressed. A novel
multiscale Bayesian inference approach is introduced based on deep
probabilistic generative models. Such generative models provide a flexible
representation by inferring on each scale a low-dimensional latent encoding
while allowing hierarchical parameter generation from coarse- to fine-scales.
Combining the multiscale generative model with Markov Chain Monte Carlo (MCMC),
inference across scales is achieved enabling us to efficiently obtain posterior
parameter samples at various scales. The estimation of coarse-scale parameters
using a low-dimensional latent embedding captures global and notable parameter
features using an inexpensive but inaccurate solver. MCMC sampling of the
fine-scale parameters is enabled by utilizing the posterior information in the
immediate coarser-scale. In this way, the global features are identified in the
coarse-scale with inference of low-dimensional variables and inexpensive
forward computation, and the local features are refined and corrected in the
fine-scale. The developed method is demonstrated with two types of permeability
estimation for flow in heterogeneous media. One is a Gaussian random field
(GRF) with uncertain length scales, and the other is channelized permeability
with the two regions defined by different GRFs. The obtained results indicate
that the method allows high-dimensional parameter estimation while exhibiting
stability, efficiency and accuracy.
</p>
<a href="http://arxiv.org/abs/2102.03169" target="_blank">arXiv:2102.03169</a> [<a href="http://arxiv.org/pdf/2102.03169" target="_blank">pdf</a>]

<h2>Metric Embedding Sub-discrimination Study. (arXiv:2102.03176v1 [cs.CV])</h2>
<h3>Ryan Furlong, Vincent O&#x27;Brien, James Garland, Francisco Dominguez-Mateos</h3>
<p>Deep metric learning is a technique used in a variety of discriminative tasks
to achieve zero-shot, one-shot or few-shot learning. When applied, the system
learns an embedding space where a non-parametric approach, such as \gls{knn},
can be used to discriminate features during test time. This work focuses on
investigating to what extent feature information contained within this
embedding space can be used to carry out sub-discrimination in the feature
space. The study shows that within a discrimination embedding, the information
on the salient attributes needed to solve the problem of sub-discrimination is
saved within the embedding and that this inherent information can be used to
carry out sub-discriminative tasks. To demonstrate this, an embedding designed
initially to discriminate faces is used to differentiate several attributes
such as gender, age and skin tone, without any additional training. The study
is split into two study cases: intra class discrimination where all the
embeddings took into consideration are from the same identity; and extra class
discrimination where the embeddings represent different identities. After the
study, it is shown that it is possible to infer common attributes to different
identities. The system can also perform extra class sub-discrimination with a
high accuracy rate, notably 99.3\%, 99.3\% and 94.1\% for gender, skin tone,
and age, respectively. Intra class tests show more mixed results with more
nuanced attributes like emotions not being reliably classified, while more
distinct attributes such as thick-framed glasses and beards, achieving 97.2\%
and 95.8\% accuracy, respectively.
</p>
<a href="http://arxiv.org/abs/2102.03176" target="_blank">arXiv:2102.03176</a> [<a href="http://arxiv.org/pdf/2102.03176" target="_blank">pdf</a>]

<h2>Last iterate convergence of SGD for Least-Squares in the Interpolation regime. (arXiv:2102.03183v1 [cs.LG])</h2>
<h3>Aditya Varre, Loucas Pillaud-Vivien, Nicolas Flammarion</h3>
<p>Motivated by the recent successes of neural networks that have the ability to
fit the data perfectly and generalize well, we study the noiseless model in the
fundamental least-squares setup. We assume that an optimum predictor fits
perfectly inputs and outputs $\langle \theta_* , \phi(X) \rangle = Y$, where
$\phi(X)$ stands for a possibly infinite dimensional non-linear feature map. To
solve this problem, we consider the estimator given by the last iterate of
stochastic gradient descent (SGD) with constant step-size. In this context, our
contribution is two fold: (i) from a (stochastic) optimization perspective, we
exhibit an archetypal problem where we can show explicitly the convergence of
SGD final iterate for a non-strongly convex problem with constant step-size
whereas usual results use some form of average and (ii) from a statistical
perspective, we give explicit non-asymptotic convergence rates in the
over-parameterized setting and leverage a fine-grained parameterization of the
problem to exhibit polynomial rates that can be faster than $O(1/T)$. The link
with reproducing kernel Hilbert spaces is established.
</p>
<a href="http://arxiv.org/abs/2102.03183" target="_blank">arXiv:2102.03183</a> [<a href="http://arxiv.org/pdf/2102.03183" target="_blank">pdf</a>]

<h2>A simpler spectral approach for clustering in directed networks. (arXiv:2102.03188v1 [cs.LG])</h2>
<h3>Simon Coste, Ludovic Stephan</h3>
<p>We study the task of clustering in directed networks. We show that using the
eigenvalue/eigenvector decomposition of the adjacency matrix is simpler than
all common methods which are based on a combination of data regularization and
SVD truncation, and works well down to the very sparse regime where the edge
density has constant order. Our analysis is based on a Master Theorem
describing sharp asymptotics for isolated eigenvalues/eigenvectors of sparse,
non-symmetric matrices with independent entries. We also describe the limiting
distribution of the entries of these eigenvectors; in the task of digraph
clustering with spectral embeddings, we provide numerical evidence for the
superiority of Gaussian Mixture clustering over the widely used k-means
algorithm.
</p>
<a href="http://arxiv.org/abs/2102.03188" target="_blank">arXiv:2102.03188</a> [<a href="http://arxiv.org/pdf/2102.03188" target="_blank">pdf</a>]

<h2>Invertible Neural Networks versus MCMC for Posterior Reconstruction in Grazing Incidence X-Ray Fluorescence. (arXiv:2102.03189v1 [cs.LG])</h2>
<h3>Anna Andrle, Nando Farchmin, Paul Hagemann, Sebastian Heidenreich, Victor Soltwisch, Gabriele Steidl</h3>
<p>Grazing incidence X-ray fluorescence is a non-destructive technique for
analyzing the geometry and compositional parameters of nanostructures appearing
e.g. in computer chips. In this paper, we propose to reconstruct the posterior
parameter distribution given a noisy measurement generated by the forward model
by an appropriately learned invertible neural network. This network resembles
the transport map from a reference distribution to the posterior. We
demonstrate by numerical comparisons that our method can compete with
established Markov Chain Monte Carlo approaches, while being more efficient and
flexible in applications.
</p>
<a href="http://arxiv.org/abs/2102.03189" target="_blank">arXiv:2102.03189</a> [<a href="http://arxiv.org/pdf/2102.03189" target="_blank">pdf</a>]

<h2>Provably Efficient Algorithms for Multi-Objective Competitive RL. (arXiv:2102.03192v1 [cs.LG])</h2>
<h3>Tiancheng Yu, Yi Tian, Jingzhao Zhang, Suvrit Sra</h3>
<p>We study multi-objective reinforcement learning (RL) where an agent's reward
is represented as a vector. In settings where an agent competes against
opponents, its performance is measured by the distance of its average return
vector to a target set. We develop statistically and computationally efficient
algorithms to approach the associated target set. Our results extend
Blackwell's approachability theorem (Blackwell, 1956) to tabular RL, where
strategic exploration becomes essential. The algorithms presented are adaptive;
their guarantees hold even without Blackwell's approachability condition. If
the opponents use fixed policies, we give an improved rate of approaching the
target set while also tackling the more ambitious goal of simultaneously
minimizing a scalar cost function. We discuss our analysis for this special
case by relating our results to previous works on constrained RL. To our
knowledge, this work provides the first provably efficient algorithms for
vector-valued Markov games and our theoretical guarantees are near-optimal.
</p>
<a href="http://arxiv.org/abs/2102.03192" target="_blank">arXiv:2102.03192</a> [<a href="http://arxiv.org/pdf/2102.03192" target="_blank">pdf</a>]

<h2>Bias-Variance Reduced Local SGD for Less Heterogeneous Federated Learning. (arXiv:2102.03198v1 [cs.LG])</h2>
<h3>Tomoya Murata, Taiji Suzuki</h3>
<p>Federated learning is one of the important learning scenarios in distributed
learning, in which we aim at learning heterogeneous local datasets efficiently
in terms of communication and computational cost. In this paper, we study new
local algorithms called Bias-Variance Reduced Local SGD (BVR-L-SGD) for
nonconvex federated learning. One of the novelties of this paper is in the
analysis of our bias and variance reduced local gradient estimators which fully
utilize small second-order heterogeneity of local objectives and suggests to
randomly pick up one of the local models instead of taking average of them when
workers are synchronized. Under small heterogeneity of local objectives, we
show that our methods achieve smaller communication complexity than both the
previous non-local and local methods for general nonconvex objectives.
Furthermore, we also compare the total execution time, that is the sum of total
communication time and total computational time per worker, and show the
superiority of our methods to the existing methods when the heterogeneity is
small and single communication time is more time consuming than single
stochastic gradient computation. Numerical results are provided to verify our
theoretical findings and give empirical evidence of the superiority of our
algorithms.
</p>
<a href="http://arxiv.org/abs/2102.03198" target="_blank">arXiv:2102.03198</a> [<a href="http://arxiv.org/pdf/2102.03198" target="_blank">pdf</a>]

<h2>Interpretable Neural Networks based classifiers for categorical inputs. (arXiv:2102.03202v1 [cs.LG])</h2>
<h3>Stefano Zamuner, Paolo De Los Rios</h3>
<p>Because of the pervasive usage of Neural Networks in human sensitive
applications, their interpretability is becoming an increasingly important
topic in machine learning. In this work we introduce a simple way to interpret
the output function of a neural network classifier that take as input
categorical variables. By exploiting a mapping between a neural network
classifier and a physical energy model, we show that in these cases each layer
of the network, and the logits layer in particular, can be expanded as a sum of
terms that account for the contribution to the classification of each input
pattern. For instance, at the first order, the expansion considers just the
linear relation between input features and output while at the second order
pairwise dependencies between input features are also accounted for. The
analysis of the contributions of each pattern, after an appropriate gauge
transformation, is presented in two cases where the effectiveness of the method
can be appreciated.
</p>
<a href="http://arxiv.org/abs/2102.03202" target="_blank">arXiv:2102.03202</a> [<a href="http://arxiv.org/pdf/2102.03202" target="_blank">pdf</a>]

<h2>A Survey on Mathematical Aspects of Machine Learning in GeoPhysics: The Cases of Weather Forecast, Wind Energy, Wave Energy, Oil and Gas Exploration. (arXiv:2102.03206v1 [cs.LG])</h2>
<h3>Miroslav Kosanic, Veljko Milutinovic</h3>
<p>This paper reviews the most notable works applying machine learning
techniques (ML) in the context of geophysics and corresponding subbranches. We
showcase both the progress achieved to date as well as the important future
directions for further research while providing an adequate background in the
fields of weather forecast, wind energy, wave energy, oil and gas exploration.
The objective is to reflect on the previous successes and provide a
comprehensive review of the synergy between these two fields in order to speed
up the novel approaches of machine learning techniques in geophysics. Last but
not least, we would like to point out possible improvements, some of which are
related to the implementation of ML algorithms using DataFlow paradigm as a
means of performance acceleration.
</p>
<a href="http://arxiv.org/abs/2102.03206" target="_blank">arXiv:2102.03206</a> [<a href="http://arxiv.org/pdf/2102.03206" target="_blank">pdf</a>]

<h2>A Deep Learning Approach Based on Graphs to Detect Plantation Lines. (arXiv:2102.03213v1 [cs.CV])</h2>
<h3>Diogo Nunes Gon&#xe7;alves, Mauro dos Santos de Arruda, Hemerson Pistori, Vanessa Jord&#xe3;o Marcato Fernandes, Ana Paula Marques Ramos, Danielle Elis Garcia Furuya, Lucas Prado Osco, Hongjie He, Jonathan Li, Jos&#xe9; Marcato Junior, Wesley Nunes Gon&#xe7;alves</h3>
<p>Deep learning-based networks are among the most prominent methods to learn
linear patterns and extract this type of information from diverse imagery
conditions. Here, we propose a deep learning approach based on graphs to detect
plantation lines in UAV-based RGB imagery presenting a challenging scenario
containing spaced plants. The first module of our method extracts a feature map
throughout the backbone, which consists of the initial layers of the VGG16.
This feature map is used as an input to the Knowledge Estimation Module (KEM),
organized in three concatenated branches for detecting 1) the plant positions,
2) the plantation lines, and 3) for the displacement vectors between the
plants. A graph modeling is applied considering each plant position on the
image as vertices, and edges are formed between two vertices (i.e. plants).
Finally, the edge is classified as pertaining to a certain plantation line
based on three probabilities (higher than 0.5): i) in visual features obtained
from the backbone; ii) a chance that the edge pixels belong to a line, from the
KEM step; and iii) an alignment of the displacement vectors with the edge, also
from KEM. Experiments were conducted in corn plantations with different growth
stages and patterns with aerial RGB imagery. A total of 564 patches with 256 x
256 pixels were used and randomly divided into training, validation, and
testing sets in a proportion of 60\%, 20\%, and 20\%, respectively. The
proposed method was compared against state-of-the-art deep learning methods,
and achieved superior performance with a significant margin, returning
precision, recall, and F1-score of 98.7\%, 91.9\%, and 95.1\%, respectively.
This approach is useful in extracting lines with spaced plantation patterns and
could be implemented in scenarios where plantation gaps occur, generating lines
with few-to-none interruptions.
</p>
<a href="http://arxiv.org/abs/2102.03213" target="_blank">arXiv:2102.03213</a> [<a href="http://arxiv.org/pdf/2102.03213" target="_blank">pdf</a>]

<h2>GNN-RL Compression: Topology-Aware Network Pruning using Multi-stage Graph Embedding and Reinforcement Learning. (arXiv:2102.03214v1 [cs.CV])</h2>
<h3>Sixing Yu, Arya Mazaheri, Ali Jannesari</h3>
<p>Model compression is an essential technique for deploying deep neural
networks (DNNs) on power and memory-constrained resources. However, existing
model-compression methods often rely on human expertise and focus on
parameters' local importance, ignoring the rich topology information within
DNNs. In this paper, we propose a novel multi-stage graph embedding technique
based on graph neural networks (GNNs) to identify the DNNs' topology and use
reinforcement learning (RL) to find a suitable compression policy. We performed
resource-constrained (i.e., FLOPs) channel pruning and compared our approach
with state-of-the-art compression methods using over-parameterized DNNs (e.g.,
ResNet and VGG-16) and mobile-friendly DNNs (e.g., MobileNet and ShuffleNet).
We evaluated our method on various models from typical to mobile-friendly
networks, such as ResNet family, VGG-16, MobileNet-v1/v2, and ShuffleNet. The
results demonstrate that our method can prune dense networks (e.g., VGG-16) by
up to 80% of their original FLOPs. More importantly, our method outperformed
state-of-the-art methods and achieved a higher accuracy by up to 1.84% for
ShuffleNet-v1. Furthermore, following our approach, the pruned VGG-16 achieved
a noticeable 1.38$\times$ speed up and 141 MB GPU memory reduction.
</p>
<a href="http://arxiv.org/abs/2102.03214" target="_blank">arXiv:2102.03214</a> [<a href="http://arxiv.org/pdf/2102.03214" target="_blank">pdf</a>]

<h2>A Collaborative Visual SLAM Framework for Service Robots. (arXiv:2102.03228v1 [cs.RO])</h2>
<h3>Ming Ouyang, Xuesong Shi, Yujie Wang, Yuxin Tian, Yingzhe Shen, Dawei Wang, Peng Wang</h3>
<p>With the rapid deployment of service robots, a method should be established
to allow multiple robots to work in the same place to collaborate and share the
spatial information. To this end, we present a collaborative visual
simultaneous localization and mapping (SLAM) framework particularly designed
for service robot scenarios. With an edge server maintaining a map database and
performing global optimization, each robot can register to an existing map,
update the map, or build new maps, all with a unified interface and low
computation and memory cost. To enable real-time information sharing, an
efficient landmark retrieval method is proposed to allow each robot to get
nearby landmarks observed by others. The framework is general enough to support
both RGB-D and monocular cameras, as well as robots with multiple cameras,
taking the rigid constraints between cameras into consideration. The proposed
framework has been fully implemented and verified with public datasets and live
experiments.
</p>
<a href="http://arxiv.org/abs/2102.03228" target="_blank">arXiv:2102.03228</a> [<a href="http://arxiv.org/pdf/2102.03228" target="_blank">pdf</a>]

<h2>Matrix Decomposition on Graphs: A Functional View. (arXiv:2102.03233v1 [cs.LG])</h2>
<h3>Abhishek Sharma, Maks Ovsjanikov</h3>
<p>We propose a functional view of matrix decomposition problems on graphs such
as geometric matrix completion and graph regularized dimensionality reduction.
Our unifying framework is based on the key idea that using a reduced basis to
represent functions on the product space is sufficient to recover a low rank
matrix approximation even from a sparse signal. We validate our framework on
several real and synthetic benchmarks (for both problems) where it either
outperforms state of the art or achieves competitive results at a fraction of
the computational effort of prior work.
</p>
<a href="http://arxiv.org/abs/2102.03233" target="_blank">arXiv:2102.03233</a> [<a href="http://arxiv.org/pdf/2102.03233" target="_blank">pdf</a>]

<h2>Exact Optimization of Conformal Predictors via Incremental and Decremental Learning. (arXiv:2102.03236v1 [cs.LG])</h2>
<h3>Giovanni Cherubin, Konstantinos Chatzikokolakis, Martin Jaggi</h3>
<p>Conformal Predictors (CP) are wrappers around ML methods, providing error
guarantees under weak assumptions on the data distribution. They are suitable
for a wide range of problems, from classification and regression to anomaly
detection. Unfortunately, their high computational complexity limits their
applicability to large datasets.

In this work, we show that it is possible to speed up a CP classifier
considerably, by studying it in conjunction with the underlying ML method, and
by exploiting incremental&amp;decremental learning. For methods such as k-NN, KDE,
and kernel LS-SVM, our approach reduces the running time by one order of
magnitude, whilst producing exact solutions. With similar ideas, we also
achieve a linear speed up for the harder case of bootstrapping. Finally, we
extend these techniques to improve upon an optimization of k-NN CP for
regression.

We evaluate our findings empirically, and discuss when methods are suitable
for CP optimization.
</p>
<a href="http://arxiv.org/abs/2102.03236" target="_blank">arXiv:2102.03236</a> [<a href="http://arxiv.org/pdf/2102.03236" target="_blank">pdf</a>]

<h2>Applications of Machine Learning in Document Digitisation. (arXiv:2102.03239v1 [cs.CV])</h2>
<h3>Christian M. Dahl, Torben S. D. Johansen, Emil N. S&#xf8;rensen, Christian E. Westermann, Simon F. Wittrock</h3>
<p>Data acquisition forms the primary step in all empirical research. The
availability of data directly impacts the quality and extent of conclusions and
insights. In particular, larger and more detailed datasets provide convincing
answers even to complex research questions. The main problem is that 'large and
detailed' usually implies 'costly and difficult', especially when the data
medium is paper and books. Human operators and manual transcription have been
the traditional approach for collecting historical data. We instead advocate
the use of modern machine learning techniques to automate the digitisation
process. We give an overview of the potential for applying machine digitisation
for data collection through two illustrative applications. The first
demonstrates that unsupervised layout classification applied to raw scans of
nurse journals can be used to construct a treatment indicator. Moreover, it
allows an assessment of assignment compliance. The second application uses
attention-based neural networks for handwritten text recognition in order to
transcribe age and birth and death dates from a large collection of Danish
death certificates. We describe each step in the digitisation pipeline and
provide implementation insights.
</p>
<a href="http://arxiv.org/abs/2102.03239" target="_blank">arXiv:2102.03239</a> [<a href="http://arxiv.org/pdf/2102.03239" target="_blank">pdf</a>]

<h2>Hyperspherical embedding for novel class classification. (arXiv:2102.03243v1 [cs.CV])</h2>
<h3>Rafael S. Pereira, Alexis Joly, Patrick Valduriez, Fabio Porto</h3>
<p>Deep learning models have become increasingly useful in many different
industries. On the domain of image classification, convolutional neural
networks proved the ability to learn robust features for the closed set
problem, as shown in many different datasets, such as MNIST FASHIONMNIST,
CIFAR10, CIFAR100, and IMAGENET. These approaches use deep neural networks with
dense layers with softmax activation functions in order to learn features that
can separate classes in a latent space. However, this traditional approach is
not useful for identifying classes unseen on the training set, known as the
open set problem. A similar problem occurs in scenarios involving learning on
small data. To tackle both problems, few-shot learning has been proposed. In
particular, metric learning learns features that obey constraints of a metric
distance in the latent space in order to perform classification. However, while
this approach proves to be useful for the open set problem, current
implementation requires pair-wise training, where both positive and negative
examples of similar images are presented during the training phase, which
limits the applicability of these approaches in large data or large class
scenarios given the combinatorial nature of the possible inputs.In this paper,
we present a constraint-based approach applied to the representations in the
latent space under the normalized softmax loss, proposed by[18]. We
experimentally validate the proposed approach for the classification of unseen
classes on different datasets using both metric learning and the normalized
softmax loss, on disjoint and joint scenarios. Our results show that not only
our proposed strategy can be efficiently trained on larger set of classes, as
it does not require pairwise learning, but also present better classification
results than the metric learning strategies surpassing its accuracy by a
significant margin.
</p>
<a href="http://arxiv.org/abs/2102.03243" target="_blank">arXiv:2102.03243</a> [<a href="http://arxiv.org/pdf/2102.03243" target="_blank">pdf</a>]

<h2>GaitSet: Cross-view Gait Recognition through Utilizing Gait as a Deep Set. (arXiv:2102.03247v1 [cs.CV])</h2>
<h3>Hanqing Chao, Kun Wang, Yiwei He, Junping Zhang, Jianfeng Feng</h3>
<p>Gait is a unique biometric feature that can be recognized at a distance;
thus, it has broad applications in crime prevention, forensic identification,
and social security. To portray a gait, existing gait recognition methods
utilize either a gait template which makes it difficult to preserve temporal
information, or a gait sequence that maintains unnecessary sequential
constraints and thus loses the flexibility of gait recognition. In this paper,
we present a novel perspective that utilizes gait as a deep set, which means
that a set of gait frames are integrated by a global-local fused deep network
inspired by the way our left- and right-hemisphere processes information to
learn information that can be used in identification. Based on this deep set
perspective, our method is immune to frame permutations, and can naturally
integrate frames from different videos that have been acquired under different
scenarios, such as diverse viewing angles, different clothes, or different
item-carrying conditions. Experiments show that under normal walking
conditions, our single-model method achieves an average rank-1 accuracy of
96.1% on the CASIA-B gait dataset and an accuracy of 87.9% on the OU-MVLP gait
dataset. Under various complex scenarios, our model also exhibits a high level
of robustness. It achieves accuracies of 90.8% and 70.3% on CASIA-B under
bag-carrying and coat-wearing walking conditions respectively, significantly
outperforming the best existing methods. Moreover, the proposed method
maintains a satisfactory accuracy even when only small numbers of frames are
available in the test samples; for example, it achieves 85.0% on CASIA-B even
when using only 7 frames. The source code has been released at
https://github.com/AbnerHqC/GaitSet.
</p>
<a href="http://arxiv.org/abs/2102.03247" target="_blank">arXiv:2102.03247</a> [<a href="http://arxiv.org/pdf/2102.03247" target="_blank">pdf</a>]

<h2>Revisiting Prioritized Experience Replay: A Value Perspective. (arXiv:2102.03261v1 [cs.LG])</h2>
<h3>Ang A. Li, Zongqing Lu, Chenglin Miao</h3>
<p>Experience replay enables off-policy reinforcement learning (RL) agents to
utilize past experiences to maximize the cumulative reward. Prioritized
experience replay that weighs experiences by the magnitude of their
temporal-difference error ($|\text{TD}|$) significantly improves the learning
efficiency. But how $|\text{TD}|$ is related to the importance of experience is
not well understood. We address this problem from an economic perspective, by
linking $|\text{TD}|$ to value of experience, which is defined as the value
added to the cumulative reward by accessing the experience. We theoretically
show the value metrics of experience are upper-bounded by $|\text{TD}|$ for
Q-learning. Furthermore, we successfully extend our theoretical framework to
maximum-entropy RL by deriving the lower and upper bounds of these value
metrics for soft Q-learning, which turn out to be the product of $|\text{TD}|$
and "on-policyness" of the experiences. Our framework links two important
quantities in RL: $|\text{TD}|$ and value of experience. We empirically show
that the bounds hold in practice, and experience replay using the upper bound
as priority improves maximum-entropy RL in Atari games.
</p>
<a href="http://arxiv.org/abs/2102.03261" target="_blank">arXiv:2102.03261</a> [<a href="http://arxiv.org/pdf/2102.03261" target="_blank">pdf</a>]

<h2>Transductive Zero-Shot Learning by Decoupled Feature Generation. (arXiv:2102.03266v1 [cs.CV])</h2>
<h3>Federico Marmoreo, Jacopo Cavazza, Vittorio Murino</h3>
<p>In this paper, we address zero-shot learning (ZSL), the problem of
recognizing categories for which no labeled visual data are available during
training. We focus on the transductive setting, in which unlabelled visual data
from unseen classes is available. State-of-the-art paradigms in ZSL typically
exploit generative adversarial networks to synthesize visual features from
semantic attributes. We posit that the main limitation of these approaches is
to adopt a single model to face two problems: 1) generating realistic visual
features, and 2) translating semantic attributes into visual cues. Differently,
we propose to decouple such tasks, solving them separately. In particular, we
train an unconditional generator to solely capture the complexity of the
distribution of visual data and we subsequently pair it with a conditional
generator devoted to enrich the prior knowledge of the data distribution with
the semantic content of the class embeddings. We present a detailed ablation
study to dissect the effect of our proposed decoupling approach, while
demonstrating its superiority over the related state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2102.03266" target="_blank">arXiv:2102.03266</a> [<a href="http://arxiv.org/pdf/2102.03266" target="_blank">pdf</a>]

<h2>Estimating 2-Sinkhorn Divergence between Gaussian Processes from Finite-Dimensional Marginals. (arXiv:2102.03267v1 [cs.LG])</h2>
<h3>Anton Mallasto</h3>
<p>\emph{Optimal Transport} (OT) has emerged as an important computational tool
in machine learning and computer vision, providing a geometrical framework for
studying probability measures. OT unfortunately suffers from the curse of
dimensionality and requires regularization for practical computations, of which
the \emph{entropic regularization} is a popular choice, which can be
'unbiased', resulting in a \emph{Sinkhorn divergence}. In this work, we study
the convergence of estimating the 2-Sinkhorn divergence between \emph{Gaussian
processes} (GPs) using their finite-dimensional marginal distributions. We show
almost sure convergence of the divergence when the marginals are sampled
according to some base measure. Furthermore, we show that using $n$ marginals
the estimation error of the divergence scales in a dimension-free way as
$\mathcal{O}\left(\epsilon^ {-1}n^{-\frac{1}{2}}\right)$, where $\epsilon$ is
the magnitude of entropic regularization.
</p>
<a href="http://arxiv.org/abs/2102.03267" target="_blank">arXiv:2102.03267</a> [<a href="http://arxiv.org/pdf/2102.03267" target="_blank">pdf</a>]

<h2>On the Sample Complexity of Causal Discovery and the Value of Domain Expertise. (arXiv:2102.03274v1 [cs.LG])</h2>
<h3>Samir Wadhwa, Roy Dong</h3>
<p>Causal discovery methods seek to identify causal relations between random
variables from purely observational data, as opposed to actively collected
experimental data where an experimenter intervenes on a subset of correlates.
One of the seminal works in this area is the Inferred Causation algorithm,
which guarantees successful causal discovery under the assumption of a
conditional independence (CI) oracle: an oracle that can states whether two
random variables are conditionally independent given another set of random
variables. Practical implementations of this algorithm incorporate statistical
tests for conditional independence, in place of a CI oracle. In this paper, we
analyze the sample complexity of causal discovery algorithms without a CI
oracle: given a certain level of confidence, how many data points are needed
for a causal discovery algorithm to identify a causal structure? Furthermore,
our methods allow us to quantify the value of domain expertise in terms of data
samples. Finally, we demonstrate the accuracy of these sample rates with
numerical examples, and quantify the benefits of sparsity priors and known
causal directions.
</p>
<a href="http://arxiv.org/abs/2102.03274" target="_blank">arXiv:2102.03274</a> [<a href="http://arxiv.org/pdf/2102.03274" target="_blank">pdf</a>]

<h2>In-Loop Meta-Learning with Gradient-Alignment Reward. (arXiv:2102.03275v1 [cs.LG])</h2>
<h3>Samuel M&#xfc;ller, Andr&#xe9; Biedenkapp, Frank Hutter</h3>
<p>At the heart of the standard deep learning training loop is a greedy gradient
step minimizing a given loss. We propose to add a second step to maximize
training generalization. To do this, we optimize the loss of the next training
step. While computing the gradient for this generally is very expensive and
many interesting applications consider non-differentiable parameters (e.g. due
to hard samples), we present a cheap-to-compute and memory-saving reward, the
gradient-alignment reward (GAR), that can guide the optimization. We use this
reward to optimize multiple distributions during model training. First, we
present the application of GAR to choosing the data distribution as a mixture
of multiple dataset splits in a small scale setting. Second, we show that it
can successfully guide learning augmentation strategies competitive with
state-of-the-art augmentation strategies on CIFAR-10 and CIFAR-100.
</p>
<a href="http://arxiv.org/abs/2102.03275" target="_blank">arXiv:2102.03275</a> [<a href="http://arxiv.org/pdf/2102.03275" target="_blank">pdf</a>]

<h2>Multi-Sample Online Learning for Spiking Neural Networks based on Generalized Expectation Maximization. (arXiv:2102.03280v1 [cs.LG])</h2>
<h3>Hyeryung Jang, Osvaldo Simeone</h3>
<p>Spiking Neural Networks (SNNs) offer a novel computational paradigm that
captures some of the efficiency of biological brains by processing through
binary neural dynamic activations. Probabilistic SNN models are typically
trained to maximize the likelihood of the desired outputs by using unbiased
estimates of the log-likelihood gradients. While prior work used single-sample
estimators obtained from a single run of the network, this paper proposes to
leverage multiple compartments that sample independent spiking signals while
sharing synaptic weights. The key idea is to use these signals to obtain more
accurate statistical estimates of the log-likelihood training criterion, as
well as of its gradient. The approach is based on generalized
expectation-maximization (GEM), which optimizes a tighter approximation of the
log-likelihood using importance sampling. The derived online learning algorithm
implements a three-factor rule with global per-compartment learning signals.
Experimental results on a classification task on the neuromorphic MNIST-DVS
data set demonstrate significant improvements in terms of log-likelihood,
accuracy, and calibration when increasing the number of compartments used for
training and inference.
</p>
<a href="http://arxiv.org/abs/2102.03280" target="_blank">arXiv:2102.03280</a> [<a href="http://arxiv.org/pdf/2102.03280" target="_blank">pdf</a>]

<h2>Categorical data as a stone guest in a data science project for predicting defective water meters. (arXiv:2102.03284v1 [cs.LG])</h2>
<h3>Giovanni Delnevo, Marco Roccetti, Luca Casini</h3>
<p>After a one-year long effort of research on the field, we developed a machine
learning-based classifier, tailored to predict whether a mechanical water meter
would fail with passage of time and intensive use as well. A recurrent deep
neural network (RNN) was trained with data extrapolated from 15 million
readings of water consumption, gathered from 1 million meters. The data we used
for training were essentially of two types: continuous vs categorical.
Categorical being a type of data that can take on one of a limited and fixed
number of possible values, on the basis of some qualitative property; while
continuous, in this case, are the values of the measurements. taken at the
meters, of the quantity of consumed water (cubic meters). In this paper, we
want to discuss the fact that while the prediction accuracy of our RNN has
exceeded the 80% on average, based on the use of continuous data, those
performances did not improve, significantly, with the introduction of
categorical information during the training phase. From a specific viewpoint,
this remains an unsolved and critical problem of our research. Yet, if we
reason about this controversial case from a data science perspective, we
realize that we have had a confirmation that accurate machine learning
solutions cannot be built without the participation of domain experts, who can
differentiate on the importance of (the relation between) different types of
data, each with its own sense, validity, and implications. Past all the
original hype, the science of data is thus evolving towards a multifaceted
discipline, where the designitations of data scientist/machine learning expert
and domain expert are symbiotic
</p>
<a href="http://arxiv.org/abs/2102.03284" target="_blank">arXiv:2102.03284</a> [<a href="http://arxiv.org/pdf/2102.03284" target="_blank">pdf</a>]

<h2>Unsupervised Novel View Synthesis from a Single Image. (arXiv:2102.03285v1 [cs.CV])</h2>
<h3>Pierluigi Zama Ramirez, Alessio Tonioni, Federico Tombari</h3>
<p>Novel view synthesis from a single image aims at generating novel views from
a single input image of an object. Several works recently achieved remarkable
results, though require some form of multi-view supervision at training time,
therefore limiting their deployment in real scenarios. This work aims at
relaxing this assumption enabling training of conditional generative model for
novel view synthesis in a completely unsupervised manner. We first pre-train a
purely generative decoder model using a GAN formulation while at the same time
training an encoder network to invert the mapping from latent code to images.
Then we swap encoder and decoder and train the network as a conditioned GAN
with a mixture of auto-encoder-like objective and self-distillation. At test
time, given a view of an object, our model first embeds the image content in a
latent code and regresses its pose w.r.t. a canonical reference system, then
generates novel views of it by keeping the code and varying the pose. We show
that our framework achieves results comparable to the state of the art on
ShapeNet and that it can be employed on unconstrained collections of natural
images, where no competing method can be trained.
</p>
<a href="http://arxiv.org/abs/2102.03285" target="_blank">arXiv:2102.03285</a> [<a href="http://arxiv.org/pdf/2102.03285" target="_blank">pdf</a>]

<h2>Pedestrian Simulation: A Review. (arXiv:2102.03289v1 [cs.RO])</h2>
<h3>Amir Rasouli</h3>
<p>This article focuses on different aspects of pedestrian (crowd) modeling and
simulation. The review includes: various modeling criteria, such as
granularity, techniques, and factors involved in modeling pedestrian behavior,
and different pedestrian simulation methods with a more detailed look at two
approaches for simulating pedestrian behavior in traffic scenes. At the end,
benefits and drawbacks of different simulation techniques are discussed and
recommendations are made for future research.
</p>
<a href="http://arxiv.org/abs/2102.03289" target="_blank">arXiv:2102.03289</a> [<a href="http://arxiv.org/pdf/2102.03289" target="_blank">pdf</a>]

<h2>baller2vec: A Multi-Entity Transformer For Multi-Agent Spatiotemporal Modeling. (arXiv:2102.03291v1 [cs.LG])</h2>
<h3>Michael A. Alcorn, Anh Nguyen</h3>
<p>Multi-agent spatiotemporal modeling is a challenging task from both an
algorithmic design and computational complexity perspective. Recent work has
explored the efficacy of traditional deep sequential models in this domain, but
these architectures are slow and cumbersome to train, particularly as model
size increases. Further, prior attempts to model interactions between agents
across time have limitations, such as imposing an order on the agents, or
making assumptions about their relationships. In this paper, we introduce
baller2vec, a multi-entity generalization of the standard Transformer that,
with minimal assumptions, can simultaneously and efficiently integrate
information across entities and time. We test the effectiveness of baller2vec
for multi-agent spatiotemporal modeling by training it to perform two different
basketball-related tasks: (1) simultaneously forecasting the trajectories of
all players on the court and (2) forecasting the trajectory of the ball. Not
only does baller2vec learn to perform these tasks well, it also appears to
"understand" the game of basketball, encoding idiosyncratic qualities of
players in its embeddings, and performing basketball-relevant functions with
its attention heads.
</p>
<a href="http://arxiv.org/abs/2102.03291" target="_blank">arXiv:2102.03291</a> [<a href="http://arxiv.org/pdf/2102.03291" target="_blank">pdf</a>]

<h2>Maintaining driver attentiveness in shared-control autonomous driving. (arXiv:2102.03298v1 [cs.RO])</h2>
<h3>Radu Calinescu, Naif Alasmari, Mario Gleirscher</h3>
<p>We present a work-in-progress approach to improving driver attentiveness in
cars provided with automated driving systems. The approach is based on a
control loop that monitors the driver's biometrics (eye movement, heart rate,
etc.) and the state of the car; analyses the driver's attentiveness level using
a deep neural network; plans driver alerts and changes in the speed of the car
using a formally verified controller; and executes this plan using actuators
ranging from acoustic and visual to haptic devices. The paper presents (i) the
self-adaptive system formed by this monitor-analyse-plan-execute (MAPE) control
loop, the car and the monitored driver, and (ii) the use of probabilistic model
checking to synthesise the controller for the planning step of the MAPE loop.
</p>
<a href="http://arxiv.org/abs/2102.03298" target="_blank">arXiv:2102.03298</a> [<a href="http://arxiv.org/pdf/2102.03298" target="_blank">pdf</a>]

<h2>Improving state estimation through projection post-processing for activity recognition in football. (arXiv:2102.03310v1 [cs.CV])</h2>
<h3>Micha&#x142; Ciszewski, Jakob S&#xf6;hl, Geurt Jongbloed</h3>
<p>The past decade has seen an increased interest in human activity recognition.
Most commonly, the raw data coming from sensors attached to body parts are
unannotated, which creates a need for fast labelling method. Part of the
procedure is choosing or designing an appropriate performance measure. We
propose a new performance measure, the Locally Time-Shifted Measure, which
addresses the issue of timing uncertainty of state transitions in the
classification result. Our main contribution is a novel post-processing method
for binary activity recognition. It improves the accuracy of the classification
methods, by correcting for unrealistically short activities in the estimate.
</p>
<a href="http://arxiv.org/abs/2102.03310" target="_blank">arXiv:2102.03310</a> [<a href="http://arxiv.org/pdf/2102.03310" target="_blank">pdf</a>]

<h2>On The Connection of Benford's Law and Neural Networks. (arXiv:2102.03313v1 [cs.LG])</h2>
<h3>Surya Kant Sahu, Abhinav Java, Arshad Shaikh</h3>
<p>Benford's law, also called Significant Digit Law, is observed in many
naturally occurring data-sets. For instance, the physical constants such as
Gravitational, Coulomb's Constant, etc., follow this law. In this paper, we
define a score, $MLH$, for how closely a Neural Network's Weights match
Benford's law. We show that Neural Network Weights follow Benford's Law
regardless of the initialization method. We make a striking connection between
Generalization and the $MLH$ of the network. We provide evidence that several
architectures from AlexNet to ResNeXt trained on ImageNet, Transformers (BERT,
Electra, etc.), and other pre-trained models on a wide variety of tasks have a
strong correlation between their test performance and the $MLH$. We also
investigate the influence of Data in the Weights to explain why NNs possibly
follow Benford's Law. With repeated experiments on multiple datasets using
MLPs, CNNs, and LSTMs, we provide empirical evidence that there is a connection
between $MLH$ while training, overfitting. Understanding this connection
between Benford's Law and Neural Networks promises a better comprehension of
the latter.
</p>
<a href="http://arxiv.org/abs/2102.03313" target="_blank">arXiv:2102.03313</a> [<a href="http://arxiv.org/pdf/2102.03313" target="_blank">pdf</a>]

<h2>Towards integrated tactile sensorimotor control in anthropomorphic soft robotic hands. (arXiv:2102.03318v1 [cs.RO])</h2>
<h3>Nathan F. Lepora, Andrew Stinchcombe, Chris Ford, Alfred Brown, John Lloyd, Manuel G. Catalano, Matteo Bianchi, Benjamin Ward-Cherrier</h3>
<p>In this work, we report on the integrated sensorimotor control of the
Pisa/IIT SoftHand, an anthropomorphic soft robot hand designed around the
principle of adaptive synergies, with the BRL tactile fingertip (TacTip), a
soft biomimetic optical tactile sensor based on the human sense of touch. Our
focus is how a sense of touch can be used to control an anthropomorphic hand
with one degree of actuation, based on an integration that respects the hand's
mechanical functionality. We consider: (i) closed-loop tactile control to
establish a light contact on an unknown held object, based on the structural
similarity with an undeformed tactile image; and (ii) controlling the estimated
pose of an edge feature of a held object, using a convolutional neural network
approach developed for controlling other sensors in the TacTip family. Overall,
this gives a foundation to endow soft robotic hands with human-like touch, with
implications for autonomous grasping, manipulation, human-robot interaction and
prosthetics. Supplemental video: https://youtu.be/ndsxj659bkQ
</p>
<a href="http://arxiv.org/abs/2102.03318" target="_blank">arXiv:2102.03318</a> [<a href="http://arxiv.org/pdf/2102.03318" target="_blank">pdf</a>]

<h2>CF-GNNExplainer: Counterfactual Explanations for Graph Neural Networks. (arXiv:2102.03322v1 [cs.LG])</h2>
<h3>Ana Lucic, Maartje ter Hoeve, Gabriele Tolomei, Maarten de Rijke, Fabrizio Silvestri</h3>
<p>Graph neural networks (GNNs) have shown increasing promise in real-world
applications, which has caused an increased interest in understanding their
predictions. However, existing methods for explaining predictions from GNNs do
not provide an opportunity for recourse: given a prediction for a particular
instance, we want to understand how the prediction can be changed. We propose
CF-GNNExplainer: the first method for generating counterfactual explanations
for GNNs, i.e., the minimal perturbations to the input graph data such that the
prediction changes. Using only edge deletions, we find that we are able to
generate counterfactual examples for the majority of instances across three
widely used datasets for GNN explanations, while removing less than 3 edges on
average, with at least 94% accuracy. This indicates that CF-GNNExplainer
primarily removes edges that are crucial for the original predictions,
resulting in minimal counterfactual examples.
</p>
<a href="http://arxiv.org/abs/2102.03322" target="_blank">arXiv:2102.03322</a> [<a href="http://arxiv.org/pdf/2102.03322" target="_blank">pdf</a>]

<h2>GIBBON: General-purpose Information-Based Bayesian OptimisatioN. (arXiv:2102.03324v1 [cs.LG])</h2>
<h3>Henry B. Moss, David S. Leslie, Javier Gonzalez, Paul Rayson</h3>
<p>This paper describes a general-purpose extension of max-value entropy search,
a popular approach for Bayesian Optimisation (BO). A novel approximation is
proposed for the information gain -- an information-theoretic quantity central
to solving a range of BO problems, including noisy, multi-fidelity and batch
optimisations across both continuous and highly-structured discrete spaces.
Previously, these problems have been tackled separately within
information-theoretic BO, each requiring a different sophisticated
approximation scheme, except for batch BO, for which no
computationally-lightweight information-theoretic approach has previously been
proposed. GIBBON (General-purpose Information-Based Bayesian OptimisatioN)
provides a single principled framework suitable for all the above,
out-performing existing approaches whilst incurring substantially lower
computational overheads. In addition, GIBBON does not require the problem's
search space to be Euclidean and so is the first high-performance yet
computationally light-weight acquisition function that supports batch BO over
general highly structured input spaces like molecular search and gene design.
Moreover, our principled derivation of GIBBON yields a natural interpretation
of a popular batch BO heuristic based on determinantal point processes.
Finally, we analyse GIBBON across a suite of synthetic benchmark tasks, a
molecular search loop, and as part of a challenging batch multi-fidelity
framework for problems with controllable experimental noise.
</p>
<a href="http://arxiv.org/abs/2102.03324" target="_blank">arXiv:2102.03324</a> [<a href="http://arxiv.org/pdf/2102.03324" target="_blank">pdf</a>]

<h2>Fusion of neural networks, for LIDAR-based evidential road mapping. (arXiv:2102.03326v1 [cs.CV])</h2>
<h3>Edouard Capellier, Franck Davoine, Veronique Cherfaoui, You Li</h3>
<p>LIDAR sensors are usually used to provide autonomous vehicles with 3D
representations of their environment. In ideal conditions, geometrical models
could detect the road in LIDAR scans, at the cost of a manual tuning of
numerical constraints, and a lack of flexibility. We instead propose an
evidential pipeline, to accumulate road detection results obtained from neural
networks. First, we introduce RoadSeg, a new convolutional architecture that is
optimized for road detection in LIDAR scans. RoadSeg is used to classify
individual LIDAR points as either belonging to the road, or not. Yet, such
point-level classification results need to be converted into a dense
representation, that can be used by an autonomous vehicle. We thus secondly
present an evidential road mapping algorithm, that fuses consecutive road
detection results. We benefitted from a reinterpretation of logistic
classifiers, which can be seen as generating a collection of simple evidential
mass functions. An evidential grid map that depicts the road can then be
obtained, by projecting the classification results from RoadSeg into grid
cells, and by handling moving objects via conflict analysis. The system was
trained and evaluated on real-life data. A python implementation maintains a 10
Hz framerate. Since road labels were needed for training, a soft labelling
procedure, relying lane-level HD maps, was used to generate coarse training and
validation sets. An additional test set was manually labelled for evaluation
purposes. So as to reach satisfactory results, the system fuses road detection
results obtained from three variants of RoadSeg, processing different LIDAR
features.
</p>
<a href="http://arxiv.org/abs/2102.03326" target="_blank">arXiv:2102.03326</a> [<a href="http://arxiv.org/pdf/2102.03326" target="_blank">pdf</a>]

<h2>ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision. (arXiv:2102.03334v1 [stat.ML])</h2>
<h3>Wonjae Kim, Bokyung Son, Ildoo Kim</h3>
<p>Vision-and-Language Pretraining (VLP) has improved performance on various
joint vision-and-language downstream tasks. Current approaches for VLP heavily
rely on image feature extraction processes, most of which involve region
supervisions (e.g., object detection) and the convolutional architecture (e.g.,
ResNet). Although disregarded in the literature, we find it problematic in
terms of both (1) efficiency/speed, that simply extracting input features
requires much more computation than the actual multimodal interaction steps;
and (2) expressive power, as it is upper bounded to the expressive power of the
visual encoder and its predefined visual vocabulary. In this paper, we present
a minimal VLP model, Vision-and-Language Transformer (ViLT), monolithic in the
sense that processing of visual inputs is drastically simplified to just the
same convolution-free manner that we process textual inputs. We show that ViLT
is up to 60 times faster than previous VLP models, yet with competitive or
better downstream task performance.
</p>
<a href="http://arxiv.org/abs/2102.03334" target="_blank">arXiv:2102.03334</a> [<a href="http://arxiv.org/pdf/2102.03334" target="_blank">pdf</a>]

<h2>Machine Learning Applications on Neuroimaging for Diagnosis and Prognosis of Epilepsy: A Review. (arXiv:2102.03336v1 [cs.LG])</h2>
<h3>Jie Yuan, Xuming Ran, Keyin Liu, Chen Yao, Yi Yao, Haiyan Wu, Quanying Liu</h3>
<p>Machine learning is playing an increasing important role in medical image
analysis, spawning new advances in neuroimaging clinical applications. However,
previous work and reviews were mainly focused on the electrophysiological
signals like EEG or SEEG; the potential of neuroimaging in epilepsy research
has been largely overlooked despite of its wide use in clinical practices. In
this review, we highlight the interactions between neuroimaging and machine
learning in the context of the epilepsy diagnosis and prognosis. We firstly
outline typical neuroimaging modalities used in epilepsy clinics, \textit{e.g}
MRI, DTI, fMRI and PET. We then introduce two approaches to apply machine
learning methods to neuroimaging data: the two-step compositional approach
which combines feature engineering and machine learning classifier, and the
end-to-end approach which is usually toward deep learning. Later a detailed
review on the machine learning tasks on epileptic images is presented, such as
segmentation, localization and lateralization tasks, as well as the tasks
directly related to the diagnosis and prognosis. In the end, we discuss current
achievements, challenges, potential future directions in the field, with the
hope to pave a way to computer-aided diagnosis and prognosis of epilepsy.
</p>
<a href="http://arxiv.org/abs/2102.03336" target="_blank">arXiv:2102.03336</a> [<a href="http://arxiv.org/pdf/2102.03336" target="_blank">pdf</a>]

<h2>NRTSI: Non-Recurrent Time Series Imputation for Irregularly-sampled Data. (arXiv:2102.03340v1 [cs.LG])</h2>
<h3>Siyuan Shan, Junier B. Oliva</h3>
<p>Time series imputation is a fundamental task for understanding time series
with missing data. Existing imputation methods often rely on recurrent models
such as RNNs and ordinary differential equations, both of which suffer from the
error compounding problems of recurrent models. In this work, we view the
imputation task from the perspective of permutation equivariant modeling of
sets and propose a novel imputation model called NRTSI without any recurrent
modules. Taking advantage of the permutation equivariant nature of NRTSI, we
design a principled and efficient hierarchical imputation procedure. NRTSI can
easily handle irregularly-sampled data, perform multiple-mode stochastic
imputation, and handle the scenario where dimensions are partially observed. We
show that NRTSI achieves state-of-the-art performance across a wide range of
commonly used time series imputation benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.03340" target="_blank">arXiv:2102.03340</a> [<a href="http://arxiv.org/pdf/2102.03340" target="_blank">pdf</a>]

<h2>On the Reproducibility of Neural Network Predictions. (arXiv:2102.03349v1 [cs.LG])</h2>
<h3>Srinadh Bhojanapalli, Kimberly Wilber, Andreas Veit, Ankit Singh Rawat, Seungyeon Kim, Aditya Menon, Sanjiv Kumar</h3>
<p>Standard training techniques for neural networks involve multiple sources of
randomness, e.g., initialization, mini-batch ordering and in some cases data
augmentation. Given that neural networks are heavily over-parameterized in
practice, such randomness can cause {\em churn} -- for the same input,
disagreements between predictions of the two models independently trained by
the same algorithm, contributing to the `reproducibility challenges' in modern
machine learning. In this paper, we study this problem of churn, identify
factors that cause it, and propose two simple means of mitigating it. We first
demonstrate that churn is indeed an issue, even for standard image
classification tasks (CIFAR and ImageNet), and study the role of the different
sources of training randomness that cause churn. By analyzing the relationship
between churn and prediction confidences, we pursue an approach with two
components for churn reduction. First, we propose using \emph{minimum entropy
regularizers} to increase prediction confidences. Second, \changes{we present a
novel variant of co-distillation approach~\citep{anil2018large} to increase
model agreement and reduce churn}. We present empirical results showing the
effectiveness of both techniques in reducing churn while improving the accuracy
of the underlying model.
</p>
<a href="http://arxiv.org/abs/2102.03349" target="_blank">arXiv:2102.03349</a> [<a href="http://arxiv.org/pdf/2102.03349" target="_blank">pdf</a>]

<h2>Automatic topography of high-dimensional data sets by non-parametric Density Peak clustering. (arXiv:1802.10549v2 [stat.ML] UPDATED)</h2>
<h3>Maria d&#x27;Errico, Elena Facco, Alessandro Laio, Alex Rodriguez</h3>
<p>Data analysis in high-dimensional spaces aims at obtaining a synthetic
description of a data set, revealing its main structure and its salient
features. We here introduce an approach providing this description in the form
of a topography of the data, namely a human-readable chart of the probability
density from which the data are harvested. The approach is based on an
unsupervised extension of Density Peak clustering and a non-parametric density
estimator that measures the probability density in the manifold containing the
data. This allows finding automatically the number and the height of the peaks
of the probability density, and the depth of the "valleys" separating them.
Importantly, the density estimator provides a measure of the error, which
allows distinguishing genuine density peaks from density fluctuations due to
finite sampling. The approach thus provides robust and visual information about
the density peaks' height, their statistical reliability, and their
hierarchical organization, offering a conceptually powerful extension of the
standard clustering partitions. We show that this framework is particularly
useful in the analysis of complex data sets.
</p>
<a href="http://arxiv.org/abs/1802.10549" target="_blank">arXiv:1802.10549</a> [<a href="http://arxiv.org/pdf/1802.10549" target="_blank">pdf</a>]

<h2>A Tutorial On Autonomous Vehicle Steering Controller Design, Simulation and Implementation. (arXiv:1803.03758v3 [cs.RO] UPDATED)</h2>
<h3>Ali Boyali, Seichi Mita, Vijay John</h3>
<p>In this tutorial, we detailed simple controllers for autonomous parking and
path following for self-driving cars providing practical methods for curvature
computation.
</p>
<a href="http://arxiv.org/abs/1803.03758" target="_blank">arXiv:1803.03758</a> [<a href="http://arxiv.org/pdf/1803.03758" target="_blank">pdf</a>]

<h2>Towards A Unified Analysis of Random Fourier Features. (arXiv:1806.09178v5 [stat.ML] UPDATED)</h2>
<h3>Zhu Li, Jean-Francois Ton, Dino Oglic, Dino Sejdinovic</h3>
<p>Random Fourier features is a widely used, simple, and effective technique for
scaling up kernel methods. The existing theoretical analysis of the approach,
however, remains focused on specific learning tasks and typically gives
pessimistic bounds which are at odds with the empirical results. We tackle
these problems and provide the first unified risk analysis of learning with
random Fourier features using the squared error and Lipschitz continuous loss
functions. In our bounds, the trade-off between the computational cost and the
expected risk convergence rate is problem specific and expressed in terms of
the regularization parameter and the \emph{number of effective degrees of
freedom}. We study both the standard random Fourier features method for which
we improve the existing bounds on the number of features required to guarantee
the corresponding minimax risk convergence rate of kernel ridge regression, as
well as a data-dependent modification which samples features proportional to
\emph{ridge leverage scores} and further reduces the required number of
features. As ridge leverage scores are expensive to compute, we devise a simple
approximation scheme which provably reduces the computational cost without loss
of statistical efficiency.
</p>
<a href="http://arxiv.org/abs/1806.09178" target="_blank">arXiv:1806.09178</a> [<a href="http://arxiv.org/pdf/1806.09178" target="_blank">pdf</a>]

<h2>Uncertainty about Uncertainty: Optimal Adaptive Algorithms for Estimating Mixtures of Unknown Coins. (arXiv:1904.09228v3 [cs.LG] UPDATED)</h2>
<h3>Jasper C.H. Lee, Paul Valiant</h3>
<p>Given a mixture between two populations of coins, "positive" coins that each
have -- unknown and potentially different -- bias $\geq\frac{1}{2}+\Delta$ and
"negative" coins with bias $\leq\frac{1}{2}-\Delta$, we consider the task of
estimating the fraction $\rho$ of positive coins to within additive error
$\epsilon$. We achieve an upper and lower bound of
$\Theta(\frac{\rho}{\epsilon^2\Delta^2}\log\frac{1}{\delta})$ samples for a
$1-\delta$ probability of success, where crucially, our lower bound applies to
all fully-adaptive algorithms. Thus, our sample complexity bounds have tight
dependence for every relevant problem parameter. A crucial component of our
lower bound proof is a decomposition lemma (see Lemmas 17 and 18) showing how
to assemble partially-adaptive bounds into a fully-adaptive bound, which may be
of independent interest: though we invoke it for the special case of Bernoulli
random variables (coins), it applies to general distributions. We present
simulation results to demonstrate the practical efficacy of our approach for
realistic problem parameters for crowdsourcing applications, focusing on the
"rare events" regime where $\rho$ is small. The fine-grained adaptive flavor of
both our algorithm and lower bound contrasts with much previous work in
distributional testing and learning.
</p>
<a href="http://arxiv.org/abs/1904.09228" target="_blank">arXiv:1904.09228</a> [<a href="http://arxiv.org/pdf/1904.09228" target="_blank">pdf</a>]

<h2>On the Privacy Risks of Model Explanations. (arXiv:1907.00164v6 [cs.LG] UPDATED)</h2>
<h3>Reza Shokri, Martin Strobel, Yair Zick</h3>
<p>Privacy and transparency are two key foundations of trustworthy machine
learning. Model explanations offer insights into a model's decisions on input
data, whereas privacy is primarily concerned with protecting information about
the training data. We analyze connections between model explanations and the
leakage of sensitive information about the model's training set. We investigate
the privacy risks of feature-based model explanations using membership
inference attacks: quantifying how much model predictions plus their
explanations leak information about the presence of a datapoint in the training
set of a model. We extensively evaluate membership inference attacks based on
feature-based model explanations, over a variety of datasets. We show that
backpropagation-based explanations can leak a significant amount of information
about individual training datapoints. This is because they reveal statistical
information about the decision boundaries of the model about an input, which
can reveal its membership. We also empirically investigate the trade-off
between privacy and explanation quality, by studying the perturbation-based
model explanations.
</p>
<a href="http://arxiv.org/abs/1907.00164" target="_blank">arXiv:1907.00164</a> [<a href="http://arxiv.org/pdf/1907.00164" target="_blank">pdf</a>]

<h2>An Alternative Cross Entropy Loss for Learning-to-Rank. (arXiv:1911.09798v5 [cs.LG] UPDATED)</h2>
<h3>Sebastian Bruch</h3>
<p>Listwise learning-to-rank methods form a powerful class of ranking algorithms
that are widely adopted in applications such as information retrieval. These
algorithms learn to rank a set of items by optimizing a loss that is a function
of the entire set -- as a surrogate to a typically non-differentiable ranking
metric. Despite their empirical success, existing listwise methods are based on
heuristics and remain theoretically ill-understood. In particular, none of the
empirically successful loss functions are related to ranking metrics. In this
work, we propose a cross entropy-based learning-to-rank loss function that is
theoretically sound, is a convex bound on NDCG -- a popular ranking metric --
and is consistent with NDCG under learning scenarios common in information
retrieval. Furthermore, empirical evaluation of an implementation of the
proposed method with gradient boosting machines on benchmark learning-to-rank
datasets demonstrates the superiority of our proposed formulation over existing
algorithms in quality and robustness.
</p>
<a href="http://arxiv.org/abs/1911.09798" target="_blank">arXiv:1911.09798</a> [<a href="http://arxiv.org/pdf/1911.09798" target="_blank">pdf</a>]

<h2>Compression of descriptor models for mobile applications. (arXiv:2001.03102v3 [cs.CV] UPDATED)</h2>
<h3>Roy Miles, Krystian Mikolajczyk</h3>
<p>Deep neural networks have demonstrated state-of-the-art performance for
feature-based image matching through the advent of new large and diverse
datasets. However, there has been little work on evaluating the computational
cost, model size, and matching accuracy tradeoffs for these models. This paper
explicitly addresses these practical metrics by considering the
state-of-the-art HardNet model. We observe a significant redundancy in the
learned weights, which we exploit through the use of depthwise separable layers
and an efficient Tucker decomposition. We demonstrate that a combination of
these methods is very effective, but still sacrifices the top-end accuracy. To
resolve this, we propose the Convolution-Depthwise-Pointwise(CDP) layer, which
provides a means of interpolating between the standard and depthwise separable
convolutions. With this proposed layer, we can achieve an 8 times reduction in
the number of parameters on the HardNet model, 13 times reduction in the
computational complexity, while sacrificing less than 1% on the overall
accuracy across theHPatchesbenchmarks. To further demonstrate the
generalisation of this approach, we apply it to the state-of-the-art SuperPoint
model, where we can significantly reduce the number of parameters and
floating-point operations, with minimal degradation in the matching accuracy.
</p>
<a href="http://arxiv.org/abs/2001.03102" target="_blank">arXiv:2001.03102</a> [<a href="http://arxiv.org/pdf/2001.03102" target="_blank">pdf</a>]

<h2>Neighborhood Structure Assisted Non-negative Matrix Factorization and its Application in Unsupervised Point-wise Anomaly Detection. (arXiv:2001.06541v3 [cs.LG] UPDATED)</h2>
<h3>Imtiaz Ahmed, Xia Ben Hu, Mithun P. Acharya, Yu Ding</h3>
<p>Dimensionality reduction is considered as an important step for ensuring
competitive performance in unsupervised learning such as anomaly detection.
Non-negative matrix factorization (NMF) is a popular and widely used method to
accomplish this goal. But NMF do not have the provision to include the
neighborhood structure information and, as a result, may fail to provide
satisfactory performance in presence of nonlinear manifold structure. To
address that shortcoming, we propose to consider and incorporate the
neighborhood structural similarity information within the NMF framework by
modeling the data through a minimum spanning tree. We label the resulting
method as the neighborhood structure assisted NMF. We further devise both
offline and online algorithmic versions of the proposed method. Empirical
comparisons using twenty benchmark datasets as well as an industrial dataset
extracted from a hydropower plant demonstrate the superiority of the
neighborhood structure assisted NMF and support our claim of merit. Looking
closer into the formulation and properties of the neighborhood structure
assisted NMF with other recent, enhanced versions of NMF reveals that inclusion
of the neighborhood structure information using MST plays a key role in
attaining the enhanced performance in anomaly detection.
</p>
<a href="http://arxiv.org/abs/2001.06541" target="_blank">arXiv:2001.06541</a> [<a href="http://arxiv.org/pdf/2001.06541" target="_blank">pdf</a>]

<h2>Bidirectional Trajectory Computation for Odometer-Aided Visual-Inertial SLAM. (arXiv:2002.00195v3 [cs.RO] UPDATED)</h2>
<h3>Jinxu Liu, Wei Gao, Zhanyi Hu</h3>
<p>Odometer-aided visual-inertial SLAM systems typically have a good performance
for navigation of wheeled platforms, while they usually suffer from degenerate
cases before the first turning. In this paper, firstly we perform an
observability analysis w.r.t. the extrinsic parameters before the first
turning, which is a complement of the existing results of observability
analyses. Secondly, inspired by the above observability analyses, we propose a
bidirectional trajectory computation method, by which the poses before the
first turning are refined in the backward computation thread, and the real-time
trajectory is adjusted accordingly. Experimental results prove that our
proposed method not only solves the problem of the unobservability of
accelerometer bias and extrinsic parameters before the first turning, but also
results in more accurate trajectories in comparison with the state-of-the-art
approaches.
</p>
<a href="http://arxiv.org/abs/2002.00195" target="_blank">arXiv:2002.00195</a> [<a href="http://arxiv.org/pdf/2002.00195" target="_blank">pdf</a>]

<h2>Out-of-Distribution Detection with Distance Guarantee in Deep Generative Models. (arXiv:2002.03328v3 [cs.LG] UPDATED)</h2>
<h3>Yufeng Zhang, Wanwei Liu, Zhenbang Chen, Ji Wang, Zhiming Liu, Kenli Li, Hongmei Wei</h3>
<p>Recent research has revealed that deep generative models including flow-based
models and Variational autoencoders may assign higher likelihood to
out-of-distribution (OOD) data than in-distribution (ID) data. However, we
cannot sample out OOD data from the model. This counterintuitive phenomenon has
not been satisfactorily explained. In this paper, we prove theorems to
investigate the divergences in flow-based model and give two explanations to
the above phenomenon from divergence and geometric perspectives, respectively.
Based on our analysis, we propose two group anomaly detection methods.
Furthermore, we decompose the KL divergence and propose a point-wise anomaly
detection method. We have conducted extensive experiments on prevalent
benchmarks to evaluate our methods. For group anomaly detection (GAD), our
method can achieve near 100\% AUROC on all problems and has robustness against
data manipulations. On the contrary, the state-of-the-art (SOTA) GAD method
performs not better than random guessing for challenging problems and can be
attacked by data manipulation in almost all cases. For point-wise anomaly
detection (PAD), our method is comparable to the SOTA PAD method on one
category of problems and outperforms the baseline significantly on another
category of problems.
</p>
<a href="http://arxiv.org/abs/2002.03328" target="_blank">arXiv:2002.03328</a> [<a href="http://arxiv.org/pdf/2002.03328" target="_blank">pdf</a>]

<h2>Learning Stochastic Behaviour of Aggregate Data. (arXiv:2002.03513v3 [cs.LG] UPDATED)</h2>
<h3>Shaojun Ma, Shu Liu, Hongyuan Zha, Haomin Zhou</h3>
<p>Learning nonlinear dynamics from aggregate datais a challenging problem
because the full trajectory of each individual is not available, namely, the
individual observed at one time may not beobserved at the next time point, or
the identity ofindividual is unavailable. This is in sharp contrastto learning
dynamics with full trajectory data, on which the majority of existing methods
are based. We propose a novel method using the weak form of Fokker Planck
Equation(FPE) -- a partial differential equation -- to describe the density
evolution of data in a sampled form, which is then combined with Wasserstein
generative adversarial network (WGAN) in the training process. Insuch a sample
based framework we are able to learn the nonlinear dynamics from aggregate data
without explicitly solving FPE. More importantly, our model can also readily
handle high dimensional cases by leveraging deep neural networks. We
demonstrate our approach in the context of aseries of synthetic and real-world
data sets.
</p>
<a href="http://arxiv.org/abs/2002.03513" target="_blank">arXiv:2002.03513</a> [<a href="http://arxiv.org/pdf/2002.03513" target="_blank">pdf</a>]

<h2>Provable Meta-Learning of Linear Representations. (arXiv:2002.11684v4 [cs.LG] UPDATED)</h2>
<h3>Nilesh Tripuraneni, Chi Jin, Michael I. Jordan</h3>
<p>Meta-learning, or learning-to-learn, seeks to design algorithms that can
utilize previous experience to rapidly learn new skills or adapt to new
environments. Representation learning -- a key tool for performing
meta-learning -- learns a data representation that can transfer knowledge
across multiple tasks, which is essential in regimes where data is scarce.
Despite a recent surge of interest in the practice of meta-learning, the
theoretical underpinnings of meta-learning algorithms are lacking, especially
in the context of learning transferable representations. In this paper, we
focus on the problem of multi-task linear regression -- in which multiple
linear regression models share a common, low-dimensional linear representation.
Here, we provide provably fast, sample-efficient algorithms to address the dual
challenges of (1) learning a common set of features from multiple, related
tasks, and (2) transferring this knowledge to new, unseen tasks. Both are
central to the general problem of meta-learning. Finally, we complement these
results by providing information-theoretic lower bounds on the sample
complexity of learning these linear features.
</p>
<a href="http://arxiv.org/abs/2002.11684" target="_blank">arXiv:2002.11684</a> [<a href="http://arxiv.org/pdf/2002.11684" target="_blank">pdf</a>]

<h2>Decision-Making for Automated Vehicles Using a Hierarchical Behavior-Based Arbitration Scheme. (arXiv:2003.01149v4 [cs.RO] UPDATED)</h2>
<h3>Piotr Franciszek Orzechowski, Christoph Burger, Martin Lauer</h3>
<p>Behavior planning and decision-making are some of the biggest challenges for
highly automated systems. A fully automated vehicle (AV) is confronted with
numerous tactical and strategical choices. Most state-of-the-art AV platforms
implement tactical and strategical behavior generation using finite state
machines. However, these usually result in poor explainability, maintainability
and scalability. Research in robotics has raised many architectures to mitigate
these problems, most interestingly behavior-based systems and hybrid
derivatives. Inspired by these approaches, we propose a hierarchical
behavior-based architecture for tactical and strategical behavior generation in
automated driving. It is a generalizing and scalable decision-making framework,
utilizing modular behavior blocks to compose more complex behaviors in a
bottom-up approach. The system is capable of combining a variety of scenario-
and methodology-specific solutions, like POMDPs, RRT* or learning-based
behavior, into one understandable and traceable architecture. We extend the
hierarchical behavior-based arbitration concept to address scenarios where
multiple behavior options are applicable but have no clear priority against
each other. Then, we formulate the behavior generation stack for automated
driving in urban and highway environments, incorporating parking and emergency
behaviors as well. Finally, we illustrate our design in an explanatory
evaluation.
</p>
<a href="http://arxiv.org/abs/2003.01149" target="_blank">arXiv:2003.01149</a> [<a href="http://arxiv.org/pdf/2003.01149" target="_blank">pdf</a>]

<h2>General linear-time inference for Gaussian Processes on one dimension. (arXiv:2003.05554v3 [stat.ML] UPDATED)</h2>
<h3>Jackson Loper, David Blei, John P. Cunningham, Liam Paninski</h3>
<p>Gaussian Processes (GPs) provide a powerful probabilistic framework for
interpolation, forecasting, and smoothing, but have been hampered by
computational scaling issues. Here we prove that for data sampled on one
dimension (e.g., a time series sampled at arbitrarily-spaced intervals),
approximate GP inference at any desired level of accuracy requires
computational effort that scales linearly with the number of observations; this
new theorem enables inference on much larger datasets than was previously
feasible. To achieve this improved scaling we propose a new family of
stationary covariance kernels: the Latent Exponentially Generated (LEG) family,
which admits a convenient stable state-space representation that allows
linear-time inference. We prove that any continuous integrable stationary
kernel can be approximated arbitrarily well by some member of the LEG family.
The proof draws connections to Spectral Mixture Kernels, providing new insight
about the flexibility of this popular family of kernels. We propose
parallelized algorithms for performing inference and learning in the LEG model,
test the algorithm on real and synthetic data, and demonstrate scaling to
datasets with billions of samples.
</p>
<a href="http://arxiv.org/abs/2003.05554" target="_blank">arXiv:2003.05554</a> [<a href="http://arxiv.org/pdf/2003.05554" target="_blank">pdf</a>]

<h2>aphBO-2GP-3B: A budgeted asynchronous parallel multi-acquisition functions for constrained Bayesian optimization on high-performing computing architecture. (arXiv:2003.09436v2 [stat.ML] UPDATED)</h2>
<h3>Anh Tran, Mike Eldred, Tim Wildey, Scott McCann, Jing Sun, Robert J. Visintainer</h3>
<p>High-fidelity complex engineering simulations are highly predictive, but also
computationally expensive and often require substantial computational efforts.
The mitigation of computational burden is usually enabled through parallelism
in high-performance cluster (HPC) architecture. In this paper, an asynchronous
constrained batch-parallel Bayesian optimization method is proposed to
efficiently solve the computationally-expensive simulation-based optimization
problems on the HPC platform, with a budgeted computational resource, where the
maximum number of simulations is a constant. The advantages of this method are
three-fold. First, the efficiency of the Bayesian optimization is improved,
where multiple input locations are evaluated massively parallel in an
asynchronous manner to accelerate the optimization convergence with respect to
physical runtime. This efficiency feature is further improved so that when each
of the inputs is finished, another input is queried without waiting for the
whole batch to complete. Second, the method can handle both known and unknown
constraints. Third, the proposed method considers several acquisition functions
at the same time and sample based on an evolving probability mass distribution
function using a modified GP-Hedge scheme, where parameters are corresponding
to the performance of each acquisition function. The proposed framework is
termed aphBO-2GP-3B, which corresponds to asynchronous parallel hedge Bayesian
optimization with two Gaussian processes and three batches. The aphBO-2GP-3B
framework is demonstrated using two high-fidelity expensive industrial
applications, where the first one is based on finite element analysis (FEA) and
the second one is based on computational fluid dynamics (CFD) simulations.
</p>
<a href="http://arxiv.org/abs/2003.09436" target="_blank">arXiv:2003.09436</a> [<a href="http://arxiv.org/pdf/2003.09436" target="_blank">pdf</a>]

<h2>Event Based, Near Eye Gaze Tracking Beyond 10,000Hz. (arXiv:2004.03577v2 [cs.CV] UPDATED)</h2>
<h3>Anastasios N. Angelopoulos, Julien N.P. Martel, Amit P.S. Kohli, Jorg Conradt, Gordon Wetzstein</h3>
<p>The cameras in modern gaze-tracking systems suffer from fundamental bandwidth
and power limitations, constraining data acquisition speed to 300 Hz
realistically. This obstructs the use of mobile eye trackers to perform, e.g.,
low latency predictive rendering, or to study quick and subtle eye motions like
microsaccades using head-mounted devices in the wild. Here, we propose a hybrid
frame-event-based near-eye gaze tracking system offering update rates beyond
10,000 Hz with an accuracy that matches that of high-end desktop-mounted
commercial trackers when evaluated in the same conditions. Our system builds on
emerging event cameras that simultaneously acquire regularly sampled frames and
adaptively sampled events. We develop an online 2D pupil fitting method that
updates a parametric model every one or few events. Moreover, we propose a
polynomial regressor for estimating the point of gaze from the parametric pupil
model in real time. Using the first event-based gaze dataset, available at
https://github.com/aangelopoulos/event_based_gaze_tracking , we demonstrate
that our system achieves accuracies of 0.45 degrees--1.75 degrees for fields of
view from 45 degrees to 98 degrees. With this technology, we hope to enable a
new generation of ultra-low-latency gaze-contingent rendering and display
techniques for virtual and augmented reality.
</p>
<a href="http://arxiv.org/abs/2004.03577" target="_blank">arXiv:2004.03577</a> [<a href="http://arxiv.org/pdf/2004.03577" target="_blank">pdf</a>]

<h2>Distributed Learning and Inference with Compressed Images. (arXiv:2004.10497v2 [cs.CV] UPDATED)</h2>
<h3>Sudeep Katakol, Basem Elbarashy, Luis Herranz, Joost van de Weijer, Antonio M. Lopez</h3>
<p>Modern computer vision requires processing large amounts of data, both while
training the model and/or during inference, once the model is deployed.
Scenarios where images are captured and processed in physically separated
locations are increasingly common (e.g. autonomous vehicles, cloud computing).
In addition, many devices suffer from limited resources to store or transmit
data (e.g. storage space, channel capacity). In these scenarios, lossy image
compression plays a crucial role to effectively increase the number of images
collected under such constraints. However, lossy compression entails some
undesired degradation of the data that may harm the performance of the
downstream analysis task at hand, since important semantic information may be
lost in the process. Moreover, we may only have compressed images at training
time but are able to use original images at inference time, or vice versa, and
in such a case, the downstream model suffers from covariate shift. In this
paper, we analyze this phenomenon, with a special focus on vision-based
perception for autonomous driving as a paradigmatic scenario. We see that loss
of semantic information and covariate shift do indeed exist, resulting in a
drop in performance that depends on the compression rate. In order to address
the problem, we propose dataset restoration, based on image restoration with
generative adversarial networks (GANs). Our method is agnostic to both the
particular image compression method and the downstream task; and has the
advantage of not adding additional cost to the deployed models, which is
particularly important in resource-limited devices. The presented experiments
focus on semantic segmentation as a challenging use case, cover a broad range
of compression rates and diverse datasets, and show how our method is able to
significantly alleviate the negative effects of compression on the downstream
visual task.
</p>
<a href="http://arxiv.org/abs/2004.10497" target="_blank">arXiv:2004.10497</a> [<a href="http://arxiv.org/pdf/2004.10497" target="_blank">pdf</a>]

<h2>On the Minimax Optimality of the EM Algorithm for Learning Two-Component Mixed Linear Regression. (arXiv:2006.02601v2 [stat.ML] UPDATED)</h2>
<h3>Jeongyeol Kwon, Nhat Ho, Constantine Caramanis</h3>
<p>We study the convergence rates of the EM algorithm for learning two-component
mixed linear regression under all regimes of signal-to-noise ratio (SNR). We
resolve a long-standing question that many recent results have attempted to
tackle: we completely characterize the convergence behavior of EM, and show
that the EM algorithm achieves minimax optimal sample complexity under all SNR
regimes. In particular, when the SNR is sufficiently large, the EM updates
converge to the true parameter $\theta^{*}$ at the standard parametric
convergence rate $\mathcal{O}((d/n)^{1/2})$ after $\mathcal{O}(\log(n/d))$
iterations. In the regime where the SNR is above $\mathcal{O}((d/n)^{1/4})$ and
below some constant, the EM iterates converge to a $\mathcal{O}({\rm SNR}^{-1}
(d/n)^{1/2})$ neighborhood of the true parameter, when the number of iterations
is of the order $\mathcal{O}({\rm SNR}^{-2} \log(n/d))$. In the low SNR regime
where the SNR is below $\mathcal{O}((d/n)^{1/4})$, we show that EM converges to
a $\mathcal{O}((d/n)^{1/4})$ neighborhood of the true parameters, after
$\mathcal{O}((n/d)^{1/2})$ iterations. Notably, these results are achieved
under mild conditions of either random initialization or an efficiently
computable local initialization. By providing tight convergence guarantees of
the EM algorithm in middle-to-low SNR regimes, we fill the remaining gap in the
literature, and significantly, reveal that in low SNR, EM changes rate,
matching the $n^{-1/4}$ rate of the MLE, a behavior that previous work had been
unable to show.
</p>
<a href="http://arxiv.org/abs/2006.02601" target="_blank">arXiv:2006.02601</a> [<a href="http://arxiv.org/pdf/2006.02601" target="_blank">pdf</a>]

<h2>Almost sure convergence rates for Stochastic Gradient Descent and Stochastic Heavy Ball. (arXiv:2006.07867v2 [cs.LG] UPDATED)</h2>
<h3>Othmane Sebbouh, Robert M. Gower, Aaron Defazio</h3>
<p>We study stochastic gradient descent (SGD) and the stochastic heavy ball
method (SHB, otherwise known as the momentum method) for the general stochastic
approximation problem.

For SGD, in the convex and smooth setting, we provide the first \emph{almost
sure} asymptotic convergence \emph{rates} for a weighted average of the
iterates . More precisely, we show that the convergence rate of the function
values is arbitrarily close to $o(1/\sqrt{k})$, and is exactly $o(1/k)$ in the
so-called overparametrized case. We show that these results still hold when
using stochastic line search and stochastic Polyak stepsizes, thereby giving
the first proof of convergence of these methods in the non-overparametrized
regime.

Using a substantially different analysis, we show that these rates hold for
SHB as well, but at the last iterate. This distinction is important because it
is the last iterate of SGD and SHB which is used in practice. We also show that
the last iterate of SHB converges to a minimizer \emph{almost surely}.
Additionally, we prove that the function values of the deterministic HB
converge at a $o(1/k)$ rate, which is faster than the previously known
$O(1/k)$.

Finally, in the nonconvex setting, we prove similar rates on the lowest
gradient norm along the trajectory of SGD.
</p>
<a href="http://arxiv.org/abs/2006.07867" target="_blank">arXiv:2006.07867</a> [<a href="http://arxiv.org/pdf/2006.07867" target="_blank">pdf</a>]

<h2>Achieving Fairness via Post-Processing in Web-Scale Recommender Systems. (arXiv:2006.11350v2 [stat.ML] UPDATED)</h2>
<h3>Preetam Nandy, Cyrus Diciccio, Divya Venugopalan, Heloise Logan, Kinjal Basu, Noureddine El Karoui</h3>
<p>Building fair recommender systems is a challenging and extremely important
area of study due to its immense impact on society. We focus on two commonly
accepted notions of fairness for machine learning models powering such
recommender systems, namely equality of opportunity and equalized odds. These
measures of fairness make sure that equally "qualified" (or "unqualified")
candidates are treated equally regardless of their protected attribute status
(such as gender or race). In this paper, we propose scalable methods for
achieving equality of opportunity and equalized odds in rankings in the
presence of position bias, which commonly plagues data generated from
recommendation systems. Our algorithms are model agnostic in the sense that
they depend only on the final scores provided by a model, making them easily
applicable to virtually all web-scale recommender systems. We conduct extensive
simulations as well as real-world experiments to show the efficacy of our
approach.
</p>
<a href="http://arxiv.org/abs/2006.11350" target="_blank">arXiv:2006.11350</a> [<a href="http://arxiv.org/pdf/2006.11350" target="_blank">pdf</a>]

<h2>On the Theoretical Equivalence of Several Trade-Off Curves Assessing Statistical Proximity. (arXiv:2006.11809v2 [cs.LG] UPDATED)</h2>
<h3>Rodrigue Siry, Ryan Webster, Loic Simon, Julien Rabin</h3>
<p>The recent advent of powerful generative models has triggered the renewed
development of quantitative measures to assess the proximity of two probability
distributions. As the scalar Frechet inception distance remains popular,
several methods have explored computing entire curves, which reveal the
trade-off between the fidelity and variability of the first distribution with
respect to the second one. Several of such variants have been proposed
independently and while intuitively similar, their relationship has not yet
been made explicit. In an effort to make the emerging picture of generative
evaluation more clear, we propose a unification of four curves known
respectively as: the precision-recall (PR) curve, the Lorenz curve, the
receiver operating characteristic (ROC) curve and a special case of R\'enyi
divergence frontiers. In addition, we discuss possible links between PR /
Lorenz curves with the derivation of domain adaptation bounds.
</p>
<a href="http://arxiv.org/abs/2006.11809" target="_blank">arXiv:2006.11809</a> [<a href="http://arxiv.org/pdf/2006.11809" target="_blank">pdf</a>]

<h2>Turbocharging Treewidth-Bounded Bayesian Network Structure Learning. (arXiv:2006.13843v2 [cs.AI] UPDATED)</h2>
<h3>Vaidyanathan P. R., Stefan Szeider</h3>
<p>We present a new approach for learning the structure of a treewidth-bounded
Bayesian Network (BN). The key to our approach is applying an exact method
(based on MaxSAT) locally, to improve the score of a heuristically computed BN.
This approach allows us to scale the power of exact methods -- so far only
applicable to BNs with several dozens of random variables -- to large BNs with
several thousands of random variables. Our experiments show that our method
improves the score of BNs provided by state-of-the-art heuristic methods, often
significantly.
</p>
<a href="http://arxiv.org/abs/2006.13843" target="_blank">arXiv:2006.13843</a> [<a href="http://arxiv.org/pdf/2006.13843" target="_blank">pdf</a>]

<h2>Sliced Iterative Normalizing Flows. (arXiv:2007.00674v2 [cs.LG] UPDATED)</h2>
<h3>Biwei Dai, Uros Seljak</h3>
<p>We develop an iterative (greedy) deep learning (DL) algorithm which is able
to transform an arbitrary probability distribution function (PDF) into the
target PDF. The model is based on iterative Optimal Transport of a series of 1D
slices, matching on each slice the marginal PDF to the target. The axes of the
orthogonal slices are chosen to maximize the PDF difference using Wasserstein
distance at each iteration, which enables the algorithm to scale well to high
dimensions. As special cases of this algorithm, we introduce two iterative
Normalizing Flow (NF) models, which map from the data to the latent space (GIS)
and vice versa (SIG). We show that SIG is able to generate high quality samples
of image datasets, which match the GAN benchmarks. GIS obtains competitive
results on density estimation tasks compared to the density trained NFs, and is
more stable, faster, and achieves higher p(x) when trained on small training
sets. SINF approach deviates significantly from the current DL paradigm, as it
is greedy and does not use concepts such as mini-batching, stochastic gradient
descent and gradient back-propagation through deep layers.
</p>
<a href="http://arxiv.org/abs/2007.00674" target="_blank">arXiv:2007.00674</a> [<a href="http://arxiv.org/pdf/2007.00674" target="_blank">pdf</a>]

<h2>A Closer Look at Art Mediums: The MAMe Image Classification Dataset. (arXiv:2007.13693v2 [cs.CV] UPDATED)</h2>
<h3>Ferran Par&#xe9;s, Anna Arias-Duart, Dario Garcia-Gasulla, Gema Campo-Franc&#xe9;s, Nina Viladrich, Eduard Ayguad&#xe9;, Jes&#xfa;s Labarta</h3>
<p>Art is an expression of human creativity, skill and technology. An
exceptionally rich source of visual content. In the context of AI image
processing systems, artworks represent one of the most challenging domains
conceivable: Properly perceiving art requires attention to detail, a huge
generalization capacity, and recognizing both simple and complex visual
patterns. To challenge the AI community, this work introduces a novel image
classification task focused on museum art mediums, the MAMe dataset. Data is
gathered from three different museums, and aggregated by art experts into 29
classes of mediums (i.e. materials and techniques). For each class, MAMe
contains a minimum of 850 high-resolution and variable shape images (700 for
training, 150 for test). The combination of volume, resolution and shape allows
MAMe to fill a void in current image classification challenges, empowering
research in aspects so far overseen by the research community. After reviewing
the singularity of MAMe in the context of current image classification tasks, a
thorough description of the task is provided, together with dataset statistics.
Experiments are conducted to evaluate the impact of using high-resolution
images, variable shape inputs and both of these properties together. Results
illustrate the positive impact in performance when using high-resolution
images, while highlighting the lack of solutions to exploit variable shapes. An
additional experiment exposes the distinctiveness between the MAMe dataset and
the prototypical ImageNet dataset. Finally, the baselines are inspected using
explainability methods and expert knowledge, to gain insights on the challenges
that remain ahead.
</p>
<a href="http://arxiv.org/abs/2007.13693" target="_blank">arXiv:2007.13693</a> [<a href="http://arxiv.org/pdf/2007.13693" target="_blank">pdf</a>]

<h2>Action sequencing using visual permutations. (arXiv:2008.01156v2 [cs.RO] UPDATED)</h2>
<h3>Michael Burke, Kartic Subr, Subramanian Ramamoorthy</h3>
<p>Humans can easily reason about the sequence of high level actions needed to
complete tasks, but it is particularly difficult to instil this ability in
robots trained from relatively few examples. This work considers the task of
neural action sequencing conditioned on a single reference visual state. This
task is extremely challenging as it is not only subject to the significant
combinatorial complexity that arises from large action sets, but also requires
a model that can perform some form of symbol grounding, mapping high
dimensional input data to actions, while reasoning about action relationships.
This paper takes a permutation perspective and argues that action sequencing
benefits from the ability to reason about both permutations and ordering
concepts. Empirical analysis shows that neural models trained with latent
permutations outperform standard neural architectures in constrained action
sequencing tasks. Results also show that action sequencing using visual
permutations is an effective mechanism to initialise and speed up traditional
planning techniques and successfully scales to far greater action set sizes
than models considered previously.
</p>
<a href="http://arxiv.org/abs/2008.01156" target="_blank">arXiv:2008.01156</a> [<a href="http://arxiv.org/pdf/2008.01156" target="_blank">pdf</a>]

<h2>PatchNets: Patch-Based Generalizable Deep Implicit 3D Shape Representations. (arXiv:2008.01639v2 [cs.CV] UPDATED)</h2>
<h3>Edgar Tretschk, Ayush Tewari, Vladislav Golyanik, Michael Zollh&#xf6;fer, Carsten Stoll, Christian Theobalt</h3>
<p>Implicit surface representations, such as signed-distance functions, combined
with deep learning have led to impressive models which can represent detailed
shapes of objects with arbitrary topology. Since a continuous function is
learned, the reconstructions can also be extracted at any arbitrary resolution.
However, large datasets such as ShapeNet are required to train such models. In
this paper, we present a new mid-level patch-based surface representation. At
the level of patches, objects across different categories share similarities,
which leads to more generalizable models. We then introduce a novel method to
learn this patch-based representation in a canonical space, such that it is as
object-agnostic as possible. We show that our representation trained on one
category of objects from ShapeNet can also well represent detailed shapes from
any other category. In addition, it can be trained using much fewer shapes,
compared to existing approaches. We show several applications of our new
representation, including shape interpolation and partial point cloud
completion. Due to explicit control over positions, orientations and scales of
patches, our representation is also more controllable compared to object-level
representations, which enables us to deform encoded shapes non-rigidly.
</p>
<a href="http://arxiv.org/abs/2008.01639" target="_blank">arXiv:2008.01639</a> [<a href="http://arxiv.org/pdf/2008.01639" target="_blank">pdf</a>]

<h2>Mixed-Initiative Level Design with RL Brush. (arXiv:2008.02778v2 [cs.AI] UPDATED)</h2>
<h3>Omar Delarosa, Hang Dong, Mindy Ruan, Ahmed Khalifa, Julian Togelius</h3>
<p>This paper introduces \textit{RL Brush}, a level-editing tool for tile-based
games designed for mixed-initiative co-creation. The tool uses
reinforcement-learning-based models to augment manual human level-design
through the addition of AI-generated suggestions. Here, we apply \textit{RL
Brush} to designing levels for the classic puzzle game \textit{Sokoban}. We put
the tool online and tested it in 39 different sessions. The results show that
users using the AI suggestions stay around longer and their created levels on
average are more playable and more complex than without.
</p>
<a href="http://arxiv.org/abs/2008.02778" target="_blank">arXiv:2008.02778</a> [<a href="http://arxiv.org/pdf/2008.02778" target="_blank">pdf</a>]

<h2>Benign Overfitting and Noisy Features. (arXiv:2008.02901v2 [stat.ML] UPDATED)</h2>
<h3>Zhu Li, Weijie Su, Dino Sejdinovic</h3>
<p>Modern machine learning often operates in the regime where the number of
parameters is much higher than the number of data points, with zero training
loss and yet good generalization, thereby contradicting the classical
bias-variance trade-off. This \textit{benign overfitting} phenomenon has
recently been characterized using so called \textit{double descent} curves
where the risk undergoes another descent (in addition to the classical U-shaped
learning curve when the number of parameters is small) as we increase the
number of parameters beyond a certain threshold. In this paper, we examine the
conditions under which \textit{Benign Overfitting} occurs in the random feature
(RF) models, i.e. in a two-layer neural network with fixed first layer weights.
We adopt a new view of random feature and show that \textit{benign overfitting}
arises due to the noise which resides in such features (the noise may already
be present in the data and propagate to the features or it may be added by the
user to the features directly) and plays an important implicit regularization
role in the phenomenon.
</p>
<a href="http://arxiv.org/abs/2008.02901" target="_blank">arXiv:2008.02901</a> [<a href="http://arxiv.org/pdf/2008.02901" target="_blank">pdf</a>]

<h2>Towards Practical 2D Grapevine Bud Detection with Fully Convolutional Networks. (arXiv:2008.11872v2 [cs.CV] UPDATED)</h2>
<h3>Wenceslao Villegas Marset, Diego Sebasti&#xe1;n P&#xe9;rez, Carlos Ariel D&#xed;az, Facundo Bromberg</h3>
<p>In Viticulture, visual inspection of the plant is a necessary task for
measuring relevant variables. In many cases, these visual inspections are
susceptible to automation through computer vision methods. Bud detection is one
such visual task, central for the measurement of important variables such as:
measurement of bud sunlight exposure, autonomous pruning, bud counting,
type-of-bud classification, bud geometric characterization, internode length,
bud area, and bud development stage, among others. This paper presents a
computer method for grapevine bud detection based on a Fully Convolutional
Networks MobileNet architecture (FCN-MN). To validate its performance, this
architecture was compared in the detection task with a strong method for bud
detection, Scanning Windows (SW) based on a patch classifier, showing
improvements over three aspects of detection: segmentation, correspondence
identification and localization. The best version of FCN-MN showed a detection
F1-measure of $88.6\%$ (for true positives defined as detected components whose
intersection-over-union with the true bud is above $0.5$), and false positives
that are small and near the true bud. Splits -- false positives overlapping the
true bud -- showed a mean segmentation precision of $89.3\% (21.7)$, while
false alarms -- false positives not overlapping the true bud -- showed a mean
pixel area of only $8\%$ the area of a true bud, and a distance (between mass
centers) of $1.1$ true bud diameters. The paper concludes by discussing how
these results for FCN-MN would produce sufficiently accurate measurements of
bud variables such as bud number, bud area, and internode length, suggesting a
good performance in a practical setup.
</p>
<a href="http://arxiv.org/abs/2008.11872" target="_blank">arXiv:2008.11872</a> [<a href="http://arxiv.org/pdf/2008.11872" target="_blank">pdf</a>]

<h2>Constrained Labeling for Weakly Supervised Learning. (arXiv:2009.07360v3 [cs.LG] UPDATED)</h2>
<h3>Chidubem Arachie, Bert Huang</h3>
<p>Curation of large fully supervised datasets has become one of the major
roadblocks for machine learning. Weak supervision provides an alternative to
supervised learning by training with cheap, noisy, and possibly correlated
labeling functions from varying sources. The key challenge in weakly supervised
learning is combining the different weak supervision signals while navigating
misleading correlations in their errors. In this paper, we propose a simple
data-free approach for combining weak supervision signals by defining a
constrained space for the possible labels of the weak signals and training with
a random labeling within this constrained space. Our method is efficient and
stable, converging after a few iterations of gradient descent. We prove
theoretical conditions under which the worst-case error of the randomized label
decreases with the rank of the linear constraints. We show experimentally that
our method outperforms other weak supervision methods on various text- and
image-classification tasks.
</p>
<a href="http://arxiv.org/abs/2009.07360" target="_blank">arXiv:2009.07360</a> [<a href="http://arxiv.org/pdf/2009.07360" target="_blank">pdf</a>]

<h2>Evaluating representations by the complexity of learning low-loss predictors. (arXiv:2009.07368v2 [cs.LG] UPDATED)</h2>
<h3>William F. Whitney, Min Jae Song, David Brandfonbrener, Jaan Altosaar, Kyunghyun Cho</h3>
<p>We consider the problem of evaluating representations of data for use in
solving a downstream task. We propose to measure the quality of a
representation by the complexity of learning a predictor on top of the
representation that achieves low loss on a task of interest, and introduce two
methods, surplus description length (SDL) and $\varepsilon$ sample complexity
($\varepsilon$SC). In contrast to prior methods, which measure the amount of
information about the optimal predictor that is present in a specific amount of
data, our methods measure the amount of information needed from the data to
recover an approximation of the optimal predictor up to a specified tolerance.
We present a framework to compare these methods based on plotting the
validation loss versus evaluation dataset size (the "loss-data" curve).
Existing measures, such as mutual information and minimum description length
probes, correspond to slices and integrals along the data axis of the loss-data
curve, while ours correspond to slices and integrals along the loss axis. We
provide experiments on real data to compare the behavior of each of these
methods over datasets of varying size along with a high performance open source
library for representation evaluation at
https://github.com/willwhitney/reprieve.
</p>
<a href="http://arxiv.org/abs/2009.07368" target="_blank">arXiv:2009.07368</a> [<a href="http://arxiv.org/pdf/2009.07368" target="_blank">pdf</a>]

<h2>Modeling Text with Decision Forests using Categorical-Set Splits. (arXiv:2009.09991v3 [cs.LG] UPDATED)</h2>
<h3>Mathieu Guillame-Bert, Sebastian Bruch, Petr Mitrichev, Petr Mikheev, Jan Pfeifer</h3>
<p>Decision forest algorithms typically model data by learning a binary tree
structure recursively where every node splits the feature space into two
sub-regions, sending examples into the left or right branch as a result. In
axis-aligned decision forests, the "decision" to route an input example is the
result of the evaluation of a condition on a single dimension in the feature
space. Such conditions are learned using efficient, often greedy algorithms
that optimize a local loss function. For example, a node's condition may be a
threshold function applied to a numerical feature, and its parameter may be
learned by sweeping over the set of values available at that node and choosing
a threshold that maximizes some measure of purity. Crucially, whether an
algorithm exists to learn and evaluate conditions for a feature type determines
whether a decision forest algorithm can model that feature type at all. For
example, decision forests today cannot consume textual features directly --
such features must be transformed to summary statistics instead. In this work,
we set out to bridge that gap. We define a condition that is specific to
categorical-set features -- defined as an unordered set of categorical
variables -- and present an algorithm to learn it, thereby equipping decision
forests with the ability to directly model text, albeit without preserving
sequential order. Our algorithm is efficient during training and the resulting
conditions are fast to evaluate with our extension of the QuickScorer inference
algorithm. Experiments on benchmark text classification datasets demonstrate
the utility and effectiveness of our proposal.
</p>
<a href="http://arxiv.org/abs/2009.09991" target="_blank">arXiv:2009.09991</a> [<a href="http://arxiv.org/pdf/2009.09991" target="_blank">pdf</a>]

<h2>Task-Adaptive Robot Learning from Demonstration with Gaussian Process Models under Replication. (arXiv:2010.07795v3 [cs.RO] UPDATED)</h2>
<h3>Miguel Arduengo, Adri&#xe0; Colom&#xe9;, J&#xfa;lia Borr&#xe0;s, Luis Sentis, Carme Torras</h3>
<p>Learning from Demonstration (LfD) is a paradigm that allows robots to learn
complex manipulation tasks that can not be easily scripted, but can be
demonstrated by a human teacher. One of the challenges of LfD is to enable
robots to acquire skills that can be adapted to different scenarios. In this
paper, we propose to achieve this by exploiting the variations in the
demonstrations to retrieve an adaptive and robust policy, using Gaussian
Process (GP) models. Adaptability is enhanced by incorporating task parameters
into the model, which encode different specifications within the same task.
With our formulation, these parameters can be either real, integer, or
categorical. Furthermore, we propose a GP design that exploits the structure of
replications, i.e., repeated demonstrations with identical conditions within
data. Our method significantly reduces the computational cost of model fitting
in complex tasks, where replications are essential to obtain a robust model. We
illustrate our approach through several experiments on a handwritten letter
demonstration dataset.
</p>
<a href="http://arxiv.org/abs/2010.07795" target="_blank">arXiv:2010.07795</a> [<a href="http://arxiv.org/pdf/2010.07795" target="_blank">pdf</a>]

<h2>MicroNets: Neural Network Architectures for Deploying TinyML Applications on Commodity Microcontrollers. (arXiv:2010.11267v3 [cs.LG] UPDATED)</h2>
<h3>Colby Banbury, Chuteng Zhou, Igor Fedorov, Ramon Matas Navarro, Urmish Thakker, Dibakar Gope, Vijay Janapa Reddi, Matthew Mattina, Paul N. Whatmough</h3>
<p>Executing machine learning workloads locally on resource constrained
microcontrollers (MCUs) promises to drastically expand the application space of
IoT. However, so-called TinyML presents severe technical challenges, as deep
neural network inference demands a large compute and memory budget. To address
this challenge, neural architecture search (NAS) promises to help design
accurate ML models that meet the tight MCU memory, latency and energy
constraints. A key component of NAS algorithms is their latency/energy model,
i.e., the mapping from a given neural network architecture to its inference
latency/energy on an MCU. In this paper, we observe an intriguing property of
NAS search spaces for MCU model design: on average, model latency varies
linearly with model operation (op) count under a uniform prior over models in
the search space. Exploiting this insight, we employ differentiable NAS (DNAS)
to search for models with low memory usage and low op count, where op count is
treated as a viable proxy to latency. Experimental results validate our
methodology, yielding our MicroNet models, which we deploy on MCUs using
Tensorflow Lite Micro, a standard open-source NN inference runtime widely used
in the TinyML community. MicroNets demonstrate state-of-the-art results for all
three TinyMLperf industry-standard benchmark tasks: visual wake words, audio
keyword spotting, and anomaly detection.
</p>
<a href="http://arxiv.org/abs/2010.11267" target="_blank">arXiv:2010.11267</a> [<a href="http://arxiv.org/pdf/2010.11267" target="_blank">pdf</a>]

<h2>On a Guided Nonnegative Matrix Factorization. (arXiv:2010.11365v2 [cs.LG] UPDATED)</h2>
<h3>Joshua Vendrow, Jamie Haddock, Elizaveta Rebrova, Deanna Needell</h3>
<p>Fully unsupervised topic models have found fantastic success in document
clustering and classification. However, these models often suffer from the
tendency to learn less-than-meaningful or even redundant topics when the data
is biased towards a set of features. For this reason, we propose an approach
based upon the nonnegative matrix factorization (NMF) model, deemed
\textit{Guided NMF}, that incorporates user-designed seed word supervision. Our
experimental results demonstrate the promise of this model and illustrate that
it is competitive with other methods of this ilk with only very little
supervision information.
</p>
<a href="http://arxiv.org/abs/2010.11365" target="_blank">arXiv:2010.11365</a> [<a href="http://arxiv.org/pdf/2010.11365" target="_blank">pdf</a>]

<h2>Learning to Actively Learn: A Robust Approach. (arXiv:2010.15382v2 [cs.LG] UPDATED)</h2>
<h3>Jifan Zhang, Kevin Jamieson</h3>
<p>This work proposes a procedure for designing algorithms for specific adaptive
data collection tasks like active learning and pure-exploration multi-armed
bandits. Unlike the design of traditional adaptive algorithms that rely on
concentration of measure and careful analysis to justify the correctness and
sample complexity of the procedure, our adaptive algorithm is learned via
adversarial training over equivalence classes of problems derived from
information theoretic lower bounds. In particular, a single adaptive learning
algorithm is learned that competes with the best adaptive algorithm learned for
each equivalence class. Our procedure takes as input just the available
queries, set of hypotheses, loss function, and total query budget. This is in
contrast to existing meta-learning work that learns an adaptive algorithm
relative to an explicit, user-defined subset or prior distribution over
problems which can be challenging to define and be mismatched to the instance
encountered at test time. This work is particularly focused on the regime when
the total query budget is very small, such as a few dozen, which is much
smaller than those budgets typically considered by theoretically derived
algorithms. We perform synthetic experiments to justify the stability and
effectiveness of the training procedure, and then evaluate the method on tasks
derived from real data including a noisy 20 Questions game and a joke
recommendation task.
</p>
<a href="http://arxiv.org/abs/2010.15382" target="_blank">arXiv:2010.15382</a> [<a href="http://arxiv.org/pdf/2010.15382" target="_blank">pdf</a>]

<h2>Robust Watermarking Using Inverse Gradient Attention. (arXiv:2011.10850v2 [cs.CV] UPDATED)</h2>
<h3>Honglei Zhang, Hu Wang, Yuanzhouhan Cao, Chunhua Shen, Yidong Li</h3>
<p>Watermarking is the procedure of encoding desired information into an image
to resist potential noises while ensuring the embedded image has little
perceptual perturbations from the original image. Recently, with the tremendous
successes gained by deep neural networks in various fields, digital
watermarking has attracted increasing number of attentions. The neglect of
considering the pixel importance within the cover image of deep neural models
will inevitably affect the model robustness for information hiding. Targeting
at the problem, in this paper, we propose a novel deep watermarking scheme with
Inverse Gradient Attention (IGA), combing the ideas of adversarial learning and
attention mechanism to endow different importance to different pixels. With the
proposed method, the model is able to spotlight pixels with more robustness for
embedding data. Besides, from an orthogonal point of view, in order to increase
the model embedding capacity, we propose a complementary message coding module.
Empirically, extensive experiments show that the proposed model outperforms the
state-of-the-art methods on two prevalent datasets under multiple settings.
</p>
<a href="http://arxiv.org/abs/2011.10850" target="_blank">arXiv:2011.10850</a> [<a href="http://arxiv.org/pdf/2011.10850" target="_blank">pdf</a>]

<h2>REPAINT: Knowledge Transfer in Deep Reinforcement Learning. (arXiv:2011.11827v2 [cs.LG] UPDATED)</h2>
<h3>Yunzhe Tao, Sahika Genc, Jonathan Chung, Tao Sun, Sunil Mallya</h3>
<p>Accelerating learning processes for complex tasks by leveraging previously
learned tasks has been one of the most challenging problems in reinforcement
learning, especially when the similarity between source and target tasks is
low. This work proposes REPresentation And INstance Transfer (REPAINT)
algorithm for knowledge transfer in deep reinforcement learning. REPAINT not
only transfers the representation of a pre-trained teacher policy in the
on-policy learning, but also uses an advantage-based experience selection
approach to transfer useful samples collected following the teacher policy in
the off-policy learning. Our experimental results on several benchmark tasks
show that REPAINT significantly reduces the total training time in generic
cases of task similarity. In particular, when the source tasks are dissimilar
to, or sub-tasks of, the target tasks, REPAINT outperforms other baselines in
both training-time reduction and asymptotic performance of return scores.
</p>
<a href="http://arxiv.org/abs/2011.11827" target="_blank">arXiv:2011.11827</a> [<a href="http://arxiv.org/pdf/2011.11827" target="_blank">pdf</a>]

<h2>World Model as a Graph: Learning Latent Landmarks for Planning. (arXiv:2011.12491v2 [cs.AI] UPDATED)</h2>
<h3>Lunjun Zhang, Ge Yang, Bradly C. Stadie</h3>
<p>Planning - the ability to analyze the structure of a problem in the large and
decompose it into interrelated subproblems - is a hallmark of human
intelligence. While deep reinforcement learning (RL) has shown great promise
for solving relatively straightforward control tasks, it remains an open
problem how to best incorporate planning into existing deep RL paradigms to
handle increasingly complex environments. One prominent framework, Model-Based
RL, learns a world model and plans using step-by-step virtual rollouts. This
type of world model quickly diverges from reality when the planning horizon
increases, thus struggling at long-horizon planning. How can we learn world
models that endow agents with the ability to do temporally extended reasoning?
In this work, we propose to learn graph-structured world models composed of
sparse, multi-step transitions. We devise a novel algorithm to learn latent
landmarks that are scattered (in terms of reachability) across the goal space
as the nodes on the graph. In this same graph, the edges are the reachability
estimates distilled from Q-functions. On a variety of high-dimensional
continuous control tasks ranging from robotic manipulation to navigation, we
demonstrate that our method, named L3P, significantly outperforms prior work,
and is oftentimes the only method capable of leveraging both the robustness of
model-free RL and generalization of graph-search algorithms. We believe our
work is an important step towards scalable planning in reinforcement learning.
</p>
<a href="http://arxiv.org/abs/2011.12491" target="_blank">arXiv:2011.12491</a> [<a href="http://arxiv.org/pdf/2011.12491" target="_blank">pdf</a>]

<h2>Scale-covariant and scale-invariant Gaussian derivative networks. (arXiv:2011.14759v6 [cs.CV] UPDATED)</h2>
<h3>Tony Lindeberg</h3>
<p>This paper presents a hybrid approach between scale-space theory and deep
learning, where a deep learning architecture is constructed by coupling
parameterized scale-space operations in cascade. By sharing the learnt
parameters between multiple scale channels, and by using the transformation
properties of the scale-space primitives under scaling transformations, the
resulting network becomes provably scale covariant. By in addition performing
max pooling over the multiple scale channels, a resulting network architecture
for image classification also becomes provably scale invariant. We investigate
the performance of such networks on the MNISTLargeScale dataset, which contains
rescaled images from original MNIST over a factor of 4 concerning training data
and over a factor of 16 concerning testing data. It is demonstrated that the
resulting approach allows for scale generalization, enabling good performance
for classifying patterns at scales not present in the training data.
</p>
<a href="http://arxiv.org/abs/2011.14759" target="_blank">arXiv:2011.14759</a> [<a href="http://arxiv.org/pdf/2011.14759" target="_blank">pdf</a>]

<h2>Globally Optimal Relative Pose Estimation with Gravity Prior. (arXiv:2012.00458v2 [cs.CV] UPDATED)</h2>
<h3>Yaqing Ding, Daniel Barath, Jian Yang, Hui Kong, Zuzana Kukelova</h3>
<p>Smartphones, tablets and camera systems used, e.g., in cars and UAVs, are
typically equipped with IMUs (inertial measurement units) that can measure the
gravity vector accurately. Using this additional information, the $y$-axes of
the cameras can be aligned, reducing their relative orientation to a single
degree-of-freedom. With this assumption, we propose a novel globally optimal
solver, minimizing the algebraic error in the least-squares sense, to estimate
the relative pose in the over-determined case. Based on the epipolar
constraint, we convert the optimization problem into solving two polynomials
with only two unknowns. Also, a fast solver is proposed using the first-order
approximation of the rotation. The proposed solvers are compared with the
state-of-the-art ones on four real-world datasets with approx. 50000 image
pairs in total. Moreover, we collected a dataset, by a smartphone, consisting
of 10933 image pairs, gravity directions, and ground truth 3D reconstructions.
</p>
<a href="http://arxiv.org/abs/2012.00458" target="_blank">arXiv:2012.00458</a> [<a href="http://arxiv.org/pdf/2012.00458" target="_blank">pdf</a>]

<h2>Camera-aware Proxies for Unsupervised Person Re-Identification. (arXiv:2012.10674v2 [cs.CV] UPDATED)</h2>
<h3>Menglin Wang, Baisheng Lai, Jianqiang Huang, Xiaojin Gong, Xian-Sheng Hua</h3>
<p>This paper tackles the purely unsupervised person re-identification (Re-ID)
problem that requires no annotations. Some previous methods adopt clustering
techniques to generate pseudo labels and use the produced labels to train Re-ID
models progressively. These methods are relatively simple but effective.
However, most clustering-based methods take each cluster as a pseudo identity
class, neglecting the large intra-ID variance caused mainly by the change of
camera views. To address this issue, we propose to split each single cluster
into multiple proxies and each proxy represents the instances coming from the
same camera. These camera-aware proxies enable us to deal with large intra-ID
variance and generate more reliable pseudo labels for learning. Based on the
camera-aware proxies, we design both intra- and inter-camera contrastive
learning components for our Re-ID model to effectively learn the ID
discrimination ability within and across cameras. Meanwhile, a proxy-balanced
sampling strategy is also designed, which facilitates our learning further.
Extensive experiments on three large-scale Re-ID datasets show that our
proposed approach outperforms most unsupervised methods by a significant
margin. Especially, on the challenging MSMT17 dataset, we gain $14.3\%$ Rank-1
and $10.2\%$ mAP improvements when compared to the second place. Code is
available at: \texttt{https://github.com/Terminator8758/CAP-master}.
</p>
<a href="http://arxiv.org/abs/2012.10674" target="_blank">arXiv:2012.10674</a> [<a href="http://arxiv.org/pdf/2012.10674" target="_blank">pdf</a>]

<h2>Voxel R-CNN: Towards High Performance Voxel-based 3D Object Detection. (arXiv:2012.15712v2 [cs.CV] UPDATED)</h2>
<h3>Jiajun Deng, Shaoshuai Shi, Peiwei Li, Wengang Zhou, Yanyong Zhang, Houqiang Li</h3>
<p>Recent advances on 3D object detection heavily rely on how the 3D data are
represented, \emph{i.e.}, voxel-based or point-based representation. Many
existing high performance 3D detectors are point-based because this structure
can better retain precise point positions. Nevertheless, point-level features
lead to high computation overheads due to unordered storage. In contrast, the
voxel-based structure is better suited for feature extraction but often yields
lower accuracy because the input data are divided into grids. In this paper, we
take a slightly different viewpoint -- we find that precise positioning of raw
points is not essential for high performance 3D object detection and that the
coarse voxel granularity can also offer sufficient detection accuracy. Bearing
this view in mind, we devise a simple but effective voxel-based framework,
named Voxel R-CNN. By taking full advantage of voxel features in a two stage
approach, our method achieves comparable detection accuracy with
state-of-the-art point-based models, but at a fraction of the computation cost.
Voxel R-CNN consists of a 3D backbone network, a 2D bird-eye-view (BEV) Region
Proposal Network and a detect head. A voxel RoI pooling is devised to extract
RoI features directly from voxel features for further refinement. Extensive
experiments are conducted on the widely used KITTI Dataset and the more recent
Waymo Open Dataset. Our results show that compared to existing voxel-based
methods, Voxel R-CNN delivers a higher detection accuracy while maintaining a
real-time frame processing rate, \emph{i.e}., at a speed of 25 FPS on an NVIDIA
RTX 2080 Ti GPU. The code is available at
\url{https://github.com/djiajunustc/Voxel-R-CNN}.
</p>
<a href="http://arxiv.org/abs/2012.15712" target="_blank">arXiv:2012.15712</a> [<a href="http://arxiv.org/pdf/2012.15712" target="_blank">pdf</a>]

<h2>PointCutMix: Regularization Strategy for Point Cloud Classification. (arXiv:2101.01461v2 [cs.CV] UPDATED)</h2>
<h3>Jinlai Zhang, Lyujie Chen, Bo Ouyang, Binbin Liu, Jihong Zhu, Yujing Chen, Yanmei Meng, Danfeng Wu</h3>
<p>As 3D point cloud analysis has received increasing attention, the
insufficient scale of point cloud datasets and the weak generalization ability
of networks become prominent. In this paper, we propose a simple and effective
augmentation method for the point cloud data, named PointCutMix, to alleviate
those problems. It finds the optimal assignment between two point clouds and
generates new training data by replacing the points in one sample with their
optimal assigned pairs. Two replacement strategies are proposed to adapt to the
accuracy or robustness requirement for different tasks, one of which is to
randomly select all replacing points while the other one is to select k nearest
neighbors of a single random point. Both strategies consistently and
significantly improve the performance of various models on point cloud
classification problems. By introducing the saliency maps to guide the
selection of replacing points, the performance further improves. Moreover,
PointCutMix is validated to enhance the model robustness against the point
attack. It is worth noting that when using as a defense method, our method
outperforms the state-of-the-art defense algorithms. The code is available
at:https://github.com/cuge1995/PointCutMix
</p>
<a href="http://arxiv.org/abs/2101.01461" target="_blank">arXiv:2101.01461</a> [<a href="http://arxiv.org/pdf/2101.01461" target="_blank">pdf</a>]

<h2>An Integrated Attribute Guided Dense Attention Model for Fine-Grained Generalized Zero-Shot Learning. (arXiv:2101.02141v2 [cs.CV] UPDATED)</h2>
<h3>Tasfia Shermin, Shyh Wei Teng, Ferdous Sohel, Manzur Murshed, Guojun Lu</h3>
<p>Embedding learning (EL) and feature synthesizing (FS) are two of the popular
categories of fine-grained GZSL methods. The global feature exploring EL or FS
methods do not explore fine distinction as they ignore local details. And, the
local detail exploring EL or FS methods either neglect direct attribute
guidance or global information. Consequently, neither method performs well. In
this paper, we propose to explore global and direct attribute-supervised local
visual features for both EL and FS categories in an integrated manner for
fine-grained GZSL. The proposed integrated network has an EL sub-network and a
FS sub-network. Consequently, the proposed integrated network can be tested in
two ways. We propose a novel two-step dense attention mechanism to discover
attribute-guided local visual features. We introduce new mutual learning
between the sub-networks to exploit mutually beneficial information for
optimization. Moreover, to reduce bias towards the source domain during
testing, we propose to compute source-target class similarity based on mutual
information and transfer-learn the target classes. We demonstrate that our
proposed method outperforms contemporary methods on benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2101.02141" target="_blank">arXiv:2101.02141</a> [<a href="http://arxiv.org/pdf/2101.02141" target="_blank">pdf</a>]

<h2>Regret Analysis of Distributed Gaussian Process Estimation and Coverage. (arXiv:2101.04306v2 [cs.RO] UPDATED)</h2>
<h3>Lai Wei, Andrew McDonald, Vaibhav Srivastava</h3>
<p>We study the problem of distributed multi-robot coverage over an unknown,
nonuniform sensory field. Modeling the sensory field as a realization of a
Gaussian Process and using Bayesian techniques, we devise a policy which aims
to balance the tradeoff between learning the sensory function and covering the
environment. We propose an adaptive coverage algorithm called Deterministic
Sequencing of Learning and Coverage (DSLC) that schedules learning and coverage
epochs such that its emphasis gradually shifts from exploration to exploitation
while never fully ceasing to learn. Using a novel definition of coverage regret
which characterizes overall coverage performance of a multi-robot team over a
time horizon $T$, we analyze DSLC to provide an upper bound on expected
cumulative coverage regret. Finally, we illustrate the empirical performance of
the algorithm through simulations of the coverage task over an unknown
distribution of wildfires.
</p>
<a href="http://arxiv.org/abs/2101.04306" target="_blank">arXiv:2101.04306</a> [<a href="http://arxiv.org/pdf/2101.04306" target="_blank">pdf</a>]

<h2>Faster Convergence in Deep-Predictive-Coding Networks to Learn Deeper Representations. (arXiv:2101.06848v2 [cs.AI] UPDATED)</h2>
<h3>Isaac J. Sledge, Jose C. Principe</h3>
<p>Deep-predictive-coding networks (DPCNs) are hierarchical, generative models
that rely on feed-forward and feed-back connections to modulate latent feature
representations of stimuli in a dynamic and context-sensitive manner. A crucial
element of DPCNs is a forward-backward inference procedure to uncover sparse
states of a dynamic model, which are used for invariant feature extraction.
However, this inference and the corresponding backwards network parameter
updating are major computational bottlenecks. They severely limit the network
depths that can be reasonably implemented and easily trained. We therefore
propose an optimization strategy, with better empirical and theoretical
convergence, based on accelerated proximal gradients.

We demonstrate that the ability to construct deeper DPCNs leads to receptive
fields that capture well the entire notions of objects on which the networks
are trained. This improves the feature representations. It yields completely
unsupervised classifiers that surpass convolutional and convolutional-recurrent
autoencoders and are on par with convolutional networks trained in a supervised
manner. This is despite the DPCNs having orders of magnitude fewer parameters.
</p>
<a href="http://arxiv.org/abs/2101.06848" target="_blank">arXiv:2101.06848</a> [<a href="http://arxiv.org/pdf/2101.06848" target="_blank">pdf</a>]

<h2>Identity-aware Graph Neural Networks. (arXiv:2101.10320v2 [cs.LG] UPDATED)</h2>
<h3>Jiaxuan You, Jonathan Gomes-Selman, Rex Ying, Jure Leskovec</h3>
<p>Message passing Graph Neural Networks (GNNs) provide a powerful modeling
framework for relational data. However, the expressive power of existing GNNs
is upper-bounded by the 1-Weisfeiler-Lehman (1-WL) graph isomorphism test,
which means GNNs that are not able to predict node clustering coefficients and
shortest path distances, and cannot differentiate between different d-regular
graphs. Here we develop a class of message passing GNNs, named Identity-aware
Graph Neural Networks (ID-GNNs), with greater expressive power than the 1-WL
test. ID-GNN offers a minimal but powerful solution to limitations of existing
GNNs. ID-GNN extends existing GNN architectures by inductively considering
nodes' identities during message passing. To embed a given node, ID-GNN first
extracts the ego network centered at the node, then conducts rounds of
heterogeneous message passing, where different sets of parameters are applied
to the center node than to other surrounding nodes in the ego network. We
further propose a simplified but faster version of ID-GNN that injects node
identity information as augmented node features. Altogether, both versions of
ID-GNN represent general extensions of message passing GNNs, where experiments
show that transforming existing GNNs to ID-GNNs yields on average 40% accuracy
improvement on challenging node, edge, and graph property prediction tasks; 3%
accuracy improvement on node and graph classification benchmarks; and 15% ROC
AUC improvement on real-world link prediction tasks. Additionally, ID-GNNs
demonstrate improved or comparable performance over other task-specific graph
networks.
</p>
<a href="http://arxiv.org/abs/2101.10320" target="_blank">arXiv:2101.10320</a> [<a href="http://arxiv.org/pdf/2101.10320" target="_blank">pdf</a>]

<h2>Spatial-Channel Transformer Network for Trajectory Prediction on the Traffic Scenes. (arXiv:2101.11472v2 [cs.CV] UPDATED)</h2>
<h3>Jingwen Zhao, Xuanpeng Li, Qifan Xue, Weigong Zhang</h3>
<p>Predicting motion of surrounding agents is critical to real-world
applications of tactical path planning for autonomous driving. Due to the
complex temporal dependencies and social interactions of agents, on-line
trajectory prediction is a challenging task. With the development of attention
mechanism in recent years, transformer model has been applied in natural
language sequence processing first and then image processing. In this paper, we
present a Spatial-Channel Transformer Network for trajectory prediction with
attention functions. Instead of RNN models, we employ transformer model to
capture the spatial-temporal features of agents. A channel-wise module is
inserted to measure the social interaction between agents. We find that the
Spatial-Channel Transformer Network achieves promising results on real-world
trajectory prediction datasets on the traffic scenes.
</p>
<a href="http://arxiv.org/abs/2101.11472" target="_blank">arXiv:2101.11472</a> [<a href="http://arxiv.org/pdf/2101.11472" target="_blank">pdf</a>]

<h2>Fusion Moves for Graph Matching. (arXiv:2101.12085v2 [cs.CV] UPDATED)</h2>
<h3>Lisa Hutschenreiter, Stefan Haller, Lorenz Feineis, Carsten Rother, Dagmar Kainm&#xfc;ller, Bogdan Savchynskyy</h3>
<p>We contribute to approximate algorithms for the quadratic assignment problem
also known as graph matching. Inspired by the success of the fusion moves
technique developed for multilabel discrete Markov random fields, we
investigate its applicability to graph matching. In particular, we show how it
can be efficiently combined with the dedicated state-of-the-art Lagrange dual
methods that have recently shown superior results in computer vision and
bio-imaging applications. As our empirical evaluation on a wide variety of
graph matching datasets suggests, fusion moves notably improve performance of
these methods in terms of speed and quality of the obtained solutions. Hence,
this combination results in a state-of-the-art solver for graph matching.
</p>
<a href="http://arxiv.org/abs/2101.12085" target="_blank">arXiv:2101.12085</a> [<a href="http://arxiv.org/pdf/2101.12085" target="_blank">pdf</a>]

<h2>Policy Mirror Descent for Reinforcement Learning: Linear Convergence, New Sampling Complexity, and Generalized Problem Classes. (arXiv:2102.00135v3 [cs.LG] UPDATED)</h2>
<h3>Guanghui Lan</h3>
<p>We present new policy mirror descent (PMD) methods for solving reinforcement
learning (RL) problems with either strongly convex or general convex
regularizers. By exploring the structural properties of these overall seemly
highly nonconvex problems we show that the PMD methods exhibit fast linear rate
of convergence to the global optimality. We develop stochastic counterparts of
these methods, and establish an ${\cal O}(1/\epsilon)$ (resp., ${\cal
O}(1/\epsilon^2)$) sampling complexity for solving these RL problems with
strongly (resp., general) convex regularizers using different sampling schemes,
where $\epsilon$ denote the target accuracy. We further show that the
complexity for computing the gradients of these regularizers, if necessary, can
be bounded by ${\cal O}\{(\log_\gamma \epsilon) [(1-\gamma)L/\mu]^{1/2}\log
(1/\epsilon)\}$ (resp., ${\cal O} \{(\log_\gamma \epsilon )
(L/\epsilon)^{1/2}\}$)for problems with strongly (resp., general) convex
regularizers. Here $\gamma$ denotes the discounting factor. To the best of our
knowledge, these complexity bounds, along with our algorithmic developments,
appear to be new in both optimization and RL literature. The introduction of
these convex regularizers also greatly expands the flexibility and
applicability of RL models.
</p>
<a href="http://arxiv.org/abs/2102.00135" target="_blank">arXiv:2102.00135</a> [<a href="http://arxiv.org/pdf/2102.00135" target="_blank">pdf</a>]

<h2>Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms. (arXiv:2102.00815v2 [cs.LG] UPDATED)</h2>
<h3>Chi Jin, Qinghua Liu, Sobhan Miryoosefi</h3>
<p>Finding the minimal structural assumptions that empower sample-efficient
learning is one of the most important research directions in Reinforcement
Learning (RL). This paper advances our understanding of this fundamental
question by introducing a new complexity measure -- Bellman Eluder (BE)
dimension. We show that the family of RL problems of low BE dimension is
remarkably rich, which subsumes a vast majority of existing tractable RL
problems including but not limited to tabular MDPs, linear MDPs, reactive
POMDPs, low Bellman rank problems as well as low Eluder dimension problems.
This paper further designs a new optimization-based algorithm -- GOLF, and
reanalyzes a hypothesis elimination-based algorithm -- OLIVE (proposed in Jiang
et al. (2017)). We prove that both algorithms learn the near-optimal policies
of low BE dimension problems in a number of samples that is polynomial in all
relevant parameters, but independent of the size of state-action space. Our
regret and sample complexity results match or improve the best existing results
for several well-known subclasses of low BE dimension problems.
</p>
<a href="http://arxiv.org/abs/2102.00815" target="_blank">arXiv:2102.00815</a> [<a href="http://arxiv.org/pdf/2102.00815" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Decision-Making and Control in Power Systems: Tutorial, Review, and Vision. (arXiv:2102.01168v3 [cs.LG] UPDATED)</h2>
<h3>Xin Chen, Guannan Qu, Yujie Tang, Steven Low, Na Li</h3>
<p>With large-scale integration of renewable generation and ubiquitous
distributed energy resources (DERs), modern power systems confront a series of
new challenges in operation and control, such as growing complexity, increasing
uncertainty, and aggravating volatility. While the upside is that more and more
data are available owing to the widely-deployed smart meters, smart sensors,
and upgraded communication networks. As a result, data-driven control
techniques, especially reinforcement learning (RL), have attracted surging
attention in recent years. In this paper, we focus on RL and aim to provide a
tutorial on various RL techniques and how they can be applied to the
decision-making and control in power systems. In particular, we select three
key applications, including frequency regulation, voltage control, and energy
management, for illustration, and present the typical ways to model and tackle
them with RL methods. We conclude by emphasizing two critical issues in the
application of RL, i.e., safety and scalability. Several potential future
directions are discussed as well.
</p>
<a href="http://arxiv.org/abs/2102.01168" target="_blank">arXiv:2102.01168</a> [<a href="http://arxiv.org/pdf/2102.01168" target="_blank">pdf</a>]

<h2>Learning Diverse-Structured Networks for Adversarial Robustness. (arXiv:2102.01886v2 [cs.LG] UPDATED)</h2>
<h3>Xuefeng Du, Jingfeng Zhang, Bo Han, Tongliang Liu, Yu Rong, Gang Niu, Junzhou Huang, Masashi Sugiyama</h3>
<p>In adversarial training (AT), the main focus has been the objective and
optimizer while the model has been less studied, so that the models being used
are still those classic ones in standard training (ST). Classic network
architectures (NAs) are generally worse than searched NAs in ST, which should
be the same in AT. In this paper, we argue that NA and AT cannot be handled
independently, since given a dataset, the optimal NA in ST would be no longer
optimal in AT. That being said, AT is time-consuming itself; if we directly
search NAs in AT over large search spaces, the computation will be practically
infeasible. Thus, we propose a diverse-structured network (DS-Net), to
significantly reduce the size of the search space: instead of low-level
operations, we only consider predefined atomic blocks, where an atomic block is
a time-tested building block like the residual block. There are only a few
atomic blocks and thus we can weight all atomic blocks rather than find the
best one in a searched block of DS-Net, which is an essential trade-off between
exploring diverse structures and exploiting the best structures. Empirical
results demonstrate the advantages of DS-Net, i.e., weighting the atomic
blocks.
</p>
<a href="http://arxiv.org/abs/2102.01886" target="_blank">arXiv:2102.01886</a> [<a href="http://arxiv.org/pdf/2102.01886" target="_blank">pdf</a>]

<h2>Real-Time Optimal Trajectory Planning for Autonomous Vehicles and Lap Time Simulation Using Machine Learning. (arXiv:2102.02315v2 [cs.RO] UPDATED)</h2>
<h3>Sam Garlick, Andrew Bradley</h3>
<p>The widespread development of driverless vehicles has led to the formation of
autonomous racing competitions, where the high speeds and fierce rivalry in
motorsport provide a testbed to accelerate technology development. A particular
challenge for an autonomous vehicle is that of identifying a target trajectory
- or in the case of a racing car, the ideal racing line. Many existing
approaches to identifying the racing line are either not the time-optimal
solutions, or have solution times which are computationally expensive, thus
rendering them unsuitable for real-time application using on-board processing
hardware. This paper describes a machine learning approach to generating an
accurate prediction of the racing line in real-time on desktop processing
hardware. The proposed algorithm is a dense feed-forward neural network,
trained using a dataset comprising racing lines for a large number of circuits
calculated via a traditional optimal control lap time simulation. The network
is capable of predicting the racing line with a mean absolute error of
+/-0.27m, meaning that the accuracy outperforms a human driver, and is
comparable to other parts of the autonomous vehicle control system. The system
generates predictions within 33ms, making it over 9,000 times faster than
traditional methods of finding the optimal racing line. Results suggest that a
data-driven approach may therefore be favourable for real-time generation of
near-optimal racing lines than traditional computational methods.
</p>
<a href="http://arxiv.org/abs/2102.02315" target="_blank">arXiv:2102.02315</a> [<a href="http://arxiv.org/pdf/2102.02315" target="_blank">pdf</a>]

<h2>A review of motion planning algorithms for intelligent robotics. (arXiv:2102.02376v2 [cs.RO] UPDATED)</h2>
<h3>Chengmin Zhou, Bingding Huang, Pasi Fr&#xe4;nti</h3>
<p>We investigate and analyze principles of typical motion planning algorithms.
These include traditional planning algorithms, supervised learning, optimal
value reinforcement learning, policy gradient reinforcement learning.
Traditional planning algorithms we investigated include graph search
algorithms, sampling-based algorithms, and interpolating curve algorithms.
Supervised learning algorithms include MSVM, LSTM, MCTS and CNN. Optimal value
reinforcement learning algorithms include Q learning, DQN, double DQN, dueling
DQN. Policy gradient algorithms include policy gradient method, actor-critic
algorithm, A3C, A2C, DPG, DDPG, TRPO and PPO. New general criteria are also
introduced to evaluate performance and application of motion planning
algorithms by analytical comparisons. Convergence speed and stability of
optimal value and policy gradient algorithms are specially analyzed. Future
directions are presented analytically according to principles and analytical
comparisons of motion planning algorithms. This paper provides researchers with
a clear and comprehensive understanding about advantages, disadvantages,
relationships, and future of motion planning algorithms in robotics, and paves
ways for better motion planning algorithms.
</p>
<a href="http://arxiv.org/abs/2102.02376" target="_blank">arXiv:2102.02376</a> [<a href="http://arxiv.org/pdf/2102.02376" target="_blank">pdf</a>]

