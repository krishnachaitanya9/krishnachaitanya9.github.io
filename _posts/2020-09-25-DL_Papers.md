---
title: Latest Deep Learning Papers
date: 2021-01-29 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (135 Articles)</h1>
<h2>On Statistical Bias In Active Learning: How and When To Fix It. (arXiv:2101.11665v1 [stat.ML])</h2>
<h3>Sebastian Farquhar, Yarin Gal, Tom Rainforth</h3>
<p>Active learning is a powerful tool when labelling data is expensive, but it
introduces a bias because the training data no longer follows the population
distribution. We formalize this bias and investigate the situations in which it
can be harmful and sometimes even helpful. We further introduce novel
corrective weights to remove bias when doing so is beneficial. Through this,
our work not only provides a useful mechanism that can improve the active
learning approach, but also an explanation of the empirical successes of
various existing approaches which ignore this bias. In particular, we show that
this bias can be actively helpful when training overparameterized models --
like neural networks -- with relatively little data.
</p>
<a href="http://arxiv.org/abs/2101.11665" target="_blank">arXiv:2101.11665</a> [<a href="http://arxiv.org/pdf/2101.11665" target="_blank">pdf</a>]

<h2>HDIB1M -- Handwritten Document Image Binarization 1 Million Dataset. (arXiv:2101.11674v1 [cs.CV])</h2>
<h3>Kaustubh Sadekar, Prajwal Singh, Shanmuganathan Raman</h3>
<p>Handwritten document image binarization is a challenging task due to high
diversity in the content, page style, and condition of the documents. While the
traditional thresholding methods fail to generalize on such challenging
scenarios, deep learning based methods can generalize well however, require a
large training data. Current datasets for handwritten document image
binarization are limited in size and fail to represent several challenging
real-world scenarios. To solve this problem, we propose HDIB1M - a handwritten
document image binarization dataset of 1M images. We also present a novel
method used to generate this dataset. To show the effectiveness of our dataset
we train a deep learning model UNetED on our dataset and evaluate its
performance on other publicly available datasets. The dataset and the code will
be made available to the community.
</p>
<a href="http://arxiv.org/abs/2101.11674" target="_blank">arXiv:2101.11674</a> [<a href="http://arxiv.org/pdf/2101.11674" target="_blank">pdf</a>]

<h2>A Hybrid 2-stage Neural Optimization for Pareto Front Extraction. (arXiv:2101.11684v1 [cs.LG])</h2>
<h3>Gurpreet Singh, Soumyajit Gupta, Matthew Lease, Clint Dawson</h3>
<p>Classification, recommendation, and ranking problems often involve competing
goals with additional constraints (e.g., to satisfy fairness or diversity
criteria). Such optimization problems are quite challenging, often involving
non-convex functions along with considerations of user preferences in balancing
trade-offs. Pareto solutions represent optimal frontiers for jointly optimizing
multiple competing objectives. A major obstacle for frequently used
linear-scalarization strategies is that the resulting optimization problem
might not always converge to a global optimum. Furthermore, such methods only
return one solution point per run. A Pareto solution set is a subset of all
such global optima over multiple runs for different trade-off choices.
Therefore, a Pareto front can only be guaranteed with multiple runs of the
linear-scalarization problem, where all runs converge to their respective
global optima. Consequently, extracting a Pareto front for practical problems
is computationally intractable with substantial computational overheads,
limited scalability, and reduced accuracy. We propose a robust, low cost,
two-stage, hybrid neural Pareto optimization approach that is accurate and
scales (compute space and time) with data dimensions, as well as number of
functions and constraints. The first stage (neural network) efficiently
extracts a weak Pareto front, using Fritz-John conditions as the discriminator,
with no assumptions of convexity on the objectives or constraints. The second
stage (efficient Pareto filter) extracts the strong Pareto optimal subset given
the weak front from stage 1. Fritz-John conditions provide us with theoretical
bounds on approximation error between the true and network extracted weak
Pareto front. Numerical experiments demonstrates the accuracy and efficiency on
a canonical set of benchmark problems and a fairness optimization task from
prior works.
</p>
<a href="http://arxiv.org/abs/2101.11684" target="_blank">arXiv:2101.11684</a> [<a href="http://arxiv.org/pdf/2101.11684" target="_blank">pdf</a>]

<h2>CNN with large memory layers. (arXiv:2101.11685v1 [cs.CV])</h2>
<h3>Rasul Karimov, Victor Lempitsky</h3>
<p>This work is centred around the recently proposed product key memory
structure \cite{large_memory}, implemented for a number of computer vision
applications. The memory structure can be regarded as a simple computation
primitive suitable to be augmented to nearly all neural network architectures.
The memory block allows implementing sparse access to memory with square root
complexity scaling with respect to the memory capacity. The latter scaling is
possible due to the incorporation of Cartesian product space decomposition of
the key space for the nearest neighbour search. We have tested the memory layer
on the classification, image reconstruction and relocalization problems and
found that for some of those, the memory layers can provide significant
speed/accuracy improvement with the high utilization of the key-value elements,
while others require more careful fine-tuning and suffer from dying keys. To
tackle the later problem we have introduced a simple technique of memory
re-initialization which helps us to eliminate unused key-value pairs from the
memory and engage them in training again. We have conducted various experiments
and got improvements in speed and accuracy for classification and PoseNet
relocalization models.

We showed that the re-initialization has a huge impact on a toy example of
randomly labeled data and observed some gains in performance on the image
classification task. We have also demonstrated the generalization property
perseverance of the large memory layers on the relocalization problem, while
observing the spatial correlations between the images and the selected memory
cells.
</p>
<a href="http://arxiv.org/abs/2101.11685" target="_blank">arXiv:2101.11685</a> [<a href="http://arxiv.org/pdf/2101.11685" target="_blank">pdf</a>]

<h2>Hadamard Powers and the Identification of Mixtures of Products. (arXiv:2101.11688v1 [cs.LG])</h2>
<h3>Spencer L. Gordon, Leonard J. Schulman</h3>
<p>The Hadamard Power of a matrix is the matrix consisting of all Hadamard
products of subsets of its rows. We obtain several results concerning when a
Hadamard Power has full column rank. This question in turn is central to the
following problem: given a mixture of $k$ product distributions on a list of
binary random variables $X_1,\ldots,X_n$, can the probability model be
identified from the joint statistics of the $X_i$.
</p>
<a href="http://arxiv.org/abs/2101.11688" target="_blank">arXiv:2101.11688</a> [<a href="http://arxiv.org/pdf/2101.11688" target="_blank">pdf</a>]

<h2>Dopamine: Differentially Private Secure Federated Learning on Medical Data. (arXiv:2101.11693v1 [cs.LG])</h2>
<h3>Mohammad Malekzadeh, Burak Hasircioglu, Nitish Mital, Kunal Katarya, Mehmet Emre Ozfatura, Deniz G&#xfc;nd&#xfc;z</h3>
<p>While rich medical datasets are hosted in hospitals distributed across
countries, concerns on patients' privacy is a barrier against utilizing such
data to train deep neural networks (DNNs) for medical diagnostics. We propose
Dopamine, a system to train DNNs on distributed medical data, which employs
federated learning (FL) with differentially-private stochastic gradient descent
(DPSGD), and, in combination with secure multi-party aggregation, can establish
a better privacy-utility trade-off than the existing approaches. Results on a
diabetic retinopathy (DR) task show that Dopamine provides a privacy guarantee
close to the centralized training counterpart, while achieving a better
classification accuracy than FL with parallel differential privacy where DPSGD
is applied without coordination. Code is available at
https://github.com/ipc-lab/private-ml-for-health.
</p>
<a href="http://arxiv.org/abs/2101.11693" target="_blank">arXiv:2101.11693</a> [<a href="http://arxiv.org/pdf/2101.11693" target="_blank">pdf</a>]

<h2>Multi-Modal Aesthetic Assessment for MObile Gaming Image. (arXiv:2101.11700v1 [cs.CV])</h2>
<h3>Zhenyu Lei, Yejing Xie, Suiyi Ling, Andreas Pastor, Junle Wang, Patrick Le Callet</h3>
<p>With the proliferation of various gaming technology, services, game styles,
and platforms, multi-dimensional aesthetic assessment of the gaming contents is
becoming more and more important for the gaming industry. Depending on the
diverse needs of diversified game players, game designers, graphical
developers, etc. in particular conditions, multi-modal aesthetic assessment is
required to consider different aesthetic dimensions/perspectives. Since there
are different underlying relationships between different aesthetic dimensions,
e.g., between the `Colorfulness' and `Color Harmony', it could be advantageous
to leverage effective information attached in multiple relevant dimensions. To
this end, we solve this problem via multi-task learning. Our inclination is to
seek and learn the correlations between different aesthetic relevant dimensions
to further boost the generalization performance in predicting all the aesthetic
dimensions. Therefore, the `bottleneck' of obtaining good predictions with
limited labeled data for one individual dimension could be unplugged by
harnessing complementary sources of other dimensions, i.e., augment the
training data indirectly by sharing training information across dimensions.
According to experimental results, the proposed model outperforms
state-of-the-art aesthetic metrics significantly in predicting four gaming
aesthetic dimensions.
</p>
<a href="http://arxiv.org/abs/2101.11700" target="_blank">arXiv:2101.11700</a> [<a href="http://arxiv.org/pdf/2101.11700" target="_blank">pdf</a>]

<h2>Better sampling in explanation methods can prevent dieselgate-like deception. (arXiv:2101.11702v1 [cs.LG])</h2>
<h3>Domen Vre&#x161;, Marko Robnik &#x160;ikonja</h3>
<p>Machine learning models are used in many sensitive areas where besides
predictive accuracy their comprehensibility is also important. Interpretability
of prediction models is necessary to determine their biases and causes of
errors, and is a necessary prerequisite for users' confidence. For complex
state-of-the-art black-box models post-hoc model-independent explanation
techniques are an established solution. Popular and effective techniques, such
as IME, LIME, and SHAP, use perturbation of instance features to explain
individual predictions. Recently, Slack et al. (2020) put their robustness into
question by showing that their outcomes can be manipulated due to poor
perturbation sampling employed. This weakness would allow dieselgate type
cheating of owners of sensitive models who could deceive inspection and hide
potentially unethical or illegal biases existing in their predictive models.
This could undermine public trust in machine learning models and give rise to
legal restrictions on their use.

We show that better sampling in these explanation methods prevents malicious
manipulations. The proposed sampling uses data generators that learn the
training set distribution and generate new perturbation instances much more
similar to the training set. We show that the improved sampling increases the
robustness of the LIME and SHAP, while previously untested method IME is
already the most robust of all.
</p>
<a href="http://arxiv.org/abs/2101.11702" target="_blank">arXiv:2101.11702</a> [<a href="http://arxiv.org/pdf/2101.11702" target="_blank">pdf</a>]

<h2>A Unified Framework for Feature Extraction based on Contrastive Learning. (arXiv:2101.11703v1 [cs.LG])</h2>
<h3>Hongjie Zhang</h3>
<p>Feature extraction is an efficient approach for alleviating the curse of
dimensionality in high-dimensional data. With the development of contrastive
learning in the field of self-supervised learning, we propose a unified
framework for feature extraction based on contrastive learning from a new
perspective, which is suitable for both unsupervised and supervised feature
extraction. In this framework, we first construct a contrastive learning graph
based on graph embedding (GE), which proposes a new way to define positive and
negative pairs. Then, we solve the projection matrix by minimizing the
contrastive loss function. In this framework, we can consider not only similar
samples but also dissimilar samples on the basis of unsupervised GE, so as to
narrow the gap with supervised feature extraction. In order to verify the
effectiveness of our proposed framework for unsupervised and supervised feature
extraction, we improved the unsupervised GE method LPP with local preserving,
the supervised GE method LDA without local preserving, and the supervised GE
method LFDA with local preserving, and proposed CL-LPP, CL-LDA, and CL-LFDA,
respectively. Finally, we performed numerical experiments on five real
datasets.
</p>
<a href="http://arxiv.org/abs/2101.11703" target="_blank">arXiv:2101.11703</a> [<a href="http://arxiv.org/pdf/2101.11703" target="_blank">pdf</a>]

<h2>A Case Study of Deep Learning Based Multi-Modal Methods for Predicting the Age-Suitability Rating of Movie Trailers. (arXiv:2101.11704v1 [cs.LG])</h2>
<h3>Mahsa Shafaei, Christos Smailis, Ioannis A. Kakadiaris, Thamar Solorio</h3>
<p>In this work, we explore different approaches to combine modalities for the
problem of automated age-suitability rating of movie trailers. First, we
introduce a new dataset containing videos of movie trailers in English
downloaded from IMDB and YouTube, along with their corresponding
age-suitability rating labels. Secondly, we propose a multi-modal deep learning
pipeline addressing the movie trailer age suitability rating problem. This is
the first attempt to combine video, audio, and speech information for this
problem, and our experimental results show that multi-modal approaches
significantly outperform the best mono and bimodal models in this task.
</p>
<a href="http://arxiv.org/abs/2101.11704" target="_blank">arXiv:2101.11704</a> [<a href="http://arxiv.org/pdf/2101.11704" target="_blank">pdf</a>]

<h2>Damage detection in operational wind turbine blades using a new approach based on machine learning. (arXiv:2101.11711v1 [cs.LG])</h2>
<h3>Kartik Chandrasekhar, Nevena Stevanovic, Elizabeth J. Cross, Nikolaos Dervilis, Keith Worden</h3>
<p>The application of reliable structural health monitoring (SHM) technologies
to operational wind turbine blades is a challenging task, due to the uncertain
nature of the environments they operate in. In this paper, a novel SHM
methodology, which uses Gaussian Processes (GPs) is proposed. The methodology
takes advantage of the fact that the blades on a turbine are nominally
identical in structural properties and encounter the same environmental and
operational variables (EOVs). The properties of interest are the first edgewise
frequencies of the blades. The GPs are used to predict the edge frequencies of
one blade given that of another, after these relationships between the pairs of
blades have been learned when the blades are in a healthy state. In using this
approach, the proposed SHM methodology is able to identify when the blades
start behaving differently from one another over time. To validate the concept,
the proposed SHM system is applied to real onshore wind turbine blade data,
where some form of damage was known to have taken place. X-bar control chart
analysis of the residual errors between the GP predictions and actual
frequencies show that the system successfully identified early onset of damage
as early as six months before it was identified and remedied.
</p>
<a href="http://arxiv.org/abs/2101.11711" target="_blank">arXiv:2101.11711</a> [<a href="http://arxiv.org/pdf/2101.11711" target="_blank">pdf</a>]

<h2>TT-Rec: Tensor Train Compression for Deep Learning Recommendation Models. (arXiv:2101.11714v1 [cs.LG])</h2>
<h3>Chunxing Yin, Bilge Acun, Xing Liu, Carole-Jean Wu</h3>
<p>The memory capacity of embedding tables in deep learning recommendation
models (DLRMs) is increasing dramatically from tens of GBs to TBs across the
industry. Given the fast growth in DLRMs, novel solutions are urgently needed,
in order to enable fast and efficient DLRM innovations. At the same time, this
must be done without having to exponentially increase infrastructure capacity
demands. In this paper, we demonstrate the promising potential of Tensor Train
decomposition for DLRMs (TT-Rec), an important yet under-investigated context.
We design and implement optimized kernels (TT-EmbeddingBag) to evaluate the
proposed TT-Rec design. TT-EmbeddingBag is 3 times faster than the SOTA TT
implementation. The performance of TT-Rec is further optimized with the batched
matrix multiplication and caching strategies for embedding vector lookup
operations. In addition, we present mathematically and empirically the effect
of weight initialization distribution on DLRM accuracy and propose to
initialize the tensor cores of TT-Rec following the sampled Gaussian
distribution. We evaluate TT-Rec across three important design space dimensions
-- memory capacity, accuracy, and timing performance -- by training MLPerf-DLRM
with Criteo's Kaggle and Terabyte data sets. TT-Rec achieves 117 times and 112
times model size compression, for Kaggle and Terabyte, respectively. This
impressive model size reduction can come with no accuracy nor training time
overhead as compared to the uncompressed baseline.
</p>
<a href="http://arxiv.org/abs/2101.11714" target="_blank">arXiv:2101.11714</a> [<a href="http://arxiv.org/pdf/2101.11714" target="_blank">pdf</a>]

<h2>Failure Prediction in Production Line Based on Federated Learning: An Empirical Study. (arXiv:2101.11715v1 [cs.LG])</h2>
<h3>Ning Ge, Guanghao Li, Li Zhang, Yi Liu Yi Liu</h3>
<p>Data protection across organizations is limiting the application of
centralized learning (CL) techniques. Federated learning (FL) enables multiple
participants to build a learning model without sharing data. Nevertheless,
there are very few research works on FL in intelligent manufacturing. This
paper presents the results of an empirical study on failure prediction in the
production line based on FL. This paper (1) designs Federated Support Vector
Machine (FedSVM) and Federated Random Forest (FedRF) algorithms for the
horizontal FL and vertical FL scenarios, respectively; (2) proposes an
experiment process for evaluating the effectiveness between the FL and CL
algorithms; (3) finds that the performance of FL and CL are not significantly
different on the global testing data, on the random partial testing data, and
on the estimated unknown Bosch data, respectively. The fact that the testing
data is heterogeneous enhances our findings. Our study reveals that FL can
replace CL for failure prediction.
</p>
<a href="http://arxiv.org/abs/2101.11715" target="_blank">arXiv:2101.11715</a> [<a href="http://arxiv.org/pdf/2101.11715" target="_blank">pdf</a>]

<h2>Disambiguating Symbolic Expressions in Informal Documents. (arXiv:2101.11716v1 [cs.LG])</h2>
<h3>Dennis M&#xfc;ller, Cezary Kaliszyk</h3>
<p>We propose the task of disambiguating symbolic expressions in informal STEM
documents in the form of LaTeX files - that is, determining their precise
semantics and abstract syntax tree - as a neural machine translation task. We
discuss the distinct challenges involved and present a dataset with roughly
33,000 entries. We evaluated several baseline models on this dataset, which
failed to yield even syntactically valid LaTeX before overfitting.
Consequently, we describe a methodology using a transformer language model
pre-trained on sources obtained from arxiv.org, which yields promising results
despite the small size of the dataset. We evaluate our model using a plurality
of dedicated techniques, taking the syntax and semantics of symbolic
expressions into account.
</p>
<a href="http://arxiv.org/abs/2101.11716" target="_blank">arXiv:2101.11716</a> [<a href="http://arxiv.org/pdf/2101.11716" target="_blank">pdf</a>]

<h2>Overestimation learning with guarantees. (arXiv:2101.11717v1 [cs.LG])</h2>
<h3>Adrien Gauffriau, Fran&#xe7;ois Malgouyres (IMT), M&#xe9;lanie Ducoffe</h3>
<p>We describe a complete method that learns a neural network which is
guaranteed to overestimate a reference function on a given domain. The neural
network can then be used as a surrogate for the reference function. The method
involves two steps. In the first step, we construct an adaptive set of Majoring
Points. In the second step, we optimize a well-chosen neural network to
overestimate the Majoring Points. In order to extend the guarantee on the
Majoring Points to the whole domain, we necessarily have to make an assumption
on the reference function. In this study, we assume that the reference function
is monotonic. We provide experiments on synthetic and real problems. The
experiments show that the density of the Majoring Points concentrate where the
reference function varies. The learned over-estimations are both guaranteed to
overestimate the reference function and are proven empirically to provide good
approximations of it. Experiments on real data show that the method makes it
possible to use the surrogate function in embedded systems for which an
underestimation is critical; when computing the reference function requires too
many resources.
</p>
<a href="http://arxiv.org/abs/2101.11717" target="_blank">arXiv:2101.11717</a> [<a href="http://arxiv.org/pdf/2101.11717" target="_blank">pdf</a>]

<h2>On the mapping between Hopfield networks and Restricted Boltzmann Machines. (arXiv:2101.11744v1 [cs.LG])</h2>
<h3>Matthew Smart, Anton Zilman</h3>
<p>Hopfield networks (HNs) and Restricted Boltzmann Machines (RBMs) are two
important models at the interface of statistical physics, machine learning, and
neuroscience. Recently, there has been interest in the relationship between HNs
and RBMs, due to their similarity under the statistical mechanics formalism. An
exact mapping between HNs and RBMs has been previously noted for the special
case of orthogonal (uncorrelated) encoded patterns. We present here an exact
mapping in the general case of correlated pattern HNs, which are more broadly
applicable to existing datasets. Specifically, we show that any HN with $N$
binary variables and $p&lt;N$ arbitrary binary patterns can be transformed into an
RBM with $N$ binary visible variables and $p$ gaussian hidden variables. We
outline the conditions under which the reverse mapping exists, and conduct
experiments on the MNIST dataset which suggest the mapping provides a useful
initialization to the RBM weights. We discuss extensions, the potential
importance of this correspondence for the training of RBMs, and for
understanding the performance of deep architectures which utilize RBMs.
</p>
<a href="http://arxiv.org/abs/2101.11744" target="_blank">arXiv:2101.11744</a> [<a href="http://arxiv.org/pdf/2101.11744" target="_blank">pdf</a>]

<h2>Assessing the applicability of Deep Learning-based visible-infrared fusion methods for fire imagery. (arXiv:2101.11745v1 [cs.CV])</h2>
<h3>J. F. Cipri&#xe1;n-S&#xe1;nchez, G. Ochoa-Ruiz, M. Gonzalez-Mendoza, L. Rossi</h3>
<p>Early wildfire detection is of paramount importance to avoid as much damage
as possible to the environment, properties, and lives. Deep Learning (DL)
models that can leverage both visible and infrared information have the
potential to display state-of-the-art performance, with lower false-positive
rates than existing techniques. However, most DL-based image fusion methods
have not been evaluated in the domain of fire imagery. Additionally, to the
best of our knowledge, no publicly available dataset contains visible-infrared
fused fire images. There is a growing interest in DL-based image fusion
techniques due to their reduced complexity. Due to the latter, we select three
state-of-the-art, DL-based image fusion techniques and evaluate them for the
specific task of fire image fusion. We compare the performance of these methods
on selected metrics. Finally, we also present an extension to one of the said
methods, that we called FIRe-GAN, that improves the generation of artificial
infrared images and fused ones on selected metrics.
</p>
<a href="http://arxiv.org/abs/2101.11745" target="_blank">arXiv:2101.11745</a> [<a href="http://arxiv.org/pdf/2101.11745" target="_blank">pdf</a>]

<h2>Faster Kernel Interpolation for Gaussian Processes. (arXiv:2101.11751v1 [cs.LG])</h2>
<h3>Mohit Yadav, Daniel Sheldon, Cameron Musco</h3>
<p>A key challenge in scaling Gaussian Process (GP) regression to massive
datasets is that exact inference requires computation with a dense n x n kernel
matrix, where n is the number of data points. Significant work focuses on
approximating the kernel matrix via interpolation using a smaller set of m
inducing points. Structured kernel interpolation (SKI) is among the most
scalable methods: by placing inducing points on a dense grid and using
structured matrix algebra, SKI achieves per-iteration time of O(n + m log m)
for approximate inference. This linear scaling in n enables inference for very
large data sets; however the cost is per-iteration, which remains a limitation
for extremely large n. We show that the SKI per-iteration time can be reduced
to O(m log m) after a single O(n) time precomputation step by reframing SKI as
solving a natural Bayesian linear regression problem with a fixed set of m
compact basis functions. With per-iteration complexity independent of the
dataset size n for a fixed grid, our method scales to truly massive data sets.
We demonstrate speedups in practice for a wide range of m and n and apply the
method to GP inference on a three-dimensional weather radar dataset with over
100 million points.
</p>
<a href="http://arxiv.org/abs/2101.11751" target="_blank">arXiv:2101.11751</a> [<a href="http://arxiv.org/pdf/2101.11751" target="_blank">pdf</a>]

<h2>Improving Neural Network Robustness through Neighborhood Preserving Layers. (arXiv:2101.11766v1 [cs.LG])</h2>
<h3>Bingyuan Liu, Christopher Malon, Lingzhou Xue, Erik Kruus</h3>
<p>Robustness against adversarial attack in neural networks is an important
research topic in the machine learning community. We observe one major source
of vulnerability of neural nets is from overparameterized fully-connected
layers. In this paper, we propose a new neighborhood preserving layer which can
replace these fully connected layers to improve the network robustness. We
demonstrate a novel neural network architecture which can incorporate such
layers and also can be trained efficiently. We theoretically prove that our
models are more robust against distortion because they effectively control the
magnitude of gradients. Finally, we empirically show that our designed network
architecture is more robust against state-of-art gradient descent based
attacks, such as a PGD attack on the benchmark datasets MNIST and CIFAR10.
</p>
<a href="http://arxiv.org/abs/2101.11766" target="_blank">arXiv:2101.11766</a> [<a href="http://arxiv.org/pdf/2101.11766" target="_blank">pdf</a>]

<h2>Learning $\mathbf{\mathit{Matching}}$ Representations for Individualized Organ Transplantation Allocation. (arXiv:2101.11769v1 [stat.ML])</h2>
<h3>Can Xu, Ahmed M. Alaa, Ioana Bica, Brent D. Ershoff, Maxime Cannesson, Mihaela van der Schaar</h3>
<p>Organ transplantation is often the last resort for treating end-stage
illness, but the probability of a successful transplantation depends greatly on
compatibility between donors and recipients. Current medical practice relies on
coarse rules for donor-recipient matching, but is short of domain knowledge
regarding the complex factors underlying organ compatibility. In this paper, we
formulate the problem of learning data-driven rules for organ matching using
observational data for organ allocations and transplant outcomes. This problem
departs from the standard supervised learning setup in that it involves
matching the two feature spaces (i.e., donors and recipients), and requires
estimating transplant outcomes under counterfactual matches not observed in the
data. To address these problems, we propose a model based on representation
learning to predict donor-recipient compatibility; our model learns
representations that cluster donor features, and applies donor-invariant
transformations to recipient features to predict outcomes for a given
donor-recipient feature instance. Experiments on semi-synthetic and real-world
datasets show that our model outperforms state-of-art allocation methods and
policies executed by human experts.
</p>
<a href="http://arxiv.org/abs/2101.11769" target="_blank">arXiv:2101.11769</a> [<a href="http://arxiv.org/pdf/2101.11769" target="_blank">pdf</a>]

<h2>Evolutionary Co-Design of Morphology and Control of Soft Tensegrity Modular Robots with Programmable Stiffness. (arXiv:2101.11772v1 [cs.RO])</h2>
<h3>Davide Zappetti, Jean Marc Bejjani, Dario Floreano</h3>
<p>Tensegrity structures are lightweight, can undergo large deformations, and
have outstanding robustness capabilities. These unique properties inspired
roboticists to investigate their use. However, the morphological design,
control, assembly, and actuation of tensegrity robots are still difficult
tasks. Moreover, the stiffness of tensegrity robots is still an underestimated
design parameter. In this article, we propose to use easy to assemble, actuated
tensegrity modules and body-brain co-evolution to design soft tensegrity
modular robots. Moreover, we prove the importance of tensegrity robots
stiffness showing how the evolution suggests a different morphology, control,
and locomotion strategy according to the modules stiffness.
</p>
<a href="http://arxiv.org/abs/2101.11772" target="_blank">arXiv:2101.11772</a> [<a href="http://arxiv.org/pdf/2101.11772" target="_blank">pdf</a>]

<h2>Object Detection Made Simpler by Eliminating Heuristic NMS. (arXiv:2101.11782v1 [cs.CV])</h2>
<h3>Qiang Zhou, Chaohui Yu, Chunhua Shen, Zhibin Wang, Hao Li</h3>
<p>We show a simple NMS-free, end-to-end object detection framework, of which
the network is a minimal modification to a one-stage object detector such as
the FCOS detection model [Tian et al. 2019]. We attain on par or even improved
detection accuracy compared with the original one-stage detector. It performs
detection at almost the same inference speed, while being even simpler in that
now the post-processing NMS (non-maximum suppression) is eliminated during
inference. If the network is capable of identifying only one positive sample
for prediction for each ground-truth object instance in an image, then NMS
would become unnecessary. This is made possible by attaching a compact PSS head
for automatic selection of the single positive sample for each instance (see
Fig. 1). As the learning objective involves both one-to-many and one-to-one
label assignments, there is a conflict in the labels of some training examples,
making the learning challenging. We show that by employing a stop-gradient
operation, we can successfully tackle this issue and train the detector. On the
COCO dataset, our simple design achieves superior performance compared to both
the FCOS baseline detector with NMS post-processing and the recent end-to-end
NMS-free detectors. Our extensive ablation studies justify the rationale of the
design choices.
</p>
<a href="http://arxiv.org/abs/2101.11782" target="_blank">arXiv:2101.11782</a> [<a href="http://arxiv.org/pdf/2101.11782" target="_blank">pdf</a>]

<h2>Augmenting Proposals by the Detector Itself. (arXiv:2101.11789v1 [cs.CV])</h2>
<h3>Xiaopei Wan, Zhenhua Guo, Chao He, Yujiu Yang, Fangbo Tao</h3>
<p>Lacking enough high quality proposals for RoI box head has impeded two-stage
and multi-stage object detectors for a long time, and many previous works try
to solve it via improving RPN's performance or manually generating proposals
from ground truth. However, these methods either need huge training and
inference costs or bring little improvements. In this paper, we design a novel
training method named APDI, which means augmenting proposals by the detector
itself and can generate proposals with higher quality. Furthermore, APDI makes
it possible to integrate IoU head into RoI box head. And it does not add any
hyperparameter, which is beneficial for future research and downstream tasks.
Extensive experiments on COCO dataset show that our method brings at least 2.7
AP improvements on Faster R-CNN with various backbones, and APDI can cooperate
with advanced RPNs, such as GA-RPN and Cascade RPN, to obtain extra gains.
Furthermore, it brings significant improvements on Cascade R-CNN.
</p>
<a href="http://arxiv.org/abs/2101.11789" target="_blank">arXiv:2101.11789</a> [<a href="http://arxiv.org/pdf/2101.11789" target="_blank">pdf</a>]

<h2>DOC2PPT: Automatic Presentation Slides Generation from Scientific Documents. (arXiv:2101.11796v1 [cs.CV])</h2>
<h3>Tsu-Jui Fu, William Yang Wang, Daniel McDuff, Yale Song</h3>
<p>Creating presentation materials requires complex multimodal reasoning skills
to summarize key concepts and arrange them in a logical and visually pleasing
manner. Can machines learn to emulate this laborious process? We present a
novel task and approach for document-to-slide generation. Solving this involves
document summarization, image and text retrieval, slide structure, and layout
prediction to arrange key elements in a form suitable for presentation. We
propose a hierarchical sequence-to-sequence approach to tackle our task in an
end-to-end manner. Our approach exploits the inherent structures within
documents and slides and incorporates paraphrasing and layout prediction
modules to generate slides. To help accelerate research in this domain, we
release a dataset about 6K paired documents and slide decks used in our
experiments. We show that our approach outperforms strong baselines and
produces slides with rich content and aligned imagery.
</p>
<a href="http://arxiv.org/abs/2101.11796" target="_blank">arXiv:2101.11796</a> [<a href="http://arxiv.org/pdf/2101.11796" target="_blank">pdf</a>]

<h2>Covert Model Poisoning Against Federated Learning: Algorithm Design and Optimization. (arXiv:2101.11799v1 [cs.LG])</h2>
<h3>Kang Wei, Jun Li, Ming Ding, Chuan Ma, Yo-Seb Jeon, H. Vincent Poor</h3>
<p>Federated learning (FL), as a type of distributed machine learning
frameworks, is vulnerable to external attacks on FL models during parameters
transmissions. An attacker in FL may control a number of participant clients,
and purposely craft the uploaded model parameters to manipulate system outputs,
namely, model poisoning (MP). In this paper, we aim to propose effective MP
algorithms to combat state-of-the-art defensive aggregation mechanisms (e.g.,
Krum and Trimmed mean) implemented at the server without being noticed, i.e.,
covert MP (CMP). Specifically, we first formulate the MP as an optimization
problem by minimizing the Euclidean distance between the manipulated model and
designated one, constrained by a defensive aggregation rule. Then, we develop
CMP algorithms against different defensive mechanisms based on the solutions of
their corresponding optimization problems. Furthermore, to reduce the
optimization complexity, we propose low complexity CMP algorithms with a slight
performance degradation. In the case that the attacker does not know the
defensive aggregation mechanism, we design a blind CMP algorithm, in which the
manipulated model will be adjusted properly according to the aggregated model
generated by the unknown defensive aggregation. Our experimental results
demonstrate that the proposed CMP algorithms are effective and substantially
outperform existing attack mechanisms.
</p>
<a href="http://arxiv.org/abs/2101.11799" target="_blank">arXiv:2101.11799</a> [<a href="http://arxiv.org/pdf/2101.11799" target="_blank">pdf</a>]

<h2>AdaSpring: Context-adaptive and Runtime-evolutionary Deep Model Compression for Mobile Applications. (arXiv:2101.11800v1 [cs.LG])</h2>
<h3>Sicong Liu, Bin Guo, Ke Ma, Zhiwen Yu, Junzhao Du</h3>
<p>There are many deep learning (e.g., DNN) powered mobile and wearable
applications today continuously and unobtrusively sensing the ambient
surroundings to enhance all aspects of human lives. To enable robust and
private mobile sensing, DNN tends to be deployed locally on the
resource-constrained mobile devices via model compression. The current practice
either hand-crafted DNN compression techniques, i.e., for optimizing
DNN-relative performance (e.g., parameter size), or on-demand DNN compression
methods, i.e., for optimizing hardware-dependent metrics (e.g., latency),
cannot be locally online because they require offline retraining to ensure
accuracy. Also, none of them have correlated their efforts with runtime
adaptive compression to consider the dynamic nature of the deployment context
of mobile applications. To address those challenges, we present AdaSpring, a
context-adaptive and self-evolutionary DNN compression framework. It enables
the runtime adaptive DNN compression locally online. Specifically, it presents
the ensemble training of a retraining-free and self-evolutionary network to
integrate multiple alternative DNN compression configurations (i.e., compressed
architectures and weights). It then introduces the runtime search strategy to
quickly search for the most suitable compression configurations and evolve the
corresponding weights. With evaluation on five tasks across three platforms and
a real-world case study, experiment outcomes show that AdaSpring obtains up to
3.1x latency reduction, 4.2 x energy efficiency improvement in DNNs, compared
to hand-crafted compression techniques, while only incurring &lt;= 6.2ms
runtime-evolution latency.
</p>
<a href="http://arxiv.org/abs/2101.11800" target="_blank">arXiv:2101.11800</a> [<a href="http://arxiv.org/pdf/2101.11800" target="_blank">pdf</a>]

<h2>SwingBot: Learning Physical Features from In-hand Tactile Exploration for Dynamic Swing-up Manipulation. (arXiv:2101.11812v1 [cs.RO])</h2>
<h3>Chen Wang, Shaoxiong Wang, Branden Romero, Filipe Veiga, Edward Adelson</h3>
<p>Several robot manipulation tasks are extremely sensitive to variations of the
physical properties of the manipulated objects. One such task is manipulating
objects by using gravity or arm accelerations, increasing the importance of
mass, center of mass, and friction information. We present SwingBot, a robot
that is able to learn the physical features of a held object through tactile
exploration. Two exploration actions (tilting and shaking) provide the tactile
information used to create a physical feature embedding space. With this
embedding, SwingBot is able to predict the swing angle achieved by a robot
performing dynamic swing-up manipulations on a previously unseen object. Using
these predictions, it is able to search for the optimal control parameters for
a desired swing-up angle. We show that with the learned physical features our
end-to-end self-supervised learning pipeline is able to substantially improve
the accuracy of swinging up unseen objects. We also show that objects with
similar dynamics are closer to each other on the embedding space and that the
embedding can be disentangled into values of specific physical properties.
</p>
<a href="http://arxiv.org/abs/2101.11812" target="_blank">arXiv:2101.11812</a> [<a href="http://arxiv.org/pdf/2101.11812" target="_blank">pdf</a>]

<h2>Interpolating Classifiers Make Few Mistakes. (arXiv:2101.11815v1 [stat.ML])</h2>
<h3>Tengyuan Liang, Benjamin Recht</h3>
<p>This paper provides elementary analyses of the regret and generalization of
minimum-norm interpolating classifiers (MNIC). The MNIC is the function of
smallest Reproducing Kernel Hilbert Space norm that perfectly interpolates a
label pattern on a finite data set. We derive a mistake bound for MNIC and a
regularized variant that holds for all data sets. This bound follows from
elementary properties of matrix inverses. Under the assumption that the data is
independently and identically distributed, the mistake bound implies that MNIC
generalizes at a rate proportional to the norm of the interpolating solution
and inversely proportional to the number of data points. This rate matches
similar rates derived for margin classifiers and perceptrons. We derive several
plausible generative models where the norm of the interpolating classifier is
bounded or grows at a rate sublinear in $n$. We also show that as long as the
population class conditional distributions are sufficiently separable in total
variation, then MNIC generalizes with a fast rate.
</p>
<a href="http://arxiv.org/abs/2101.11815" target="_blank">arXiv:2101.11815</a> [<a href="http://arxiv.org/pdf/2101.11815" target="_blank">pdf</a>]

<h2>Acoustic Communication and Sensing for Inflatable Modular Soft Robots. (arXiv:2101.11817v1 [cs.RO])</h2>
<h3>D. S. Drew, M. Devlin, E. Hawkes, S. Follmer</h3>
<p>Modular soft robots combine the strengths of two traditionally separate areas
of robotics. As modular robots, they can show robustness to individual failure
and reconfigurability; as soft robots, they can deform and undergo large shape
changes in order to adapt to their environment, and have inherent human safety.
However, for sensing and communication these robots also combine the challenges
of both: they require solutions that are scalable (low cost and complexity) and
efficient (low power) to enable collectives of large numbers of robots, and
these solutions must also be able to interface with the high extension ratio
elastic bodies of soft robots. In this work, we seek to address these
challenges using acoustic signals produced by piezoelectric surface transducers
that are cheap, simple, and low power, and that not only integrate with but
also leverage the elastic robot skins for signal transmission. Importantly, to
further increase scalability, the transducers exhibit multi-functionality made
possible by a relatively flat frequency response across the audible and
ultrasonic ranges. With minimal hardware, they enable directional contact-based
communication, audible-range communication at a distance, and exteroceptive
sensing. We demonstrate a subset of the decentralized collective behaviors
these functions make possible with multi-robot hardware implementations. The
use of acoustic waves in this domain is shown to provide distinct advantages
over existing solutions.
</p>
<a href="http://arxiv.org/abs/2101.11817" target="_blank">arXiv:2101.11817</a> [<a href="http://arxiv.org/pdf/2101.11817" target="_blank">pdf</a>]

<h2>Adaptive Decision Forest: An Incremental Machine Learning Framework. (arXiv:2101.11828v1 [cs.LG])</h2>
<h3>Md Geaur Rahman, Md Zahidul Islam</h3>
<p>In this study, we present an incremental machine learning framework called
Adaptive Decision Forest (ADF), which produces a decision forest to classify
new records. Based on our two novel theorems, we introduce a new splitting
strategy called iSAT, which allows ADF to classify new records even if they are
associated with previously unseen classes. ADF is capable of identifying and
handling concept drift; it, however, does not forget previously gained
knowledge. Moreover, ADF is capable of handling big data if the data can be
divided into batches. We evaluate ADF on five publicly available natural data
sets and one synthetic data set, and compare the performance of ADF against the
performance of eight state-of-the-art techniques. Our experimental results,
including statistical sign test and Nemenyi test analyses, indicate a clear
superiority of the proposed framework over the state-of-the-art techniques.
</p>
<a href="http://arxiv.org/abs/2101.11828" target="_blank">arXiv:2101.11828</a> [<a href="http://arxiv.org/pdf/2101.11828" target="_blank">pdf</a>]

<h2>Neural Architecture Search with Random Labels. (arXiv:2101.11834v1 [cs.CV])</h2>
<h3>Xuanyang Zhang, Pengfei Hou, Xiangyu Zhang, Jian Sun</h3>
<p>In this paper, we investigate a new variant of neural architecture search
(NAS) paradigm -- searching with random labels (RLNAS). The task sounds
counter-intuitive for most existing NAS algorithms since random label provides
few information on the performance of each candidate architecture. Instead, we
propose a novel NAS framework based on ease-of-convergence hypothesis, which
requires only random labels during searching. The algorithm involves two steps:
first, we train a SuperNet using random labels; second, from the SuperNet we
extract the sub-network whose weights change most significantly during the
training. Extensive experiments are evaluated on multiple datasets (e.g.
NAS-Bench-201 and ImageNet) and multiple search spaces (e.g. DARTS-like and
MobileNet-like). Very surprisingly, RLNAS achieves comparable or even better
results compared with state-of-the-art NAS methods such as PC-DARTS, Single
Path One-Shot, even though the counterparts utilize full ground truth labels
for searching. We hope our finding could inspire new understandings on the
essential of NAS.
</p>
<a href="http://arxiv.org/abs/2101.11834" target="_blank">arXiv:2101.11834</a> [<a href="http://arxiv.org/pdf/2101.11834" target="_blank">pdf</a>]

<h2>Reducing ReLU Count for Privacy-Preserving CNN Speedup. (arXiv:2101.11835v1 [cs.CV])</h2>
<h3>Inbar Helbitz, Shai Avidan</h3>
<p>Privacy-Preserving Machine Learning algorithms must balance classification
accuracy with data privacy. This can be done using a combination of
cryptographic and machine learning tools such as Convolutional Neural Networks
(CNN). CNNs typically consist of two types of operations: a convolutional or
linear layer, followed by a non-linear function such as ReLU. Each of these
types can be implemented efficiently using a different cryptographic tool. But
these tools require different representations and switching between them is
time-consuming and expensive. Recent research suggests that ReLU is responsible
for most of the communication bandwidth. ReLU is usually applied at each pixel
(or activation) location, which is quite expensive. We propose to share ReLU
operations. Specifically, the ReLU decision of one activation can be used by
others, and we explore different ways to group activations and different ways
to determine the ReLU for such a group of activations. Experiments on several
datasets reveal that we can cut the number of ReLU operations by up to three
orders of magnitude and, as a result, cut the communication bandwidth by more
than 50%.
</p>
<a href="http://arxiv.org/abs/2101.11835" target="_blank">arXiv:2101.11835</a> [<a href="http://arxiv.org/pdf/2101.11835" target="_blank">pdf</a>]

<h2>A Taxonomy of Explainable Bayesian Networks. (arXiv:2101.11844v1 [cs.AI])</h2>
<h3>Iena Petronella Derks, Alta de Waal</h3>
<p>Artificial Intelligence (AI), and in particular, the explainability thereof,
has gained phenomenal attention over the last few years. Whilst we usually do
not question the decision-making process of these systems in situations where
only the outcome is of interest, we do however pay close attention when these
systems are applied in areas where the decisions directly influence the lives
of humans. It is especially noisy and uncertain observations close to the
decision boundary which results in predictions which cannot necessarily be
explained that may foster mistrust among end-users. This drew attention to AI
methods for which the outcomes can be explained. Bayesian networks are
probabilistic graphical models that can be used as a tool to manage
uncertainty. The probabilistic framework of a Bayesian network allows for
explainability in the model, reasoning and evidence. The use of these methods
is mostly ad hoc and not as well organised as explainability methods in the
wider AI research field. As such, we introduce a taxonomy of explainability in
Bayesian networks. We extend the existing categorisation of explainability in
the model, reasoning or evidence to include explanation of decisions. The
explanations obtained from the explainability methods are illustrated by means
of a simple medical diagnostic scenario. The taxonomy introduced in this paper
has the potential not only to encourage end-users to efficiently communicate
outcomes obtained, but also support their understanding of how and, more
importantly, why certain predictions were made.
</p>
<a href="http://arxiv.org/abs/2101.11844" target="_blank">arXiv:2101.11844</a> [<a href="http://arxiv.org/pdf/2101.11844" target="_blank">pdf</a>]

<h2>Interpreting and Unifying Graph Neural Networks with An Optimization Framework. (arXiv:2101.11859v1 [cs.LG])</h2>
<h3>Meiqi Zhu, Xiao Wang, Chuan Shi, Houye Ji, Peng Cui</h3>
<p>Graph Neural Networks (GNNs) have received considerable attention on
graph-structured data learning for a wide variety of tasks. The well-designed
propagation mechanism which has been demonstrated effective is the most
fundamental part of GNNs. Although most of GNNs basically follow a message
passing manner, litter effort has been made to discover and analyze their
essential relations. In this paper, we establish a surprising connection
between different propagation mechanisms with a unified optimization problem,
showing that despite the proliferation of various GNNs, in fact, their proposed
propagation mechanisms are the optimal solution optimizing a feature fitting
function over a wide class of graph kernels with a graph regularization term.
Our proposed unified optimization framework, summarizing the commonalities
between several of the most representative GNNs, not only provides a
macroscopic view on surveying the relations between different GNNs, but also
further opens up new opportunities for flexibly designing new GNNs. With the
proposed framework, we discover that existing works usually utilize naive graph
convolutional kernels for feature fitting function, and we further develop two
novel objective functions considering adjustable graph kernels showing low-pass
or high-pass filtering capabilities respectively. Moreover, we provide the
convergence proofs and expressive power comparisons for the proposed models.
Extensive experiments on benchmark datasets clearly show that the proposed GNNs
not only outperform the state-of-the-art methods but also have good ability to
alleviate over-smoothing, and further verify the feasibility for designing GNNs
with our unified optimization framework.
</p>
<a href="http://arxiv.org/abs/2101.11859" target="_blank">arXiv:2101.11859</a> [<a href="http://arxiv.org/pdf/2101.11859" target="_blank">pdf</a>]

<h2>The Hidden Tasks of Generative Adversarial Networks: An Alternative Perspective on GAN Training. (arXiv:2101.11863v1 [cs.LG])</h2>
<h3>Romann M. Weber</h3>
<p>We present an alternative perspective on the training of generative
adversarial networks (GANs), showing that the training step for a GAN generator
decomposes into two implicit sub-problems. In the first, the discriminator
provides new target data to the generator in the form of "inverse examples"
produced by approximately inverting classifier labels. In the second, these
examples are used as targets to update the generator via least-squares
regression, regardless of the main loss specified to train the network. We
experimentally validate our main theoretical result and discuss implications
for alternative training methods that are made possible by making these
sub-problems explicit. We also introduce a simple representation of inductive
bias in networks, which we apply to describing the generator's output relative
to its regression targets.
</p>
<a href="http://arxiv.org/abs/2101.11863" target="_blank">arXiv:2101.11863</a> [<a href="http://arxiv.org/pdf/2101.11863" target="_blank">pdf</a>]

<h2>Strategic Argumentation Dialogues for Persuasion: Framework and Experiments Based on Modelling the Beliefs and Concerns of the Persuadee. (arXiv:2101.11870v1 [cs.AI])</h2>
<h3>Emmanuel Hadoux, Anthony Hunter, Sylwia Polberg</h3>
<p>Persuasion is an important and yet complex aspect of human intelligence. When
undertaken through dialogue, the deployment of good arguments, and therefore
counterarguments, clearly has a significant effect on the ability to be
successful in persuasion. Two key dimensions for determining whether an
argument is good in a particular dialogue are the degree to which the intended
audience believes the argument and counterarguments, and the impact that the
argument has on the concerns of the intended audience. In this paper, we
present a framework for modelling persuadees in terms of their beliefs and
concerns, and for harnessing these models in optimizing the choice of move in
persuasion dialogues. Our approach is based on the Monte Carlo Tree Search
which allows optimization in real-time. We provide empirical results of a study
with human participants showing that our automated persuasion system based on
this technology is superior to a baseline system that does not take the beliefs
and concerns into account in its strategy.
</p>
<a href="http://arxiv.org/abs/2101.11870" target="_blank">arXiv:2101.11870</a> [<a href="http://arxiv.org/pdf/2101.11870" target="_blank">pdf</a>]

<h2>COMPAS: Representation Learning with Compositional Part Sharing for Few-Shot Classification. (arXiv:2101.11878v1 [cs.CV])</h2>
<h3>Ju He, Adam Kortylewski, Alan Yuille</h3>
<p>Few-shot image classification consists of two consecutive learning processes:
1) In the meta-learning stage, the model acquires a knowledge base from a set
of training classes. 2) During meta-testing, the acquired knowledge is used to
recognize unseen classes from very few examples. Inspired by the compositional
representation of objects in humans, we train a neural network architecture
that explicitly represents objects as a set of parts and their spatial
composition. In particular, during meta-learning, we train a knowledge base
that consists of a dictionary of part representations and a dictionary of part
activation maps that encode frequent spatial activation patterns of parts. The
elements of both dictionaries are shared among the training classes. During
meta-testing, the representation of unseen classes is learned using the part
representations and the part activation maps from the knowledge base. Finally,
an attention mechanism is used to strengthen those parts that are most
important for each category. We demonstrate the value of our compositional
learning framework for a few-shot classification using miniImageNet,
tieredImageNet, CIFAR-FS, and FC100, where we achieve state-of-the-art
performance.
</p>
<a href="http://arxiv.org/abs/2101.11878" target="_blank">arXiv:2101.11878</a> [<a href="http://arxiv.org/pdf/2101.11878" target="_blank">pdf</a>]

<h2>Deep learning via LSTM models for COVID-19 infection forecasting in India. (arXiv:2101.11881v1 [cs.LG])</h2>
<h3>Rohitash Chandra, Ayush Jain, Divyanshu Singh Chauhan</h3>
<p>We have entered an era of a pandemic that has shaken the world with major
impact to medical systems, economics and agriculture. Prominent computational
and mathematical models have been unreliable due to the complexity of the
spread of infections. Moreover, lack of data collection and reporting makes any
such modelling attempts unreliable. Hence we need to re-look at the situation
with the latest data sources and most comprehensive forecasting models. Deep
learning models such as recurrent neural networks are well suited for modelling
temporal sequences. In this paper, prominent recurrent neural networks, in
particular \textit{long short term memory} (LSTMs) networks, bidirectional
LSTM, and encoder-decoder LSTM models for multi-step (short-term) forecasting
the spread of COVID-infections among selected states in India. We select states
with COVID-19 hotpots in terms of the rate of infections and compare with
states where infections have been contained or reached their peak and provide
two months ahead forecast that shows that cases will slowly decline. Our
results show that long-term forecasts are promising which motivates the
application of the method in other countries or areas. We note that although we
made some progress in forecasting, the challenges in modelling remain due to
data and difficulty in capturing factors such as population density, travel
logistics, and social aspects such culture and lifestyle.
</p>
<a href="http://arxiv.org/abs/2101.11881" target="_blank">arXiv:2101.11881</a> [<a href="http://arxiv.org/pdf/2101.11881" target="_blank">pdf</a>]

<h2>Causality and independence in perfectly adapted dynamical systems. (arXiv:2101.11885v1 [cs.AI])</h2>
<h3>Tineke Blom, Joris M. Mooij</h3>
<p>Perfect adaptation in a dynamical system is the phenomenon that one or more
variables have an initial transient response to a persistent change in an
external stimulus but revert to their original value as the system converges to
equilibrium. The causal ordering algorithm can be used to construct an
equilibrium causal ordering graph that represents causal relations and a Markov
ordering graph that implies conditional independences from a set of equilibrium
equations. Based on this, we formulate sufficient graphical conditions to
identify perfect adaptation from a set of first-order differential equations.
Furthermore, we give sufficient conditions to test for the presence of perfect
adaptation in experimental equilibrium data. We apply our ideas to a simple
model for a protein signalling pathway and test its predictions both in
simulations and on real-world protein expression data. We demonstrate that
perfect adaptation in this model can explain why the presence and orientation
of edges in the output of causal discovery algorithms does not always appear to
agree with the direction of edges in biological consensus networks.
</p>
<a href="http://arxiv.org/abs/2101.11885" target="_blank">arXiv:2101.11885</a> [<a href="http://arxiv.org/pdf/2101.11885" target="_blank">pdf</a>]

<h2>Automatic design of novel potential 3CL$^{\text{pro}}$ and PL$^{\text{pro}}$ inhibitors. (arXiv:2101.11890v1 [cs.LG])</h2>
<h3>Timothy Atkinson, Saeed Saremi, Faustino Gomez, Jonathan Masci</h3>
<p>With the goal of designing novel inhibitors for SARS-CoV-1 and SARS-CoV-2, we
propose the general molecule optimization framework, Molecular Neural Assay
Search (MONAS), consisting of three components: a property predictor which
identifies molecules with specific desirable properties, an energy model which
approximates the statistical similarity of a given molecule to known training
molecules, and a molecule search method. In this work, these components are
instantiated with graph neural networks (GNNs), Deep Energy Estimator Networks
(DEEN) and Monte Carlo tree search (MCTS), respectively. This implementation is
used to identify 120K molecules (out of 40-million explored) which the GNN
determined to be likely SARS-CoV-1 inhibitors, and, at the same time, are
statistically close to the dataset used to train the GNN.
</p>
<a href="http://arxiv.org/abs/2101.11890" target="_blank">arXiv:2101.11890</a> [<a href="http://arxiv.org/pdf/2101.11890" target="_blank">pdf</a>]

<h2>Self-supervised Cross-silo Federated Neural Architecture Search. (arXiv:2101.11896v1 [cs.LG])</h2>
<h3>Xinle Liang, Yang Liu, Jiahuan Luo, Yuanqin He, Tianjian Chen, Qiang Yang</h3>
<p>Federated Learning (FL) provides both model performance and data privacy for
machine learning tasks where samples or features are distributed among
different parties. In the training process of FL, no party has a global view of
data distributions or model architectures of other parties. Thus the
manually-designed architectures may not be optimal. In the past, Neural
Architecture Search (NAS) has been applied to FL to address this critical
issue. However, existing Federated NAS approaches require prohibitive
communication and computation effort, as well as the availability of
high-quality labels. In this work, we present Self-supervised Vertical
Federated Neural Architecture Search (SS-VFNAS) for automating FL where
participants hold feature-partitioned data, a common cross-silo scenario called
Vertical Federated Learning (VFL). In the proposed framework, each party first
conducts NAS using self-supervised approach to find a local optimal
architecture with its own data. Then, parties collaboratively improve the local
optimal architecture in a VFL framework with supervision. We demonstrate
experimentally that our approach has superior performance, communication
efficiency and privacy compared to Federated NAS and is capable of generating
high-performance and highly-transferable heterogeneous architectures even with
insufficient overlapping samples, providing automation for those parties
without deep learning expertise.
</p>
<a href="http://arxiv.org/abs/2101.11896" target="_blank">arXiv:2101.11896</a> [<a href="http://arxiv.org/pdf/2101.11896" target="_blank">pdf</a>]

<h2>A Machine Learning Challenge for Prognostic Modelling in Head and Neck Cancer Using Multi-modal Data. (arXiv:2101.11935v1 [cs.LG])</h2>
<h3>Michal Kazmierski, Mattea Welch, Sejin Kim, Chris McIntosh, Princess Margaret Head, Neck Cancer Group, Katrina Rey-McIntyre, Shao Hui Huang, Tirth Patel, Tony Tadic, Michael Milosevic, Fei-Fei Liu, Andrew Hope, Scott Bratman, Benjamin Haibe-Kains</h3>
<p>Accurate prognosis for an individual patient is a key component of precision
oncology. Recent advances in machine learning have enabled the development of
models using a wider range of data, including imaging. Radiomics aims to
extract quantitative predictive and prognostic biomarkers from routine medical
imaging, but evidence for computed tomography radiomics for prognosis remains
inconclusive. We have conducted an institutional machine learning challenge to
develop an accurate model for overall survival prediction in head and neck
cancer using clinical data etxracted from electronic medical records and
pre-treatment radiological images, as well as to evaluate the true added
benefit of radiomics for head and neck cancer prognosis. Using a large,
retrospective dataset of 2,552 patients and a rigorous evaluation framework, we
compared 12 different submissions using imaging and clinical data, separately
or in combination. The winning approach used non-linear, multitask learning on
clinical data and tumour volume, achieving high prognostic accuracy for 2-year
and lifetime survival prediction and outperforming models relying on clinical
data only, engineered radiomics and deep learning. Combining all submissions in
an ensemble model resulted in improved accuracy, with the highest gain from a
image-based deep learning model. Our results show the potential of machine
learning and simple, informative prognostic factors in combination with large
datasets as a tool to guide personalized cancer care.
</p>
<a href="http://arxiv.org/abs/2101.11935" target="_blank">arXiv:2101.11935</a> [<a href="http://arxiv.org/pdf/2101.11935" target="_blank">pdf</a>]

<h2>Exploring Cross-Image Pixel Contrast for Semantic Segmentation. (arXiv:2101.11939v1 [cs.CV])</h2>
<h3>Wenguan Wang, Tianfei Zhou, Fisher Yu, Jifeng Dai, Ender Konukoglu, Luc Van Gool</h3>
<p>Current semantic segmentation methods focus only on mining "local" context,
i.e., dependencies between pixels within individual images, by
context-aggregation modules (e.g., dilated convolution, neural attention) or
structure-aware optimization criteria (e.g., IoU-like loss). However, they
ignore "global" context of the training data, i.e., rich semantic relations
between pixels across different images. Inspired by the recent advance in
unsupervised contrastive representation learning, we propose a pixel-wise
contrastive framework for semantic segmentation in the fully supervised
setting. The core idea is to enforce pixel embeddings belonging to a same
semantic class to be more similar than embeddings from different classes. It
raises a pixel-wise metric learning paradigm for semantic segmentation, by
explicitly exploring the structures of labeled pixels, which are long ignored
in the field. Our method can be effortlessly incorporated into existing
segmentation frameworks without extra overhead during testing. We
experimentally show that, with famous segmentation models (i.e., DeepLabV3,
HRNet, OCR) and backbones (i.e., ResNet, HR-Net), our method brings consistent
performance improvements across diverse datasets (i.e., Cityscapes,
PASCAL-Context, COCO-Stuff). We expect this work will encourage our community
to rethink the current de facto training paradigm in fully supervised semantic
segmentation.
</p>
<a href="http://arxiv.org/abs/2101.11939" target="_blank">arXiv:2101.11939</a> [<a href="http://arxiv.org/pdf/2101.11939" target="_blank">pdf</a>]

<h2>Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss. (arXiv:2101.11952v1 [cs.CV])</h2>
<h3>Xue Yang, Junchi Yan, Qi Ming, Wentao Wang, Xiaopeng Zhang, Qi Tian</h3>
<p>Boundary discontinuity and its inconsistency to the final detection metric
have been the bottleneck for rotating detection regression loss design. In this
paper, we propose a novel regression loss based on Gaussian Wasserstein
distance as a fundamental approach to solve the problem. Specifically, the
rotated bounding box is converted to a 2-D Gaussian distribution, which enables
to approximate the indifferentiable rotational IoU induced loss by the Gaussian
Wasserstein distance (GWD) which can be learned efficiently by gradient
back-propagation. GWD can still be informative for learning even there is no
overlapping between two rotating bounding boxes which is often the case for
small object detection. Thanks to its three unique properties, GWD can also
elegantly solve the boundary discontinuity and square-like problem regardless
how the bounding box is defined. Experiments on five datasets using different
detectors show the effectiveness of our approach. Codes are available at
https://github.com/yangxue0827/RotationDetection.
</p>
<a href="http://arxiv.org/abs/2101.11952" target="_blank">arXiv:2101.11952</a> [<a href="http://arxiv.org/pdf/2101.11952" target="_blank">pdf</a>]

<h2>PSpan:Mining Frequent Subnets of Petri Nets. (arXiv:2101.11972v1 [cs.LG])</h2>
<h3>Ruqian Lu, Shuhan Zhang</h3>
<p>This paper proposes for the first time an algorithm PSpan for mining frequent
complete subnets from a set of Petri nets. We introduced the concept of
complete subnets and the net graph representation. PSpan transforms Petri nets
in net graphs and performs sub-net graph mining on them, then transforms the
results back to frequent subnets. PSpan follows the pattern growth approach and
has similar complexity like gSpan in graph mining. Experiments have been done
to confirm PSpan's reliability and complexity. Besides C/E nets, it applies
also to a set of other Petri net subclasses.
</p>
<a href="http://arxiv.org/abs/2101.11972" target="_blank">arXiv:2101.11972</a> [<a href="http://arxiv.org/pdf/2101.11972" target="_blank">pdf</a>]

<h2>Disembodied Machine Learning: On the Illusion of Objectivity in NLP. (arXiv:2101.11974v1 [cs.AI])</h2>
<h3>Zeerak Waseem, Smarika Lulz, Joachim Bingel, Isabelle Augenstein</h3>
<p>Machine Learning seeks to identify and encode bodies of knowledge within
provided datasets. However, data encodes subjective content, which determines
the possible outcomes of the models trained on it. Because such subjectivity
enables marginalisation of parts of society, it is termed (social) `bias' and
sought to be removed. In this paper, we contextualise this discourse of bias in
the ML community against the subjective choices in the development process.
Through a consideration of how choices in data and model development construct
subjectivity, or biases that are represented in a model, we argue that
addressing and mitigating biases is near-impossible. This is because both data
and ML models are objects for which meaning is made in each step of the
development pipeline, from data selection over annotation to model training and
analysis. Accordingly, we find the prevalent discourse of bias limiting in its
ability to address social marginalisation. We recommend to be conscientious of
this, and to accept that de-biasing methods only correct for a fraction of
biases.
</p>
<a href="http://arxiv.org/abs/2101.11974" target="_blank">arXiv:2101.11974</a> [<a href="http://arxiv.org/pdf/2101.11974" target="_blank">pdf</a>]

<h2>Embedding Symbolic Temporal Knowledge into Deep Sequential Models. (arXiv:2101.11981v1 [cs.AI])</h2>
<h3>Yaqi Xie, Fan Zhou, Harold Soh</h3>
<p>Sequences and time-series often arise in robot tasks, e.g., in activity
recognition and imitation learning. In recent years, deep neural networks
(DNNs) have emerged as an effective data-driven methodology for processing
sequences given sufficient training data and compute resources. However, when
data is limited, simpler models such as logic/rule-based methods work
surprisingly well, especially when relevant prior knowledge is applied in their
construction. However, unlike DNNs, these "structured" models can be difficult
to extend, and do not work well with raw unstructured data. In this work, we
seek to learn flexible DNNs, yet leverage prior temporal knowledge when
available. Our approach is to embed symbolic knowledge expressed as linear
temporal logic (LTL) and use these embeddings to guide the training of deep
models. Specifically, we construct semantic-based embeddings of automata
generated from LTL formula via a Graph Neural Network. Experiments show that
these learnt embeddings can lead to improvements in downstream robot tasks such
as sequential action recognition and imitation learning.
</p>
<a href="http://arxiv.org/abs/2101.11981" target="_blank">arXiv:2101.11981</a> [<a href="http://arxiv.org/pdf/2101.11981" target="_blank">pdf</a>]

<h2>Machine learning for cloud resources management -- An overview. (arXiv:2101.11984v1 [cs.LG])</h2>
<h3>V.N. Tsakalidou, P. Mitsou, G.A. Papakostas</h3>
<p>Nowadays, an important topic that is considered a lot is how to integrate
Machine Learning(ML) to cloud resources management. In this study, our goal is
to explore the most important cloud resources management issues that have been
combined with ML and which present many promising results. To accomplish this,
we used chronological charts based on some keywords that we considered
important and tried to answer the question: is ML suitable for resources
management problems in the cloud? Furthermore, a short discussion takes place
on the data that are available and the open challenges on it. A big collection
of researches is used to make sensible comparisons between the ML techniques
that are used in the different kinds of cloud resources management fields and
we propose the most suitable ML model for each field. 1
</p>
<a href="http://arxiv.org/abs/2101.11984" target="_blank">arXiv:2101.11984</a> [<a href="http://arxiv.org/pdf/2101.11984" target="_blank">pdf</a>]

<h2>Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet. (arXiv:2101.11986v1 [cs.CV])</h2>
<h3>Li Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Francis EH Tay, Jiashi Feng, Shuicheng Yan</h3>
<p>Transformers, which are popular for language modeling, have been explored for
solving vision tasks recently, e.g., the Vision Transformers (ViT) for image
classification. The ViT model splits each image into a sequence of tokens with
fixed length and then applies multiple Transformer layers to model their global
relation for classification. However, ViT achieves inferior performance
compared with CNNs when trained from scratch on a midsize dataset (e.g.,
ImageNet). We find it is because: 1) the simple tokenization of input images
fails to model the important local structure (e.g., edges, lines) among
neighboring pixels, leading to its low training sample efficiency; 2) the
redundant attention backbone design of ViT leads to limited feature richness in
fixed computation budgets and limited training samples.

To overcome such limitations, we propose a new Tokens-To-Token Vision
Transformers (T2T-ViT), which introduces 1) a layer-wise Tokens-to-Token (T2T)
transformation to progressively structurize the image to tokens by recursively
aggregating neighboring Tokens into one Token (Tokens-to-Token), such that
local structure presented by surrounding tokens can be modeled and tokens
length can be reduced; 2) an efficient backbone with a deep-narrow structure
for vision transformers motivated by CNN architecture design after extensive
study. Notably, T2T-ViT reduces the parameter counts and MACs of vanilla ViT by
200\%, while achieving more than 2.5\% improvement when trained from scratch on
ImageNet. It also outperforms ResNets and achieves comparable performance with
MobileNets when directly training on ImageNet. For example, T2T-ViT with
ResNet50 comparable size can achieve 80.7\% top-1 accuracy on ImageNet. (Code:
https://github.com/yitu-opensource/T2T-ViT)
</p>
<a href="http://arxiv.org/abs/2101.11986" target="_blank">arXiv:2101.11986</a> [<a href="http://arxiv.org/pdf/2101.11986" target="_blank">pdf</a>]

<h2>PIG-Net: Inception based Deep Learning Architecture for 3D Point Cloud Segmentation. (arXiv:2101.11987v1 [cs.CV])</h2>
<h3>Sindhu Hegde, Shankar Gangisetty</h3>
<p>Point clouds, being the simple and compact representation of surface geometry
of 3D objects, have gained increasing popularity with the evolution of deep
learning networks for classification and segmentation tasks. Unlike human,
teaching the machine to analyze the segments of an object is a challenging task
and quite essential in various machine vision applications. In this paper, we
address the problem of segmentation and labelling of the 3D point clouds by
proposing a inception based deep network architecture called PIG-Net, that
effectively characterizes the local and global geometric details of the point
clouds. In PIG-Net, the local features are extracted from the transformed input
points using the proposed inception layers and then aligned by feature
transform. These local features are aggregated using the global average pooling
layer to obtain the global features. Finally, feed the concatenated local and
global features to the convolution layers for segmenting the 3D point clouds.
We perform an exhaustive experimental analysis of the PIG-Net architecture on
two state-of-the-art datasets, namely, ShapeNet [1] and PartNet [2]. We
evaluate the effectiveness of our network by performing ablation study.
</p>
<a href="http://arxiv.org/abs/2101.11987" target="_blank">arXiv:2101.11987</a> [<a href="http://arxiv.org/pdf/2101.11987" target="_blank">pdf</a>]

<h2>Acting in Delayed Environments with Non-Stationary Markov Policies. (arXiv:2101.11992v1 [cs.LG])</h2>
<h3>Esther Derman, Gal Dalal, Shie Mannor</h3>
<p>The standard Markov Decision Process (MDP) formulation hinges on the
assumption that an action is executed immediately after it was chosen. However,
assuming it is often unrealistic and can lead to catastrophic failures in
applications such as robotic manipulation, cloud computing, and finance. We
introduce a framework for learning and planning in MDPs where the
decision-maker commits actions that are executed with a delay of $m$ steps. The
brute-force state augmentation baseline where the state is concatenated to the
last $m$ committed actions suffers from an exponential complexity in $m$, as we
show for policy iteration. We then prove that with execution delay, Markov
policies in the original state-space are sufficient for attaining maximal
reward, but need to be non-stationary. As for stationary Markov policies, we
show they are sub-optimal in general. Consequently, we devise a non-stationary
Q-learning style model-based algorithm that solves delayed execution tasks
without resorting to state-augmentation. Experiments on tabular, physical, and
Atari domains reveal that it converges quickly to high performance even for
substantial delays, while standard approaches that either ignore the delay or
rely on state-augmentation struggle or fail due to divergence. The code is
available at https://github.com/galdl/rl_delay_basic.git.
</p>
<a href="http://arxiv.org/abs/2101.11992" target="_blank">arXiv:2101.11992</a> [<a href="http://arxiv.org/pdf/2101.11992" target="_blank">pdf</a>]

<h2>Copula-based conformal prediction for Multi-Target Regression. (arXiv:2101.12002v1 [cs.LG])</h2>
<h3>Soundouss Messoudi, S&#xe9;bastien Destercke, Sylvain Rousseau</h3>
<p>There are relatively few works dealing with conformal prediction for
multi-task learning issues, and this is particularly true for multi-target
regression. This paper focuses on the problem of providing valid (i.e.,
frequency calibrated) multi-variate predictions. To do so, we propose to use
copula functions applied to deep neural networks for inductive conformal
prediction. We show that the proposed method ensures efficiency and validity
for multi-target regression problems on various data sets.
</p>
<a href="http://arxiv.org/abs/2101.12002" target="_blank">arXiv:2101.12002</a> [<a href="http://arxiv.org/pdf/2101.12002" target="_blank">pdf</a>]

<h2>A Fully Rigorous Proof of the Derivation of Xavier and He's Initialization for Deep ReLU Networks. (arXiv:2101.12017v1 [cs.LG])</h2>
<h3>Quynh Nguyen</h3>
<p>A fully rigorous proof of the derivation of Xavier/He's initialization for
ReLU nets is given.
</p>
<a href="http://arxiv.org/abs/2101.12017" target="_blank">arXiv:2101.12017</a> [<a href="http://arxiv.org/pdf/2101.12017" target="_blank">pdf</a>]

<h2>BENDR: using transformers and a contrastive self-supervised learning task to learn from massive amounts of EEG data. (arXiv:2101.12037v1 [cs.LG])</h2>
<h3>Demetres Kostas, Stephane Aroca-Ouellette, Frank Rudzicz</h3>
<p>Deep neural networks (DNNs) used for brain-computer-interface (BCI)
classification are commonly expected to learn general features when trained
across a variety of contexts, such that these features could be fine-tuned to
specific contexts. While some success is found in such an approach, we suggest
that this interpretation is limited and an alternative would better leverage
the newly (publicly) available massive EEG datasets. We consider how to adapt
techniques and architectures used for language modelling (LM), that appear
capable of ingesting awesome amounts of data, towards the development of
encephalography modelling (EM) with DNNs in the same vein. We specifically
adapt an approach effectively used for automatic speech recognition, which
similarly (to LMs) uses a self-supervised training objective to learn
compressed representations of raw data signals. After adaptation to EEG, we
find that a single pre-trained model is capable of modelling completely novel
raw EEG sequences recorded with differing hardware, and different subjects
performing different tasks. Furthermore, both the internal representations of
this model and the entire architecture can be fine-tuned to a variety of
downstream BCI and EEG classification tasks, outperforming prior work in more
task-specific (sleep stage classification) self-supervision.
</p>
<a href="http://arxiv.org/abs/2101.12037" target="_blank">arXiv:2101.12037</a> [<a href="http://arxiv.org/pdf/2101.12037" target="_blank">pdf</a>]

<h2>Measuring Intelligence and Growth Rate: Variations on Hibbard's Intelligence Measure. (arXiv:2101.12047v1 [cs.AI])</h2>
<h3>Samuel Alexander, Bill Hibbard</h3>
<p>In 2011, Hibbard suggested an intelligence measure for agents who compete in
an adversarial sequence prediction game. We argue that Hibbard's idea should
actually be considered as two separate ideas: first, that the intelligence of
such agents can be measured based on the growth rates of the runtimes of the
competitors that they defeat; and second, one specific (somewhat arbitrary)
method for measuring said growth rates. Whereas Hibbard's intelligence measure
is based on the latter growth-rate-measuring method, we survey other methods
for measuring function growth rates, and exhibit the resulting Hibbard-like
intelligence measures and taxonomies. Of particular interest, we obtain
intelligence taxonomies based on Big-O and Big-Theta notation systems, which
taxonomies are novel in that they challenge conventional notions of what an
intelligence measure should look like. We discuss how intelligence measurement
of sequence predictors can indirectly serve as intelligence measurement for
agents with Artificial General Intelligence (AGIs).
</p>
<a href="http://arxiv.org/abs/2101.12047" target="_blank">arXiv:2101.12047</a> [<a href="http://arxiv.org/pdf/2101.12047" target="_blank">pdf</a>]

<h2>VAE^2: Preventing Posterior Collapse of Variational Video Predictions in the Wild. (arXiv:2101.12050v1 [cs.CV])</h2>
<h3>Yizhou Zhou, Chong Luo, Xiaoyan Sun, Zheng-Jun Zha, Wenjun Zeng</h3>
<p>Predicting future frames of video sequences is challenging due to the complex
and stochastic nature of the problem. Video prediction methods based on
variational auto-encoders (VAEs) have been a great success, but they require
the training data to contain multiple possible futures for an observed video
sequence. This is hard to be fulfilled when videos are captured in the wild
where any given observation only has a determinate future. As a result,
training a vanilla VAE model with these videos inevitably causes posterior
collapse. To alleviate this problem, we propose a novel VAE structure, dabbed
VAE-in-VAE or VAE$^2$. The key idea is to explicitly introduce stochasticity
into the VAE. We treat part of the observed video sequence as a random
transition state that bridges its past and future, and maximize the likelihood
of a Markov Chain over the video sequence under all possible transition states.
A tractable lower bound is proposed for this intractable objective function and
an end-to-end optimization algorithm is designed accordingly. VAE$^2$ can
mitigate the posterior collapse problem to a large extent, as it breaks the
direct dependence between future and observation and does not directly regress
the determinate future provided by the training data. We carry out experiments
on a large-scale dataset called Cityscapes, which contains videos collected
from a number of urban cities. Results show that VAE$^2$ is capable of
predicting diverse futures and is more resistant to posterior collapse than the
other state-of-the-art VAE-based approaches. We believe that VAE$^2$ is also
applicable to other stochastic sequence prediction problems where training data
are lack of stochasticity.
</p>
<a href="http://arxiv.org/abs/2101.12050" target="_blank">arXiv:2101.12050</a> [<a href="http://arxiv.org/pdf/2101.12050" target="_blank">pdf</a>]

<h2>Vx2Text: End-to-End Learning of Video-Based Text Generation From Multimodal Inputs. (arXiv:2101.12059v1 [cs.CV])</h2>
<h3>Xudong Lin, Gedas Bertasius, Jue Wang, Shih-Fu Chang, Devi Parikh, Lorenzo Torresani</h3>
<p>We present \textsc{Vx2Text}, a framework for text generation from multimodal
inputs consisting of video plus text, speech, or audio. In order to leverage
transformer networks, which have been shown to be effective at modeling
language, each modality is first converted into a set of language embeddings by
a learnable tokenizer. This allows our approach to perform multimodal fusion in
the language space, thus eliminating the need for ad-hoc cross-modal fusion
modules. To address the non-differentiability of tokenization on continuous
inputs (e.g., video or audio), we utilize a relaxation scheme that enables
end-to-end training. Furthermore, unlike prior encoder-only models, our network
includes an autoregressive decoder to generate open-ended text from the
multimodal embeddings fused by the language encoder. This renders our approach
fully generative and makes it directly applicable to different "video+$x$ to
text" problems without the need to design specialized network heads for each
task. The proposed framework is not only conceptually simple but also
remarkably effective: experiments demonstrate that our approach based on a
single architecture outperforms the state-of-the-art on three video-based
text-generation tasks -- captioning, question answering and audio-visual
scene-aware dialog.
</p>
<a href="http://arxiv.org/abs/2101.12059" target="_blank">arXiv:2101.12059</a> [<a href="http://arxiv.org/pdf/2101.12059" target="_blank">pdf</a>]

<h2>Autoregressive Denoising Diffusion Models for Multivariate Probabilistic Time Series Forecasting. (arXiv:2101.12072v1 [cs.LG])</h2>
<h3>Kashif Rasul, Calvin Seward, Ingmar Schuster, Roland Vollgraf</h3>
<p>In this work, we propose \texttt{TimeGrad}, an autoregressive model for
multivariate probabilistic time series forecasting which samples from the data
distribution at each time step by estimating its gradient. To this end, we use
diffusion probabilistic models, a class of latent variable models closely
connected to score matching and energy-based methods. Our model learns
gradients by optimizing a variational bound on the data likelihood and at
inference time converts white noise into a sample of the distribution of
interest through a Markov chain using Langevin sampling. We demonstrate
experimentally that the proposed autoregressive denoising diffusion model is
the new state-of-the-art multivariate probabilistic forecasting method on
real-world data sets with thousands of correlated dimensions. We hope that this
method is a useful tool for practitioners and lays the foundation for future
research in this area.
</p>
<a href="http://arxiv.org/abs/2101.12072" target="_blank">arXiv:2101.12072</a> [<a href="http://arxiv.org/pdf/2101.12072" target="_blank">pdf</a>]

<h2>Visualization of Nonlinear Programming for Robot Motion Planning. (arXiv:2101.12075v1 [cs.RO])</h2>
<h3>David H&#xe4;gele, Moataz Abdelaal, Ozgur S. Oguz, Marc Toussaint, Daniel Weiskopf</h3>
<p>Nonlinear programming targets nonlinear optimization with constraints, which
is a generic yet complex methodology involving humans for problem modeling and
algorithms for problem solving. We address the particularly hard challenge of
supporting domain experts in handling, understanding, and trouble-shooting
high-dimensional optimization with a large number of constraints. Leveraging
visual analytics, users are supported in exploring the computation process of
nonlinear constraint optimization. Our system was designed for robot motion
planning problems and developed in tight collaboration with domain experts in
nonlinear programming and robotics. We report on the experiences from this
design study, illustrate the usefulness for relevant example cases, and discuss
the extension to visual analytics for nonlinear programming in general.
</p>
<a href="http://arxiv.org/abs/2101.12075" target="_blank">arXiv:2101.12075</a> [<a href="http://arxiv.org/pdf/2101.12075" target="_blank">pdf</a>]

<h2>Generalising via Meta-Examples for Continual Learning in the Wild. (arXiv:2101.12081v1 [cs.LG])</h2>
<h3>Alessia Bertugli, Stefano Vincenzi, Simone Calderara, Andrea Passerini</h3>
<p>Learning quickly and continually is still an ambitious task for neural
networks. Indeed, many real-world applications do not reflect the learning
setting where neural networks shine, as data are usually few, mostly unlabelled
and come as a stream. To narrow this gap, we introduce FUSION - Few-shot
UnSupervIsed cONtinual learning - a novel strategy which aims to deal with
neural networks that "learn in the wild", simulating a real distribution and
flow of unbalanced tasks. We equip FUSION with MEML - Meta-Example
Meta-Learning - a new module that simultaneously alleviates catastrophic
forgetting and favours the generalisation and future learning of new tasks. To
encourage features reuse during the meta-optimisation, our model exploits a
single inner loop per task, taking advantage of an aggregated representation
achieved through the use of a self-attention mechanism. To further enhance the
generalisation capability of MEML, we extend it by adopting a technique that
creates various augmented tasks and optimises over the hardest. Experimental
results on few-shot learning benchmarks show that our model exceeds the other
baselines in both FUSION and fully supervised case. We also explore how it
behaves in standard continual learning consistently outperforming
state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2101.12081" target="_blank">arXiv:2101.12081</a> [<a href="http://arxiv.org/pdf/2101.12081" target="_blank">pdf</a>]

<h2>Fusion Moves for Graph Matching. (arXiv:2101.12085v1 [cs.CV])</h2>
<h3>Lisa Hutschenreiter, Stefan Haller, Lorenz Feineis, Carsten Rother, Dagmar Kainm&#xfc;ller, Bogdan Savchynskyy</h3>
<p>We contribute to approximate algorithms for the quadratic assignment problem
also known as graph matching. Inspired by the success of the fusion moves
technique developed for multilabel discrete Markov random fields, we
investigate its applicability to graph matching. In particular, we show how it
can be efficiently combined with the dedicated state-of-the-art Lagrange dual
methods that have recently shown superior results in computer vision and
bio-imaging applications. As our empirical evaluation on a wide variety of
graph matching datasets suggests, fusion moves notably improve performance of
these methods in terms of speed and quality of the obtained solutions. Hence,
this combination results in a state-of-the-art solver for graph matching.
</p>
<a href="http://arxiv.org/abs/2101.12085" target="_blank">arXiv:2101.12085</a> [<a href="http://arxiv.org/pdf/2101.12085" target="_blank">pdf</a>]

<h2>Learning Structural Edits via Incremental Tree Transformations. (arXiv:2101.12087v1 [cs.LG])</h2>
<h3>Ziyu Yao, Frank F. Xu, Pengcheng Yin, Huan Sun, Graham Neubig</h3>
<p>While most neural generative models generate outputs in a single pass, the
human creative process is usually one of iterative building and refinement.
Recent work has proposed models of editing processes, but these mostly focus on
editing sequential data and/or only model a single editing pass. In this paper,
we present a generic model for incremental editing of structured data (i.e.,
"structural edits"). Particularly, we focus on tree-structured data, taking
abstract syntax trees of computer programs as our canonical example. Our editor
learns to iteratively generate tree edits (e.g., deleting or adding a subtree)
and applies them to the partially edited data, thereby the entire editing
process can be formulated as consecutive, incremental tree transformations. To
show the unique benefits of modeling tree edits directly, we further propose a
novel edit encoder for learning to represent edits, as well as an imitation
learning method that allows the editor to be more robust. We evaluate our
proposed editor on two source code edit datasets, where results show that, with
the proposed edit encoder, our editor significantly improves accuracy over
previous approaches that generate the edited program directly in one pass.
Finally, we demonstrate that training our editor to imitate experts and correct
its mistakes dynamically can further improve its performance.
</p>
<a href="http://arxiv.org/abs/2101.12087" target="_blank">arXiv:2101.12087</a> [<a href="http://arxiv.org/pdf/2101.12087" target="_blank">pdf</a>]

<h2>Adversarial Machine Learning Attacks on Condition-Based Maintenance Capabilities. (arXiv:2101.12097v1 [cs.LG])</h2>
<h3>Hamidreza Habibollahi Najaf Abadi</h3>
<p>Condition-based maintenance (CBM) strategies exploit machine learning models
to assess the health status of systems based on the collected data from the
physical environment, while machine learning models are vulnerable to
adversarial attacks. A malicious adversary can manipulate the collected data to
deceive the machine learning model and affect the CBM system's performance.
Adversarial machine learning techniques introduced in the computer vision
domain can be used to make stealthy attacks on CBM systems by adding
perturbation to data to confuse trained models. The stealthy nature causes
difficulty and delay in detection of the attacks. In this paper, adversarial
machine learning in the domain of CBM is introduced. A case study shows how
adversarial machine learning can be used to attack CBM capabilities.
Adversarial samples are crafted using the Fast Gradient Sign method, and the
performance of a CBM system under attack is investigated. The obtained results
reveal that CBM systems are vulnerable to adversarial machine learning attacks
and defense strategies need to be considered.
</p>
<a href="http://arxiv.org/abs/2101.12097" target="_blank">arXiv:2101.12097</a> [<a href="http://arxiv.org/pdf/2101.12097" target="_blank">pdf</a>]

<h2>An Analysis Of Protected Health Information Leakage In Deep-Learning Based De-Identification Algorithms. (arXiv:2101.12099v1 [cs.LG])</h2>
<h3>Salman Seyedi, Li Xiong, Shamim Nemati, Gari D. Clifford</h3>
<p>The increasing complexity of algorithms for analyzing medical data, including
de-identification tasks, raises the possibility that complex algorithms are
learning not just the general representation of the problem, but specifics of
given individuals within the data. Modern legal frameworks specifically
prohibit the intentional or accidental distribution of patient data, but have
not addressed this potential avenue for leakage of such protected health
information. Modern deep learning algorithms have the highest potential of such
leakage due to complexity of the models. Recent research in the field has
highlighted such issues in non-medical data, but all analysis is likely to be
data and algorithm specific. We, therefore, chose to analyze a state-of-the-art
free-text de-identification algorithm based on LSTM (Long Short-Term Memory)
and its potential in encoding any individual in the training set. Using the
i2b2 Challenge Data, we trained, then analyzed the model to assess whether the
output of the LSTM, before the compression layer of the classifier, could be
used to estimate the membership of the training data. Furthermore, we used
different attacks including membership inference attack method to attack the
model. Results indicate that the attacks could not identify whether members of
the training data were distinguishable from non-members based on the model
output. This indicates that the model does not provide any strong evidence into
the identification of the individuals in the training data set and there is not
yet empirical evidence it is unsafe to distribute the model for general use.
</p>
<a href="http://arxiv.org/abs/2101.12099" target="_blank">arXiv:2101.12099</a> [<a href="http://arxiv.org/pdf/2101.12099" target="_blank">pdf</a>]

<h2>Increasing the Confidence of Deep Neural Networks by Coverage Analysis. (arXiv:2101.12100v1 [cs.LG])</h2>
<h3>Giulio Rossolini, Alessandro Biondi, Giorgio Carlo Buttazzo</h3>
<p>The great performance of machine learning algorithms and deep neural networks
in several perception and control tasks is pushing the industry to adopt such
technologies in safety-critical applications, as autonomous robots and
self-driving vehicles. At present, however, several issues need to be solved to
make deep learning methods more trustworthy, predictable, safe, and secure
against adversarial attacks. Although several methods have been proposed to
improve the trustworthiness of deep neural networks, most of them are tailored
for specific classes of adversarial examples, hence failing to detect other
corner cases or unsafe inputs that heavily deviate from the training samples.

This paper presents a lightweight monitoring architecture based on coverage
paradigms to enhance the model robustness against different unsafe inputs. In
particular, four coverage analysis methods are proposed and tested in the
architecture for evaluating multiple detection logics. Experimental results
show that the proposed approach is effective in detecting both powerful
adversarial examples and out-of-distribution inputs, introducing limited
extra-execution time and memory requirements.
</p>
<a href="http://arxiv.org/abs/2101.12100" target="_blank">arXiv:2101.12100</a> [<a href="http://arxiv.org/pdf/2101.12100" target="_blank">pdf</a>]

<h2>Domain Adaptation by Topology Regularization. (arXiv:2101.12102v1 [cs.CV])</h2>
<h3>Deborah Weeks, Samuel Rivera</h3>
<p>Deep learning has become the leading approach to assisted target recognition.
While these methods typically require large amounts of labeled training data,
domain adaptation (DA) or transfer learning (TL) enables these algorithms to
transfer knowledge from a labelled (source) data set to an unlabelled but
related (target) data set of interest. DA enables networks to overcome the
distribution mismatch between the source and target that leads to poor
generalization in the target domain. DA techniques align these distributions by
minimizing a divergence measurement between source and target, making the
transfer of knowledge from source to target possible. While these algorithms
have advanced significantly in recent years, most do not explicitly leverage
global data manifold structure in aligning the source and target. We propose to
leverage global data structure by applying a topological data analysis (TDA)
technique called persistent homology to TL.

In this paper, we examine the use of persistent homology in a domain
adversarial (DAd) convolutional neural network (CNN) architecture. The
experiments show that aligning persistence alone is insufficient for transfer,
but must be considered along with the lifetimes of the topological
singularities. In addition, we found that longer lifetimes indicate robust
discriminative features and more favorable structure in data. We found that
existing divergence minimization based approaches to DA improve the topological
structure, as indicated over a baseline without these regularization
techniques. We hope these experiments highlight how topological structure can
be leveraged to boost performance in TL tasks.
</p>
<a href="http://arxiv.org/abs/2101.12102" target="_blank">arXiv:2101.12102</a> [<a href="http://arxiv.org/pdf/2101.12102" target="_blank">pdf</a>]

<h2>Low Complexity Approximate Bayesian Logistic Regression for Sparse Online Learning. (arXiv:2101.12113v1 [cs.LG])</h2>
<h3>Gil I. Shamir, Wojciech Szpankowski</h3>
<p>Theoretical results show that Bayesian methods can achieve lower bounds on
regret for online logistic regression. In practice, however, such techniques
may not be feasible especially for very large feature sets. Various
approximations that, for huge sparse feature sets, diminish the theoretical
advantages, must be used. Often, they apply stochastic gradient methods with
hyper-parameters that must be tuned on some surrogate loss, defeating
theoretical advantages of Bayesian methods. The surrogate loss, defined to
approximate the mixture, requires techniques as Monte Carlo sampling,
increasing computations per example. We propose low complexity analytical
approximations for sparse online logistic and probit regressions. Unlike
variational inference and other methods, our methods use analytical closed
forms, substantially lowering computations. Unlike dense solutions, as Gaussian
Mixtures, our methods allow for sparse problems with huge feature sets without
increasing complexity. With the analytical closed forms, there is also no need
for applying stochastic gradient methods on surrogate losses, and for tuning
and balancing learning and regularization hyper-parameters. Empirical results
top the performance of the more computationally involved methods. Like such
methods, our methods still reveal per feature and per example uncertainty
measures.
</p>
<a href="http://arxiv.org/abs/2101.12113" target="_blank">arXiv:2101.12113</a> [<a href="http://arxiv.org/pdf/2101.12113" target="_blank">pdf</a>]

<h2>Model-Based Policy Search Using Monte Carlo Gradient Estimation with Real Systems Application. (arXiv:2101.12115v1 [cs.LG])</h2>
<h3>Fabio Amadio, Alberto Dalla Libera, Riccardo Antonello, Daniel Nikovski, Ruggero Carli, Diego Romeres</h3>
<p>In this paper, we present a Model-Based Reinforcement Learning algorithm
named Monte Carlo Probabilistic Inference for Learning COntrol (MC-PILCO). The
algorithm relies on Gaussian Processes (GPs) to model the system dynamics and
on a Monte Carlo approach to estimate the policy gradient. This defines a
framework in which we ablate the choice of the following components: (i) the
selection of the cost function, (ii) the optimization of policies using
dropout, (iii) an improved data efficiency through the use of structured
kernels in the GP models. The combination of the aforementioned aspects affects
dramatically the performance of MC-PILCO. Numerical comparisons in a simulated
cart-pole environment show that MC-PILCO exhibits better data-efficiency and
control performance w.r.t. state-of-the-art GP-based MBRL algorithms. Finally,
we apply MC-PILCO to real systems, considering in particular systems with
partially measurable states. We discuss the importance of modeling both the
measurement system and the state estimators during policy optimization. The
effectiveness of the proposed solutions has been tested in simulation and in
two real systems, a Furuta pendulum and a ball-and-plate.
</p>
<a href="http://arxiv.org/abs/2101.12115" target="_blank">arXiv:2101.12115</a> [<a href="http://arxiv.org/pdf/2101.12115" target="_blank">pdf</a>]

<h2>tf.data: A Machine Learning Data Processing Framework. (arXiv:2101.12127v1 [cs.LG])</h2>
<h3>Derek G. Murray, Jiri Simsa, Ana Klimovic, Ihor Indyk</h3>
<p>Training machine learning models requires feeding input data for models to
ingest. Input pipelines for machine learning jobs are often challenging to
implement efficiently as they require reading large volumes of data, applying
complex transformations, and transferring data to hardware accelerators while
overlapping computation and communication to achieve optimal performance. We
present tf.data, a framework for building and executing efficient input
pipelines for machine learning jobs. The tf.data API provides operators which
can be parameterized with user-defined computation, composed, and reused across
different machine learning domains. These abstractions allow users to focus on
the application logic of data processing, while tf.data's runtime ensures that
pipelines run efficiently.

We demonstrate that input pipeline performance is critical to the end-to-end
training time of state-of-the-art machine learning models. tf.data delivers the
high performance required, while avoiding the need for manual tuning of
performance knobs. We show that tf.data features, such as parallelism, caching,
static optimizations, and non-deterministic execution are essential for high
performance. Finally, we characterize machine learning input pipelines for
millions of jobs that ran in Google's fleet, showing that input data processing
is highly diverse and consumes a significant fraction of job resources. Our
analysis motivates future research directions, such as sharing computation
across jobs and pushing data projection to the storage layer.
</p>
<a href="http://arxiv.org/abs/2101.12127" target="_blank">arXiv:2101.12127</a> [<a href="http://arxiv.org/pdf/2101.12127" target="_blank">pdf</a>]

<h2>Self-Attention Meta-Learner for Continual Learning. (arXiv:2101.12136v1 [cs.LG])</h2>
<h3>Ghada Sokar, Decebal Constantin Mocanu, Mykola Pechenizkiy</h3>
<p>Continual learning aims to provide intelligent agents capable of learning
multiple tasks sequentially with neural networks. One of its main challenging,
catastrophic forgetting, is caused by the neural networks non-optimal ability
to learn in non-stationary distributions. In most settings of the current
approaches, the agent starts from randomly initialized parameters and is
optimized to master the current task regardless of the usefulness of the
learned representation for future tasks. Moreover, each of the future tasks
uses all the previously learned knowledge although parts of this knowledge
might not be helpful for its learning. These cause interference among tasks,
especially when the data of previous tasks is not accessible. In this paper, we
propose a new method, named Self-Attention Meta-Learner (SAM), which learns a
prior knowledge for continual learning that permits learning a sequence of
tasks, while avoiding catastrophic forgetting. SAM incorporates an attention
mechanism that learns to select the particular relevant representation for each
future task. Each task builds a specific representation branch on top of the
selected knowledge, avoiding the interference between tasks. We evaluate the
proposed method on the Split CIFAR-10/100 and Split MNIST benchmarks in the
task agnostic inference. We empirically show that we can achieve a better
performance than several state-of-the-art methods for continual learning by
building on the top of selected representation learned by SAM. We also show the
role of the meta-attention mechanism in boosting informative features
corresponding to the input data and identifying the correct target in the task
agnostic inference. Finally, we demonstrate that popular existing continual
learning methods gain a performance boost when they adopt SAM as a starting
point.
</p>
<a href="http://arxiv.org/abs/2101.12136" target="_blank">arXiv:2101.12136</a> [<a href="http://arxiv.org/pdf/2101.12136" target="_blank">pdf</a>]

<h2>Discriminative Appearance Modeling with Multi-track Pooling for Real-time Multi-object Tracking. (arXiv:2101.12159v1 [cs.CV])</h2>
<h3>Chanho Kim, Li Fuxin, Mazen Alotaibi, James M. Rehg</h3>
<p>In multi-object tracking, the tracker maintains in its memory the appearance
and motion information for each object in the scene. This memory is utilized
for finding matches between tracks and detections and is updated based on the
matching result. Many approaches model each target in isolation and lack the
ability to use all the targets in the scene to jointly update the memory. This
can be problematic when there are similar looking objects in the scene. In this
paper, we solve the problem of simultaneously considering all tracks during
memory updating, with only a small spatial overhead, via a novel multi-track
pooling module. We additionally propose a training strategy adapted to
multi-track pooling which generates hard tracking episodes online. We show that
the combination of these innovations results in a strong discriminative
appearance model, enabling the use of greedy data association to achieve online
tracking performance. Our experiments demonstrate real-time, state-of-the-art
performance on public multi-object tracking (MOT) datasets.
</p>
<a href="http://arxiv.org/abs/2101.12159" target="_blank">arXiv:2101.12159</a> [<a href="http://arxiv.org/pdf/2101.12159" target="_blank">pdf</a>]

<h2>On the Origin of Implicit Regularization in Stochastic Gradient Descent. (arXiv:2101.12176v1 [cs.LG])</h2>
<h3>Samuel L. Smith, Benoit Dherin, David G. T. Barrett, Soham De</h3>
<p>For infinitesimal learning rates, stochastic gradient descent (SGD) follows
the path of gradient flow on the full batch loss function. However moderately
large learning rates can achieve higher test accuracies, and this
generalization benefit is not explained by convergence bounds, since the
learning rate which maximizes test accuracy is often larger than the learning
rate which minimizes training loss. To interpret this phenomenon we prove that
for SGD with random shuffling, the mean SGD iterate also stays close to the
path of gradient flow if the learning rate is small and finite, but on a
modified loss. This modified loss is composed of the original loss function and
an implicit regularizer, which penalizes the norms of the minibatch gradients.
Under mild assumptions, when the batch size is small the scale of the implicit
regularization term is proportional to the ratio of the learning rate to the
batch size. We verify empirically that explicitly including the implicit
regularizer in the loss can enhance the test accuracy when the learning rate is
small.
</p>
<a href="http://arxiv.org/abs/2101.12176" target="_blank">arXiv:2101.12176</a> [<a href="http://arxiv.org/pdf/2101.12176" target="_blank">pdf</a>]

<h2>Playable Video Generation. (arXiv:2101.12195v1 [cs.CV])</h2>
<h3>Willi Menapace, St&#xe9;phane Lathuili&#xe8;re, Sergey Tulyakov, Aliaksandr Siarohin, Elisa Ricci</h3>
<p>This paper introduces the unsupervised learning problem of playable video
generation (PVG). In PVG, we aim at allowing a user to control the generated
video by selecting a discrete action at every time step as when playing a video
game. The difficulty of the task lies both in learning semantically consistent
actions and in generating realistic videos conditioned on the user input. We
propose a novel framework for PVG that is trained in a self-supervised manner
on a large dataset of unlabelled videos. We employ an encoder-decoder
architecture where the predicted action labels act as bottleneck. The network
is constrained to learn a rich action space using, as main driving loss, a
reconstruction loss on the generated video. We demonstrate the effectiveness of
the proposed approach on several datasets with wide environment variety.
Further details, code and examples are available on our project page
willi-menapace.github.io/playable-video-generation-website.
</p>
<a href="http://arxiv.org/abs/2101.12195" target="_blank">arXiv:2101.12195</a> [<a href="http://arxiv.org/pdf/2101.12195" target="_blank">pdf</a>]

<h2>Federated Multi-Armed Bandits. (arXiv:2101.12204v1 [cs.LG])</h2>
<h3>Chengshuai Shi, Cong Shen</h3>
<p>Federated multi-armed bandits (FMAB) is a new bandit paradigm that parallels
the federated learning (FL) framework in supervised learning. It is inspired by
practical applications in cognitive radio and recommender systems, and enjoys
features that are analogous to FL. This paper proposes a general framework of
FMAB and then studies two specific federated bandit models. We first study the
approximate model where the heterogeneous local models are random realizations
of the global model from an unknown distribution. This model introduces a new
uncertainty of client sampling, as the global model may not be reliably learned
even if the finite local models are perfectly known. Furthermore, this
uncertainty cannot be quantified a priori without knowledge of the
suboptimality gap. We solve the approximate model by proposing Federated Double
UCB (Fed2-UCB), which constructs a novel "double UCB" principle accounting for
uncertainties from both arm and client sampling. We show that gradually
admitting new clients is critical in achieving an O(log(T)) regret while
explicitly considering the communication cost. The exact model, where the
global bandit model is the exact average of heterogeneous local models, is then
studied as a special case. We show that, somewhat surprisingly, the
order-optimal regret can be achieved independent of the number of clients with
a careful choice of the update periodicity. Experiments using both synthetic
and real-world datasets corroborate the theoretical analysis and demonstrate
the effectiveness and efficiency of the proposed algorithms.
</p>
<a href="http://arxiv.org/abs/2101.12204" target="_blank">arXiv:2101.12204</a> [<a href="http://arxiv.org/pdf/2101.12204" target="_blank">pdf</a>]

<h2>A New Algorithmic Decision for Categorical Syllogisms via Caroll's Diagrams. (arXiv:1802.04127v4 [cs.AI] UPDATED)</h2>
<h3>Necla Kircali Gursoy, Ibrahim Senturk, Tahsin Oner, Arif Gursoy</h3>
<p>In this paper, we deal with a calculus system SLCD (Syllogistic Logic with
Carroll Diagrams), which gives a formal approach to logical reasoning with
diagrams, for representations of the fundamental Aristotelian categorical
propositions and show that they are closed under the syllogistic criterion of
inference which is the deletion of middle term. Therefore, it is implemented to
let the formalism comprise synchronically bilateral and trilateral
diagrammatical appearance and a naive algorithmic nature. And also, there is no
need specific knowledge or exclusive ability to understand as well as to use
it. Consequently, we give an effective algorithm used to determine whether a
syllogistic reasoning valid or not by using SLCD.
</p>
<a href="http://arxiv.org/abs/1802.04127" target="_blank">arXiv:1802.04127</a> [<a href="http://arxiv.org/pdf/1802.04127" target="_blank">pdf</a>]

<h2>Simulator Predictive Control: Using Learned Task Representations and MPC for Zero-Shot Generalization and Sequencing. (arXiv:1810.02422v3 [cs.RO] UPDATED)</h2>
<h3>Zhanpeng He, Ryan Julian, Eric Heiden, Hejia Zhang, Stefan Schaal, Joseph J. Lim, Gaurav Sukhatme, Karol Hausman</h3>
<p>Simulation-to-real transfer is an important strategy for making reinforcement
learning practical with real robots. Successful sim-to-real transfer systems
have difficulty producing policies which generalize across tasks, despite
training for thousands of hours equivalent real robot time. To address this
shortcoming, we present a novel approach to efficiently learning new robotic
skills directly on a real robot, based on model-predictive control (MPC) and an
algorithm for learning task representations. In short, we show how to reuse the
simulation from the pre-training step of sim-to-real methods as a tool for
foresight, allowing the sim-to-real policy adapt to unseen tasks. Rather than
end-to-end learning policies for single tasks and attempting to transfer them,
we first use simulation to simultaneously learn (1) a continuous
parameterization (i.e. a skill embedding or latent) of task-appropriate
primitive skills, and (2) a single policy for these skills which is conditioned
on this representation. We then directly transfer our multi-skill policy to a
real robot, and actuate the robot by choosing sequences of skill latents which
actuate the policy, with each latent corresponding to a pre-learned primitive
skill controller. We complete unseen tasks by choosing new sequences of skill
latents to control the robot using MPC, where our MPC model is composed of the
pre-trained skill policy executed in the simulation environment, run in
parallel with the real robot. We discuss the background and principles of our
method, detail its practical implementation, and evaluate its performance by
using our method to train a real Sawyer Robot to achieve motion tasks such as
drawing and block pushing.
</p>
<a href="http://arxiv.org/abs/1810.02422" target="_blank">arXiv:1810.02422</a> [<a href="http://arxiv.org/pdf/1810.02422" target="_blank">pdf</a>]

<h2>A proof of convergence of multi-class logistic regression network. (arXiv:1903.12600v4 [stat.ML] UPDATED)</h2>
<h3>Marek Rychlik</h3>
<p>This paper revisits the special type of a neural network known under two
names. In the statistics and machine learning community it is known as a
multi-class logistic regression neural network. In the neural network
community, it is simply the soft-max layer. The importance is underscored by
its role in deep learning: as the last layer, whose autput is actually the
classification of the input patterns, such as images. Our exposition focuses on
mathematically rigorous derivation of the key equation expressing the gradient.
The fringe benefit of our approach is a fully vectorized expression, which is a
basis of an efficient implementation. The second result of this paper is the
positivity of the second derivative of the cross-entropy loss function as
function of the weights. This result proves that optimization methods based on
convexity may be used to train this network. As a corollary, we demonstrate
that no $L^2$-regularizer is needed to guarantee convergence of gradient
descent.
</p>
<a href="http://arxiv.org/abs/1903.12600" target="_blank">arXiv:1903.12600</a> [<a href="http://arxiv.org/pdf/1903.12600" target="_blank">pdf</a>]

<h2>Exchangeable deep neural networks for set-to-set matching and learning. (arXiv:1910.09972v2 [cs.CV] UPDATED)</h2>
<h3>Yuki Saito, Takuma Nakamura, Hirotaka Hachiya, Kenji Fukumizu</h3>
<p>Matching two different sets of items, called heterogeneous set-to-set
matching problem, has recently received attention as a promising problem. The
difficulties are to extract features to match a correct pair of different sets
and also preserve two types of exchangeability required for set-to-set
matching: the pair of sets, as well as the items in each set, should be
exchangeable. In this study, we propose a novel deep learning architecture to
address the abovementioned difficulties and also an efficient training
framework for set-to-set matching. We evaluate the methods through experiments
based on two industrial applications: fashion set recommendation and group
re-identification. In these experiments, we show that the proposed method
provides significant improvements and results compared with the
state-of-the-art methods, thereby validating our architecture for the
heterogeneous set matching problem.
</p>
<a href="http://arxiv.org/abs/1910.09972" target="_blank">arXiv:1910.09972</a> [<a href="http://arxiv.org/pdf/1910.09972" target="_blank">pdf</a>]

<h2>The Generalization Error of the Minimum-norm Solutions for Over-parameterized Neural Networks. (arXiv:1912.06987v2 [stat.ML] UPDATED)</h2>
<h3>Weinan E, Chao Ma, Lei Wu</h3>
<p>We study the generalization properties of minimum-norm solutions for three
over-parametrized machine learning models including the random feature model,
the two-layer neural network model and the residual network model. We proved
that for all three models, the generalization error for the minimum-norm
solution is comparable to the Monte Carlo rate, up to some logarithmic terms,
as long as the models are sufficiently over-parametrized.
</p>
<a href="http://arxiv.org/abs/1912.06987" target="_blank">arXiv:1912.06987</a> [<a href="http://arxiv.org/pdf/1912.06987" target="_blank">pdf</a>]

<h2>Learning Spatiotemporal Features via Video and Text Pair Discrimination. (arXiv:2001.05691v3 [cs.CV] UPDATED)</h2>
<h3>Tianhao Li, Limin Wang</h3>
<p>Current video representations heavily rely on learning from manually
annotated video datasets which are time-consuming and expensive to acquire. We
observe videos are naturally accompanied by abundant text information such as
YouTube titles and Instagram captions. In this paper, we leverage this
visual-textual connection to learn spatiotemporal features in an efficient
weakly-supervised manner. We present a general cross-modal pair discrimination
(CPD) framework to capture this correlation between a video and its associated
text. Specifically, we adopt noise-contrastive estimation to tackle the
computational issue imposed by the huge amount of pair instance classes and
design a practical curriculum learning strategy. We train our CPD models on
both standard video dataset (Kinetics-210k) and uncurated web video dataset
(Instagram-300k) to demonstrate its effectiveness. Without further fine-tuning,
the learnt models obtain competitive results for action classification on
Kinetics under the linear classification protocol. Moreover, our visual model
provides an effective initialization to fine-tune on downstream tasks, which
yields a remarkable performance gain for action recognition on UCF101 and
HMDB51, compared with the existing state-of-the-art self-supervised training
methods. In addition, our CPD model yields a new state of the art for zero-shot
action recognition on UCF101 by directly utilizing the learnt visual-textual
embeddings. The code will be made available at
https://github.com/MCG-NJU/CPD-Video.
</p>
<a href="http://arxiv.org/abs/2001.05691" target="_blank">arXiv:2001.05691</a> [<a href="http://arxiv.org/pdf/2001.05691" target="_blank">pdf</a>]

<h2>Graph-based Interpolation of Feature Vectors for Accurate Few-Shot Classification. (arXiv:2001.09849v4 [cs.LG] UPDATED)</h2>
<h3>Yuqing Hu, Vincent Gripon, St&#xe9;phane Pateux</h3>
<p>In few-shot classification, the aim is to learn models able to discriminate
classes using only a small number of labeled examples. In this context, works
have proposed to introduce Graph Neural Networks (GNNs) aiming at exploiting
the information contained in other samples treated concurrently, what is
commonly referred to as the transductive setting in the literature. These GNNs
are trained all together with a backbone feature extractor. In this paper, we
propose a new method that relies on graphs only to interpolate feature vectors
instead, resulting in a transductive learning setting with no additional
parameters to train. Our proposed method thus exploits two levels of
information: a) transfer features obtained on generic datasets, b) transductive
information obtained from other samples to be classified. Using standard
few-shot vision classification datasets, we demonstrate its ability to bring
significant gains compared to other works.
</p>
<a href="http://arxiv.org/abs/2001.09849" target="_blank">arXiv:2001.09849</a> [<a href="http://arxiv.org/pdf/2001.09849" target="_blank">pdf</a>]

<h2>AutoFCL: Automatically Tuning Fully Connected Layers for Handling Small Dataset. (arXiv:2001.11951v4 [cs.CV] UPDATED)</h2>
<h3>S.H.Shabbeer Basha, Sravan Kumar Vinakota, Shiv Ram Dubey, Viswanath Pulabaigari, Snehasis Mukherjee</h3>
<p>Deep Convolutional Neural Networks (CNN) have evolved as popular machine
learning models for image classification during the past few years, due to
their ability to learn the problem-specific features directly from the input
images. The success of deep learning models solicits architecture engineering
rather than hand-engineering the features. However, designing state-of-the-art
CNN for a given task remains a non-trivial and challenging task, especially
when training data size is less. To address this phenomena, transfer learning
has been used as a popularly adopted technique. While transferring the learned
knowledge from one task to another, fine-tuning with the target-dependent Fully
Connected (FC) layers generally produces better results over the target task.
In this paper, the proposed AutoFCL model attempts to learn the structure of FC
layers of a CNN automatically using Bayesian optimization. To evaluate the
performance of the proposed AutoFCL, we utilize five pre-trained CNN models
such as VGG-16, ResNet, DenseNet, MobileNet, and NASNetMobile. The experiments
are conducted on three benchmark datasets, namely CalTech-101, Oxford-102
Flowers, and UC Merced Land Use datasets. Fine-tuning the newly learned
(target-dependent) FC layers leads to state-of-the-art performance, according
to the experiments carried out in this research. The proposed AutoFCL method
outperforms the existing methods over CalTech-101 and Oxford-102 Flowers
datasets by achieving the accuracy of 94.38% and 98.89%, respectively. However,
our method achieves comparable performance on the UC Merced Land Use dataset
with 96.83% accuracy. The source codes of this research are available at
https://github.com/shabbeersh/AutoFCL.
</p>
<a href="http://arxiv.org/abs/2001.11951" target="_blank">arXiv:2001.11951</a> [<a href="http://arxiv.org/pdf/2001.11951" target="_blank">pdf</a>]

<h2>On Calibration of Mixup Training for Deep Neural Networks. (arXiv:2003.09946v4 [cs.LG] UPDATED)</h2>
<h3>Juan Maro&#xf1;as, Daniel Ramos, Roberto Paredes</h3>
<p>Deep Neural Networks (DNN) represent the state of the art in many tasks.
However, due to their overparameterization, their generalization capabilities
are in doubt and still a field under study. Consequently, DNN can overfit and
assign overconfident predictions -- effects that have been shown to affect the
calibration of the confidences assigned to unseen data. Data Augmentation (DA)
strategies have been proposed to regularize these models, being Mixup one of
the most popular due to its ability to improve the accuracy, the uncertainty
quantification and the calibration of DNN. In this work however we argue and
provide empirical evidence that, due to its fundamentals, Mixup does not
necessarily improve calibration. Based on our observations we propose a new
loss function that improves the calibration, and also sometimes the accuracy,
of DNN trained with this DA technique. Our loss is inspired by Bayes decision
theory and introduces a new training framework for designing losses for
probabilistic modelling. We provide state-of-the-art accuracy with consistent
improvements in calibration performance. Appendix and code are provided here:
https://github.com/jmaronas/calibration_MixupDNN_ARCLoss.pytorch.git
</p>
<a href="http://arxiv.org/abs/2003.09946" target="_blank">arXiv:2003.09946</a> [<a href="http://arxiv.org/pdf/2003.09946" target="_blank">pdf</a>]

<h2>Synergic Adversarial Label Learning with DR and AMD for Retinal Image Grading. (arXiv:2003.10607v3 [cs.CV] UPDATED)</h2>
<h3>Lie Ju, Xin Wang, Xin Zhao, Huimin Lu, Dwarikanath Mahapatra, Paul Bonnington, Zongyuan Ge</h3>
<p>The need for comprehensive and automated screening methods for retinal image
classification has long been recognized. Well-qualified doctors annotated
images are very expensive and only a limited amount of data is available for
various retinal diseases such as age-related macular degeneration (AMD) and
diabetic retinopathy (DR). Some studies show that AMD and DR share some common
features like hemorrhagic points and exudation but most classification
algorithms only train those disease models independently. Inspired by knowledge
distillation where additional monitoring signals from various sources is
beneficial to train a robust model with much fewer data. We propose a method
called synergic adversarial label learning (SALL) which leverages relevant
retinal disease labels in both semantic and feature space as additional signals
and train the model in a collaborative manner. Our experiments on DR and AMD
fundus image classification task demonstrate that the proposed method can
significantly improve the accuracy of the model for grading diseases. In
addition, we conduct additional experiments to show the effectiveness of SALL
from the aspects of reliability and interpretability in the context of medical
imaging application.
</p>
<a href="http://arxiv.org/abs/2003.10607" target="_blank">arXiv:2003.10607</a> [<a href="http://arxiv.org/pdf/2003.10607" target="_blank">pdf</a>]

<h2>Fashion Meets Computer Vision: A Survey. (arXiv:2003.13988v2 [cs.CV] UPDATED)</h2>
<h3>Wen-Huang Cheng, Sijie Song, Chieh-Yun Chen, Shintami Chusnul Hidayati, Jiaying Liu</h3>
<p>Fashion is the way we present ourselves to the world and has become one of
the world's largest industries. Fashion, mainly conveyed by vision, has thus
attracted much attention from computer vision researchers in recent years.
Given the rapid development, this paper provides a comprehensive survey of more
than 200 major fashion-related works covering four main aspects for enabling
intelligent fashion: (1) Fashion detection includes landmark detection, fashion
parsing, and item retrieval, (2) Fashion analysis contains attribute
recognition, style learning, and popularity prediction, (3) Fashion synthesis
involves style transfer, pose transformation, and physical simulation, and (4)
Fashion recommendation comprises fashion compatibility, outfit matching, and
hairstyle suggestion. For each task, the benchmark datasets and the evaluation
protocols are summarized. Furthermore, we highlight promising directions for
future research.
</p>
<a href="http://arxiv.org/abs/2003.13988" target="_blank">arXiv:2003.13988</a> [<a href="http://arxiv.org/pdf/2003.13988" target="_blank">pdf</a>]

<h2>NBDT: Neural-Backed Decision Trees. (arXiv:2004.00221v3 [cs.CV] UPDATED)</h2>
<h3>Alvin Wan, Lisa Dunlap, Daniel Ho, Jihan Yin, Scott Lee, Henry Jin, Suzanne Petryk, Sarah Adel Bargal, Joseph E. Gonzalez</h3>
<p>Machine learning applications such as finance and medicine demand accurate
and justifiable predictions, barring most deep learning methods from use. In
response, previous work combines decision trees with deep learning, yielding
models that (1) sacrifice interpretability for accuracy or (2) sacrifice
accuracy for interpretability. We forgo this dilemma by jointly improving
accuracy and interpretability using Neural-Backed Decision Trees (NBDTs). NBDTs
replace a neural network's final linear layer with a differentiable sequence of
decisions and a surrogate loss. This forces the model to learn high-level
concepts and lessens reliance on highly-uncertain decisions, yielding (1)
accuracy: NBDTs match or outperform modern neural networks on CIFAR, ImageNet
and better generalize to unseen classes by up to 16%. Furthermore, our
surrogate loss improves the original model's accuracy by up to 2%. NBDTs also
afford (2) interpretability: improving human trustby clearly identifying model
mistakes and assisting in dataset debugging. Code and pretrained NBDTs are at
https://github.com/alvinwan/neural-backed-decision-trees.
</p>
<a href="http://arxiv.org/abs/2004.00221" target="_blank">arXiv:2004.00221</a> [<a href="http://arxiv.org/pdf/2004.00221" target="_blank">pdf</a>]

<h2>Revisiting visual-inertial structure from motion for odometry and SLAM initialization. (arXiv:2006.06017v2 [cs.CV] UPDATED)</h2>
<h3>Georgios Evangelidis, Branislav Micusik</h3>
<p>In this paper, an efficient closed-form solution for the state initialization
in visual-inertial odometry (VIO) and simultaneous localization and mapping
(SLAM) is presented. Unlike the state-of-the-art, we do not derive linear
equations from triangulating pairs of point observations. Instead, we build on
a direct triangulation of the unknown $3D$ point paired with each of its
observations. We show and validate the high impact of such a simple difference.
The resulting linear system has a simpler structure and the solution through
analytic elimination only requires solving a $6\times 6$ linear system (or $9
\times 9$ when accelerometer bias is included). In addition, all the
observations of every scene point are jointly related, thereby leading to a
less biased and more robust solution. The proposed formulation attains up to
$50$ percent decreased velocity and point reconstruction error compared to the
standard closed-form solver, while it is $4\times$ faster for a $7$-frame set.
Apart from the inherent efficiency, fewer iterations are needed by any further
non-linear refinement thanks to better parameter initialization. In this
context, we provide the analytic Jacobians for a non-linear optimizer that
optionally refines the initial parameters. The superior performance of the
proposed solver is established by quantitative comparisons with the
state-of-the-art solver.
</p>
<a href="http://arxiv.org/abs/2006.06017" target="_blank">arXiv:2006.06017</a> [<a href="http://arxiv.org/pdf/2006.06017" target="_blank">pdf</a>]

<h2>Fair clustering via equitable group representations. (arXiv:2006.11009v2 [cs.LG] UPDATED)</h2>
<h3>Mohsen Abbasi, Aditya Bhaskara, Suresh Venkatasubramanian</h3>
<p>What does it mean for a clustering to be fair? One popular approach seeks to
ensure that each cluster contains groups in (roughly) the same proportion in
which they exist in the population. The normative principle at play is balance:
any cluster might act as a representative of the data, and thus should reflect
its diversity.

But clustering also captures a different form of representativeness. A core
principle in most clustering problems is that a cluster center should be
representative of the cluster it represents, by being "close" to the points
associated with it. This is so that we can effectively replace the points by
their cluster centers without significant loss in fidelity, and indeed is a
common "use case" for clustering. For such a clustering to be fair, the centers
should "represent" different groups equally well. We call such a clustering a
group-representative clustering.

In this paper, we study the structure and computation of group-representative
clusterings. We show that this notion naturally parallels the development of
fairness notions in classification, with direct analogs of ideas like
demographic parity and equal opportunity. We demonstrate how these notions are
distinct from and cannot be captured by balance-based notions of fairness. We
present approximation algorithms for group representative $k$-median clustering
and couple this with an empirical evaluation on various real-world data sets.
</p>
<a href="http://arxiv.org/abs/2006.11009" target="_blank">arXiv:2006.11009</a> [<a href="http://arxiv.org/pdf/2006.11009" target="_blank">pdf</a>]

<h2>Free-rider Attacks on Model Aggregation in Federated Learning. (arXiv:2006.11901v2 [cs.LG] UPDATED)</h2>
<h3>Yann Fraboni, Richard Vidal, Marco Lorenzi</h3>
<p>Free-rider attacks against federated learning consist in dissimulating
participation to the federated learning process with the goal of obtaining the
final aggregated model without actually contributing with any data. This kind
of attacks is critical in sensitive applications of federated learning, where
data is scarce and the model has high commercial value. We introduce here the
first theoretical and experimental analysis of free-rider attacks on federated
learning schemes based on iterative parameters aggregation, such as FedAvg or
FedProx, and provide formal guarantees for these attacks to converge to the
aggregated models of the fair participants. We first show that a
straightforward implementation of this attack can be simply achieved by not
updating the local parameters during the iterative federated optimization. As
this attack can be detected by adopting simple countermeasures at the server
level, we subsequently study more complex disguising schemes based on
stochastic updates of the free-rider parameters. We demonstrate the proposed
strategies on a number of experimental scenarios, in both iid and non-iid
settings. We conclude by providing recommendations to avoid free-rider attacks
in real world applications of federated learning, especially in sensitive
domains where security of data and models is critical.
</p>
<a href="http://arxiv.org/abs/2006.11901" target="_blank">arXiv:2006.11901</a> [<a href="http://arxiv.org/pdf/2006.11901" target="_blank">pdf</a>]

<h2>Detecting Malicious Accounts in Permissionless Blockchains using Temporal Graph Properties. (arXiv:2007.05169v2 [cs.LG] UPDATED)</h2>
<h3>Rachit Agarwal, Shikhar Barve, Sandeep K. Shukla</h3>
<p>The temporal nature of modeling accounts as nodes and transactions as
directed edges in a directed graph -- for a blockchain, enables us to
understand the behavior (malicious or benign) of the accounts. Predictive
classification of accounts as malicious or benign could help users of the
permissionless blockchain platforms to operate in a secure manner. Motivated by
this, we introduce temporal features such as burst and attractiveness on top of
several already used graph properties such as the node degree and clustering
coefficient. Using identified features, we train various Machine Learning (ML)
algorithms and identify the algorithm that performs the best in detecting which
accounts are malicious. We then study the behavior of the accounts over
different temporal granularities of the dataset before assigning them malicious
tags. For Ethereum blockchain, we identify that for the entire dataset - the
ExtraTreesClassifier performs the best among supervised ML algorithms. On the
other hand, using cosine similarity on top of the results provided by
unsupervised ML algorithms such as K-Means on the entire dataset, we were able
to detect 554 more suspicious accounts. Further, using behavior change analysis
for accounts, we identify 814 unique suspicious accounts across different
temporal granularities.
</p>
<a href="http://arxiv.org/abs/2007.05169" target="_blank">arXiv:2007.05169</a> [<a href="http://arxiv.org/pdf/2007.05169" target="_blank">pdf</a>]

<h2>FADACS: A Few-shot Adversarial Domain Adaptation Architecture for Context-Aware Parking Availability Sensing. (arXiv:2007.08551v2 [cs.LG] UPDATED)</h2>
<h3>Wei Shao, Sichen Zhao, Zhen Zhang, Shiyu Wang, Mohammad Saiedur Rahaman, Andy Song, Flora Dilys Salim</h3>
<p>Existing research on parking availability sensing mainly relies on extensive
contextual and historical information. In practice, the availability of such
information is a challenge as it requires continuous collection of sensory
signals. In this study, we design an end-to-end transfer learning framework for
parking availability sensing to predict parking occupancy in areas in which the
parking data is insufficient to feed into data-hungry models. This framework
overcomes two main challenges: 1) many real-world cases cannot provide enough
data for most existing data-driven models, and 2) it is difficult to merge
sensor data and heterogeneous contextual information due to the differing urban
fabric and spatial characteristics. Our work adopts a widely-used concept,
adversarial domain adaptation, to predict the parking occupancy in an area
without abundant sensor data by leveraging data from other areas with similar
features. In this paper, we utilise more than 35 million parking data records
from sensors placed in two different cities, one a city centre and the other a
coastal tourist town. We also utilise heterogeneous spatio-temporal contextual
information from external resources, including weather and points of interest.
We quantify the strength of our proposed framework in different cases and
compare it to the existing data-driven approaches. The results show that the
proposed framework is comparable to existing state-of-the-art methods and also
provide some valuable insights on parking availability prediction.
</p>
<a href="http://arxiv.org/abs/2007.08551" target="_blank">arXiv:2007.08551</a> [<a href="http://arxiv.org/pdf/2007.08551" target="_blank">pdf</a>]

<h2>Moving fast and slow: Analysis of representations and post-processing in speech-driven automatic gesture generation. (arXiv:2007.09170v3 [cs.CV] UPDATED)</h2>
<h3>Taras Kucherenko, Dai Hasegawa, Naoshi Kaneko, Gustav Eje Henter, Hedvig Kjellstr&#xf6;m</h3>
<p>This paper presents a novel framework for speech-driven gesture production,
applicable to virtual agents to enhance human-computer interaction.
Specifically, we extend recent deep-learning-based, data-driven methods for
speech-driven gesture generation by incorporating representation learning. Our
model takes speech as input and produces gestures as output, in the form of a
sequence of 3D coordinates. We provide an analysis of different representations
for the input (speech) and the output (motion) of the network by both objective
and subjective evaluations. We also analyse the importance of smoothing of the
produced motion. Our results indicated that the proposed method improved on our
baseline in terms of objective measures. For example, it better captured the
motion dynamics and better matched the motion-speed distribution. Moreover, we
performed user studies on two different datasets. The studies confirmed that
our proposed method is perceived as more natural than the baseline, although
the difference in the studies was eliminated by appropriate post-processing:
hip-centering and smoothing. We conclude that it is important to take both
motion representation and post-processing into account when designing an
automatic gesture-production method.
</p>
<a href="http://arxiv.org/abs/2007.09170" target="_blank">arXiv:2007.09170</a> [<a href="http://arxiv.org/pdf/2007.09170" target="_blank">pdf</a>]

<h2>Nonclosedness of Sets of Neural Networks in Sobolev Spaces. (arXiv:2007.11730v4 [stat.ML] UPDATED)</h2>
<h3>Scott Mahan, Emily King, Alex Cloninger</h3>
<p>We examine the closedness of sets of realized neural networks of a fixed
architecture in Sobolev spaces. For an exactly $m$-times differentiable
activation function $\rho$, we construct a sequence of neural networks
$(\Phi_n)_{n \in \mathbb{N}}$ whose realizations converge in order-$(m-1)$
Sobolev norm to a function that cannot be realized exactly by a neural network.
Thus, sets of realized neural networks are not closed in order-$(m-1)$ Sobolev
spaces $W^{m-1,p}$ for $p \in [1,\infty]$. We further show that these sets are
not closed in $W^{m,p}$ under slightly stronger conditions on the $m$-th
derivative of $\rho$. For a real analytic activation function, we show that
sets of realized neural networks are not closed in $W^{k,p}$ for any $k \in
\mathbb{N}$. The nonclosedness allows for approximation of non-network target
functions with unbounded parameter growth. We partially characterize the rate
of parameter growth for most activation functions by showing that a specific
sequence of realized neural networks can approximate the activation function's
derivative with weights increasing inversely proportional to the $L^p$
approximation error. Finally, we present experimental results showing that
networks are capable of closely approximating non-network target functions with
increasing parameters via training.
</p>
<a href="http://arxiv.org/abs/2007.11730" target="_blank">arXiv:2007.11730</a> [<a href="http://arxiv.org/pdf/2007.11730" target="_blank">pdf</a>]

<h2>Pseudoinverse Graph Convolutional Networks: Fast Filters Tailored for Large Eigengaps of Dense Graphs and Hypergraphs. (arXiv:2008.00720v2 [cs.LG] UPDATED)</h2>
<h3>Dominik Alfke, Martin Stoll</h3>
<p>Graph Convolutional Networks (GCNs) have proven to be successful tools for
semi-supervised classification on graph-based datasets. We propose a new GCN
variant whose three-part filter space is targeted at dense graphs. Examples
include Gaussian graphs for 3D point clouds with an increased focus on
non-local information, as well as hypergraphs based on categorical data. These
graphs differ from the common sparse benchmark graphs in terms of the spectral
properties of their graph Laplacian. Most notably we observe large eigengaps,
which are unfavorable for popular existing GCN architectures. Our method
overcomes these issues by utilizing the pseudoinverse of the Laplacian. Another
key ingredient is a low-rank approximation of the convolutional matrix,
ensuring computational efficiency and increasing accuracy at the same time. We
outline how the necessary eigeninformation can be computed efficiently in each
applications and discuss the appropriate choice of the only metaparameter, the
approximation rank. We finally showcase our method's performance regarding
runtime and accuracy in various experiments with real-world datasets.
</p>
<a href="http://arxiv.org/abs/2008.00720" target="_blank">arXiv:2008.00720</a> [<a href="http://arxiv.org/pdf/2008.00720" target="_blank">pdf</a>]

<h2>Local error quantification for Neural Network Differential Equation solvers. (arXiv:2008.12190v3 [cs.LG] UPDATED)</h2>
<h3>Akshunna S. Dogra, William T Redman</h3>
<p>Neural networks have been identified as powerful tools for the study of
complex systems. A noteworthy example is the neural network differential
equation (NN DE) solver, which can provide functional approximations to the
solutions of a wide variety of differential equations. Such solvers produce
robust functional expressions, are well suited for further manipulations on the
quantities of interest (for example, taking derivatives), and capable of
leveraging the modern advances in parallelization and computing power. However,
there is a lack of work on the role precise error quantification can play in
their predictions: usually, the focus is on ambiguous and/or global measures of
performance like the loss function and/or obtaining global bounds on the errors
associated with the predictions. Precise, local error quantification is seldom
possible without external means or outright knowledge of the true solution. We
address these concerns in the context of dynamical system NN DE solvers,
leveraging learnt information within the NN DE solvers to develop methods that
allow them to be more accurate and efficient, while still pursuing an
unsupervised approach that does not rely on external tools or data. We achieve
this via methods that can precisely estimate NN DE solver prediction errors
point-wise, thus allowing the user the capacity for efficient and targeted
error correction. We exemplify the utility of our methods by testing them on a
nonlinear and a chaotic system each.
</p>
<a href="http://arxiv.org/abs/2008.12190" target="_blank">arXiv:2008.12190</a> [<a href="http://arxiv.org/pdf/2008.12190" target="_blank">pdf</a>]

<h2>A Hybrid PAC Reinforcement Learning Algorithm. (arXiv:2009.02602v2 [cs.LG] UPDATED)</h2>
<h3>Ashkan Zehfroosh, Herbert G. Tanner</h3>
<p>This paper offers a new hybrid probably approximately correct (PAC)
reinforcement learning (RL) algorithm for Markov decision processes (MDPs) that
intelligently maintains favorable features of its parents. The designed
algorithm, referred to as the Dyna-Delayed Q-learning (DDQ) algorithm, combines
model-free and model-based learning approaches while outperforming both in most
cases. The paper includes a PAC analysis of the DDQ algorithm and a derivation
of its sample complexity. Numerical results are provided to support the claim
regarding the new algorithm's sample efficiency compared to its parents as well
as the best known model-free and model-based algorithms in application.
</p>
<a href="http://arxiv.org/abs/2009.02602" target="_blank">arXiv:2009.02602</a> [<a href="http://arxiv.org/pdf/2009.02602" target="_blank">pdf</a>]

<h2>Quantifying Explainability of Saliency Methods in Deep Neural Networks. (arXiv:2009.02899v2 [cs.CV] UPDATED)</h2>
<h3>Erico Tjoa, Cuntai Guan</h3>
<p>One way to achieve eXplainable artificial intelligence (XAI) is through the
use of post-hoc analysis methods. In particular, methods that generate heatmaps
have been used to explain black-box models, such as deep neural network. In
some cases, heatmaps are appealing due to the intuitive and visual ways to
understand them. However, quantitative analysis that demonstrates the actual
potential of heatmaps have been lacking, and comparison between different
methods are not standardized as well. In this paper, we introduce a synthetic
dataset that can be generated adhoc along with the ground-truth heatmaps for
better quantitative assessment. Each sample data is an image of a cell with
easily distinguishable features, facilitating a more transparent assessment of
different XAI methods. Comparison and recommendations are made, shortcomings
are clarified along with suggestions for future research directions to handle
the finer details of select post-hoc analysis methods.
</p>
<a href="http://arxiv.org/abs/2009.02899" target="_blank">arXiv:2009.02899</a> [<a href="http://arxiv.org/pdf/2009.02899" target="_blank">pdf</a>]

<h2>Physical Exercise Recommendation and Success Prediction Using Interconnected Recurrent Neural Networks. (arXiv:2010.00482v2 [cs.LG] UPDATED)</h2>
<h3>Arash Mahyari, Peter Pirolli</h3>
<p>Unhealthy behaviors, e.g., physical inactivity and unhealthful food choice,
are the primary healthcare cost drivers in developed countries. Pervasive
computational, sensing, and communication technology provided by smartphones
and smartwatches have made it possible to support individuals in their everyday
lives to develop healthier lifestyles. In this paper, we propose an exercise
recommendation system that also predicts individual success rates. The system,
consisting of two inter-connected recurrent neural networks (RNNs), uses the
history of workouts to recommend the next workout activity for each individual.
The system then predicts the probability of successful completion of the
predicted activity by the individual. The prediction accuracy of this
interconnected-RNN model is assessed on previously published data from a
four-week mobile health experiment and is shown to improve upon previous
predictions from a computational cognitive model.
</p>
<a href="http://arxiv.org/abs/2010.00482" target="_blank">arXiv:2010.00482</a> [<a href="http://arxiv.org/pdf/2010.00482" target="_blank">pdf</a>]

<h2>Is Model-Free Learning Nearly Optimal for Non-Stationary RL?. (arXiv:2010.03161v2 [cs.LG] UPDATED)</h2>
<h3>Weichao Mao, Kaiqing Zhang, Ruihao Zhu, David Simchi-Levi, Tamer Ba&#x15f;ar</h3>
<p>We consider model-free reinforcement learning (RL) in non-stationary Markov
decision processes. Both the reward functions and the state transition
functions are allowed to vary arbitrarily over time as long as their cumulative
variations do not exceed certain variation budgets. We propose Restarted
Q-Learning with Upper Confidence Bounds (RestartQ-UCB), the first model-free
algorithm for non-stationary RL, and show that it outperforms existing
solutions in terms of dynamic regret. Specifically, RestartQ-UCB with
Freedman-type bonus terms achieves a dynamic regret bound of
$\widetilde{O}(S^{\frac{1}{3}} A^{\frac{1}{3}} \Delta^{\frac{1}{3}} H
T^{\frac{2}{3}})$, where $S$ and $A$ are the numbers of states and actions,
respectively, $\Delta&gt;0$ is the variation budget, $H$ is the number of time
steps per episode, and $T$ is the total number of time steps. We further show
that our algorithm is \emph{nearly optimal} by establishing an
information-theoretical lower bound of $\Omega(S^{\frac{1}{3}} A^{\frac{1}{3}}
\Delta^{\frac{1}{3}} H^{\frac{2}{3}} T^{\frac{2}{3}})$, the first lower bound
in non-stationary RL. Numerical experiments validate the advantages of
RestartQ-UCB in terms of both cumulative rewards and computational efficiency.
We further demonstrate the power of our results in the context of multi-agent
RL, where non-stationarity is a key challenge.
</p>
<a href="http://arxiv.org/abs/2010.03161" target="_blank">arXiv:2010.03161</a> [<a href="http://arxiv.org/pdf/2010.03161" target="_blank">pdf</a>]

<h2>Revisiting Batch Normalization for Improving Corruption Robustness. (arXiv:2010.03630v4 [cs.CV] UPDATED)</h2>
<h3>Philipp Benz, Chaoning Zhang, Adil Karjauv, In So Kweon</h3>
<p>The performance of DNNs trained on clean images has been shown to decrease
when the test images have common corruptions. In this work, we interpret
corruption robustness as a domain shift and propose to rectify batch
normalization (BN) statistics for improving model robustness. This is motivated
by perceiving the shift from the clean domain to the corruption domain as a
style shift that is represented by the BN statistics. We find that simply
estimating and adapting the BN statistics on a few (32 for instance)
representation samples, without retraining the model, improves the corruption
robustness by a large margin on several benchmark datasets with a wide range of
model architectures. For example, on ImageNet-C, statistics adaptation improves
the top1 accuracy of ResNet50 from 39.2% to 48.7%. Moreover, we find that this
technique can further improve state-of-the-art robust models from 58.1% to
63.3%.
</p>
<a href="http://arxiv.org/abs/2010.03630" target="_blank">arXiv:2010.03630</a> [<a href="http://arxiv.org/pdf/2010.03630" target="_blank">pdf</a>]

<h2>A general approach to compute the relevance of middle-level input features. (arXiv:2010.08639v2 [cs.LG] UPDATED)</h2>
<h3>Andrea Apicella, Salvatore Giugliano, Francesco Isgr&#xf2;, Roberto Prevete</h3>
<p>This work proposes a novel general framework, in the context of eXplainable
Artificial Intelligence (XAI), to construct explanations for the behaviour of
Machine Learning (ML) models in terms of middle-level features. One can isolate
two different ways to provide explanations in the context of XAI: low and
middle-level explanations. Middle-level explanations have been introduced for
alleviating some deficiencies of low-level explanations such as, in the context
of image classification, the fact that human users are left with a significant
interpretive burden: starting from low-level explanations, one has to identify
properties of the overall input that are perceptually salient for the human
visual system. However, a general approach to correctly evaluate the elements
of middle-level explanations with respect ML model responses has never been
proposed in the literature.
</p>
<a href="http://arxiv.org/abs/2010.08639" target="_blank">arXiv:2010.08639</a> [<a href="http://arxiv.org/pdf/2010.08639" target="_blank">pdf</a>]

<h2>Robot Learning with Crash Constraints. (arXiv:2010.08669v3 [cs.RO] UPDATED)</h2>
<h3>Alonso Marco, Dominik Baumann, Majid Khadiv, Philipp Hennig, Ludovic Righetti, Sebastian Trimpe</h3>
<p>In the past decade, numerous machine learning algorithms have been shown to
successfully learn optimal policies to control real robotic systems. However,
it is common to encounter failing behaviors as the learning loop progresses.
Specifically, in robot applications where failing is undesired but not
catastrophic, many algorithms struggle with leveraging data obtained from
failures. This is usually caused by (i) the failed experiment ending
prematurely, or (ii) the acquired data being scarce or corrupted. Both
complicate the design of proper reward functions to penalize failures. In this
paper, we propose a framework that addresses those issues. We consider failing
behaviors as those that violate a constraint and address the problem of
learning with crash constraints, where no data is obtained upon constraint
violation. The no-data case is addressed by a novel GP model (GPCR) for the
constraint that combines discrete events (failure/success) with continuous
observations (only obtained upon success). We demonstrate the effectiveness of
our framework on simulated benchmarks and on a real jumping quadruped, where
the constraint threshold is unknown a priori. Experimental data is collected,
by means of constrained Bayesian optimization, directly on the real robot. Our
results outperform manual tuning and GPCR proves useful on estimating the
constraint threshold.
</p>
<a href="http://arxiv.org/abs/2010.08669" target="_blank">arXiv:2010.08669</a> [<a href="http://arxiv.org/pdf/2010.08669" target="_blank">pdf</a>]

<h2>Optimism in the Face of Adversity: Understanding and Improving Deep Learning through Adversarial Robustness. (arXiv:2010.09624v2 [cs.LG] UPDATED)</h2>
<h3>Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard</h3>
<p>Driven by massive amounts of data and important advances in computational
resources, new deep learning systems have achieved outstanding results in a
large spectrum of applications. Nevertheless, our current theoretical
understanding on the mathematical foundations of deep learning lags far behind
its empirical success. Towards solving the vulnerability of neural networks,
however, the field of adversarial robustness has recently become one of the
main sources of explanations of our deep models. In this article, we provide an
in-depth review of the field of adversarial robustness in deep learning, and
give a self-contained introduction to its main notions. But, in contrast to the
mainstream pessimistic perspective of adversarial robustness, we focus on the
main positive aspects that it entails. We highlight the intuitive connection
between adversarial examples and the geometry of deep neural networks, and
eventually explore how the geometric study of adversarial examples can serve as
a powerful tool to understand deep learning. Furthermore, we demonstrate the
broad applicability of adversarial robustness, providing an overview of the
main emerging applications of adversarial robustness beyond security. The goal
of this article is to provide readers with a set of new perspectives to
understand deep learning, and to supply them with intuitive tools and insights
on how to use adversarial robustness to improve it.
</p>
<a href="http://arxiv.org/abs/2010.09624" target="_blank">arXiv:2010.09624</a> [<a href="http://arxiv.org/pdf/2010.09624" target="_blank">pdf</a>]

<h2>Method and Dataset Entity Mining in Scientific Literature: A CNN + Bi-LSTM Model with Self-attention. (arXiv:2010.13583v2 [cs.AI] UPDATED)</h2>
<h3>Linlin Hou, Ji Zhang, Ou Wu, Ting Yu, Zhen Wang, Zhao Li, Jianliang Gao, Yingchun Ye, Rujing Yao</h3>
<p>Literature analysis facilitates researchers to acquire a good understanding
of the development of science and technology. The traditional literature
analysis focuses largely on the literature metadata such as topics, authors,
abstracts, keywords, references, etc., and little attention was paid to the
main content of papers. In many scientific domains such as science, computing,
engineering, etc., the methods and datasets involved in the scientific papers
published in those domains carry important information and are quite useful for
domain analysis as well as algorithm and dataset recommendation. In this paper,
we propose a novel entity recognition model, called MDER, which is able to
effectively extract the method and dataset entities from the main textual
content of scientific papers. The model utilizes rule embedding and adopts a
parallel structure of CNN and Bi-LSTM with the self-attention mechanism. We
evaluate the proposed model on datasets which are constructed from the
published papers of four research areas in computer science, i.e., NLP, CV,
Data Mining and AI. The experimental results demonstrate that our model
performs well in all the four areas and it features a good learning capacity
for cross-area learning and recognition. We also conduct experiments to
evaluate the effectiveness of different building modules within our model which
indicate that the importance of different building modules in collectively
contributing to the good entity recognition performance as a whole. The data
augmentation experiments on our model demonstrated that data augmentation
positively contributes to model training, making our model much more robust in
dealing with the scenarios where only small number of training samples are
available. We finally apply our model on PAKDD papers published from 2009-2019
to mine insightful results from scientific papers published in a longer time
span.
</p>
<a href="http://arxiv.org/abs/2010.13583" target="_blank">arXiv:2010.13583</a> [<a href="http://arxiv.org/pdf/2010.13583" target="_blank">pdf</a>]

<h2>An Optimal Control Approach to Learning in SIDARTHE Epidemic model. (arXiv:2010.14878v2 [cs.LG] UPDATED)</h2>
<h3>Andrea Zugarini, Enrico Meloni, Alessandro Betti, Andrea Panizza, Marco Corneli, Marco Gori</h3>
<p>The COVID-19 outbreak has stimulated the interest in the proposal of novel
epidemiological models to predict the course of the epidemic so as to help
planning effective control strategies. In particular, in order to properly
interpret the available data, it has become clear that one must go beyond most
classic epidemiological models and consider models that, like the recently
proposed SIDARTHE, offer a richer description of the stages of infection. The
problem of learning the parameters of these models is of crucial importance
especially when assuming that they are time-variant, which further enriches
their effectiveness. In this paper we propose a general approach for learning
time-variant parameters of dynamic compartmental models from epidemic data. We
formulate the problem in terms of a functional risk that depends on the
learning variables through the solutions of a dynamic system. The resulting
variational problem is then solved by using a gradient flow on a suitable,
regularized functional. We forecast the epidemic evolution in Italy and France.
Results indicate that the model provides reliable and challenging predictions
over all available data as well as the fundamental role of the chosen strategy
on the time-variant parameters.
</p>
<a href="http://arxiv.org/abs/2010.14878" target="_blank">arXiv:2010.14878</a> [<a href="http://arxiv.org/pdf/2010.14878" target="_blank">pdf</a>]

<h2>Predicting Classification Accuracy When Adding New Unobserved Classes. (arXiv:2010.15011v2 [cs.LG] UPDATED)</h2>
<h3>Yuli Slavutsky, Yuval Benjamini</h3>
<p>Multiclass classifiers are often designed and evaluated only on a sample from
the classes on which they will eventually be applied. Hence, their final
accuracy remains unknown. In this work we study how a classifier's performance
over the initial class sample can be used to extrapolate its expected accuracy
on a larger, unobserved set of classes. For this, we define a measure of
separation between correct and incorrect classes that is independent of the
number of classes: the reversed ROC (rROC), which is obtained by replacing the
roles of classes and data-points in the common ROC. We show that the
classification accuracy is a function of the rROC in multiclass classifiers,
for which the learned representation of data from the initial class sample
remains unchanged when new classes are added. Using these results we formulate
a robust neural-network-based algorithm, CleaneX, which learns to estimate the
accuracy of such classifiers on arbitrarily large sets of classes. Unlike
previous methods, our method uses both the observed accuracies of the
classifier and densities of classification scores, and therefore achieves
remarkably better predictions than current state-of-the-art methods on both
simulations and real datasets of object detection, face recognition, and brain
decoding.
</p>
<a href="http://arxiv.org/abs/2010.15011" target="_blank">arXiv:2010.15011</a> [<a href="http://arxiv.org/pdf/2010.15011" target="_blank">pdf</a>]

<h2>Calibration-Aided Edge Inference Offloading via Adaptive Model Partitioning of Deep Neural Networks. (arXiv:2010.16335v2 [cs.LG] UPDATED)</h2>
<h3>Roberto G. Pacheco, Rodrigo S. Couto, Osvaldo Simeone</h3>
<p>Mobile devices can offload deep neural network (DNN)-based inference to the
cloud, overcoming local hardware and energy limitations. However, offloading
adds communication delay, thus increasing the overall inference time, and hence
it should be used only when needed. An approach to address this problem
consists of the use of adaptive model partitioning based on early-exit DNNs.
Accordingly, the inference starts at the mobile device, and an intermediate
layer estimates the accuracy: If the estimated accuracy is sufficient, the
device takes the inference decision; Otherwise, the remaining layers of the DNN
run at the cloud. Thus, the device offloads the inference to the cloud only if
it cannot classify a sample with high confidence. This offloading requires a
correct accuracy prediction at the device. Nevertheless, DNNs are typically
miscalibrated, providing overconfident decisions. This work shows that the
employment of a miscalibrated early-exit DNN for offloading via model
partitioning can significantly decrease inference accuracy. In contrast, we
argue that implementing a calibration algorithm prior to deployment can solve
this problem, allowing for more reliable offloading decisions.
</p>
<a href="http://arxiv.org/abs/2010.16335" target="_blank">arXiv:2010.16335</a> [<a href="http://arxiv.org/pdf/2010.16335" target="_blank">pdf</a>]

<h2>$(f,\Gamma)$-Divergences: Interpolating between $f$-Divergences and Integral Probability Metrics. (arXiv:2011.05953v2 [stat.ML] UPDATED)</h2>
<h3>Jeremiah Birrell, Paul Dupuis, Markos A. Katsoulakis, Yannis Pantazis, Luc Rey-Bellet</h3>
<p>We develop a rigorous and general framework for constructing
information-theoretic divergences that subsume both $f$-divergences and
integral probability metrics (IPMs), such as the $1$-Wasserstein distance. We
prove under which assumptions these divergences, hereafter referred to as
$(f,\Gamma)$-divergences, provide a notion of `distance' between probability
measures and show that they can be expressed as a two-stage
mass-redistribution/mass-transport process. The $(f,\Gamma)$-divergences
inherit features from IPMs, such as the ability to compare distributions which
are not absolutely continuous, as well as from $f$-divergences, namely the
strict concavity of their variational representations and the ability to
control heavy-tailed distributions for particular choices of $f$. When
combined, these features establish a divergence with improved properties for
estimation, statistical learning, and uncertainty quantification applications.
Using statistical learning as an example, we demonstrate their advantage in
training generative adversarial networks (GANs) for heavy-tailed,
not-absolutely continuous sample distributions and we also show improved
performance and stability over gradient-penalized Wasserstein GAN in image
generation.
</p>
<a href="http://arxiv.org/abs/2011.05953" target="_blank">arXiv:2011.05953</a> [<a href="http://arxiv.org/pdf/2011.05953" target="_blank">pdf</a>]

<h2>Trajectory Prediction in Autonomous Driving with a Lane Heading Auxiliary Loss. (arXiv:2011.06679v2 [cs.CV] UPDATED)</h2>
<h3>Ross Greer, Nachiket Deo, Mohan Trivedi</h3>
<p>Predicting a vehicle's trajectory is an essential ability for autonomous
vehicles navigating through complex urban traffic scenes. Bird's-eye-view
roadmap information provides valuable information for making trajectory
predictions, and while state-of-the-art models extract this information via
image convolution, auxiliary loss functions can augment patterns inferred from
deep learning by further encoding common knowledge of social and legal driving
behaviors. Since human driving behavior is inherently multimodal, models which
allow for multimodal output tend to outperform single-prediction models on
standard metrics. We propose a loss function which enhances such models by
enforcing expected driving rules on all predicted modes. Our contribution to
trajectory prediction is twofold; we propose a new metric which addresses
failure cases of the off-road rate metric by penalizing trajectories that
oppose the ascribed heading (flow direction) of a driving lane, and we show
this metric to be differentiable and therefore suitable as an auxiliary loss
function. We then use this auxiliary loss to extend the the standard multiple
trajectory prediction (MTP) and MultiPath models, achieving improved results on
the nuScenes prediction benchmark by predicting trajectories which better
conform to the lane-following rules of the road.
</p>
<a href="http://arxiv.org/abs/2011.06679" target="_blank">arXiv:2011.06679</a> [<a href="http://arxiv.org/pdf/2011.06679" target="_blank">pdf</a>]

<h2>Enforcing robust control guarantees within neural network policies. (arXiv:2011.08105v2 [cs.LG] UPDATED)</h2>
<h3>Priya L. Donti, Melrose Roderick, Mahyar Fazlyab, J. Zico Kolter</h3>
<p>When designing controllers for safety-critical systems, practitioners often
face a challenging tradeoff between robustness and performance. While robust
control methods provide rigorous guarantees on system stability under certain
worst-case disturbances, they often yield simple controllers that perform
poorly in the average (non-worst) case. In contrast, nonlinear control methods
trained using deep learning have achieved state-of-the-art performance on many
control tasks, but often lack robustness guarantees. In this paper, we propose
a technique that combines the strengths of these two approaches: constructing a
generic nonlinear control policy class, parameterized by neural networks, that
nonetheless enforces the same provable robustness criteria as robust control.
Specifically, our approach entails integrating custom convex-optimization-based
projection layers into a neural network-based policy. We demonstrate the power
of this approach on several domains, improving in average-case performance over
existing robust control methods and in worst-case stability over (non-robust)
deep RL methods.
</p>
<a href="http://arxiv.org/abs/2011.08105" target="_blank">arXiv:2011.08105</a> [<a href="http://arxiv.org/pdf/2011.08105" target="_blank">pdf</a>]

<h2>Statistical and computational thresholds for the planted $k$-densest sub-hypergraph problem. (arXiv:2011.11500v2 [cs.LG] UPDATED)</h2>
<h3>Luca Corinzia, Paolo Penna, Wojciech Szpankowski, Joachim M. Buhmann</h3>
<p>In this work, we consider the problem of recovery a planted $k$-densest
sub-hypergraph on $d$-uniform hypergraphs. This fundamental problem appears in
different contexts, e.g., community detection, average-case complexity, and
neuroscience applications as a structural variant of tensor-PCA problem. We
provide tight \emph{information-theoretic} upper and lower bounds for the exact
recovery threshold by the maximum-likelihood estimator, as well as
\emph{algorithmic} bounds based on approximate message passing algorithms. The
problem exhibits a typical statistical-to-computational gap observed in
analogous sparse settings that widen with increasing sparsity of the problem.
The bounds show that the signal structure impacts the location of the
statistical and computational phase transition that the known existing bounds
for the tensor-PCA model do not capture. This effect is due to the generic
planted signal prior that this latter model addresses.
</p>
<a href="http://arxiv.org/abs/2011.11500" target="_blank">arXiv:2011.11500</a> [<a href="http://arxiv.org/pdf/2011.11500" target="_blank">pdf</a>]

<h2>UKPGAN: Unsupervised KeyPoint GANeration. (arXiv:2011.11974v2 [cs.CV] UPDATED)</h2>
<h3>Yang You, Wenhai Liu, Yong-Lu Li, Weiming Wang, Cewu Lu</h3>
<p>Keypoint detection is an essential component for the object registration and
alignment. However, previous works mainly focused on how to register keypoints
under arbitrary rigid transformations. Differently, in this work, we reckon
keypoints under an information compression scheme to represent the whole
object. Based on this, we propose UKPGAN, an unsupervised 3D keypoint detector
where keypoints are detected so that they could reconstruct the original object
shape. Two modules: GAN-based keypoint sparsity control and salient information
distillation modules are proposed to locate those important keypoints.
Extensive experiments show that our keypoints preserve the semantic information
of objects and align well with human annotated part and keypoint labels.
Furthermore, we show that UKPGAN can be applied to either rigid objects or
non-rigid SMPL human bodies under arbitrary pose deformations. As a keypoint
detector, our model is stable under both rigid and non-rigid transformations,
with local reference frame estimation. Our code is available on
https://github.com/qq456cvb/UKPGAN.
</p>
<a href="http://arxiv.org/abs/2011.11974" target="_blank">arXiv:2011.11974</a> [<a href="http://arxiv.org/pdf/2011.11974" target="_blank">pdf</a>]

<h2>torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation. (arXiv:2011.12913v2 [cs.LG] UPDATED)</h2>
<h3>Yoshitomo Matsubara</h3>
<p>While knowledge distillation (transfer) has been attracting attentions from
the research community, the recent development in the fields has heightened the
need for reproducible studies and highly generalized frameworks to lower
barriers to such high-quality, reproducible deep learning research. Several
researchers voluntarily published frameworks used in their knowledge
distillation studies to help other interested researchers reproduce their
original work. Such frameworks, however, are usually neither well generalized
nor maintained, thus researchers are still required to write a lot of code to
refactor/build on the frameworks for introducing new methods, models, datasets
and designing experiments. In this paper, we present our developed open-source
framework built on PyTorch and dedicated for knowledge distillation studies.
The framework is designed to enable users to design experiments by declarative
PyYAML configuration files, and helps researchers complete the recently
proposed ML Code Completeness Checklist. Using the developed framework, we
demonstrate its various efficient training strategies, and implement a variety
of knowledge distillation methods. We also reproduce some of their original
experimental results on the ImageNet and COCO datasets presented at major
machine learning conferences such as ICLR, NeurIPS, CVPR and ECCV, including
recent state-of-the-art methods. All the source code, configurations, log files
and trained model weights are publicly available at
https://github.com/yoshitomo-matsubara/torchdistill .
</p>
<a href="http://arxiv.org/abs/2011.12913" target="_blank">arXiv:2011.12913</a> [<a href="http://arxiv.org/pdf/2011.12913" target="_blank">pdf</a>]

<h2>The NEOLIX Open Dataset for Autonomous Driving. (arXiv:2011.13528v2 [cs.CV] UPDATED)</h2>
<h3>Lichao Wang, Lanxin Lei, Hongli Song, Weibao Wang</h3>
<p>With the gradual maturity of 5G technology,autonomous driving technology has
attracted moreand more attention among the research commu-nity. Autonomous
driving vehicles rely on the co-operation of artificial intelligence, visual
comput-ing, radar, monitoring equipment and GPS, whichenables computers to
operate motor vehicles auto-matically and safely without human
interference.However, the large-scale dataset for training andsystem evaluation
is still a hot potato in the devel-opment of robust perception models. In this
paper,we present the NEOLIX dataset and its applica-tions in the autonomous
driving area. Our datasetincludes about 30,000 frames with point cloud la-bels,
and more than 600k 3D bounding boxes withannotations. The data collection
covers multipleregions, and various driving conditions, includingday, night,
dawn, dusk and sunny day. In orderto label this complete dataset, we developed
vari-ous tools and algorithms specified for each task tospeed up the labelling
process. It is expected thatour dataset and related algorithms can support
andmotivate researchers for the further developmentof autonomous driving in the
field of computer vi-sion.
</p>
<a href="http://arxiv.org/abs/2011.13528" target="_blank">arXiv:2011.13528</a> [<a href="http://arxiv.org/pdf/2011.13528" target="_blank">pdf</a>]

<h2>Refining Deep Generative Models via Discriminator Gradient Flow. (arXiv:2012.00780v2 [cs.LG] UPDATED)</h2>
<h3>Abdul Fatir Ansari, Ming Liang Ang, Harold Soh</h3>
<p>Deep generative modeling has seen impressive advances in recent years, to the
point where it is now commonplace to see simulated samples (e.g., images) that
closely resemble real-world data. However, generation quality is generally
inconsistent for any given model and can vary dramatically between samples. We
introduce Discriminator Gradient flow (DGflow), a new technique that improves
generated samples via the gradient flow of entropy-regularized f-divergences
between the real and the generated data distributions. The gradient flow takes
the form of a non-linear Fokker-Plank equation, which can be easily simulated
by sampling from the equivalent McKean-Vlasov process. By refining inferior
samples, our technique avoids wasteful sample rejection used by previous
methods (DRS &amp; MH-GAN). Compared to existing works that focus on specific GAN
variants, we show our refinement approach can be applied to GANs with
vector-valued critics and even other deep generative models such as VAEs and
Normalizing Flows. Empirical results on multiple synthetic, image, and text
datasets demonstrate that DGflow leads to significant improvement in the
quality of generated samples for a variety of generative models, outperforming
the state-of-the-art Discriminator Optimal Transport (DOT) and Discriminator
Driven Latent Sampling (DDLS) methods.
</p>
<a href="http://arxiv.org/abs/2012.00780" target="_blank">arXiv:2012.00780</a> [<a href="http://arxiv.org/pdf/2012.00780" target="_blank">pdf</a>]

<h2>When Do Curricula Work?. (arXiv:2012.03107v2 [cs.LG] UPDATED)</h2>
<h3>Xiaoxia Wu, Ethan Dyer, Behnam Neyshabur</h3>
<p>Inspired by human learning, researchers have proposed ordering examples
during training based on their difficulty. Both curriculum learning, exposing a
network to easier examples early in training, and anti-curriculum learning,
showing the most difficult examples first, have been suggested as improvements
to the standard i.i.d. training. In this work, we set out to investigate the
relative benefits of ordered learning. We first investigate the \emph{implicit
curricula} resulting from architectural and optimization bias and find that
samples are learned in a highly consistent order. Next, to quantify the benefit
of \emph{explicit curricula}, we conduct extensive experiments over thousands
of orderings spanning three kinds of learning: curriculum, anti-curriculum, and
random-curriculum -- in which the size of the training dataset is dynamically
increased over time, but the examples are randomly ordered. We find that for
standard benchmark datasets, curricula have only marginal benefits, and that
randomly ordered samples perform as well or better than curricula and
anti-curricula, suggesting that any benefit is entirely due to the dynamic
training set size. Inspired by common use cases of curriculum learning in
practice, we investigate the role of limited training time budget and noisy
data in the success of curriculum learning. Our experiments demonstrate that
curriculum, but not anti-curriculum can indeed improve the performance either
with limited training time budget or in existence of noisy data.
</p>
<a href="http://arxiv.org/abs/2012.03107" target="_blank">arXiv:2012.03107</a> [<a href="http://arxiv.org/pdf/2012.03107" target="_blank">pdf</a>]

<h2>Personalized Federated Learning with First Order Model Optimization. (arXiv:2012.08565v3 [cs.LG] UPDATED)</h2>
<h3>Michael Zhang, Karan Sapra, Sanja Fidler, Serena Yeung, Jose M. Alvarez</h3>
<p>While federated learning traditionally aims to train a single global model
across decentralized local datasets, one model may not always be ideal for all
participating clients. Here we propose an alternative, where each client only
federates with other relevant clients to obtain a stronger model per
client-specific objectives. To achieve this personalization, rather than
computing a single model average with constant weights for the entire
federation as in traditional FL, we efficiently calculate optimal weighted
model combinations for each client, based on figuring out how much a client can
benefit from another's model. We do not assume knowledge of any underlying data
distributions or client similarities, and allow each client to optimize for
arbitrary target distributions of interest, enabling greater flexibility for
personalization. We evaluate and characterize our method on a variety of
federated settings, datasets, and degrees of local data heterogeneity. Our
method outperforms existing alternatives, while also enabling new features for
personalized FL such as transfer outside of local data distributions.
</p>
<a href="http://arxiv.org/abs/2012.08565" target="_blank">arXiv:2012.08565</a> [<a href="http://arxiv.org/pdf/2012.08565" target="_blank">pdf</a>]

<h2>RBM-Flow and D-Flow: Invertible Flows with Discrete Energy Base Spaces. (arXiv:2012.13196v2 [cs.LG] UPDATED)</h2>
<h3>Daniel O&#x27;Connor, Walter Vinci</h3>
<p>Efficient sampling of complex data distributions can be achieved using
trained invertible flows (IF), where the model distribution is generated by
pushing a simple base distribution through multiple non-linear bijective
transformations. However, the iterative nature of the transformations in IFs
can limit the approximation to the target distribution. In this paper we seek
to mitigate this by implementing RBM-Flow, an IF model whose base distribution
is a Restricted Boltzmann Machine (RBM) with a continuous smoothing applied. We
show that by using RBM-Flow we are able to improve the quality of samples
generated, quantified by the Inception Scores (IS) and Frechet Inception
Distance (FID), over baseline models with the same IF transformations, but with
less expressive base distributions. Furthermore, we also obtain D-Flow, an IF
model with uncorrelated discrete latent variables. We show that D-Flow achieves
similar likelihoods and FID/IS scores to those of a typical IF with Gaussian
base variables, but with the additional benefit that global features are
meaningfully encoded as discrete labels in the latent space.
</p>
<a href="http://arxiv.org/abs/2012.13196" target="_blank">arXiv:2012.13196</a> [<a href="http://arxiv.org/pdf/2012.13196" target="_blank">pdf</a>]

<h2>Uncertainty-Wizard: Fast and User-Friendly Neural Network Uncertainty Quantification. (arXiv:2101.00982v2 [cs.LG] UPDATED)</h2>
<h3>Michael Weiss, Paolo Tonella</h3>
<p>Uncertainty and confidence have been shown to be useful metrics in a wide
variety of techniques proposed for deep learning testing, including test data
selection and system supervision.We present uncertainty-wizard, a tool that
allows to quantify such uncertainty and confidence in artificial neural
networks. It is built on top of the industry-leading tf.keras deep learning API
and it provides a near-transparent and easy to understand interface. At the
same time, it includes major performance optimizations that we benchmarked on
two different machines and different configurations.
</p>
<a href="http://arxiv.org/abs/2101.00982" target="_blank">arXiv:2101.00982</a> [<a href="http://arxiv.org/pdf/2101.00982" target="_blank">pdf</a>]

<h2>Control-Data Separation and Logical Condition Propagation for Efficient Inference on Probabilistic Programs. (arXiv:2101.01502v2 [cs.LG] UPDATED)</h2>
<h3>Ichiro Hasuo, Yuichiro Oyabu, Clovis Eberhart, Kohei Suenaga, Kenta Cho, Shin-ya Katsumata</h3>
<p>We introduce a novel sampling algorithm for Bayesian inference on imperative
probabilistic programs. It features a hierarchical architecture that separates
control flows from data: the top-level samples a control flow, and the bottom
level samples data values along the control flow picked by the top level. This
separation allows us to plug various language-based analysis techniques in
probabilistic program sampling; specifically, we use logical backward
propagation of observations for sampling efficiency. We implemented our
algorithm on top of Anglican. The experimental results demonstrate our
algorithm's efficiency, especially for programs with while loops and rare
observations.
</p>
<a href="http://arxiv.org/abs/2101.01502" target="_blank">arXiv:2101.01502</a> [<a href="http://arxiv.org/pdf/2101.01502" target="_blank">pdf</a>]

<h2>Understanding the Effect of Out-of-distribution Examples and Interactive Explanations on Human-AI Decision Making. (arXiv:2101.05303v2 [cs.AI] UPDATED)</h2>
<h3>Han Liu, Vivian Lai, Chenhao Tan</h3>
<p>Although AI holds promise for improving human decision making in societally
critical domains, it remains an open question how human-AI teams can reliably
outperform AI alone and human alone in challenging prediction tasks (also known
as complementary performance). We explore two directions to understand the gaps
in achieving complementary performance. First, we argue that the typical
experimental setup limits the potential of human-AI teams. To account for lower
AI performance out-of-distribution than in-distribution because of distribution
shift, we design experiments with different distribution types and investigate
human performance for both in-distribution and out-of-distribution examples.
Second, we develop novel interfaces to support interactive explanations so that
humans can actively engage with AI assistance. Using in-person user study and
large-scale randomized experiments across three tasks, we demonstrate a clear
difference between in-distribution and out-of-distribution, and observe mixed
results for interactive explanations: while interactive explanations improve
human perception of AI assistance's usefulness, they may magnify human biases
and lead to limited performance improvement. Overall, our work points out
critical challenges and future directions towards complementary performance.
</p>
<a href="http://arxiv.org/abs/2101.05303" target="_blank">arXiv:2101.05303</a> [<a href="http://arxiv.org/pdf/2101.05303" target="_blank">pdf</a>]

<h2>Multi-robot Symmetric Rendezvous Search on the Line. (arXiv:2101.05324v3 [cs.RO] UPDATED)</h2>
<h3>Deniz Ozsoyeller, Pratap Tokekar</h3>
<p>We study the Symmetric Rendezvous Search Problem for a multi-robot system.
There are $n&gt;2$ robots arbitrarily located on a line. Their goal is to meet
somewhere on the line as quickly as possible. The robots do not know the
initial location of any of the other robots or their own positions on the line.
The symmetric version of the problem requires the robots to execute the same
search strategy to achieve rendezvous. Therefore, we solve the problem in an
online fashion with a randomized strategy. In this paper, we present a
symmetric rendezvous algorithm which achieves a constant competitive ratio for
the total distance traveled by the robots. We validate our theoretical results
through simulations.
</p>
<a href="http://arxiv.org/abs/2101.05324" target="_blank">arXiv:2101.05324</a> [<a href="http://arxiv.org/pdf/2101.05324" target="_blank">pdf</a>]

<h2>Variance Based Samples Weighting for Supervised Deep Learning. (arXiv:2101.07561v2 [stat.ML] UPDATED)</h2>
<h3>Paul Novello (CEA, X, Inria), Ga&#xeb;l Po&#xeb;tte (CEA), David Lugato (CEA), Pietro Congedo (X, Inria)</h3>
<p>In the context of supervised learning of a function by a Neural Network (NN),
we claim and empirically justify that a NN yields better results when the
distribution of the data set focuses on regions where the function to learn is
steeper. We first traduce this assumption in a mathematically workable way
using Taylor expansion. Then, theoretical derivations allow to construct a
methodology that we call Variance Based Samples Weighting (VBSW). VBSW uses
local variance of the labels to weight the training points. This methodology is
general, scalable, cost effective, and significantly increases the performances
of a large class of NNs for various classification and regression tasks on
image, text and multivariate data. We highlight its benefits with experiments
involving NNs from shallow linear NN to Resnet or Bert.
</p>
<a href="http://arxiv.org/abs/2101.07561" target="_blank">arXiv:2101.07561</a> [<a href="http://arxiv.org/pdf/2101.07561" target="_blank">pdf</a>]

<h2>SparseDNN: Fast Sparse Deep Learning Inference on CPUs. (arXiv:2101.07948v2 [cs.LG] UPDATED)</h2>
<h3>Ziheng Wang</h3>
<p>The last few years have seen gigantic leaps in algorithms and systems to
support efficient deep learning inference. Pruning and quantization algorithms
can now consistently compress neural networks by an order of magnitude. For a
compressed neural network, a multitude of inference frameworks have been
designed to maximize the performance of the target hardware. While we find
mature support for quantized neural networks in production frameworks such as
OpenVINO and MNN, support for pruned sparse neural networks is still lacking.
To tackle this challenge, we present SparseDNN, a sparse deep learning
inference engine targeting CPUs. We present both kernel-level optimizations
with a sparse code generator to accelerate sparse operators and novel
network-level optimizations catering to sparse networks. We show that our
sparse code generator can achieve significant speedups over state-of-the-art
sparse and dense libraries. On end-to-end benchmarks such as Huggingface
pruneBERT, SparseDNN achieves up to 5x throughput improvement over dense
inference with state-of-the-art OpenVINO.
</p>
<a href="http://arxiv.org/abs/2101.07948" target="_blank">arXiv:2101.07948</a> [<a href="http://arxiv.org/pdf/2101.07948" target="_blank">pdf</a>]

<h2>Quadratic Residual Networks: A New Class of Neural Networks for Solving Forward and Inverse Problems in Physics Involving PDEs. (arXiv:2101.08366v2 [cs.LG] UPDATED)</h2>
<h3>Jie Bu, Anuj Karpatne</h3>
<p>We propose quadratic residual networks (QRes) as a new type of
parameter-efficient neural network architecture, by adding a quadratic residual
term to the weighted sum of inputs before applying activation functions. With
sufficiently high functional capacity (or expressive power), we show that it is
especially powerful for solving forward and inverse physics problems involving
partial differential equations (PDEs). Using tools from algebraic geometry, we
theoretically demonstrate that, in contrast to plain neural networks, QRes
shows better parameter efficiency in terms of network width and depth thanks to
higher non-linearity in every neuron. Finally, we empirically show that QRes
shows faster convergence speed in terms of number of training epochs especially
in learning complex patterns.
</p>
<a href="http://arxiv.org/abs/2101.08366" target="_blank">arXiv:2101.08366</a> [<a href="http://arxiv.org/pdf/2101.08366" target="_blank">pdf</a>]

<h2>Activity Graph Transformer for Temporal Action Localization. (arXiv:2101.08540v2 [cs.CV] UPDATED)</h2>
<h3>Megha Nawhal, Greg Mori</h3>
<p>We introduce Activity Graph Transformer, an end-to-end learnable model for
temporal action localization, that receives a video as input and directly
predicts a set of action instances that appear in the video. Detecting and
localizing action instances in untrimmed videos requires reasoning over
multiple action instances in a video. The dominant paradigms in the literature
process videos temporally to either propose action regions or directly produce
frame-level detections. However, sequential processing of videos is problematic
when the action instances have non-sequential dependencies and/or non-linear
temporal ordering, such as overlapping action instances or re-occurrence of
action instances over the course of the video. In this work, we capture this
non-linear temporal structure by reasoning over the videos as non-sequential
entities in the form of graphs. We evaluate our model on challenging datasets:
THUMOS14, Charades, and EPIC-Kitchens-100. Our results show that our proposed
model outperforms the state-of-the-art by a considerable margin.
</p>
<a href="http://arxiv.org/abs/2101.08540" target="_blank">arXiv:2101.08540</a> [<a href="http://arxiv.org/pdf/2101.08540" target="_blank">pdf</a>]

<h2>Selfish Sparse RNN Training. (arXiv:2101.09048v2 [cs.LG] UPDATED)</h2>
<h3>Shiwei Liu, Decebal Constantin Mocanu, Yulong Pei, Mykola Pechenizkiy</h3>
<p>Sparse neural networks have been widely applied to reduce the necessary
resource requirements to train and deploy over-parameterized deep neural
networks. For inference acceleration, methods that induce sparsity from a
pre-trained dense network (dense-to-sparse) work effectively. Recently, dynamic
sparse training (DST) has been proposed to train sparse neural networks without
pre-training a dense network (sparse-to-sparse), so that the training process
can also be accelerated. However, previous sparse-to-sparse methods mainly
focus on Multilayer Perceptron Networks (MLPs) and Convolutional Neural
Networks (CNNs), failing to match the performance of dense-to-sparse methods in
Recurrent Neural Networks (RNNs) setting. In this paper, we propose an approach
to train sparse RNNs with a fixed parameter count in one single run, without
compromising performance. During training, we allow RNN layers to have a
non-uniform redistribution across cell gates for a better regularization.
Further, we introduce SNT-ASGD, a variant of the averaged stochastic gradient
optimizer, which significantly improves the performance of all sparse training
methods for RNNs. Using these strategies, we achieve state-of-the-art sparse
training results with various types of RNNs on Penn TreeBank and Wikitext-2
datasets.
</p>
<a href="http://arxiv.org/abs/2101.09048" target="_blank">arXiv:2101.09048</a> [<a href="http://arxiv.org/pdf/2101.09048" target="_blank">pdf</a>]

<h2>Fighting deepfakes by detecting GAN DCT anomalies. (arXiv:2101.09781v2 [cs.CV] UPDATED)</h2>
<h3>Oliver Giudice (1), Luca Guarnera (1 and 2), Sebastiano Battiato (1 and 2) ((1) University of Catania, (2) iCTLab s.r.l. - Spin-off of University of Catania)</h3>
<p>Synthetic multimedia content created through AI technologies, such as
Generative Adversarial Networks (GAN), applied to human faces can bring serious
social and political consequences in the private life of every person.
State-of-the-art algorithms use deep neural networks to detect a fake content
but unfortunately almost all approaches appear to be neither generalizable nor
explainable. A new fast detection method able to discriminate Deepfake images
with blazing speed and high precision is exposed. By employing Discrete Cosine
Transform (DCT), anomalous frequencies in real and Deepfake datasets were
analyzed. The \beta statistics inferred by the AC coefficients distribution
have been the key to recognize GAN-engine generated data. The technique has
been validated on pristine high quality faces synthesized by different GANs
architectures. Experiments carried out show that the method is innovative,
exceeds the state-of-the-art and also gives many insights in terms of
explainability.
</p>
<a href="http://arxiv.org/abs/2101.09781" target="_blank">arXiv:2101.09781</a> [<a href="http://arxiv.org/pdf/2101.09781" target="_blank">pdf</a>]

<h2>Spatio-temporal Data Augmentation for Visual Surveillance. (arXiv:2101.09895v2 [cs.CV] UPDATED)</h2>
<h3>Jae-Yeul Kim, Jong-Eun Ha</h3>
<p>Visual surveillance aims to stably detect a foreground object using a
continuous image acquired from a fixed camera. Recent deep learning methods
based on supervised learning show superior performance compared to classical
background subtraction algorithms. However, there is still a room for
improvement in static foreground, dynamic background, hard shadow, illumination
changes, camouflage, etc. In addition, most of the deep learning-based methods
operates well on environments similar to training. If the testing environments
are different from training ones, their performance degrades. As a result,
additional training on those operating environments is required to ensure a
good performance. Our previous work which uses spatio-temporal input data
consisted of a number of past images, background images and current image
showed promising results in different environments from training, although it
uses a simple U-NET structure. In this paper, we propose a data augmentation
technique suitable for visual surveillance for additional performance
improvement using the same network used in our previous work. In deep learning,
most data augmentation techniques deal with spatial-level data augmentation
techniques for use in image classification and object detection. In this paper,
we propose a new method of data augmentation in the spatio-temporal dimension
suitable for our previous work. Two data augmentation methods of adjusting
background model images and past images are proposed. Through this, it is shown
that performance can be improved in difficult areas such as static foreground
and ghost objects, compared to previous studies. Through quantitative and
qualitative evaluation using SBI, LASIESTA, and our own dataset, we show that
it gives superior performance compared to deep learning-based algorithms and
background subtraction algorithms.
</p>
<a href="http://arxiv.org/abs/2101.09895" target="_blank">arXiv:2101.09895</a> [<a href="http://arxiv.org/pdf/2101.09895" target="_blank">pdf</a>]

<h2>CPTR: Full Transformer Network for Image Captioning. (arXiv:2101.10804v3 [cs.CV] UPDATED)</h2>
<h3>Wei Liu, Sihan Chen, Longteng Guo, Xinxin Zhu, Jing Liu</h3>
<p>In this paper, we consider the image captioning task from a new
sequence-to-sequence prediction perspective and propose CaPtion TransformeR
(CPTR) which takes the sequentialized raw images as the input to Transformer.
Compared to the "CNN+Transformer" design paradigm, our model can model global
context at every encoder layer from the beginning and is totally
convolution-free. Extensive experiments demonstrate the effectiveness of the
proposed model and we surpass the conventional "CNN+Transformer" methods on the
MSCOCO dataset. Besides, we provide detailed visualizations of the
self-attention between patches in the encoder and the "words-to-patches"
attention in the decoder thanks to the full Transformer architecture.
</p>
<a href="http://arxiv.org/abs/2101.10804" target="_blank">arXiv:2101.10804</a> [<a href="http://arxiv.org/pdf/2101.10804" target="_blank">pdf</a>]

<h2>Prototypical Pseudo Label Denoising and Target Structure Learning for Domain Adaptive Semantic Segmentation. (arXiv:2101.10979v2 [cs.CV] UPDATED)</h2>
<h3>Pan Zhang, Bo Zhang, Ting Zhang, Dong Chen, Yong Wang, Fang Wen</h3>
<p>Self-training is a competitive approach in domain adaptive segmentation,
which trains the network with the pseudo labels on the target domain. However
inevitably, the pseudo labels are noisy and the target features are dispersed
due to the discrepancy between source and target domains. In this paper, we
rely on representative prototypes, the feature centroids of classes, to address
the two issues for unsupervised domain adaptation. In particular, we take one
step further and exploit the feature distances from prototypes that provide
richer information than mere prototypes. Specifically, we use it to estimate
the likelihood of pseudo labels to facilitate online correction in the course
of training. Meanwhile, we align the prototypical assignments based on relative
feature distances for two different views of the same target, producing a more
compact target feature space. Moreover, we find that distilling the already
learned knowledge to a self-supervised pretrained model further boosts the
performance. Our method shows tremendous performance advantage over
state-of-the-art methods. We will make the code publicly available.
</p>
<a href="http://arxiv.org/abs/2101.10979" target="_blank">arXiv:2101.10979</a> [<a href="http://arxiv.org/pdf/2101.10979" target="_blank">pdf</a>]

<h2>Puzzle-CAM: Improved localization via matching partial and full features. (arXiv:2101.11253v2 [cs.CV] UPDATED)</h2>
<h3>Sanghyun Jo, In-Jae Yu</h3>
<p>Weakly-supervised semantic segmentation (WSSS) is introduced to narrow the
gap for semantic segmentation performance from pixel-level supervision to
image-level supervision. Most advanced approaches are based on class activation
maps (CAMs) to generate pseudo-labels to train the segmentation network. The
main limitation of WSSS is that the process of generating pseudo-labels from
CAMs that use an image classifier is mainly focused on the most discriminative
parts of the objects. To address this issue, we propose Puzzle-CAM, a process
that minimizes differences between the features from separate patches and the
whole image. Our method consists of a puzzle module and two regularization
terms to discover the most integrated region in an object. Puzzle-CAM can
activate the overall region of an object using image-level supervision without
requiring extra parameters. % In experiments, Puzzle-CAM outperformed previous
state-of-the-art methods using the same labels for supervision on the PASCAL
VOC 2012 test dataset. In experiments, Puzzle-CAM outperformed previous
state-of-the-art methods using the same labels for supervision on the PASCAL
VOC 2012 dataset. Code associated with our experiments is available at
\url{https://github.com/OFRIN/PuzzleCAM}.
</p>
<a href="http://arxiv.org/abs/2101.11253" target="_blank">arXiv:2101.11253</a> [<a href="http://arxiv.org/pdf/2101.11253" target="_blank">pdf</a>]

<h2>Generative Multi-Label Zero-Shot Learning. (arXiv:2101.11606v2 [cs.CV] UPDATED)</h2>
<h3>Akshita Gupta, Sanath Narayan, Salman Khan, Fahad Shahbaz Khan, Ling Shao, Joost van de Weijer</h3>
<p>Multi-label zero-shot learning strives to classify images into multiple
unseen categories for which no data is available during training. The test
samples can additionally contain seen categories in the generalized variant.
Existing approaches rely on learning either shared or label-specific attention
from the seen classes. Nevertheless, computing reliable attention maps for
unseen classes during inference in a multi-label setting is still a challenge.
In contrast, state-of-the-art single-label generative adversarial network (GAN)
based approaches learn to directly synthesize the class-specific visual
features from the corresponding class attribute embeddings. However,
synthesizing multi-label features from GANs is still unexplored in the context
of zero-shot setting. In this work, we introduce different fusion approaches at
the attribute-level, feature-level and cross-level (across attribute and
feature-levels) for synthesizing multi-label features from their corresponding
multi-label class embedding. To the best of our knowledge, our work is the
first to tackle the problem of multi-label feature synthesis in the
(generalized) zero-shot setting. Comprehensive experiments are performed on
three zero-shot image classification benchmarks: NUS-WIDE, Open Images and MS
COCO. Our cross-level fusion-based generative approach outperforms the
state-of-the-art on all three datasets. Furthermore, we show the generalization
capabilities of our fusion approach in the zero-shot detection task on MS COCO,
achieving favorable performance against existing methods. The source code is
available at https://github.com/akshitac8/Generative_MLZSL.
</p>
<a href="http://arxiv.org/abs/2101.11606" target="_blank">arXiv:2101.11606</a> [<a href="http://arxiv.org/pdf/2101.11606" target="_blank">pdf</a>]

<h2>Robust Ensemble Model Training via Random Layer Sampling Against Adversarial Attack. (arXiv:2005.10757v2 [cs.CV] CROSS LISTED)</h2>
<h3>Hakmin Lee, Hong Joo Lee, Seong Tae Kim, Yong Man Ro</h3>
<p>Deep neural networks have achieved substantial achievements in several
computer vision areas, but have vulnerabilities that are often fooled by
adversarial examples that are not recognized by humans. This is an important
issue for security or medical applications. In this paper, we propose an
ensemble model training framework with random layer sampling to improve the
robustness of deep neural networks. In the proposed training framework, we
generate various sampled model through the random layer sampling and update the
weight of the sampled model. After the ensemble models are trained, it can hide
the gradient efficiently and avoid the gradient-based attack by the random
layer sampling method. To evaluate our proposed method, comprehensive and
comparative experiments have been conducted on three datasets. Experimental
results show that the proposed method improves the adversarial robustness.
</p>
<a href="http://arxiv.org/abs/2005.10757" target="_blank">arXiv:2005.10757</a> [<a href="http://arxiv.org/pdf/2005.10757" target="_blank">pdf</a>]

<h2>Variance Based Samples Weighting for Supervised Deep Learning. (arXiv:2101.07561v2 [stat.ML] CROSS LISTED)</h2>
<h3>Paul Novello (CEA, X, Inria), Ga&#xeb;l Po&#xeb;tte (CEA), David Lugato (CEA), Pietro Congedo (X, Inria)</h3>
<p>In the context of supervised learning of a function by a Neural Network (NN),
we claim and empirically justify that a NN yields better results when the
distribution of the data set focuses on regions where the function to learn is
steeper. We first traduce this assumption in a mathematically workable way
using Taylor expansion. Then, theoretical derivations allow to construct a
methodology that we call Variance Based Samples Weighting (VBSW). VBSW uses
local variance of the labels to weight the training points. This methodology is
general, scalable, cost effective, and significantly increases the performances
of a large class of NNs for various classification and regression tasks on
image, text and multivariate data. We highlight its benefits with experiments
involving NNs from shallow linear NN to Resnet or Bert.
</p>
<a href="http://arxiv.org/abs/2101.07561" target="_blank">arXiv:2101.07561</a> [<a href="http://arxiv.org/pdf/2101.07561" target="_blank">pdf</a>]

