---
title: Latest Deep Learning Papers
date: 2020-10-12 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Finding geodesics on graphs using reinforcement learning. (arXiv:2010.04820v1 [math.PR])</h2>
<h3>Daniel Kious, C&#xe9;cile Mailler, Bruno Schapira</h3>
<p>It is well-known in biology that ants are able to find shortest paths between
their nest and the food by successive random explorations, without any mean of
communication other than the pheromones they leave behind them. This striking
phenomenon has been observed experimentally and modelled by different
mean-field reinforcement-learning models in the biology literature.

In this paper, we introduce the first probabilistic reinforcement-learning
model for this phenomenon. In this model, the ants explore a finite graph in
which two nodes are distinguished as the nest and the source of food. The ants
perform successive random walks on this graph, starting from the nest and
stopped when first reaching the food, and the transition probabilities of each
random walk depend on the realizations of all previous walks through some
dynamic weighting of the graph. We discuss different variants of this model
based on different reinforcement rules and show that slight changes in this
reinforcement rule can lead to drastically different outcomes.

We prove that, in two variants of this model and when the underlying graph
is, respectively, any series-parallel graph and a 5-edge non-series-parallel
losange graph, the ants indeed eventually find the shortest path(s) between
their nest and the food. Both proofs rely on the electrical network method for
random walks on weighted graphs and on Rubin's embedding in continuous time.
The proof in the series-parallel cases uses the recursive nature of this family
of graphs, while the proof in the seemingly-simpler losange case turns out to
be quite intricate: it relies on a fine analysis of some stochastic
approximation, and on various couplings with standard and generalised P\'olya
urns.
</p>
<a href="http://arxiv.org/abs/2010.04820" target="_blank">arXiv:2010.04820</a> [<a href="http://arxiv.org/pdf/2010.04820" target="_blank">pdf</a>]

<h2>Paying down metadata debt: learning the representation of concepts using topic models. (arXiv:2010.04836v1 [cs.LG])</h2>
<h3>Jiahao Chen, Manuela Veloso</h3>
<p>We introduce a data management problem called metadata debt, to identify the
mapping between data concepts and their logical representations. We describe
how this mapping can be learned using semisupervised topic models based on
low-rank matrix factorizations that account for missing and noisy labels,
coupled with sparsity penalties to improve localization and interpretability.
We introduce a gauge transformation approach that allows us to construct
explicit associations between topics and concept labels, and thus assign
meaning to topics. We also show how to use this topic model for semisupervised
learning tasks like extrapolating from known labels, evaluating possible errors
in existing labels, and predicting missing features. We show results from this
topic model in predicting subject tags on over 25,000 datasets from Kaggle.com,
demonstrating the ability to learn semantically meaningful features.
</p>
<a href="http://arxiv.org/abs/2010.04836" target="_blank">arXiv:2010.04836</a> [<a href="http://arxiv.org/pdf/2010.04836" target="_blank">pdf</a>]

<h2>Kernel Methods for Policy Evaluation: Treatment Effects, Mediation Analysis, and Off-Policy Planning. (arXiv:2010.04855v1 [econ.EM])</h2>
<h3>Rahul Singh, Liyuan Xu, Arthur Gretton</h3>
<p>We propose a novel framework for non-parametric policy evaluation in static
and dynamic settings. Under the assumption of selection on observables, we
consider treatment effects of the population, of sub-populations, and of
alternative populations that may have alternative covariate distributions. We
further consider the decomposition of a total effect into a direct effect and
an indirect effect (as mediated by a particular mechanism). Under the
assumption of sequential selection on observables, we consider the effects of
sequences of treatments. Across settings, we allow for treatments that may be
discrete, continuous, or even text. Across settings, we allow for estimation of
not only counterfactual mean outcomes but also counterfactual distributions of
outcomes. We unify analyses across settings by showing that all of these causal
learning problems reduce to the re-weighting of a prediction, i.e. causal
adjustment. We implement the re-weighting as an inner product in a function
space called a reproducing kernel Hilbert space (RKHS), with a closed form
solution that can be computed in one line of code. We prove uniform consistency
and provide finite sample rates of convergence. We evaluate our estimators in
simulations devised by other authors. We use our new estimators to evaluate
continuous and heterogeneous treatment effects of the US Jobs Corps training
program for disadvantaged youth.
</p>
<a href="http://arxiv.org/abs/2010.04855" target="_blank">arXiv:2010.04855</a> [<a href="http://arxiv.org/pdf/2010.04855" target="_blank">pdf</a>]

<h2>Rare-Event Simulation for Neural Network and Random Forest Predictors. (arXiv:2010.04890v1 [cs.LG])</h2>
<h3>Yuanlu Bai, Zhiyuan Huang, Henry Lam, Ding Zhao</h3>
<p>We study rare-event simulation for a class of problems where the target
hitting sets of interest are defined via modern machine learning tools such as
neural networks and random forests. This problem is motivated from fast
emerging studies on the safety evaluation of intelligent systems, robustness
quantification of learning models, and other potential applications to
large-scale simulation in which machine learning tools can be used to
approximate complex rare-event set boundaries. We investigate an importance
sampling scheme that integrates the dominating point machinery in large
deviations and sequential mixed integer programming to locate the underlying
dominating points. Our approach works for a range of neural network
architectures including fully connected layers, rectified linear units,
normalization, pooling and convolutional layers, and random forests built from
standard decision trees. We provide efficiency guarantees and numerical
demonstration of our approach using a classification model in the UCI Machine
Learning Repository.
</p>
<a href="http://arxiv.org/abs/2010.04890" target="_blank">arXiv:2010.04890</a> [<a href="http://arxiv.org/pdf/2010.04890" target="_blank">pdf</a>]

<h2>Training without Gradients -- A Filtering Approach. (arXiv:2010.04908v1 [math.OC])</h2>
<h3>Isaac Yaesh, Natan Grinfeld</h3>
<p>A particle filtering approach is suggested for the training of multi-layer
neural networks without utilizing gradients calculation. The network weights
are considered to be the components of the estimated state-vector of a noise
driven linear system, whereas the neural network serves as the measurement
function in the estimation problem. A simple example is used to provide a
preliminary demonstration of the concept, which remains to be further studied
for training deep neural networks.
</p>
<a href="http://arxiv.org/abs/2010.04908" target="_blank">arXiv:2010.04908</a> [<a href="http://arxiv.org/pdf/2010.04908" target="_blank">pdf</a>]

<h2>On The Convergence of First Order Methods for Quasar-Convex Optimization. (arXiv:2010.04937v1 [math.OC])</h2>
<h3>Jikai Jin</h3>
<p>In recent years, the success of deep learning has inspired many researchers
to study the optimization of general smooth non-convex functions. However,
recent works have established pessimistic worst-case complexities for this
class functions, which is in stark contrast with their superior performance in
real-world applications (e.g. training deep neural networks). On the other
hand, it is found that many popular non-convex optimization problems enjoy
certain structured properties which bear some similarities to convexity. In
this paper, we study the class of \textit{quasar-convex functions} to close the
gap between theory and practice. We study the convergence of first order
methods in a variety of different settings and under different optimality
criterions. We prove complexity upper bounds that are similar to standard
results established for convex functions and much better that state-of-the-art
convergence rates of non-convex functions. Overall, this paper suggests that
\textit{quasar-convexity} allows efficient optimization procedures, and we are
looking forward to seeing more problems that demonstrate similar properties in
practice.
</p>
<a href="http://arxiv.org/abs/2010.04937" target="_blank">arXiv:2010.04937</a> [<a href="http://arxiv.org/pdf/2010.04937" target="_blank">pdf</a>]

<h2>Decode efficient prefix codes. (arXiv:2010.05005v1 [cs.DS])</h2>
<h3>Shashwat Banchhor, Rishikesh Gajjala, Yogish Sabharwal, Sandeep Sen</h3>
<p>Data compression is used in a wide variety of tasks, including compression of
databases, large learning models, videos, images, etc. The cost of
decompressing (decoding) data can be prohibitive for certain real-time
applications. In many scenarios, it is acceptable to sacrifice (to some extent)
on compression in the interest of fast decoding. In this work, we introduce and
study a novel problem of finding a prefix tree having the best decode time
under the constraint that the code length does not exceed a certain threshold
for a natural class of memory access cost functions that use blocking (also
referred to as lookup tables), i.e., these decoding schemes access multiple
prefix tree entries in a single access, using associative memory table
look-ups. We present (i) an exact algorithm for this problem that is polynomial
in the number of characters and the codelength; (ii) a strongly polynomial
pseudo approximation algorithm that achieves the best decode time by relaxing
the codelength constraint by a small factor; and (iii) a more efficient version
of the pseudo approximation algorithm that achieves near optimal decode time by
relaxing the codelength constraint by a small factor. All our algorithms are
based on dynamic programming and capitalize on an interesting structure of the
optimal solution. To the best of our knowledge, there is no prior work that
gives any provable theoretical guarantees for minimizing decode time along with
the code length. We also demonstrate the performance benefits of our algorithm
on different types of real-world data sets, namely (i) a deep learning model
(Mobilenet-V2); (ii) image and (iii) text data. We also implement and evaluate
the performance of our algorithms on the GPU.
</p>
<a href="http://arxiv.org/abs/2010.05005" target="_blank">arXiv:2010.05005</a> [<a href="http://arxiv.org/pdf/2010.05005" target="_blank">pdf</a>]

<h2>Comparison of Short Blocklength Sphere Shaping and Nonlinearity Compensation in WDM Systems. (arXiv:2010.05021v1 [cs.IT])</h2>
<h3>Abdelkerim Amari, Lutz Lampe, O. S. Sunish Kumar, Yunus Can Gultekin, Alex Alvarado</h3>
<p>In optical communication systems, short blocklength probabilistic enumerative
sphere shaping (ESS) provides both linear shaping gain and nonlinear tolerance.
In this work, we investigate the performance and complexity of ESS in
comparison with fiber nonlinearity compensation via digital back propagation
(DBP) with different steps per span. We evaluate the impact of the shaping
blocklength in terms of nonlinear tolerance and also consider the case of ESS
with a Volterra-based nonlinear equalizer (VNLE), which provides lower
complexity than DBP. In single-channel transmission, ESS with VNLE achieves
similar performance in terms of finite length bit-metric decoding rate to
uniform signaling with one step per span DBP. In the context of a dense
wavelength-division multiplexing (WDM) transmission system, we show that ESS
outperforms uniform signaling with DBP for different step sizes.
</p>
<a href="http://arxiv.org/abs/2010.05021" target="_blank">arXiv:2010.05021</a> [<a href="http://arxiv.org/pdf/2010.05021" target="_blank">pdf</a>]

<h2>Maximin Optimization for Binary Regression. (arXiv:2010.05077v1 [cs.LG])</h2>
<h3>Nisan Chiprut, Amir Globerson, Ami Wiesel</h3>
<p>We consider regression problems with binary weights. Such optimization
problems are ubiquitous in quantized learning models and digital communication
systems. A natural approach is to optimize the corresponding Lagrangian using
variants of the gradient ascent-descent method. Such maximin techniques are
still poorly understood even in the concave-convex case. The non-convex binary
constraints may lead to spurious local minima. Interestingly, we prove that
this approach is optimal in linear regression with low noise conditions as well
as robust regression with a small number of outliers. Practically, the method
also performs well in regression with cross entropy loss, as well as non-convex
multi-layer neural networks. Taken together our approach highlights the
potential of saddle-point optimization for learning constrained models.
</p>
<a href="http://arxiv.org/abs/2010.05077" target="_blank">arXiv:2010.05077</a> [<a href="http://arxiv.org/pdf/2010.05077" target="_blank">pdf</a>]

<h2>AEGD: Adaptive Gradient Decent with Energy. (arXiv:2010.05109v1 [math.OC])</h2>
<h3>Hailiang Liu, Xuping Tian</h3>
<p>In this paper, we propose AEGD, a new algorithm for first-order
gradient-based optimization of stochastic objective functions, based on
adaptive updates of quadratic energy. As long as an objective function is
bounded from below, AEGD can be applied, and it is shown to be unconditionally
energy stable, irrespective of the step size. In addition, AEGD enjoys tight
convergence rates, yet allows a large step size. The method is straightforward
to implement and requires little tuning of hyper-parameters. Experimental
results demonstrate that AEGD works well for various optimization problems: it
is robust with respect to initial data, capable of making rapid initial
progress, shows comparable and most times better generalization performance
than SGD with momentum for deep neural networks. The implementation of the
algorithm can be found at https://github.com/txping/AEGD.
</p>
<a href="http://arxiv.org/abs/2010.05109" target="_blank">arXiv:2010.05109</a> [<a href="http://arxiv.org/pdf/2010.05109" target="_blank">pdf</a>]

<h2>What causes the test error? Going beyond bias-variance via ANOVA. (arXiv:2010.05170v1 [stat.ML])</h2>
<h3>Licong Lin, Edgar Dobriban</h3>
<p>Modern machine learning methods are often overparametrized, allowing
adaptation to the data at a fine level. This can seem puzzling; in the worst
case, such models do not need to generalize. This puzzle inspired a great
amount of work, arguing when overparametrization reduces test error, in a
phenomenon called "double descent". Recent work aimed to understand in greater
depth why overparametrization is helpful for generalization. This leads to
discovering the unimodality of variance as a function of the level of
parametrization, and to decomposing the variance into that arising from label
noise, initialization, and randomness in the training data to understand the
sources of the error.

In this work we develop a deeper understanding of this area. Specifically, we
propose using the analysis of variance (ANOVA) to decompose the variance in the
test error in a symmetric way, for studying the generalization performance of
certain two-layer linear and non-linear networks. The advantage of the analysis
of variance is that it reveals the effects of initialization, label noise, and
training data more clearly than prior approaches. Moreover, we also study the
monotonicity and unimodality of the variance components. While prior work
studied the unimodality of the overall variance, we study the properties of
each term in variance decomposition.

One key insight is that in typical settings, the interaction between training
samples and initialization can dominate the variance; surprisingly being larger
than their marginal effect. Also, we characterize "phase transitions" where the
variance changes from unimodal to monotone. On a technical level, we leverage
advanced deterministic equivalent techniques for Haar random matrices,
that---to our knowledge---have not yet been used in the area. We also verify
our results in numerical simulations and on empirical data examples.
</p>
<a href="http://arxiv.org/abs/2010.05170" target="_blank">arXiv:2010.05170</a> [<a href="http://arxiv.org/pdf/2010.05170" target="_blank">pdf</a>]

<h2>Efficient Long-Range Convolutions for Point Clouds. (arXiv:2010.05295v1 [stat.ML])</h2>
<h3>Yifan Peng, Lin Lin, Lexing Ying, Leonardo Zepeda-N&#xfa;&#xf1;ez</h3>
<p>The efficient treatment of long-range interactions for point clouds is a
challenging problem in many scientific machine learning applications. To
extract global information, one usually needs a large window size, a large
number of layers, and/or a large number of channels. This can often
significantly increase the computational cost. In this work, we present a novel
neural network layer that directly incorporates long-range information for a
point cloud. This layer, dubbed the long-range convolutional (LRC)-layer,
leverages the convolutional theorem coupled with the non-uniform Fourier
transform. In a nutshell, the LRC-layer mollifies the point cloud to an
adequately sized regular grid, computes its Fourier transform, multiplies the
result by a set of trainable Fourier multipliers, computes the inverse Fourier
transform, and finally interpolates the result back to the point cloud. The
resulting global all-to-all convolution operation can be performed in
nearly-linear time asymptotically with respect to the number of input points.
The LRC-layer is a particularly powerful tool when combined with local
convolution as together they offer efficient and seamless treatment of both
short and long range interactions. We showcase this framework by introducing a
neural network architecture that combines LRC-layers with short-range
convolutional layers to accurately learn the energy and force associated with a
$N$-body potential. We also exploit the induced two-level decomposition and
propose an efficient strategy to train the combined architecture with a reduced
number of samples.
</p>
<a href="http://arxiv.org/abs/2010.05295" target="_blank">arXiv:2010.05295</a> [<a href="http://arxiv.org/pdf/2010.05295" target="_blank">pdf</a>]

<h2>Learning Linear Non-Gaussian Graphical Models with Multidirected Edges. (arXiv:2010.05306v1 [cs.LG])</h2>
<h3>Yiheng Liu, Elina Robeva, Huanqing Wang</h3>
<p>In this paper we propose a new method to learn the underlying acyclic mixed
graph of a linear non-Gaussian structural equation model given observational
data. We build on an algorithm proposed by Wang and Drton, and we show that one
can augment the hidden variable structure of the recovered model by learning
{\em multidirected edges} rather than only directed and bidirected ones.
Multidirected edges appear when more than two of the observed variables have a
hidden common cause. We detect the presence of such hidden causes by looking at
higher order cumulants and exploiting the multi-trek rule. Our method recovers
the correct structure when the underlying graph is a bow-free acyclic mixed
graph with potential multi-directed edges.
</p>
<a href="http://arxiv.org/abs/2010.05306" target="_blank">arXiv:2010.05306</a> [<a href="http://arxiv.org/pdf/2010.05306" target="_blank">pdf</a>]

<h2>Koopman Operator, Geometry, and Learning. (arXiv:2010.05377v1 [math.DS])</h2>
<h3>Igor Mezic</h3>
<p>We provide a framework for learning of dynamical systems rooted in the
concept of representations and Koopman operators. The interplay between the two
leads to the full description of systems that can be represented linearly in a
finite dimension, based on the properties of the Koopman operator spectrum. The
geometry of state space is connected to the notion of representation, both in
the linear case - where it is related to joint level sets of eigenfunctions -
and in the nonlinear representation case. As shown here, even nonlinear
finite-dimensional representations can be learned using the Koopman operator
framework, leading to a new class of representation eigenproblems. The
connection to learning using neural networks is given. An extension of the
Koopman operator theory to "static" maps between different spaces is provided.
The effect of the Koopman operator spectrum on Mori-Zwanzig type
representations is discussed.
</p>
<a href="http://arxiv.org/abs/2010.05377" target="_blank">arXiv:2010.05377</a> [<a href="http://arxiv.org/pdf/2010.05377" target="_blank">pdf</a>]

<h2>Throughput Analysis of Small Cell Networks under D-TDD and FFR. (arXiv:2010.05426v1 [cs.IT])</h2>
<h3>Meiyan Song, Hangguan Shan, Howard H. Yang, Tony Q. S. Quek</h3>
<p>Dynamic time-division duplex (D-TDD) has emerged as an effective solution to
accommodate the unaligned downlink and uplink traffic in small cell networks.
However, the flexibility of traffic configuration also introduces additional
inter-cell interference. In this letter, we study the effectiveness of applying
fractional frequency reuse (FFR) as an interference coordination technique for
D-TDD small cell networks. We derive the analytical expressions of downlink and
uplink mean packet throughput (MPT), then study a network parameter
optimization problem to maximize MPT while guaranteeing each user's throughput.
Numerical results corroborate the benefits of the proposed FFR-based D-TDD in
terms of improving throughput.
</p>
<a href="http://arxiv.org/abs/2010.05426" target="_blank">arXiv:2010.05426</a> [<a href="http://arxiv.org/pdf/2010.05426" target="_blank">pdf</a>]

<h2>Towards Expressive Graph Representation. (arXiv:2010.05427v1 [cs.LG])</h2>
<h3>Chengsheng Mao, Liang Yao, Yuan Luo</h3>
<p>Graph Neural Network (GNN) aggregates the neighborhood of each node into the
node embedding and shows its powerful capability for graph representation
learning. However, most existing GNN variants aggregate the neighborhood
information in a fixed non-injective fashion, which may map different graphs or
nodes to the same embedding, reducing the model expressiveness. We present a
theoretical framework to design a continuous injective set function for
neighborhood aggregation in GNN. Using the framework, we propose expressive GNN
that aggregates the neighborhood of each node with a continuous injective set
function, so that a GNN layer maps similar nodes with similar neighborhoods to
similar embeddings, different nodes to different embeddings and the equivalent
nodes or isomorphic graphs to the same embeddings. Moreover, the proposed
expressive GNN can naturally learn expressive representations for graphs with
continuous node attributes. We validate the proposed expressive GNN (ExpGNN)
for graph classification on multiple benchmark datasets including simple graphs
and attributed graphs. The experimental results demonstrate that our model
achieves state-of-the-art performances on most of the benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.05427" target="_blank">arXiv:2010.05427</a> [<a href="http://arxiv.org/pdf/2010.05427" target="_blank">pdf</a>]

<h2>Towards Theoretically Understanding Why SGD Generalizes Better Than ADAM in Deep Learning. (arXiv:2010.05627v1 [cs.LG])</h2>
<h3>Pan Zhou, Jiashi Feng, Chao Ma, Caiming Xiong, Steven HOI, Weinan E</h3>
<p>It is not clear yet why ADAM-alike adaptive gradient algorithms suffer from
worse generalization performance than SGD despite their faster training speed.
This work aims to provide understandings on this generalization gap by
analyzing their local convergence behaviors. Specifically, we observe the heavy
tails of gradient noise in these algorithms. This motivates us to analyze these
algorithms through their Levy-driven stochastic differential equations (SDEs)
because of the similar convergence behaviors of an algorithm and its SDE. Then
we establish the escaping time of these SDEs from a local basin. The result
shows that (1) the escaping time of both SGD and ADAM~depends on the Radon
measure of the basin positively and the heaviness of gradient noise negatively;
(2) for the same basin, SGD enjoys smaller escaping time than ADAM, mainly
because (a) the geometry adaptation in ADAM~via adaptively scaling each
gradient coordinate well diminishes the anisotropic structure in gradient noise
and results in larger Radon measure of a basin; (b) the exponential gradient
average in ADAM~smooths its gradient and leads to lighter gradient noise tails
than SGD. So SGD is more locally unstable than ADAM~at sharp minima defined as
the minima whose local basins have small Radon measure, and can better escape
from them to flatter ones with larger Radon measure. As flat minima here which
often refer to the minima at flat or asymmetric basins/valleys often generalize
better than sharp ones~\cite{keskar2016large,he2019asymmetric}, our result
explains the better generalization performance of SGD over ADAM. Finally,
experimental results confirm our heavy-tailed gradient noise assumption and
theoretical affirmation.
</p>
<a href="http://arxiv.org/abs/2010.05627" target="_blank">arXiv:2010.05627</a> [<a href="http://arxiv.org/pdf/2010.05627" target="_blank">pdf</a>]

<h2>Learning to Decode: Reinforcement Learning for Decoding of Sparse Graph-Based Channel Codes. (arXiv:2010.05637v1 [cs.IT])</h2>
<h3>Salman Habib, Allison Beemer, Joerg Kliewer</h3>
<p>We show in this work that reinforcement learning can be successfully applied
to decoding short to moderate length sparse graph-based channel codes.
Specifically, we focus on low-density parity check (LDPC) codes, which for
example have been standardized in the context of 5G cellular communication
systems due to their excellent error correcting performance. These codes are
typically decoded via belief propagation iterative decoding on the
corresponding bipartite (Tanner) graph of the code via flooding, i.e., all
check and variable nodes in the Tanner graph are updated at once. In contrast,
in this paper we utilize a sequential update policy which selects the optimum
check node (CN) scheduling in order to improve decoding performance. In
particular, we model the CN update process as a multi-armed bandit process with
dependent arms and employ a Q-learning scheme for optimizing the CN scheduling
policy. In order to reduce the learning complexity, we propose a novel
graph-induced CN clustering approach to partition the state space in such a way
that dependencies between clusters are minimized. Our results show that
compared to other decoding approaches from the literature, the proposed
reinforcement learning scheme not only significantly improves the decoding
performance, but also reduces the decoding complexity dramatically once the
model is learned.
</p>
<a href="http://arxiv.org/abs/2010.05637" target="_blank">arXiv:2010.05637</a> [<a href="http://arxiv.org/pdf/2010.05637" target="_blank">pdf</a>]

<h2>Optimization and Machine Learning Training Algorithms for Fitting Numerical Physics Models. (arXiv:2010.05668v1 [nucl-th])</h2>
<h3>Raghu Bollapragada, Matt Menickelly, Witold Nazarewicz, Jared O&#x27;Neal, Paul-Gerhard Reinhard, Stefan M. Wild</h3>
<p>We address the calibration of a computationally expensive nuclear physics
model for which derivative information with respect to the fit parameters is
not readily available. Of particular interest is the performance of
optimization-based training algorithms when dozens, rather than millions or
more, of training data are available and when the expense of the model places
limitations on the number of concurrent model evaluations that can be
performed.

As a case study, we consider the Fayans energy density functional model,
which has characteristics similar to many model fitting and calibration
problems in nuclear physics. We analyze hyperparameter tuning considerations
and variability associated with stochastic optimization algorithms and
illustrate considerations for tuning in different computational settings.
</p>
<a href="http://arxiv.org/abs/2010.05668" target="_blank">arXiv:2010.05668</a> [<a href="http://arxiv.org/pdf/2010.05668" target="_blank">pdf</a>]

<h2>Deep Autoencoder based Energy Method for the Bending, Vibration, and Buckling Analysis of Kirchhoff Plates. (arXiv:2010.05698v1 [cs.LG])</h2>
<h3>Xiaoying Zhuang, Hongwei Guo, Naif Alajlan, Timon Rabczuk</h3>
<p>In this paper, we present a deep autoencoder based energy method (DAEM) for
the bending, vibration and buckling analysis of Kirchhoff plates. The DAEM
exploits the higher order continuity of the DAEM and integrates a deep
autoencoder and the minimum total potential principle in one framework yielding
an unsupervised feature learning method. The DAEM is a specific type of
feedforward deep neural network (DNN) and can also serve as function
approximator. With robust feature extraction capacity, the DAEM can more
efficiently identify patterns behind the whole energy system, such as the field
variables, natural frequency and critical buckling load factor studied in this
paper. The objective function is to minimize the total potential energy. The
DAEM performs unsupervised learning based on random generated points inside the
physical domain so that the total potential energy is minimized at all points.
For vibration and buckling analysis, the loss function is constructed based on
Rayleigh's principle and the fundamental frequency and the critical buckling
load is extracted. A scaled hyperbolic tangent activation function for the
underlying mechanical model is presented which meets the continuity requirement
and alleviates the gradient vanishing/explosive problems under bending
analysis. The DAEM can be easily implemented and we employed the Pytorch
library and the LBFGS optimizer. A comprehensive study of the DAEM
configuration is performed for several numerical examples with various
geometries, load conditions, and boundary conditions.
</p>
<a href="http://arxiv.org/abs/2010.05698" target="_blank">arXiv:2010.05698</a> [<a href="http://arxiv.org/pdf/2010.05698" target="_blank">pdf</a>]

<h2>Capturing Dynamics of Time-Varying Data via Topology. (arXiv:2010.05780v1 [cs.LG])</h2>
<h3>Lu Xian, Henry Adams, Chad M. Topaz, Lori Ziegelmeier</h3>
<p>One approach to understanding complex data is to study its shape through the
lens of algebraic topology. While the early development of topological data
analysis focused primarily on static data, in recent years, theoretical and
applied studies have turned to data that varies in time. A time-varying
collection of metric spaces as formed, for example, by a moving school of fish
or flock of birds, can contain a vast amount of information. There is often a
need to simplify or summarize the dynamic behavior. We provide an introduction
to topological summaries of time-varying metric spaces including vineyards
[17], crocker plots [52], and multiparameter rank functions [34]. We then
introduce a new tool to summarize time-varying metric spaces: a crocker stack.
Crocker stacks are convenient for visualization, amenable to machine learning,
and satisfy a desirable stability property which we prove. We demonstrate the
utility of crocker stacks for a parameter identification task involving an
influential model of biological aggregations [54]. Altogether, we aim to bring
the broader applied mathematics community up-to-date on topological summaries
of time-varying metric spaces.
</p>
<a href="http://arxiv.org/abs/2010.05780" target="_blank">arXiv:2010.05780</a> [<a href="http://arxiv.org/pdf/2010.05780" target="_blank">pdf</a>]

<h2>Permutation invariant networks to learn Wasserstein metrics. (arXiv:2010.05820v1 [cs.LG])</h2>
<h3>Arijit Sehanobish, Neal Ravindra, David van Dijk</h3>
<p>Understanding the space of probability measures on a metric space equipped
with a Wasserstein distance is one of the fundamental questions in mathematical
analysis. The Wasserstein metric has received a lot of attention in the machine
learning community especially for its principled way of comparing
distributions. In this work, we use a permutation invariant network to map
samples from probability measures into a low-dimensional space such that the
Euclidean distance between the encoded samples reflects the Wasserstein
distance between probability measures. We show that our network can generalize
to correctly compute distances between unseen densities. We also show that
these networks can learn the first and the second moments of probability
distributions.
</p>
<a href="http://arxiv.org/abs/2010.05820" target="_blank">arXiv:2010.05820</a> [<a href="http://arxiv.org/pdf/2010.05820" target="_blank">pdf</a>]

<h2>Stability and chaos in dynamical last passage percolation. (arXiv:2010.05837v1 [math.PR])</h2>
<h3>Shirshendu Ganguly, Alan Hammond</h3>
<p>Many complex statistical mechanical models have intricate energy landscapes.
The ground state, or lowest energy state, lies at the base of the deepest
valley. In examples such as spin glasses and Gaussian polymers, there are many
valleys; the abundance of near-ground states (at the base of valleys) indicates
the phenomenon of chaos, under which the ground state alters profoundly when
the model's disorder is slightly perturbed. In this article, we compute the
critical exponent that governs the onset of chaos in a dynamic manifestation of
a canonical model in the Kardar-Parisi-Zhang [KPZ] universality class, Brownian
last passage percolation [LPP]. In this model in its static form, semi-discrete
polymers advance through Brownian noise, their energy given by the integral of
the white noise encountered along their journey. A ground state is a geodesic,
of extremal energy given its endpoints. We perturb Brownian LPP by evolving the
disorder under an Ornstein-Uhlenbeck flow. We prove that, for polymers of
length $n$, a sharp phase transition marking the onset of chaos is witnessed at
the critical time $n^{-1/3}$. Indeed, the overlap between the geodesics at
times zero and $t &gt; 0$ that travel a given distance of order $n$ will be shown
to be of order $n$ when $t\ll n^{-1/3}$; and to be of smaller order when $t\gg
n^{-1/3}$. We expect this exponent to be shared among many interface models.
The present work thus sheds light on the dynamical aspect of the KPZ class; it
builds on several recent advances. These include Chatterjee's harmonic analytic
theory [Cha14] of equivalence of superconcentration and chaos in Gaussian
spaces; a refined understanding of the static landscape geometry of Brownian
LPP developed in the companion paper [GH20]; and, underlying the latter, strong
comparison estimates of the geodesic energy profile to Brownian motion in
[CHH19].
</p>
<a href="http://arxiv.org/abs/2010.05837" target="_blank">arXiv:2010.05837</a> [<a href="http://arxiv.org/pdf/2010.05837" target="_blank">pdf</a>]

<h2>Control of Unknown (Linear) Systems with Receding Horizon Learning. (arXiv:2010.05891v1 [eess.SY])</h2>
<h3>Christian Ebenbauer, Fabian Pfitz, Shuyou Yu</h3>
<p>A receding horizon learning scheme is proposed to transfer the state of a
discrete-time dynamical control system to zero without the need of a system
model. Global state convergence to zero is proved for the class of stabilizable
and detectable linear time-invariant systems, assuming that only input and
output data is available and an upper bound of the state dimension is known.
The proposed scheme consists of a receding horizon control scheme and a
proximity-based estimation scheme to estimate and control the closed-loop
trajectory. Simulations are presented for linear and nonlinear systems.
</p>
<a href="http://arxiv.org/abs/2010.05891" target="_blank">arXiv:2010.05891</a> [<a href="http://arxiv.org/pdf/2010.05891" target="_blank">pdf</a>]

<h2>SLIP: Learning to Predict in Unknown Dynamical Systems with Long-Term Memory. (arXiv:2010.05899v1 [cs.LG])</h2>
<h3>Paria Rashidinejad, Jiantao Jiao, Stuart Russell</h3>
<p>We present an efficient and practical (polynomial time) algorithm for online
prediction in unknown and partially observed linear dynamical systems (LDS)
under stochastic noise. When the system parameters are known, the optimal
linear predictor is the Kalman filter. However, the performance of existing
predictive models is poor in important classes of LDS that are only marginally
stable and exhibit long-term forecast memory. We tackle this problem through
bounding the generalized Kolmogorov width of the Kalman filter model by
spectral methods and conducting tight convex relaxation. We provide a
finite-sample analysis, showing that our algorithm competes with Kalman filter
in hindsight with only logarithmic regret. Our regret analysis relies on
Mendelson's small-ball method, providing sharp error bounds without
concentration, boundedness, or exponential forgetting assumptions. We also give
experimental results demonstrating that our algorithm outperforms
state-of-the-art methods. Our theoretical and experimental results shed light
on the conditions required for efficient probably approximately correct (PAC)
learning of the Kalman filter from partially observed data.
</p>
<a href="http://arxiv.org/abs/2010.05899" target="_blank">arXiv:2010.05899</a> [<a href="http://arxiv.org/pdf/2010.05899" target="_blank">pdf</a>]

<h2>Graph Matrices: Norm Bounds and Applications. (arXiv:1604.03423v4 [math.CO] UPDATED)</h2>
<h3>Kwangjun Ahn, Dhruv Medarametla, Aaron Potechin</h3>
<p>Graph matrices are a type of random matrix which has the following
properties:

1. The entries of the matrix depend on a random input. Moreover, this
dependence can be described by a small graph.

2. The matrix (as a function of the input) is symmetric under permutations of
$[n]$.

Graph matrices are important objects to study because they are closely
connected to the sum of squares hierarchy, one of the most powerful techniques
we know of for solving combinatorial optimization problems as well as inference
problems arising from physics and machine learning. However, since graph
matrices generally have dependent entries, they are not captured by current
results in random matrix theory.

In this paper, we use the trace power method to prove a general norm bound on
all graph matrices which is accurate up to polylogarithmic factors. We then
describe several applications of this norm bound. In particular, we show that
for several technical lemmas in the literature, while the original analyses
were quite involved, we can give direct proofs using graph matrices and this
norm bound.
</p>
<a href="http://arxiv.org/abs/1604.03423" target="_blank">arXiv:1604.03423</a> [<a href="http://arxiv.org/pdf/1604.03423" target="_blank">pdf</a>]

<h2>Universal Bayes consistency in metric spaces. (arXiv:1906.09855v5 [cs.LG] UPDATED)</h2>
<h3>Steve Hanneke, Aryeh Kontorovich, Sivan Sabato, Roi Weiss</h3>
<p>We extend a recently proposed 1-nearest-neighbor-based multiclass learning
algorithm and prove that our modification is universally strongly
Bayes-consistent in all metric spaces admitting any such learner, making it an
"optimistically universal" Bayes-consistent learner. This is the first learning
algorithm known to enjoy this property; by comparison, the $k$-NN classifier
and its variants are not generally universally Bayes-consistent, except under
additional structural assumptions, such as an inner product, a norm, finite
dimension, or a Besicovitch-type property. The metric spaces in which universal
Bayes consistency is possible are the "essentially separable" ones -- a notion
that we define, which is more general than standard separability. The existence
of metric spaces that are not essentially separable is widely believed to be
independent of the ZFC axioms of set theory. We prove that essential
separability exactly characterizes the existence of a universal
Bayes-consistent learner for the given metric space. In particular, this yields
the first impossibility result for universal Bayes consistency. Taken together,
our results completely characterize strong and weak universal Bayes consistency
in metric spaces.
</p>
<a href="http://arxiv.org/abs/1906.09855" target="_blank">arXiv:1906.09855</a> [<a href="http://arxiv.org/pdf/1906.09855" target="_blank">pdf</a>]

<h2>Eight-dimensional Octonion-like but Associative Normed Division Algebra. (arXiv:1908.06172v5 [math.GM] UPDATED)</h2>
<h3>Joy Christian (Oxford)</h3>
<p>We present an eight-dimensional even sub-algebra of the 2^4 = 16-dimensional
associative Clifford algebra Cl(4,0) and show that its eight-dimensional
elements denoted as X and Y respect the norm relation ||XY|| = ||X|| ||Y||,
thus forming an octonion-like but associative normed division algebra, provided
the norms are calculated using fundamental geometric product instead of the
usual scalar product. The corresponding 7-sphere has a topology that differs
from that of octonionic 7-sphere.
</p>
<a href="http://arxiv.org/abs/1908.06172" target="_blank">arXiv:1908.06172</a> [<a href="http://arxiv.org/pdf/1908.06172" target="_blank">pdf</a>]

<h2>Exact model comparisons in the plausibility framework. (arXiv:1911.00469v2 [math.ST] UPDATED)</h2>
<h3>Stefan B&#xf6;hringer, Dietmar Lohmann</h3>
<p>Plausibility is a formalization of exact tests for parametric models and
generalizes procedures such as Fisher's exact test. The resulting tests are
based on cumulative probabilities of the probability density function and
evaluate consistency with a parametric family while providing exact control of
the $\alpha$ level for finite sample size. Model comparisons are inefficient in
this approach. We generalize plausibility by incorporating weighing which
allows to perform model comparisons. We show that one weighing scheme is
asymptotically equivalent to the likelihood ratio test (LRT) and has finite
sample guarantees for the test size under the null hypothesis unlike the LRT.
We confirm theoretical properties in simulations that mimic the data set of our
data application. We apply the method to a retinoblastoma data set and
demonstrate a parent-of-origin effect. Weighted plausibility also has
applications in high-dimensional data analysis and P-values for penalized
regression models can be derived. We demonstrate superior performance as
compared to a data-splitting procedure in a simulation study. We apply weighted
plausibility to a high-dimensional gene expression, case-control prostate
cancer data set. We discuss the flexibility of the approach by relating
weighted plausibility to targeted learning, the bootstrap, and sparsity
selection.
</p>
<a href="http://arxiv.org/abs/1911.00469" target="_blank">arXiv:1911.00469</a> [<a href="http://arxiv.org/pdf/1911.00469" target="_blank">pdf</a>]

<h2>Minimax Value Interval for Off-Policy Evaluation and Policy Optimization. (arXiv:2002.02081v4 [cs.LG] UPDATED)</h2>
<h3>Nan Jiang, Jiawei Huang</h3>
<p>We study minimax methods for off-policy evaluation (OPE) using value
functions and marginalized importance weights. Despite that they hold promises
of overcoming the exponential variance in traditional importance sampling,
several key problems remain:

(1) They require function approximation and are generally biased. For the
sake of trustworthy OPE, is there anyway to quantify the biases?

(2) They are split into two styles ("weight-learning" vs "value-learning").
Can we unify them?

In this paper we answer both questions positively. By slightly altering the
derivation of previous methods (one from each style; Uehara et al., 2020), we
unify them into a single value interval that comes with a special type of
double robustness: when either the value-function or the importance-weight
class is well specified, the interval is valid and its length quantifies the
misspecification of the other class. Our interval also provides a unified view
of and new insights to some recent methods, and we further explore the
implications of our results on exploration and exploitation in off-policy
policy optimization with insufficient data coverage.
</p>
<a href="http://arxiv.org/abs/2002.02081" target="_blank">arXiv:2002.02081</a> [<a href="http://arxiv.org/pdf/2002.02081" target="_blank">pdf</a>]

<h2>Stochastic gradient descent with random learning rate. (arXiv:2003.06926v4 [cs.LG] UPDATED)</h2>
<h3>Daniele Musso</h3>
<p>We propose to optimize neural networks with a uniformly-distributed random
learning rate. The associated stochastic gradient descent algorithm can be
approximated by continuous stochastic equations and analyzed within the
Fokker-Planck formalism. In the small learning rate regime, the training
process is characterized by an effective temperature which depends on the
average learning rate, the mini-batch size and the momentum of the optimization
algorithm. By comparing the random learning rate protocol with cyclic and
constant protocols, we suggest that the random choice is generically the best
strategy in the small learning rate regime, yielding better regularization
without extra computational cost. We provide supporting evidence through
experiments on both shallow, fully-connected and deep, convolutional neural
networks for image classification on the MNIST and CIFAR10 datasets.
</p>
<a href="http://arxiv.org/abs/2003.06926" target="_blank">arXiv:2003.06926</a> [<a href="http://arxiv.org/pdf/2003.06926" target="_blank">pdf</a>]

<h2>MomentumRNN: Integrating Momentum into Recurrent Neural Networks. (arXiv:2006.06919v2 [cs.LG] UPDATED)</h2>
<h3>Tan M. Nguyen, Richard G. Baraniuk, Andrea L. Bertozzi, Stanley J. Osher, Bao Wang</h3>
<p>Designing deep neural networks is an art that often involves an expensive
search over candidate architectures. To overcome this for recurrent neural nets
(RNNs), we establish a connection between the hidden state dynamics in an RNN
and gradient descent (GD). We then integrate momentum into this framework and
propose a new family of RNNs, called {\em MomentumRNNs}. We theoretically prove
and numerically demonstrate that MomentumRNNs alleviate the vanishing gradient
issue in training RNNs. We study the momentum long-short term memory
(MomentumLSTM) and verify its advantages in convergence speed and accuracy over
its LSTM counterpart across a variety of benchmarks. We also demonstrate that
MomentumRNN is applicable to many types of recurrent cells, including those in
the state-of-the-art orthogonal RNNs. Finally, we show that other advanced
momentum-based optimization methods, such as Adam and Nesterov accelerated
gradients with a restart, can be easily incorporated into the MomentumRNN
framework for designing new recurrent cells with even better performance. The
code is available at https://github.com/minhtannguyen/MomentumRNN.
</p>
<a href="http://arxiv.org/abs/2006.06919" target="_blank">arXiv:2006.06919</a> [<a href="http://arxiv.org/pdf/2006.06919" target="_blank">pdf</a>]

<h2>Interpolation and Learning with Scale Dependent Kernels. (arXiv:2006.09984v2 [stat.ML] UPDATED)</h2>
<h3>Nicol&#xf2; Pagliana, Alessandro Rudi, Ernesto De Vito, Lorenzo Rosasco</h3>
<p>We study the learning properties of nonparametric ridge-less least squares.
In particular, we consider the common case of estimators defined by scale
dependent kernels, and focus on the role of the scale. These estimators
interpolate the data and the scale can be shown to control their stability
through the condition number. Our analysis shows that are different regimes
depending on the interplay between the sample size, its dimensions, and the
smoothness of the problem. Indeed, when the sample size is less than
exponential in the data dimension, then the scale can be chosen so that the
learning error decreases. As the sample size becomes larger, the overall error
stop decreasing but interestingly the scale can be chosen in such a way that
the variance due to noise remains bounded. Our analysis combines, probabilistic
results with a number of analytic techniques from interpolation theory.
</p>
<a href="http://arxiv.org/abs/2006.09984" target="_blank">arXiv:2006.09984</a> [<a href="http://arxiv.org/pdf/2006.09984" target="_blank">pdf</a>]

<h2>Theory-Inspired Path-Regularized Differential Network Architecture Search. (arXiv:2006.16537v2 [cs.LG] UPDATED)</h2>
<h3>Pan Zhou, Caiming Xiong, Richard Socher, Steven C.H. Hoi</h3>
<p>Despite its high search efficiency, differential architecture search (DARTS)
often selects network architectures with dominated skip connections which lead
to performance degradation. However, theoretical understandings on this issue
remain absent, hindering the development of more advanced methods in a
principled way. In this work, we solve this problem by theoretically analyzing
the effects of various types of operations, e.g. convolution, skip connection
and zero operation, to the network optimization. We prove that the
architectures with more skip connections can converge faster than the other
candidates, and thus are selected by DARTS. This result, for the first time,
theoretically and explicitly reveals the impact of skip connections to fast
network optimization and its competitive advantage over other types of
operations in DARTS. Then we propose a theory-inspired path-regularized DARTS
that consists of two key modules: (i) a differential group-structured sparse
binary gate introduced for each operation to avoid unfair competition among
operations, and (ii) a path-depth-wise regularization used to incite search
exploration for deep architectures that often converge slower than shallow ones
as shown in our theory and are not well explored during the search.
Experimental results on image classification tasks validate its advantages.
</p>
<a href="http://arxiv.org/abs/2006.16537" target="_blank">arXiv:2006.16537</a> [<a href="http://arxiv.org/pdf/2006.16537" target="_blank">pdf</a>]

<h2>Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal Sample Complexity. (arXiv:2007.07461v2 [cs.LG] UPDATED)</h2>
<h3>Kaiqing Zhang, Sham M. Kakade, Tamer Ba&#x15f;ar, Lin F. Yang</h3>
<p>Model-based reinforcement learning (RL), which finds an optimal policy using
an empirical model, has long been recognized as one of the corner stones of RL.
It is especially suitable for multi-agent RL (MARL), as it naturally decouples
the learning and the planning phases, and avoids the non-stationarity problem
when all agents are improving their policies simultaneously using samples.
Though intuitive and widely-used, the sample complexity of model-based MARL
algorithms has not been fully investigated. In this paper, our goal is to
address the fundamental question about its sample complexity. We study arguably
the most basic MARL setting: two-player discounted zero-sum Markov games, given
only access to a generative model. We show that model-based MARL achieves a
sample complexity of $\tilde O(|S||A||B|(1-\gamma)^{-3}\epsilon^{-2})$ for
finding the Nash equilibrium (NE) value up to some $\epsilon$ error, and the
$\epsilon$-NE policies with a smooth planning oracle, where $\gamma$ is the
discount factor, and $S,A,B$ denote the state space, and the action spaces for
the two agents. We further show that such a sample bound is minimax-optimal (up
to logarithmic factors) if the algorithm is reward-agnostic, where the
algorithm queries state transition samples without reward knowledge, by
establishing a matching lower bound. This is in contrast to the usual
reward-aware setting, with a
$\tilde\Omega(|S|(|A|+|B|)(1-\gamma)^{-3}\epsilon^{-2})$ lower bound, where
this model-based approach is near-optimal with only a gap on the $|A|,|B|$
dependence. Our results not only demonstrate the sample-efficiency of this
basic model-based approach in MARL, but also elaborate on the fundamental
tradeoff between its power (easily handling the more challenging
reward-agnostic case) and limitation (less adaptive and suboptimal in
$|A|,|B|$), particularly arises in the multi-agent context.
</p>
<a href="http://arxiv.org/abs/2007.07461" target="_blank">arXiv:2007.07461</a> [<a href="http://arxiv.org/pdf/2007.07461" target="_blank">pdf</a>]

<h2>Sum-Rate Maximization for IRS-Assisted UAV OFDMA Communication Systems. (arXiv:2008.09939v2 [cs.IT] UPDATED)</h2>
<h3>Zhiqiang Wei, Yuanxin Cai, Zhuo Sun, Derrick Wing Kwan Ng, Jinhong Yuan, Mingyu Zhou, Lixin Sun</h3>
<p>In this paper, we consider the application of intelligent reflecting surface
(IRS) in unmanned aerial vehicle (UAV)-based orthogonal frequency division
multiple access (OFDMA) communication systems, which exploits both the
significant beamforming gain brought by the IRS and the high mobility of UAV
for improving the system sum-rate. The joint design of UAV's trajectory, IRS
scheduling, and communication resource allocation for the proposed system is
formulated as a non-convex optimization problem to maximize the system sum-rate
while taking into account the heterogeneous quality-of-service (QoS)
requirement of each user. The existence of an IRS introduces both
frequency-selectivity and spatial-selectivity in the fading of the composite
channel from the UAV to ground users. To facilitate the design, we first derive
the expression of the composite channels and propose a parametric approximation
approach to establish an upper and a lower bound for the formulated problem. An
alternating optimization algorithm is devised to handle the lower bound
optimization problem and its performance is compared with the benchmark
performance achieved by solving the upper bound problem. Simulation results
unveil the small gap between the developed bounds and the promising sum-rate
gain achieved by the deployment of an IRS in UAV-based communication systems.
</p>
<a href="http://arxiv.org/abs/2008.09939" target="_blank">arXiv:2008.09939</a> [<a href="http://arxiv.org/pdf/2008.09939" target="_blank">pdf</a>]

<h2>A Topological Framework for Deep Learning. (arXiv:2008.13697v7 [cs.LG] UPDATED)</h2>
<h3>Mustafa Hajij, Kyle Istvan</h3>
<p>We utilize classical facts from topology to show that the classification
problem in machine learning is always solvable under very mild conditions.
Furthermore, we show that a softmax classification network acts on an input
topological space by a finite sequence of topological moves to achieve the
classification task. Moreover, given a training dataset, we show how
topological formalism can be used to suggest the appropriate architectural
choices for neural networks designed to be trained as classifiers on the data.
Finally, we show how the architecture of a neural network cannot be chosen
independently from the shape of the underlying data. To demonstrate these
results, we provide example datasets and show how they are acted upon by neural
nets from this topological perspective.
</p>
<a href="http://arxiv.org/abs/2008.13697" target="_blank">arXiv:2008.13697</a> [<a href="http://arxiv.org/pdf/2008.13697" target="_blank">pdf</a>]

<h2>Variance Reduced EXTRA and DIGing and Their Optimal Acceleration for Strongly Convex Decentralized Optimization. (arXiv:2009.04373v2 [math.OC] UPDATED)</h2>
<h3>Huan Li, Zhouchen Lin, Yongchun Fang</h3>
<p>We study stochastic decentralized optimization for the problem of training
machine learning models with large-scale distributed data. We extend the widely
used EXTRA and DIGing methods with variance reduction (VR), and propose two
methods: VR-EXTRA and VR-DIGing. The proposed VR-EXTRA requires the time of
$O((\kappa_s+n)\log\frac{1}{\epsilon})$ stochastic gradient evaluations and
$O((\kappa_b+\kappa_c)\log\frac{1}{\epsilon})$ communication rounds to reach
precision $\epsilon$, where $\kappa_s$ and $\kappa_b$ are the stochastic
condition number and batch condition number for strongly convex and smooth
problems, respectively, $\kappa_c$ is the condition number of the communication
network, and $n$ is the sample size on each distributed node. The proposed
VR-DIGing has a little higher communication cost of
$O((\kappa_b+\kappa_c^2)\log\frac{1}{\epsilon})$. Our stochastic gradient
computation complexities are the same as the ones of single-machine VR methods,
such as SAG, SAGA, and SVRG, and our communication complexities keep the same
as those of EXTRA and DIGing, respectively. To further speed up the
convergence, we also propose the accelerated VR-EXTRA and VR-DIGing with both
the optimal $O((\sqrt{n\kappa_s}+n)\log\frac{1}{\epsilon})$ stochastic gradient
computation complexity and $O(\sqrt{\kappa_b\kappa_c}\log\frac{1}{\epsilon})$
communication complexity. Our stochastic gradient computation complexity is
also the same as the ones of single-machine accelerated VR methods, such as
Katyusha, and our communication complexity keeps the same as those of
accelerated full batch decentralized methods, such as MSDA.
</p>
<a href="http://arxiv.org/abs/2009.04373" target="_blank">arXiv:2009.04373</a> [<a href="http://arxiv.org/pdf/2009.04373" target="_blank">pdf</a>]

<h2>Improving Convergence for Nonconvex Composite Programming. (arXiv:2009.10629v2 [math.OC] UPDATED)</h2>
<h3>Kai Yang, Masoud Asgharian, Sahir Bhatnagar</h3>
<p>High-dimensional nonconvex problems are popular in today's machine learning
and statistical genetics research. Recently, Ghadimi and Lan [1] proposed an
algorithm to optimize nonconvex high-dimensional problems. There are several
parameters in their algorithm that are to be set before running the algorithm.
It is not trivial how to choose these parameters nor there is, to the best of
our knowledge, an explicit rule on how to select the parameters to make the
algorithm converges faster. We analyze Ghadimi and Lan's algorithm to gain an
interpretation based on the inequality constraints for convergence and the
upper bound for the norm of the gradient analogue. Our interpretation of their
algorithm suggests this to be a damped Nesterov's acceleration scheme. Based on
this, we propose an approach on how to select the parameters to improve
convergence of the algorithm. Our numerical studies using high-dimensional
nonconvex sparse learning problems, motivated by image denoising and
statistical genetics applications, show that convergence can be made, on
average, considerably faster than that of the conventional ISTA algorithm for
such optimization problems with over $10000$ variables should the parameters be
chosen using our proposed approach.
</p>
<a href="http://arxiv.org/abs/2009.10629" target="_blank">arXiv:2009.10629</a> [<a href="http://arxiv.org/pdf/2009.10629" target="_blank">pdf</a>]

<h2>Definable Eilenberg--Mac Lane Universal Coefficient Theorems. (arXiv:2009.10805v3 [math.AT] UPDATED)</h2>
<h3>Martino Lupini</h3>
<p>We prove definable versions of the Universal Coefficient Theorems of
Eilenberg--Mac Lane expressing the (Steenrod) homology groups of a compact
metrizable space in terms of its integral cohomology groups, and the (\v{C}ech)
cohomology groups of a polyhedron in terms of its integral homology groups.
Precisely, we show that, given a compact metrizable space $X$, a (not
necessarily compact) polyhedron $Y$, and an abelian Polish group $G$ with the
division closure property, there are natural definable exact sequences
\begin{equation*} 0\rightarrow \mathrm{Ext}\left( H^{n+1}(X),G\right)
\rightarrow H_{n}(X;G)\rightarrow \mathrm{Hom}\left( H^{n}(X),G\right)
\rightarrow 0 \end{equation*} and \begin{equation*} 0\rightarrow
\mathrm{Ext}\left( H_{n-1}(Y),G\right) \rightarrow H^{n}(Y;G)\rightarrow
\mathrm{Hom}\left( H_{n}(Y),G\right) \rightarrow 0 \end{equation*} which
definably split, where $H_{n}(X;G)$ is the $n$-dimensional definable homology
group of $X$ with coefficients in $G$ and $H^{n}(Y;G)$ is the $n$ -dimensional
definable cohomology group of $Y$ with coefficients in $G$.

Both of these results are obtained as corollaries of a general algebraic
Universal Coefficient Theorem relating the cohomology of a cochain complex of
countable free abelian groups to the definable homology of its $G$-dual chain
complex of Polish groups.
</p>
<a href="http://arxiv.org/abs/2009.10805" target="_blank">arXiv:2009.10805</a> [<a href="http://arxiv.org/pdf/2009.10805" target="_blank">pdf</a>]

<h2>SPARC-LDPC Coding for MIMO Massive Unsourced Random Access. (arXiv:2009.10912v2 [cs.IT] UPDATED)</h2>
<h3>Tianya Li, Yongpeng Wu, Mengfan Zheng, Dongming Wang, Wenjun Zhang</h3>
<p>A joint sparse-regression-code (SPARC) and low-density-parity-check (LDPC)
coding scheme for multiple-input multiple-output (MIMO) massive unsourced
random access (URA) is proposed in this paper. Different from the
state-of-the-art covariance based maximum likelihood (CB-ML) detection scheme,
we first split users' messages into two parts. The former part is encoded by
SPARCs and tasked to recover part of the messages, the corresponding channel
coefficients as well as the interleaving patterns by compressed sensing. The
latter part is coded by LDPC codes and then interleaved by the
interleave-division multiple access (IDMA) scheme. The decoding of the latter
part is based on belief propogation (BP) joint with successive interference
cancellation (SIC). Numerical results show our scheme outperforms the CB-ML
scheme when the number of antennas at the base station is smaller than that of
active users. The complexity of our scheme is with the order
$\mathcal{O}\left(2^{B_p}ML+\widehat{K}ML\right)$ and lower than the CB-ML
scheme. Moreover, our scheme has higher spectral efficiency (nearly $15$ times
larger) than CB-ML as we only split messages into two parts.
</p>
<a href="http://arxiv.org/abs/2009.10912" target="_blank">arXiv:2009.10912</a> [<a href="http://arxiv.org/pdf/2009.10912" target="_blank">pdf</a>]

<h2>Finite-Time Analysis for Double Q-learning. (arXiv:2009.14257v2 [cs.LG] UPDATED)</h2>
<h3>Huaqing Xiong, Lin Zhao, Yingbin Liang, Wei Zhang</h3>
<p>Although Q-learning is one of the most successful algorithms for finding the
best action-value function (and thus the optimal policy) in reinforcement
learning, its implementation often suffers from large overestimation of
Q-function values incurred by random sampling. The double Q-learning algorithm
proposed in~\citet{hasselt2010double} overcomes such an overestimation issue by
randomly switching the update between two Q-estimators, and has thus gained
significant popularity in practice. However, the theoretical understanding of
double Q-learning is rather limited. So far only the asymptotic convergence has
been established, which does not characterize how fast the algorithm converges.
In this paper, we provide the first non-asymptotic (i.e., finite-time) analysis
for double Q-learning. We show that both synchronous and asynchronous double
Q-learning are guaranteed to converge to an $\epsilon$-accurate neighborhood of
the global optimum by taking $\tilde{\Omega}\left(\left(
\frac{1}{(1-\gamma)^6\epsilon^2}\right)^{\frac{1}{\omega}}
+\left(\frac{1}{1-\gamma}\right)^{\frac{1}{1-\omega}}\right)$ iterations, where
$\omega\in(0,1)$ is the decay parameter of the learning rate, and $\gamma$ is
the discount factor. Our analysis develops novel techniques to derive
finite-time bounds on the difference between two inter-connected stochastic
processes, which is new to the literature of stochastic approximation.
</p>
<a href="http://arxiv.org/abs/2009.14257" target="_blank">arXiv:2009.14257</a> [<a href="http://arxiv.org/pdf/2009.14257" target="_blank">pdf</a>]

<h2>Fictitious play in zero-sum stochastic games. (arXiv:2010.04223v2 [cs.GT] UPDATED)</h2>
<h3>Muhammed O. Sayin, Francesca Parise, Asuman Ozdaglar</h3>
<p>We present fictitious play dynamics for the general class of stochastic games
and analyze its convergence properties in zero-sum stochastic games. Our
dynamics involves agents forming beliefs on opponent strategy and their own
continuation payoff (Q-function), and playing a myopic best response using
estimated continuation payoffs. Agents update their beliefs at states visited
from observations of opponent actions. A key property of the learning dynamics
is that update of the beliefs on Q-functions occurs at a slower timescale than
update of the beliefs on strategies. We show both in the model-based and
model-free cases (without knowledge of agent payoff functions and state
transition probabilities), the beliefs on strategies converge to a stationary
mixed Nash equilibrium of the zero-sum stochastic game.
</p>
<a href="http://arxiv.org/abs/2010.04223" target="_blank">arXiv:2010.04223</a> [<a href="http://arxiv.org/pdf/2010.04223" target="_blank">pdf</a>]

<h2>Graph Convolutional Value Decomposition in Multi-Agent Reinforcement Learning. (arXiv:2010.04740v1 [cs.LG])</h2>
<h3>Navid Naderializadeh, Fan H. Hung, Sean Soleyman, Deepak Khosla</h3>
<p>We propose a novel framework for value function factorization in multi-agent
deep reinforcement learning using graph neural networks (GNNs). In particular,
we consider the team of agents as the set of nodes of a complete directed
graph, whose edge weights are governed by an attention mechanism. Building upon
this underlying graph, we introduce a mixing GNN module, which is responsible
for two tasks: i) factorizing the team state-action value function into
individual per-agent observation-action value functions, and ii) explicit
credit assignment to each agent in terms of fractions of the global team
reward. Our approach, which we call GraphMIX, follows the centralized training
and decentralized execution paradigm, enabling the agents to make their
decisions independently once training is completed. Experimental results on the
StarCraft II multi-agent challenge (SMAC) environment demonstrate the
superiority of our proposed approach as compared to the state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2010.04740" target="_blank">arXiv:2010.04740</a> [<a href="http://arxiv.org/pdf/2010.04740" target="_blank">pdf</a>]

<h2>Learning to Pronounce Chinese Without a Pronunciation Dictionary. (arXiv:2010.04744v1 [cs.CL])</h2>
<h3>Christopher Chu, Scot Fang, Kevin Knight</h3>
<p>We demonstrate a program that learns to pronounce Chinese text in Mandarin,
without a pronunciation dictionary. From non-parallel streams of Chinese
characters and Chinese pinyin syllables, it establishes a many-to-many mapping
between characters and pronunciations. Using unsupervised methods, the program
effectively deciphers writing into speech. Its token-level
character-to-syllable accuracy is 89%, which significantly exceeds the 22%
accuracy of prior work.
</p>
<a href="http://arxiv.org/abs/2010.04744" target="_blank">arXiv:2010.04744</a> [<a href="http://arxiv.org/pdf/2010.04744" target="_blank">pdf</a>]

<h2>Igloo: Soundly Linking Compositional Refinement and Separation Logic for Distributed System Verification. (arXiv:2010.04749v1 [cs.LO])</h2>
<h3>Christoph Sprenger, Tobias Klenze, Marco Eilers, Felix A. Wolf, Peter M&#xfc;ller, Martin Clochard, David Basin</h3>
<p>Lighthouse projects such as CompCert, seL4, IronFleet, and DeepSpec have
demonstrated that full verification of entire systems is feasible by
establishing a refinement relation between an abstract system specification and
an executable implementation. Existing approaches however impose severe
restrictions on either the abstract system specifications due to their limited
expressiveness or versatility, or on the executable code due to their reliance
on suboptimal code extraction or inexpressive program logics. We propose a
novel methodology that combines the compositional refinement of abstract,
event-based models of distributed systems with the verification of full-fledged
program code using expressive separation logics, which support features of
realistic programming languages like mutable heap data structures and
concurrency. The main technical contribution of our work is a formal framework
that soundly relates event-based system models to program specifications in
separation logics, such that successful verification establishes a refinement
relation between the model and the code. We formalized our framework, Igloo, in
Isabelle/HOL. Our framework enables the sound combination of tools for protocol
development with existing program verifiers. We report on three case studies, a
leader election protocol, a replication protocol, and a security protocol, for
which we refine formal requirements into program specifications (in
Isabelle/HOL) that we implement in Java and Python and prove correct using the
VeriFast and Nagini tools.
</p>
<a href="http://arxiv.org/abs/2010.04749" target="_blank">arXiv:2010.04749</a> [<a href="http://arxiv.org/pdf/2010.04749" target="_blank">pdf</a>]

<h2>Robust Behavioral Cloning for Autonomous Vehicles using End-to-End Imitation Learning. (arXiv:2010.04767v1 [cs.RO])</h2>
<h3>Tanmay Vilas Samak, Chinmay Vilas Samak, Sivanathan Kandhasamy</h3>
<p>In this work, we present a robust pipeline for cloning driving behavior of a
human using end-to-end imitation learning. The proposed pipeline was employed
to train and deploy three distinct driving behavior models onto a simulated
vehicle. The training phase comprised of data collection, balancing,
augmentation, preprocessing and training a neural network, following which, the
trained model was deployed onto the ego vehicle to predict steering commands
based on the feed from an onboard camera. A novel coupled control law was
formulated to generate longitudinal control commands on-the-go based on the
predicted steering angle and other parameters such as actual speed of the ego
vehicle and the prescribed constraints for speed and steering. We analyzed
computational efficiency of the pipeline and evaluated robustness of the
trained models through exhaustive experimentation. Even a relatively shallow
convolutional neural network model was able to learn key driving behaviors from
sparsely labelled datasets and was tolerant to environmental variations during
deployment of the said driving behaviors.
</p>
<a href="http://arxiv.org/abs/2010.04767" target="_blank">arXiv:2010.04767</a> [<a href="http://arxiv.org/pdf/2010.04767" target="_blank">pdf</a>]

<h2>Thermal-Aware Compilation of Spiking Neural Networks to Neuromorphic Hardware. (arXiv:2010.04773v1 [cs.NE])</h2>
<h3>Twisha Titirsha, Anup Das</h3>
<p>Hardware implementation of neuromorphic computing can significantly improve
performance and energy efficiency of machine learning tasks implemented with
spiking neural networks (SNNs), making these hardware platforms particularly
suitable for embedded systems and other energy-constrained environments. We
observe that the long bitlines and wordlines in a crossbar of the hardware
create significant current variations when propagating spikes through its
synaptic elements, which are typically designed with non-volatile memory (NVM).
Such current variations create a thermal gradient within each crossbar of the
hardware, depending on the machine learning workload and the mapping of neurons
and synapses of the workload to these crossbars. \mr{This thermal gradient
becomes significant at scaled technology nodes and it increases the leakage
power in the hardware leading to an increase in the energy consumption.} We
propose a novel technique to map neurons and synapses of SNN-based machine
learning workloads to neuromorphic hardware. We make two novel contributions.
First, we formulate a detailed thermal model for a crossbar in a neuromorphic
hardware incorporating workload dependency, where the temperature of each
NVM-based synaptic cell is computed considering the thermal contributions from
its neighboring cells. Second, we incorporate this thermal model in the mapping
of neurons and synapses of SNN-based workloads using a hill-climbing heuristic.
The objective is to reduce the thermal gradient in crossbars. We evaluate our
neuron and synapse mapping technique using 10 machine learning workloads for a
state-of-the-art neuromorphic hardware. We demonstrate an average 11.4K
reduction in the average temperature of each crossbar in the hardware, leading
to a 52% reduction in the leakage power consumption (11% lower total energy
consumption) compared to a performance-oriented SNN mapping technique.
</p>
<a href="http://arxiv.org/abs/2010.04773" target="_blank">arXiv:2010.04773</a> [<a href="http://arxiv.org/pdf/2010.04773" target="_blank">pdf</a>]

<h2>A Graph Neural Network Approach for Scalable and Dynamic IP Similarity in Enterprise Networks. (arXiv:2010.04777v1 [cs.LG])</h2>
<h3>Hazem M. Soliman, Geoff Salmon, Dusan Sovilij, Mohan Rao</h3>
<p>Measuring similarity between IP addresses is an important task in the daily
operations of any enterprise network. Applications that depend on an IP
similarity measure include measuring correlation between security alerts,
building baselines for behavioral modelling, debugging network failures and
tracking persistent attacks. However, IPs do not have a natural similarity
measure by definition. Deep Learning architectures are a promising solution
here since they are able to learn numerical representations for IPs directly
from data, allowing various distance measures to be applied on the calculated
representations. Current works have utilized Natural Language Processing (NLP)
techniques for learning IP embeddings. However, these approaches have no proper
way to handle out-of-vocabulary (OOV) IPs not seen during training. In this
paper, we propose a novel approach for IP embedding using an adapted graph
neural network (GNN) architecture. This approach has the advantages of working
on the raw data, scalability and, most importantly, induction, i.e. the ability
to measure similarity between previously unseen IPs. Using data from an
enterprise network, our approach is able to identify similarities between local
DNS servers and root DNS servers even though some of these machines are never
encountered during the training phase.
</p>
<a href="http://arxiv.org/abs/2010.04777" target="_blank">arXiv:2010.04777</a> [<a href="http://arxiv.org/pdf/2010.04777" target="_blank">pdf</a>]

<h2>Learning Languages in the Limit from Positive Information with Finitely Many Memory Changes. (arXiv:2010.04782v1 [cs.FL])</h2>
<h3>Timo K&#xf6;tzing, Karen Seidel</h3>
<p>We investigate learning collections of languages from texts by an inductive
inference machine with access to the current datum and its memory in form of
states. The bounded memory states (BMS) learner is considered successful in
case it eventually settles on a correct hypothesis while exploiting only
finitely many different states.

We give the complete map of all pairwise relations for an established
collection of learning success restrictions. Most prominently, we show that
non-U-shapedness is not restrictive, while conservativeness and (strong)
monotonicity are. Some results carry over from iterative learning by a general
lemma showing that, for a wealth of restrictions (the \emph{semantic}
restrictions), iterative and bounded memory states learning are equivalent. We
also give an example of a non-semantic restriction (strongly non-U-shapedness)
where the two settings differ.
</p>
<a href="http://arxiv.org/abs/2010.04782" target="_blank">arXiv:2010.04782</a> [<a href="http://arxiv.org/pdf/2010.04782" target="_blank">pdf</a>]

<h2>A Reactive Autonomous Camera System for the RAVEN II Surgical Robot. (arXiv:2010.04785v1 [cs.RO])</h2>
<h3>Kay Hutchinson, Mohammad Samin Yasar, Harshneet Bhatia, Homa Alemzadeh</h3>
<p>The endoscopic camera of a surgical robot provides surgeons with a magnified
3D view of the surgical field, but repositioning it increases mental workload
and operation time. Poor camera placement contributes to safety-critical events
when surgical tools move out of the view of the camera. This paper presents a
proof of concept of an autonomous camera system for the Raven II surgical robot
that aims to reduce surgeon workload and improve safety by providing an optimal
view of the workspace showing all objects of interest. This system uses
transfer learning to localize and classify objects of interest within the view
of a stereoscopic camera. The positions and centroid of the objects are
estimated and a set of control rules determines the movement of the camera
towards a more desired view. Our perception module had an accuracy of 61.21%
overall for identifying objects of interest and was able to localize both
graspers and multiple blocks in the environment. Comparison of the commands
proposed by our system with the desired commands from a survey of 13
participants indicates that the autonomous camera system proposes appropriate
movements for the tilt and pan of the camera.
</p>
<a href="http://arxiv.org/abs/2010.04785" target="_blank">arXiv:2010.04785</a> [<a href="http://arxiv.org/pdf/2010.04785" target="_blank">pdf</a>]

<h2>Reparametrizing gradient descent. (arXiv:2010.04786v1 [cs.LG])</h2>
<h3>David Sprunger</h3>
<p>In this work, we propose an optimization algorithm which we call norm-adapted
gradient descent. This algorithm is similar to other gradient-based
optimization algorithms like Adam or Adagrad in that it adapts the learning
rate of stochastic gradient descent at each iteration. However, rather than
using statistical properties of observed gradients, norm-adapted gradient
descent relies on a first-order estimate of the effect of a standard gradient
descent update step, much like the Newton-Raphson method in many dimensions.
Our algorithm can also be compared to quasi-Newton methods, but we seek roots
rather than stationary points. Seeking roots can be justified by the fact that
for models with sufficient capacity measured by nonnegative loss functions,
roots coincide with global optima. This work presents several experiments where
we have used our algorithm; in these results, it appears norm-adapted descent
is particularly strong in regression settings but is also capable of training
classifiers.
</p>
<a href="http://arxiv.org/abs/2010.04786" target="_blank">arXiv:2010.04786</a> [<a href="http://arxiv.org/pdf/2010.04786" target="_blank">pdf</a>]

<h2>ChrEn: Cherokee-English Machine Translation for Endangered Language Revitalization. (arXiv:2010.04791v1 [cs.CL])</h2>
<h3>Shiyue Zhang, Benjamin Frey, Mohit Bansal</h3>
<p>Cherokee is a highly endangered Native American language spoken by the
Cherokee people. The Cherokee culture is deeply embedded in its language.
However, there are approximately only 2,000 fluent first language Cherokee
speakers remaining in the world, and the number is declining every year. To
help save this endangered language, we introduce ChrEn, a Cherokee-English
parallel dataset, to facilitate machine translation research between Cherokee
and English. Compared to some popular machine translation language pairs, ChrEn
is extremely low-resource, only containing 14k sentence pairs in total. We
split our parallel data in ways that facilitate both in-domain and
out-of-domain evaluation. We also collect 5k Cherokee monolingual data to
enable semi-supervised learning. Besides these datasets, we propose several
Cherokee-English and English-Cherokee machine translation systems. We compare
SMT (phrase-based) versus NMT (RNN-based and Transformer-based) systems;
supervised versus semi-supervised (via language model, back-translation, and
BERT/Multilingual-BERT) methods; as well as transfer learning versus
multilingual joint training with 4 other languages. Our best results are
15.8/12.7 BLEU for in-domain and 6.5/5.0 BLEU for out-of-domain Chr-En/EnChr
translations, respectively, and we hope that our dataset and systems will
encourage future work by the community for Cherokee language revitalization.
Our data, code, and demo will be publicly available at
https://github.com/ZhangShiyue/ChrEn
</p>
<a href="http://arxiv.org/abs/2010.04791" target="_blank">arXiv:2010.04791</a> [<a href="http://arxiv.org/pdf/2010.04791" target="_blank">pdf</a>]

<h2>Cluster Activation Mapping with Applications to Medical Imaging. (arXiv:2010.04794v1 [cs.CV])</h2>
<h3>Sarah Ryan, Nichole Carlson, Harris Butler, Tasha Fingerlin, Lisa Maier, Fuyong Xing</h3>
<p>An open question in deep clustering is how to understand what in the image is
creating the cluster assignments. This visual understanding is essential to be
able to trust the results of an inherently complex algorithm like deep
learning, especially when the derived cluster assignments may be used to inform
decision-making or create new disease sub-types. In this work, we developed
novel methodology to generate CLuster Activation Mapping (CLAM) which combines
an unsupervised deep clustering framework with a modification of Score-CAM, an
approach for discriminative localization in the supervised setting. We
evaluated our approach using a simulation study based on computed tomography
scans of the lung, and applied it to 3D CT scans from a sarcoidosis population
to identify new clusters of sarcoidosis based purely on CT scan presentation.
</p>
<a href="http://arxiv.org/abs/2010.04794" target="_blank">arXiv:2010.04794</a> [<a href="http://arxiv.org/pdf/2010.04794" target="_blank">pdf</a>]

<h2>A Tensor Compiler for Unified Machine Learning Prediction Serving. (arXiv:2010.04804v1 [cs.LG])</h2>
<h3>Supun Nakandala Karla Saur, Gyeong-In Yu, Konstantinos Karanasos, Carlo Curino, Markus Weimer, Matteo Interlandi</h3>
<p>Machine Learning (ML) adoption in the enterprise requires simpler and more
efficient software infrastructure---the bespoke solutions typical in large web
companies are simply untenable. Model scoring, the process of obtaining
predictions from a trained model over new data, is a primary contributor to
infrastructure complexity and cost as models are trained once but used many
times. In this paper we propose HUMMINGBIRD, a novel approach to model scoring,
which compiles featurization operators and traditional ML models (e.g.,
decision trees) into a small set of tensor operations. This approach inherently
reduces infrastructure complexity and directly leverages existing investments
in Neural Network compilers and runtimes to generate efficient computations for
both CPU and hardware accelerators. Our performance results are intriguing:
despite replacing imperative computations (e.g., tree traversals) with tensor
computation abstractions, HUMMINGBIRD is competitive and often outperforms
hand-crafted kernels on micro-benchmarks on both CPU and GPU, while enabling
seamless end-to-end acceleration of ML pipelines. We have released HUMMINGBIRD
as open source.
</p>
<a href="http://arxiv.org/abs/2010.04804" target="_blank">arXiv:2010.04804</a> [<a href="http://arxiv.org/pdf/2010.04804" target="_blank">pdf</a>]

<h2>Discussion of Kallus (2020) and Mo, Qi, and Liu (2020): New Objectives for Policy Learning. (arXiv:2010.04805v1 [stat.ML])</h2>
<h3>Sijia Li, Xiudi Li, Alex Luedtke</h3>
<p>We discuss the thought-provoking new objective functions for policy learning
that were proposed in "More efficient policy learning via optimal retargeting"
by Nathan Kallus and "Learning optimal distributionally robust individualized
treatment rules" by Weibin Mo, Zhengling Qi, and Yufeng Liu. We show that it is
important to take the curvature of the value function into account when working
within the retargeting framework, and we introduce two ways to do so. We also
describe more efficient approaches for leveraging calibration data when
learning distributionally robust policies.
</p>
<a href="http://arxiv.org/abs/2010.04805" target="_blank">arXiv:2010.04805</a> [<a href="http://arxiv.org/pdf/2010.04805" target="_blank">pdf</a>]

<h2>Characterizing Policy Divergence for Personalized Meta-Reinforcement Learning. (arXiv:2010.04816v1 [cs.LG])</h2>
<h3>Michael Zhang</h3>
<p>Despite ample motivation from costly exploration and limited trajectory data,
rapidly adapting to new environments with few-shot reinforcement learning (RL)
can remain a challenging task, especially with respect to personalized
settings. Here, we consider the problem of recommending optimal policies to a
set of multiple entities each with potentially different characteristics, such
that individual entities may parameterize distinct environments with unique
transition dynamics. Inspired by existing literature in meta-learning, we
extend previous work by focusing on the notion that certain environments are
more similar to each other than others in personalized settings, and propose a
model-free meta-learning algorithm that prioritizes past experiences by
relevance during gradient-based adaptation. Our algorithm involves
characterizing past policy divergence through methods in inverse reinforcement
learning, and we illustrate how such metrics are able to effectively
distinguish past policy parameters by the environment they were deployed in,
leading to more effective fast adaptation during test time. To study
personalization more effectively we introduce a navigation testbed to
specifically incorporate environment diversity across training episodes, and
demonstrate that our approach outperforms meta-learning alternatives with
respect to few-shot reinforcement learning in personalized settings.
</p>
<a href="http://arxiv.org/abs/2010.04816" target="_blank">arXiv:2010.04816</a> [<a href="http://arxiv.org/pdf/2010.04816" target="_blank">pdf</a>]

<h2>Understanding Spatial Robustness of Deep Neural Networks. (arXiv:2010.04821v1 [cs.SE])</h2>
<h3>Ziyuan Zhong, Yuchi Tian, Baishakhi Ray</h3>
<p>Deep Neural Networks (DNNs) are being deployed in a wide range of settings
today, from safety-critical applications like autonomous driving to commercial
applications involving image classifications. However, recent research has
shown that DNNs can be brittle to even slight variations of the input data.
Therefore, rigorous testing of DNNs has gained widespread attention.

While DNN robustness under norm-bound perturbation got significant attention
over the past few years, our knowledge is still limited when natural variants
of the input images come. These natural variants, e.g. a rotated or a rainy
version of the original input, are especially concerning as they can occur
naturally in the field without any active adversary and may lead to undesirable
consequences. Thus, it is important to identify the inputs whose small
variations may lead to erroneous DNN behaviors. The very few studies that
looked at DNN's robustness under natural variants, however, focus on estimating
the overall robustness of DNNs across all the test data rather than localizing
such error-producing points. This work aims to bridge this gap.

To this end, we study the local per-input robustness properties of the DNNs
and leverage those properties to build a white-box (DEEPROBUST-W) and a
black-box (DEEPROBUST-B) tool to automatically identify the non-robust points.
Our evaluation of these methods on nine DNN models spanning three widely used
image classification datasets shows that they are effective in flagging points
of poor robustness. In particular, DEEPROBUST-W and DEEPROBUST-B are able to
achieve an F1 score of up to 91.4% and 99.1%, respectively. We further show
that DEEPROBUST-W can be applied to a regression problem for a self-driving car
application.
</p>
<a href="http://arxiv.org/abs/2010.04821" target="_blank">arXiv:2010.04821</a> [<a href="http://arxiv.org/pdf/2010.04821" target="_blank">pdf</a>]

<h2>A Cross-Level Information Transmission Network for Predicting Phenotype from New Genotype: Application to Cancer Precision Medicine. (arXiv:2010.04824v1 [cs.LG])</h2>
<h3>Di He, Lei Xie</h3>
<p>An unsolved fundamental problem in biology and ecology is to predict
observable traits (phenotypes) from a new genetic constitution (genotype) of an
organism under environmental perturbations (e.g., drug treatment). The
emergence of multiple omics data provides new opportunities but imposes great
challenges in the predictive modeling of genotype-phenotype associations.
Firstly, the high-dimensionality of genomics data and the lack of labeled data
often make the existing supervised learning techniques less successful.
Secondly, it is a challenging task to integrate heterogeneous omics data from
different resources. Finally, the information transmission from DNA to
phenotype involves multiple intermediate levels of RNA, protein, metabolite,
etc. The higher-level features (e.g., gene expression) usually have stronger
discriminative power than the lower level features (e.g., somatic mutation). To
address above issues, we proposed a novel Cross-LEvel Information Transmission
network (CLEIT) framework. CLEIT aims to explicitly model the asymmetrical
multi-level organization of the biological system. Inspired by domain
adaptation, CLEIT first learns the latent representation of high-level domain
then uses it as ground-truth embedding to improve the representation learning
of the low-level domain in the form of contrastive loss. In addition, we adopt
a pre-training-fine-tuning approach to leveraging the unlabeled heterogeneous
omics data to improve the generalizability of CLEIT. We demonstrate the
effectiveness and performance boost of CLEIT in predicting anti-cancer drug
sensitivity from somatic mutations via the assistance of gene expressions when
compared with state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.04824" target="_blank">arXiv:2010.04824</a> [<a href="http://arxiv.org/pdf/2010.04824" target="_blank">pdf</a>]

<h2>On Task-Level Dialogue Composition of Generative Transformer Model. (arXiv:2010.04826v1 [cs.CL])</h2>
<h3>Prasanna Parthasarathi, Arvind Neelakantan, Sharan Narang</h3>
<p>Task-oriented dialogue systems help users accomplish tasks such as booking a
movie ticket and ordering food via conversation. Generative models
parameterized by a deep neural network are widely used for next turn response
generation in such systems. It is natural for users of the system to want to
accomplish multiple tasks within the same conversation, but the ability of
generative models to compose multiple tasks is not well studied. In this work,
we begin by studying the effect of training human-human task-oriented dialogues
towards improving the ability to compose multiple tasks on Transformer
generative models. To that end, we propose and explore two solutions: (1)
creating synthetic multiple task dialogue data for training from human-human
single task dialogue and (2) forcing the encoder representation to be invariant
to single and multiple task dialogues using an auxiliary loss. The results from
our experiments highlight the difficulty of even the sophisticated variant of
transformer model in learning to compose multiple tasks from single task
dialogues.
</p>
<a href="http://arxiv.org/abs/2010.04826" target="_blank">arXiv:2010.04826</a> [<a href="http://arxiv.org/pdf/2010.04826" target="_blank">pdf</a>]

<h2>Students Readiness for E-learning in the Universities in Yemen. (arXiv:2010.04830v1 [cs.CY])</h2>
<h3>Adnan Sharaf Ali Yousef Al-Absi, Ivelina Peneva, Krasimir Yordzhev</h3>
<p>The e-learning is an advanced version of traditional education. It is defined
as a way of learning by using the communication mechanisms of modern computer
networks and multimedia, including voice, image, and graphics and mechanisms to
search electronic libraries, as well as web portals, whether in the context of
distance learning or in the classroom. The people who engage in the transition
to web-supported education are the administrative staff, the faculty, and the
students. They all have their needs and they all should meet specific
requirements in order to facilitate the transition. The article presents the
results of questionnaire research of the students readiness for e-learning in
Yemeni universities.
</p>
<a href="http://arxiv.org/abs/2010.04830" target="_blank">arXiv:2010.04830</a> [<a href="http://arxiv.org/pdf/2010.04830" target="_blank">pdf</a>]

<h2>Improving Local Identifiability in Probabilistic Box Embeddings. (arXiv:2010.04831v1 [cs.LG])</h2>
<h3>Shib Sankar Dasgupta, Michael Boratko, Dongxu Zhang, Luke Vilnis, Xiang Lorraine Li, Andrew McCallum</h3>
<p>Geometric embeddings have recently received attention for their natural
ability to represent transitive asymmetric relations via containment. Box
embeddings, where objects are represented by n-dimensional hyperrectangles, are
a particularly promising example of such an embedding as they are closed under
intersection and their volume can be calculated easily, allowing them to
naturally represent calibrated probability distributions. The benefits of
geometric embeddings also introduce a problem of local identifiability,
however, where whole neighborhoods of parameters result in equivalent loss
which impedes learning. Prior work addressed some of these issues by using an
approximation to Gaussian convolution over the box parameters, however, this
intersection operation also increases the sparsity of the gradient. In this
work, we model the box parameters with min and max Gumbel distributions, which
were chosen such that space is still closed under the operation of the
intersection. The calculation of the expected intersection volume involves all
parameters, and we demonstrate experimentally that this drastically improves
the ability of such models to learn.
</p>
<a href="http://arxiv.org/abs/2010.04831" target="_blank">arXiv:2010.04831</a> [<a href="http://arxiv.org/pdf/2010.04831" target="_blank">pdf</a>]

<h2>Emotional Musical Prosody: Validated Vocal Dataset for Human Robot Interaction. (arXiv:2010.04839v1 [cs.RO])</h2>
<h3>Richard Savery, Lisa Zahray, Gil Weinberg</h3>
<p>Human collaboration with robotics is dependant on the development of a
relationship between human and robot, without which performance and utilization
can decrease. Emotion and personality conveyance has been shown to enhance
robotic collaborations, with improved human-robot relationships and increased
trust. One under-explored way for an artificial agent to convey emotions is
through non-linguistic musical prosody. In this work we present a new 4.2 hour
dataset of improvised emotional vocal phrases based on the Geneva Emotion
Wheel. This dataset has been validated through extensive listening tests and
shows promising preliminary results for use in generative systems.
</p>
<a href="http://arxiv.org/abs/2010.04839" target="_blank">arXiv:2010.04839</a> [<a href="http://arxiv.org/pdf/2010.04839" target="_blank">pdf</a>]

<h2>Conformal retrofitting via Riemannian manifolds: distilling task-specific graphs into pretrained embeddings. (arXiv:2010.04842v1 [cs.LG])</h2>
<h3>Justin Dieter, Arun Tejasvi Chaganty</h3>
<p>Pretrained (language) embeddings are versatile, task-agnostic feature
representations of entities, like words, that are central to many machine
learning applications. These representations can be enriched through
retrofitting, a class of methods that incorporate task-specific domain
knowledge encoded as a graph over a subset of these entities. However, existing
retrofitting algorithms face two limitations: they overfit the observed graph
by failing to represent relationships with missing entities; and they underfit
the observed graph by only learning embeddings in Euclidean manifolds, which
cannot faithfully represent even simple tree-structured or cyclic graphs. We
address these problems with two key contributions: (i) we propose a novel
regularizer, a conformality regularizer, that preserves local geometry from the
pretrained embeddings---enabling generalization to missing entities and (ii) a
new Riemannian feedforward layer that learns to map pre-trained embeddings onto
a non-Euclidean manifold that can better represent the entire graph. Through
experiments on WordNet, we demonstrate that the conformality regularizer
prevents even existing (Euclidean-only) methods from overfitting on link
prediction for missing entities, and---together with the Riemannian feedforward
layer---learns non-Euclidean embeddings that outperform them.
</p>
<a href="http://arxiv.org/abs/2010.04842" target="_blank">arXiv:2010.04842</a> [<a href="http://arxiv.org/pdf/2010.04842" target="_blank">pdf</a>]

<h2>Voting-based Approaches For Differentially Private Federated Learning. (arXiv:2010.04851v1 [cs.LG])</h2>
<h3>Yuqing Zhu, Xiang Yu, Yi-Hsuan Tsai, Francesco Pittaluga, Masoud Faraki, Manmohan chandraker, Yu-Xiang Wang</h3>
<p>While federated learning (FL) enables distributed agents to collaboratively
train a centralized model without sharing data with each other, it fails to
protect users against inference attacks that mine private information from the
centralized model. Thus, facilitating federated learning methods with
differential privacy (DPFL) becomes attractive. Existing algorithms based on
privately aggregating clipped gradients require many rounds of communication,
which may not converge, and cannot scale up to large-capacity models due to
explicit dimension-dependence in its added noise. In this paper, we adopt the
knowledge transfer model of private learning pioneered by Papernot et al.
(2017; 2018) and extend their algorithm PATE, as well as the recent alternative
PrivateKNN (Zhu et al., 2020) to the federated learning setting. The key
difference is that our method privately aggregates the labels from the agents
in a voting scheme, instead of aggregating the gradients, hence avoiding the
dimension dependence and achieving significant savings in communication cost.
Theoretically, we show that when the margins of the voting scores are large,
the agents enjoy exponentially higher accuracy and stronger (data-dependent)
differential privacy guarantees on both agent-level and instance-level.
Extensive experiments show that our approach significantly improves the
privacy-utility trade-off over the current state-of-the-art in DPFL.
</p>
<a href="http://arxiv.org/abs/2010.04851" target="_blank">arXiv:2010.04851</a> [<a href="http://arxiv.org/pdf/2010.04851" target="_blank">pdf</a>]

<h2>RatE: Relation-Adaptive Translating Embedding for Knowledge Graph Completion. (arXiv:2010.04863v1 [cs.CL])</h2>
<h3>Hao Huang, Guodong Long, Tao Shen, Jing Jiang, Chengqi Zhang</h3>
<p>Many graph embedding approaches have been proposed for knowledge graph
completion via link prediction. Among those, translating embedding approaches
enjoy the advantages of light-weight structure, high efficiency and great
interpretability. Especially when extended to complex vector space, they show
the capability in handling various relation patterns including symmetry,
antisymmetry, inversion and composition. However, previous translating
embedding approaches defined in complex vector space suffer from two main
issues: 1) representing and modeling capacities of the model are limited by the
translation function with rigorous multiplication of two complex numbers; and
2) embedding ambiguity caused by one-to-many relations is not explicitly
alleviated. In this paper, we propose a relation-adaptive translation function
built upon a novel weighted product in complex space, where the weights are
learnable, relation-specific and independent to embedding size. The translation
function only requires eight more scalar parameters each relation, but improves
expressive power and alleviates embedding ambiguity problem. Based on the
function, we then present our Relation-adaptive translating Embedding (RatE)
approach to score each graph triple. Moreover, a novel negative sampling method
is proposed to utilize both prior knowledge and self-adversarial learning for
effective optimization. Experiments verify RatE achieves state-of-the-art
performance on four link prediction benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.04863" target="_blank">arXiv:2010.04863</a> [<a href="http://arxiv.org/pdf/2010.04863" target="_blank">pdf</a>]

<h2>Learning Acoustic Scattering Fields for Highly Dynamic Interactive Sound Propagation. (arXiv:2010.04865v1 [cs.SD])</h2>
<h3>Zhenyu Tang, Hsien-Yu Meng, Dinesh Manocha</h3>
<p>We present a novel hybrid sound propagation algorithm for interactive
applications. Our approach is designed for general dynamic scenes and uses a
neural network-based learned scattered field representation along with ray
tracing to generate specular, diffuse, diffraction, and occlusion effects
efficiently. To handle general objects, we exploit properties of the acoustic
scattering field and use geometric deep learning to approximate the field using
spherical harmonics. We use a large dataset for training, and compare its
accuracy with the ground truth generated using an accurate wave-based solver.
The additional overhead of computing the learned scattered field at runtime is
small and we highlight the interactive performance by generating plausible
sound effects in dynamic scenes with diffraction and occlusion effects. We
demonstrate the perceptual benefits of our approach based on an audio-visual
user study.
</p>
<a href="http://arxiv.org/abs/2010.04865" target="_blank">arXiv:2010.04865</a> [<a href="http://arxiv.org/pdf/2010.04865" target="_blank">pdf</a>]

<h2>Robust Constrained-MDPs: Soft-Constrained Robust Policy Optimization under Model Uncertainty. (arXiv:2010.04870v1 [cs.LG])</h2>
<h3>Reazul Hasan Russel, Mouhacine Benosman, Jeroen Van Baar</h3>
<p>In this paper, we focus on the problem of robustifying reinforcement learning
(RL) algorithms with respect to model uncertainties. Indeed, in the framework
of model-based RL, we propose to merge the theory of constrained Markov
decision process (CMDP), with the theory of robust Markov decision process
(RMDP), leading to a formulation of robust constrained-MDPs (RCMDP). This
formulation, simple in essence, allows us to design RL algorithms that are
robust in performance, and provides constraint satisfaction guarantees, with
respect to uncertainties in the system's states transition probabilities. The
need for RCMPDs is important for real-life applications of RL. For instance,
such formulation can play an important role for policy transfer from simulation
to real world (Sim2Real) in safety critical applications, which would benefit
from performance and safety guarantees which are robust w.r.t model
uncertainty. We first propose the general problem formulation under the concept
of RCMDP, and then propose a Lagrangian formulation of the optimal problem,
leading to a robust-constrained policy gradient RL algorithm. We finally
validate this concept on the inventory management problem.
</p>
<a href="http://arxiv.org/abs/2010.04870" target="_blank">arXiv:2010.04870</a> [<a href="http://arxiv.org/pdf/2010.04870" target="_blank">pdf</a>]

<h2>Training Binary Neural Networks through Learning with Noisy Supervision. (arXiv:2010.04871v1 [cs.CV])</h2>
<h3>Kai Han, Yunhe Wang, Yixing Xu, Chunjing Xu, Enhua Wu, Chang Xu</h3>
<p>This paper formalizes the binarization operations over neural networks from a
learning perspective. In contrast to classical hand crafted rules (\eg hard
thresholding) to binarize full-precision neurons, we propose to learn a mapping
from full-precision neurons to the target binary ones. Each individual weight
entry will not be binarized independently. Instead, they are taken as a whole
to accomplish the binarization, just as they work together in generating
convolution features. To help the training of the binarization mapping, the
full-precision neurons after taking sign operations is regarded as some
auxiliary supervision signal, which is noisy but still has valuable guidance.
An unbiased estimator is therefore introduced to mitigate the influence of the
supervision noise. Experimental results on benchmark datasets indicate that the
proposed binarization technique attains consistent improvements over baselines.
</p>
<a href="http://arxiv.org/abs/2010.04871" target="_blank">arXiv:2010.04871</a> [<a href="http://arxiv.org/pdf/2010.04871" target="_blank">pdf</a>]

<h2>Self-play for Data Efficient Language Acquisition. (arXiv:2010.04872v1 [cs.CL])</h2>
<h3>Charles Lovering, Ellie Pavlick</h3>
<p>When communicating, people behave consistently across conversational roles:
People understand the words they say and are able to produce the words they
hear. To date, artificial agents developed for language tasks have lacked such
symmetry, meaning agents trained to produce language are unable to understand
it and vice-versa. In this work, we exploit the symmetric nature of
communication in order to improve both the efficiency and quality of language
acquisition in learning agents. Specifically, we consider the setting in which
an agent must learn to both understand and generate words in an existing
language, but with the assumption that access to interaction with "oracle"
speakers of the language is very limited. We show that using self-play as a
substitute for direct supervision enables the agent to transfer its knowledge
across roles (e.g. training as a listener but testing as a speaker) and make
better inferences about the ground truth lexicon using only a handful of
interactions with the oracle.
</p>
<a href="http://arxiv.org/abs/2010.04872" target="_blank">arXiv:2010.04872</a> [<a href="http://arxiv.org/pdf/2010.04872" target="_blank">pdf</a>]

<h2>Point process models for sequence detection in high-dimensional neural spike trains. (arXiv:2010.04875v1 [stat.ML])</h2>
<h3>Alex H. Williams, Anthony Degleris, Yixin Wang, Scott W. Linderman</h3>
<p>Sparse sequences of neural spikes are posited to underlie aspects of working
memory, motor production, and learning. Discovering these sequences in an
unsupervised manner is a longstanding problem in statistical neuroscience.
Promising recent work utilized a convolutive nonnegative matrix factorization
model to tackle this challenge. However, this model requires spike times to be
discretized, utilizes a sub-optimal least-squares criterion, and does not
provide uncertainty estimates for model predictions or estimated parameters. We
address each of these shortcomings by developing a point process model that
characterizes fine-scale sequences at the level of individual spikes and
represents sequence occurrences as a small number of marked events in
continuous time. This ultra-sparse representation of sequence events opens new
possibilities for spike train modeling. For example, we introduce learnable
time warping parameters to model sequences of varying duration, which have been
experimentally observed in neural circuits. We demonstrate these advantages on
experimental recordings from songbird higher vocal center and rodent
hippocampus.
</p>
<a href="http://arxiv.org/abs/2010.04875" target="_blank">arXiv:2010.04875</a> [<a href="http://arxiv.org/pdf/2010.04875" target="_blank">pdf</a>]

<h2>Accelerate Your CNN from Three Dimensions: A Comprehensive Pruning Framework. (arXiv:2010.04879v1 [cs.CV])</h2>
<h3>Wenxiao Wang, Minghao Chen, Shuai Zhao, Jinming Hu, Boxi Wu, Zhengxu Yu, Deng Cai, Haifeng Liu</h3>
<p>To deploy a pre-trained deep CNN on resource-constrained mobile devices,
neural network pruning is often used to cut down the model's computational
cost. For example, filter-level pruning (reducing the model's width) or
layer-level pruning (reducing the model's depth) can both save computations
with some sacrifice of accuracy. Besides, reducing the resolution of input
images can also reach the same goal. Most previous methods focus on reducing
one or two of these dimensions (i.e., depth, width, and image resolution) for
acceleration. However, excessive reduction of any single dimension will lead to
unacceptable accuracy loss, and we have to prune these three dimensions
comprehensively to yield the best result. In this paper, a simple yet effective
pruning framework is proposed to comprehensively consider these three
dimensions. Our framework falls into two steps: 1) Determining the optimal
depth (d*), width (w*), and image resolution (r) for the model. 2) Pruning the
model in terms of (d*, w*, r*). Specifically, at the first step, we formulate
model acceleration as an optimization problem. It takes depth (d), width (w)
and image resolution (r) as variables and the model's accuracy as the
optimization objective. Although it is hard to determine the expression of the
objective function, approximating it with polynomials is still feasible, during
which several properties of the objective function are utilized to ease and
speedup the fitting process. Then the optimal d*, w* and r* are attained by
maximizing the objective function with Lagrange multiplier theorem and KKT
conditions. Extensive experiments are done on several popular architectures and
datasets. The results show that we have outperformd the state-of-the-art
pruning methods. The code will be published soon.
</p>
<a href="http://arxiv.org/abs/2010.04879" target="_blank">arXiv:2010.04879</a> [<a href="http://arxiv.org/pdf/2010.04879" target="_blank">pdf</a>]

<h2>Designing for Recommending Intermediate States in A Scientific Workflow Management System. (arXiv:2010.04880v1 [cs.IR])</h2>
<h3>Debasish Chakroborti, Banani Roy, Sristy Sumana Nath</h3>
<p>To process a large amount of data sequentially and systematically, proper
management of workflow components (i.e., modules, data, configurations,
associations among ports and links) in a Scientific Workflow Management System
(SWfMS) is inevitable. Managing data with provenance in a SWfMS to support
reusability of workflows, modules, and data is not a simple task. Handling such
components is even more burdensome for frequently assembled and executed
complex workflows for investigating large datasets with different technologies
(i.e., various learning algorithms or models). However, a great many studies
propose various techniques and technologies for managing and recommending
services in a SWfMS, but only a very few studies consider the management of
data in a SWfMS for efficient storing and facilitating workflow executions.
Furthermore, there is no study to inquire about the effectiveness and
efficiency of such data management in a SWfMS from a user perspective. In this
paper, we present and evaluate a GUI version of such a novel approach of
intermediate data management with two use cases (Plant Phenotyping and
Bioinformatics). The technique we call GUI-RISPTS (Recommending Intermediate
States from Pipelines Considering Tool-States) can facilitate executions of
workflows with processed data (i.e., intermediate outcomes of modules in a
workflow) and can thus reduce the computational time of some modules in a
SWfMS. We integrated GUI-RISPTS with an existing workflow management system
called SciWorCS. In SciWorCS, we present an interface that users use for
selecting the recommendation of intermediate states (i.e., modules' outcomes).
We investigated GUI-RISP's effectiveness from users' perspectives along with
measuring its overhead in terms of storage and efficiency in workflow
execution.
</p>
<a href="http://arxiv.org/abs/2010.04880" target="_blank">arXiv:2010.04880</a> [<a href="http://arxiv.org/pdf/2010.04880" target="_blank">pdf</a>]

<h2>Deep Active Learning for Joint Classification & Segmentation with Weak Annotator. (arXiv:2010.04889v1 [cs.CV])</h2>
<h3>Soufiane Belharbi, Ismail Ben Ayed, Luke McCaffrey, Eric Granger</h3>
<p>CNN visualization and interpretation methods, like class activation maps
(CAMs), are typically used to highlight the image regions linked to the class
predictions. These models allow to simultaneously classify images and yield
pixel-wise localization scores, without the need for costly pixel-level
annotations. However, they are prone to high false positive localization, and
thus poor visualisations when processing challenging images, such as histology
images for cancer grading and localization. In this paper, an active learning
(AL) framework is proposed to alleviate this issue by progressively integrating
pixel-wise annotation during training. Given training data with global
class-level labels, our deep weakly-supervised learning (WSL) model
simultaneously allows for supervised learning for classification, and active
learning for segmentation of images selected for pixel-level annotation by an
oracle. Unlike traditional AL methods that focus on acquisition method, we also
propose leveraging the unlabeled images to improve model accuracy with less
oracle-annotation. To this end, self-learning is considered where the model is
used to pseudo-annotate a large number of relevant unlabeled samples, which are
then integrated during the learning process with oracle-annotated samples. Our
extensive experiments are conducted on complex high resolution medical and
natural images from two benchmark datasets -- GlaS for colon cancer, and
CUB-200-2011 for bird species. Results indicate that by using simply random
acquisition, our approach can significantly outperform segmentation obtained
with state-of the-art CAMs and AL methods, using an identical
oracle-supervision budget. Our method provides an efficient solution to improve
the regions of interest (ROI) segmentation accuracy for real-world visual
recognition applications.
</p>
<a href="http://arxiv.org/abs/2010.04889" target="_blank">arXiv:2010.04889</a> [<a href="http://arxiv.org/pdf/2010.04889" target="_blank">pdf</a>]

<h2>Trust the Model When It Is Confident: Masked Model-based Actor-Critic. (arXiv:2010.04893v1 [cs.LG])</h2>
<h3>Feiyang Pan, Jia He, Dandan Tu, Qing He</h3>
<p>It is a popular belief that model-based Reinforcement Learning (RL) is more
sample efficient than model-free RL, but in practice, it is not always true due
to overweighed model errors. In complex and noisy settings, model-based RL
tends to have trouble using the model if it does not know when to trust the
model.

In this work, we find that better model usage can make a huge difference. We
show theoretically that if the use of model-generated data is restricted to
state-action pairs where the model error is small, the performance gap between
model and real rollouts can be reduced. It motivates us to use model rollouts
only when the model is confident about its predictions. We propose Masked
Model-based Actor-Critic (M2AC), a novel policy optimization algorithm that
maximizes a model-based lower-bound of the true value function. M2AC implements
a masking mechanism based on the model's uncertainty to decide whether its
prediction should be used or not. Consequently, the new algorithm tends to give
robust policy improvements. Experiments on continuous control benchmarks
demonstrate that M2AC has strong performance even when using long model
rollouts in very noisy environments, and it significantly outperforms previous
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.04893" target="_blank">arXiv:2010.04893</a> [<a href="http://arxiv.org/pdf/2010.04893" target="_blank">pdf</a>]

<h2>HAMLET: A Hierarchical Agent-based Machine Learning Platform. (arXiv:2010.04894v1 [cs.LG])</h2>
<h3>Ahmad Esmaeili, John C. Gallagher, John A. Springer, Eric T. Matson</h3>
<p>Hierarchical Multi-Agent Systems provide a convenient and relevant way to
analyze, model, and simulate complex systems in which a large number of
entities are interacting at different levels of abstraction. In this paper, we
introduce HAMLET (Hierarchical Agent-based Machine LEarning plaTform), a
platform based on hierarchical multi-agent systems, to facilitate the research
and democratization of machine learning entities distributed geographically or
locally. This is carried out by firstly modeling the machine learning solutions
as a hypergraph and then autonomously setting up a multi-level structure
composed of heterogeneous agents based on their innate capabilities and learned
skills. HAMLET aids the design and management of machine learning systems and
provides analytical capabilities for the research communities to assess the
existing and/or new algorithms/datasets through flexible and customizable
queries. The proposed platform does not assume restrictions on the type of
machine learning algorithms/datasets and is theoretically proven to be sound
and complete with polynomial computational requirements. Additionally, it is
examined empirically on 120 training and four generalized batch testing tasks
performed on 24 machine learning algorithms and 9 standard datasets. The
experimental results provided not only establish confidence in the platform's
consistency and correctness but also demonstrates its testing and analytical
capacity.
</p>
<a href="http://arxiv.org/abs/2010.04894" target="_blank">arXiv:2010.04894</a> [<a href="http://arxiv.org/pdf/2010.04894" target="_blank">pdf</a>]

<h2>UniNet: Scalable Network Representation Learning with Metropolis-Hastings Sampling. (arXiv:2010.04895v1 [cs.LG])</h2>
<h3>Xingyu Yao, Yingxia Shao, Bin Cui, Lei Chen</h3>
<p>Network representation learning (NRL) technique has been successfully adopted
in various data mining and machine learning applications. Random walk based NRL
is one popular paradigm, which uses a set of random walks to capture the
network structural information, and then employs word2vec models to learn the
low-dimensional representations. However, until now there is lack of a
framework, which unifies existing random walk based NRL models and supports to
efficiently learn from large networks. The main obstacle comes from the diverse
random walk models and the inefficient sampling method for the random walk
generation. In this paper, we first introduce a new and efficient edge sampler
based on Metropolis-Hastings sampling technique, and theoretically show the
convergence property of the edge sampler to arbitrary discrete probability
distributions. Then we propose a random walk model abstraction, in which users
can easily define different transition probability by specifying dynamic edge
weights and random walk states. The abstraction is efficiently supported by our
edge sampler, since our sampler can draw samples from unnormalized probability
distribution in constant time complexity. Finally, with the new edge sampler
and random walk model abstraction, we carefully implement a scalable NRL
framework called UniNet. We conduct comprehensive experiments with five random
walk based NRL models over eleven real-world datasets, and the results clearly
demonstrate the efficiency of UniNet over billion-edge networks.
</p>
<a href="http://arxiv.org/abs/2010.04895" target="_blank">arXiv:2010.04895</a> [<a href="http://arxiv.org/pdf/2010.04895" target="_blank">pdf</a>]

<h2>Semi-Autonomous Teleoperation of Mobile Manipulators for Safely and Efficiently Executing Machine Tending Tasks Human-Supervised Semi-Autonomous Mobile Manipulators for Safely and Efficiently Executing Machine Tending Tasks. (arXiv:2010.04899v1 [cs.RO])</h2>
<h3>Sarah Al-Hussaini, Shantanu Thakar, Hyojeong Kim, Pradeep Rajendran, Brual C. Shah, Jeremy A. Marvel, Satyandra K. Gupta</h3>
<p>Mobile manipulators can be used for machine tending and material handling
tasks in small volume manufacturing applications. These applications usually
have semi-structured work environment. The use of a fully autonomous mobile
manipulator for such applications can be risky, as an inaccurate model of the
workspace may result in damage to expensive equipment. On the other hand, the
use of a fully teleoperated mobile manipulator may require a significant amount
of operator time. In this paper, a semi-autonomous mobile manipulator is
developed for safely and efficiently carrying out machine tending tasks under
human supervision. The robot is capable of generating motion plans from the
high-level task description and presenting simulation results to the human for
approval. The human operator can authorize the robot to execute the
automatically generated plan or provide additional input to the planner to
refine the plan. If the level of uncertainty in some parts of the workspace
model is high, then the human can decide to perform teleoperation to safely
execute the task. Our preliminary user trials show that non-expert operators
can quickly learn to use the system and perform machine tending tasks.
</p>
<a href="http://arxiv.org/abs/2010.04899" target="_blank">arXiv:2010.04899</a> [<a href="http://arxiv.org/pdf/2010.04899" target="_blank">pdf</a>]

<h2>Toward Micro-Dialect Identification in Diaglossic and Code-Switched Environments. (arXiv:2010.04900v1 [cs.CL])</h2>
<h3>Muhammad Abdul-Mageed, Chiyu Zhang, AbdelRahim Elmadany, Lyle Ungar</h3>
<p>Although the prediction of dialects is an important language processing task,
with a wide range of applications, existing work is largely limited to
coarse-grained varieties. Inspired by geolocation research, we propose the
novel task of Micro-Dialect Identification (MDI) and introduce MARBERT, a new
language model with striking abilities to predict a fine-grained variety (as
small as that of a city) given a single, short message. For modeling, we offer
a range of novel spatially and linguistically-motivated multi-task learning
models. To showcase the utility of our models, we introduce a new, large-scale
dataset of Arabic micro-varieties (low-resource) suited to our tasks. MARBERT
predicts micro-dialects with 9.9% F1, ~76X better than a majority class
baseline. Our new language model also establishes new state-of-the-art on
several external tasks.
</p>
<a href="http://arxiv.org/abs/2010.04900" target="_blank">arXiv:2010.04900</a> [<a href="http://arxiv.org/pdf/2010.04900" target="_blank">pdf</a>]

<h2>ByzShield: An Efficient and Robust System for Distributed Training. (arXiv:2010.04902v1 [cs.LG])</h2>
<h3>Konstantinos Konstantinidis, Aditya Ramamoorthy</h3>
<p>Training of large scale models on distributed clusters is a critical
component of the machine learning pipeline. However, this training can easily
be made to fail if some workers behave in an adversarial (Byzantine) fashion
whereby they return arbitrary results to the parameter server (PS). A plethora
of existing papers consider a variety of attack models and propose robust
aggregation and/or computational redundancy to alleviate the effects of these
attacks. In this work we consider an omniscient attack model where the
adversary has full knowledge about the gradient computation assignments of the
workers and can choose to attack (up to) any q out of n worker nodes to induce
maximal damage. Our redundancy-based method ByzShield leverages the properties
of bipartite expander graphs for the assignment of tasks to workers; this helps
to effectively mitigate the effect of the Byzantine behavior. Specifically, we
demonstrate an upper bound on the worst case fraction of corrupted gradients
based on the eigenvalues of our constructions which are based on mutually
orthogonal Latin squares and Ramanujan graphs. Our numerical experiments
indicate over a 36% reduction on average in the fraction of corrupted gradients
compared to the state of the art. Likewise, our experiments on training
followed by image classification on the CIFAR-10 dataset show that ByzShield
has on average a 20% advantage in accuracy under the most sophisticated
attacks. ByzShield also tolerates a much larger fraction of adversarial nodes
compared to prior work.
</p>
<a href="http://arxiv.org/abs/2010.04902" target="_blank">arXiv:2010.04902</a> [<a href="http://arxiv.org/pdf/2010.04902" target="_blank">pdf</a>]

<h2>Multi-path Neural Networks for On-device Multi-domain Visual Classification. (arXiv:2010.04904v1 [cs.CV])</h2>
<h3>Qifei Wang, Junjie Ke, Joshua Greaves, Grace Chu, Gabriel Bender, Luciano Sbaiz, Alec Go, Andrew Howard, Feng Yang, Ming-Hsuan Yang, Jeff Gilbert, Peyman Milanfar</h3>
<p>Learning multiple domains/tasks with a single model is important for
improving data efficiency and lowering inference cost for numerous vision
tasks, especially on resource-constrained mobile devices. However,
hand-crafting a multi-domain/task model can be both tedious and challenging.
This paper proposes a novel approach to automatically learn a multi-path
network for multi-domain visual classification on mobile devices. The proposed
multi-path network is learned from neural architecture search by applying one
reinforcement learning controller for each domain to select the best path in
the super-network created from a MobileNetV3-like search space. An adaptive
balanced domain prioritization algorithm is proposed to balance optimizing the
joint model on multiple domains simultaneously. The determined multi-path model
selectively shares parameters across domains in shared nodes while keeping
domain-specific parameters within non-shared nodes in individual domain paths.
This approach effectively reduces the total number of parameters and FLOPS,
encouraging positive knowledge transfer while mitigating negative interference
across domains. Extensive evaluations on the Visual Decathlon dataset
demonstrate that the proposed multi-path model achieves state-of-the-art
performance in terms of accuracy, model size, and FLOPS against other
approaches using MobileNetV3-like architectures. Furthermore, the proposed
method improves average accuracy over learning single-domain models
individually, and reduces the total number of parameters and FLOPS by 78% and
32% respectively, compared to the approach that simply bundles single-domain
models for multi-domain learning.
</p>
<a href="http://arxiv.org/abs/2010.04904" target="_blank">arXiv:2010.04904</a> [<a href="http://arxiv.org/pdf/2010.04904" target="_blank">pdf</a>]

<h2>Accelerating Finite-temperature Kohn-Sham Density Functional Theory with Deep Neural Networks. (arXiv:2010.04905v1 [cond-mat.mtrl-sci])</h2>
<h3>J. Austin Ellis, Attila Cangi, Normand A. Modine, J. Adam Stephens, Aidan P. Thompson, Sivasankaran Rajamanickam</h3>
<p>We present a numerical modeling workflow based on machine learning (ML) which
reproduces the the total energies produced by Kohn-Sham density functional
theory (DFT) at finite electronic temperature to within chemical accuracy at
negligible computational cost. Based on deep neural networks, our workflow
yields the local density of states (LDOS) for a given atomic configuration.
From the LDOS, spatially-resolved, energy-resolved, and integrated quantities
can be calculated, including the DFT total free energy, which serves as the
Born-Oppenheimer potential energy surface for the atoms. We demonstrate the
efficacy of this approach for both solid and liquid metals and compare results
between independent and unified machine-learning models for solid and liquid
aluminum. Our machine-learning density functional theory framework opens up the
path towards multiscale materials modeling for matter under ambient and extreme
conditions at a computational scale and cost that is unattainable with current
algorithms.
</p>
<a href="http://arxiv.org/abs/2010.04905" target="_blank">arXiv:2010.04905</a> [<a href="http://arxiv.org/pdf/2010.04905" target="_blank">pdf</a>]

<h2>Improve the Robustness and Accuracy of Deep Neural Network with $L_{2,\infty}$ Normalization. (arXiv:2010.04912v1 [stat.ML])</h2>
<h3>Lijia Yu, Xiao-Shan Gao</h3>
<p>In this paper, the robustness and accuracy of the deep neural network (DNN)
was enhanced by introducing the $L_{2,\infty}$ normalization of the weight
matrices of the DNN with Relu as the activation function. It is proved that the
$L_{2,\infty}$ normalization leads to large dihedral angles between two
adjacent faces of the polyhedron graph of the DNN function and hence smoother
DNN functions, which reduces over-fitting. A measure is proposed for the
robustness of a classification DNN, which is the average radius of the maximal
robust spheres with the sample data as centers. A lower bound for the
robustness measure is given in terms of the $L_{2,\infty}$ norm. Finally, an
upper bound for the Rademacher complexity of DNN with $L_{2,\infty}$
normalization is given. An algorithm is given to train a DNN with the
$L_{2,\infty}$ normalization and experimental results are used to show that the
$L_{2,\infty}$ normalization is effective to improve the robustness and
accuracy.
</p>
<a href="http://arxiv.org/abs/2010.04912" target="_blank">arXiv:2010.04912</a> [<a href="http://arxiv.org/pdf/2010.04912" target="_blank">pdf</a>]

<h2>Generalized Independent Noise Condition for Estimating Linear Non-Gaussian Latent Variable Graphs. (arXiv:2010.04917v1 [cs.LG])</h2>
<h3>Feng Xie, Ruichu Cai, Biwei Huang, Clark Glymour, Zhifeng Hao, Kun Zhang</h3>
<p>Causal discovery aims to recover causal structures or models underlying the
observed data. Despite its success in certain domains, most existing methods
focus on causal relations between observed variables, while in many scenarios
the observed ones may not be the underlying causal variables (e.g., image
pixels), but are generated by latent causal variables or confounders that are
causally related. To this end, in this paper, we consider Linear, Non-Gaussian
Latent variable Models (LiNGLaMs), in which latent confounders are also
causally related, and propose a Generalized Independent Noise (GIN) condition
to estimate such latent variable graphs. Specifically, for two observed random
vectors $\mathbf{Y}$ and $\mathbf{Z}$, GIN holds if and only if
$\omega^{\intercal}\mathbf{Y}$ and $\mathbf{Z}$ are statistically independent,
where $\omega$ is a parameter vector characterized from the cross-covariance
between $\mathbf{Y}$ and $\mathbf{Z}$. From the graphical view, roughly
speaking, GIN implies that causally earlier latent common causes of variables
in $\mathbf{Y}$ d-separate $\mathbf{Y}$ from $\mathbf{Z}$. Interestingly, we
find that the independent noise condition, i.e., if there is no confounder,
causes are independent from the error of regressing the effect on the causes,
can be seen as a special case of GIN. Moreover, we show that GIN helps locate
latent variables and identify their causal structure, including causal
directions. We further develop a recursive learning algorithm to achieve these
goals. Experimental results on synthetic and real-world data demonstrate the
effectiveness of our method.
</p>
<a href="http://arxiv.org/abs/2010.04917" target="_blank">arXiv:2010.04917</a> [<a href="http://arxiv.org/pdf/2010.04917" target="_blank">pdf</a>]

<h2>Automatically Deriving Control-Flow Graph Generators from Operational Semantics. (arXiv:2010.04918v1 [cs.PL])</h2>
<h3>James Koppel, Jackson Kearl, Armando Solar-Lezama</h3>
<p>We develop the first theory of control-flow graphs from first principles, and
use it to create an algorithm for automatically synthesizing many variants of
control-flow graph generators from a language's operational semantics. Our
approach first introduces a new algorithm for converting a large class of
small-step operational semantics to an abstract machine. It next uses a
technique called "abstract rewriting" to automatically abstract the semantics
of a language, which is used both to directly generate a CFG from a program
("interpreted mode") and to generate standalone code, similar to a
human-written CFG generator, for any program in a language. We show how the
choice of two abstraction and projection parameters allow our approach to
synthesize several families of CFG-generators useful for different kinds of
tools. We prove the correspondence between the generated graphs and the
original semantics. We provide and prove an algorithm for automatically proving
the termination of interpreted-mode generators. In addition to our theoretical
results, we have implemented this algorithm in a tool called Mandate, and show
that it produces human-readable code on two medium-size languages with 60-80
rules, featuring nearly all intraprocedural control constructs common in modern
languages. We then showed these CFG-generators were sufficient to build two
static analyzers atop them. Our work is a promising step towards the grand
vision of being able to synthesize all desired tools from the semantics of a
programming language.
</p>
<a href="http://arxiv.org/abs/2010.04918" target="_blank">arXiv:2010.04918</a> [<a href="http://arxiv.org/pdf/2010.04918" target="_blank">pdf</a>]

<h2>Latent Tree Learning with Ordered Neurons: What Parses Does It Produce?. (arXiv:2010.04926v1 [cs.CL])</h2>
<h3>Yian Zhang</h3>
<p>Recent latent tree learning models can learn constituency parsing without any
exposure to human-annotated tree structures. One such model is ON-LSTM (Shen et
al., 2019), which is trained on language modelling and has
near-state-of-the-art performance on unsupervised parsing. In order to better
understand the performance and consistency of the model as well as how the
parses it generates are different from gold-standard PTB parses, we replicate
the model with different restarts and examine their parses. We find that (1)
the model has reasonably consistent parsing behaviors across different
restarts, (2) the model struggles with the internal structures of complex noun
phrases, (3) the model has a tendency to overestimate the height of the split
points right before verbs. We speculate that both problems could potentially be
solved by adopting a different training task other than unidirectional language
modelling.
</p>
<a href="http://arxiv.org/abs/2010.04926" target="_blank">arXiv:2010.04926</a> [<a href="http://arxiv.org/pdf/2010.04926" target="_blank">pdf</a>]

<h2>Contrastive Rendering for Ultrasound Image Segmentation. (arXiv:2010.04928v1 [eess.IV])</h2>
<h3>Haoming Li, Xin Yang, Jiamin Liang, Wenlong Shi, Chaoyu Chen, Haoran Dou, Rui Li, Rui Gao, Guangquan Zhou, Jinghui Fang, Xiaowen Liang, Ruobing Huang, Alejandro Frangi, Zhiyi Chen, Dong Ni</h3>
<p>Ultrasound (US) image segmentation embraced its significant improvement in
deep learning era. However, the lack of sharp boundaries in US images still
remains an inherent challenge for segmentation. Previous methods often resort
to global context, multi-scale cues or auxiliary guidance to estimate the
boundaries. It is hard for these methods to approach pixel-level learning for
fine-grained boundary generating. In this paper, we propose a novel and
effective framework to improve boundary estimation in US images. Our work has
three highlights. First, we propose to formulate the boundary estimation as a
rendering task, which can recognize ambiguous points (pixels/voxels) and
calibrate the boundary prediction via enriched feature representation learning.
Second, we introduce point-wise contrastive learning to enhance the similarity
of points from the same class and contrastively decrease the similarity of
points from different classes. Boundary ambiguities are therefore further
addressed. Third, both rendering and contrastive learning tasks contribute to
consistent improvement while reducing network parameters. As a
proof-of-concept, we performed validation experiments on a challenging dataset
of 86 ovarian US volumes. Results show that our proposed method outperforms
state-of-the-art methods and has the potential to be used in clinical practice.
</p>
<a href="http://arxiv.org/abs/2010.04928" target="_blank">arXiv:2010.04928</a> [<a href="http://arxiv.org/pdf/2010.04928" target="_blank">pdf</a>]

<h2>An Empirical Study on Detecting COVID-19 in Chest X-ray Images Using Deep Learning Based Methods. (arXiv:2010.04936v1 [eess.IV])</h2>
<h3>Ramtin Babaeipour, Elham Azizi, Hassan Khotanlou</h3>
<p>Spreading of COVID-19 virus has increased the efforts to provide testing
kits. Not only the preparation of these kits had been hard, rare, and expensive
but also using them is another issue. Results have shown that these kits take
some crucial time to recognize the virus, in addition to the fact that they
encounter with 30% loss. In this paper, we have studied the usage of x-ray
pictures which are ubiquitous, for the classification of COVID-19 chest Xray
images, by the existing convolutional neural networks (CNNs). We intend to
train chest x-rays of infected and not infected ones with different CNNs
architectures including VGG19, Densnet-121, and Xception. Training these
architectures resulted in different accuracies which were much faster and more
precise than usual ways of testing.
</p>
<a href="http://arxiv.org/abs/2010.04936" target="_blank">arXiv:2010.04936</a> [<a href="http://arxiv.org/pdf/2010.04936" target="_blank">pdf</a>]

<h2>Deep Neural Network Test Coverage: How Far Are We?. (arXiv:2010.04946v1 [cs.SE])</h2>
<h3>Junjie Chen, Ming Yan, Zan Wang, Yuning Kang, Zhuo Wu</h3>
<p>DNN testing is one of the most effective methods to guarantee the quality of
DNN. In DNN testing, many test coverage metrics have been proposed to measure
test effectiveness, including structural coverage and non-structural coverage
(which are classified according to whether considering which structural
elements are covered during testing). Those test coverage metrics are proposed
based on the assumption: they are correlated with test effectiveness (i.e., the
generation of adversarial test inputs or the error-revealing capability of test
inputs in DNN testing studies). However, it is still unknown whether the
assumption is tenable. In this work, we conducted the first extensive study to
systematically validate the assumption by controlling for the size of test
sets. In the study, we studied seven typical test coverage metrics based on 9
pairs of datasets and models with great diversity (including four pairs that
have never been used to evaluate these test coverage metrics before). The
results demonstrate that the assumption fails for structural coverage in
general but holds for non-structural coverage on more than half of subjects,
indicating that measuring the difference of DNN behaviors between test inputs
and training data is more promising than measuring which structural elements
are covered by test inputs for measuring test effectiveness. Even so, the
current non-structural coverage metrics still can be improved from several
aspects such as unfriendly parameters and unstable performance. That indicates
that although a lot of test coverage metrics have been proposed before, there
is still a lot of room for improvement of measuring test effectiveness in DNN
testing, and our study has pointed out some promising directions.
</p>
<a href="http://arxiv.org/abs/2010.04946" target="_blank">arXiv:2010.04946</a> [<a href="http://arxiv.org/pdf/2010.04946" target="_blank">pdf</a>]

<h2>Double Forward Propagation for Memorized Batch Normalization. (arXiv:2010.04947v1 [cs.LG])</h2>
<h3>Yong Guo, Qingyao Wu, Chaorui Deng, Jian Chen, Mingkui Tan</h3>
<p>Batch Normalization (BN) has been a standard component in designing deep
neural networks (DNNs). Although the standard BN can significantly accelerate
the training of DNNs and improve the generalization performance, it has several
underlying limitations which may hamper the performance in both training and
inference. In the training stage, BN relies on estimating the mean and variance
of data using a single minibatch. Consequently, BN can be unstable when the
batch size is very small or the data is poorly sampled. In the inference stage,
BN often uses the so called moving mean and moving variance instead of batch
statistics, i.e., the training and inference rules in BN are not consistent.
Regarding these issues, we propose a memorized batch normalization (MBN), which
considers multiple recent batches to obtain more accurate and robust
statistics. Note that after the SGD update for each batch, the model parameters
will change, and the features will change accordingly, leading to the
Distribution Shift before and after the update for the considered batch. To
alleviate this issue, we present a simple Double-Forward scheme in MBN which
can further improve the performance. Compared to related methods, the proposed
MBN exhibits consistent behaviors in both training and inference. Empirical
results show that the MBN based models trained with the Double-Forward scheme
greatly reduce the sensitivity of data and significantly improve the
generalization performance.
</p>
<a href="http://arxiv.org/abs/2010.04947" target="_blank">arXiv:2010.04947</a> [<a href="http://arxiv.org/pdf/2010.04947" target="_blank">pdf</a>]

<h2>Making Online Sketching Hashing Even Faster. (arXiv:2010.04948v1 [cs.LG])</h2>
<h3>Xixian Chen, Haiqin Yang, Shenglin Zhao, Michael R. Lyu, Irwin King</h3>
<p>Data-dependent hashing methods have demonstrated good performance in various
machine learning applications to learn a low-dimensional representation from
the original data. However, they still suffer from several obstacles: First,
most of existing hashing methods are trained in a batch mode, yielding
inefficiency for training streaming data. Second, the computational cost and
the memory consumption increase extraordinarily in the big data setting, which
perplexes the training procedure. Third, the lack of labeled data hinders the
improvement of the model performance. To address these difficulties, we utilize
online sketching hashing (OSH) and present a FasteR Online Sketching Hashing
(FROSH) algorithm to sketch the data in a more compact form via an independent
transformation. We provide theoretical justification to guarantee that our
proposed FROSH consumes less time and achieves a comparable sketching precision
under the same memory cost of OSH. We also extend FROSH to its distributed
implementation, namely DFROSH, to further reduce the training time cost of
FROSH while deriving the theoretical bound of the sketching precision. Finally,
we conduct extensive experiments on both synthetic and real datasets to
demonstrate the attractive merits of FROSH and DFROSH.
</p>
<a href="http://arxiv.org/abs/2010.04948" target="_blank">arXiv:2010.04948</a> [<a href="http://arxiv.org/pdf/2010.04948" target="_blank">pdf</a>]

<h2>A Model Compression Method with Matrix Product Operators for Speech Enhancement. (arXiv:2010.04950v1 [cs.SD])</h2>
<h3>Xingwei Sun, Ze-Feng Gao, Zhong-Yi Lu, Junfeng Li, Yonghong Yan</h3>
<p>The deep neural network (DNN) based speech enhancement approaches have
achieved promising performance. However, the number of parameters involved in
these methods is usually enormous for the real applications of speech
enhancement on the device with the limited resources. This seriously restricts
the applications. To deal with this issue, model compression techniques are
being widely studied. In this paper, we propose a model compression method
based on matrix product operators (MPO) to substantially reduce the number of
parameters in DNN models for speech enhancement. In this method, the weight
matrices in the linear transformations of neural network model are replaced by
the MPO decomposition format before training. In experiment, this process is
applied to the causal neural network models, such as the feedforward multilayer
perceptron (MLP) and long short-term memory (LSTM) models. Both MLP and LSTM
models with/without compression are then utilized to estimate the ideal ratio
mask for monaural speech enhancement. The experimental results show that our
proposed MPO-based method outperforms the widely-used pruning method for speech
enhancement under various compression rates, and further improvement can be
achieved with respect to low compression rates. Our proposal provides an
effective model compression method for speech enhancement, especially in
cloud-free application.
</p>
<a href="http://arxiv.org/abs/2010.04950" target="_blank">arXiv:2010.04950</a> [<a href="http://arxiv.org/pdf/2010.04950" target="_blank">pdf</a>]

<h2>Block-term Tensor Neural Networks. (arXiv:2010.04963v1 [cs.LG])</h2>
<h3>Jinmian Yea, Guangxi Li, Di Chen, Haiqin Yang, Shandian Zhe, Zenglin Xu</h3>
<p>Deep neural networks (DNNs) have achieved outstanding performance in a wide
range of applications, e.g., image classification, natural language processing,
etc. Despite the good performance, the huge number of parameters in DNNs brings
challenges to efficient training of DNNs and also their deployment in low-end
devices with limited computing resources. In this paper, we explore the
correlations in the weight matrices, and approximate the weight matrices with
the low-rank block-term tensors. We name the new corresponding structure as
block-term tensor layers (BT-layers), which can be easily adapted to neural
network models, such as CNNs and RNNs. In particular, the inputs and the
outputs in BT-layers are reshaped into low-dimensional high-order tensors with
a similar or improved representation power. Sufficient experiments have
demonstrated that BT-layers in CNNs and RNNs can achieve a very large
compression ratio on the number of parameters while preserving or improving the
representation power of the original DNNs.
</p>
<a href="http://arxiv.org/abs/2010.04963" target="_blank">arXiv:2010.04963</a> [<a href="http://arxiv.org/pdf/2010.04963" target="_blank">pdf</a>]

<h2>Light Field Salient Object Detection: A Review and Benchmark. (arXiv:2010.04968v1 [cs.CV])</h2>
<h3>Yao Jiang, Tao Zhou, Ge-Peng Ji, Keren Fu, Qijun Zhao, Deng-Ping Fan</h3>
<p>Salient object detection (SOD) is a long-standing research topic in computer
vision and has drawn an increasing amount of research interest in the past
decade. This paper provides the first comprehensive review and benchmark for
SOD on light field, which has long been lacking in the saliency community.
Firstly, we introduce the preliminary knowledge of light field including theory
and data forms, and then review existing studies on light field SOD, covering
ten traditional models, six deep learning-based models, one comparative study,
and one brief review. Existing datasets for light field SOD are summarized with
detailed information and statistical analysis. Secondly, we benchmark seven
representative light field SOD models together with several cutting-edge RGB-D
SOD models on four widely used light field datasets, from which insightful
discussions and analyses including the comparison between light field SOD and
RGB-D SOD models are achieved. Besides, due to the inconsistency of datasets in
their current forms, we further generate complete data and supplement focal
stacks, depth maps and multi-view images for the inconsistent datasets, making
them consistent and unified. Our supplemented data makes a universal benchmark
possible. Lastly, because light field SOD is a quite special problem attributed
to its diverse data representations and high dependency on acquisition
hardware, making it differ greatly from other saliency detection tasks, we
provide nine hints into the challenges and future directions, and outline
several open issues. We hope our review and benchmarking could serve as a
catalyst to advance research in this field. All the materials including
collected models, datasets, benchmarking results, and supplemented light field
datasets will be publicly available at our project site.
</p>
<a href="http://arxiv.org/abs/2010.04968" target="_blank">arXiv:2010.04968</a> [<a href="http://arxiv.org/pdf/2010.04968" target="_blank">pdf</a>]

<h2>MS-Ranker: Accumulating Evidence from Potentially Correct Candidates for Answer Selection. (arXiv:2010.04970v1 [cs.CL])</h2>
<h3>Yingxue Zhang, Fandong Meng, Peng Li, Ping Jian, Jie Zhou</h3>
<p>As conventional answer selection (AS) methods generally match the question
with each candidate answer independently, they suffer from the lack of matching
information between the question and the candidate. To address this problem, we
propose a novel reinforcement learning (RL) based multi-step ranking model,
named MS-Ranker, which accumulates information from potentially correct
candidate answers as extra evidence for matching the question with a candidate.
In specific, we explicitly consider the potential correctness of candidates and
update the evidence with a gating mechanism. Moreover, as we use a listwise
ranking reward, our model learns to pay more attention to the overall
performance. Experiments on two benchmarks, namely WikiQA and SemEval-2016 CQA,
show that our model significantly outperforms existing methods that do not rely
on external resources.
</p>
<a href="http://arxiv.org/abs/2010.04970" target="_blank">arXiv:2010.04970</a> [<a href="http://arxiv.org/pdf/2010.04970" target="_blank">pdf</a>]

<h2>Tag Recommendation for Online Q&A Communities based on BERT Pre-Training Technique. (arXiv:2010.04971v1 [cs.CL])</h2>
<h3>Navid Khezrian, Jafar Habibi, Issa Annamoradnejad</h3>
<p>Online Q&amp;A and open source communities use tags and keywords to index,
categorize, and search for specific content. The most obvious advantage of tag
recommendation is the correct classification of information. In this study, we
used the BERT pre-training technique in tag recommendation task for online Q&amp;A
and open-source communities for the first time. Our evaluation on freecode
datasets show that the proposed method, called TagBERT, is more accurate
compared to deep learning and other baseline methods. Moreover, our model
achieved a high stability by solving the problem of previous researches, where
increasing the number of tag recommendations significantly reduced model
performance.
</p>
<a href="http://arxiv.org/abs/2010.04971" target="_blank">arXiv:2010.04971</a> [<a href="http://arxiv.org/pdf/2010.04971" target="_blank">pdf</a>]

<h2>Distilling a Deep Neural Network into a Takagi-Sugeno-Kang Fuzzy Inference System. (arXiv:2010.04974v1 [cs.AI])</h2>
<h3>Xiangming Gu, Xiang Cheng</h3>
<p>Deep neural networks (DNNs) demonstrate great success in classification
tasks. However, they act as black boxes and we don't know how they make
decisions in a particular classification task. To this end, we propose to
distill the knowledge from a DNN into a fuzzy inference system (FIS), which is
Takagi-Sugeno-Kang (TSK)-type in this paper. The model has the capability to
express the knowledge acquired by a DNN based on fuzzy rules, thus explaining a
particular decision much easier. Knowledge distillation (KD) is applied to
create a TSK-type FIS that generalizes better than one directly from the
training data, which is guaranteed through experiments in this paper. To
further improve the performances, we modify the baseline method of KD and
obtain good results.
</p>
<a href="http://arxiv.org/abs/2010.04974" target="_blank">arXiv:2010.04974</a> [<a href="http://arxiv.org/pdf/2010.04974" target="_blank">pdf</a>]

<h2>Bio-inspired Obstacle Avoidance for Flying Robots with Active Sensing. (arXiv:2010.04977v1 [cs.RO])</h2>
<h3>Gang Chen, Wei Dong, Xinjun Sheng, Xiangyang Zhu, Han Ding</h3>
<p>This paper presents a novel vision-based obstacle avoidance system for flying
robots working in dynamic environments. Instead of fusing multiple sensors to
enlarge the view field, we introduce a bio-inspired solution that utilizes a
stereo camera with independent rotational DOF to sense the obstacles actively.
In particular, the rotation is planned heuristically by multiple objectives
that can benefit flight safety, including tracking dynamic obstacles, observing
the heading direction, and exploring the previously unseen area. With this
sensing result, a flight path is planned based on real-time sampling and
collision checking in state space, which constitutes an active sense and avoid
(ASAA) system. Experiments demonstrate that this system is capable of handling
environments with dynamic obstacles and abrupt changes in goal direction. Since
only one stereo camera is utilized, this system provides a low-cost but
effective approach to overcome the view field limitation in visual navigation.
</p>
<a href="http://arxiv.org/abs/2010.04977" target="_blank">arXiv:2010.04977</a> [<a href="http://arxiv.org/pdf/2010.04977" target="_blank">pdf</a>]

<h2>Event-Triggered Multi-agent Reinforcement Learning with Communication under Limited-bandwidth Constraint. (arXiv:2010.04978v1 [cs.MA])</h2>
<h3>Guangzheng Hu, Yuanheng Zhu, Dongbin Zhao, Mengchen Zhao, Jianye Hao</h3>
<p>Communicating with each other in a distributed manner and behaving as a group
are essential in multi-agent reinforcement learning. However, real-world
multi-agent systems suffer from restrictions on limited-bandwidth
communication. If the bandwidth is fully occupied, some agents are not able to
send messages promptly to others, causing decision delay and impairing
cooperative effects. Recent related work has started to address the problem but
still fails in maximally reducing the consumption of communication resources.
In this paper, we propose Event-Triggered Communication Network (ETCNet) to
enhance the communication efficiency in multi-agent systems by sending messages
only when necessary. According to the information theory, the limited bandwidth
is translated to the penalty threshold of an event-triggered strategy, which
determines whether an agent at each step sends a message or not. Then the
design of the event-triggered strategy is formulated as a constrained Markov
decision problem, and reinforcement learning finds the best communication
protocol that satisfies the limited bandwidth constraint. Experiments on
typical multi-agent tasks demonstrate that ETCNet outperforms other methods in
terms of the reduction of bandwidth occupancy and still preserves the
cooperative performance of multi-agent systems at the most.
</p>
<a href="http://arxiv.org/abs/2010.04978" target="_blank">arXiv:2010.04978</a> [<a href="http://arxiv.org/pdf/2010.04978" target="_blank">pdf</a>]

<h2>FIND: Human-in-the-Loop Debugging Deep Text Classifiers. (arXiv:2010.04987v1 [cs.CL])</h2>
<h3>Piyawat Lertvittayakumjorn, Lucia Specia, Francesca Toni</h3>
<p>Since obtaining a perfect training dataset (i.e., a dataset which is
considerably large, unbiased, and well-representative of unseen cases) is
hardly possible, many real-world text classifiers are trained on the available,
yet imperfect, datasets. These classifiers are thus likely to have undesirable
properties. For instance, they may have biases against some sub-populations or
may not work effectively in the wild due to overfitting. In this paper, we
propose FIND -- a framework which enables humans to debug deep learning text
classifiers by disabling irrelevant hidden features. Experiments show that by
using FIND, humans can improve CNN text classifiers which were trained under
different types of imperfect datasets (including datasets with biases and
datasets with dissimilar train-test distributions).
</p>
<a href="http://arxiv.org/abs/2010.04987" target="_blank">arXiv:2010.04987</a> [<a href="http://arxiv.org/pdf/2010.04987" target="_blank">pdf</a>]

<h2>The emergence of Explainability of Intelligent Systems: Delivering Explainable and Personalised Recommendations for Energy Efficiency. (arXiv:2010.04990v1 [cs.AI])</h2>
<h3>Christos Sardianos, Iraklis Varlamis, Christos Chronis, George Dimitrakopoulos, Abdullah Alsalemi, Yassine Himeur, Faycal Bensaali, Abbes Amira</h3>
<p>The recent advances in artificial intelligence namely in machine learning and
deep learning, have boosted the performance of intelligent systems in several
ways. This gave rise to human expectations, but also created the need for a
deeper understanding of how intelligent systems think and decide. The concept
of explainability appeared, in the extent of explaining the internal system
mechanics in human terms. Recommendation systems are intelligent systems that
support human decision making, and as such, they have to be explainable in
order to increase user trust and improve the acceptance of recommendations. In
this work, we focus on a context-aware recommendation system for energy
efficiency and develop a mechanism for explainable and persuasive
recommendations, which are personalized to user preferences and habits. The
persuasive facts either emphasize on the economical saving prospects (Econ) or
on a positive ecological impact (Eco) and explanations provide the reason for
recommending an energy saving action. Based on a study conducted using a
Telegram bot, different scenarios have been validated with actual data and
human feedback. Current results show a total increase of 19\% on the
recommendation acceptance ratio when both economical and ecological persuasive
facts are employed. This revolutionary approach on recommendation systems,
demonstrates how intelligent recommendations can effectively encourage energy
saving behavior.
</p>
<a href="http://arxiv.org/abs/2010.04990" target="_blank">arXiv:2010.04990</a> [<a href="http://arxiv.org/pdf/2010.04990" target="_blank">pdf</a>]

<h2>A Recursive Markov Blanket-Based Approach to Causal Structure Learning. (arXiv:2010.04992v1 [cs.LG])</h2>
<h3>Ehsan Mokhtarian, Sina Akbari, AmirEmad Ghassami, Negar Kiyavash</h3>
<p>One of the main approaches for causal structure learning is constraint-based
methods. These methods are particularly valued as they are guaranteed to
asymptotically find a structure which is statistically equivalent to the ground
truth. However, they may require exponentially large number of conditional
independence (CI) tests in the number of variables of the system. In this
paper, we propose a novel recursive constraint-based method for causal
structure learning. The key idea of the proposed approach is to recursively use
Markov blanket information in order to identify a variable that can be removed
from the set of variables without changing the statistical relations among the
remaining variables. Once such a variable is found, its neighbors are
identified, the removable variable is removed, and the Markov blanket
information of the remaining variables is updated. Our proposed approach
reduces the required number of conditional independence tests for structure
learning compared to the state of the art. We also provide a lower bound on the
number of CI tests required by any constraint-based method. Comparing this
lower bound to our achievable bound demonstrates the efficiency of our
approach. We evaluate and compare the performance of the proposed method on
both synthetic and real world structures against the state of the art.
</p>
<a href="http://arxiv.org/abs/2010.04992" target="_blank">arXiv:2010.04992</a> [<a href="http://arxiv.org/pdf/2010.04992" target="_blank">pdf</a>]

<h2>Beyond Language: Learning Commonsense from Images for Reasoning. (arXiv:2010.05001v1 [cs.CL])</h2>
<h3>Wanqing Cui, Yanyan Lan, Liang Pang, Jiafeng Guo, Xueqi Cheng</h3>
<p>This paper proposes a novel approach to learn commonsense from images,
instead of limited raw texts or costly constructed knowledge bases, for the
commonsense reasoning problem in NLP. Our motivation comes from the fact that
an image is worth a thousand words, where richer scene information could be
leveraged to help distill the commonsense knowledge, which is often hidden in
languages. Our approach, namely Loire, consists of two stages. In the first
stage, a bi-modal sequence-to-sequence approach is utilized to conduct the
scene layout generation task, based on a text representation model ViBERT. In
this way, the required visual scene knowledge, such as spatial relations, will
be encoded in ViBERT by the supervised learning process with some bi-modal data
like COCO. Then ViBERT is concatenated with a pre-trained language model to
perform the downstream commonsense reasoning tasks. Experimental results on two
commonsense reasoning problems, i.e. commonsense question answering and pronoun
resolution, demonstrate that Loire outperforms traditional language-based
methods. We also give some case studies to show what knowledge is learned from
images and explain how the generated scene layout helps the commonsense
reasoning process.
</p>
<a href="http://arxiv.org/abs/2010.05001" target="_blank">arXiv:2010.05001</a> [<a href="http://arxiv.org/pdf/2010.05001" target="_blank">pdf</a>]

<h2>Automated Concatenation of Embeddings for Structured Prediction. (arXiv:2010.05006v1 [cs.CL])</h2>
<h3>Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei Huang, Kewei Tu</h3>
<p>Pretrained contextualized embeddings are powerful word representations for
structured prediction tasks. Recent work found that better word representations
can be obtained by concatenating different types of embeddings. However, the
selection of embeddings to form the best concatenated representation usually
varies depending on the task and the collection of candidate embeddings, and
the ever-increasing number of embedding types makes it a more difficult
problem. In this paper, we propose Automated Concatenation of Embeddings (ACE)
to automate the process of finding better concatenations of embeddings for
structured prediction tasks, based on a formulation inspired by recent progress
on neural architecture search. Specifically, a controller alternately samples a
concatenation of embeddings, according to its current belief of the
effectiveness of individual embedding types in consideration for a task, and
updates the belief based on a reward. We follow strategies in reinforcement
learning to optimize the parameters of the controller and compute the reward
based on the accuracy of a task model, which is fed with the sampled
concatenation as input and trained on a task dataset. Empirical results on 6
tasks and 23 datasets show that our approach outperforms strong baselines and
achieves state-of-the-art performance with fine-tuned embeddings in the vast
majority of evaluations.
</p>
<a href="http://arxiv.org/abs/2010.05006" target="_blank">arXiv:2010.05006</a> [<a href="http://arxiv.org/pdf/2010.05006" target="_blank">pdf</a>]

<h2>Category-Learning with Context-Augmented Autoencoder. (arXiv:2010.05007v1 [cs.LG])</h2>
<h3>Denis Kuzminykh, Laida Kushnareva, Timofey Grigoryev, Alexander Zatolokin</h3>
<p>Finding an interpretable non-redundant representation of real-world data is
one of the key problems in Machine Learning. Biological neural networks are
known to solve this problem quite well in unsupervised manner, yet unsupervised
artificial neural networks either struggle to do it or require fine tuning for
each task individually. We associate this with the fact that a biological brain
learns in the context of the relationships between observations, while an
artificial network does not. We also notice that, though a naive data
augmentation technique can be very useful for supervised learning problems,
autoencoders typically fail to generalize transformations from data
augmentations. Thus, we believe that providing additional knowledge about
relationships between data samples will improve model's capability of finding
useful inner data representation. More formally, we consider a dataset not as a
manifold, but as a category, where the examples are objects. Two these objects
are connected by a morphism, if they actually represent different
transformations of the same entity. Following this formalism, we propose a
novel method of using data augmentations when training autoencoders. We train a
Variational Autoencoder in such a way, that it makes transformation outcome
predictable by auxiliary network in terms of the hidden representation. We
believe that the classification accuracy of a linear classifier on the learned
representation is a good metric to measure its interpretability. In our
experiments, present approach outperforms $\beta$-VAE and is comparable with
Gaussian-mixture VAE.
</p>
<a href="http://arxiv.org/abs/2010.05007" target="_blank">arXiv:2010.05007</a> [<a href="http://arxiv.org/pdf/2010.05007" target="_blank">pdf</a>]

<h2>An Encoder-Decoder CNN for Hair Removal in Dermoscopic Images. (arXiv:2010.05013v1 [cs.CV])</h2>
<h3>Lidia Talavera-Mart&#xed;nez, Pedro Bibiloni, Manuel Gonz&#xe1;lez-Hidalgo</h3>
<p>The process of removing occluding hair has a relevant role in the early and
accurate diagnosis of skin cancer. It consists of detecting hairs and restore
the texture below them, which is sporadically occluded. In this work, we
present a model based on convolutional neural networks for hair removal in
dermoscopic images. During the network's training, we use a combined loss
function to improve the restoration ability of the proposed model. In order to
train the CNN and to quantitatively validate their performance, we simulate the
presence of skin hair in hairless images extracted from publicly known datasets
such as the PH2, dermquest, dermis, EDRA2002, and the ISIC Data Archive. As far
as we know, there is no other hair removal method based on deep learning. Thus,
we compare our results with six state-of-the-art algorithms based on
traditional computer vision techniques by means of similarity measures that
compare the reference hairless image and the one with hair simulated. Finally,
a statistical test is used to compare the methods. Both qualitative and
quantitative results demonstrate the effectiveness of our network.
</p>
<a href="http://arxiv.org/abs/2010.05013" target="_blank">arXiv:2010.05013</a> [<a href="http://arxiv.org/pdf/2010.05013" target="_blank">pdf</a>]

<h2>Reinforcement Learning on Computational Resource Allocation of Cloud-based Wireless Networks. (arXiv:2010.05024v1 [cs.AI])</h2>
<h3>Beiran Chen, Yi Zhang, George Iosifidis, Mingming Liu</h3>
<p>Wireless networks used for Internet of Things (IoT) are expected to largely
involve cloud-based computing and processing. Softwarised and centralised
signal processing and network switching in the cloud enables flexible network
control and management. In a cloud environment, dynamic computational resource
allocation is essential to save energy while maintaining the performance of the
processes. The stochastic features of the Central Processing Unit (CPU) load
variation as well as the possible complex parallelisation situations of the
cloud processes makes the dynamic resource allocation an interesting research
challenge. This paper models this dynamic computational resource allocation
problem into a Markov Decision Process (MDP) and designs a model-based
reinforcement-learning agent to optimise the dynamic resource allocation of the
CPU usage. Value iteration method is used for the reinforcement-learning agent
to pick up the optimal policy during the MDP. To evaluate our performance we
analyse two types of processes that can be used in the cloud-based IoT networks
with different levels of parallelisation capabilities, i.e., Software-Defined
Radio (SDR) and Software-Defined Networking (SDN). The results show that our
agent rapidly converges to the optimal policy, stably performs in different
parameter settings, outperforms or at least equally performs compared to a
baseline algorithm in energy savings for different scenarios.
</p>
<a href="http://arxiv.org/abs/2010.05024" target="_blank">arXiv:2010.05024</a> [<a href="http://arxiv.org/pdf/2010.05024" target="_blank">pdf</a>]

<h2>Weakly Supervised Learning for Judging the Credibility of Movie Reviews. (arXiv:2010.05025v1 [cs.IR])</h2>
<h3>Han-Sub Shin, Hyuk-Yoon Kwon</h3>
<p>In this paper, we deal with the problem of judging the credibility of movie
reviews. The problem is challenging because even experts cannot clearly and
efficiently judge the credibility of a movie review and the number of movie
reviews is very large. To attack this problem, we propose a weakly supervised
learning method for fast annotation. In terms of predefined criteria for weakly
supervised learning, we present a simple and clear criterion based on
historical movie ratings associated with movie reviewers. The proposed method
has the following two advantages. First, it is significantly efficient because
we can annotate the entire data sets according to the predefined rule. Indeed,
we show that the proposed method can annotate 8,000 movie reviews only in 0.712
seconds. Second, a criterion adapted for weakly supervised learning is simple
but effective. We use as a comparison learning method that uses the helpfulness
votes of other reviewers as the criterion to judge the credibility of movie
reviews, which has been widely used to judge the credibility of online reviews.
We indicate that the proposed learning method is comparable to or even better
than the helpfulness vote method by showing an improvement over the accuracy of
the latter method of 1.57% $~ 4.54%.
</p>
<a href="http://arxiv.org/abs/2010.05025" target="_blank">arXiv:2010.05025</a> [<a href="http://arxiv.org/pdf/2010.05025" target="_blank">pdf</a>]

<h2>Predicting Developers' IDE Commands with Machine Learning. (arXiv:2010.05036v1 [cs.SE])</h2>
<h3>Tyson Bulmer, Lloyd Montgomery, Daniela Damian</h3>
<p>When a developer is writing code they are usually focused and in a
state-of-mind which some refer to as flow. Breaking out of this flow can cause
the developer to lose their train of thought and have to start their thought
process from the beginning. This loss of thought can be caused by interruptions
and sometimes slow IDE interactions. Predictive functionality has been
harnessed in user applications to speed up load times, such as in Google
Chrome's browser which has a feature called "Predicting Network Actions". This
will pre-load web-pages that the user is most likely to click through. This
mitigates the interruption that load times can introduce. In this paper we seek
to make the first step towards predicting user commands in the IDE. Using the
MSR 2018 Challenge Data of over 3000 developer session and over 10 million
recorded events, we analyze and cleanse the data to be parsed into event
series, which can then be used to train a variety of machine learning models,
including a neural network, to predict user induced commands. Our highest
performing model is able to obtain a 5 cross-fold validation prediction
accuracy of 64%.
</p>
<a href="http://arxiv.org/abs/2010.05036" target="_blank">arXiv:2010.05036</a> [<a href="http://arxiv.org/pdf/2010.05036" target="_blank">pdf</a>]

<h2>Cross-Stack Workload Characterization of Deep Recommendation Systems. (arXiv:2010.05037v1 [cs.AR])</h2>
<h3>Samuel Hsia, Udit Gupta, Mark Wilkening, Carole-Jean Wu, Gu-Yeon Wei, David Brooks</h3>
<p>Deep learning based recommendation systems form the backbone of most
personalized cloud services. Though the computer architecture community has
recently started to take notice of deep recommendation inference, the resulting
solutions have taken wildly different approaches - ranging from near memory
processing to at-scale optimizations. To better design future hardware systems
for deep recommendation inference, we must first systematically examine and
characterize the underlying systems-level impact of design decisions across the
different levels of the execution stack. In this paper, we characterize eight
industry-representative deep recommendation models at three different levels of
the execution stack: algorithms and software, systems platforms, and hardware
microarchitectures. Through this cross-stack characterization, we first show
that system deployment choices (i.e., CPUs or GPUs, batch size granularity) can
give us up to 15x speedup. To better understand the bottlenecks for further
optimization, we look at both software operator usage breakdown and CPU
frontend and backend microarchitectural inefficiencies. Finally, we model the
correlation between key algorithmic model architecture features and hardware
bottlenecks, revealing the absence of a single dominant algorithmic component
behind each hardware bottleneck.
</p>
<a href="http://arxiv.org/abs/2010.05037" target="_blank">arXiv:2010.05037</a> [<a href="http://arxiv.org/pdf/2010.05037" target="_blank">pdf</a>]

<h2>EB-DEVS: A Formal Framework for Modeling and Simulation of Emergent Behavior in Dynamic Complex Systems. (arXiv:2010.05042v1 [cs.MA])</h2>
<h3>Daniel J. Foguelman, Philipp Henning, Adelinde Uhrmacher, Rodrigo Castro</h3>
<p>Emergent behavior is a key feature defining a system under study as a complex
system. Simulation has been recognized as the only way to deal with the study
of the emergency of properties (at a macroscopic level) among groups of system
components (at a microscopic level), for the manifestations of emergent
structures cannot be deduced from analysing components in isolation. A
systems-oriented generalisation must consider the presence of feedback loops
(micro components react to macro properties), interaction among components of
different classes (modular composition) and layered interaction of subsystems
operating at different spatio-temporal scales (hierarchical organisation). In
this work we introduce Emergent Behavior-DEVS (EB-DEVS) a Modeling and
Simulation (M\&amp;S) formalism that permits reasoning about complex systems where
emergent behavior is placed at the forefront of the analysis activity. EB-DEVS
builds on the DEVS formalism, adding upward/downward communication channels to
well-established capabilities for modular and hierarchical M\&amp;S of
heterogeneous multi-formalism systems. EB-DEVS takes a minimalist stance on
expressiveness, introducing a small set of extensions on Classic DEVS that can
cope with emergent behavior, and making both formalisms interoperable (the
modeler decides which subsystems deserve to be expressed via micro-macro
dynamics). We present three case studies: flocks of birds with learning,
population epidemics with vaccination and sub-cellular dynamics with
homeostasis, through which we showcase how EB-DEVS performs by placing emergent
properties at the center of the M\&amp;S process.
</p>
<a href="http://arxiv.org/abs/2010.05042" target="_blank">arXiv:2010.05042</a> [<a href="http://arxiv.org/pdf/2010.05042" target="_blank">pdf</a>]

<h2>Interpreting Multivariate Interactions in DNNs. (arXiv:2010.05045v1 [cs.LG])</h2>
<h3>Hao Zhang, Yichen Xie, Longjie Zheng, Die Zhang, Quanshi Zhang</h3>
<p>This paper aims to explain deep neural networks (DNNs) from the perspective
of multivariate interactions. In this paper, we define and quantify the
significance of interactions among multiple input variables of the DNN. Input
variables with strong interactions usually form a coalition and reflect
prototype features, which are memorized and used by the DNN for inference. We
define the significance of interactions based on the Shapley value, which is
designed to assign the attribution value of each input variable to the
inference. We have conducted experiments with various DNNs. Experimental
results have demonstrated the effectiveness of the proposed method.
</p>
<a href="http://arxiv.org/abs/2010.05045" target="_blank">arXiv:2010.05045</a> [<a href="http://arxiv.org/pdf/2010.05045" target="_blank">pdf</a>]

<h2>Drawing with AI -- Exploring Collaborative Inking Experiences Based on Mid-air Pointing and Reinforcement Learning. (arXiv:2010.05047v1 [cs.HC])</h2>
<h3>Franziska Geiger, Michelle Martin, Monika Pichlmair, Ilhan Aslan, Hannes Ritschel, Bj&#xf6;rn Bittner, Elisabeth Andr&#xe9;</h3>
<p>Digitalization is changing the nature of tools and materials, which are used
in artistic practices in professional and non-professional settings. For
example, today it is common that even children express their ideas and explore
their creativity by drawing on tablets as digital canvases. While there are
many software-based tools, which resemble traditional tools, such as various
forms of virtual brushes, erasers, etc. in contrast to traditional materials
there is potential in augmenting software-based tools and digital canvases with
artificial intelligence. Curious about how it would feel to interact with a
digital canvas, which would be in contrast to a traditional canvas dynamic,
responsive, and potentially able to continuously adapt to its user's input, we
developed a drawing application and conducted a qualitative study with 14
users. In this paper, we describe details of our design process, which lead up
to using a k-armed bandit as a simple form of reinforcement learning and a
LeapMotion sensor to allow people from all walks of like, old and young to draw
on pervasive displays, small and large, positioned near or far.
</p>
<a href="http://arxiv.org/abs/2010.05047" target="_blank">arXiv:2010.05047</a> [<a href="http://arxiv.org/pdf/2010.05047" target="_blank">pdf</a>]

<h2>A Predictive Autoscaler for Elastic Batch Jobs. (arXiv:2010.05049v1 [cs.LG])</h2>
<h3>Peng Gao</h3>
<p>Large batch jobs such as Deep Learning, HPC and Spark require far more
computational resources and higher cost than conventional online service. Like
the processing of other time series data, these jobs possess a variety of
characteristics such as trend, burst, and seasonality. Cloud providers offer
short-term instances to achieve scalability, stability, and cost-efficiency.
Given the time lag caused by joining into the cluster and initialization,
crowded workloads may lead to a violation in the scheduling system. Based on
the assumption that there are infinite resources and ideal placements available
for users to require in the cloud environment, we propose a predictive
autoscaler to provide an elastic interface for the customers and overprovision
instances based on the trained regression model. We contribute to a method to
embed heterogeneous resource requirements in continuous space into discrete
resource buckets and an autoscaler to do predictive expand plans on the time
series of resource bucket counts. Our experimental evaluation of the production
resources usage data validates the solution and the results show that the
predictive autoscaler relieves the burden of making scaling plans, avoids long
launching time at lower cost and outperforms other prediction methods with
fine-tuned settings.
</p>
<a href="http://arxiv.org/abs/2010.05049" target="_blank">arXiv:2010.05049</a> [<a href="http://arxiv.org/pdf/2010.05049" target="_blank">pdf</a>]

<h2>Fairness-aware Agnostic Federated Learning. (arXiv:2010.05057v1 [cs.LG])</h2>
<h3>Wei Du, Depeng Xu, Xintao Wu, Hanghang Tong</h3>
<p>Federated learning is an emerging framework that builds centralized machine
learning models with training data distributed across multiple devices. Most of
the previous works about federated learning focus on the privacy protection and
communication cost reduction. However, how to achieve fairness in federated
learning is under-explored and challenging especially when testing data
distribution is different from training distribution or even unknown.
Introducing simple fairness constraints on the centralized model cannot achieve
model fairness on unknown testing data. In this paper, we develop a
fairness-aware agnostic federated learning framework (AgnosticFair) to deal
with the challenge of unknown testing distribution. We use kernel reweighing
functions to assign a reweighing value on each training sample in both loss
function and fairness constraint. Therefore, the centralized model built from
AgnosticFair can achieve high accuracy and fairness guarantee on unknown
testing data. Moreover, the built model can be directly applied to local sites
as it guarantees fairness on local data distributions. To our best knowledge,
this is the first work to achieve fairness in federated learning. Experimental
results on two real datasets demonstrate the effectiveness in terms of both
utility and fairness under data shift scenarios.
</p>
<a href="http://arxiv.org/abs/2010.05057" target="_blank">arXiv:2010.05057</a> [<a href="http://arxiv.org/pdf/2010.05057" target="_blank">pdf</a>]

<h2>Meta-Aggregating Networks for Class-Incremental Learning. (arXiv:2010.05063v1 [cs.CV])</h2>
<h3>Yaoyao Liu, Bernt Schiele, Qianru Sun</h3>
<p>Class-Incremental Learning (CIL) aims to learn a classification model with
the number of classes increasing phase-by-phase. The inherent problem in CIL is
the stability-plasticity dilemma between the learning of old and new classes,
i.e., high-plasticity models easily forget old classes but high-stability
models are weak to learn new classes. We alleviate this issue by proposing a
novel network architecture called Meta-Aggregating Networks (MANets) in which
we explicitly build two residual blocks at each residual level (taking ResNet
as the baseline architecture): a stable block and a plastic block. We aggregate
the output feature maps from these two blocks and then feed the results to the
next-level blocks. We meta-learn the aggregating weights in order to
dynamically optimize and balance between two types of blocks, i.e., between
stability and plasticity. We conduct extensive experiments on three CIL
benchmarks: CIFAR-100, ImageNet-Subset, and ImageNet, and show that many
existing CIL methods can be straightforwardly incorporated on the architecture
of MANets to boost their performance.
</p>
<a href="http://arxiv.org/abs/2010.05063" target="_blank">arXiv:2010.05063</a> [<a href="http://arxiv.org/pdf/2010.05063" target="_blank">pdf</a>]

<h2>LSMAT Least Squares Medial Axis Transform. (arXiv:2010.05066v1 [cs.GR])</h2>
<h3>Daniel Rebain, Baptiste Angles, Julien Valentin, Nicholas Vining, Jiju Peethambaran, Shahram Izadi, Andrea Tagliasacchi</h3>
<p>The medial axis transform has applications in numerous fields including
visualization, computer graphics, and computer vision. Unfortunately,
traditional medial axis transformations are usually brittle in the presence of
outliers, perturbations and/or noise along the boundary of objects. To overcome
this limitation, we introduce a new formulation of the medial axis transform
which is naturally robust in the presence of these artifacts. Unlike previous
work which has approached the medial axis from a computational geometry angle,
we consider it from a numerical optimization perspective. In this work, we
follow the definition of the medial axis transform as "the set of maximally
inscribed spheres". We show how this definition can be formulated as a least
squares relaxation where the transform is obtained by minimizing a continuous
optimization problem. The proposed approach is inherently parallelizable by
performing independant optimization of each sphere using Gauss-Newton, and its
least-squares form allows it to be significantly more robust compared to
traditional computational geometry approaches. Extensive experiments on 2D and
3D objects demonstrate that our method provides superior results to the state
of the art on both synthetic and real-data.
</p>
<a href="http://arxiv.org/abs/2010.05066" target="_blank">arXiv:2010.05066</a> [<a href="http://arxiv.org/pdf/2010.05066" target="_blank">pdf</a>]

<h2>AnomalyBench: An Open Benchmark for Explainable Anomaly Detection. (arXiv:2010.05073v1 [cs.LG])</h2>
<h3>Vincent Jacob, Fei Song, Arnaud Stiegler, Yanlei Diao, Nesime Tatbul</h3>
<p>Access to high-quality data repositories and benchmarks have been
instrumental in advancing the state of the art in many domains, as they provide
the research community a common ground for training, testing, evaluating,
comparing, and experimenting with novel machine learning models. Lack of such
community resources for anomaly detection (AD) severely limits progress. In
this report, we present AnomalyBench, the first comprehensive benchmark for
explainable AD over high-dimensional (2000+) time series data. AnomalyBench has
been systematically constructed based on real data traces from ~100 repeated
executions of 10 large-scale stream processing jobs on a Spark cluster. 30+ of
these executions were disturbed by introducing ~100 instances of different
types of anomalous events (e.g., misbehaving inputs, resource contention,
process failures). For each of these anomaly instances, ground truth labels for
the root-cause interval as well as those for the effect interval are available,
providing a means for supporting both AD tasks and explanation discovery (ED)
tasks via root-cause analysis. We demonstrate the key design features and
practical utility of AnomalyBench through an experimental study with three
state-of-the-art semi-supervised AD techniques.
</p>
<a href="http://arxiv.org/abs/2010.05073" target="_blank">arXiv:2010.05073</a> [<a href="http://arxiv.org/pdf/2010.05073" target="_blank">pdf</a>]

<h2>Noise in Classification. (arXiv:2010.05080v1 [cs.LG])</h2>
<h3>Maria-Florina Balcan, Nika Haghtalab</h3>
<p>This chapter considers the computational and statistical aspects of learning
linear thresholds in presence of noise. When there is no noise, several
algorithms exist that efficiently learn near-optimal linear thresholds using a
small amount of data. However, even a small amount of adversarial noise makes
this problem notoriously hard in the worst-case. We discuss approaches for
dealing with these negative results by exploiting natural assumptions on the
data-generating process.
</p>
<a href="http://arxiv.org/abs/2010.05080" target="_blank">arXiv:2010.05080</a> [<a href="http://arxiv.org/pdf/2010.05080" target="_blank">pdf</a>]

<h2>Software Sustainability & High Energy Physics. (arXiv:2010.05102v1 [hep-ex])</h2>
<h3>Daniel S. Katz, Sudhir Malik, Mark S. Neubauer, Graeme A. Stewart, K&#xe9;t&#xe9;vi A. Assamagan, Erin A. Becker, Neil P. Chue Hong, Ian A. Cosden, Samuel Meehan, Edward J. W. Moyse, Adrian M. Price-Whelan, Elizabeth Sexton-Kennedy, Meirin Oan Evans, Matthew Feickert, Clemens Lange, Kilian Lieret, Rob Quick, Arturo S&#xe1;nchez Pineda, Christopher Tunnell</h3>
<p>New facilities of the 2020s, such as the High Luminosity Large Hadron
Collider (HL-LHC), will be relevant through at least the 2030s. This means that
their software efforts and those that are used to analyze their data need to
consider sustainability to enable their adaptability to new challenges,
longevity, and efficiency, over at least this period. This will help ensure
that this software will be easier to develop and maintain, that it remains
available in the future on new platforms, that it meets new needs, and that it
is as reusable as possible. This report discusses a virtual half-day workshop
on "Software Sustainability and High Energy Physics" that aimed 1) to bring
together experts from HEP as well as those from outside to share their
experiences and practices, and 2) to articulate a vision that helps the
Institute for Research and Innovation in Software for High Energy Physics
(IRIS-HEP) to create a work plan to implement elements of software
sustainability. Software sustainability practices could lead to new
collaborations, including elements of HEP software being directly used outside
the field, and, as has happened more frequently in recent years, to HEP
developers contributing to software developed outside the field rather than
reinventing it. A focus on and skills related to sustainable software will give
HEP software developers an important skill that is essential to careers in the
realm of software, inside or outside HEP. The report closes with
recommendations to improve software sustainability in HEP, aimed at the HEP
community via IRIS-HEP and the HEP Software Foundation (HSF).
</p>
<a href="http://arxiv.org/abs/2010.05102" target="_blank">arXiv:2010.05102</a> [<a href="http://arxiv.org/pdf/2010.05102" target="_blank">pdf</a>]

<h2>On the Importance of Adaptive Data Collection for Extremely Imbalanced Pairwise Tasks. (arXiv:2010.05103v1 [cs.CL])</h2>
<h3>Stephen Mussmann, Robin Jia, Percy Liang</h3>
<p>Many pairwise classification tasks, such as paraphrase detection and
open-domain question answering, naturally have extreme label imbalance (e.g.,
$99.99\%$ of examples are negatives). In contrast, many recent datasets
heuristically choose examples to ensure label balance. We show that these
heuristics lead to trained models that generalize poorly: State-of-the art
models trained on QQP and WikiQA each have only $2.4\%$ average precision when
evaluated on realistically imbalanced test data. We instead collect training
data with active learning, using a BERT-based embedding model to efficiently
retrieve uncertain points from a very large pool of unlabeled utterance pairs.
By creating balanced training data with more informative negative examples,
active learning greatly improves average precision to $32.5\%$ on QQP and
$20.1\%$ on WikiQA.
</p>
<a href="http://arxiv.org/abs/2010.05103" target="_blank">arXiv:2010.05103</a> [<a href="http://arxiv.org/pdf/2010.05103" target="_blank">pdf</a>]

<h2>Contrastive Representation Learning: A Framework and Review. (arXiv:2010.05113v1 [cs.LG])</h2>
<h3>Phuc H. Le-Khac, Graham Healy, Alan F. Smeaton</h3>
<p>Contrastive Learning has recently received interest due to its success in
self-supervised representation learning in the computer vision domain. However,
the origins of Contrastive Learning date as far back as the 1990s and its
development has spanned across many fields and domains including Metric
Learning and natural language processing. In this paper we provide a
comprehensive literature review and we propose a general Contrastive
Representation Learning framework that simplifies and unifies many different
contrastive learning methods. We also provide a taxonomy for each of the
components of contrastive learning in order to summarise it and distinguish it
from other forms of machine learning. We then discuss the inductive biases
which are present in any contrastive learning system and we analyse our
framework under different views from various sub-fields of Machine Learning.
Examples of how contrastive learning has been applied in computer vision,
natural language processing, audio processing, and others, as well as in
Reinforcement Learning are also presented. Finally, we discuss the challenges
and some of the most promising future research directions ahead.
</p>
<a href="http://arxiv.org/abs/2010.05113" target="_blank">arXiv:2010.05113</a> [<a href="http://arxiv.org/pdf/2010.05113" target="_blank">pdf</a>]

<h2>Towards Hardware-Agnostic Gaze-Trackers. (arXiv:2010.05123v1 [cs.AI])</h2>
<h3>Jatin Sharma, Jon Campbell, Pete Ansell, Jay Beavers, Christopher O&#x27;Dowd</h3>
<p>Gaze-tracking is a novel way of interacting with computers which allows new
scenarios, such as enabling people with motor-neuron disabilities to control
their computers or doctors to interact with patient information without
touching screen or keyboard. Further, there are emerging applications of
gaze-tracking in interactive gaming, user experience research, human attention
analysis and behavioral studies. Accurate estimation of the gaze may involve
accounting for head-pose, head-position, eye rotation, distance from the object
as well as operating conditions such as illumination, occlusion, background
noise and various biological aspects of the user. Commercially available
gaze-trackers utilize specialized sensor assemblies that usually consist of an
infrared light source and camera. There are several challenges in the universal
proliferation of gaze-tracking as accessibility technologies, specifically its
affordability, reliability, and ease-of-use. In this paper, we try to address
these challenges through the development of a hardware-agnostic gaze-tracker.
We present a deep neural network architecture as an appearance-based method for
constrained gaze-tracking that utilizes facial imagery captured on an ordinary
RGB camera ubiquitous in all modern computing devices. Our system achieved an
error of 1.8073cm on GazeCapture dataset without any calibration or device
specific fine-tuning. This research shows promise that one day soon any
computer, tablet, or phone will be controllable using just your eyes due to the
prediction capabilities of deep neutral networks.
</p>
<a href="http://arxiv.org/abs/2010.05123" target="_blank">arXiv:2010.05123</a> [<a href="http://arxiv.org/pdf/2010.05123" target="_blank">pdf</a>]

<h2>Is It Time to Redefine the Classification Task for Deep Neural Networks?. (arXiv:2010.05125v1 [cs.LG])</h2>
<h3>Keji Han, Yun Li</h3>
<p>Deep neural networks (DNNs) is demonstrated to be vulnerable to the
adversarial example, which is generated by adding small adversarial
perturbation into the original legitimate example to cause the wrong outputs of
DNNs. Nowadays, most works focus on the robustness of the deep model, while few
works pay attention to the robustness of the learning task itself defined on
DNNs. So we redefine this issue as the robustness of deep neural learning
system. A deep neural learning system consists of the deep model and the
learning task defined on the deep model. Moreover, the deep model is usually a
deep neural network, involving the model architecture, data, training loss and
training algorithm. We speculate that the vulnerability of the deep learning
system also roots in the learning task itself. This paper defines the
interval-label classification task for the deep classification system, whose
labels are predefined non-overlapping intervals, instead of a fixed value (hard
label) or probability vector (soft label). The experimental results demonstrate
that the interval-label classification task is more robust than the traditional
classification task while retaining accuracy.
</p>
<a href="http://arxiv.org/abs/2010.05125" target="_blank">arXiv:2010.05125</a> [<a href="http://arxiv.org/pdf/2010.05125" target="_blank">pdf</a>]

<h2>Segmenting Epipolar Line. (arXiv:2010.05131v1 [cs.CV])</h2>
<h3>Shengjie Li, Qi Cai, Yuanxin Wu</h3>
<p>Identifying feature correspondence between two images is a fundamental
procedure in three-dimensional computer vision. Usually the feature search
space is confined by the epipolar line. Using the cheirality constraint, this
paper finds that the feature search space can be restrained to one of two or
three segments of the epipolar line that are defined by the epipole and a
so-called virtual infinity point.
</p>
<a href="http://arxiv.org/abs/2010.05131" target="_blank">arXiv:2010.05131</a> [<a href="http://arxiv.org/pdf/2010.05131" target="_blank">pdf</a>]

<h2>SDMTL: Semi-Decoupled Multi-grained Trajectory Learning for 3D human motion prediction. (arXiv:2010.05133v1 [cs.CV])</h2>
<h3>Xiaoli Liu, Jianqin Yin</h3>
<p>Predicting future human motion is critical for intelligent robots to interact
with humans in the real world, and human motion has the nature of
multi-granularity. However, most of the existing work either implicitly modeled
multi-granularity information via fixed modes or focused on modeling a single
granularity, making it hard to well capture this nature for accurate
predictions. In contrast, we propose a novel end-to-end network, Semi-Decoupled
Multi-grained Trajectory Learning network (SDMTL), to predict future poses,
which not only flexibly captures rich multi-grained trajectory information but
also aggregates multi-granularity information for predictions. Specifically, we
first introduce a Brain-inspired Semi-decoupled Motion-sensitive Encoding
module (BSME), effectively capturing spatiotemporal features in a
semi-decoupled manner. Then, we capture the temporal dynamics of motion
trajectory at multi-granularity, including fine granularity and coarse
granularity. We learn multi-grained trajectory information using BSMEs
hierarchically and further capture the information of temporal evolutional
directions at each granularity by gathering the outputs of BSMEs at each
granularity and applying temporal convolutions along the motion trajectory.
Next, the captured motion dynamics can be further enhanced by aggregating the
information of multi-granularity with a weighted summation scheme. Finally,
experimental results on two benchmarks, including Human3.6M and CMU-Mocap, show
that our method achieves state-of-the-art performance, demonstrating the
effectiveness of our proposed method. The code will be available if the paper
is accepted.
</p>
<a href="http://arxiv.org/abs/2010.05133" target="_blank">arXiv:2010.05133</a> [<a href="http://arxiv.org/pdf/2010.05133" target="_blank">pdf</a>]

<h2>Deep Imitation Learning for Bimanual Robotic Manipulation. (arXiv:2010.05134v1 [cs.RO])</h2>
<h3>Fan Xie, Alexander Chowdhury, M. Clara De Paolis Kaluza, Linfeng Zhao, Lawson L.S. Wong, Rose Yu</h3>
<p>We present a deep imitation learning framework for robotic bimanual
manipulation in a continuous state-action space. Imitation learning has been
effectively utilized in mimicking bimanual manipulation movements, but
generalizing the movement to objects in different locations has not been
explored. We hypothesize that to precisely generalize the learned behavior
relative to an object's location requires modeling relational information in
the environment. To achieve this, we designed a method that (i) uses a
multi-model framework to decomposes complex dynamics into elemental movement
primitives, and (ii) parameterizes each primitive using a recurrent graph
neural network to capture interactions. Our model is a deep, hierarchical,
modular architecture with a high-level planner that learns to compose
primitives sequentially and a low-level controller which integrates primitive
dynamics modules and inverse kinematics control. We demonstrate the
effectiveness using several simulated bimanual robotic manipulation tasks.
Compared to models based on previous imitation learning studies, our model
generalizes better and achieves higher success rates in the simulated tasks.
</p>
<a href="http://arxiv.org/abs/2010.05134" target="_blank">arXiv:2010.05134</a> [<a href="http://arxiv.org/pdf/2010.05134" target="_blank">pdf</a>]

<h2>An Open Review of OpenReview: A Critical Analysis of the Machine Learning Conference Review Process. (arXiv:2010.05137v1 [cs.LG])</h2>
<h3>David Tran, Alex Valtchanov, Keshav Ganapathy, Raymond Feng, Eric Slud, Micah Goldblum, Tom Goldstein</h3>
<p>Mainstream machine learning conferences have seen a dramatic increase in the
number of participants, along with a growing range of perspectives, in recent
years. Members of the machine learning community are likely to overhear
allegations ranging from randomness of acceptance decisions to institutional
bias. In this work, we critically analyze the review process through a
comprehensive study of papers submitted to ICLR between 2017 and 2020. We
quantify reproducibility/randomness in review scores and acceptance decisions,
and examine whether scores correlate with paper impact. Our findings suggest
strong institutional bias in accept/reject decisions, even after controlling
for paper quality. Furthermore, we find evidence for a gender gap, with female
authors receiving lower scores, lower acceptance rates, and fewer citations per
paper than their male counterparts. We conclude our work with recommendations
for future conference organizers.
</p>
<a href="http://arxiv.org/abs/2010.05137" target="_blank">arXiv:2010.05137</a> [<a href="http://arxiv.org/pdf/2010.05137" target="_blank">pdf</a>]

<h2>Plan ahead: Self-Supervised Text Planning for Paragraph Completion Task. (arXiv:2010.05141v1 [cs.CL])</h2>
<h3>Dongyeop Kang, Eduard Hovy</h3>
<p>Despite the recent success of contextualized language models on various NLP
tasks, language model itself cannot capture textual coherence of a long,
multi-sentence document (e.g., a paragraph). Humans often make structural
decisions on what and how to say about before making utterances. Guiding
surface realization with such high-level decisions and structuring text in a
coherent way is essentially called a planning process. Where can the model
learn such high-level coherence? A paragraph itself contains various forms of
inductive coherence signals called self-supervision in this work, such as
sentence orders, topical keywords, rhetorical structures, and so on. Motivated
by that, this work proposes a new paragraph completion task PARCOM; predicting
masked sentences in a paragraph. However, the task suffers from predicting and
selecting appropriate topical content with respect to the given context. To
address that, we propose a self-supervised text planner SSPlanner that predicts
what to say first (content prediction), then guides the pretrained language
model (surface realization) using the predicted content. SSPlanner outperforms
the baseline generation models on the paragraph completion task in both
automatic and human evaluation. We also find that a combination of noun and
verb types of keywords is the most effective for content selection. As more
number of content keywords are provided, overall generation quality also
increases.
</p>
<a href="http://arxiv.org/abs/2010.05141" target="_blank">arXiv:2010.05141</a> [<a href="http://arxiv.org/pdf/2010.05141" target="_blank">pdf</a>]

<h2>Safe Reinforcement Learning with Natural Language Constraints. (arXiv:2010.05150v1 [cs.CL])</h2>
<h3>Tsung-Yen Yang, Michael Hu, Yinlam Chow, Peter J. Ramadge, Karthik Narasimhan</h3>
<p>In this paper, we tackle the problem of learning control policies for tasks
when provided with constraints in natural language. In contrast to instruction
following, language here is used not to specify goals, but rather to describe
situations that an agent must avoid during its exploration of the environment.
Specifying constraints in natural language also differs from the predominant
paradigm in safe reinforcement learning, where safety criteria are enforced by
hand-defined cost functions. While natural language allows for easy and
flexible specification of safety constraints and budget limitations, its
ambiguous nature presents a challenge when mapping these specifications into
representations that can be used by techniques for safe reinforcement learning.
To address this, we develop a model that contains two components: (1) a
constraint interpreter to encode natural language constraints into vector
representations capturing spatial and temporal information on forbidden states,
and (2) a policy network that uses these representations to output a policy
with minimal constraint violations. Our model is end-to-end differentiable and
we train it using a recently proposed algorithm for constrained policy
optimization. To empirically demonstrate the effectiveness of our approach, we
create a new benchmark task for autonomous navigation with crowd-sourced
free-form text specifying three different types of constraints. Our method
outperforms several baselines by achieving 6-7 times higher returns and 76%
fewer constraint violations on average. Dataset and code to reproduce our
experiments are available at https://sites.google.com/view/polco-hazard-world/.
</p>
<a href="http://arxiv.org/abs/2010.05150" target="_blank">arXiv:2010.05150</a> [<a href="http://arxiv.org/pdf/2010.05150" target="_blank">pdf</a>]

<h2>Online Learning and Distributed Control for Residential Demand Response. (arXiv:2010.05153v1 [eess.SY])</h2>
<h3>Xin Chen, Yingying Li, Jun Shimada, Na Li</h3>
<p>This paper studies the automated control method for regulating air
conditioner (AC)-type loads in incentive-based residential demand response
(DR). The critical challenge is that the customer responses to load adjustment
are uncertain and unknown in practice. In this paper, we formulate the AC
control problem in a DR event as a Markov decision process that integrates the
indoor thermal dynamics and customer opt-out status transition. Specifically,
machine learning techniques including Gaussian process and logistic regression
are employed to learn the unknown thermal dynamics model and customer opt-out
behavior model, respectively. We consider two typical DR objectives for AC load
control: 1) minimizing the total load demand, 2) closely tracking a regulated
power trajectory. Based on the Thompson sampling framework, we propose an
online DR control algorithm to learn the customer behaviors and make real-time
AC control schemes. This algorithm considers the influence of various
environmental factors on customer behaviors, and is implemented in a
distributed fashion to preserve the privacy of customers. Numerical simulations
demonstrate the control optimality and learning efficiency of the proposed
algorithm.
</p>
<a href="http://arxiv.org/abs/2010.05153" target="_blank">arXiv:2010.05153</a> [<a href="http://arxiv.org/pdf/2010.05153" target="_blank">pdf</a>]

<h2>Lambda Learner: Fast Incremental Learning on Data Streams. (arXiv:2010.05154v1 [cs.LG])</h2>
<h3>Rohan Ramanath, Konstantin Salomatin, Jeffrey D. Gee, Kirill Talanine, Onkar Dalal, Gungor Polatkan, Sara Smoot, Deepak Kumar</h3>
<p>One of the most well-established applications of machine learning is in
deciding what content to show website visitors. When observation data comes
from high-velocity, user-generated data streams, machine learning methods
perform a balancing act between model complexity, training time, and
computational costs. Furthermore, when model freshness is critical, the
training of models becomes time-constrained. Parallelized batch offline
training, although horizontally scalable, is often not time-considerate or
cost-effective. In this paper, we propose Lambda Learner, a new framework for
training models by incremental updates in response to mini-batches from data
streams. We show that the resulting model of our framework closely estimates a
periodically updated model trained on offline data and outperforms it when
model updates are time-sensitive. We provide theoretical proof that the
incremental learning updates improve the loss-function over a stale batch
model. We present a large-scale deployment on the sponsored content platform
for a large social network, serving hundreds of millions of users across
different channels (e.g., desktop, mobile). We address challenges and
complexities from both algorithms and infrastructure perspectives, and
illustrate the system details for computation, storage, and streaming
production of training data.
</p>
<a href="http://arxiv.org/abs/2010.05154" target="_blank">arXiv:2010.05154</a> [<a href="http://arxiv.org/pdf/2010.05154" target="_blank">pdf</a>]

<h2>Robust Fairness under Covariate Shift. (arXiv:2010.05166v1 [cs.LG])</h2>
<h3>Ashkan Rezaei, Anqi Liu, Omid Memarrast, Brian Ziebart</h3>
<p>Making predictions that are fair with regard to protected group membership
(race, gender, age, etc.) has become an important requirement for
classification algorithms. Existing techniques derive a fair model from sampled
labeled data relying on the assumption that training and testing data are
identically and independently drawn (iid) from the same distribution.In
practice, distribution shift can and does occur between training and testing
datasets as the characteristics of individuals interacting with the machine
learning system -- and which individuals interact with the system -- change. We
investigate fairness under covariate shift, a relaxation of the iid assumption
in which the inputs or covariates change while the conditional label
distribution remains the same. We seek fair decisions under these assumptions
on target data with unknown labels.We propose an approach that obtains the
predictor that is robust to the worst-case in terms of target performance while
satisfying target fairness requirements and matching statistical properties of
the source data. We demonstrate the benefits of our approach on benchmark
prediction tasks.
</p>
<a href="http://arxiv.org/abs/2010.05166" target="_blank">arXiv:2010.05166</a> [<a href="http://arxiv.org/pdf/2010.05166" target="_blank">pdf</a>]

<h2>fairseq S2T: Fast Speech-to-Text Modeling with fairseq. (arXiv:2010.05171v1 [cs.CL])</h2>
<h3>Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino</h3>
<p>We introduce fairseq S2T, a fairseq extension for speech-to-text (S2T)
modeling tasks such as end-to-end speech recognition and speech-to-text
translation. It follows fairseq's careful design for scalability and
extensibility. We provide end-to-end workflows from data pre-processing, model
training to offline (online) inference. We implement state-of-the-art RNN-based
as well as Transformer-based models and open-source detailed training recipes.
Fairseq's machine translation models and language models can be seamlessly
integrated into S2T workflows for multi-task learning or transfer learning.
Fairseq S2T documentation and examples are available at
https://github.com/pytorch/fairseq/tree/master/examples/speech_to_text.
</p>
<a href="http://arxiv.org/abs/2010.05171" target="_blank">arXiv:2010.05171</a> [<a href="http://arxiv.org/pdf/2010.05171" target="_blank">pdf</a>]

<h2>Contrastive Explanations for Reinforcement Learning via Embedded Self Predictions. (arXiv:2010.05180v1 [cs.AI])</h2>
<h3>Zhengxian Lin, Kim-Ho Lam, Alan Fern</h3>
<p>We investigate a deep reinforcement learning (RL) architecture that supports
explaining why a learned agent prefers one action over another. The key idea is
to learn action-values that are directly represented via human-understandable
properties of expected futures. This is realized via the embedded
self-prediction (ESP)model, which learns said properties in terms of human
provided features. Action preferences can then be explained by contrasting the
future properties predicted for each action. To address cases where there are a
large number of features, we develop a novel method for computing minimal
sufficient explanations from anESP. Our case studies in three domains,
including a complex strategy game, show that ESP models can be effectively
learned and support insightful explanations.
</p>
<a href="http://arxiv.org/abs/2010.05180" target="_blank">arXiv:2010.05180</a> [<a href="http://arxiv.org/pdf/2010.05180" target="_blank">pdf</a>]

<h2>Constructing a Visual Relationship Authenticity Dataset. (arXiv:2010.05185v1 [cs.CV])</h2>
<h3>Chenhui Chu, Yuto Takebayashi, Mishra Vipul, Yuta Nakashima</h3>
<p>A visual relationship denotes a relationship between two objects in an image,
which can be represented as a triplet of (subject; predicate; object). Visual
relationship detection is crucial for scene understanding in images. Existing
visual relationship detection datasets only contain true relationships that
correctly describe the content in an image. However, distinguishing false
visual relationships from true ones is also crucial for image understanding and
grounded natural language processing. In this paper, we construct a visual
relationship authenticity dataset, where both true and false relationships
among all objects appeared in the captions in the Flickr30k entities image
caption dataset are annotated. The dataset is available at
https://github.com/codecreator2053/VR_ClassifiedDataset. We hope that this
dataset can promote the study on both vision and language understanding.
</p>
<a href="http://arxiv.org/abs/2010.05185" target="_blank">arXiv:2010.05185</a> [<a href="http://arxiv.org/pdf/2010.05185" target="_blank">pdf</a>]

<h2>On the Road from Edge Computing to the Edge Mesh. (arXiv:2010.05187v1 [cs.DC])</h2>
<h3>Panagiotis Oikonomou, Anna Karanika, Christos Anagnostopoulos, Kostas Kolomvatsos</h3>
<p>Nowadays, we are witnessing the advent of the Internet of Things (EC) with
numerous devices performing interactions between them or with end users. The
huge number of devices leads to huge volumes of collected data that demand the
appropriate processing. The 'legacy' approach is to rely on Cloud where
increased computational resources can be adopted to realize any processing.
However, even if the communication with the Cloud back end lasts for some
seconds there are cases where problems in the network or the need for
supporting real time applications require a reduced latency in the provision of
responses/outcomes. Edge Computing (EC) comes into the scene as the 'solver' of
the latency problem (and not only). Any processing can be performed close to
data sources, i.e., at EC nodes having direct connection with IoT devices.
Hence, an ecosystem of processing nodes can be present at the edge of the
network giving the opportunity to apply novel services upon the collected data.
Various challenges should be met before we talk about a fully automated
ecosystem where EC nodes can cooperate or understand the status of them and the
environment to be capable of efficiently serving end users or applications. In
this paper, we perform a survey of the relevant research activities targeting
to support the vision of Edge Mesh (EM), i.e., a 'cover' of intelligence upon
the EC infrastructure. We present all the parts of the EC/EM framework starting
from the necessary hardware and discussing research outcomes in every aspect of
EC nodes functioning. We present technologies and theories adopted for data,
tasks and resource management while discussing how (deep) machine learning and
optimization techniques are adopted to solve various problems. Our aim is to
provide a starting point for novel research to conclude efficient
services/applications opening up the path to realize the future EC form.
</p>
<a href="http://arxiv.org/abs/2010.05187" target="_blank">arXiv:2010.05187</a> [<a href="http://arxiv.org/pdf/2010.05187" target="_blank">pdf</a>]

<h2>Learning Adaptive Language Interfaces through Decomposition. (arXiv:2010.05190v1 [cs.CL])</h2>
<h3>Siddharth Karamcheti, Dorsa Sadigh, Percy Liang</h3>
<p>Our goal is to create an interactive natural language interface that
efficiently and reliably learns from users to complete tasks in simulated
robotics settings. We introduce a neural semantic parsing system that learns
new high-level abstractions through decomposition: users interactively teach
the system by breaking down high-level utterances describing novel behavior
into low-level steps that it can understand. Unfortunately, existing methods
either rely on grammars which parse sentences with limited flexibility, or
neural sequence-to-sequence models that do not learn efficiently or reliably
from individual examples. Our approach bridges this gap, demonstrating the
flexibility of modern neural systems, as well as the one-shot reliable
generalization of grammar-based methods. Our crowdsourced interactive
experiments suggest that over time, users complete complex tasks more
efficiently while using our system by leveraging what they just taught. At the
same time, getting users to trust the system enough to be incentivized to teach
high-level utterances is still an ongoing challenge. We end with a discussion
of some of the obstacles we need to overcome to fully realize the potential of
the interactive paradigm.
</p>
<a href="http://arxiv.org/abs/2010.05190" target="_blank">arXiv:2010.05190</a> [<a href="http://arxiv.org/pdf/2010.05190" target="_blank">pdf</a>]

<h2>Detecting Foodborne Illness Complaints in Multiple Languages Using English Annotations Only. (arXiv:2010.05194v1 [cs.CL])</h2>
<h3>Ziyi Liu, Giannis Karamanolakis, Daniel Hsu, Luis Gravano</h3>
<p>Health departments have been deploying text classification systems for the
early detection of foodborne illness complaints in social media documents such
as Yelp restaurant reviews. Current systems have been successfully applied for
documents in English and, as a result, a promising direction is to increase
coverage and recall by considering documents in additional languages, such as
Spanish or Chinese. Training previous systems for more languages, however,
would be expensive, as it would require the manual annotation of many documents
for each new target language. To address this challenge, we consider
cross-lingual learning and train multilingual classifiers using only the
annotations for English-language reviews. Recent zero-shot approaches based on
pre-trained multi-lingual BERT (mBERT) have been shown to effectively align
languages for aspects such as sentiment. Interestingly, we show that those
approaches are less effective for capturing the nuances of foodborne illness,
our public health application of interest. To improve performance without extra
annotations, we create artificial training documents in the target language
through machine translation and train mBERT jointly for the source (English)
and target language. Furthermore, we show that translating labeled documents to
multiple languages leads to additional performance improvements for some target
languages. We demonstrate the benefits of our approach through extensive
experiments with Yelp restaurant reviews in seven languages. Our classifiers
identify foodborne illness complaints in multilingual reviews from the Yelp
Challenge dataset, which highlights the potential of our general approach for
deployment in health departments.
</p>
<a href="http://arxiv.org/abs/2010.05194" target="_blank">arXiv:2010.05194</a> [<a href="http://arxiv.org/pdf/2010.05194" target="_blank">pdf</a>]

<h2>TaxoNN: A Light-Weight Accelerator for Deep Neural Network Training. (arXiv:2010.05197v1 [cs.AR])</h2>
<h3>Reza Hojabr, Kamyar Givaki, Kossar Pourahmadi, Parsa Nooralinejad, Ahmad Khonsari, Dara Rahmati, M. Hassan Najafi</h3>
<p>Emerging intelligent embedded devices rely on Deep Neural Networks (DNNs) to
be able to interact with the real-world environment. This interaction comes
with the ability to retrain DNNs, since environmental conditions change
continuously in time. Stochastic Gradient Descent (SGD) is a widely used
algorithm to train DNNs by optimizing the parameters over the training data
iteratively. In this work, first we present a novel approach to add the
training ability to a baseline DNN accelerator (inference only) by splitting
the SGD algorithm into simple computational elements. Then, based on this
heuristic approach we propose TaxoNN, a light-weight accelerator for DNN
training. TaxoNN can easily tune the DNN weights by reusing the hardware
resources used in the inference process using a time-multiplexing approach and
low-bitwidth units. Our experimental results show that TaxoNN delivers, on
average, 0.97% higher misclassification rate compared to a full-precision
implementation. Moreover, TaxoNN provides 2.1$\times$ power saving and
1.65$\times$ area reduction over the state-of-the-art DNN training accelerator.
</p>
<a href="http://arxiv.org/abs/2010.05197" target="_blank">arXiv:2010.05197</a> [<a href="http://arxiv.org/pdf/2010.05197" target="_blank">pdf</a>]

<h2>Total heat flux convergence in the calculation of 2d and 3d heat losses through building elements. (arXiv:2010.05207v1 [cs.CE])</h2>
<h3>Sanjin Gumbarevi&#x107;, Bojan Milovanovi&#x107;, Margim Ga&#x161;i, Marina Bagari&#x107;</h3>
<p>Heat losses through the building envelope is one of the key factors in the
calculation of the building energy balance. If steady-state heat conduction is
observed, which is commonly used to assess the heat losses in building, there
is an analytical solution for one-dimensional problem. For two and
three-dimensional problems, especially for the complex geometry cases, one must
use numerical methods to solve the heat conduction equation. To standardise two
and three-dimensional calculation of heat losses through building elements, ISO
10211 standard can be used. The standard has four benchmark examples with
criteria that must be satisfied to declare a method as a high-precision
calculation method. A problem occurs for Case 1 of benchmark test because the
analysed problem has a singular point due to discretely assigned Dirichlet
boundary conditions. The reliability of the results around the singular point
could be improved by the refinement of the mesh in the area around the singular
point, but as a point of interest is the total heat flux that is entering the
building element, and it must converge between subdivisions, this method is not
good since the reliable result cannot be reached. The problem for the
convergence is in the marginal node because the temperature gradient in it
increases as the temperature difference remains constant and the distance
between the corresponding nodes decreases. For that reason, Case 1 from the
benchmark is inadequate because even if there is a discontinuity in temperature
field on the boundary, there is an interval in which this change is to happen,
and the heat flux has a theoretical limit which is not infinity. From the
results of this research, it is shown that one should neglect a certain number
of singular points in order to achieve the tolerance given by the standard
since the temperature further from the marginal node is stable for any
subdivision.
</p>
<a href="http://arxiv.org/abs/2010.05207" target="_blank">arXiv:2010.05207</a> [<a href="http://arxiv.org/pdf/2010.05207" target="_blank">pdf</a>]

<h2>Generalized Few-Shot Semantic Segmentation. (arXiv:2010.05210v1 [cs.CV])</h2>
<h3>Zhuotao Tian, Xin Lai, Li Jiang, Michelle Shu, Hengshuang Zhao, Jiaya Jia</h3>
<p>Training semantic segmentation models requires a large amount of finely
annotated data, making it hard to quickly adapt to novel classes not satisfying
this condition. Few-Shot Segmentation (FS-Seg) tackles this problem with many
constraints. In this paper, we introduce a new benchmark, called Generalized
Few-Shot Semantic Segmentation (GFS-Seg), to analyze the generalization ability
of segmentation models to simultaneously recognize novel categories with very
few examples as well as base categories with sufficient examples. Previous
state-of-the-art FS-Seg methods fall short in GFS-Seg and the performance
discrepancy mainly comes from the constrained training setting of FS-Seg. To
make GFS-Seg tractable, we set up a GFS-Seg baseline that achieves decent
performance without structural change on the original model. Then, as context
is the key for boosting performance on semantic segmentation, we propose the
Context-Aware Prototype Learning (CAPL) that significantly improves performance
by leveraging the contextual information to update class prototypes with
aligned features. Extensive experiments on Pascal-VOC and COCO manifest the
effectiveness of CAPL, and CAPL also generalizes well to FS-Seg.
</p>
<a href="http://arxiv.org/abs/2010.05210" target="_blank">arXiv:2010.05210</a> [<a href="http://arxiv.org/pdf/2010.05210" target="_blank">pdf</a>]

<h2>Partial FC: Training 10 Million Identities on a Single Machine. (arXiv:2010.05222v1 [cs.CV])</h2>
<h3>Xiang An, Xuhan Zhu, Yang Xiao, Lan Wu, Ming Zhang, Yuan Gao, Bin Qin, Debing Zhang, Ying Fu</h3>
<p>Face recognition has been an active and vital topic among computer vision
community for a long time. Previous researches mainly focus on loss functions
used for facial feature extraction network, among which the improvements of
softmax-based loss functions greatly promote the performance of face
recognition. However, the contradiction between the drastically increasing
number of face identities and the shortage of GPU memories is gradually
becoming irreconcilable. In this paper, we thoroughly analyze the optimization
goal of softmax-based loss functions and the difficulty of training massive
identities. We find that the importance of negative classes in softmax function
in face representation learning is not as high as we previously thought. The
experiment demonstrates no loss of accuracy when training with only 10\%
randomly sampled classes for the softmax-based loss functions, compared with
training with full classes using state-of-the-art models on mainstream
benchmarks. We also implement a very efficient distributed sampling algorithm,
taking into account model accuracy and training efficiency, which uses only
eight NVIDIA RTX2080Ti to complete classification tasks with tens of millions
of identities. The code of this paper has been made available
https://github.com/deepinsight/insightface/tree/master/recognition/partial_fc.
</p>
<a href="http://arxiv.org/abs/2010.05222" target="_blank">arXiv:2010.05222</a> [<a href="http://arxiv.org/pdf/2010.05222" target="_blank">pdf</a>]

<h2>End to End Binarized Neural Networks for Text Classification. (arXiv:2010.05223v1 [cs.LG])</h2>
<h3>Harshil Jain, Akshat Agarwal, Kumar Shridhar, Denis Kleyko</h3>
<p>Deep neural networks have demonstrated their superior performance in almost
every Natural Language Processing task, however, their increasing complexity
raises concerns. In particular, these networks require high expenses on
computational hardware, and training budget is a concern for many. Even for a
trained network, the inference phase can be too demanding for
resource-constrained devices, thus limiting its applicability. The
state-of-the-art transformer models are a vivid example. Simplifying the
computations performed by a network is one way of relaxing the complexity
requirements. In this paper, we propose an end to end binarized neural network
architecture for the intent classification task. In order to fully utilize the
potential of end to end binarization, both input representations (vector
embeddings of tokens statistics) and the classifier are binarized. We
demonstrate the efficiency of such architecture on the intent classification of
short texts over three datasets and for text classification with a larger
dataset. The proposed architecture achieves comparable to the state-of-the-art
results on standard intent classification datasets while utilizing ~ 20-40%
lesser memory and training time. Furthermore, the individual components of the
architecture, such as binarized vector embeddings of documents or binarized
classifiers, can be used separately with not necessarily fully binary
architectures.
</p>
<a href="http://arxiv.org/abs/2010.05223" target="_blank">arXiv:2010.05223</a> [<a href="http://arxiv.org/pdf/2010.05223" target="_blank">pdf</a>]

<h2>An Energy-Efficient High Definition Map Data Distribution Mechanism for Autonomous Driving. (arXiv:2010.05233v1 [cs.RO])</h2>
<h3>Jinliang Xie, Jie Tang, Shaoshan Liu</h3>
<p>Autonomous Driving is now the promising future of transportation. As one
basis for autonomous driving, High Definition Map (HD map) provides
high-precision descriptions of the environment, therefore it enables more
accurate perception and localization while improving the efficiency of path
planning. However, an extremely large amount of map data needs to be
transmitted during driving, thus posing great challenge for real-time and
safety requirements for autonomous driving. To this end, we first demonstrate
how the existing data distribution mechanism can support HD map services.
Furthermore, considering the constraints of vehicle power, vehicle speed, base
station bandwidth, etc., we propose a HD map data distribution mechanism on top
of Vehicle-to-Infrastructure (V2I) data transmission. By this mechanism, the
map provision task is allocated to the selected RSU nodes and transmits
proportionate HD map data cooperatively. Their works on map data loading aims
to provide in-time HD map data service with optimized in-vehicle energy
consumption. Finally, we model the selection of RSU nodes into a partial
knapsack problem and propose a greedy strategy-based data transmission
algorithm. Experimental results confirm that within limited energy consumption,
the proposed mechanism can ensure HD map data service by coordinating multiple
RSUs with the shortest data transmission time.
</p>
<a href="http://arxiv.org/abs/2010.05233" target="_blank">arXiv:2010.05233</a> [<a href="http://arxiv.org/pdf/2010.05233" target="_blank">pdf</a>]

<h2>A Practical Guide to Graph Neural Networks. (arXiv:2010.05234v1 [cs.LG])</h2>
<h3>Isaac Ronald Ward, Jack Joyner, Casey Lickfold, Stash Rowe, Yulan Guo, Mohammed Bennamoun</h3>
<p>Graph neural networks (GNNs) have recently grown in popularity in the field
of artificial intelligence due to their unique ability to ingest relatively
unstructured data types as input data. Although some elements of the GNN
architecture are conceptually similar in operation to traditional neural
networks (and neural network variants), other elements represent a departure
from traditional deep learning techniques. This tutorial exposes the power and
novelty of GNNs to the average deep learning enthusiast by collating and
presenting details on the motivations, concepts, mathematics, and applications
of the most common types of GNNs. Importantly, we present this tutorial
concisely, alongside worked code examples, and at an introductory pace, thus
providing a practical and accessible guide to understanding and using GNNs.
</p>
<a href="http://arxiv.org/abs/2010.05234" target="_blank">arXiv:2010.05234</a> [<a href="http://arxiv.org/pdf/2010.05234" target="_blank">pdf</a>]

<h2>General stochastic separation theorems with optimal bounds. (arXiv:2010.05241v1 [cs.AI])</h2>
<h3>Bogdan Grechuk, Alexander N. Gorban, Ivan Y. Tyukin</h3>
<p>Phenomenon of stochastic separability was revealed and used in machine
learning to correct errors of Artificial Intelligence (AI) systems and analyze
AI instabilities. In high-dimensional datasets under broad assumptions each
point can be separated from the rest of the set by simple and robust Fisher's
discriminant (is Fisher separable). Errors or clusters of errors can be
separated from the rest of the data. The ability to correct an AI system also
opens up the possibility of an attack on it, and the high dimensionality
induces vulnerabilities caused by the same stochastic separability that holds
the keys to understanding the fundamentals of robustness and adaptivity in
high-dimensional data-driven AI. To manage errors and analyze vulnerabilities,
the stochastic separation theorems should evaluate the probability that the
dataset will be Fisher separable in given dimensionality and for a given class
of distributions. Explicit and optimal estimates of these separation
probabilities are required, and this problem is solved in present work. The
general stochastic separation theorems with optimal probability estimates are
obtained for important classes of distributions: log-concave distribution,
their convex combinations and product distributions. The standard i.i.d.
assumption was significantly relaxed. These theorems and estimates can be used
both for correction of high-dimensional data driven AI systems and for analysis
of their vulnerabilities. The third area of application is the emergence of
memories in ensembles of neurons, the phenomena of grandmother's cells and
sparse coding in the brain, and explanation of unexpected effectiveness of
small neural ensembles in high-dimensional brain.
</p>
<a href="http://arxiv.org/abs/2010.05241" target="_blank">arXiv:2010.05241</a> [<a href="http://arxiv.org/pdf/2010.05241" target="_blank">pdf</a>]

<h2>Data Agnostic RoBERTa-based Natural Language to SQL Query Generation. (arXiv:2010.05243v1 [cs.AI])</h2>
<h3>Debaditya Pal, Harsh Sharma, Kaustubh Chaudhari</h3>
<p>Relational databases are among the most widely used architectures to store
massive amounts of data in the modern world. However, there is a barrier
between these databases and the average user. The user often lacks the
knowledge of a query language such as SQL required to interact with the
database. The NL2SQL task aims at finding deep learning approaches to solve
this problem by converting natural language questions into valid SQL queries.
Given the sensitive nature of some databases and the growing need for data
privacy, we have presented an approach with data privacy at its core. We have
passed RoBERTa embeddings and data-agnostic knowledge vectors into LSTM based
submodels to predict the final query. Although we have not achieved state of
the art results, we have eliminated the need for the table data, right from the
training of the model, and have achieved a test set execution accuracy of
76.7%. By eliminating the table data dependency while training we have created
a model capable of zero shot learning based on the natural language question
and table schema alone.
</p>
<a href="http://arxiv.org/abs/2010.05243" target="_blank">arXiv:2010.05243</a> [<a href="http://arxiv.org/pdf/2010.05243" target="_blank">pdf</a>]

<h2>Advanced Dropout: A Model-free Methodology for Bayesian Dropout Optimization. (arXiv:2010.05244v1 [cs.LG])</h2>
<h3>Jiyang Xie, Zhanyu Ma, Guoqiang Zhang, Jing-Hao Xue, Zheng-Hua Tan, Jun Guo</h3>
<p>Due to lack of data, overfitting ubiquitously exists in real-world
applications of deep neural networks (DNNs). In this paper, we propose advanced
dropout, a model-free methodology, to mitigate overfitting and improve the
performance of DNNs. The advanced dropout technique applies a model-free and
easily implemented distribution with a parametric prior, and adaptively adjusts
dropout rate. Specifically, the distribution parameters are optimized by
stochastic gradient variational Bayes (SGVB) inference in order to carry out an
end-to-end training of DNNs. We evaluate the effectiveness of the advanced
dropout against nine dropout techniques on five widely used datasets in
computer vision. The advanced dropout outperforms all the referred techniques
by 0.83% on average for all the datasets. An ablation study is conducted to
analyze the effectiveness of each component. Meanwhile, convergence of dropout
rate and ability to prevent overfitting are discussed in terms of
classification performance. Moreover, we extend the application of the advanced
dropout to uncertainty inference and network pruning, and we find that the
advanced dropout is superior to the corresponding referred methods. The
advanced dropout improves classification accuracies by 4% in uncertainty
inference and by 0.2% and 0.5% when pruning more than 90% of nodes and 99.8% of
parameters, respectively.
</p>
<a href="http://arxiv.org/abs/2010.05244" target="_blank">arXiv:2010.05244</a> [<a href="http://arxiv.org/pdf/2010.05244" target="_blank">pdf</a>]

<h2>Telerobotic Operation of Intensive Care Unit Ventilators. (arXiv:2010.05247v1 [cs.RO])</h2>
<h3>Balazs P. Vagvolgyi, Mikhail Khrenov, Jonathan Cope, Anton Deguet, Peter Kazanzides, Sajid Manzoor, Russell H. Taylor, Axel Krieger</h3>
<p>Since the first reports of a novel coronavirus (SARS-CoV-2) in December 2019,
over 33 million people have been infected worldwide and approximately 1 million
people worldwide have died from the disease caused by this virus, COVID-19. In
the US alone, there have been approximately 7 million cases and over 200,000
deaths. This outbreak has placed an enormous strain on healthcare systems and
workers. Severe cases require hospital care, and 8.5\% of patients require
mechanical ventilation in an intensive care unit (ICU). One major challenge is
the necessity for clinical care personnel to don and doff cumbersome personal
protective equipment (PPE) in order to enter an ICU unit to make simple
adjustments to ventilator settings. Although future ventilators and other ICU
equipment may be controllable remotely through computer networks, the enormous
installed base of existing ventilators do not have this capability. This paper
reports the development of a simple, low cost telerobotic system that permits
adjustment of ventilator settings from outside the ICU. The system consists of
a small Cartesian robot capable of operating a ventilator touch screen with
camera vision control via a wirelessly connected tablet master device located
outside the room. Engineering system tests demonstrated that the open-loop
mechanical repeatability of the device was 7.5\,mm, and that the average
positioning error of the robotic finger under visual servoing control was
5.94\,mm. Successful usability tests in a simulated ICU environment were
carried out and are reported. In addition to enabling a significant reduction
in PPE consumption, the prototype system has been shown in a preliminary
evaluation to significantly reduce the total time required for a respiratory
therapist to perform typical setting adjustments on a commercial ventilator,
including donning and doffing PPE, from 271 seconds to 109 seconds.
</p>
<a href="http://arxiv.org/abs/2010.05247" target="_blank">arXiv:2010.05247</a> [<a href="http://arxiv.org/pdf/2010.05247" target="_blank">pdf</a>]

<h2>Domain Agnostic Learning for Unbiased Authentication. (arXiv:2010.05250v1 [stat.ML])</h2>
<h3>Jian Liang, Yuren Cao, Shuang Li, Bing Bai, Hao Li, Fei Wang, Kun Bai</h3>
<p>Authentication is the task of confirming the matching relationship between a
data instance and a given identity. Typical examples of authentication problems
include face recognition and person re-identification. Data-driven
authentication could be affected by undesired biases, i.e., the models are
often trained in one domain (e.g., for people wearing spring outfits) while
applied in other domains (e.g., they change the clothes to summer outfits).
Previous works have made efforts to eliminate domain-difference. They typically
assume domain annotations are provided, and all the domains share classes.
However, for authentication, there could be a large number of domains shared by
different identities/classes, and it is impossible to annotate these domains
exhaustively. It could make domain-difference challenging to model and
eliminate. In this paper, we propose a domain-agnostic method that eliminates
domain-difference without domain labels. We alternately perform latent domain
discovery and domain-difference elimination until our model no longer detects
domain-difference. In our approach, the latent domains are discovered by
learning the heterogeneous predictive relationships between inputs and outputs.
Then domain-difference is eliminated in both class-dependent and
class-independent components. Comprehensive empirical evaluation results are
provided to demonstrate the effectiveness and superiority of our proposed
method.
</p>
<a href="http://arxiv.org/abs/2010.05250" target="_blank">arXiv:2010.05250</a> [<a href="http://arxiv.org/pdf/2010.05250" target="_blank">pdf</a>]

<h2>A Comprehensive Survey on Local Differential Privacy Toward Data Statistics and Analysis in Crowdsensing. (arXiv:2010.05253v1 [cs.CR])</h2>
<h3>Teng Wang, Jun Zhao, Xuefeng Zhang, Xinyu Yang</h3>
<p>Collecting and analyzing massive data generated from smart devices have
become increasingly pervasive in crowdsensing, which are the building blocks
for data-driven decision-making. However, extensive statistics and analysis of
such data will seriously threaten the privacy of participating users. Local
differential privacy (LDP) has been proposed as an excellent and prevalent
privacy model with distributed architecture, which can provide strong privacy
guarantees for each user while collecting and analyzing data. LDP ensures that
each user's data is locally perturbed first in the client-side and then sent to
the server-side, thereby protecting data from privacy leaks on both the
client-side and server-side. This survey presents a comprehensive and
systematic overview of LDP with respect to privacy models, research tasks,
enabling mechanisms, and various applications. Specifically, we first provide a
theoretical summarization of LDP, including the LDP model, the variants of LDP,
and the basic framework of LDP algorithms. Then, we investigate and compare the
diverse LDP mechanisms for various data statistics and analysis tasks from the
perspectives of frequency estimation, mean estimation, and machine learning.
What's more, we also summarize practical LDP-based application scenarios.
Finally, we outline several future research directions under LDP.
</p>
<a href="http://arxiv.org/abs/2010.05253" target="_blank">arXiv:2010.05253</a> [<a href="http://arxiv.org/pdf/2010.05253" target="_blank">pdf</a>]

<h2>Few-shot Learning for Multi-label Intent Detection. (arXiv:2010.05256v1 [cs.CL])</h2>
<h3>Yutai Hou, Yongkui Lai, Yushan Wu, Wanxiang Che, Ting Liu</h3>
<p>In this paper, we study the few-shot multi-label classification for user
intent detection. For multi-label intent detection, state-of-the-art work
estimates label-instance relevance scores and uses a threshold to select
multiple associated intent labels. To determine appropriate thresholds with
only a few examples, we first learn universal thresholding experience on
data-rich domains, and then adapt the thresholds to certain few-shot domains
with a calibration based on nonparametric learning. For better calculation of
label-instance relevance score, we introduce label name embedding as anchor
points in representation space, which refines representations of different
classes to be well-separated from each other. Experiments on two datasets show
that the proposed model significantly outperforms strong baselines in both
one-shot and five-shot settings.
</p>
<a href="http://arxiv.org/abs/2010.05256" target="_blank">arXiv:2010.05256</a> [<a href="http://arxiv.org/pdf/2010.05256" target="_blank">pdf</a>]

<h2>Shape-aware Generative Adversarial Networks for Attribute Transfer. (arXiv:2010.05259v1 [cs.CV])</h2>
<h3>Lei Luo, William Hsu, Shangxian Wang</h3>
<p>Generative adversarial networks (GANs) have been successfully applied to
transfer visual attributes in many domains, including that of human face
images. This success is partly attributable to the facts that human faces have
similar shapes and the positions of eyes, noses, and mouths are fixed among
different people. Attribute transfer is more challenging when the source and
target domain share different shapes. In this paper, we introduce a shape-aware
GAN model that is able to preserve shape when transferring attributes, and
propose its application to some real-world domains. Compared to other
state-of-art GANs-based image-to-image translation models, the model we propose
is able to generate more visually appealing results while maintaining the
quality of results from transfer learning.
</p>
<a href="http://arxiv.org/abs/2010.05259" target="_blank">arXiv:2010.05259</a> [<a href="http://arxiv.org/pdf/2010.05259" target="_blank">pdf</a>]

<h2>Fast Convergence of Langevin Dynamics on Manifold: Geodesics meet Log-Sobolev. (arXiv:2010.05263v1 [cs.LG])</h2>
<h3>Xiao Wang, Qi Lei, Ioannis Panageas</h3>
<p>Sampling is a fundamental and arguably very important task with numerous
applications in Machine Learning. One approach to sample from a high
dimensional distribution $e^{-f}$ for some function $f$ is the Langevin
Algorithm (LA). Recently, there has been a lot of progress in showing fast
convergence of LA even in cases where $f$ is non-convex, notably [53], [39] in
which the former paper focuses on functions $f$ defined in $\mathbb{R}^n$ and
the latter paper focuses on functions with symmetries (like matrix completion
type objectives) with manifold structure. Our work generalizes the results of
[53] where $f$ is defined on a manifold $M$ rather than $\mathbb{R}^n$. From
technical point of view, we show that KL decreases in a geometric rate whenever
the distribution $e^{-f}$ satisfies a log-Sobolev inequality on $M$.
</p>
<a href="http://arxiv.org/abs/2010.05263" target="_blank">arXiv:2010.05263</a> [<a href="http://arxiv.org/pdf/2010.05263" target="_blank">pdf</a>]

<h2>Boosting Continuous Sign Language Recognition via Cross Modality Augmentation. (arXiv:2010.05264v1 [cs.CV])</h2>
<h3>Junfu Pu, Wengang Zhou, Hezhen Hu, Houqiang Li</h3>
<p>Continuous sign language recognition (SLR) deals with unaligned video-text
pair and uses the word error rate (WER), i.e., edit distance, as the main
evaluation metric. Since it is not differentiable, we usually instead optimize
the learning model with the connectionist temporal classification (CTC)
objective loss, which maximizes the posterior probability over the sequential
alignment. Due to the optimization gap, the predicted sentence with the highest
decoding probability may not be the best choice under the WER metric. To tackle
this issue, we propose a novel architecture with cross modality augmentation.
Specifically, we first augment cross-modal data by simulating the calculation
procedure of WER, i.e., substitution, deletion and insertion on both text label
and its corresponding video. With these real and generated pseudo video-text
pairs, we propose multiple loss terms to minimize the cross modality distance
between the video and ground truth label, and make the network distinguish the
difference between real and pseudo modalities. The proposed framework can be
easily extended to other existing CTC based continuous SLR architectures.
Extensive experiments on two continuous SLR benchmarks, i.e.,
RWTH-PHOENIX-Weather and CSL, validate the effectiveness of our proposed
method.
</p>
<a href="http://arxiv.org/abs/2010.05264" target="_blank">arXiv:2010.05264</a> [<a href="http://arxiv.org/pdf/2010.05264" target="_blank">pdf</a>]

<h2>Unsupervised Distillation of Syntactic Information from Contextualized Word Representations. (arXiv:2010.05265v1 [cs.CL])</h2>
<h3>Shauli Ravfogel, Yanai Elazar, Jacob Goldberger, Yoav Goldberg</h3>
<p>Contextualized word representations, such as ELMo and BERT, were shown to
perform well on various semantic and syntactic tasks. In this work, we tackle
the task of unsupervised disentanglement between semantics and structure in
neural language representations: we aim to learn a transformation of the
contextualized vectors, that discards the lexical semantics, but keeps the
structural information. To this end, we automatically generate groups of
sentences which are structurally similar but semantically different, and use
metric-learning approach to learn a transformation that emphasizes the
structural component that is encoded in the vectors. We demonstrate that our
transformation clusters vectors in space by structural properties, rather than
by lexical semantics. Finally, we demonstrate the utility of our distilled
representations by showing that they outperform the original contextualized
representations in a few-shot parsing setting.
</p>
<a href="http://arxiv.org/abs/2010.05265" target="_blank">arXiv:2010.05265</a> [<a href="http://arxiv.org/pdf/2010.05265" target="_blank">pdf</a>]

<h2>A Case-Study on the Impact of Dynamic Time Warping in Time Series Regression. (arXiv:2010.05270v1 [cs.LG])</h2>
<h3>Vivek Mahato, P&#xe1;draig Cunningham</h3>
<p>It is well understood that Dynamic Time Warping (DTW) is effective in
revealing similarities between time series that do not align perfectly. In this
paper, we illustrate this on spectroscopy time-series data. We show that DTW is
effective in improving accuracy on a regression task when only a single
wavelength is considered. When combined with k-Nearest Neighbour, DTW has the
added advantage that it can reveal similarities and differences between samples
at the level of the time-series. However, in the problem, we consider here data
is available across a spectrum of wavelengths. If aggregate statistics (means,
variances) are used across many wavelengths the benefits of DTW are no longer
apparent. We present this as another example of a situation where big data
trumps sophisticated models in Machine Learning.
</p>
<a href="http://arxiv.org/abs/2010.05270" target="_blank">arXiv:2010.05270</a> [<a href="http://arxiv.org/pdf/2010.05270" target="_blank">pdf</a>]

<h2>IF-Defense: 3D Adversarial Point Cloud Defense via Implicit Function based Restoration. (arXiv:2010.05272v1 [cs.CV])</h2>
<h3>Ziyi Wu, Yueqi Duan, He Wang, Qingnan Fan, Leonidas J. Guibas</h3>
<p>Point cloud is an important 3D data representation widely used in many
essential applications. Leveraging deep neural networks, recent works have
shown great success in processing 3D point clouds. However, those deep neural
networks are vulnerable to various 3D adversarial attacks, which can be
summarized as two primary types: point perturbation that affects local point
distribution, and surface distortion that causes dramatic changes in geometry.
In this paper, we propose a novel 3D adversarial point cloud defense method
leveraging implicit function based restoration (IF-Defense) to address both the
aforementioned attacks. It is composed of two steps: 1) it predicts an implicit
function that captures the clean shape through a surface recovery module, and
2) restores a clean and complete point cloud via minimizing the difference
between the attacked point cloud and the predicted implicit function under
geometry- and distribution- aware constraints. Our experimental results show
that IF-Defense achieves the state-of-the-art defense performance against all
existing adversarial attacks on PointNet, PointNet++, DGCNN and PointConv.
Comparing with previous methods, IF-Defense presents 20.02% improvement in
classification accuracy against salient point dropping attack and 16.29%
against LG-GAN attack on PointNet.
</p>
<a href="http://arxiv.org/abs/2010.05272" target="_blank">arXiv:2010.05272</a> [<a href="http://arxiv.org/pdf/2010.05272" target="_blank">pdf</a>]

<h2>Federated Learning via Posterior Averaging: A New Perspective and Practical Algorithms. (arXiv:2010.05273v1 [cs.LG])</h2>
<h3>Maruan Al-Shedivat, Jennifer Gillenwater, Eric Xing, Afshin Rostamizadeh</h3>
<p>Federated learning is typically approached as an optimization problem, where
the goal is to minimize a global loss function by distributing computation
across client devices that possess local data and specify different parts of
the global objective. We present an alternative perspective and formulate
federated learning as a posterior inference problem, where the goal is to infer
a global posterior distribution by having client devices each infer the
posterior of their local data. While exact inference is often intractable, this
perspective provides a principled way to search for global optima in federated
settings. Further, starting with the analysis of federated quadratic
objectives, we develop a computation- and communication-efficient approximate
posterior inference algorithm -- federated posterior averaging (FedPA). Our
algorithm uses MCMC for approximate inference of local posteriors on the
clients and efficiently communicates their statistics to the server, where the
latter uses them to refine a global estimate of the posterior mode. Finally, we
show that FedPA generalizes federated averaging (FedAvg), can similarly benefit
from adaptive optimizers, and yields state-of-the-art results on four realistic
and challenging benchmarks, converging faster, to better optima.
</p>
<a href="http://arxiv.org/abs/2010.05273" target="_blank">arXiv:2010.05273</a> [<a href="http://arxiv.org/pdf/2010.05273" target="_blank">pdf</a>]

<h2>Distributed Resource Allocation with Multi-Agent Deep Reinforcement Learning for 5G-V2V Communication. (arXiv:2010.05290v1 [cs.NI])</h2>
<h3>Alperen G&#xfc;ndogan, H. Murat G&#xfc;rsu, Volker Pauli, Wolfgang Kellerer</h3>
<p>We consider the distributed resource selection problem in Vehicle-to-vehicle
(V2V) communication in the absence of a base station. Each vehicle autonomously
selects transmission resources from a pool of shared resources to disseminate
Cooperative Awareness Messages (CAMs). This is a consensus problem where each
vehicle has to select a unique resource. The problem becomes more challenging
when---due to mobility---the number of vehicles in vicinity of each other is
changing dynamically. In a congested scenario, allocation of unique resources
for each vehicle becomes infeasible and a congested resource allocation
strategy has to be developed. The standardized approach in 5G, namely
semi-persistent scheduling (SPS) suffers from effects caused by spatial
distribution of the vehicles. In our approach, we turn this into an advantage.
We propose a novel DIstributed Resource Allocation mechanism using multi-agent
reinforcement Learning (DIRAL) which builds on a unique state representation.
One challenging issue is to cope with the non-stationarity introduced by
concurrently learning agents which causes convergence problems in multi-agent
learning systems. We aimed to tackle non-stationarity with unique state
representation. Specifically, we deploy view-based positional distribution as a
state representation to tackle non-stationarity and perform complex joint
behavior in a distributed fashion. Our results showed that DIRAL improves PRR
by 20% compared to SPS in challenging congested scenarios.
</p>
<a href="http://arxiv.org/abs/2010.05290" target="_blank">arXiv:2010.05290</a> [<a href="http://arxiv.org/pdf/2010.05290" target="_blank">pdf</a>]

<h2>Combining Learned and Analytical Models for Predicting Action Effects from Sensory Data. (arXiv:1710.04102v4 [cs.RO] UPDATED)</h2>
<h3>Alina Kloss, Stefan Schaal, Jeannette Bohg</h3>
<p>One of the most basic skills a robot should possess is predicting the effect
of physical interactions with objects in the environment. This enables optimal
action selection to reach a certain goal state. Traditionally, dynamics are
approximated by physics-based analytical models. These models rely on specific
state representations that may be hard to obtain from raw sensory data,
especially if no knowledge of the object shape is assumed. More recently, we
have seen learning approaches that can predict the effect of complex physical
interactions directly from sensory input. It is however an open question how
far these models generalize beyond their training data. In this work, we
investigate the advantages and limitations of neural network based learning
approaches for predicting the effects of actions based on sensory input and
show how analytical and learned models can be combined to leverage the best of
both worlds. As physical interaction task, we use planar pushing, for which
there exists a well-known analytical model and a large real-world dataset. We
propose to use a convolutional neural network to convert raw depth images or
organized point clouds into a suitable representation for the analytical model
and compare this approach to using neural networks for both, perception and
prediction. A systematic evaluation of the proposed approach on a very large
real-world dataset shows two main advantages of the hybrid architecture.
Compared to a pure neural network, it significantly (i) reduces required
training data and (ii) improves generalization to novel physical interaction.
</p>
<a href="http://arxiv.org/abs/1710.04102" target="_blank">arXiv:1710.04102</a> [<a href="http://arxiv.org/pdf/1710.04102" target="_blank">pdf</a>]

<h2>Graph Pattern Mining and Learning through User-defined Relations (Extended Version). (arXiv:1809.05241v2 [cs.LG] UPDATED)</h2>
<h3>Carlos H. C. Teixeira, Leonardo Cotta, Bruno Ribeiro, Wagner Meira Jr</h3>
<p>In this work we propose R-GPM, a parallel computing framework for graph
pattern mining (GPM) through a user-defined subgraph relation. More
specifically, we enable the computation of statistics of patterns through their
subgraph classes, generalizing traditional GPM methods. R-GPM provides
efficient estimators for these statistics by employing a MCMC sampling
algorithm combined with several optimizations. We provide both theoretical
guarantees and empirical evaluations of our estimators in application scenarios
such as stochastic optimization of deep high-order graph neural network models
and pattern (motif) counting. We also propose and evaluate optimizations that
enable improvements of our estimators accuracy, while reducing their
computational costs in up to 3-orders-of-magnitude. Finally,we show that R-GPM
is scalable, providing near-linear speedups on 44 cores in all of our tests.
</p>
<a href="http://arxiv.org/abs/1809.05241" target="_blank">arXiv:1809.05241</a> [<a href="http://arxiv.org/pdf/1809.05241" target="_blank">pdf</a>]

<h2>Towards Linear Time Neural Machine Translation with Capsule Networks. (arXiv:1811.00287v4 [cs.CL] UPDATED)</h2>
<h3>Mingxuan Wang, Jun Xie, Zhixing Tan, Jinsong Su, Deyi Xiong, Lei Li</h3>
<p>In this study, we first investigate a novel capsule network with dynamic
routing for linear time Neural Machine Translation (NMT), referred as
\textsc{CapsNMT}. \textsc{CapsNMT} uses an aggregation mechanism to map the
source sentence into a matrix with pre-determined size, and then applys a deep
LSTM network to decode the target sequence from the source representation.
Unlike the previous work \cite{sutskever2014sequence} to store the source
sentence with a passive and bottom-up way, the dynamic routing policy encodes
the source sentence with an iterative process to decide the credit attribution
between nodes from lower and higher layers. \textsc{CapsNMT} has two core
properties: it runs in time that is linear in the length of the sequences and
provides a more flexible way to select, represent and aggregates the part-whole
information of the source sentence. On WMT14 English-German task and a larger
WMT14 English-French task, \textsc{CapsNMT} achieves comparable results with
the state-of-the-art NMT systems. To the best of our knowledge, this is the
first work that capsule networks have been empirically investigated for
sequence to sequence problems.
</p>
<a href="http://arxiv.org/abs/1811.00287" target="_blank">arXiv:1811.00287</a> [<a href="http://arxiv.org/pdf/1811.00287" target="_blank">pdf</a>]

<h2>Hypergraph Convolution and Hypergraph Attention. (arXiv:1901.08150v2 [cs.LG] UPDATED)</h2>
<h3>Song Bai, Feihu Zhang, Philip H.S. Torr</h3>
<p>Recently, graph neural networks have attracted great attention and achieved
prominent performance in various research fields. Most of those algorithms have
assumed pairwise relationships of objects of interest. However, in many real
applications, the relationships between objects are in higher-order, beyond a
pairwise formulation. To efficiently learn deep embeddings on the high-order
graph-structured data, we introduce two end-to-end trainable operators to the
family of graph neural networks, i.e., hypergraph convolution and hypergraph
attention. Whilst hypergraph convolution defines the basic formulation of
performing convolution on a hypergraph, hypergraph attention further enhances
the capacity of representation learning by leveraging an attention module. With
the two operators, a graph neural network is readily extended to a more
flexible model and applied to diverse applications where non-pairwise
relationships are observed. Extensive experimental results with semi-supervised
node classification demonstrate the effectiveness of hypergraph convolution and
hypergraph attention.
</p>
<a href="http://arxiv.org/abs/1901.08150" target="_blank">arXiv:1901.08150</a> [<a href="http://arxiv.org/pdf/1901.08150" target="_blank">pdf</a>]

<h2>Learning Dynamic-Objective Policies from a Class of Optimal Trajectories. (arXiv:1902.10139v3 [cs.SY] UPDATED)</h2>
<h3>Christopher Iliffe Sprague, Dario Izzo, Petter &#xd6;gren</h3>
<p>Optimal state-feedback controllers, capable of changing between different
objective functions, are advantageous to systems in which unexpected situations
may arise. However, synthesising such controllers, even for a single objective,
is a demanding process. In this paper, we present a novel and straightforward
approach to synthesising these policies through a combination of trajectory
optimisation, homotopy continuation, and imitation learning. We use numerical
continuation to efficiently generate optimal demonstrations across several
objectives and boundary conditions, and use these to train our policies.
Additionally, we demonstrate the ability of our policies to effectively learn
families of optimal state-feedback controllers, which can be used to change
objective functions online. We illustrate this approach across two trajectory
optimisation problems, an inverted pendulum swingup and a spacecraft orbit
transfer, and show that the synthesised policies, when evaluated in simulation,
produce trajectories that are near-optimal. These results indicate the benefit
of trajectory optimisation and homotopy continuation to the synthesis of
controllers in dynamic-objective contexts.
</p>
<a href="http://arxiv.org/abs/1902.10139" target="_blank">arXiv:1902.10139</a> [<a href="http://arxiv.org/pdf/1902.10139" target="_blank">pdf</a>]

<h2>Two models of double descent for weak features. (arXiv:1903.07571v2 [cs.LG] UPDATED)</h2>
<h3>Mikhail Belkin, Daniel Hsu, Ji Xu</h3>
<p>The "double descent" risk curve was proposed to qualitatively describe the
out-of-sample prediction accuracy of variably-parameterized machine learning
models. This article provides a precise mathematical analysis for the shape of
this curve in two simple data models with the least squares/least norm
predictor. Specifically, it is shown that the risk peaks when the number of
features $p$ is close to the sample size $n$, but also that the risk decreases
towards its minimum as $p$ increases beyond $n$. This behavior is contrasted
with that of "prescient" models that select features in an a priori optimal
order.
</p>
<a href="http://arxiv.org/abs/1903.07571" target="_blank">arXiv:1903.07571</a> [<a href="http://arxiv.org/pdf/1903.07571" target="_blank">pdf</a>]

<h2>Optimal Obfuscation Mechanisms via Machine Learning. (arXiv:1904.01059v4 [cs.LG] UPDATED)</h2>
<h3>Marco Romanelli, Konstantinos Chatzikokolakis, Catuscia Palamidessi</h3>
<p>We consider the problem of obfuscating sensitive information while preserving
utility, and we propose a machine learning approach inspired by the generative
adversarial networks paradigm. The idea is to set up two nets: the generator,
that tries to produce an optimal obfuscation mechanism to protect the data, and
the classifier, that tries to de-obfuscate the data. By letting the two nets
compete against each other, the mechanism improves its degree of protection,
until an equilibrium is reached. We apply our method to the case of location
privacy, and we perform experiments on synthetic data and on real data from the
Gowalla dataset. We evaluate the privacy of the mechanism not only by its
capacity to defeat the classifier, but also in terms of the Bayes error, which
represents the strongest possible adversary. We compare the privacy-utility
tradeoff of our method to that of the planar Laplace mechanism used in
geo-indistinguishability, showing favorable results. Like the Laplace
mechanism, our system can be deployed at the user end for protecting his
location.
</p>
<a href="http://arxiv.org/abs/1904.01059" target="_blank">arXiv:1904.01059</a> [<a href="http://arxiv.org/pdf/1904.01059" target="_blank">pdf</a>]

<h2>Facial Pose Estimation by Deep Learning from Label Distributions. (arXiv:1904.13102v4 [cs.CV] UPDATED)</h2>
<h3>Zhaoxiang Liu, Zezhou Chen, Jinqiang Bai, Shaohua Li, Shiguo Lian</h3>
<p>Facial pose estimation has gained a lot of attentions in many practical
applications, such as human-robot interaction, gaze estimation and driver
monitoring. Meanwhile, end-to-end deep learning-based facial pose estimation is
becoming more and more popular. However, facial pose estimation suffers from a
key challenge: the lack of sufficient training data for many poses, especially
for large poses. Inspired by the observation that the faces under close poses
look similar, we reformulate the facial pose estimation as a label distribution
learning problem, considering each face image as an example associated with a
Gaussian label distribution rather than a single label, and construct a
convolutional neural network which is trained with a multi-loss function on
AFLW dataset and 300W-LP dataset to predict the facial poses directly from
color image. Extensive experiments are conducted on several popular benchmarks,
including AFLW2000, BIWI, AFLW and AFW, where our approach shows a significant
advantage over other state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/1904.13102" target="_blank">arXiv:1904.13102</a> [<a href="http://arxiv.org/pdf/1904.13102" target="_blank">pdf</a>]

<h2>Deep Learning for Sequential Recommendation: Algorithms, Influential Factors, and Evaluations. (arXiv:1905.01997v3 [cs.IR] UPDATED)</h2>
<h3>Hui Fang, Danning Zhang, Yiheng Shu, Guibing Guo</h3>
<p>In the field of sequential recommendation, deep learning (DL)-based methods
have received a lot of attention in the past few years and surpassed
traditional models such as Markov chain-based and factorization-based ones.
However, there is little systematic study on DL-based methods, especially
regarding to how to design an effective DL model for sequential recommendation.
In this view, this survey focuses on DL-based sequential recommender systems by
taking the aforementioned issues into consideration. Specifically,we illustrate
the concept of sequential recommendation, propose a categorization of existing
algorithms in terms of three types of behavioral sequence, summarize the key
factors affecting the performance of DL-based models, and conduct corresponding
evaluations to demonstrate the effects of these factors. We conclude this
survey by systematically outlining future directions and challenges in this
field.
</p>
<a href="http://arxiv.org/abs/1905.01997" target="_blank">arXiv:1905.01997</a> [<a href="http://arxiv.org/pdf/1905.01997" target="_blank">pdf</a>]

<h2>PerceptNet: Learning Perceptual Similarity of Haptic Textures in Presence of Unorderable Triplets. (arXiv:1905.03302v2 [cs.LG] UPDATED)</h2>
<h3>Priyadarshini Kumari, Siddhartha Chaudhuri, Subhasis Chaudhuri</h3>
<p>In order to design haptic icons or build a haptic vocabulary, we require a
set of easily distinguishable haptic signals to avoid perceptual ambiguity,
which in turn requires a way to accurately estimate the perceptual
(dis)similarity of such signals. In this work, we present a novel method to
learn such a perceptual metric based on data from human studies. Our method is
based on a deep neural network that projects signals to an embedding space
where the natural Euclidean distance accurately models the degree of
dissimilarity between two signals. The network is trained only on non-numerical
comparisons of triplets of signals, using a novel triplet loss that considers
both types of triplets that are easy to order (inequality constraints), as well
as those that are unorderable/ambiguous (equality constraints). Unlike prior
MDS-based non-parametric approaches, our method can be trained on a partial set
of comparisons and can embed new haptic signals without retraining the model
from scratch. Extensive experimental evaluations show that our method is
significantly more effective at modeling perceptual dissimilarity than
alternatives.
</p>
<a href="http://arxiv.org/abs/1905.03302" target="_blank">arXiv:1905.03302</a> [<a href="http://arxiv.org/pdf/1905.03302" target="_blank">pdf</a>]

<h2>Proportionally Fair Clustering. (arXiv:1905.03674v3 [cs.LG] UPDATED)</h2>
<h3>Xingyu Chen, Brandon Fain, Liang Lyu, Kamesh Munagala</h3>
<p>We extend the fair machine learning literature by considering the problem of
proportional centroid clustering in a metric context. For clustering $n$ points
with $k$ centers, we define fairness as proportionality to mean that any $n/k$
points are entitled to form their own cluster if there is another center that
is closer in distance for all $n/k$ points. We seek clustering solutions to
which there are no such justified complaints from any subsets of agents,
without assuming any a priori notion of protected subsets. We present and
analyze algorithms to efficiently compute, optimize, and audit proportional
solutions. We conclude with an empirical examination of the tradeoff between
proportional solutions and the $k$-means objective.
</p>
<a href="http://arxiv.org/abs/1905.03674" target="_blank">arXiv:1905.03674</a> [<a href="http://arxiv.org/pdf/1905.03674" target="_blank">pdf</a>]

<h2>ODE Analysis of Stochastic Gradient Methods with Optimism and Anchoring for Minimax Problems. (arXiv:1905.10899v3 [cs.LG] UPDATED)</h2>
<h3>Ernest K. Ryu, Kun Yuan, Wotao Yin</h3>
<p>Despite remarkable empirical success, the training dynamics of generative
adversarial networks (GAN), which involves solving a minimax game using
stochastic gradients, is still poorly understood. In this work, we analyze
last-iterate convergence of simultaneous gradient descent (simGD) and its
variants under the assumption of convex-concavity, guided by a continuous-time
analysis with differential equations. First, we show that simGD, as is,
converges with stochastic sub-gradients under strict convexity in the primal
variable. Second, we generalize optimistic simGD to accommodate an optimism
rate separate from the learning rate and show its convergence with full
gradients. Finally, we present anchored simGD, a new method, and show
convergence with stochastic subgradients.
</p>
<a href="http://arxiv.org/abs/1905.10899" target="_blank">arXiv:1905.10899</a> [<a href="http://arxiv.org/pdf/1905.10899" target="_blank">pdf</a>]

<h2>Generative Modeling by Estimating Gradients of the Data Distribution. (arXiv:1907.05600v3 [cs.LG] UPDATED)</h2>
<h3>Yang Song, Stefano Ermon</h3>
<p>We introduce a new generative model where samples are produced via Langevin
dynamics using gradients of the data distribution estimated with score
matching. Because gradients can be ill-defined and hard to estimate when the
data resides on low-dimensional manifolds, we perturb the data with different
levels of Gaussian noise, and jointly estimate the corresponding scores, i.e.,
the vector fields of gradients of the perturbed data distribution for all noise
levels. For sampling, we propose an annealed Langevin dynamics where we use
gradients corresponding to gradually decreasing noise levels as the sampling
process gets closer to the data manifold. Our framework allows flexible model
architectures, requires no sampling during training or the use of adversarial
methods, and provides a learning objective that can be used for principled
model comparisons. Our models produce samples comparable to GANs on MNIST,
CelebA and CIFAR-10 datasets, achieving a new state-of-the-art inception score
of 8.87 on CIFAR-10. Additionally, we demonstrate that our models learn
effective representations via image inpainting experiments.
</p>
<a href="http://arxiv.org/abs/1907.05600" target="_blank">arXiv:1907.05600</a> [<a href="http://arxiv.org/pdf/1907.05600" target="_blank">pdf</a>]

<h2>Warp and Learn: Novel Views Generation for Vehicles and Other Objects. (arXiv:1907.10634v3 [cs.CV] UPDATED)</h2>
<h3>Andrea Palazzi, Luca Bergamini, Simone Calderara, Rita Cucchiara</h3>
<p>In this work we introduce a new self-supervised, semi-parametric approach for
synthesizing novel views of a vehicle starting from a single monocular image.
Differently from parametric (i.e. entirely learning-based) methods, we show how
a-priori geometric knowledge about the object and the 3D world can be
successfully integrated into a deep learning based image generation framework.
As this geometric component is not learnt, we call our approach
semi-parametric. In particular, we exploit man-made object symmetry and
piece-wise planarity to integrate rich a-priori visual information into the
novel viewpoint synthesis process. An Image Completion Network (ICN) is then
trained to generate a realistic image starting from this geometric guidance.
This careful blend between parametric and non-parametric components allows us
to i) operate in a real-world scenario, ii) preserve high-frequency visual
information such as textures, iii) handle truly arbitrary 3D roto-translations
of the input and iv) perform shape transfer to completely different 3D models.
Eventually, we show that our approach can be easily complemented with synthetic
data and extended to other rigid objects with completely different topology,
even in presence of concave structures and holes (e.g. chairs). A comprehensive
experimental analysis against state-of-the-art competitors shows the efficacy
of our method both from a quantitative and a perceptive point of view.
Supplementary material, animated results, code and data are available at:
https://github.com/ndrplz/semiparametric
</p>
<a href="http://arxiv.org/abs/1907.10634" target="_blank">arXiv:1907.10634</a> [<a href="http://arxiv.org/pdf/1907.10634" target="_blank">pdf</a>]

<h2>Robust Online Multi-target Visual Tracking using a HISP Filter with Discriminative Deep Appearance Learning. (arXiv:1908.03945v6 [cs.CV] UPDATED)</h2>
<h3>Nathanael L. Baisa</h3>
<p>We propose a novel online multi-target visual tracker based on the recently
developed Hypothesized and Independent Stochastic Population (HISP) filter. The
HISP filter combines advantages of traditional tracking approaches like MHT and
point-process-based approaches like PHD filter, and it has linear complexity
while maintaining track identities. We apply this filter for tracking multiple
targets in video sequences acquired under varying environmental conditions and
targets density using a tracking-by-detection approach. We also adopt deep CNN
appearance representation by training a verification-identification network
(VerIdNet) on large-scale person re-identification data sets. We construct an
augmented likelihood in a principled manner using this deep CNN appearance
features and spatio-temporal information. Furthermore, we solve the problem of
two or more targets having identical label considering the weight propagated
with each confirmed hypothesis. Extensive experiments on MOT16 and MOT17
benchmark data sets show that our tracker significantly outperforms several
state-of-the-art trackers in terms of tracking accuracy.
</p>
<a href="http://arxiv.org/abs/1908.03945" target="_blank">arXiv:1908.03945</a> [<a href="http://arxiv.org/pdf/1908.03945" target="_blank">pdf</a>]

<h2>Effective Training of Convolutional Neural Networks with Low-bitwidth Weights and Activations. (arXiv:1908.04680v2 [cs.CV] UPDATED)</h2>
<h3>Bohan Zhuang, Jing Liu, Mingkui Tan, Lingqiao Liu, Ian Reid, Chunhua Shen</h3>
<p>This paper tackles the problem of training a deep convolutional neural
network of both low-bitwidth weights and activations. Optimizing a
low-precision network is very challenging due to the non-differentiability of
the quantizer, which may result in substantial accuracy loss. To address this,
we propose three practical approaches, including (i) progressive quantization;
(ii) stochastic precision; and (iii) joint knowledge distillation to improve
the network training. First, for progressive quantization, we propose two
schemes to progressively find good local minima. Specifically, we propose to
first optimize a net with quantized weights and subsequently quantize
activations. This is in contrast to the traditional methods which optimize them
simultaneously. Furthermore, we propose a second progressive quantization
scheme which gradually decreases the bit-width from high-precision to
low-precision during training. Second, to alleviate the excessive training
burden due to the multi-round training stages, we further propose a one-stage
stochastic precision strategy to randomly sample and quantize sub-networks
while keeping other parts in full-precision. Finally, we adopt a novel learning
scheme to jointly train a full-precision model alongside the low-precision one.
By doing so, the full-precision model provides hints to guide the low-precision
model training and significantly improves the performance of the low-precision
network. Extensive experiments on various datasets (e.g., CIFAR-100, ImageNet)
show the effectiveness of the proposed methods.
</p>
<a href="http://arxiv.org/abs/1908.04680" target="_blank">arXiv:1908.04680</a> [<a href="http://arxiv.org/pdf/1908.04680" target="_blank">pdf</a>]

<h2>Edge-Computing-Enabled Smart Cities: A Comprehensive Survey. (arXiv:1909.08747v2 [cs.NI] UPDATED)</h2>
<h3>Latif U. Khan, Ibrar Yaqoob, Nguyen H. Tran, S. M. Ahsan Kazmi, Tri Nguyen Dang, Choong Seon Hong</h3>
<p>Recent years have disclosed a remarkable proliferation of compute-intensive
applications in smart cities. Such applications continuously generate enormous
amounts of data which demand strict latency-aware computational processing
capabilities. Although edge computing is an appealing technology to compensate
for stringent latency related issues, its deployment engenders new challenges.
In this survey, we highlight the role of edge computing in realizing the vision
of smart cities. First, we analyze the evolution of edge computing paradigms.
Subsequently, we critically review the state-of-the-art literature focusing on
edge computing applications in smart cities. Later, we categorize and classify
the literature by devising a comprehensive and meticulous taxonomy.
Furthermore, we identify and discuss key requirements, and enumerate recently
reported synergies of edge computing enabled smart cities. Finally, several
indispensable open challenges along with their causes and guidelines are
discussed, serving as future research directions.
</p>
<a href="http://arxiv.org/abs/1909.08747" target="_blank">arXiv:1909.08747</a> [<a href="http://arxiv.org/pdf/1909.08747" target="_blank">pdf</a>]

<h2>Recurrent Independent Mechanisms. (arXiv:1909.10893v4 [cs.LG] UPDATED)</h2>
<h3>Anirudh Goyal, Alex Lamb, Jordan Hoffmann, Shagun Sodhani, Sergey Levine, Yoshua Bengio, Bernhard Sch&#xf6;lkopf</h3>
<p>Learning modular structures which reflect the dynamics of the environment can
lead to better generalization and robustness to changes which only affect a few
of the underlying causes. We propose Recurrent Independent Mechanisms (RIMs), a
new recurrent architecture in which multiple groups of recurrent cells operate
with nearly independent transition dynamics, communicate only sparingly through
the bottleneck of attention, and are only updated at time steps where they are
most relevant. We show that this leads to specialization amongst the RIMs,
which in turn allows for dramatically improved generalization on tasks where
some factors of variation differ systematically between training and
evaluation.
</p>
<a href="http://arxiv.org/abs/1909.10893" target="_blank">arXiv:1909.10893</a> [<a href="http://arxiv.org/pdf/1909.10893" target="_blank">pdf</a>]

<h2>Formal Language Constraints for Markov Decision Processes. (arXiv:1910.01074v2 [cs.LG] UPDATED)</h2>
<h3>Eleanor Quint, Dong Xu, Samuel Flint, Stephen Scott, Matthew Dwyer</h3>
<p>In order to satisfy safety conditions, an agent may be constrained from
acting freely. A safe controller can be designed a priori if an environment is
well understood, but not when learning is employed. In particular,
reinforcement learned (RL) controllers require exploration, which can be
hazardous in safety critical situations. We study the benefits of giving
structure to the constraints of a constrained Markov decision process by
specifying them in formal languages as a step towards using safety methods from
software engineering and controller synthesis. We instantiate these constraints
as finite automata to efficiently recognise constraint violations. Constraint
states are then used to augment the underlying MDP state and to learn a dense
cost function, easing the problem of quickly learning joint MDP/constraint
dynamics. We empirically evaluate the effect of these methods on training a
variety of RL algorithms over several constraints specified in Safety Gym,
MuJoCo, and Atari environments.
</p>
<a href="http://arxiv.org/abs/1910.01074" target="_blank">arXiv:1910.01074</a> [<a href="http://arxiv.org/pdf/1910.01074" target="_blank">pdf</a>]

<h2>Thieves on Sesame Street! Model Extraction of BERT-based APIs. (arXiv:1910.12366v3 [cs.CL] UPDATED)</h2>
<h3>Kalpesh Krishna, Gaurav Singh Tomar, Ankur P. Parikh, Nicolas Papernot, Mohit Iyyer</h3>
<p>We study the problem of model extraction in natural language processing, in
which an adversary with only query access to a victim model attempts to
reconstruct a local copy of that model. Assuming that both the adversary and
victim model fine-tune a large pretrained language model such as BERT (Devlin
et al. 2019), we show that the adversary does not need any real training data
to successfully mount the attack. In fact, the attacker need not even use
grammatical or semantically meaningful queries: we show that random sequences
of words coupled with task-specific heuristics form effective queries for model
extraction on a diverse set of NLP tasks, including natural language inference
and question answering. Our work thus highlights an exploit only made feasible
by the shift towards transfer learning methods within the NLP community: for a
query budget of a few hundred dollars, an attacker can extract a model that
performs only slightly worse than the victim model. Finally, we study two
defense strategies against model extraction---membership classification and API
watermarking---which while successful against naive adversaries, are
ineffective against more sophisticated ones.
</p>
<a href="http://arxiv.org/abs/1910.12366" target="_blank">arXiv:1910.12366</a> [<a href="http://arxiv.org/pdf/1910.12366" target="_blank">pdf</a>]

<h2>Interactive Gibson Benchmark: A Benchmark for Interactive Navigation in Cluttered Environments. (arXiv:1910.14442v2 [cs.RO] UPDATED)</h2>
<h3>Fei Xia, William B. Shen, Chengshu Li, Priya Kasimbeg, Micael Tchapmi, Alexander Toshev, Li Fei-Fei, Roberto Mart&#xed;n-Mart&#xed;n, Silvio Savarese</h3>
<p>We present Interactive Gibson Benchmark, the first comprehensive benchmark
for training and evaluating Interactive Navigation: robot navigation strategies
where physical interaction with objects is allowed and even encouraged to
accomplish a task. For example, the robot can move objects if needed in order
to clear a path leading to the goal location. Our benchmark comprises two novel
elements: 1) a new experimental setup, the Interactive Gibson Environment,
which simulates high fidelity visuals of indoor scenes, and high fidelity
physical dynamics of the robot and common objects found in these scenes; 2) a
set of Interactive Navigation metrics which allows one to study the interplay
between navigation and physical interaction. We present and evaluate multiple
learning-based baselines in Interactive Gibson, and provide insights into
regimes of navigation with different trade-offs between navigation path
efficiency and disturbance of surrounding objects. We make our benchmark
publicly available(https://sites.google.com/view/interactivegibsonenv) and
encourage researchers from all disciplines in robotics (e.g. planning,
learning, control) to propose, evaluate, and compare their Interactive
Navigation solutions in Interactive Gibson.
</p>
<a href="http://arxiv.org/abs/1910.14442" target="_blank">arXiv:1910.14442</a> [<a href="http://arxiv.org/pdf/1910.14442" target="_blank">pdf</a>]

<h2>Improving Joint Training of Inference Networks and Structured Prediction Energy Networks. (arXiv:1911.02891v2 [cs.CL] UPDATED)</h2>
<h3>Lifu Tu, Richard Yuanzhe Pang, Kevin Gimpel</h3>
<p>Deep energy-based models are powerful, but pose challenges for learning and
inference (Belanger and McCallum, 2016). Tu and Gimpel (2018) developed an
efficient framework for energy-based models by training "inference networks" to
approximate structured inference instead of using gradient descent. However,
their alternating optimization approach suffers from instabilities during
training, requiring additional loss terms and careful hyperparameter tuning. In
this paper, we contribute several strategies to stabilize and improve this
joint training of energy functions and inference networks for structured
prediction. We design a compound objective to jointly train both cost-augmented
and test-time inference networks along with the energy function. We propose
joint parameterizations for the inference networks that encourage them to
capture complementary functionality during learning. We empirically validate
our strategies on two sequence labeling tasks, showing easier paths to strong
performance than prior work, as well as further improvements with global energy
terms.
</p>
<a href="http://arxiv.org/abs/1911.02891" target="_blank">arXiv:1911.02891</a> [<a href="http://arxiv.org/pdf/1911.02891" target="_blank">pdf</a>]

<h2>ADCC: An Effective and Intelligent Attention Dense Color Constancy System for Studying Images in Smart Cities. (arXiv:1911.07163v2 [cs.CV] UPDATED)</h2>
<h3>Yilang Zhang, Neal N. Xiong, Zheng Wei, Xin Yuan, Jian Wang</h3>
<p>As a novel method eliminating chromatic aberration on objects, computational
color constancy has becoming a fundamental prerequisite for many computer
vision applications. Among algorithms performing this task, the learning-based
ones have achieved great success in recent years. However, they fail to fully
consider the spatial information of images, leaving plenty of room for
improvement of the accuracy of illuminant estimation. In this paper, by
exploiting the spatial information of images, we propose a color constancy
algorithm called Attention Dense Color Constancy (ADCC) using convolutional
neural network (CNN). Specifically, based on the 2D log-chrominance histograms
of the input images as well as their specially augmented ones, ADCC estimates
the illuminant with a self-attention DenseNet. The augmented images help to
tell apart the edge gradients, edge pixels and non-edge ones in log-histogram,
which contribute significantly to the feature extraction and color-ambiguity
elimination, thereby advancing the accuracy of illuminant estimation.
Simulations and experiments on benchmark datasets demonstrate that the proposed
algorithm is effective for illuminant estimation compared to the
state-of-the-art methods. Thus, ADCC offers great potential in promoting
applications of smart cities, such as smart camera, where color is an important
factor for distinguishing objects.
</p>
<a href="http://arxiv.org/abs/1911.07163" target="_blank">arXiv:1911.07163</a> [<a href="http://arxiv.org/pdf/1911.07163" target="_blank">pdf</a>]

<h2>Utility Analysis of Network Architectures for 3D Point Cloud Processing. (arXiv:1911.09053v2 [cs.CV] UPDATED)</h2>
<h3>Wen Shen, Zhihua Wei, Shikun Huang, Binbin Zhang, Quanshi Zhang</h3>
<p>In this paper, we diagnose deep neural networks for 3D point cloud processing
to explore utilities of different network architectures. We propose a number of
hypotheses on the effects of specific network architectures on the
representation capacity of DNNs. In order to prove the hypotheses, we design
five metrics to diagnose various types of DNNs from the following perspectives,
information discarding, information concentration, rotation robustness,
adversarial robustness, and neighborhood inconsistency. We conduct comparative
studies based on such metrics to verify the hypotheses. We further use the
verified hypotheses to revise architectures of existing DNNs to improve their
utilities. Experiments demonstrate the effectiveness of our method.
</p>
<a href="http://arxiv.org/abs/1911.09053" target="_blank">arXiv:1911.09053</a> [<a href="http://arxiv.org/pdf/1911.09053" target="_blank">pdf</a>]

<h2>Unsupervised Keyword Extraction for Full-sentence VQA. (arXiv:1911.10354v3 [cs.CV] UPDATED)</h2>
<h3>Kohei Uehara, Tatsuya Harada</h3>
<p>In the majority of the existing Visual Question Answering (VQA) research, the
answers consist of short, often single words, as per instructions given to the
annotators during dataset construction. This study envisions a VQA task for
natural situations, where the answers are more likely to be sentences rather
than single words. To bridge the gap between this natural VQA and existing VQA
approaches, a novel unsupervised keyword extraction method is proposed. The
method is based on the principle that the full-sentence answers can be
decomposed into two parts: one that contains new information answering the
question (i.e., keywords), and one that contains information already included
in the question. Discriminative decoders were designed to achieve such
decomposition, and the method was experimentally implemented on VQA datasets
containing full-sentence answers. The results show that the proposed model can
accurately extract the keywords without being given explicit annotations
describing them.
</p>
<a href="http://arxiv.org/abs/1911.10354" target="_blank">arXiv:1911.10354</a> [<a href="http://arxiv.org/pdf/1911.10354" target="_blank">pdf</a>]

<h2>Stigmergic Independent Reinforcement Learning for Multi-Agent Collaboration. (arXiv:1911.12504v2 [cs.AI] UPDATED)</h2>
<h3>Xing Xu, Rongpeng Li, Zhifeng Zhao, Honggang Zhang</h3>
<p>With the rapid evolution of wireless mobile devices, there is a stronger need
to design proper collaboration mechanisms among the intelligent agents.
Following their individual observations, multiple intelligent agents could
cooperate and gradually approach the final collective objective through
continuously learning from the environment. In that regard, Independent
Reinforcement Learning (IRL) is often deployed within the multi-agent
collaboration to alleviate the dilemma of non-stationary learning environment.
However, behavioral strategies of the intelligent agents in IRL could only be
formulated upon their local individual observations of the global environment,
and appropriate communication mechanisms must be introduced to reduce their
behavioral localities. In this paper, we tackle the communication problem among
the intelligent agents in IRL by jointly adopting two mechanisms with different
scales. For the large scale, we introduce the stigmergy mechanism as an
indirect communication bridge among the independent learning agents and
carefully design a mathematical representation to indicate the impact of
digital pheromone. For the small scale, we propose a conflict-avoidance
mechanism between adjacent agents by implementing an additionally embedded
neural network to provide more opportunities for participants with higher
action priorities. Besides, we also present a federal training method to
effectively optimize the neural network within each agent in a decentralized
manner. Finally, we establish a simulation scenario where a number of mobile
agents in a certain area move automatically to form a specified target shape,
and demonstrate the superiorities of our proposed methods through extensive
simulations.
</p>
<a href="http://arxiv.org/abs/1911.12504" target="_blank">arXiv:1911.12504</a> [<a href="http://arxiv.org/pdf/1911.12504" target="_blank">pdf</a>]

<h2>Comparative Study of Differentially Private Synthetic Data Algorithms from the NIST PSCR Differential Privacy Synthetic Data Challenge. (arXiv:1911.12704v3 [stat.AP] UPDATED)</h2>
<h3>Claire McKay Bowen, Joshua Snoke</h3>
<p>Differentially private synthetic data generation offers a recent solution to
release analytically useful data while preserving the privacy of individuals in
the data. In order to utilize these algorithms for public policy decisions,
policymakers need an accurate understanding of these algorithms' comparative
performance. Correspondingly, data practitioners require standard metrics for
evaluating the analytic qualities of the synthetic data. In this paper, we
present an in-depth evaluation of several differentially private synthetic data
algorithms using actual differentially private synthetic data sets created by
contestants in the 2018-2019 National Institute of Standards and Technology
Public Safety Communications Research (NIST PSCR) Division's ``Differential
Privacy Synthetic Data Challenge.'' We offer analyses of these algorithms based
on both the accuracy of the data they created and their usability by potential
data providers. We frame the methods used in the NIST PSCR data challenge
within the broader differentially private synthetic data literature. We
implement additional utility metrics, including two of our own, on the
differentially private synthetic data and compare mechanism utility on three
categories. Our comparative assessment of the differentially private data
synthesis methods and the quality metrics shows the relative usefulness, the
general strengths and weaknesses, and offers preferred choices of algorithms
and metrics. Finally we describe the implications of our evaluation for
policymakers seeking to implement differentially private synthetic data
algorithms on future data products.
</p>
<a href="http://arxiv.org/abs/1911.12704" target="_blank">arXiv:1911.12704</a> [<a href="http://arxiv.org/pdf/1911.12704" target="_blank">pdf</a>]

<h2>How to Support Users in Understanding Intelligent Systems? Structuring the Discussion. (arXiv:2001.08301v3 [cs.HC] UPDATED)</h2>
<h3>Malin Eiband, Daniel Buschek, Heinrich Hussmann</h3>
<p>The opaque nature of many intelligent systems violates established usability
principles and thus presents a challenge for human-computer interaction.
Research in the field therefore highlights the need for transparency,
scrutability, intelligibility, interpretability and explainability, among
others. While all of these terms carry a vision of supporting users in
understanding intelligent systems, the underlying notions and assumptions about
users and their interaction with the system often remain unclear. We review the
literature in HCI through the lens of implied user questions to synthesise a
conceptual framework integrating user mindsets, user involvement, and knowledge
outcomes to reveal, differentiate and classify current notions in prior work.
This framework aims to resolve conceptual ambiguity in the field and enables
researchers to clarify their assumptions and become aware of those made in
prior work. We thus hope to advance and structure the dialogue in the HCI
research community on supporting users in understanding intelligent systems.
</p>
<a href="http://arxiv.org/abs/2001.08301" target="_blank">arXiv:2001.08301</a> [<a href="http://arxiv.org/pdf/2001.08301" target="_blank">pdf</a>]

<h2>Understanding and Optimizing Packed Neural Network Training for Hyper-Parameter Tuning. (arXiv:2002.02885v2 [cs.LG] UPDATED)</h2>
<h3>Rui Liu, Sanjan Krishnan, Aaron J. Elmore, Michael J. Franklin</h3>
<p>As neural networks are increasingly employed in machine learning practice,
organizations will have to determine how to share limited training resources
among a diverse set of model training tasks. This paper studies jointly
training multiple neural network models on a single GPU. We present an
empirical study of this operation, called pack, and end-to-end experiments that
suggest significant improvements for hyperparameter search systems. Our
research prototype is in TensorFlow, and we evaluate performance across
different models (ResNet, MobileNet, DenseNet, and MLP) and training scenarios.
The results suggest: (1) packing two models can bring up to 40% performance
improvement over unpacked setups for a single training step and the improvement
increases when packing more models; (2) the benefit of a pack primitive largely
depends on a number of factors including memory capacity, chip architecture,
neural network structure, and batch size; (3) there exists a trade-off between
packing and unpacking when training multiple neural network models on limited
resources; (4) a pack-based Hyperband is up to 2.7x faster than the original
Hyperband training method in our experiment setting, with this improvement
growing as memory size increases and subsequently the density of models packed.
</p>
<a href="http://arxiv.org/abs/2002.02885" target="_blank">arXiv:2002.02885</a> [<a href="http://arxiv.org/pdf/2002.02885" target="_blank">pdf</a>]

<h2>Local Facial Attribute Transfer through Inpainting. (arXiv:2002.03040v2 [cs.CV] UPDATED)</h2>
<h3>Ricard Durall, Franz-Josef Pfreundt, Janis Keuper</h3>
<p>The term attribute transfer refers to the tasks of altering images in such a
way, that the semantic interpretation of a given input image is shifted towards
an intended direction, which is quantified by semantic attributes. Prominent
example applications are photo realistic changes of facial features and
expressions, like changing the hair color, adding a smile, enlarging the nose
or altering the entire context of a scene, like transforming a summer landscape
into a winter panorama. Recent advances in attribute transfer are mostly based
on generative deep neural networks, using various techniques to manipulate
images in the latent space of the generator.

In this paper, we present a novel method for the common sub-task of local
attribute transfers, where only parts of a face have to be altered in order to
achieve semantic changes (e.g. removing a mustache). In contrast to previous
methods, where such local changes have been implemented by generating new
(global) images, we propose to formulate local attribute transfers as an
inpainting problem. Removing and regenerating only parts of images, our
Attribute Transfer Inpainting Generative Adversarial Network (ATI-GAN) is able
to utilize local context information to focus on the attributes while keeping
the background unmodified resulting in visually sound results.
</p>
<a href="http://arxiv.org/abs/2002.03040" target="_blank">arXiv:2002.03040</a> [<a href="http://arxiv.org/pdf/2002.03040" target="_blank">pdf</a>]

<h2>A Unified Network Architecture for Semi-Structured Deep Distributional Regression. (arXiv:2002.05777v3 [stat.ML] UPDATED)</h2>
<h3>David R&#xfc;gamer, Chris Kolb, Nadja Klein</h3>
<p>We propose a unified network architecture for deep distributional regression
in which entire conditional distributions can be learned in a general framework
of interpretable regression models and deep neural networks. Our approach
combines advanced statistical models and deep neural networks within a unifying
network, contrasting previous approaches that embed the neural network part as
a predictor in an additive regression model. To avoid identifiability issues
between different model parts, we construct an orthogonalization cell that
projects the deep neural network part into the orthogonal complement of the
statistical model predictor, facilitating both estimation and interpretability
in high-dimensional settings. We identify appropriate default penalties that
can also be understood as prior distribution assumptions in the Bayesian
version of our network architecture. We consider several use cases in
experiments with synthetic data and real-world applications to illustrate
special merits of our approach.
</p>
<a href="http://arxiv.org/abs/2002.05777" target="_blank">arXiv:2002.05777</a> [<a href="http://arxiv.org/pdf/2002.05777" target="_blank">pdf</a>]

<h2>FeatureNMS: Non-Maximum Suppression by Learning Feature Embeddings. (arXiv:2002.07662v2 [cs.CV] UPDATED)</h2>
<h3>Niels Ole Salscheider</h3>
<p>Most state of the art object detectors output multiple detections per object.
The duplicates are removed in a post-processing step called Non-Maximum
Suppression. Classical Non-Maximum Suppression has shortcomings in scenes that
contain objects with high overlap: This heuristic assumes that a high overlap
between two bounding boxes corresponds to a high probability of one being a
duplicate. We propose FeatureNMS to solve this problem. FeatureNMS recognizes
duplicates not only based on the intersection over union between the bounding
boxes, but also based on the difference of feature vectors. These feature
vectors can encode more information like visual appearance. Our approach
outperforms classical NMS and derived approaches and achieves state of the art
performance.
</p>
<a href="http://arxiv.org/abs/2002.07662" target="_blank">arXiv:2002.07662</a> [<a href="http://arxiv.org/pdf/2002.07662" target="_blank">pdf</a>]

<h2>Beyond Clicks: Modeling Multi-Relational Item Graph for Session-Based Target Behavior Prediction. (arXiv:2002.07993v2 [cs.IR] UPDATED)</h2>
<h3>Wen Wang, Wei Zhang, Shukai Liu, Qi Liu, Bo Zhang, Leyu Lin, Hongyuan Zha</h3>
<p>Session-based target behavior prediction aims to predict the next item to be
interacted with specific behavior types (e.g., clicking). Although existing
methods for session-based behavior prediction leverage powerful representation
learning approaches to encode items' sequential relevance in a low-dimensional
space, they suffer from several limitations. Firstly, they focus on only
utilizing the same type of user behavior for prediction, but ignore the
potential of taking other behavior data as auxiliary information. This is
particularly crucial when the target behavior is sparse but important (e.g.,
buying or sharing an item). Secondly, item-to-item relations are modeled
separately and locally in one behavior sequence, and they lack a principled way
to globally encode these relations more effectively. To overcome these
limitations, we propose a novel Multi-relational Graph Neural Network model for
Session-based target behavior Prediction, namely MGNN-SPred for short.
Specifically, we build a Multi-Relational Item Graph (MRIG) based on all
behavior sequences from all sessions, involving target and auxiliary behavior
types. Based on MRIG, MGNN-SPred learns global item-to-item relations and
further obtains user preferences w.r.t. current target and auxiliary behavior
sequences, respectively. In the end, MGNN-SPred leverages a gating mechanism to
adaptively fuse user representations for predicting next item interacted with
target behavior. The extensive experiments on two real-world datasets
demonstrate the superiority of MGNN-SPred by comparing with state-of-the-art
session-based prediction methods, validating the benefits of leveraging
auxiliary behavior and learning item-to-item relations over MRIG.
</p>
<a href="http://arxiv.org/abs/2002.07993" target="_blank">arXiv:2002.07993</a> [<a href="http://arxiv.org/pdf/2002.07993" target="_blank">pdf</a>]

<h2>Augmented Cyclic Consistency Regularization for Unpaired Image-to-Image Translation. (arXiv:2003.00187v2 [cs.CV] UPDATED)</h2>
<h3>Takehiko Ohkawa, Naoto Inoue, Hirokatsu Kataoka, Nakamasa Inoue</h3>
<p>Unpaired image-to-image (I2I) translation has received considerable attention
in pattern recognition and computer vision because of recent advancements in
generative adversarial networks (GANs). However, due to the lack of explicit
supervision, unpaired I2I models often fail to generate realistic images,
especially in challenging datasets with different backgrounds and poses. Hence,
stabilization is indispensable for GANs and applications of I2I translation.
Herein, we propose Augmented Cyclic Consistency Regularization (ACCR), a novel
regularization method for unpaired I2I translation. Our main idea is to enforce
consistency regularization originating from semi-supervised learning on the
discriminators leveraging real, fake, reconstructed, and augmented samples. We
regularize the discriminators to output similar predictions when fed pairs of
original and perturbed images. We qualitatively clarify why consistency
regularization on fake and reconstructed samples works well. Quantitatively,
our method outperforms the consistency regularized GAN (CR-GAN) in real-world
translations and demonstrates efficacy against several data augmentation
variants and cycle-consistent constraints.
</p>
<a href="http://arxiv.org/abs/2003.00187" target="_blank">arXiv:2003.00187</a> [<a href="http://arxiv.org/pdf/2003.00187" target="_blank">pdf</a>]

<h2>Markov Chain Monte Carlo with Neural Network Surrogates: Application to Contaminant Source Identification. (arXiv:2003.02322v2 [cs.CE] UPDATED)</h2>
<h3>Zitong Zhou, Daniel M. Tartakovsky</h3>
<p>Subsurface remediation often involves reconstruction of contaminant release
history from sparse observations of solute concentration. Markov Chain Monte
Carlo (MCMC), the most accurate and general method for this task, is rarely
used in practice because of its high computational cost associated with
multiple solves of contaminant transport equations. We propose an adaptive MCMC
method, in which a transport model is replaced with a fast and accurate
surrogate model in the form of a deep convolutional neural network (CNN). The
CNN-based surrogate is trained on a small number of the transport model runs
based on the prior knowledge of the unknown release history. Thus reduced
computational cost allows one to reduce the sampling error associated with
construction of the approximate likelihood function. As all MCMC strategies for
source identification, our method has an added advantage of quantifying
predictive uncertainty and accounting for measurement errors. Our numerical
experiments demonstrate the accuracy comparable to that of MCMC with the
forward transport model, which is obtained at a fraction of the computational
cost of the latter.
</p>
<a href="http://arxiv.org/abs/2003.02322" target="_blank">arXiv:2003.02322</a> [<a href="http://arxiv.org/pdf/2003.02322" target="_blank">pdf</a>]

<h2>Likelihood Regret: An Out-of-Distribution Detection Score For Variational Auto-encoder. (arXiv:2003.02977v3 [cs.LG] UPDATED)</h2>
<h3>Zhisheng Xiao, Qing Yan, Yali Amit</h3>
<p>Deep probabilistic generative models enable modeling the likelihoods of very
high dimensional data. An important application of generative modeling should
be the ability to detect out-of-distribution (OOD) samples by setting a
threshold on the likelihood. However, some recent studies show that
probabilistic generative models can, in some cases, assign higher likelihoods
on certain types of OOD samples, making the OOD detection rules based on
likelihood threshold problematic. To address this issue, several OOD detection
methods have been proposed for deep generative models. In this paper, we make
the observation that many of these methods fail when applied to generative
models based on Variational Auto-encoders (VAE). As an alternative, we propose
Likelihood Regret, an efficient OOD score for VAEs. We benchmark our proposed
method over existing approaches, and empirical results suggest that our method
obtains the best overall OOD detection performances when applied to VAEs.
</p>
<a href="http://arxiv.org/abs/2003.02977" target="_blank">arXiv:2003.02977</a> [<a href="http://arxiv.org/pdf/2003.02977" target="_blank">pdf</a>]

<h2>Gradient-based adversarial attacks on categorical sequence models via traversing an embedded world. (arXiv:2003.04173v3 [cs.LG] UPDATED)</h2>
<h3>Ivan Fursov, Alexey Zaytsev, Nikita Kluchnikov, Andrey Kravchenko, Evgeny Burnaev</h3>
<p>Deep learning models suffer from a phenomenon called adversarial attacks: we
can apply minor changes to the model input to fool a classifier for a
particular example. The literature mostly considers adversarial attacks on
models with images and other structured inputs. However, the adversarial
attacks for categorical sequences can also be harmful. Successful attacks for
inputs in the form of categorical sequences should address the following
challenges: (1) non-differentiability of the target function, (2) constraints
on transformations of initial sequences, and (3) diversity of possible
problems. We handle these challenges using two black-box adversarial attacks.
The first approach adopts a Monte-Carlo method and allows usage in any
scenario, the second approach uses a continuous relaxation of models and target
metrics, and thus allows usage of state-of-the-art methods for adversarial
attacks with little additional effort. Results for money transactions, medical
fraud, and NLP datasets suggest that proposed methods generate reasonable
adversarial sequences that are close to original ones but fool machine learning
models.
</p>
<a href="http://arxiv.org/abs/2003.04173" target="_blank">arXiv:2003.04173</a> [<a href="http://arxiv.org/pdf/2003.04173" target="_blank">pdf</a>]

<h2>Unpaired Image-to-Image Translation using Adversarial Consistency Loss. (arXiv:2003.04858v5 [cs.CV] UPDATED)</h2>
<h3>Yihao Zhao, Ruihai Wu, Hao Dong</h3>
<p>Unpaired image-to-image translation is a class of vision problems whose goal
is to find the mapping between different image domains using unpaired training
data. Cycle-consistency loss is a widely used constraint for such problems.
However, due to the strict pixel-level constraint, it cannot perform geometric
changes, remove large objects, or ignore irrelevant texture. In this paper, we
propose a novel adversarial-consistency loss for image-to-image translation.
This loss does not require the translated image to be translated back to be a
specific source image but can encourage the translated images to retain
important features of the source images and overcome the drawbacks of
cycle-consistency loss noted above. Our method achieves state-of-the-art
results on three challenging tasks: glasses removal, male-to-female
translation, and selfie-to-anime translation.
</p>
<a href="http://arxiv.org/abs/2003.04858" target="_blank">arXiv:2003.04858</a> [<a href="http://arxiv.org/pdf/2003.04858" target="_blank">pdf</a>]

<h2>Generalized Energy Based Models. (arXiv:2003.05033v4 [stat.ML] UPDATED)</h2>
<h3>Michael Arbel, Liang Zhou, Arthur Gretton</h3>
<p>We introduce the Generalized Energy Based Model (GEBM) for generative
modelling. These models combine two trained components: a base distribution
(generally an implicit model), which can learn the support of data with low
intrinsic dimension in a high dimensional space; and an energy function, to
refine the probability mass on the learned support. Both the energy function
and base jointly constitute the final model, unlike GANs, which retain only the
base distribution (the "generator"). GEBMs are trained by alternating between
learning the energy and the base. We show that both training stages are
well-defined: the energy is learned by maximising a generalized likelihood, and
the resulting energy-based loss provides informative gradients for learning the
base. Samples from the posterior on the latent space of the trained model can
be obtained via MCMC, thus finding regions in this space that produce better
quality samples. Empirically, the GEBM samples on image-generation tasks are of
much better quality than those from the learned generator alone, indicating
that all else being equal, the GEBM will outperform a GAN of the same
complexity. When using normalizing flows as base measures, GEBMs succeed on
density modelling tasks, returning comparable performance to direct maximum
likelihood of the same networks.
</p>
<a href="http://arxiv.org/abs/2003.05033" target="_blank">arXiv:2003.05033</a> [<a href="http://arxiv.org/pdf/2003.05033" target="_blank">pdf</a>]

<h2>SUOD: Accelerating Large-scare Unsupervised Heterogeneous Outlier Detection. (arXiv:2003.05731v2 [cs.LG] UPDATED)</h2>
<h3>Yue Zhao, Xiyang Hu, Cheng Cheng, Cong Wang, Changlin Wan, Wen Wang, Jianing Yang, Haoping Bai, Zheng Li, Cao Xiao, Yunlong Wang, Zhi Qiao, Jimeng Sun, Leman Akoglu</h3>
<p>Outlier detection (OD) is a key data mining task for identifying abnormal
objects from general samples with numerous high-stake applications including
fraud detection and intrusion detection. Due to the lack of ground truth
labels, practitioners often have to build a large number of unsupervised models
that are heterogeneous (i.e., different algorithms and hyperparameters) for
further combination and analysis with ensemble learning, rather than relying on
a single model. However, this yields severe scalability issues on
high-dimensional, large datasets.

How to accelerate the training and predicting with a large number of
heterogeneous unsupervised OD models? How to ensure the acceleration does not
deteriorate detection models' accuracy? How to accommodate the acceleration
need for both a single worker setting and a distributed system with multiple
workers? In this study, we propose a three-module acceleration system called
SUOD (scalable unsupervised outlier detection) to address these questions. It
focuses on three complementary aspects to accelerate (dimensionality reduction
for high-dimensional data, model approximation for complex models, and
execution efficiency improvement for taskload imbalance within distributed
systems), while controlling detection performance degradation. Extensive
experiments on more than 20 benchmark datasets demonstrate SUOD's effectiveness
in heterogeneous OD acceleration. By the submission time, the released
open-source system has been widely used with more than 700,000 times downloads.
A real-world deployment case on fraudulent claim analysis at IQVIA, a leading
healthcare firm, is also provided.
</p>
<a href="http://arxiv.org/abs/2003.05731" target="_blank">arXiv:2003.05731</a> [<a href="http://arxiv.org/pdf/2003.05731" target="_blank">pdf</a>]

<h2>Partial Quantifier Elimination By Certificate Clauses. (arXiv:2003.09667v5 [cs.LO] UPDATED)</h2>
<h3>Eugene Goldberg</h3>
<p>We study a modification of the Quantifier Elimination (QE) problem called
Partial QE (PQE) for propositional CNF formulas. In PQE, only a small subset of
target clauses is taken out of the scope of quantifiers. The appeal of PQE is
twofold. First, it provides a language for performing $\mathit{incremental}$
computations. Many verification problems (e.g. equivalence checking and model
checking) are inherently incremental and so can be solved in terms of PQE.
Second, PQE can be dramatically simpler than QE. We perform PQE by adding a set
of clauses depending only on unquantified variables that make the target
clauses redundant. Proving redundancy of a target clause is done by derivation
of a "certificate" clause $\mathit{implying}$ the former. We implemented this
idea in a PQE algorithm called $\mathit{START}$. It bears some similarity to a
SAT-solver with conflict driven learning. A major difference here is that
$\mathit{START}$ backtracks as soon as a target clause is proved redundant
(even if no conflict occurred). We experimentally evaluate $\mathit{START}$ on
a practical problem. We use this problem to compare PQE with QE and QBF
solving.
</p>
<a href="http://arxiv.org/abs/2003.09667" target="_blank">arXiv:2003.09667</a> [<a href="http://arxiv.org/pdf/2003.09667" target="_blank">pdf</a>]

<h2>Pre-training for Abstractive Document Summarization by Reinstating Source Text. (arXiv:2004.01853v4 [cs.CL] UPDATED)</h2>
<h3>Yanyan Zou, Xingxing Zhang, Wei Lu, Furu Wei, Ming Zhou</h3>
<p>Abstractive document summarization is usually modeled as a
sequence-to-sequence (Seq2Seq) learning problem. Unfortunately, training large
Seq2Seq based summarization models on limited supervised summarization data is
challenging. This paper presents three pre-training objectives which allow us
to pre-train a Seq2Seq based abstractive summarization model on unlabeled text.
The main idea is that, given an input text artificially constructed from a
document, a model is pre-trained to reinstate the original document. These
objectives include sentence reordering, next sentence generation, and masked
document generation, which have close relations with the abstractive document
summarization task. Experiments on two benchmark summarization datasets (i.e.,
CNN/DailyMail and New York Times) show that all three objectives can improve
performance upon baselines. Compared to models pre-trained on large-scale data
(more than 160GB), our method, with only 19GB text for pre-training, achieves
comparable results, which demonstrates its effectiveness.
</p>
<a href="http://arxiv.org/abs/2004.01853" target="_blank">arXiv:2004.01853</a> [<a href="http://arxiv.org/pdf/2004.01853" target="_blank">pdf</a>]

<h2>Optimus: Organizing Sentences via Pre-trained Modeling of a Latent Space. (arXiv:2004.04092v4 [cs.CL] UPDATED)</h2>
<h3>Chunyuan Li, Xiang Gao, Yuan Li, Baolin Peng, Xiujun Li, Yizhe Zhang, Jianfeng Gao</h3>
<p>When trained effectively, the Variational Autoencoder (VAE) can be both a
powerful generative model and an effective representation learning framework
for natural language. In this paper, we propose the first large-scale language
VAE model, Optimus. A universal latent embedding space for sentences is first
pre-trained on large text corpus, and then fine-tuned for various language
generation and understanding tasks. Compared with GPT-2, Optimus enables guided
language generation from an abstract level using the latent vectors. Compared
with BERT, Optimus can generalize better on low-resource language understanding
tasks due to the smooth latent space structure. Extensive experimental results
on a wide range of language tasks demonstrate the effectiveness of Optimus. It
achieves new state-of-the-art on VAE language modeling benchmarks. We hope that
our first pre-trained big VAE language model itself and results can help the
NLP community renew the interests of deep generative models in the era of
large-scale pre-training, and make these principled methods more practical.
</p>
<a href="http://arxiv.org/abs/2004.04092" target="_blank">arXiv:2004.04092</a> [<a href="http://arxiv.org/pdf/2004.04092" target="_blank">pdf</a>]

<h2>On the Neural Tangent Kernel of Deep Networks with Orthogonal Initialization. (arXiv:2004.05867v3 [cs.LG] UPDATED)</h2>
<h3>Wei Huang, Weitao Du, Richard Yi Da Xu</h3>
<p>In recent years, a critical initialization scheme of orthogonal
initialization on deep nonlinear networks has been proposed. The orthogonal
weights are crucial to achieve {\it dynamical isometry} for random networks,
where the entire spectrum of singular values of an input-output Jacobian are
around one. The strong empirical evidence that orthogonal initialization in
linear networks and the linear regime of nonlinear networks can speed up
training than Gaussian initialization raise great interests. One recent work
has proven the benefit of orthogonal initialization in linear networks.
However, the dynamics behind it have not been revealed on nonlinear networks.
In this work, we study the Neural Tangent Kernel (NTK), which can describe
dynamics of gradient descent training of wide network, and focus on
fully-connected and nonlinear networks with orthogonal initialization. We prove
that NTK of Gaussian and orthogonal weights are equal when the network width is
infinite, resulting in a conclusion that orthogonal initialization can speed up
training is a finite-width effect in the small learning rate regime. Then we
find that during training, the NTK of infinite-width network with orthogonal
initialization stays constant theoretically and varies at a rate of the same
order as Gaussian ones empirically, as the width tends to infinity. Finally, we
conduct a thorough empirical investigation of training speed on CIFAR10
datasets and show the benefit of orthogonal initialization lies in the large
learning rate and depth phase in a linear regime of nonlinear network.
</p>
<a href="http://arxiv.org/abs/2004.05867" target="_blank">arXiv:2004.05867</a> [<a href="http://arxiv.org/pdf/2004.05867" target="_blank">pdf</a>]

<h2>Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks. (arXiv:2004.05937v4 [cs.CV] UPDATED)</h2>
<h3>Lin Wang, Kuk-Jin Yoon</h3>
<p>Deep neural models in recent years have been successful in almost every
field, including extremely complex problem statements. However, these models
are huge in size, with millions (and even billions) of parameters, thus
demanding more heavy computation power and failing to be deployed on edge
devices. Besides, the performance boost is highly dependent on redundant
labeled data. To achieve faster speeds and to handle the problems caused by the
lack of data, knowledge distillation (KD) has been proposed to transfer
information learned from one model to another. KD is often characterized by the
so-called `Student-Teacher' (S-T) learning framework and has been broadly
applied in model compression and knowledge transfer. This paper is about KD and
S-T learning, which are being actively studied in recent years. First, we aim
to provide explanations of what KD is and how/why it works. Then, we provide a
comprehensive survey on the recent progress of KD methods together with S-T
frameworks typically for vision tasks. In general, we consider some fundamental
questions that have been driving this research area and thoroughly generalize
the research progress and technical details. Additionally, we systematically
analyze the research status of KD in vision applications. Finally, we discuss
the potentials and open challenges of existing methods and prospect the future
directions of KD and S-T learning.
</p>
<a href="http://arxiv.org/abs/2004.05937" target="_blank">arXiv:2004.05937</a> [<a href="http://arxiv.org/pdf/2004.05937" target="_blank">pdf</a>]

<h2>What's so special about BERT's layers? A closer look at the NLP pipeline in monolingual and multilingual models. (arXiv:2004.06499v2 [cs.CL] UPDATED)</h2>
<h3>Wietse de Vries, Andreas van Cranenburgh, Malvina Nissim</h3>
<p>Peeking into the inner workings of BERT has shown that its layers resemble
the classical NLP pipeline, with progressively more complex tasks being
concentrated in later layers. To investigate to what extent these results also
hold for a language other than English, we probe a Dutch BERT-based model and
the multilingual BERT model for Dutch NLP tasks. In addition, through a deeper
analysis of part-of-speech tagging, we show that also within a given task,
information is spread over different parts of the network and the pipeline
might not be as neat as it seems. Each layer has different specialisations, so
that it may be more useful to combine information from different layers,
instead of selecting a single one based on the best overall performance.
</p>
<a href="http://arxiv.org/abs/2004.06499" target="_blank">arXiv:2004.06499</a> [<a href="http://arxiv.org/pdf/2004.06499" target="_blank">pdf</a>]

<h2>Natural Disaster Classification using Aerial Photography Explainable for Typhoon Damaged Region. (arXiv:2004.10130v2 [cs.CV] UPDATED)</h2>
<h3>Takato Yasuno, Masazumi Amakata, Masahiro Okano</h3>
<p>Recent years, typhoon damages has become social problem owing to climate
change. Especially, 9 September 2019, Typhoon Faxai passed on the south Chiba
prefecture in Japan, whose damages included with electric and water provision
stop and house roof break because of strong wind recorded on the maximum 45
meter per second. A large amount of tree fell down, and the neighbor electric
poles also fell down at the same time. These disaster features have caused that
it took eighteen days for recovery longer than past ones. Initial responses are
important for faster recovery. As long as we can, aerial survey for global
screening of devastated region would be required for decision support to
respond where to recover ahead. This paper proposes a practical method to
visualize the damaged areas focused on the typhoon disaster features using
aerial photography. This method can classify eight classes which contains land
covers without damages and areas with disaster, where an aerial photograph is
partitioned into 4,096 grids that is 64 by 64, with each unit image of 48 meter
square. Using target feature class probabilities, we can visualize disaster
features map to scale the color range from blue to red or yellow. Furthermore,
we can realize disaster feature mapping on each unit grid images to compute the
convolutional activation map using Grad-CAM based on deep neural network layers
for classification. This paper demonstrates case studies applied to aerial
photographs recorded at the south Chiba prefecture in Japan after typhoon
disaster.
</p>
<a href="http://arxiv.org/abs/2004.10130" target="_blank">arXiv:2004.10130</a> [<a href="http://arxiv.org/pdf/2004.10130" target="_blank">pdf</a>]

<h2>Deep Multimodal Neural Architecture Search. (arXiv:2004.12070v2 [cs.CV] UPDATED)</h2>
<h3>Zhou Yu, Yuhao Cui, Jun Yu, Meng Wang, Dacheng Tao, Qi Tian</h3>
<p>Designing effective neural networks is fundamentally important in deep
multimodal learning. Most existing works focus on a single task and design
neural architectures manually, which are highly task-specific and hard to
generalize to different tasks. In this paper, we devise a generalized deep
multimodal neural architecture search (MMnas) framework for various multimodal
learning tasks. Given multimodal input, we first define a set of primitive
operations, and then construct a deep encoder-decoder based unified backbone,
where each encoder or decoder block corresponds to an operation searched from a
predefined operation pool. On top of the unified backbone, we attach
task-specific heads to tackle different multimodal learning tasks. By using a
gradient-based NAS algorithm, the optimal architectures for different tasks are
learned efficiently. Extensive ablation studies, comprehensive analysis, and
comparative experimental results show that the obtained MMnasNet significantly
outperforms existing state-of-the-art approaches across three multimodal
learning tasks (over five datasets), including visual question answering,
image-text matching, and visual grounding.
</p>
<a href="http://arxiv.org/abs/2004.12070" target="_blank">arXiv:2004.12070</a> [<a href="http://arxiv.org/pdf/2004.12070" target="_blank">pdf</a>]

<h2>KrakN: Transfer Learning framework for thin crack detection in infrastructure maintenance. (arXiv:2004.12337v2 [cs.CV] UPDATED)</h2>
<h3>Mateusz &#x17b;arski, Bartosz W&#xf3;jcik, Jaros&#x142;aw Adam Miszczak</h3>
<p>Monitoring the technical condition of infrastructure is a crucial element to
its maintenance. Currently applied methods are outdated, labour-intensive and
inaccurate. At the same time, the latest methods using Artificial Intelligence
techniques are severely limited in their application due to two main factors --
labour-intensive gathering of new datasets and high demand for computing power.
We propose to utilize custom made framework -- KrakN, to overcome these
limiting factors. It enables the development of unique infrastructure defects
detectors on digital images, achieving the accuracy of above 90%. The framework
supports semi-automatic creation of new datasets and has modest computing power
requirements. It is implemented in the form of a ready-to-use software package
openly distributed to the public. Thus, it can be used to immediately implement
the methods proposed in this paper in the process of infrastructure management
by government units, regardless of their financial capabilities.
</p>
<a href="http://arxiv.org/abs/2004.12337" target="_blank">arXiv:2004.12337</a> [<a href="http://arxiv.org/pdf/2004.12337" target="_blank">pdf</a>]

<h2>Learning to Learn to Disambiguate: Meta-Learning for Few-Shot Word Sense Disambiguation. (arXiv:2004.14355v3 [cs.CL] UPDATED)</h2>
<h3>Nithin Holla, Pushkar Mishra, Helen Yannakoudakis, Ekaterina Shutova</h3>
<p>The success of deep learning methods hinges on the availability of large
training datasets annotated for the task of interest. In contrast to human
intelligence, these methods lack versatility and struggle to learn and adapt
quickly to new tasks, where labeled data is scarce. Meta-learning aims to solve
this problem by training a model on a large number of few-shot tasks, with an
objective to learn new tasks quickly from a small number of examples. In this
paper, we propose a meta-learning framework for few-shot word sense
disambiguation (WSD), where the goal is to learn to disambiguate unseen words
from only a few labeled instances. Meta-learning approaches have so far been
typically tested in an $N$-way, $K$-shot classification setting where each task
has $N$ classes with $K$ examples per class. Owing to its nature, WSD deviates
from this controlled setup and requires the models to handle a large number of
highly unbalanced classes. We extend several popular meta-learning approaches
to this scenario, and analyze their strengths and weaknesses in this new
challenging setting.
</p>
<a href="http://arxiv.org/abs/2004.14355" target="_blank">arXiv:2004.14355</a> [<a href="http://arxiv.org/pdf/2004.14355" target="_blank">pdf</a>]

<h2>Few-Shot Learning for Opinion Summarization. (arXiv:2004.14884v3 [cs.LG] UPDATED)</h2>
<h3>Arthur Bra&#x17e;inskas, Mirella Lapata, Ivan Titov</h3>
<p>Opinion summarization is the automatic creation of text reflecting subjective
information expressed in multiple documents, such as user reviews of a product.
The task is practically important and has attracted a lot of attention.
However, due to the high cost of summary production, datasets large enough for
training supervised models are lacking. Instead, the task has been
traditionally approached with extractive methods that learn to select text
fragments in an unsupervised or weakly-supervised way. Recently, it has been
shown that abstractive summaries, potentially more fluent and better at
reflecting conflicting information, can also be produced in an unsupervised
fashion. However, these models, not being exposed to actual summaries, fail to
capture their essential properties. In this work, we show that even a handful
of summaries is sufficient to bootstrap generation of the summary text with all
expected properties, such as writing style, informativeness, fluency, and
sentiment preservation. We start by training a conditional Transformer language
model to generate a new product review given other available reviews of the
product. The model is also conditioned on review properties that are directly
related to summaries; the properties are derived from reviews with no manual
effort. In the second stage, we fine-tune a plug-in module that learns to
predict property values on a handful of summaries. This lets us switch the
generator to the summarization mode. We show on Amazon and Yelp datasets that
our approach substantially outperforms previous extractive and abstractive
methods in automatic and human evaluation.
</p>
<a href="http://arxiv.org/abs/2004.14884" target="_blank">arXiv:2004.14884</a> [<a href="http://arxiv.org/pdf/2004.14884" target="_blank">pdf</a>]

<h2>DeePore: a deep learning workflow for rapid and comprehensive characterization of porous materials. (arXiv:2005.03759v2 [cond-mat.mtrl-sci] UPDATED)</h2>
<h3>Arash Rabbani, Masoud Babaei, Reza Shams, Ying Da Wang, Traiwit Chung</h3>
<p>DeePore is a deep learning workflow for rapid estimation of a wide range of
porous material properties based on the binarized micro-tomography images. By
combining naturally occurring porous textures we generated 17700 semi-real 3-D
micro-structures of porous geo-materials with size of 256^3 voxels and 30
physical properties of each sample are calculated using physical simulations on
the corresponding pore network models. Next, a designed feed-forward
convolutional neural network (CNN) is trained based on the dataset to estimate
several morphological, hydraulic, electrical, and mechanical characteristics of
the porous material in a fraction of a second. In order to fine-tune the CNN
design, we tested 9 different training scenarios and selected the one with the
highest average coefficient of determination (R^2) equal to 0.885 for 1418
testing samples. Additionally, 3 independent synthetic images as well as 3
realistic tomography images have been tested using the proposed method and
results are compared with pore network modelling and experimental data,
respectively. Tested absolute permeabilities had around 13 % relative error
compared to the experimental data which is noticeable considering the accuracy
of the direct numerical simulation methods such as Lattice Boltzmann and Finite
Volume. The workflow is compatible with any physical size of the images due to
its dimensionless approach and can be used to characterize large-scale 3-D
images by averaging the model outputs for a sliding window that scans the whole
geometry.
</p>
<a href="http://arxiv.org/abs/2005.03759" target="_blank">arXiv:2005.03759</a> [<a href="http://arxiv.org/pdf/2005.03759" target="_blank">pdf</a>]

<h2>HVS-Based Perceptual Color Compression of Image Data. (arXiv:2005.07930v2 [eess.IV] UPDATED)</h2>
<h3>Lee Prangnell, Victor Sanchez</h3>
<p>In contemporary lossy image coding applications, a desired aim is to
decrease, as much as possible, bits per pixel without inducing perceptually
conspicuous distortions in RGB image data. In this paper, we propose a novel
color-based perceptual compression technique, named RGB-PAQ. RGB-PAQ is based
on CIELAB Just Noticeable Color Difference (JNCD) and Human Visual System (HVS)
spectral sensitivity. We utilize CIELAB JNCD and HVS spectral sensitivity
modeling to separately adjust quantization levels at the Coding Block (CB)
level. In essence, our method is designed to capitalize on the inability of the
HVS to perceptually differentiate photons in very similar wavelength bands. In
terms of application, the proposed technique can be used with RGB (4:4:4) image
data of various bit depths and spatial resolutions including, for example, true
color and deep color images in HD and Ultra HD resolutions. In the evaluations,
we compare RGB-PAQ with a set of anchor methods; namely, HEVC, JPEG, JPEG 2000
and Google WebP. Compared with HEVC HM RExt, RGB-PAQ achieves up to 77.8% bits
reductions. The subjective evaluations confirm that the compression artifacts
induced by RGB-PAQ proved to be either imperceptible (MOS = 5) or
near-imperceptible (MOS = 4) in the vast majority of cases.
</p>
<a href="http://arxiv.org/abs/2005.07930" target="_blank">arXiv:2005.07930</a> [<a href="http://arxiv.org/pdf/2005.07930" target="_blank">pdf</a>]

<h2>A Self-ensembling Framework for Semi-supervised Knee Cartilage Defects Assessment with Dual-Consistency. (arXiv:2005.09212v2 [eess.IV] UPDATED)</h2>
<h3>Jiayu Huo, Liping Si, Xi Ouyang, Kai Xuan, Weiwu Yao, Zhong Xue, Qian Wang, Dinggang Shen, Lichi Zhang</h3>
<p>Knee osteoarthritis (OA) is one of the most common musculoskeletal disorders
and requires early-stage diagnosis. Nowadays, the deep convolutional neural
networks have achieved greatly in the computer-aided diagnosis field. However,
the construction of the deep learning models usually requires great amounts of
annotated data, which is generally high-cost. In this paper, we propose a novel
approach for knee cartilage defects assessment, including severity
classification and lesion localization. This can be treated as a subtask of
knee OA diagnosis. Particularly, we design a self-ensembling framework, which
is composed of a student network and a teacher network with the same structure.
The student network learns from both labeled data and unlabeled data and the
teacher network averages the student model weights through the training course.
A novel attention loss function is developed to obtain accurate attention
masks. With dual-consistency checking of the attention in the lesion
classification and localization, the two networks can gradually optimize the
attention distribution and improve the performance of each other, whereas the
training relies on partially labeled data only and follows the semi-supervised
manner. Experiments show that the proposed method can significantly improve the
self-ensembling performance in both knee cartilage defects classification and
localization, and also greatly reduce the needs of annotated data.
</p>
<a href="http://arxiv.org/abs/2005.09212" target="_blank">arXiv:2005.09212</a> [<a href="http://arxiv.org/pdf/2005.09212" target="_blank">pdf</a>]

<h2>Personalized Chatbot Trustworthiness Ratings. (arXiv:2005.10067v2 [cs.SI] UPDATED)</h2>
<h3>Biplav Srivastava, Francesca Rossi, Sheema Usmani, and Mariana Bernagozzi</h3>
<p>Conversation agents, commonly referred to as chatbots, are increasingly
deployed in many domains to allow people to have a natural interaction while
trying to solve a specific problem. Given their widespread use, it is important
to provide their users with methods and tools to increase users awareness of
various properties of the chatbots, including non-functional properties that
users may consider important in order to trust a specific chatbot. For example,
users may want to use chatbots that are not biased, that do not use abusive
language, that do not leak information to other users, and that respond in a
style which is appropriate for the user's cognitive level.

In this paper, we address the setting where a chatbot cannot be modified, its
training data cannot be accessed, and yet a neutral party wants to assess and
communicate its trustworthiness to a user, tailored to the user's priorities
over the various trust issues. Such a rating can help users choose among
alternative chatbots, developers test their systems, business leaders price
their offering, and regulators set policies. We envision a personalized rating
methodology for chatbots that relies on separate rating modules for each issue,
and users' detected priority orderings among the relevant trust issues, to
generate an aggregate personalized rating for the trustworthiness of a chatbot.
The method is independent of the specific trust issues and is parametric to the
aggregation procedure, thereby allowing for seamless generalization. We
illustrate its general use, integrate it with a live chatbot, and evaluate it
on four dialog datasets and representative user profiles, validated with user
surveys.
</p>
<a href="http://arxiv.org/abs/2005.10067" target="_blank">arXiv:2005.10067</a> [<a href="http://arxiv.org/pdf/2005.10067" target="_blank">pdf</a>]

<h2>How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey. (arXiv:2005.11691v6 [eess.SP] UPDATED)</h2>
<h3>Jiexia Ye, Juanjuan Zhao, Kejiang Ye, Chengzhong Xu</h3>
<p>In recent years, various deep learning architectures have been proposed to
solve complex challenges (e.g. spatial dependency, temporal dependency) in
traffic domain, which have achieved satisfactory performance. These
architectures are composed of multiple deep learning techniques in order to
tackle various challenges in traffic tasks. Traditionally, convolution neural
networks (CNNs) are utilized to model spatial dependency by decomposing the
traffic network as grids. However, many traffic networks are graph-structured
in nature. In order to utilize such spatial information fully, it's more
appropriate to formulate traffic networks as graphs mathematically. Recently,
various novel deep learning techniques have been developed to process graph
data, called graph neural networks (GNNs). More and more works combine GNNs
with other deep learning techniques to construct an architecture dealing with
various challenges in a complex traffic task, where GNNs are responsible for
extracting spatial correlations in traffic network. These graph-based
architectures have achieved state-of-the-art performance. To provide a
comprehensive and clear picture of such emerging trend, this survey carefully
examines various graph-based deep learning architectures in many traffic
applications. We first give guidelines to formulate a traffic problem based on
graph and construct graphs from various kinds of traffic datasets. Then we
decompose these graph-based architectures to discuss their shared deep learning
techniques, clarifying the utilization of each technique in traffic tasks.
What's more, we summarize some common traffic challenges and the corresponding
graph-based deep learning solutions to each challenge. Finally, we provide
benchmark datasets, open source codes and future research directions in this
rapidly growing field.
</p>
<a href="http://arxiv.org/abs/2005.11691" target="_blank">arXiv:2005.11691</a> [<a href="http://arxiv.org/pdf/2005.11691" target="_blank">pdf</a>]

<h2>Common Sense or World Knowledge? Investigating Adapter-Based Knowledge Injection into Pretrained Transformers. (arXiv:2005.11787v2 [cs.CL] UPDATED)</h2>
<h3>Anne Lauscher, Olga Majewska, Leonardo F. R. Ribeiro, Iryna Gurevych, Nikolai Rozanov, Goran Glava&#x161;</h3>
<p>Following the major success of neural language models (LMs) such as BERT or
GPT-2 on a variety of language understanding tasks, recent work focused on
injecting (structured) knowledge from external resources into these models.
While on the one hand, joint pretraining (i.e., training from scratch, adding
objectives based on external knowledge to the primary LM objective) may be
prohibitively computationally expensive, post-hoc fine-tuning on external
knowledge, on the other hand, may lead to the catastrophic forgetting of
distributional knowledge. In this work, we investigate models for complementing
the distributional knowledge of BERT with conceptual knowledge from ConceptNet
and its corresponding Open Mind Common Sense (OMCS) corpus, respectively, using
adapter training. While overall results on the GLUE benchmark paint an
inconclusive picture, a deeper analysis reveals that our adapter-based models
substantially outperform BERT (up to 15-20 performance points) on inference
tasks that require the type of conceptual knowledge explicitly present in
ConceptNet and OMCS. All code and experiments are open sourced under:
https://github.com/wluper/retrograph .
</p>
<a href="http://arxiv.org/abs/2005.11787" target="_blank">arXiv:2005.11787</a> [<a href="http://arxiv.org/pdf/2005.11787" target="_blank">pdf</a>]

<h2>A Structural Model for Contextual Code Changes. (arXiv:2005.13209v2 [cs.PL] UPDATED)</h2>
<h3>Shaked Brody, Uri Alon, Eran Yahav</h3>
<p>We address the problem of predicting edit completions based on a learned
model that was trained on past edits. Given a code snippet that is partially
edited, our goal is to predict a completion of the edit for the rest of the
snippet. We refer to this task as the EditCompletion task and present a novel
approach for tackling it. The main idea is to directly represent structural
edits. This allows us to model the likelihood of the edit itself, rather than
learning the likelihood of the edited code. We represent an edit operation as a
path in the program's Abstract Syntax Tree (AST), originating from the source
of the edit to the target of the edit. Using this representation, we present a
powerful and lightweight neural model for the EditCompletion task.

We conduct a thorough evaluation, comparing our approach to a variety of
representation and modeling approaches that are driven by multiple strong
models such as LSTMs, Transformers, and neural CRFs. Our experiments show that
our model achieves a 28% relative gain over state-of-the-art sequential models
and 2x higher accuracy than syntactic models that learn to generate the edited
code, as opposed to modeling the edits directly.

Our code, dataset, and trained models are publicly available at
https://github.com/tech-srl/c3po/ .
</p>
<a href="http://arxiv.org/abs/2005.13209" target="_blank">arXiv:2005.13209</a> [<a href="http://arxiv.org/pdf/2005.13209" target="_blank">pdf</a>]

<h2>Explainable Artificial Intelligence: a Systematic Review. (arXiv:2006.00093v4 [cs.AI] UPDATED)</h2>
<h3>Giulia Vilone, Luca Longo</h3>
<p>Explainable Artificial Intelligence (XAI) has experienced a significant
growth over the last few years. This is due to the widespread application of
machine learning, particularly deep learning, that has led to the development
of highly accurate models but lack explainability and interpretability. A
plethora of methods to tackle this problem have been proposed, developed and
tested. This systematic review contributes to the body of knowledge by
clustering these methods with a hierarchical classification system with four
main clusters: review articles, theories and notions, methods and their
evaluation. It also summarises the state-of-the-art in XAI and recommends
future research directions.
</p>
<a href="http://arxiv.org/abs/2006.00093" target="_blank">arXiv:2006.00093</a> [<a href="http://arxiv.org/pdf/2006.00093" target="_blank">pdf</a>]

<h2>Earnings Prediction with Deep Learning. (arXiv:2006.03132v2 [q-fin.GN] UPDATED)</h2>
<h3>Lars Elend, Sebastian A. Tideman, Kerstin Lopatta, Oliver Kramer</h3>
<p>In the financial sector, a reliable forecast the future financial performance
of a company is of great importance for investors' investment decisions. In
this paper we compare long-term short-term memory (LSTM) networks to temporal
convolution network (TCNs) in the prediction of future earnings per share
(EPS). The experimental analysis is based on quarterly financial reporting data
and daily stock market returns. For a broad sample of US firms, we find that
both LSTMs outperform the naive persistent model with up to 30.0% more accurate
predictions, while TCNs achieve and an improvement of 30.8%. Both types of
networks are at least as accurate as analysts and exceed them by up to 12.2%
(LSTM) and 13.2% (TCN).
</p>
<a href="http://arxiv.org/abs/2006.03132" target="_blank">arXiv:2006.03132</a> [<a href="http://arxiv.org/pdf/2006.03132" target="_blank">pdf</a>]

<h2>Machine Learning Automatically Detects COVID-19 using Chest CTs in a Large Multicenter Cohort. (arXiv:2006.04998v3 [eess.IV] UPDATED)</h2>
<h3>Eduardo Jose Mortani Barbosa Jr., Bogdan Georgescu, Shikha Chaganti, Gorka Bastarrika Aleman, Jordi Broncano Cabrero, Guillaume Chabin, Thomas Flohr, Philippe Grenier, Sasa Grbic, Nakul Gupta, Fran&#xe7;ois Mellot, Savvas Nicolaou, Thomas Re, Pina Sanelli, Alexander W. Sauter, Youngjin Yoo, Valentin Ziebandt, Dorin Comaniciu</h3>
<p>Objectives: To investigate machine-learning classifiers and interpretable
models using chest CT for detection of COVID-19 and differentiation from other
pneumonias, ILD and normal CTs.

Methods: Our retrospective multi-institutional study obtained 2096 chest CTs
from 16 institutions (including 1077 COVID-19 patients). Training/testing
cohorts included 927/100 COVID-19, 388/33 ILD, 189/33 other pneumonias, and
559/34 normal (no pathologies) CTs. A metric-based approach for classification
of COVID-19 used interpretable features, relying on logistic regression and
random forests. A deep learning-based classifier differentiated COVID-19 via 3D
features extracted directly from CT attenuation and probability distribution of
airspace opacities.

Results: Most discriminative features of COVID-19 are percentage of airspace
opacity and peripheral and basal predominant opacities, concordant with the
typical characterization of COVID-19 in the literature. Unsupervised
hierarchical clustering compares feature distribution across COVID-19 and
control cohorts. The metrics-based classifier achieved AUC=0.83,
sensitivity=0.74, and specificity=0.79 of versus respectively 0.93, 0.90, and
0.83 for the DL-based classifier. Most of ambiguity comes from non-COVID-19
pneumonia with manifestations that overlap with COVID-19, as well as mild
COVID-19 cases. Non-COVID-19 classification performance is 91% for ILD, 64% for
other pneumonias and 94% for no pathologies, which demonstrates the robustness
of our method against different compositions of control groups.

Conclusions: Our new method accurately discriminates COVID-19 from other
types of pneumonia, ILD, and no pathologies CTs, using quantitative imaging
features derived from chest CT, while balancing interpretability of results and
classification performance, and therefore may be useful to facilitate diagnosis
of COVID-19.
</p>
<a href="http://arxiv.org/abs/2006.04998" target="_blank">arXiv:2006.04998</a> [<a href="http://arxiv.org/pdf/2006.04998" target="_blank">pdf</a>]

<h2>Better Together: Resnet-50 accuracy with $13 \times$ fewer parameters and at $3\times$ speed. (arXiv:2006.05624v3 [cs.LG] UPDATED)</h2>
<h3>Utkarsh Nath, Shrinu Kushagra</h3>
<p>Recent research on compressing deep neural networks has focused on reducing
the number of parameters. Smaller networks are easier to export and deploy on
edge-devices. We introduce Adjoined networks as a training approach that can
regularize and compress any CNN-based neural architecture. Our one-shot
learning paradigm trains both the original and the smaller networks together.
The parameters of the smaller network are shared across both the architectures.
We prove strong theoretical guarantees on the regularization behavior of the
adjoint training paradigm. We complement our theoretical analysis by an
extensive empirical evaluation of both the compression and regularization
behavior of adjoint networks. For resnet-50 trained adjointly on Imagenet, we
are able to achieve a $13.7x$ reduction in the number of parameters (For size
comparison, we ignore the parameters in the last linear layer as it varies by
dataset and are typically dropped during fine-tuning. Else, the reductions are
$11.5x$ and $95x$ for imagenet and cifar-100 respectively.) and a $3x$
improvement in inference time without any significant drop in accuracy. For the
same architecture on CIFAR-100, we are able to achieve a $99.7x$ reduction in
the number of parameters and a $5x$ improvement in inference time. On both
these datasets, the original network trained in the adjoint fashion gains about
$3\%$ in top-1 accuracy as compared to the same network trained in the standard
fashion.
</p>
<a href="http://arxiv.org/abs/2006.05624" target="_blank">arXiv:2006.05624</a> [<a href="http://arxiv.org/pdf/2006.05624" target="_blank">pdf</a>]

<h2>Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning. (arXiv:2006.06119v3 [cs.CV] UPDATED)</h2>
<h3>Ruozi Huang, Huang Hu, Wei Wu, Kei Sawada, Mi Zhang, Daxin Jiang</h3>
<p>Dancing to music is one of human's innate abilities since ancient times. In
machine learning research, however, synthesizing dance movements from music is
a challenging problem. Recently, researchers synthesize human motion sequences
through autoregressive models like recurrent neural network (RNN). Such an
approach often generates short sequences due to an accumulation of prediction
errors that are fed back into the neural network. This problem becomes even
more severe in the long motion sequence generation. Besides, the consistency
between dance and music in terms of style, rhythm and beat is yet to be taken
into account during modeling. In this paper, we formalize the music-driven
dance generation as a sequence-to-sequence learning problem and devise a novel
seq2seq architecture to efficiently process long sequences of music features
and capture the fine-grained correspondence between music and dance.
Furthermore, we propose a curriculum learning strategy to alleviate error
accumulation of autoregressive models in long motion sequence generation, which
gently changes the training process from a fully guided teacher-forcing scheme
using the previous ground-truth movements, towards a less guided autoregressive
scheme mostly using the generated movements instead. Extensive experiments
demonstrate that our approach significantly outperforms the existing methods on
automatic metrics and human evaluation. The code and data are now available at
https://github.com/stonyhu/DanceRevolution.
</p>
<a href="http://arxiv.org/abs/2006.06119" target="_blank">arXiv:2006.06119</a> [<a href="http://arxiv.org/pdf/2006.06119" target="_blank">pdf</a>]

<h2>A Tailored Convolutional Neural Network for Nonlinear Manifold Learning of Computational Physics Data using Unstructured Spatial Discretizations. (arXiv:2006.06154v2 [physics.comp-ph] UPDATED)</h2>
<h3>John Tencer, Kevin Potter</h3>
<p>We propose a nonlinear manifold learning technique based on deep
convolutional autoencoders that is appropriate for model order reduction of
physical systems in complex geometries. Convolutional neural networks have
proven to be highly advantageous for compressing data arising from systems
demonstrating a slow-decaying Kolmogorov n-width. However, these networks are
restricted to data on structured meshes. Unstructured meshes are often required
for performing analyses of real systems with complex geometry. Our custom graph
convolution operators based on the available differential operators for a given
spatial discretization effectively extend the application space of deep
convolutional autoencoders to systems with arbitrarily complex geometry that
are typically discretized using unstructured meshes. We propose sets of
convolution operators based on the spatial derivative operators for the
underlying spatial discretization, making the method particularly well suited
to data arising from the solution of partial differential equations. We
demonstrate the method using examples from heat transfer and fluid mechanics
and show better than an order of magnitude improvement in accuracy over linear
methods.
</p>
<a href="http://arxiv.org/abs/2006.06154" target="_blank">arXiv:2006.06154</a> [<a href="http://arxiv.org/pdf/2006.06154" target="_blank">pdf</a>]

<h2>Task-similarity Aware Meta-learning through Nonparametric Kernel Regression. (arXiv:2006.07212v2 [cs.LG] UPDATED)</h2>
<h3>Arun Venkitaraman, Anders Hansson, Bo Wahlberg</h3>
<p>This paper investigates the use of nonparametric kernel-regression to obtain
a tasksimilarity aware meta-learning algorithm. Our hypothesis is that the use
of tasksimilarity helps meta-learning when the available tasks are limited and
may contain outlier/ dissimilar tasks. While existing meta-learning approaches
implicitly assume the tasks as being similar, it is generally unclear how this
task-similarity could be quantified and used in the learning. As a result, most
popular metalearning approaches do not actively use the
similarity/dissimilarity between the tasks, but rely on availability of huge
number of tasks for their working. Our contribution is a novel framework for
meta-learning that explicitly uses task-similarity in the form of kernels and
an associated meta-learning algorithm. We model the task-specific parameters to
belong to a reproducing kernel Hilbert space where the kernel function captures
the similarity across tasks. The proposed algorithm iteratively learns a
meta-parameter which is used to assign a task-specific descriptor for every
task. The task descriptors are then used to quantify the task-similarity
through the kernel function. We show how our approach conceptually generalizes
the popular meta-learning approaches of model-agnostic meta-learning (MAML) and
Meta-stochastic gradient descent (Meta-SGD) approaches. Numerical experiments
with regression tasks show that our algorithm outperforms these approaches when
the number of tasks is limited, even in the presence of outlier or dissimilar
tasks. This supports our hypothesis that task-similarity helps improve the
metalearning performance in task-limited and adverse settings.
</p>
<a href="http://arxiv.org/abs/2006.07212" target="_blank">arXiv:2006.07212</a> [<a href="http://arxiv.org/pdf/2006.07212" target="_blank">pdf</a>]

<h2>AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights. (arXiv:2006.08217v2 [cs.LG] UPDATED)</h2>
<h3>Byeongho Heo, Sanghyuk Chun, Seong Joon Oh, Dongyoon Han, Sangdoo Yun, Gyuwan Kim, Youngjung Uh, Jung-Woo Ha</h3>
<p>Normalization techniques are a boon for modern deep learning. They let
weights converge more quickly with often better generalization performances. It
has been argued that the normalization-induced scale invariance among the
weights provides an advantageous ground for gradient descent (GD) optimizers:
the effective step sizes are automatically reduced over time, stabilizing the
overall training procedure. It is often overlooked, however, that the
additional introduction of momentum in GD optimizers results in a far more
rapid reduction in effective step sizes for scale-invariant weights, a
phenomenon that has not yet been studied and may have caused unwanted side
effects in the current practice. This is a crucial issue because arguably the
vast majority of modern deep neural networks consist of (1) momentum-based GD
(e.g. SGD or Adam) and (2) scale-invariant parameters. In this paper, we verify
that the widely-adopted combination of the two ingredients lead to the
premature decay of effective step sizes and sub-optimal model performances. We
propose a simple and effective remedy, SGDP and AdamP: get rid of the radial
component, or the norm-increasing direction, at each optimizer step. Because of
the scale invariance, this modification only alters the effective step sizes
without changing the effective update directions, thus enjoying the original
convergence properties of GD optimizers. Given the ubiquity of momentum GD and
scale invariance in machine learning, we have evaluated our methods against the
baselines on 13 benchmarks. They range from vision tasks like classification
(e.g. ImageNet), retrieval (e.g. CUB and SOP), and detection (e.g. COCO) to
language modelling (e.g. WikiText) and audio classification (e.g. DCASE) tasks.
We verify that our solution brings about uniform gains in those benchmarks.
Source code is available at https://github.com/clovaai/AdamP.
</p>
<a href="http://arxiv.org/abs/2006.08217" target="_blank">arXiv:2006.08217</a> [<a href="http://arxiv.org/pdf/2006.08217" target="_blank">pdf</a>]

<h2>FCOS: A simple and strong anchor-free object detector. (arXiv:2006.09214v3 [cs.CV] UPDATED)</h2>
<h3>Zhi Tian, Chunhua Shen, Hao Chen, Tong He</h3>
<p>In computer vision, object detection is one of most important tasks, which
underpins a few instance-level recognition tasks and many downstream
applications. Recently one-stage methods have gained much attention over
two-stage approaches due to their simpler design and competitive performance.
Here we propose a fully convolutional one-stage object detector (FCOS) to solve
object detection in a per-pixel prediction fashion, analogue to other dense
prediction problems such as semantic segmentation. Almost all state-of-the-art
object detectors such as RetinaNet, SSD, YOLOv3, and Faster R-CNN rely on
pre-defined anchor boxes. In contrast, our proposed detector FCOS is anchor box
free, as well as proposal free. By eliminating the pre-defined set of anchor
boxes, FCOS completely avoids the complicated computation related to anchor
boxes such as calculating the intersection over union (IoU) scores during
training. More importantly, we also avoid all hyper-parameters related to
anchor boxes, which are often sensitive to the final detection performance.
With the only post-processing non-maximum suppression (NMS), we demonstrate a
much simpler and flexible detection framework achieving improved detection
accuracy. We hope that the proposed FCOS framework can serve as a simple and
strong alternative for many other instance-level tasks. Code and pre-trained
models are available at: https://git.io/AdelaiDet
</p>
<a href="http://arxiv.org/abs/2006.09214" target="_blank">arXiv:2006.09214</a> [<a href="http://arxiv.org/pdf/2006.09214" target="_blank">pdf</a>]

<h2>Prior knowledge distillation based on financial time series. (arXiv:2006.09247v4 [cs.LG] UPDATED)</h2>
<h3>Jie Fang, Jianwu Lin</h3>
<p>One of the major characteristics of financial time series is that they
contain a large amount of non-stationary noise, which is challenging for deep
neural networks. People normally use various features to address this problem.
However, the performance of these features depends on the choice of
hyper-parameters. In this paper, we propose to use neural networks to represent
these indicators and train a large network constructed of smaller networks as
feature layers to fine-tune the prior knowledge represented by the indicators.
During back propagation, prior knowledge is transferred from human logic to
machine logic via gradient descent. Prior knowledge is the deep belief of
neural network and teaches the network to not be affected by non-stationary
noise. Moreover, co-distillation is applied to distill the structure into a
much smaller size to reduce redundant features and the risk of overfitting. In
addition, the decisions of the smaller networks in terms of gradient descent
are more robust and cautious than those of large networks. In numerical
experiments, we find that our algorithm is faster and more accurate than
traditional methods on real financial datasets. We also conduct experiments to
verify and comprehend the method.
</p>
<a href="http://arxiv.org/abs/2006.09247" target="_blank">arXiv:2006.09247</a> [<a href="http://arxiv.org/pdf/2006.09247" target="_blank">pdf</a>]

<h2>A Practical Online Method for Distributionally Deep Robust Optimization. (arXiv:2006.10138v2 [cs.LG] UPDATED)</h2>
<h3>Qi Qi, Zhishuai Guo, Yi Xu, Rong Jin, Tianbao Yang</h3>
<p>In this paper, we propose a practical online method for solving a
distributionally robust optimization (DRO) for deep learning, which has
important applications in machine learning for improving the robustness of
neural networks. In the literature, most methods for solving DRO are based on
stochastic primal-dual methods. However, primal-dual methods for deep DRO
suffer from several drawbacks: (1) manipulating a high-dimensional dual
variable corresponding to the size of data is time expensive; (2) they are not
friendly to online learning where data is coming sequentially. To address these
issues, we transform the min-max formulation into a minimization formulation
and propose a practical duality-free online stochastic method for solving deep
DRO with KL divergence regularization. The proposed online stochastic method
resembles the practical stochastic Nesterov's method in several perspectives
that are widely used for learning deep neural networks. Under a
Polyak-Lojasiewicz (PL) condition, we prove that the proposed method can enjoy
an optimal sample complexity and a better round complexity (the number of
gradient evaluations divided by a fixed mini-batch size) with a moderate
mini-batch size than existing algorithms for solving the min-max or min
formulation of DRO. Of independent interest, the proposed method can be also
used for solving a family of stochastic compositional problems.
</p>
<a href="http://arxiv.org/abs/2006.10138" target="_blank">arXiv:2006.10138</a> [<a href="http://arxiv.org/pdf/2006.10138" target="_blank">pdf</a>]

<h2>Dynamic of Stochastic Gradient Descent with State-Dependent Noise. (arXiv:2006.13719v3 [cs.LG] UPDATED)</h2>
<h3>Qi Meng, Shiqi Gong, Wei Chen, Zhi-Ming Ma, Tie-Yan Liu</h3>
<p>Stochastic gradient descent (SGD) and its variants are mainstream methods to
train deep neural networks. Since neural networks are non-convex, more and more
works study the dynamic behavior of SGD and the impact to its generalization,
especially the escaping efficiency from local minima. However, these works take
the over-simplified assumption that the covariance of the noise in SGD is (or
can be upper bounded by) constant, although it is actually state-dependent. In
this work, we conduct a formal study on the dynamic behavior of SGD with
state-dependent noise. Specifically, we show that the covariance of the noise
of SGD in the local region of the local minima is a quadratic function of the
state. Thus, we propose a novel power-law dynamic with state-dependent
diffusion to approximate the dynamic of SGD. We prove that, power-law dynamic
can escape from sharp minima exponentially faster than flat minima, while the
previous dynamics can only escape sharp minima polynomially faster than flat
minima. Our experiments well verified our theoretical results. Inspired by our
theory, we propose to add additional state-dependent noise into (large-batch)
SGD to further improve its generalization ability. Experiments verify that our
method is effective.
</p>
<a href="http://arxiv.org/abs/2006.13719" target="_blank">arXiv:2006.13719</a> [<a href="http://arxiv.org/pdf/2006.13719" target="_blank">pdf</a>]

<h2>Deep Sea Robotic Imaging Simulator. (arXiv:2006.15398v2 [cs.CV] UPDATED)</h2>
<h3>Yifan Song, David Nakath, Mengkun She, Furkan Elibol, Kevin K&#xf6;ser</h3>
<p>Nowadays underwater vision systems are being widely applied in ocean
research. However, the largest portion of the ocean - the deep sea - still
remains mostly unexplored. Only relatively few image sets have been taken from
the deep sea due to the physical limitations caused by technical challenges and
enormous costs. Deep sea images are very different from the images taken in
shallow waters and this area did not get much attention from the community. The
shortage of deep sea images and the corresponding ground truth data for
evaluation and training is becoming a bottleneck for the development of
underwater computer vision methods. Thus, this paper presents a physical
model-based image simulation solution, which uses an in-air texture and depth
information as inputs, to generate underwater image sequences taken by robots
in deep ocean scenarios. Different from shallow water conditions, artificial
illumination plays a vital role in deep sea image formation as it strongly
affects the scene appearance. Our radiometric image formation model considers
both attenuation and scattering effects with co-moving spotlights in the dark.
By detailed analysis and evaluation of the underwater image formation model, we
propose a 3D lookup table structure in combination with a novel rendering
strategy to improve simulation performance. This enables us to integrate an
interactive deep sea robotic vision simulation in the Unmanned Underwater
Vehicles simulator. To inspire further deep sea vision research by the
community, we will release the source code of our deep sea image converter to
the public.
</p>
<a href="http://arxiv.org/abs/2006.15398" target="_blank">arXiv:2006.15398</a> [<a href="http://arxiv.org/pdf/2006.15398" target="_blank">pdf</a>]

<h2>Lachesis: Automated Generation of Persistent Partitionings for UDF-Centric Analytics. (arXiv:2006.16529v4 [cs.DB] UPDATED)</h2>
<h3>Jia Zou, Pratik Barhate, Amitabh Das, Arun Iyengar, Binhang Yuan, Dimitrije Jankov, Chris Jermaine</h3>
<p>Persistent partitioning is effective in avoiding expensive shuffling
operations. However it remains a significant challenge to automate this process
for Big Data analytics workloads that extensively use user defined functions
(UDFs), where sub-computations are hard to be reused for partitionings compared
to relational applications. In addition, functional dependency that is widely
utilized for partitioning selection is often unavailable in the unstructured
data that is ubiquitous in UDF-centric analytics. We propose the Lachesis
system, which represents UDF-centric workloads as workflows of analyzable and
reusable sub-computations. Lachesis further adopts a deep reinforcement
learning model to infer which sub-computations should be used to partition the
underlying data. This analysis is then applied to automatically optimize the
storage of the data across applications to improve the performance and users'
productivity.
</p>
<a href="http://arxiv.org/abs/2006.16529" target="_blank">arXiv:2006.16529</a> [<a href="http://arxiv.org/pdf/2006.16529" target="_blank">pdf</a>]

<h2>Early Exit or Not: Resource-Efficient Blind Quality Enhancement for Compressed Images. (arXiv:2006.16581v5 [eess.IV] UPDATED)</h2>
<h3>Qunliang Xing, Mai Xu, Tianyi Li, Zhenyu Guan</h3>
<p>Lossy image compression is pervasively conducted to save communication
bandwidth, resulting in undesirable compression artifacts. Recently, extensive
approaches have been proposed to reduce image compression artifacts at the
decoder side; however, they require a series of architecture-identical models
to process images with different quality, which are inefficient and
resource-consuming. Besides, it is common in practice that compressed images
are with unknown quality and it is intractable for existing approaches to
select a suitable model for blind quality enhancement. In this paper, we
propose a resource-efficient blind quality enhancement (RBQE) approach for
compressed images. Specifically, our approach blindly and progressively
enhances the quality of compressed images through a dynamic deep neural network
(DNN), in which an early-exit strategy is embedded. Then, our approach can
automatically decide to terminate or continue enhancement according to the
assessed quality of enhanced images. Consequently, slight artifacts can be
removed in a simpler and faster process, while the severe artifacts can be
further removed in a more elaborate process. Extensive experiments demonstrate
that our RBQE approach achieves state-of-the-art performance in terms of both
blind quality enhancement and resource efficiency. The code is available at
https://github.com/RyanXingQL/RBQE.
</p>
<a href="http://arxiv.org/abs/2006.16581" target="_blank">arXiv:2006.16581</a> [<a href="http://arxiv.org/pdf/2006.16581" target="_blank">pdf</a>]

<h2>Adaptive SpMV/SpMSpV on GPUs for Input Vectors of Varied Sparsity. (arXiv:2006.16767v2 [cs.DC] UPDATED)</h2>
<h3>Min Li, Yulong Ao, Chao Yang</h3>
<p>Despite numerous efforts for optimizing the performance of Sparse Matrix and
Vector Multiplication (SpMV) on modern hardware architectures, few works are
done to its sparse counterpart, Sparse Matrix and Sparse Vector Multiplication
(SpMSpV), not to mention dealing with input vectors of varied sparsity. The key
challenge is that depending on the sparsity levels, distribution of data, and
compute platform, the optimal choice of SpMV/SpMSpV kernel can vary, and a
static choice does not suffice. In this paper, we propose an adaptive
SpMV/SpMSpV framework, which can automatically select the appropriate
SpMV/SpMSpV kernel on GPUs for any sparse matrix and vector at the runtime.
Based on systematic analysis on key factors such as computing pattern, workload
distribution and write-back strategy, eight candidate SpMV/SpMSpV kernels are
encapsulated into the framework to achieve high performance in a seamless
manner. A comprehensive study on machine learning based kernel selector is
performed to choose the kernel and adapt with the varieties of both the input
and hardware from both accuracy and overhead perspectives. Experiments
demonstrate that the adaptive framework can substantially outperform the
previous state-of-the-art in real-world applications on NVIDIA Tesla K40m, P100
and V100 GPUs.
</p>
<a href="http://arxiv.org/abs/2006.16767" target="_blank">arXiv:2006.16767</a> [<a href="http://arxiv.org/pdf/2006.16767" target="_blank">pdf</a>]

<h2>Explainable Deep One-Class Classification. (arXiv:2007.01760v2 [cs.CV] UPDATED)</h2>
<h3>Philipp Liznerski, Lukas Ruff, Robert A. Vandermeulen, Billy Joe Franks, Marius Kloft, Klaus-Robert M&#xfc;ller</h3>
<p>Deep one-class classification variants for anomaly detection learn a mapping
that concentrates nominal samples in feature space causing anomalies to be
mapped away. Because this transformation is highly non-linear, finding
interpretations poses a significant challenge. In this paper we present an
explainable deep one-class classification method, Fully Convolutional Data
Description (FCDD), where the mapped samples are themselves also an explanation
heatmap. FCDD yields competitive detection performance and provides reasonable
explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet.
On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps,
FCDD sets a new state of the art in the unsupervised setting. Our method can
incorporate ground-truth anomaly maps during training and using even a few of
these (~5) improves performance significantly. Finally, using FCDD's
explanations we demonstrate the vulnerability of deep one-class classification
models to spurious image features such as image watermarks.
</p>
<a href="http://arxiv.org/abs/2007.01760" target="_blank">arXiv:2007.01760</a> [<a href="http://arxiv.org/pdf/2007.01760" target="_blank">pdf</a>]

<h2>An Elastic Interaction-Based Loss Function for Medical Image Segmentation. (arXiv:2007.02663v2 [eess.IV] UPDATED)</h2>
<h3>Yuan Lan, Yang Xiang, Luchan Zhang</h3>
<p>Deep learning techniques have shown their success in medical image
segmentation since they are easy to manipulate and robust to various types of
datasets. The commonly used loss functions in the deep segmentation task are
pixel-wise loss functions. This results in a bottleneck for these models to
achieve high precision for complicated structures in biomedical images. For
example, the predicted small blood vessels in retinal images are often
disconnected or even missed under the supervision of the pixel-wise losses.
This paper addresses this problem by introducing a long-range elastic
interaction-based training strategy. In this strategy, convolutional neural
network (CNN) learns the target region under the guidance of the elastic
interaction energy between the boundary of the predicted region and that of the
actual object. Under the supervision of the proposed loss, the boundary of the
predicted region is attracted strongly by the object boundary and tends to stay
connected. Experimental results show that our method is able to achieve
considerable improvements compared to commonly used pixel-wise loss functions
(cross entropy and dice Loss) and other recent loss functions on three retinal
vessel segmentation datasets, DRIVE, STARE and CHASEDB1.
</p>
<a href="http://arxiv.org/abs/2007.02663" target="_blank">arXiv:2007.02663</a> [<a href="http://arxiv.org/pdf/2007.02663" target="_blank">pdf</a>]

<h2>Identifying Latent Stochastic Differential Equations with Variational Auto-Encoders. (arXiv:2007.06075v2 [stat.ML] UPDATED)</h2>
<h3>Ali Hasan, Jo&#xe3;o M. Pereira, Sina Farsiu, Vahid Tarokh</h3>
<p>We present a method for learning latent stochastic differential equations
(SDEs) from high dimensional time series data. Given a time series generated
from a lower dimensional It\^{o} process, the proposed method uncovers the
relevant parameters of the SDE through a self-supervised learning approach.
Using the framework of variational autoencoders (VAEs), we consider a
conditional generative model for the data based on the Euler-Maruyama
approximation of SDE solutions. Furthermore, we use recent results on
identifiability of semi-supervised learning to show that our model can recover
not only the underlying SDE parameters, but also the original latent space, up
to an isometry, in the limit of infinite data. We validate the model through a
series of different simulated video processing tasks where the underlying SDE
is known. Our results suggest that the proposed method effectively learns the
underlying SDE, as predicted by the theory.
</p>
<a href="http://arxiv.org/abs/2007.06075" target="_blank">arXiv:2007.06075</a> [<a href="http://arxiv.org/pdf/2007.06075" target="_blank">pdf</a>]

<h2>GeoStat Representations of Time Series for Fast Classification. (arXiv:2007.06682v2 [cs.LG] UPDATED)</h2>
<h3>Robert J. Ravier, Mohammadreza Soltani, Miguel Sim&#xf5;es, Denis Garagic, Vahid Tarokh</h3>
<p>Recent advances in time series classification have largely focused on methods
that either employ deep learning or utilize other machine learning models for
feature extraction. Though successful, their power often comes at the
requirement of computational complexity. In this paper, we introduce GeoStat
representations for time series. GeoStat representations are based off of a
generalization of recent methods for trajectory classification, and summarize
the information of a time series in terms of comprehensive statistics of
(possibly windowed) distributions of easy to compute differential geometric
quantities, requiring no dynamic time warping. The features used are intuitive
and require minimal parameter tuning. We perform an exhaustive evaluation of
GeoStat on a number of real datasets, showing that simple KNN and SVM
classifiers trained on these representations exhibit surprising performance
relative to modern single model methods requiring significant computational
power, achieving state of the art results in many cases. In particular, we show
that this methodology achieves good performance on a challenging dataset
involving the classification of fishing vessels, where our methods achieve good
performance relative to the state of the art despite only having access to
approximately two percent of the dataset used in training and evaluating this
state of the art.
</p>
<a href="http://arxiv.org/abs/2007.06682" target="_blank">arXiv:2007.06682</a> [<a href="http://arxiv.org/pdf/2007.06682" target="_blank">pdf</a>]

<h2>Vehicle Trajectory Prediction by Transfer Learning of Semi-Supervised Models. (arXiv:2007.06781v2 [cs.CV] UPDATED)</h2>
<h3>Nick Lamm, Shashank Jaiprakash, Malavika Srikanth, Iddo Drori</h3>
<p>In this work we show that semi-supervised models for vehicle trajectory
prediction significantly improve performance over supervised models on
state-of-the-art real-world benchmarks. Moving from supervised to
semi-supervised models allows scaling-up by using unlabeled data, increasing
the number of images in pre-training from Millions to a Billion. We perform
ablation studies comparing transfer learning of semi-supervised and supervised
models while keeping all other factors equal. Within semi-supervised models we
compare contrastive learning with teacher-student methods as well as networks
predicting a small number of trajectories with networks predicting
probabilities over a large trajectory set. Our results using both low-level and
mid-level representations of the driving environment demonstrate the
applicability of semi-supervised methods for real-world vehicle trajectory
prediction.
</p>
<a href="http://arxiv.org/abs/2007.06781" target="_blank">arXiv:2007.06781</a> [<a href="http://arxiv.org/pdf/2007.06781" target="_blank">pdf</a>]

<h2>Disturbance Decoupling for Gradient-based Multi-Agent Learning with Quadratic Costs. (arXiv:2007.07228v2 [cs.GT] UPDATED)</h2>
<h3>Sarah H. Q. Li, Lillian Ratliff, Beh&#xe7;et A&#xe7;&#x131;kme&#x15f;e</h3>
<p>Motivated by applications of multi-agent learning in noisy environments, this
paper studies the robustness of gradient-based learning dynamics with respect
to disturbances. While disturbances injected along a coordinate corresponding
to any individual player's actions can always affect the overall learning
dynamics, a subset of players can be disturbance decoupled---i.e., such
players' actions are completely unaffected by the injected disturbance. We
provide necessary and sufficient conditions to guarantee this property for
games with quadratic cost functions, which encompass quadratic one-shot
continuous games, finite-horizon linear quadratic (LQ) dynamic games, and
bilinear games. Specifically, disturbance decoupling is characterized by both
algebraic and graph-theoretic conditions on the learning dynamics, the latter
is obtained by constructing a game graph based on gradients of players' costs.
For LQ games, we show that disturbance decoupling imposes constraints on the
controllable and unobservable subspaces of players. For two player bilinear
games, we show that disturbance decoupling within a player's action coordinates
imposes constraints on the payoff matrices. Illustrative numerical examples are
provided.
</p>
<a href="http://arxiv.org/abs/2007.07228" target="_blank">arXiv:2007.07228</a> [<a href="http://arxiv.org/pdf/2007.07228" target="_blank">pdf</a>]

<h2>Self-Supervised Representation Learning for Detection of ACL Tear Injury in Knee MRI. (arXiv:2007.07761v2 [cs.CV] UPDATED)</h2>
<h3>Siladittya Manna, Saumik Bhattacharya, Umapada Pal</h3>
<p>The success and efficiency of Deep Learning based models for computer vision
applications require large scale human annotated data which are often expensive
to generate. Self-supervised learning, a subset of unsupervised learning,
handles this problem by learning meaningful features from unlabeled image or
video data. In this paper, we propose a self-supervised learning approach to
learn transferable features from MRI clips by enforcing the model to learn
anatomical features. The pretext task models are designed to predict the
correct ordering of the jumbled image patches that the MRI frames are divided
into. To the best of our knowledge, none of the supervised learning models
performing injury classification task from MRI frames, provide any explanations
for the decisions made by the models, making our work the first of its kind on
MRI data. Experiments on the pretext task show that this proposed approach
enables the model to learn spatial context invariant features which helps in
reliable and explainable performance in downstream tasks like classification of
ACL tear injury from knee MRI. The efficiency of the novel Convolutional Neural
Network proposed in this paper is reflected in the experimental results
obtained in the downstream task.
</p>
<a href="http://arxiv.org/abs/2007.07761" target="_blank">arXiv:2007.07761</a> [<a href="http://arxiv.org/pdf/2007.07761" target="_blank">pdf</a>]

<h2>Unsupervised anomaly detection for discrete sequence healthcare data. (arXiv:2007.10098v2 [cs.LG] UPDATED)</h2>
<h3>Victoria Snorovikhina, Alexey Zaytsev</h3>
<p>Fraud in healthcare is widespread, as doctors could prescribe unnecessary
treatments to increase bills. Insurance companies want to detect these
anomalous fraudulent bills and reduce their losses. Traditional fraud detection
methods use expert rules and manual data processing.

Recently, machine learning techniques automate this process, but hand-labeled
data is extremely costly and usually out of date. We propose a machine learning
model that automates fraud detection in an unsupervised way. Two deep learning
approaches include LSTM neural network for prediction next patient visit and a
seq2seq model. For normalization of produced anomaly scores, we propose
Empirical Distribution Function (EDF) approach. So, the algorithm works with
high class imbalance problems.

We use real data on sequences of patients' visits data from Allianz company
for the validation. The models provide state-of-the-art results for
unsupervised anomaly detection for fraud detection in healthcare. Our EDF
approach further improves the quality of LSTM model.
</p>
<a href="http://arxiv.org/abs/2007.10098" target="_blank">arXiv:2007.10098</a> [<a href="http://arxiv.org/pdf/2007.10098" target="_blank">pdf</a>]

<h2>Balanced Meta-Softmax for Long-Tailed Visual Recognition. (arXiv:2007.10740v2 [cs.LG] UPDATED)</h2>
<h3>Jiawei Ren, Cunjun Yu, Shunan Sheng, Xiao Ma, Haiyu Zhao, Shuai Yi, Hongsheng Li</h3>
<p>Deep classifiers have achieved great success in visual recognition. However,
real-world data is long-tailed by nature, leading to the mismatch between
training and testing distributions. In this paper, we show that Softmax
function, though used in most classification tasks, gives a biased gradient
estimation under the long-tailed setup. This paper presents Balanced Softmax,
an elegant unbiased extension of Softmax, to accommodate the label distribution
shift between training and testing. Theoretically, we derive the generalization
bound for multiclass Softmax regression and show our loss minimizes the bound.
In addition, we introduce Balanced Meta-Softmax, applying a complementary Meta
Sampler to estimate the optimal class sample rate and further improve
long-tailed learning. In our experiments, we demonstrate that Balanced
Meta-Softmax outperforms state-of-the-art long-tailed classification solutions
on both visual recognition and instance segmentation tasks.
</p>
<a href="http://arxiv.org/abs/2007.10740" target="_blank">arXiv:2007.10740</a> [<a href="http://arxiv.org/pdf/2007.10740" target="_blank">pdf</a>]

<h2>A finite sample analysis of the double descent phenomenon for ridge function estimation. (arXiv:2007.12882v2 [stat.ML] UPDATED)</h2>
<h3>Emmanuel Caron, Stephane Chretien</h3>
<p>Recent extensive numerical experiments in high scale machine learning have
allowed to uncover a quite counterintuitive phase transition, as a function of
the ratio between the sample size and the number of parameters in the model. As
the number of parameters $p$ approaches the sample size $n$, the generalisation
error (a.k.a. testing error) increases, but it many cases, it starts decreasing
again past the threshold $p=n$. This surprising phenomenon, brought to the
theoretical community attention in \cite{belkin2019reconciling}, has been
thorougly investigated lately, more specifically for simpler models than deep
neural networks, such as the linear model when the parameter is taken to be the
minimum norm solution to the least-square problem, mostly in the asymptotic
regime when $p$ and $n$ tend to $+\infty$; see e.g. \cite{hastie2019surprises}.
In the present paper, we propose a finite sample analysis of non-linear models
of \textit{ridge} type, where we investigate the double descent phenomenon for
both the \textit{estimation problem} and the prediction problem. Our results
show that the double descent phenomenon can be precisely demonstrated in
non-linear settings and complements recent works of \cite{bartlett2020benign}
and \cite{chinot2020benign}. Our analysis is based on efficient but elementary
tools closely related to the continuous Newton method
\cite{neuberger2007continuous}.
</p>
<a href="http://arxiv.org/abs/2007.12882" target="_blank">arXiv:2007.12882</a> [<a href="http://arxiv.org/pdf/2007.12882" target="_blank">pdf</a>]

<h2>Fast active learning for pure exploration in reinforcement learning. (arXiv:2007.13442v2 [cs.LG] UPDATED)</h2>
<h3>Pierre M&#xe9;nard, Omar Darwiche Domingues, Anders Jonsson, Emilie Kaufmann, Edouard Leurent, Michal Valko</h3>
<p>Realistic environments often provide agents with very limited feedback. When
the environment is initially unknown, the feedback, in the beginning, can be
completely absent, and the agents may first choose to devote all their effort
on exploring efficiently. The exploration remains a challenge while it has been
addressed with many hand-tuned heuristics with different levels of generality
on one side, and a few theoretically-backed exploration strategies on the
other. Many of them are incarnated by intrinsic motivation and in particular
explorations bonuses. A common rule of thumb for exploration bonuses is to use
$1/\sqrt{n}$ bonus that is added to the empirical estimates of the reward,
where $n$ is a number of times this particular state (or a state-action pair)
was visited. We show that, surprisingly, for a pure-exploration objective of
reward-free exploration, bonuses that scale with $1/n$ bring faster learning
rates, improving the known upper bounds with respect to the dependence on the
horizon $H$. Furthermore, we show that with an improved analysis of the
stopping time, we can improve by a factor $H$ the sample complexity in the
best-policy identification setting, which is another pure-exploration
objective, where the environment provides rewards but the agent is not
penalized for its behavior during the exploration phase.
</p>
<a href="http://arxiv.org/abs/2007.13442" target="_blank">arXiv:2007.13442</a> [<a href="http://arxiv.org/pdf/2007.13442" target="_blank">pdf</a>]

<h2>MADGAN: unsupervised Medical Anomaly Detection GAN using multiple adjacent brain MRI slice reconstruction. (arXiv:2007.13559v2 [cs.CV] UPDATED)</h2>
<h3>Changhee Han, Leonardo Rundo, Kohei Murao, Tomoyuki Noguchi, Yuki Shimahara, Zoltan Adam Milacski, Saori Koshino, Evis Sala, Hideki Nakayama, Shinichi Satoh</h3>
<p>Unsupervised learning can discover various unseen abnormalities, relying on
large-scale unannotated medical images of healthy subjects. Towards this,
unsupervised methods reconstruct a 2D/3D single medical image to detect
outliers either in the learned feature space or from high reconstruction loss.
However, without considering continuity between multiple adjacent slices, they
cannot directly discriminate diseases composed of the accumulation of subtle
anatomical anomalies, such as Alzheimer's Disease (AD). Moreover, no study has
shown how unsupervised anomaly detection is associated with either disease
stages, various (i.e., more than two types of) diseases, or multi-sequence
Magnetic Resonance Imaging (MRI) scans. Therefore, we propose unsupervised
Medical Anomaly Detection Generative Adversarial Network (MADGAN), a novel
two-step method using GAN-based multiple adjacent brain MRI slice
reconstruction to detect brain anomalies at different stages on multi-sequence
structural MRI: (Reconstruction) Wasserstein loss with Gradient Penalty + 100
L1 loss-trained on 3 healthy brain axial MRI slices to reconstruct the next 3
ones-reconstructs unseen healthy/abnormal scans; (Diagnosis) Average L2 loss
per scan discriminates them, comparing the ground truth/reconstructed slices.
For training, we use two different datasets composed of 1,133 healthy
T1-weighted (T1) and 135 healthy contrast-enhanced T1 (T1c) brain MRI scans for
detecting AD and brain metastases/various diseases, respectively. Our
Self-Attention MADGAN can detect AD on T1 scans at a very early stage, Mild
Cognitive Impairment (MCI), with Area Under the Curve (AUC) 0.727, and AD at a
late stage with AUC 0.894, while detecting brain metastases on T1c scans with
AUC 0.921.
</p>
<a href="http://arxiv.org/abs/2007.13559" target="_blank">arXiv:2007.13559</a> [<a href="http://arxiv.org/pdf/2007.13559" target="_blank">pdf</a>]

<h2>RGB-D Salient Object Detection: A Survey. (arXiv:2008.00230v2 [cs.CV] UPDATED)</h2>
<h3>Tao Zhou, Deng-Ping Fan, Ming-Ming Cheng, Jianbing Shen, Ling Shao</h3>
<p>Salient object detection (SOD), which simulates the human visual perception
system to locate the most attractive object(s) in a scene, has been widely
applied to various computer vision tasks. Now, with the advent of depth
sensors, depth maps with affluent spatial information that can be beneficial in
boosting the performance of SOD, can easily be captured. Although various RGB-D
based SOD models with promising performance have been proposed over the past
several years, an in-depth understanding of these models and challenges in this
topic remains lacking. In this paper, we provide a comprehensive survey of
RGB-D based SOD models from various perspectives, and review related benchmark
datasets in detail. Further, considering that the light field can also provide
depth maps, we review SOD models and popular benchmark datasets from this
domain as well. Moreover, to investigate the SOD ability of existing models, we
carry out a comprehensive evaluation, as well as attribute-based evaluation of
several representative RGB-D based SOD models. Finally, we discuss several
challenges and open directions of RGB-D based SOD for future research. All
collected models, benchmark datasets, source code links, datasets constructed
for attribute-based evaluation, and codes for evaluation will be made publicly
available at https://github.com/taozh2017/RGBDSODsurvey
</p>
<a href="http://arxiv.org/abs/2008.00230" target="_blank">arXiv:2008.00230</a> [<a href="http://arxiv.org/pdf/2008.00230" target="_blank">pdf</a>]

<h2>A Survey on Text Classification: From Shallow to Deep Learning. (arXiv:2008.00364v3 [cs.CL] UPDATED)</h2>
<h3>Qian Li, Hao Peng, Jianxin Li, Congyin Xia, Renyu Yang, Lichao Sun, Philip S. Yu, Lifang He</h3>
<p>Text classification is the most fundamental and essential task in natural
language processing. The last decade has seen a surge of research in this area
due to the unprecedented success of deep learning. Numerous methods, datasets,
and evaluation metrics have been proposed in the literature, raising the need
for a comprehensive and updated survey. This paper fills the gap by reviewing
the state of the art approaches from 1961 to 2020, focusing on models from
shallow to deep learning. We create a taxonomy for text classification
according to the text involved and the models used for feature extraction and
classification. We then discuss each of these categories in detail, dealing
with both the technical developments and benchmark datasets that support tests
of predictions. A comprehensive comparison between different techniques, as
well as identifying the pros and cons of various evaluation metrics are also
provided in this survey. Finally, we conclude by summarizing key implications,
future research directions, and the challenges facing the research area.
</p>
<a href="http://arxiv.org/abs/2008.00364" target="_blank">arXiv:2008.00364</a> [<a href="http://arxiv.org/pdf/2008.00364" target="_blank">pdf</a>]

<h2>Graph Convolution with Low-rank Learnable Local Filters. (arXiv:2008.01818v2 [stat.ML] UPDATED)</h2>
<h3>Xiuyuan Cheng, Zichen Miao, Qiang Qiu</h3>
<p>Geometric variations like rotation, scaling, and viewpoint changes pose a
significant challenge to visual understanding. One common solution is to
directly model certain intrinsic structures, e.g., using landmarks. However, it
then becomes non-trivial to build effective deep models, especially when the
underlying non-Euclidean grid is irregular and coarse. Recent deep models using
graph convolutions provide an appropriate framework to handle such
non-Euclidean data, but many of them, particularly those based on global graph
Laplacians, lack expressiveness to capture local features required for
representation of signals lying on the non-Euclidean grid. The current paper
introduces a new type of graph convolution with learnable low-rank local
filters, which is provably more expressive than previous spectral graph
convolution methods. The model also provides a unified framework for both
spectral and spatial graph convolutions. To improve model robustness,
regularization by local graph Laplacians is introduced. The representation
stability against input graph data perturbation is theoretically proved, making
use of the graph filter locality and the local graph regularization.
Experiments on spherical mesh data, real-world facial expression
recognition/skeleton-based action recognition data, and data with simulated
graph noise show the empirical advantage of the proposed model.
</p>
<a href="http://arxiv.org/abs/2008.01818" target="_blank">arXiv:2008.01818</a> [<a href="http://arxiv.org/pdf/2008.01818" target="_blank">pdf</a>]

<h2>OpenStreetMap data use cases during the early months of the COVID-19 pandemic. (arXiv:2008.02653v2 [cs.CY] UPDATED)</h2>
<h3>Peter Mooney, A. Yair Grinberger, Marco Minghini, Serena Coetzee, Levente Juhasz, Godwin Yeboah</h3>
<p>Created by volunteers since 2004, OpenStreetMap (OSM) is a global geographic
database available under an open access license and currently used by a
multitude of actors worldwide. This chapter describes the role played by OSM
during the early months (from January to July 2020) of the ongoing COVID-19
pandemic, which - in contrast to past disasters and epidemics - is a global
event impacting both developed and developing countries. A large number of
COVID-19-related OSM use cases were collected and grouped into a number of
research frameworks which are analyzed separately: dashboards and services
simply using OSM as a basemap, applications using raw OSM data, initiatives to
collect new OSM data, imports of authoritative data into OSM, and traditional
academic research on OSM in the COVID-19 response. The wealth of examples
provided in the chapter, including an analysis of OSM tile usage in two
countries (Italy and China) deeply affected in the earliest months of 2020,
prove that OSM has been and still is heavily used to address the COVID-19
crisis, although with types and mechanisms that are often different depending
on the affected area or country and the related communities.
</p>
<a href="http://arxiv.org/abs/2008.02653" target="_blank">arXiv:2008.02653</a> [<a href="http://arxiv.org/pdf/2008.02653" target="_blank">pdf</a>]

<h2>Spacecraft Collision Avoidance Challenge: design and results of a machine learning competition. (arXiv:2008.03069v2 [cs.LG] UPDATED)</h2>
<h3>Thomas Uriot, Dario Izzo, Lu&#xed;s F. Sim{&#xf5;}es, Rasit Abay, Nils Einecke, Sven Rebhan, Jose Martinez-Heras, Francesca Letizia, Jan Siminski, Klaus Merz</h3>
<p>Spacecraft collision avoidance procedures have become an essential part of
satellite operations. Complex and constantly updated estimates of the collision
risk between orbiting objects inform the various operators who can then plan
risk mitigation measures. Such measures could be aided by the development of
suitable machine learning models predicting, for example, the evolution of the
collision risk in time. In an attempt to study this opportunity, the European
Space Agency released, in October 2019, a large curated dataset containing
information about close approach events, in the form of Conjunction Data
Messages (CDMs), collected from 2015 to 2019. This dataset was used in the
Spacecraft Collision Avoidance Challenge, a machine learning competition where
participants had to build models to predict the final collision risk between
orbiting objects. This paper describes the design and results of the
competition and discusses the challenges and lessons learned when applying
machine learning methods to this problem domain.
</p>
<a href="http://arxiv.org/abs/2008.03069" target="_blank">arXiv:2008.03069</a> [<a href="http://arxiv.org/pdf/2008.03069" target="_blank">pdf</a>]

<h2>Deep learning for photoacoustic imaging: a survey. (arXiv:2008.04221v2 [cs.CV] UPDATED)</h2>
<h3>Changchun Yang, Hengrong Lan, Feng Gao, Fei Gao</h3>
<p>Machine learning has been developed dramatically and witnessed a lot of
applications in various fields over the past few years. This boom originated in
2009, when a new model emerged, that is, the deep artificial neural network,
which began to surpass other established mature models on some important
benchmarks. Later, it was widely used in academia and industry. Ranging from
image analysis to natural language processing, it fully exerted its magic and
now become the state-of-the-art machine learning models. Deep neural networks
have great potential in medical imaging technology, medical data analysis,
medical diagnosis and other healthcare issues, and is promoted in both
pre-clinical and even clinical stages. In this review, we performed an overview
of some new developments and challenges in the application of machine learning
to medical image analysis, with a special focus on deep learning in
photoacoustic imaging. The aim of this review is threefold: (i) introducing
deep learning with some important basics, (ii) reviewing recent works that
apply deep learning in the entire ecological chain of photoacoustic imaging,
from image reconstruction to disease diagnosis, (iii) providing some open
source materials and other resources for researchers interested in applying
deep learning to photoacoustic imaging.
</p>
<a href="http://arxiv.org/abs/2008.04221" target="_blank">arXiv:2008.04221</a> [<a href="http://arxiv.org/pdf/2008.04221" target="_blank">pdf</a>]

<h2>AIPerf: Automated machine learning as an AI-HPC benchmark. (arXiv:2008.07141v5 [cs.DC] UPDATED)</h2>
<h3>Zhixiang Ren, Yongheng Liu, Tianhui Shi, Lei Xie, Yue Zhou, Jidong Zhai, Youhui Zhang, Yunquan Zhang, Wenguang Chen</h3>
<p>The plethora of complex artificial intelligence (AI) algorithms and available
high performance computing (HPC) power stimulates the expeditious development
of AI components in both hardware and software domains. Existing HPC and AI
benchmarks fail to cover the variety of heterogeneous systems while providing a
simple yet comprehensive measurement of the cross-stack performance. To address
the challenges, we propose an end-to-end benchmark suite utilizing automated
machine learning (AutoML) as a representative AI application. The extreme
computational cost and scalability make AutoML a desired workload for
benchmarking AI-HPC. We implement the algorithms in a highly parallel and
flexible way to ensure the efficiency and customizability of diverse systems.
The major metric to quantify the system performance is floating-point
operations per second (FLOPS), which is measured in a systematic and analytical
approach. We verify the benchmark's stability at discrete timestamps on
different types and scales of machines equipped with up to 400 AI accelerators.
Our evaluation shows the benchmark has near-optimal speedup and the scores
scale linearly with the number of machines to reflect the overall computing
power on AI. The source code, specifications and detailed procedures are
publicly accessible on GitHub.
</p>
<a href="http://arxiv.org/abs/2008.07141" target="_blank">arXiv:2008.07141</a> [<a href="http://arxiv.org/pdf/2008.07141" target="_blank">pdf</a>]

<h2>Visual Analytics for Temporal Hypergraph Model Exploration. (arXiv:2008.07299v2 [cs.HC] UPDATED)</h2>
<h3>Maximilian T. Fischer, Devanshu Arya, Dirk Streeb, Daniel Seebacher, Daniel A. Keim, Marcel Worring</h3>
<p>Many processes, from gene interaction in biology to computer networks to
social media, can be modeled more precisely as temporal hypergraphs than by
regular graphs. This is because hypergraphs generalize graphs by extending
edges to connect any number of vertices, allowing complex relationships to be
described more accurately and predict their behavior over time. However, the
interactive exploration and seamless refinement of such hypergraph-based
prediction models still pose a major challenge. We contribute Hyper-Matrix, a
novel visual analytics technique that addresses this challenge through a tight
coupling between machine-learning and interactive visualizations. In
particular, the technique incorporates a geometric deep learning model as a
blueprint for problem-specific models while integrating visualizations for
graph-based and category-based data with a novel combination of interactions
for an effective user-driven exploration of hypergraph models. To eliminate
demanding context switches and ensure scalability, our matrix-based
visualization provides drill-down capabilities across multiple levels of
semantic zoom, from an overview of model predictions down to the content. We
facilitate a focused analysis of relevant connections and groups based on
interactive user-steering for filtering and search tasks, a dynamically
modifiable partition hierarchy, various matrix reordering techniques, and
interactive model feedback. We evaluate our technique in a case study and
through formative evaluation with law enforcement experts using real-world
internet forum communication data. The results show that our approach surpasses
existing solutions in terms of scalability and applicability, enables the
incorporation of domain knowledge, and allows for fast search-space traversal.
With the technique, we pave the way for the visual analytics of temporal
hypergraphs in a wide variety of domains.
</p>
<a href="http://arxiv.org/abs/2008.07299" target="_blank">arXiv:2008.07299</a> [<a href="http://arxiv.org/pdf/2008.07299" target="_blank">pdf</a>]

<h2>An Experimental Study of Deep Neural Network Models for Vietnamese Multiple-Choice Reading Comprehension. (arXiv:2008.08810v2 [cs.CL] UPDATED)</h2>
<h3>Son T. Luu, Kiet Van Nguyen, Anh Gia-Tuan Nguyen, Ngan Luu-Thuy Nguyen</h3>
<p>Machine reading comprehension (MRC) is a challenging task in natural language
processing that makes computers understanding natural language texts and answer
questions based on those texts. There are many techniques for solving this
problems, and word representation is a very important technique that impact
most to the accuracy of machine reading comprehension problem in the popular
languages like English and Chinese. However, few studies on MRC have been
conducted in low-resource languages such as Vietnamese. In this paper, we
conduct several experiments on neural network-based model to understand the
impact of word representation to the Vietnamese multiple-choice machine reading
comprehension. Our experiments include using the Co-match model on six
different Vietnamese word embeddings and the BERT model for multiple-choice
reading comprehension. On the ViMMRC corpus, the accuracy of BERT model is
61.28% on test set.
</p>
<a href="http://arxiv.org/abs/2008.08810" target="_blank">arXiv:2008.08810</a> [<a href="http://arxiv.org/pdf/2008.08810" target="_blank">pdf</a>]

<h2>Assessment of Reward Functions for Reinforcement Learning Traffic Signal Control under Real-World Limitations. (arXiv:2008.11634v2 [cs.AI] UPDATED)</h2>
<h3>Alvaro Cabrejas-Egea, Shaun Howell, Maksis Knutins, Colm Connaughton</h3>
<p>Adaptive traffic signal control is one key avenue for mitigating the growing
consequences of traffic congestion. Incumbent solutions such as SCOOT and SCATS
require regular and time-consuming calibration, can't optimise well for
multiple road use modalities, and require the manual curation of many
implementation plans. A recent alternative to these approaches are deep
reinforcement learning algorithms, in which an agent learns how to take the
most appropriate action for a given state of the system. This is guided by
neural networks approximating a reward function that provides feedback to the
agent regarding the performance of the actions taken, making it sensitive to
the specific reward function chosen. Several authors have surveyed the reward
functions used in the literature, but attributing outcome differences to reward
function choice across works is problematic as there are many uncontrolled
differences, as well as different outcome metrics. This paper compares the
performance of agents using different reward functions in a simulation of a
junction in Greater Manchester, UK, across various demand profiles, subject to
real world constraints: realistic sensor inputs, controllers, calibrated
demand, intergreen times and stage sequencing. The reward metrics considered
are based on the time spent stopped, lost time, change in lost time, average
speed, queue length, junction throughput and variations of these magnitudes.
The performance of these reward functions is compared in terms of total waiting
time. We find that speed maximisation resulted in the lowest average waiting
times across all demand levels, displaying significantly better performance
than other rewards previously introduced in the literature.
</p>
<a href="http://arxiv.org/abs/2008.11634" target="_blank">arXiv:2008.11634</a> [<a href="http://arxiv.org/pdf/2008.11634" target="_blank">pdf</a>]

<h2>Continual Prototype Evolution: Learning Online from Non-Stationary Data Streams. (arXiv:2009.00919v2 [cs.CV] UPDATED)</h2>
<h3>Matthias De Lange, Tinne Tuytelaars</h3>
<p>Attaining prototypical features to represent class distributions is well
established in representation learning. However, learning prototypes online
from streams of data proves a challenging endeavor as they rapidly become
outdated, caused by an ever-changing parameter space in the learning process.
Additionally, continual learning does not assume the data stream to be
stationary, typically resulting in catastrophic forgetting of previous
knowledge. As a first, we introduce a system addressing both problems, where
prototypes evolve continually in a shared latent space, enabling learning and
prediction at any point in time. In contrast to the major body of work in
continual learning, data streams are processed in an online fashion, without
additional task-information, and an efficient memory scheme provides robustness
to imbalanced data streams. Besides nearest neighbor based prediction, learning
is facilitated by a novel objective function, encouraging cluster density about
the class prototype and increased inter-class variance. Furthermore, the latent
space quality is elevated by pseudo-prototypes in each batch, constituted by
replay of exemplars from memory. We generalize the existing paradigms in
continual learning to incorporate data incremental learning from data streams
by formalizing a two-agent learner-evaluator framework, and obtain
state-of-the-art performance by a significant margin on eight benchmarks,
including three highly imbalanced data streams.
</p>
<a href="http://arxiv.org/abs/2009.00919" target="_blank">arXiv:2009.00919</a> [<a href="http://arxiv.org/pdf/2009.00919" target="_blank">pdf</a>]

<h2>Driving Tasks Transfer in Deep Reinforcement Learning for Decision-making of Autonomous Vehicles. (arXiv:2009.03268v2 [cs.AI] UPDATED)</h2>
<h3>Hong Shu, Teng Liu, Xingyu Mu, Dongpu Cao</h3>
<p>Knowledge transfer is a promising concept to achieve real-time
decision-making for autonomous vehicles. This paper constructs a transfer deep
reinforcement learning framework to transform the driving tasks in
inter-section environments. The driving missions at the un-signalized
intersection are cast into a left turn, right turn, and running straight for
automated vehicles. The goal of the autonomous ego vehicle (AEV) is to drive
through the intersection situation efficiently and safely. This objective
promotes the studied vehicle to increase its speed and avoid crashing other
vehicles. The decision-making pol-icy learned from one driving task is
transferred and evaluated in another driving mission. Simulation results reveal
that the decision-making strategies related to similar tasks are transferable.
It indicates that the presented control framework could reduce the time
consumption and realize online implementation.
</p>
<a href="http://arxiv.org/abs/2009.03268" target="_blank">arXiv:2009.03268</a> [<a href="http://arxiv.org/pdf/2009.03268" target="_blank">pdf</a>]

<h2>PiaNet: A pyramid input augmented convolutional neural network for GGO detection in 3D lung CT scans. (arXiv:2009.05267v2 [cs.CV] UPDATED)</h2>
<h3>Weihua Liu, Xiabi Liua, Xiongbiao Luo, Murong Wang, Guanghui Han, Xinming Zhao, Zheng Zhu</h3>
<p>This paper proposes a new convolutional neural network with multiscale
processing for detecting ground-glass opacity (GGO) nodules in 3D computed
tomography (CT) images, which is referred to as PiaNet for short. PiaNet
consists of a feature-extraction module and a prediction module. The former
module is constructed by introducing pyramid multiscale source connections into
a contracting-expanding structure. The latter module includes a bounding-box
regressor and a classifier that are employed to simultaneously recognize GGO
nodules and estimate bounding boxes at multiple scales. To train the proposed
PiaNet, a two-stage transfer learning strategy is developed. In the first
stage, the feature-extraction module is embedded into a classifier network that
is trained on a large data set of GGO and non-GGO patches, which are generated
by performing data augmentation from a small number of annotated CT scans. In
the second stage, the pretrained feature-extraction module is loaded into
PiaNet, and then PiaNet is fine-tuned using the annotated CT scans. We evaluate
the proposed PiaNet on the LIDC-IDRI data set. The experimental results
demonstrate that our method outperforms state-of-the-art counterparts,
including the Subsolid CAD and Aidence systems and S4ND and GA-SSD methods.
PiaNet achieves a sensitivity of 91.75% with only one false positive per scan
</p>
<a href="http://arxiv.org/abs/2009.05267" target="_blank">arXiv:2009.05267</a> [<a href="http://arxiv.org/pdf/2009.05267" target="_blank">pdf</a>]

<h2>Activation Relaxation: A Local Dynamical Approximation to Backpropagation in the Brain. (arXiv:2009.05359v5 [cs.NE] UPDATED)</h2>
<h3>Beren Millidge, Alexander Tschantz, Anil K Seth, Christopher L Buckley</h3>
<p>The backpropagation of error algorithm (backprop) has been instrumental in
the recent success of deep learning. However, a key question remains as to
whether backprop can be formulated in a manner suitable for implementation in
neural circuitry. The primary challenge is to ensure that any candidate
formulation uses only local information, rather than relying on global signals
as in standard backprop. Recently several algorithms for approximating backprop
using only local signals have been proposed. However, these algorithms
typically impose other requirements which challenge biological plausibility:
for example, requiring complex and precise connectivity schemes, or multiple
sequential backwards phases with information being stored across phases. Here,
we propose a novel algorithm, Activation Relaxation (AR), which is motivated by
constructing the backpropagation gradient as the equilibrium point of a
dynamical system. Our algorithm converges rapidly and robustly to the correct
backpropagation gradients, requires only a single type of computational unit,
utilises only a single parallel backwards relaxation phase, and can operate on
arbitrary computation graphs. We illustrate these properties by training deep
neural networks on visual classification tasks, and describe simplifications to
the algorithm which remove further obstacles to neurobiological implementation
(for example, the weight-transport problem, and the use of nonlinear
derivatives), while preserving performance.
</p>
<a href="http://arxiv.org/abs/2009.05359" target="_blank">arXiv:2009.05359</a> [<a href="http://arxiv.org/pdf/2009.05359" target="_blank">pdf</a>]

<h2>EM-RBR: a reinforced framework for knowledge graph completion from reasoning perspective. (arXiv:2009.08656v2 [cs.AI] UPDATED)</h2>
<h3>Zhaochong An, Bozhou Chen, Houde Quan, Qihui Lin, Hongzhi Wang</h3>
<p>Knowledge graph completion aims to predict the new links in given entities
among the knowledge graph (KG). Most mainstream embedding methods focus on fact
triplets contained in the given KG, however, ignoring the rich background
information provided by logic rules driven from knowledge base implicitly. To
solve this problem, in this paper, we propose a general framework, named
EM-RBR(embedding and rule-based reasoning), capable of combining the advantages
of reasoning based on rules and the state-of-the-art models of embedding.
EM-RBR aims to utilize relational background knowledge contained in rules to
conduct multi-relation reasoning link prediction rather than superficial vector
triangle linkage in embedding models. By this way, we can explore relation
between two entities in deeper context to achieve higher accuracy. In
experiments, we demonstrate that EM-RBR achieves better performance compared
with previous models on FB15k, WN18 and our new dataset FB15k-R, especially the
new dataset where our model perform futher better than those state-of-the-arts.
We make the implementation of EM-RBR available at
https://github.com/1173710224/link-prediction-with-rule-based-reasoning.
</p>
<a href="http://arxiv.org/abs/2009.08656" target="_blank">arXiv:2009.08656</a> [<a href="http://arxiv.org/pdf/2009.08656" target="_blank">pdf</a>]

<h2>Overfit Neural Networks as a Compact Shape Representation. (arXiv:2009.09808v2 [cs.GR] UPDATED)</h2>
<h3>Thomas Davies, Derek Nowrouzezahrai, Alec Jacobson</h3>
<p>Neural networks have proven to be effective approximators of signed distance
fields (SDFs) for solid 3D objects. While prior work has focused on the
generalization power of such approximations, we instead explore their
suitability as a compact - if purposefully overfit - SDF representation of
individual shapes. Specifically, we ask whether neural networks can serve as
first-class implicit shape representations in computer graphics. We call such
overfit networks Neural Implicits. Similar to SDFs stored on a regular grid,
Neural Implicits have fixed storage profiles and memory layout, but afford far
greater accuracy. At equal storage cost, Neural Implicits consistently match or
exceed the accuracy of irregularly-sampled triangle meshes. We achieve this
with a combination of a novel loss function, sampling strategy and supervision
protocol designed to facilitate robust shape overfitting. We demonstrate the
flexibility of our representation on a variety of standard rendering and
modelling tasks.
</p>
<a href="http://arxiv.org/abs/2009.09808" target="_blank">arXiv:2009.09808</a> [<a href="http://arxiv.org/pdf/2009.09808" target="_blank">pdf</a>]

<h2>EI-MTD:Moving Target Defense for Edge Intelligence against Adversarial Attacks. (arXiv:2009.10537v2 [cs.CR] UPDATED)</h2>
<h3>Yaguan Qian, Qiqi Shao, Jiamin Wang, Xiang Lin, Yankai Guo, Zhaoquan Gu, Bin Wang, Chunming Wu</h3>
<p>With the boom of edge intelligence, its vulnerability to adversarial attacks
becomes an urgent problem. The so-called adversarial example can fool a deep
learning model on the edge node to misclassify. Due to the property of
transferability, the adversary can easily make a black-box attack using a local
substitute model. Nevertheless, the limitation of resource of edge nodes cannot
afford a complicated defense mechanism as doing on the cloud data center. To
overcome the challenge, we propose a dynamic defense mechanism, namely EI-MTD.
It first obtains robust member models with small size through differential
knowledge distillation from a complicated teacher model on the cloud data
center. Then, a dynamic scheduling policy based on a Bayesian Stackelberg game
is applied to the choice of a target model for service. This dynamic defense
can prohibit the adversary from selecting an optimal substitute model for
black-box attacks. Our experimental result shows that this dynamic scheduling
can effectively protect edge intelligence against adversarial attacks under the
black-box setting.
</p>
<a href="http://arxiv.org/abs/2009.10537" target="_blank">arXiv:2009.10537</a> [<a href="http://arxiv.org/pdf/2009.10537" target="_blank">pdf</a>]

<h2>Attention Driven Fusion for Multi-Modal Emotion Recognition. (arXiv:2009.10991v2 [eess.AS] UPDATED)</h2>
<h3>Darshana Priyasad, Tharindu Fernando, Simon Denman, Clinton Fookes, Sridha Sridharan</h3>
<p>Deep learning has emerged as a powerful alternative to hand-crafted methods
for emotion recognition on combined acoustic and text modalities. Baseline
systems model emotion information in text and acoustic modes independently
using Deep Convolutional Neural Networks (DCNN) and Recurrent Neural Networks
(RNN), followed by applying attention, fusion, and classification. In this
paper, we present a deep learning-based approach to exploit and fuse text and
acoustic data for emotion classification. We utilize a SincNet layer, based on
parameterized sinc functions with band-pass filters, to extract acoustic
features from raw audio followed by a DCNN. This approach learns filter banks
tuned for emotion recognition and provides more effective features compared to
directly applying convolutions over the raw speech signal. For text processing,
we use two branches (a DCNN and a Bi-direction RNN followed by a DCNN) in
parallel where cross attention is introduced to infer the N-gram level
correlations on hidden representations received from the Bi-RNN. Following
existing state-of-the-art, we evaluate the performance of the proposed system
on the IEMOCAP dataset. Experimental results indicate that the proposed system
outperforms existing methods, achieving 3.5% improvement in weighted accuracy.
</p>
<a href="http://arxiv.org/abs/2009.10991" target="_blank">arXiv:2009.10991</a> [<a href="http://arxiv.org/pdf/2009.10991" target="_blank">pdf</a>]

<h2>Interpreting and Boosting Dropout from a Game-Theoretic View. (arXiv:2009.11729v2 [cs.LG] UPDATED)</h2>
<h3>Hao Zhang, Sen Li, Yinchao Ma, Mingjie Li, Yichen Xie, Quanshi Zhang</h3>
<p>This paper aims to understand and improve the utility of the dropout
operation from the perspective of game-theoretic interactions. We prove that
dropout can suppress the strength of interactions between input variables of
deep neural networks (DNNs). The theoretic proof is also verified by various
experiments. Furthermore, we find that such interactions were strongly related
to the over-fitting problem in deep learning. Thus, the utility of dropout can
be regarded as decreasing interactions to alleviate the significance of
over-fitting. Based on this understanding, we propose an interaction loss to
further improve the utility of dropout. Experimental results have shown that
the interaction loss can effectively improve the utility of dropout and boost
the performance of DNNs.
</p>
<a href="http://arxiv.org/abs/2009.11729" target="_blank">arXiv:2009.11729</a> [<a href="http://arxiv.org/pdf/2009.11729" target="_blank">pdf</a>]

<h2>Towards Debiasing NLU Models from Unknown Biases. (arXiv:2009.12303v3 [cs.CL] UPDATED)</h2>
<h3>Prasetya Ajie Utama, Nafise Sadat Moosavi, Iryna Gurevych</h3>
<p>NLU models often exploit biases to achieve high dataset-specific performance
without properly learning the intended task. Recently proposed debiasing
methods are shown to be effective in mitigating this tendency. However, these
methods rely on a major assumption that the types of bias should be known
a-priori, which limits their application to many NLU tasks and datasets. In
this work, we present the first step to bridge this gap by introducing a
self-debiasing framework that prevents models from mainly utilizing biases
without knowing them in advance. The proposed framework is general and
complementary to the existing debiasing methods. We show that it allows these
existing methods to retain the improvement on the challenge datasets (i.e.,
sets of examples designed to expose models' reliance on biases) without
specifically targeting certain biases. Furthermore, the evaluation suggests
that applying the framework results in improved overall robustness.
</p>
<a href="http://arxiv.org/abs/2009.12303" target="_blank">arXiv:2009.12303</a> [<a href="http://arxiv.org/pdf/2009.12303" target="_blank">pdf</a>]

<h2>EIS -- a family of activation functions combining Exponential, ISRU, and Softplus. (arXiv:2009.13501v2 [cs.LG] UPDATED)</h2>
<h3>Koushik Biswas, Sandeep Kumar, Shilpak Banerjee, Ashish Kumar Pandey</h3>
<p>Activation functions play a pivotal role in the function learning using
neural networks. The non-linearity in the learned function is achieved by
repeated use of the activation function. Over the years, numerous activation
functions have been proposed to improve accuracy in several tasks. Basic
functions like ReLU, Sigmoid, Tanh, or Softplus have been favorite among the
deep learning community because of their simplicity. In recent years, several
novel activation functions arising from these basic functions have been
proposed, which have improved accuracy in some challenging datasets. We propose
a five hyper-parameters family of activation functions, namely EIS, defined as,
\[ \frac{x(\ln(1+e^x))^\alpha}{\sqrt{\beta+\gamma x^2}+\delta e^{-\theta x}}.
\] We show examples of activation functions from the EIS family which
outperform widely used activation functions on some well known datasets and
models. For example, $\frac{x\ln(1+e^x)}{x+1.16e^{-x}}$ beats ReLU by 0.89\% in
DenseNet-169, 0.24\% in Inception V3 in CIFAR100 dataset while 1.13\% in
Inception V3, 0.13\% in DenseNet-169, 0.94\% in SimpleNet model in CIFAR10
dataset. Also, $\frac{x\ln(1+e^x)}{\sqrt{1+x^2}}$ beats ReLU by 1.68\% in
DenseNet-169, 0.30\% in Inception V3 in CIFAR100 dataset while 1.0\% in
Inception V3, 0.15\% in DenseNet-169, 1.13\% in SimpleNet model in CIFAR10
dataset.
</p>
<a href="http://arxiv.org/abs/2009.13501" target="_blank">arXiv:2009.13501</a> [<a href="http://arxiv.org/pdf/2009.13501" target="_blank">pdf</a>]

<h2>MetaMix: Improved Meta-Learning with Interpolation-based Consistency Regularization. (arXiv:2009.13735v2 [cs.CV] UPDATED)</h2>
<h3>Yangbin Chen, Yun Ma, Tom Ko, Jianping Wang, Qing Li</h3>
<p>Model-Agnostic Meta-Learning (MAML) and its variants are popular few-shot
classification methods. They train an initializer across a variety of sampled
learning tasks (also known as episodes) such that the initialized model can
adapt quickly to new tasks. However, current MAML-based algorithms have
limitations in forming generalizable decision boundaries. In this paper, we
propose an approach called MetaMix. It generates virtual feature-target pairs
within each episode to regularize the backbone models. MetaMix can be
integrated with any of the MAML-based algorithms and learn the decision
boundaries generalizing better to new tasks. Experiments on the mini-ImageNet,
CUB, and FC100 datasets show that MetaMix improves the performance of
MAML-based algorithms and achieves state-of-the-art result when integrated with
Meta-Transfer Learning.
</p>
<a href="http://arxiv.org/abs/2009.13735" target="_blank">arXiv:2009.13735</a> [<a href="http://arxiv.org/pdf/2009.13735" target="_blank">pdf</a>]

<h2>Machine-Learning Approach to Analyze the Status of Forklift Vehicles with Irregular Movement in a Shipyard. (arXiv:2009.14025v2 [cs.LG] UPDATED)</h2>
<h3>Hyeonju Lee, Jongho Lee, Minji An, Gunil Park, Sungchul Choi</h3>
<p>In large shipyards, the management of equipment, which are used for building
a variety of ships, is critical. Because orders vary year to year, shipyard
managers are required to determine methods to make the most of their limited
resources. A particular difficulty that arises because of the nature and size
of shipyards is the management of moving vehicles. In recent years,
shipbuilding companies have attempted to manage and track the locations and
movements of vehicles using Global Positioning System (GPS) modules. However,
because certain vehicles, such as forklifts, roam irregularly around a yard,
identifying their working status without being onsite is difficult. Location
information alone is not sufficient to determine whether a vehicle is working,
moving, waiting, or resting. This study proposes an approach based on machine
learning to identify the work status of each forklift. We use the DBSCAN and
k-means algorithms to identify the area in which a particular forklift is
operating and the type of work it is performing. We developed a business
intelligence system to collect information from forklifts equipped with GPS and
Internet of Things (IoT) devices. The system provides visual information on the
status of individual forklifts and helps in the efficient management of their
movements within large shipyards.
</p>
<a href="http://arxiv.org/abs/2009.14025" target="_blank">arXiv:2009.14025</a> [<a href="http://arxiv.org/pdf/2009.14025" target="_blank">pdf</a>]

<h2>Joint Contrastive Learning with Infinite Possibilities. (arXiv:2009.14776v2 [cs.CV] UPDATED)</h2>
<h3>Qi Cai, Yu Wang, Yingwei Pan, Ting Yao, Tao Mei</h3>
<p>This paper explores useful modifications of the recent development in
contrastive learning via novel probabilistic modeling. We derive a particular
form of contrastive loss named Joint Contrastive Learning (JCL). JCL implicitly
involves the simultaneous learning of an infinite number of query-key pairs,
which poses tighter constraints when searching for invariant features. We
derive an upper bound on this formulation that allows analytical solutions in
an end-to-end training manner. While JCL is practically effective in numerous
computer vision applications, we also theoretically unveil the certain
mechanisms that govern the behavior of JCL. We demonstrate that the proposed
formulation harbors an innate agency that strongly favors similarity within
each instance-specific class, and therefore remains advantageous when searching
for discriminative features among distinct instances. We evaluate these
proposals on multiple benchmarks, demonstrating considerable improvements over
existing algorithms. Code is publicly available at:
https://github.com/caiqi/Joint-Contrastive-Learning.
</p>
<a href="http://arxiv.org/abs/2009.14776" target="_blank">arXiv:2009.14776</a> [<a href="http://arxiv.org/pdf/2009.14776" target="_blank">pdf</a>]

<h2>"Did you really mean what you said?" : Sarcasm Detection in Hindi-English Code-Mixed Data using Bilingual Word Embeddings. (arXiv:2010.00310v2 [cs.CL] UPDATED)</h2>
<h3>Akshita Aggarwal, Anshul Wadhawan, Anshima Chaudhary, Kavita Maurya</h3>
<p>With the increased use of social media platforms by people across the world,
many new interesting NLP problems have come into existence. One such being the
detection of sarcasm in the social media texts. We present a corpus of tweets
for training custom word embeddings and a Hinglish dataset labelled for sarcasm
detection. We propose a deep learning based approach to address the issue of
sarcasm detection in Hindi-English code mixed tweets using bilingual word
embeddings derived from FastText and Word2Vec approaches. We experimented with
various deep learning models, including CNNs, LSTMs, Bi-directional LSTMs (with
and without attention). We were able to outperform all state-of-the-art
performances with our deep learning models, with attention based Bi-directional
LSTMs giving the best performance exhibiting an accuracy of 78.49%.
</p>
<a href="http://arxiv.org/abs/2010.00310" target="_blank">arXiv:2010.00310</a> [<a href="http://arxiv.org/pdf/2010.00310" target="_blank">pdf</a>]

<h2>Understanding Self-supervised Learning with Dual Deep Networks. (arXiv:2010.00578v2 [cs.LG] UPDATED)</h2>
<h3>Yuandong Tian, Lantao Yu, Xinlei Chen, Surya Ganguli</h3>
<p>We propose a novel theoretical framework to understand self-supervised
learning methods that employ dual pairs of deep ReLU networks (e.g., SimCLR,
BYOL). First, we prove that in each SGD update of SimCLR, the weights at each
layer are updated by a \emph{covariance operator} that specifically amplifies
initial random selectivities that vary across data samples but survive averages
over data augmentations, which we show leads to the emergence of hierarchical
features, if the input data are generated from a hierarchical latent tree
model. With the same framework, we also show analytically that BYOL works due
to an implicit contrastive term, acting as an approximate covariance operator.
The term is formed by the inter-play between the zero-mean operation of
BatchNorm and the extra predictor in the online network. Extensive ablation
studies justify our theoretical findings.
</p>
<a href="http://arxiv.org/abs/2010.00578" target="_blank">arXiv:2010.00578</a> [<a href="http://arxiv.org/pdf/2010.00578" target="_blank">pdf</a>]

<h2>Relaxing the Constraints on Predictive Coding Models. (arXiv:2010.01047v2 [q-bio.NC] UPDATED)</h2>
<h3>Beren Millidge, Alexander Tschantz, Anil Seth, Christopher L Buckley</h3>
<p>Predictive coding is an influential theory of cortical function which posits
that the principal computation the brain performs, which underlies both
perception and learning, is the minimization of prediction errors. While
motivated by high-level notions of variational inference, detailed
neurophysiological models of cortical microcircuits which can implements its
computations have been developed. Moreover, under certain conditions,
predictive coding has been shown to approximate the backpropagation of error
algorithm, and thus provides a relatively biologically plausible
credit-assignment mechanism for training deep networks. However, standard
implementations of the algorithm still involve potentially neurally implausible
features such as identical forward and backward weights, backward nonlinear
derivatives, and 1-1 error unit connectivity. In this paper, we show that these
features are not integral to the algorithm and can be removed either directly
or through learning additional sets of parameters with Hebbian update rules
without noticeable harm to learning performance. Our work thus relaxes current
constraints on potential microcircuit designs and hopefully opens up new
regions of the design-space for neuromorphic implementations of predictive
coding.
</p>
<a href="http://arxiv.org/abs/2010.01047" target="_blank">arXiv:2010.01047</a> [<a href="http://arxiv.org/pdf/2010.01047" target="_blank">pdf</a>]

<h2>Boosted Semantic Embedding based Discriminative Feature Generation for Texture Analysis. (arXiv:2010.02002v2 [cs.LG] UPDATED)</h2>
<h3>Priyadarshini Kumari, Subhasis Chaudhuri</h3>
<p>Learning discriminative features is crucial for various robotic applications
such as object detection and classification. In this paper, we present a
general framework for the analysis of the discriminative properties of haptic
signals. Our focus is on two crucial components of a robotic perception system:
discriminative feature extraction and metric-based feature transformation to
enhance the separability of haptic signals in the projected space. We propose a
set of hand-crafted haptic features (generated only from acceleration data),
which enables discrimination of real-world textures. Since the Euclidean space
does not reflect the underlying pattern in the data, we propose to learn an
appropriate transformation function to project the feature onto the new space
and apply different pattern recognition algorithms for texture classification
and discrimination tasks. Unlike other existing methods, we use a triplet-based
method for improved discrimination in the embedded space. We further
demonstrate how to build a haptic vocabulary by selecting a compact set of the
most distinct and representative signals in the embedded space. The
experimental results show that the proposed features augmented with learned
embedding improves the performance of semantic discrimination tasks such as
classification and clustering and outperforms the related state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2010.02002" target="_blank">arXiv:2010.02002</a> [<a href="http://arxiv.org/pdf/2010.02002" target="_blank">pdf</a>]

<h2>An Ensemble Approach for Automatic Structuring of Radiology Reports. (arXiv:2010.02256v2 [cs.CL] UPDATED)</h2>
<h3>Morteza Pourreza Shahri, Amir Tahmasebi, Bingyang Ye, Henghui Zhu, Javed Aslam, Timothy Ferris</h3>
<p>Automatic structuring of electronic medical records is of high demand for
clinical workflow solutions to facilitate extraction, storage, and querying of
patient care information. However, developing a scalable solution is extremely
challenging, specifically for radiology reports, as most healthcare institutes
use either no template or department/institute specific templates. Moreover,
radiologists' reporting style varies from one to another as sentences are
telegraphic and do not follow general English grammar rules. We present an
ensemble method that consolidates the predictions of three models, capturing
various attributes of textual information for automatic labeling of sentences
with section labels. These three models are: 1) Focus Sentence model, capturing
context of the target sentence; 2) Surrounding Context model, capturing the
neighboring context of the target sentence; and finally, 3) Formatting/Layout
model, aimed at learning report formatting cues. We utilize Bi-directional
LSTMs, followed by sentence encoders, to acquire the context. Furthermore, we
define several features that incorporate the structure of reports. We compare
our proposed approach against multiple baselines and state-of-the-art
approaches on a proprietary dataset as well as 100 manually annotated radiology
notes from the MIMIC-III dataset, which we are making publicly available. Our
proposed approach significantly outperforms other approaches by achieving 97.1%
accuracy.
</p>
<a href="http://arxiv.org/abs/2010.02256" target="_blank">arXiv:2010.02256</a> [<a href="http://arxiv.org/pdf/2010.02256" target="_blank">pdf</a>]

<h2>KGPT: Knowledge-Grounded Pre-Training for Data-to-Text Generation. (arXiv:2010.02307v2 [cs.CL] UPDATED)</h2>
<h3>Wenhu Chen, Yu Su, Xifeng Yan, William Yang Wang</h3>
<p>Data-to-text generation has recently attracted substantial interests due to
its wide applications. Existing methods have shown impressive performance on an
array of tasks. However, they rely on a significant amount of labeled data for
each task, which is costly to acquire and thus limits their application to new
tasks and domains. In this paper, we propose to leverage pre-training and
transfer learning to address this issue. We propose a knowledge-grounded
pre-training (KGPT), which consists of two parts, 1) a general
knowledge-grounded generation model to generate knowledge-enriched text. 2) a
pre-training paradigm on a massive knowledge-grounded text corpus crawled from
the web. The pre-trained model can be fine-tuned on various data-to-text
generation tasks to generate task-specific text. We adopt three settings,
namely fully-supervised, zero-shot, few-shot to evaluate its effectiveness.
Under the fully-supervised setting, our model can achieve remarkable gains over
the known baselines. Under zero-shot setting, our model without seeing any
examples achieves over 30 ROUGE-L on WebNLG while all other baselines fail.
Under the few-shot setting, our model only needs about one-fifteenth as many
labeled examples to achieve the same level of performance as baseline models.
These experiments consistently prove the strong generalization ability of our
proposed framework https://github.com/wenhuchen/KGPT.
</p>
<a href="http://arxiv.org/abs/2010.02307" target="_blank">arXiv:2010.02307</a> [<a href="http://arxiv.org/pdf/2010.02307" target="_blank">pdf</a>]

<h2>Dynamic Semantic Matching and Aggregation Network for Few-shot Intent Detection. (arXiv:2010.02481v2 [cs.CL] UPDATED)</h2>
<h3>Hoang Nguyen, Chenwei Zhang, Congying Xia, Philip S. Yu</h3>
<p>Few-shot Intent Detection is challenging due to the scarcity of available
annotated utterances. Although recent works demonstrate that multi-level
matching plays an important role in transferring learned knowledge from seen
training classes to novel testing classes, they rely on a static similarity
measure and overly fine-grained matching components. These limitations inhibit
generalizing capability towards Generalized Few-shot Learning settings where
both seen and novel classes are co-existent. In this paper, we propose a novel
Semantic Matching and Aggregation Network where semantic components are
distilled from utterances via multi-head self-attention with additional dynamic
regularization constraints. These semantic components capture high-level
information, resulting in more effective matching between instances. Our
multi-perspective matching method provides a comprehensive matching measure to
enhance representations of both labeled and unlabeled instances. We also
propose a more challenging evaluation setting that considers classification on
the joint all-class label space. Extensive experimental results demonstrate the
effectiveness of our method. Our code and data are publicly available.
</p>
<a href="http://arxiv.org/abs/2010.02481" target="_blank">arXiv:2010.02481</a> [<a href="http://arxiv.org/pdf/2010.02481" target="_blank">pdf</a>]

<h2>A framework for predicting, interpreting, and improving Learning Outcomes. (arXiv:2010.02629v2 [cs.LG] UPDATED)</h2>
<h3>Chintan Donda, Sayan Dasgupta, Soma S Dhavala, Keyur Faldu, Aditi Avasthi</h3>
<p>It has long been recognized that academic success is a result of both
cognitive and non-cognitive dimensions acting together. Consequently, any
intelligent learning platform designed to improve learning outcomes (LOs) must
provide actionable inputs to the learner in these dimensions. However,
operationalizing such inputs in a production setting that is scalable is not
trivial. We develop an Embibe Score Quotient model (ESQ) to predict test scores
based on observed academic, behavioral and test-taking features of a student.
ESQ can be used to predict the future scoring potential of a student as well as
offer personalized learning nudges, both critical to improving LOs. Multiple
machine learning models are evaluated for the prediction task. In order to
provide meaningful feedback to the learner, individualized Shapley feature
attributions for each feature are computed. Prediction intervals are obtained
by applying non-parametric quantile regression, in an attempt to quantify the
uncertainty in the predictions. We apply the above modelling strategy on a
dataset consisting of more than a hundred million learner interactions on the
Embibe learning platform. We observe that the Median Absolute Error between the
observed and predicted scores is 4.58% across several user segments, and the
correlation between predicted and observed responses is 0.93. Game-like what-if
scenarios are played out to see the changes in LOs, on counterfactual examples.
We briefly discuss how a rational agent can then apply an optimal policy to
affect the learning outcomes by treating the above model like an Oracle.
</p>
<a href="http://arxiv.org/abs/2010.02629" target="_blank">arXiv:2010.02629</a> [<a href="http://arxiv.org/pdf/2010.02629" target="_blank">pdf</a>]

<h2>Reinforcement Learning in Deep Structured Teams: Initial Results with Finite and Infinite Valued Features. (arXiv:2010.02868v2 [cs.MA] UPDATED)</h2>
<h3>Jalal Arabneydi, Masoud Roudneshin, Amir G. Aghdam</h3>
<p>In this paper, we consider Markov chain and linear quadratic models for deep
structured teams with discounted and time-average cost functions under two
non-classical information structures, namely, deep state sharing and no
sharing. In deep structured teams, agents are coupled in dynamics and cost
functions through deep state, where deep state refers to a set of orthogonal
linear regressions of the states. In this article, we consider a homogeneous
linear regression for Markov chain models (i.e., empirical distribution of
states) and a few orthonormal linear regressions for linear quadratic models
(i.e., weighted average of states). Some planning algorithms are developed for
the case when the model is known, and some reinforcement learning algorithms
are proposed for the case when the model is not known completely. The
convergence of two model-free (reinforcement learning) algorithms, one for
Markov chain models and one for linear quadratic models, is established. The
results are then applied to a smart grid.
</p>
<a href="http://arxiv.org/abs/2010.02868" target="_blank">arXiv:2010.02868</a> [<a href="http://arxiv.org/pdf/2010.02868" target="_blank">pdf</a>]

<h2>Plug and Play Autoencoders for Conditional Text Generation. (arXiv:2010.02983v2 [cs.CL] UPDATED)</h2>
<h3>Florian Mai (1 and 2), Nikolaos Pappas (3), Ivan Montero (3), Noah A. Smith (3 and 4), James Henderson (1) ((1) Idiap Research Institute, (2) EPFL, (3) University of Washington, (4) Allen Institute for Artificial Intelligence)</h3>
<p>Text autoencoders are commonly used for conditional generation tasks such as
style transfer. We propose methods which are plug and play, where any
pretrained autoencoder can be used, and only require learning a mapping within
the autoencoder's embedding space, training embedding-to-embedding (Emb2Emb).
This reduces the need for labeled training data for the task and makes the
training procedure more efficient. Crucial to the success of this method is a
loss term for keeping the mapped embedding on the manifold of the autoencoder
and a mapping which is trained to navigate the manifold by learning offset
vectors. Evaluations on style transfer tasks both with and without
sequence-to-sequence supervision show that our method performs better than or
comparable to strong baselines while being up to four times faster.
</p>
<a href="http://arxiv.org/abs/2010.02983" target="_blank">arXiv:2010.02983</a> [<a href="http://arxiv.org/pdf/2010.02983" target="_blank">pdf</a>]

<h2>Low-Rank Robust Online Distance/Similarity Learning based on the Rescaled Hinge Loss. (arXiv:2010.03268v2 [cs.LG] UPDATED)</h2>
<h3>Davood Zabihzadeh, Amar Tuama, Ali Karami-Mollaee</h3>
<p>An important challenge in metric learning is scalability to both size and
dimension of input data. Online metric learning algorithms are proposed to
address this challenge. Existing methods are commonly based on (Passive
Aggressive) PA approach. Hence, they can rapidly process large volumes of data
with an adaptive learning rate. However, these algorithms are based on the
Hinge loss and so are not robust against outliers and label noise. Also,
existing online methods usually assume training triplets or pairwise
constraints are exist in advance. However, many datasets in real-world
applications are in the form of input data and their associated labels. We
address these challenges by formulating the online Distance-Similarity learning
problem with the robust Rescaled hinge loss function. The proposed model is
rather general and can be applied to any PA-based online Distance-Similarity
algorithm. Also, we develop an efficient robust one-pass triplet construction
algorithm. Finally, to provide scalability in high dimensional DML
environments, the low-rank version of the proposed methods is presented that
not only reduces the computational cost significantly but also keeps the
predictive performance of the learned metrics. Also, it provides a
straightforward extension of our methods for deep Distance-Similarity learning.
We conduct several experiments on datasets from various applications. The
results confirm that the proposed methods significantly outperform
state-of-the-art online DML methods in the presence of label noise and outliers
by a large margin.
</p>
<a href="http://arxiv.org/abs/2010.03268" target="_blank">arXiv:2010.03268</a> [<a href="http://arxiv.org/pdf/2010.03268" target="_blank">pdf</a>]

<h2>Simplifying the explanation of deep neural networks with sufficient and necessary feature-sets: case of text classification. (arXiv:2010.03724v2 [cs.LG] UPDATED)</h2>
<h3>Jiechieu Kameni Florentin Flambeau, Tsopze Norbert</h3>
<p>During the last decade, deep neural networks (DNN) have demonstrated
impressive performances solving a wide range of problems in various domains
such as medicine, finance, law, etc. Despite their great performances, they
have long been considered as black-box systems, providing good results without
being able to explain them. However, the inability to explain a system decision
presents a serious risk in critical domains such as medicine where people's
lives are at stake. Several works have been done to uncover the inner reasoning
of deep neural networks. Saliency methods explain model decisions by assigning
weights to input features that reflect their contribution to the classifier
decision. However, not all features are necessary to explain a model decision.
In practice, classifiers might strongly rely on a subset of features that might
be sufficient to explain a particular decision. The aim of this article is to
propose a method to simplify the prediction explanation of One-Dimensional (1D)
Convolutional Neural Networks (CNN) by identifying sufficient and necessary
features-sets. We also propose an adaptation of Layer-wise Relevance
Propagation for 1D-CNN. Experiments carried out on multiple datasets show that
the distribution of relevance among features is similar to that obtained with a
well known state of the art model. Moreover, the sufficient and necessary
features extracted perceptually appear convincing to humans.
</p>
<a href="http://arxiv.org/abs/2010.03724" target="_blank">arXiv:2010.03724</a> [<a href="http://arxiv.org/pdf/2010.03724" target="_blank">pdf</a>]

<h2>BERTering RAMS: What and How Much does BERT Already Know About Event Arguments? -- A Study on the RAMS Dataset. (arXiv:2010.04098v2 [cs.CL] UPDATED)</h2>
<h3>Varun Gangal, Eduard Hovy</h3>
<p>Using the attention map based probing frame-work from (Clark et al., 2019),
we observe that, on the RAMS dataset (Ebner et al., 2020), BERT's attention
heads have modest but well above-chance ability to spot event arguments sans
any training or domain finetuning, vary-ing from a low of 17.77% for Place to a
high of 51.61% for Artifact. Next, we find that linear combinations of these
heads, estimated with approx 11% of available total event argument detection
supervision, can push performance well-higher for some roles - highest two
being Victim (68.29% Accuracy) and Artifact(58.82% Accuracy). Furthermore, we
investigate how well our methods do for cross-sentence event arguments. We
propose a procedure to isolate "best heads" for cross-sentence argument
detection separately of those for intra-sentence arguments. The heads thus
estimated have superior cross-sentence performance compared to their jointly
estimated equivalents, albeit only under the unrealistic assumption that we
already know the argument is present in an-other sentence. Lastly, we seek to
isolate to what extent our numbers stem from lexical frequency based
associations between gold arguments and roles. We propose NONCE, a scheme to
create adversarial test examples by replacing gold arguments with randomly
generated "nonce" words. We find that learnt linear combinations are robust to
NONCE, though individual best heads can be more sensitive.
</p>
<a href="http://arxiv.org/abs/2010.04098" target="_blank">arXiv:2010.04098</a> [<a href="http://arxiv.org/pdf/2010.04098" target="_blank">pdf</a>]

<h2>Ensemble Hyperspectral Band Selection for Detecting Nitrogen Status in Grape Leaves. (arXiv:2010.04225v2 [cs.CV] UPDATED)</h2>
<h3>Ryan Omidi, Ali Moghimi, Alireza Pourreza, Mohamed El-Hadedy, Anas Salah Eddin</h3>
<p>The large data size and dimensionality of hyperspectral data demands complex
processing and data analysis. Multispectral data do not suffer the same
limitations, but are normally restricted to blue, green, red, red edge, and
near infrared bands. This study aimed to identify the optimal set of spectral
bands for nitrogen detection in grape leaves using ensemble feature selection
on hyperspectral data from over 3,000 leaves from 150 Flame Seedless table
grapevines. Six machine learning base rankers were included in the ensemble:
random forest, LASSO, SelectKBest, ReliefF, SVM-RFE, and chaotic crow search
algorithm (CCSA). The pipeline identified less than 0.45% of the bands as most
informative about grape nitrogen status. The selected violet, yellow-orange,
and shortwave infrared bands lie outside of the typical blue, green, red, red
edge, and near infrared bands of commercial multispectral cameras, so the
potential improvement in remote sensing of nitrogen in grapevines brought forth
by a customized multispectral sensor centered at the selected bands is
promising and worth further investigation. The proposed pipeline may also be
used for application-specific multispectral sensor design in domains other than
agriculture.
</p>
<a href="http://arxiv.org/abs/2010.04225" target="_blank">arXiv:2010.04225</a> [<a href="http://arxiv.org/pdf/2010.04225" target="_blank">pdf</a>]

<h2>Connection Pruning for Deep Spiking Neural Networks with On-Chip Learning. (arXiv:2010.04351v2 [cs.NE] UPDATED)</h2>
<h3>Thao N.N. Nguyen, Bharadwaj Veeravalli, Xuanyao Fong</h3>
<p>Long training time hinders the potential of the deep Spiking Neural Network
(SNN) with the online learning capability to be realized on the embedded
systems hardware. Our work proposes a novel connection pruning approach that
can be applied during the online Spike Timing Dependent Plasticity (STDP)-based
learning to optimize the learning time and the network connectivity of the SNN.
Our connection pruning approach was evaluated on a deep SNN with the Time To
First Spike (TTFS) coding and has successfully achieved 2.1x speed-up in the
online learning and reduced the network connectivity by 92.83%. The energy
consumption in the online learning was saved by 64%. Moreover, the connectivity
reduction results in 2.83x speed-up and 78.24% energy saved in the inference.
Meanwhile, the classification accuracy remains the same as our non-pruning
baseline on the Caltech 101 dataset. In addition, we developed an event-driven
hardware architecture on the Field Programmable Gate Array (FPGA) platform that
efficiently incorporates our proposed connection pruning approach while
incurring as little as 0.56% power overhead. Moreover, we performed a
comparison between our work and the existing works on connection pruning for
SNN to highlight the key features of each approach. To the best of our
knowledge, our work is the first to propose a connection pruning algorithm that
can be applied during the online STDP-based learning for a deep SNN with the
TTFS coding.
</p>
<a href="http://arxiv.org/abs/2010.04351" target="_blank">arXiv:2010.04351</a> [<a href="http://arxiv.org/pdf/2010.04351" target="_blank">pdf</a>]

<h2>Weaponizing Unicodes with Deep Learning -- Identifying Homoglyphs with Weakly Labeled Data. (arXiv:2010.04382v2 [cs.CR] UPDATED)</h2>
<h3>Perry Deng, Cooper Linsky, Matthew Wright</h3>
<p>Visually similar characters, or homoglyphs, can be used to perform social
engineering attacks or to evade spam and plagiarism detectors. It is thus
important to understand the capabilities of an attacker to identify homoglyphs
-- particularly ones that have not been previously spotted -- and leverage them
in attacks. We investigate a deep-learning model using embedding learning,
transfer learning, and augmentation to determine the visual similarity of
characters and thereby identify potential homoglyphs. Our approach uniquely
takes advantage of weak labels that arise from the fact that most characters
are not homoglyphs. Our model drastically outperforms the Normalized
Compression Distance approach on pairwise homoglyph identification, for which
we achieve an average precision of 0.97. We also present the first attempt at
clustering homoglyphs into sets of equivalence classes, which is more efficient
than pairwise information for security practitioners to quickly lookup
homoglyphs or to normalize confusable string encodings. To measure clustering
performance, we propose a metric (mBIOU) building on the classic
Intersection-Over-Union (IOU) metric. Our clustering method achieves 0.592
mBIOU, compared to 0.430 for the naive baseline. We also use our model to
predict over 8,000 previously unknown homoglyphs, and find good early
indications that many of these may be true positives. Source code and list of
predicted homoglyphs are uploaded to Github:
https://github.com/PerryXDeng/weaponizing_unicode
</p>
<a href="http://arxiv.org/abs/2010.04382" target="_blank">arXiv:2010.04382</a> [<a href="http://arxiv.org/pdf/2010.04382" target="_blank">pdf</a>]

<h2>Learning Invariant Representations and Risks for Semi-supervised Domain Adaptation. (arXiv:2010.04647v2 [cs.LG] UPDATED)</h2>
<h3>Bo Li, Yezhen Wang, Shanghang Zhang, Dongsheng Li, Trevor Darrell, Kurt Keutzer, Han Zhao</h3>
<p>The success of supervised learning hinges on the assumption that the training
and test data come from the same underlying distribution, which is often not
valid in practice due to potential distribution shift. In light of this, most
existing methods for unsupervised domain adaptation focus on achieving
domain-invariant representations and small source domain error. However, recent
works have shown that this is not sufficient to guarantee good generalization
on the target domain, and in fact, is provably detrimental under label
distribution shift. Furthermore, in many real-world applications it is often
feasible to obtain a small amount of labeled data from the target domain and
use them to facilitate model training with source data. Inspired by the above
observations, in this paper we propose the first method that aims to
simultaneously learn invariant representations and risks under the setting of
semi-supervised domain adaptation (Semi-DA). First, we provide a finite sample
bound for both classification and regression problems under Semi-DA. The bound
suggests a principled way to obtain target generalization, i.e. by aligning
both the marginal and conditional distributions across domains in feature
space. Motivated by this, we then introduce the LIRR algorithm for jointly
\textbf{L}earning \textbf{I}nvariant \textbf{R}epresentations and
\textbf{R}isks. Finally, extensive experiments are conducted on both
classification and regression tasks, which demonstrates LIRR consistently
achieves state-of-the-art performance and significant improvements compared
with the methods that only learn invariant representations or invariant risks.
</p>
<a href="http://arxiv.org/abs/2010.04647" target="_blank">arXiv:2010.04647</a> [<a href="http://arxiv.org/pdf/2010.04647" target="_blank">pdf</a>]

<h2>Deep Attentive Features for Prostate Segmentation in 3D Transrectal Ultrasound. (arXiv:1907.01743v1 [eess.IV] CROSS LISTED)</h2>
<h3>Yi Wang, Haoran Dou, Xiaowei Hu, Lei Zhu, Xin Yang, Ming Xu, Jing Qin, Pheng-Ann Heng, Tianfu Wang, Dong Ni</h3>
<p>Automatic prostate segmentation in transrectal ultrasound (TRUS) images is of
essential importance for image-guided prostate interventions and treatment
planning. However, developing such automatic solutions remains very challenging
due to the missing/ambiguous boundary and inhomogeneous intensity distribution
of the prostate in TRUS, as well as the large variability in prostate shapes.
This paper develops a novel 3D deep neural network equipped with attention
modules for better prostate segmentation in TRUS by fully exploiting the
complementary information encoded in different layers of the convolutional
neural network (CNN). Our attention module utilizes the attention mechanism to
selectively leverage the multilevel features integrated from different layers
to refine the features at each individual layer, suppressing the non-prostate
noise at shallow layers of the CNN and increasing more prostate details into
features at deep layers. Experimental results on challenging 3D TRUS volumes
show that our method attains satisfactory segmentation performance. The
proposed attention mechanism is a general strategy to aggregate multi-level
deep features and has the potential to be used for other medical image
segmentation tasks. The code is publicly available at
https://github.com/wulalago/DAF3D.
</p>
<a href="http://arxiv.org/abs/1907.01743" target="_blank">arXiv:1907.01743</a> [<a href="http://arxiv.org/pdf/1907.01743" target="_blank">pdf</a>]

<h2>NeuMiss networks: differential programming for supervised learning with missing values. (arXiv:2007.01627v2 [cs.LG] CROSS LISTED)</h2>
<h3>Marine Le Morvan (PARIETAL, IJCLab), Julie Josse (CMAP, XPOP), Thomas Moreau (PARIETAL), Erwan Scornet (CMAP), Ga&#xeb;l Varoquaux (PARIETAL, MILA)</h3>
<p>The presence of missing values makes supervised learning much more
challenging. Indeed, previous work has shown that even when the response is a
linear function of the complete data, the optimal predictor is a complex
function of the observed entries and the missingness indicator. As a result,
the computational or sample complexities of consistent approaches depend on the
number of missing patterns, which can be exponential in the number of
dimensions. In this work, we derive the analytical form of the optimal
predictor under a linearity assumption and various missing data mechanisms
including Missing at Random (MAR) and self-masking (Missing Not At Random).
Based on a Neumann-series approximation of the optimal predictor, we propose a
new principled architecture, named NeuMiss networks. Their originality and
strength come from the use of a new type of non-linearity: the multiplication
by the missingness indicator. We provide an upper bound on the Bayes risk of
NeuMiss networks, and show that they have good predictive accuracy with both a
number of parameters and a computational complexity independent of the number
of missing data patterns. As a result they scale well to problems with many
features, and remain statistically efficient for medium-sized samples.
Moreover, we show that, contrary to procedures using EM or imputation, they are
robust to the missing data mechanism, including difficult MNAR settings such as
self-masking.
</p>
<a href="http://arxiv.org/abs/2007.01627" target="_blank">arXiv:2007.01627</a> [<a href="http://arxiv.org/pdf/2007.01627" target="_blank">pdf</a>]

<h2>Is Standard Deviation the New Standard? Revisiting the Critic in Deep Policy Gradients. (arXiv:2010.04440v1 [cs.LG] CROSS LISTED)</h2>
<h3>Yannis Flet-Berliac, Reda Ouhamma, Odalric-Ambrym Maillard, Philippe Preux</h3>
<p>Policy gradient algorithms have proven to be successful in diverse decision
making and control tasks. However, these methods suffer from high sample
complexity and instability issues. In this paper, we address these challenges
by providing a different approach for training the critic in the actor-critic
framework. Our work builds on recent studies indicating that traditional
actor-critic algorithms do not succeed in fitting the true value function,
calling for the need to identify a better objective for the critic. In our
method, the critic uses a new state-value (resp. state-action-value) function
approximation that learns the relative value of the states (resp. state-action
pairs) rather than their absolute value as in conventional actor-critic. We
prove the theoretical consistency of the new gradient estimator and observe
dramatic empirical improvement across a variety of continuous control tasks and
algorithms. Furthermore, we validate our method in tasks with sparse rewards,
where we provide experimental evidence and theoretical insights.
</p>
<a href="http://arxiv.org/abs/2010.04440" target="_blank">arXiv:2010.04440</a> [<a href="http://arxiv.org/pdf/2010.04440" target="_blank">pdf</a>]

<h2>Machine Learning approach to muon spectroscopy analysis. (arXiv:2010.04742v1 [cond-mat.mtrl-sci])</h2>
<h3>T. Tula (1), G. M&#xf6;ller (1), J. Quintanilla (1), S. R. Giblin (2), A. D. Hillier (3), E. E. McCabe (1), S. Ramos (1), D. S. Barker (1), S. Gibson (1) ((1) School of Physical Sciences, University of Kent, (2) School of Physics and Astronomy, Cardiff University, (3) ISIS Facility, STFC Rutherford Appleton Laboratory)</h3>
<p>In recent years, Artificial Intelligence techniques have proved to be very
successful when applied to problems in physical sciences. Here we apply an
unsupervised Machine Learning (ML) algorithm called Principal Component
Analysis (PCA) as a tool to analyse the data from muon spectroscopy
experiments. Specifically, we apply the ML technique to detect phase
transitions in various materials. The measured quantity in muon spectroscopy is
an asymmetry function, which may hold information about the distribution of the
intrinsic magnetic field in combination with the dynamics of the sample. Sharp
changes of shape of asymmetry functions - measured at different temperatures -
might indicate a phase transition. Existing methods of processing the muon
spectroscopy data are based on regression analysis, but choosing the right
fitting function requires knowledge about the underlying physics of the probed
material. Conversely, Principal Component Analysis focuses on small differences
in the asymmetry curves and works without any prior assumptions about the
studied samples. We discovered that the PCA method works well in detecting
phase transitions in muon spectroscopy experiments and can serve as an
alternative to current analysis, especially if the physics of the studied
material are not entirely known. Additionally, we found out that our ML
technique seems to work best with large numbers of measurements, regardless of
whether the algorithm takes data only for a single material or whether the
analysis is performed simultaneously for many materials with different physical
properties.
</p>
<a href="http://arxiv.org/abs/2010.04742" target="_blank">arXiv:2010.04742</a> [<a href="http://arxiv.org/pdf/2010.04742" target="_blank">pdf</a>]

<h2>Nowcasting of COVID-19 confirmed cases: Foundations, trends, and challenges. (arXiv:2010.05079v1 [q-bio.PE])</h2>
<h3>Tanujit Chakraborty, Indrajit Ghosh, Tirna Mahajan, Tejasvi Arora</h3>
<p>The coronavirus disease 2019 (COVID-19) has become a public health emergency
of international concern affecting more than 200 countries and territories
worldwide. As of September 30, 2020, it has caused a pandemic outbreak with
more than 33 million confirmed infections and more than 1 million reported
deaths worldwide. Several statistical, machine learning, and hybrid models have
previously tried to forecast COVID-19 confirmed cases for profoundly affected
countries. Due to extreme uncertainty and nonstationarity in the time series
data, forecasting of COVID-19 confirmed cases has become a very challenging
job. For univariate time series forecasting, there are various statistical and
machine learning models available in the literature. But, epidemic forecasting
has a dubious track record. Its failures became more prominent due to
insufficient data input, flaws in modeling assumptions, high sensitivity of
estimates, lack of incorporation of epidemiological features, inadequate past
evidence on effects of available interventions, lack of transparency, errors,
lack of determinacy, and lack of expertise in crucial disciplines. This chapter
focuses on assessing different short-term forecasting models that can forecast
the daily COVID-19 cases for various countries. In the form of an empirical
study on forecasting accuracy, this chapter provides evidence to show that
there is no universal method available that can accurately forecast pandemic
data. Still, forecasters' predictions are useful for the effective allocation
of healthcare resources and will act as an early-warning system for government
policymakers.
</p>
<a href="http://arxiv.org/abs/2010.05079" target="_blank">arXiv:2010.05079</a> [<a href="http://arxiv.org/pdf/2010.05079" target="_blank">pdf</a>]

<h2>Interpretable Neural Networks for Panel Data Analysis in Economics. (arXiv:2010.05311v1 [econ.EM])</h2>
<h3>Yucheng Yang, Zhong Zheng, Weinan E</h3>
<p>The lack of interpretability and transparency are preventing economists from
using advanced tools like neural networks in their empirical work. In this
paper, we propose a new class of interpretable neural network models that can
achieve both high prediction accuracy and interpretability in regression
problems with time series cross-sectional data. Our model can essentially be
written as a simple function of a limited number of interpretable features. In
particular, we incorporate a class of interpretable functions named persistent
change filters as part of the neural network. We apply this model to predicting
individual's monthly employment status using high-dimensional administrative
data in China. We achieve an accuracy of 94.5% on the out-of-sample test set,
which is comparable to the most accurate conventional machine learning methods.
Furthermore, the interpretability of the model allows us to understand the
mechanism that underlies the ability for predicting employment status using
administrative data: an individual's employment status is closely related to
whether she pays different types of insurances. Our work is a useful step
towards overcoming the "black box" problem of neural networks, and provide a
promising new tool for economists to study administrative and proprietary big
data.
</p>
<a href="http://arxiv.org/abs/2010.05311" target="_blank">arXiv:2010.05311</a> [<a href="http://arxiv.org/pdf/2010.05311" target="_blank">pdf</a>]

<h2>Convergence to the fixed-node limit in deep variational Monte Carlo. (arXiv:2010.05316v1 [physics.comp-ph])</h2>
<h3>Zeno Sch&#xe4;tzle, Jan Hermann, Frank No&#xe9;</h3>
<p>Variational quantum Monte Carlo (QMC) is an ab-initio method for solving the
electronic Schr\"odinger equation that is exact in principle, but limited by
the flexibility of the available ansatzes in practice. The recently introduced
deep QMC approach, specifically two deep-neural-network ansatzes PauliNet and
FermiNet, allows variational QMC to reach the accuracy of diffusion QMC, but
little is understood about the convergence behavior of such ansatzes. Here, we
analyze how deep variational QMC approaches the fixed-node limit with
increasing network size. First, we demonstrate that a deep neural network can
overcome the limitations of a small basis set and reach the mean-field
complete-basis-set limit. Moving to electron correlation, we then perform an
extensive hyperparameter scan of a deep Jastrow factor for LiH and H$_4$ and
find that variational energies at the fixed-node limit can be obtained with a
sufficiently large network. Finally, we benchmark mean-field and many-body
ansatzes on H$_2$O, increasing the fraction of recovered fixed-node correlation
energy by half an order of magnitude compared to previous VMC results. This
analysis helps understanding the superb performance of deep variational
ansatzes, and will guide future improvements of the neural network
architectures in deep QMC.
</p>
<a href="http://arxiv.org/abs/2010.05316" target="_blank">arXiv:2010.05316</a> [<a href="http://arxiv.org/pdf/2010.05316" target="_blank">pdf</a>]

<h2>Causal learning with sufficient statistics: an information bottleneck approach. (arXiv:2010.05375v1 [stat.ML])</h2>
<h3>Daniel Chicharro, Michel Besserve, Stefano Panzeri</h3>
<p>The inference of causal relationships using observational data from partially
observed multivariate systems with hidden variables is a fundamental question
in many scientific domains. Methods extracting causal information from
conditional independencies between variables of a system are common tools for
this purpose, but are limited in the lack of independencies. To surmount this
limitation, we capitalize on the fact that the laws governing the generative
mechanisms of a system often result in substructures embodied in the generative
functional equation of a variable, which act as sufficient statistics for the
influence that other variables have on it. These functional sufficient
statistics constitute intermediate hidden variables providing new conditional
independencies to be tested. We propose to use the Information Bottleneck
method, a technique commonly applied for dimensionality reduction, to find
underlying sufficient sets of statistics. Using these statistics we formulate
new additional rules of causal orientation that provide causal information not
obtainable from standard structure learning algorithms, which exploit only
conditional independencies between observable variables. We validate the use of
sufficient statistics for structure learning both with simulated systems built
to contain specific sufficient statistics and with benchmark data from
regulatory rules previously and independently proposed to model biological
signal transduction networks.
</p>
<a href="http://arxiv.org/abs/2010.05375" target="_blank">arXiv:2010.05375</a> [<a href="http://arxiv.org/pdf/2010.05375" target="_blank">pdf</a>]

<h2>Meta-Active Learning for Node Response Prediction in Graphs. (arXiv:2010.05387v1 [stat.ML])</h2>
<h3>Tomoharu Iwata</h3>
<p>Meta-learning is an important approach to improve machine learning
performance with a limited number of observations for target tasks. However,
when observations are unbalancedly obtained, it is difficult to improve the
performance even with meta-learning methods. In this paper, we propose an
active learning method for meta-learning on node response prediction tasks in
attributed graphs, where nodes to observe are selected to improve performance
with as few observed nodes as possible. With the proposed method, we use models
based on graph convolutional neural networks for both predicting node responses
and selecting nodes, by which we can predict responses and select nodes even
for graphs with unseen response variables. The response prediction model is
trained by minimizing the expected test error. The node selection model is
trained by maximizing the expected error reduction with reinforcement learning.
We demonstrate the effectiveness of the proposed method with 11 types of road
congestion prediction tasks.
</p>
<a href="http://arxiv.org/abs/2010.05387" target="_blank">arXiv:2010.05387</a> [<a href="http://arxiv.org/pdf/2010.05387" target="_blank">pdf</a>]

<h2>Robust Finite Mixture Regression for Heterogeneous Targets. (arXiv:2010.05430v1 [stat.ML])</h2>
<h3>Jian Liang, Kun Chen, Ming Lin, Changshui Zhang, Fei Wang</h3>
<p>Finite Mixture Regression (FMR) refers to the mixture modeling scheme which
learns multiple regression models from the training data set. Each of them is
in charge of a subset. FMR is an effective scheme for handling sample
heterogeneity, where a single regression model is not enough for capturing the
complexities of the conditional distribution of the observed samples given the
features. In this paper, we propose an FMR model that 1) finds sample clusters
and jointly models multiple incomplete mixed-type targets simultaneously, 2)
achieves shared feature selection among tasks and cluster components, and 3)
detects anomaly tasks or clustered structure among tasks, and accommodates
outlier samples. We provide non-asymptotic oracle performance bounds for our
model under a high-dimensional learning framework. The proposed model is
evaluated on both synthetic and real-world data sets. The results show that our
model can achieve state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2010.05430" target="_blank">arXiv:2010.05430</a> [<a href="http://arxiv.org/pdf/2010.05430" target="_blank">pdf</a>]

<h2>Feature Extraction of Text for Deep Learning Algorithms: Application on Fake News Dectection. (arXiv:2010.05496v1 [cs.CL])</h2>
<h3>HyeonJun Kim</h3>
<p>Feature extraction is important process of machine learning and even deep
learning, as the process make algorithms function more efficiently, and also
accurate. In natural language processing used in deception detection such as
fake news detection, several ways of feature extraction in statistical aspect
had been introduced (e.g. N-gram). In this research, it will be shown that by
using deep learning algorithms and alphabet frequencies of the original text of
a news without any information about the sequence of the alphabet can actually
be used to classify fake news and trustworthy ones in high accuracy (85%). As
this pre-processing method make the data notably compact but also include the
feature that is needed for the classifier, it seems that alphabet frequencies
contains some useful features for understanding complex context or meaning of
the original text.
</p>
<a href="http://arxiv.org/abs/2010.05496" target="_blank">arXiv:2010.05496</a> [<a href="http://arxiv.org/pdf/2010.05496" target="_blank">pdf</a>]

<h2>Local Search for Policy Iteration in Continuous Control. (arXiv:2010.05545v1 [cs.LG])</h2>
<h3>Jost Tobias Springenberg, Nicolas Heess, Daniel Mankowitz, Josh Merel, Arunkumar Byravan, Abbas Abdolmaleki, Jackie Kay, Jonas Degrave, Julian Schrittwieser, Yuval Tassa, Jonas Buchli, Dan Belov, Martin Riedmiller</h3>
<p>We present an algorithm for local, regularized, policy improvement in
reinforcement learning (RL) that allows us to formulate model-based and
model-free variants in a single framework. Our algorithm can be interpreted as
a natural extension of work on KL-regularized RL and introduces a form of tree
search for continuous action spaces. We demonstrate that additional computation
spent on model-based policy improvement during learning can improve data
efficiency, and confirm that model-based policy improvement during action
selection can also be beneficial. Quantitatively, our algorithm improves data
efficiency on several continuous control benchmarks (when a model is learned in
parallel), and it provides significant improvements in wall-clock time in
high-dimensional domains (when a ground truth model is available). The unified
framework also helps us to better understand the space of model-based and
model-free algorithms. In particular, we demonstrate that some benefits
attributed to model-based RL can be obtained without a model, simply by
utilizing more computation.
</p>
<a href="http://arxiv.org/abs/2010.05545" target="_blank">arXiv:2010.05545</a> [<a href="http://arxiv.org/pdf/2010.05545" target="_blank">pdf</a>]

<h2>Graph Information Bottleneck for Subgraph Recognition. (arXiv:2010.05563v1 [cs.LG])</h2>
<h3>Junchi Yu, Tingyang Xu, Yu Rong, Yatao Bian, Junzhou Huang, Ran He</h3>
<p>Given the input graph and its label/property, several key problems of graph
learning, such as finding interpretable subgraphs, graph denoising and graph
compression, can be attributed to the fundamental problem of recognizing a
subgraph of the original one. This subgraph shall be as informative as
possible, yet contains less redundant and noisy structure. This problem setting
is closely related to the well-known information bottleneck (IB) principle,
which, however, has less been studied for the irregular graph data and graph
neural networks (GNNs). In this paper, we propose a framework of Graph
Information Bottleneck (GIB) for the subgraph recognition problem in deep graph
learning. Under this framework, one can recognize the maximally informative yet
compressive subgraph, named IB-subgraph. However, the GIB objective is
notoriously hard to optimize, mostly due to the intractability of the mutual
information of irregular graph data and the unstable optimization process. In
order to tackle these challenges, we propose: i) a GIB objective based-on a
mutual information estimator for the irregular graph data; ii) a bi-level
optimization scheme to maximize the GIB objective; iii) a connectivity loss to
stabilize the optimization process. We evaluate the properties of the
IB-subgraph in three application scenarios: improvement of graph
classification, graph interpretation and graph denoising. Extensive experiments
demonstrate that the information-theoretic IB-subgraph enjoys superior graph
properties.
</p>
<a href="http://arxiv.org/abs/2010.05563" target="_blank">arXiv:2010.05563</a> [<a href="http://arxiv.org/pdf/2010.05563" target="_blank">pdf</a>]

<h2>Rethinking Experience Replay: a Bag of Tricks for Continual Learning. (arXiv:2010.05595v1 [cs.LG])</h2>
<h3>Pietro Buzzega, Matteo Boschini, Angelo Porrello, Simone Calderara</h3>
<p>In Continual Learning, a Neural Network is trained on a stream of data whose
distribution shifts over time. Under these assumptions, it is especially
challenging to improve on classes appearing later in the stream while remaining
accurate on previous ones. This is due to the infamous problem of catastrophic
forgetting, which causes a quick performance degradation when the classifier
focuses on learning new categories. Recent literature proposed various
approaches to tackle this issue, often resorting to very sophisticated
techniques. In this work, we show that naive rehearsal can be patched to
achieve similar performance. We point out some shortcomings that restrain
Experience Replay (ER) and propose five tricks to mitigate them. Experiments
show that ER, thus enhanced, displays an accuracy gain of 51.2 and 26.9
percentage points on the CIFAR-10 and CIFAR-100 datasets respectively (memory
buffer size 1000). As a result, it surpasses current state-of-the-art
rehearsal-based methods.
</p>
<a href="http://arxiv.org/abs/2010.05595" target="_blank">arXiv:2010.05595</a> [<a href="http://arxiv.org/pdf/2010.05595" target="_blank">pdf</a>]

<h2>Deep Gated Canonical Correlation Analysis. (arXiv:2010.05620v1 [cs.LG])</h2>
<h3>Ofir Lindenbaum, Moshe Salhov, Amir Averbuch, Yuval Kluger</h3>
<p>Canonical Correlation Analysis (CCA) models can extract informative
correlated representations from multimodal unlabelled data. Despite their
success, CCA models may break if the number of variables exceeds the number of
samples. We propose Deep Gated-CCA, a method for learning correlated
representations based on a sparse subset of variables from two observed
modalities. The proposed procedure learns two non-linear transformations and
simultaneously gates the input variables to identify a subset of most
correlated variables. The non-linear transformations are learned by training
two neural networks to maximize a shared correlation loss defined based on
their outputs. Gating is obtained by adding an approximate $\ell_0$
regularization term applied to the input variables. This approximation relies
on a recently proposed continuous Gaussian based relaxation for Bernoulli
variables which act as gates. We demonstrate the efficacy of the method using
several synthetic and real examples. Most notably, the method outperforms other
linear and non-linear CCA models.
</p>
<a href="http://arxiv.org/abs/2010.05620" target="_blank">arXiv:2010.05620</a> [<a href="http://arxiv.org/pdf/2010.05620" target="_blank">pdf</a>]

<h2>Inferring Causal Direction from Observational Data: A Complexity Approach. (arXiv:2010.05635v1 [cs.LG])</h2>
<h3>Nikolaos Nikolaou, Konstantinos Sechidis</h3>
<p>At the heart of causal structure learning from observational data lies a
deceivingly simple question: given two statistically dependent random
variables, which one has a causal effect on the other? This is impossible to
answer using statistical dependence testing alone and requires that we make
additional assumptions. We propose several fast and simple criteria for
distinguishing cause and effect in pairs of discrete or continuous random
variables. The intuition behind them is that predicting the effect variable
using the cause variable should be `simpler' than the reverse -- different
notions of `simplicity' giving rise to different criteria. We demonstrate the
accuracy of the criteria on synthetic data generated under a broad family of
causal mechanisms and types of noise.
</p>
<a href="http://arxiv.org/abs/2010.05635" target="_blank">arXiv:2010.05635</a> [<a href="http://arxiv.org/pdf/2010.05635" target="_blank">pdf</a>]

<h2>From Time Series to Euclidean Spaces: On Spatial Transformations for Temporal Clustering. (arXiv:2010.05681v1 [cs.LG])</h2>
<h3>Nuno Mota Goncalves, Ioana Giurgiu, Anika Schumann</h3>
<p>Unsupervised clustering of temporal data is both challenging and crucial in
machine learning. In this paper, we show that neither traditional clustering
methods, time series specific or even deep learning-based alternatives
generalise well when both varying sampling rates and high dimensionality are
present in the input data. We propose a novel approach to temporal clustering,
in which we (1) transform the input time series into a distance-based projected
representation by using similarity measures suitable for dealing with temporal
data,(2) feed these projections into a multi-layer CNN-GRU autoencoder to
generate meaningful domain-aware latent representations, which ultimately (3)
allow for a natural separation of clusters beneficial for most important
traditional clustering algorithms. We evaluate our approach on time series
datasets from various domains and show that it not only outperforms existing
methods in all cases, by up to 32%, but is also robust and incurs negligible
computation overheads.
</p>
<a href="http://arxiv.org/abs/2010.05681" target="_blank">arXiv:2010.05681</a> [<a href="http://arxiv.org/pdf/2010.05681" target="_blank">pdf</a>]

<h2>On Feature Selection Using Anisotropic General Regression Neural Network. (arXiv:2010.05744v1 [stat.ML])</h2>
<h3>Federico Amato, Fabian Guignard, Philippe Jacquet, Mikhail Kanevski</h3>
<p>The presence of irrelevant features in the input dataset tends to reduce the
interpretability and predictive quality of machine learning models. Therefore,
the development of feature selection methods to recognize irrelevant features
is a crucial topic in machine learning. Here we show how the General Regression
Neural Network used with an anisotropic Gaussian Kernel can be used to perform
feature selection. A number of numerical experiments are conducted using
simulated data to study the robustness of the proposed methodology and its
sensitivity to sample size. Finally, a comparison with four other feature
selection methods is performed on several real world datasets.
</p>
<a href="http://arxiv.org/abs/2010.05744" target="_blank">arXiv:2010.05744</a> [<a href="http://arxiv.org/pdf/2010.05744" target="_blank">pdf</a>]

<h2>Discrete Latent Space World Models for Reinforcement Learning. (arXiv:2010.05767v1 [cs.LG])</h2>
<h3>Jan Robine, Tobias Uelwer, Stefan Harmeling</h3>
<p>Sample efficiency remains a fundamental issue of reinforcement learning.
Model-based algorithms try to make better use of data by simulating the
environment with a model. We propose a new neural network architecture for
world models based on a vector quantized-variational autoencoder (VQ-VAE) to
encode observations and a convolutional LSTM to predict the next embedding
indices. A model-free PPO agent is trained purely on simulated experience from
the world model. We adopt the setup introduced by Kaiser et al. (2020), which
only allows 100K interactions with the real environment, and show that we reach
better performance than their SimPLe algorithm in five out of six randomly
selected Atari environments, while our model is significantly smaller.
</p>
<a href="http://arxiv.org/abs/2010.05767" target="_blank">arXiv:2010.05767</a> [<a href="http://arxiv.org/pdf/2010.05767" target="_blank">pdf</a>]

<h2>Deep Learning for Information Systems Research. (arXiv:2010.05774v1 [cs.LG])</h2>
<h3>Sagar Samtani, Hongyi Zhu, Balaji Padmanabhan, Yidong Chai, Hsinchun Chen</h3>
<p>Artificial Intelligence (AI) has rapidly emerged as a key disruptive
technology in the 21st century. At the heart of modern AI lies Deep Learning
(DL), an emerging class of algorithms that has enabled today's platforms and
organizations to operate at unprecedented efficiency, effectiveness, and scale.
Despite significant interest, IS contributions in DL have been limited, which
we argue is in part due to issues with defining, positioning, and conducting DL
research. Recognizing the tremendous opportunity here for the IS community,
this work clarifies, streamlines, and presents approaches for IS scholars to
make timely and high-impact contributions. Related to this broader goal, this
paper makes five timely contributions. First, we systematically summarize the
major components of DL in a novel Deep Learning for Information Systems
Research (DL-ISR) schematic that illustrates how technical DL processes are
driven by key factors from an application environment. Second, we present a
novel Knowledge Contribution Framework (KCF) to help IS scholars position their
DL contributions for maximum impact. Third, we provide ten guidelines to help
IS scholars generate rigorous and relevant DL-ISR in a systematic, high-quality
fashion. Fourth, we present a review of prevailing journal and conference
venues to examine how IS scholars have leveraged DL for various research
inquiries. Finally, we provide a unique perspective on how IS scholars can
formulate DL-ISR inquiries by carefully considering the interplay of business
function(s), application areas(s), and the KCF. This perspective intentionally
emphasizes inter-disciplinary, intra-disciplinary, and cross-IS tradition
perspectives. Taken together, these contributions provide IS scholars a timely
framework to advance the scale, scope, and impact of deep learning research.
</p>
<a href="http://arxiv.org/abs/2010.05774" target="_blank">arXiv:2010.05774</a> [<a href="http://arxiv.org/pdf/2010.05774" target="_blank">pdf</a>]

<h2>Structural Forecasting for Tropical Cyclone Intensity Prediction: Providing Insight with Deep Learning. (arXiv:2010.05783v1 [cs.LG])</h2>
<h3>Trey McNeely, Niccol&#xf2; Dalmasso, Kimberly M. Wood, Ann B. Lee</h3>
<p>Tropical cyclone (TC) intensity forecasts are ultimately issued by human
forecasters. The human in-the-loop pipeline requires that any forecasting
guidance must be easily digestible by TC experts if it is to be adopted at
operational centers like the National Hurricane Center. Our proposed framework
leverages deep learning to provide forecasters with something neither
end-to-end prediction models nor traditional intensity guidance does: a
powerful tool for monitoring high-dimensional time series of key physically
relevant predictors and the means to understand how the predictors relate to
one another and to short-term intensity changes.
</p>
<a href="http://arxiv.org/abs/2010.05783" target="_blank">arXiv:2010.05783</a> [<a href="http://arxiv.org/pdf/2010.05783" target="_blank">pdf</a>]

<h2>How Important is the Train-Validation Split in Meta-Learning?. (arXiv:2010.05843v1 [cs.LG])</h2>
<h3>Yu Bai, Minshuo Chen, Pan Zhou, Tuo Zhao, Jason D. Lee, Sham Kakade, Huan Wang, Caiming Xiong</h3>
<p>Meta-learning aims to perform fast adaptation on a new task through learning
a "prior" from multiple existing tasks. A common practice in meta-learning is
to perform a train-validation split where the prior adapts to the task on one
split of the data, and the resulting predictor is evaluated on another split.
Despite its prevalence, the importance of the train-validation split is not
well understood either in theory or in practice, particularly in comparison to
the more direct non-splitting method, which uses all the per-task data for both
training and evaluation.

We provide a detailed theoretical study on whether and when the
train-validation split is helpful on the linear centroid meta-learning problem,
in the asymptotic setting where the number of tasks goes to infinity. We show
that the splitting method converges to the optimal prior as expected, whereas
the non-splitting method does not in general without structural assumptions on
the data. In contrast, if the data are generated from linear models (the
realizable regime), we show that both the splitting and non-splitting methods
converge to the optimal prior. Further, perhaps surprisingly, our main result
shows that the non-splitting method achieves a strictly better asymptotic
excess risk under this data distribution, even when the regularization
parameter and split ratio are optimally tuned for both methods. Our results
highlight that data splitting may not always be preferable, especially when the
data is realizable by the model. We validate our theories by experimentally
showing that the non-splitting method can indeed outperform the splitting
method, on both simulations and real meta-learning tasks.
</p>
<a href="http://arxiv.org/abs/2010.05843" target="_blank">arXiv:2010.05843</a> [<a href="http://arxiv.org/pdf/2010.05843" target="_blank">pdf</a>]

<h2>BayReL: Bayesian Relational Learning for Multi-omics Data Integration. (arXiv:2010.05895v1 [cs.LG])</h2>
<h3>Ehsan Hajiramezanali, Arman Hasanzadeh, Nick Duffield, Krishna R Narayanan, Xiaoning Qian</h3>
<p>High-throughput molecular profiling technologies have produced
high-dimensional multi-omics data, enabling systematic understanding of living
systems at the genome scale. Studying molecular interactions across different
data types helps reveal signal transduction mechanisms across different classes
of molecules. In this paper, we develop a novel Bayesian representation
learning method that infers the relational interactions across multi-omics data
types. Our method, Bayesian Relational Learning (BayReL) for multi-omics data
integration, takes advantage of a priori known relationships among the same
class of molecules, modeled as a graph at each corresponding view, to learn
view-specific latent variables as well as a multi-partite graph that encodes
the interactions across views. Our experiments on several real-world datasets
demonstrate enhanced performance of BayReL in inferring meaningful interactions
compared to existing baselines.
</p>
<a href="http://arxiv.org/abs/2010.05895" target="_blank">arXiv:2010.05895</a> [<a href="http://arxiv.org/pdf/2010.05895" target="_blank">pdf</a>]

<h2>Panel Data Quantile Regression for Treatment Effect Models. (arXiv:2001.04324v2 [stat.ME] UPDATED)</h2>
<h3>Takuya Ishihara</h3>
<p>In this study, we develop a novel estimation method of the quantile treatment
effects (QTE) under the rank invariance and rank stationarity assumptions.
Ishihara (2020) explores identification of the nonseparable panel data model
under these assumptions and propose a parametric estimation based on the
minimum distance method. However, the minimum distance estimation using this
process is computationally demanding when the dimensionality of covariates is
large. To overcome this problem, we propose a two-step estimation method based
on the quantile regression and minimum distance method. We then show
consistency and asymptotic normality of our estimator. Monte Carlo studies
indicate that our estimator performs well in finite samples. Last, we present
two empirical illustrations, to estimate the distributional effects of
insurance provision on household production and of TV watching on child
cognitive development.
</p>
<a href="http://arxiv.org/abs/2001.04324" target="_blank">arXiv:2001.04324</a> [<a href="http://arxiv.org/pdf/2001.04324" target="_blank">pdf</a>]

<h2>A new method for faster and more accurate inference of species associations from big community data. (arXiv:2003.05331v4 [q-bio.QM] UPDATED)</h2>
<h3>Maximilian Pichler, Florian Hartig</h3>
<p>Joint Species Distribution models (jSDMs) explain spatial variation in
community composition by contributions of the environment, biotic associations,
and possibly spatially structured residual variance. They show great promise as
a general analytical framework for community ecology and macroecology, but
current jSDMs scale poorly on large datasets, limiting their usefulness for
novel community data, such as datasets generated using metabarcoding and
metagenomics. Here, we present sjSDM, a novel method for estimating jSDMs that
is based on Monte-Carlo integration of the joint likelihood. Implemented in
PyTorch, a modern machine learning framework that can make use of CPU and GPU
calculations, this approach is orders of magnitude faster than existing jSDM
algorithms and can be scaled to very large datasets. Despite the dramatically
improved speed, sjSDM produces the same predictive error and more accurate
estimates of species association structures than alternative jSDM
implementations. We provide our method in an R package to facilitate its
applicability for practical data analysis.
</p>
<a href="http://arxiv.org/abs/2003.05331" target="_blank">arXiv:2003.05331</a> [<a href="http://arxiv.org/pdf/2003.05331" target="_blank">pdf</a>]

<h2>NeuMiss networks: differential programming for supervised learning with missing values. (arXiv:2007.01627v2 [cs.LG] UPDATED)</h2>
<h3>Marine Le Morvan (PARIETAL, IJCLab), Julie Josse (CMAP, XPOP), Thomas Moreau (PARIETAL), Erwan Scornet (CMAP), Ga&#xeb;l Varoquaux (PARIETAL, MILA)</h3>
<p>The presence of missing values makes supervised learning much more
challenging. Indeed, previous work has shown that even when the response is a
linear function of the complete data, the optimal predictor is a complex
function of the observed entries and the missingness indicator. As a result,
the computational or sample complexities of consistent approaches depend on the
number of missing patterns, which can be exponential in the number of
dimensions. In this work, we derive the analytical form of the optimal
predictor under a linearity assumption and various missing data mechanisms
including Missing at Random (MAR) and self-masking (Missing Not At Random).
Based on a Neumann-series approximation of the optimal predictor, we propose a
new principled architecture, named NeuMiss networks. Their originality and
strength come from the use of a new type of non-linearity: the multiplication
by the missingness indicator. We provide an upper bound on the Bayes risk of
NeuMiss networks, and show that they have good predictive accuracy with both a
number of parameters and a computational complexity independent of the number
of missing data patterns. As a result they scale well to problems with many
features, and remain statistically efficient for medium-sized samples.
Moreover, we show that, contrary to procedures using EM or imputation, they are
robust to the missing data mechanism, including difficult MNAR settings such as
self-masking.
</p>
<a href="http://arxiv.org/abs/2007.01627" target="_blank">arXiv:2007.01627</a> [<a href="http://arxiv.org/pdf/2007.01627" target="_blank">pdf</a>]

<h2>CausalWorld: A Robotic Manipulation Benchmark for Causal Structure and Transfer Learning. (arXiv:2010.04296v1 [cs.RO] CROSS LISTED)</h2>
<h3>Ossama Ahmed, Frederik Tr&#xe4;uble, Anirudh Goyal, Alexander Neitz, Manuel W&#xfc;thrich, Yoshua Bengio, Bernhard Sch&#xf6;lkopf, Stefan Bauer</h3>
<p>Despite recent successes of reinforcement learning (RL), it remains a
challenge for agents to transfer learned skills to related environments. To
facilitate research addressing this problem, we propose CausalWorld, a
benchmark for causal structure and transfer learning in a robotic manipulation
environment. The environment is a simulation of an open-source robotic
platform, hence offering the possibility of sim-to-real transfer. Tasks consist
of constructing 3D shapes from a given set of blocks - inspired by how children
learn to build complex structures. The key strength of CausalWorld is that it
provides a combinatorial family of such tasks with common causal structure and
underlying factors (including, e.g., robot and object masses, colors, sizes).
The user (or the agent) may intervene on all causal variables, which allows for
fine-grained control over how similar different tasks (or task distributions)
are. One can thus easily define training and evaluation distributions of a
desired difficulty level, targeting a specific form of generalization (e.g.,
only changes in appearance or object mass). Further, this common
parametrization facilitates defining curricula by interpolating between an
initial and a target task. While users may define their own task distributions,
we present eight meaningful distributions as concrete benchmarks, ranging from
simple to very challenging, all of which require long-horizon planning as well
as precise low-level motor control. Finally, we provide baseline results for a
subset of these tasks on distinct training curricula and corresponding
evaluation protocols, verifying the feasibility of the tasks in this benchmark.
</p>
<a href="http://arxiv.org/abs/2010.04296" target="_blank">arXiv:2010.04296</a> [<a href="http://arxiv.org/pdf/2010.04296" target="_blank">pdf</a>]

<h2>Wildfire Smoke and Air Quality: How Machine Learning Can Guide Forest Management. (arXiv:2010.04651v1 [stat.AP] CROSS LISTED)</h2>
<h3>Lorenzo Tomaselli, Coty Jen, Ann B. Lee</h3>
<p>Prescribed burns are currently the most effective method of reducing the risk
of widespread wildfires, but a largely missing component in forest management
is knowing which fuels one can safely burn to minimize exposure to toxic smoke.
Here we show how machine learning, such as spectral clustering and manifold
learning, can provide interpretable representations and powerful tools for
differentiating between smoke types, hence providing forest managers with vital
information on effective strategies to reduce climate-induced wildfires while
minimizing production of harmful smoke.
</p>
<a href="http://arxiv.org/abs/2010.04651" target="_blank">arXiv:2010.04651</a> [<a href="http://arxiv.org/pdf/2010.04651" target="_blank">pdf</a>]

