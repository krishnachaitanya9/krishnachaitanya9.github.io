---
title: Latest Deep Learning Papers
date: 2021-01-24 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (106 Articles)</h1>
<h2>A Person Re-identification Data Augmentation Method with Adversarial Defense Effect. (arXiv:2101.08783v1 [cs.CV])</h2>
<h3>Yunpeng Gong, Zhiyong Zeng, Liwen Chen, Yifan Luo, Bin Weng, Feng Ye</h3>
<p>The security of the Person Re-identification(ReID) model plays a decisive
role in the application of ReID. However, deep neural networks have been shown
to be vulnerable, and adding undetectable adversarial perturbations to clean
images can trick deep neural networks that perform well in clean images. We
propose a ReID multi-modal data augmentation method with adversarial defense
effect: 1) Grayscale Patch Replacement, it consists of Local Grayscale Patch
Replacement(LGPR) and Global Grayscale Patch Replacement(GGPR). This method can
not only improve the accuracy of the model, but also help the model defend
against adversarial examples; 2) Multi-Modal Defense, it integrates three
homogeneous modal images of visible, grayscale and sketch, and further
strengthens the defense ability of the model. These methods fuse different
modalities of homogeneous images to enrich the input sample variety, the
variaty of samples will reduce the over-fitting of the ReID model to color
variations and make the adversarial space of the dataset that the attack method
can find difficult to align, thus the accuracy of model is improved, and the
attack effect is greatly reduced. The more modal homogeneous images are fused,
the stronger the defense capabilities is . The proposed method performs well on
multiple datasets, and successfully defends the attack of MS-SSIM proposed by
CVPR2020 against ReID [10], and increases the accuracy by 467 times(0.2% to
93.3%).
</p>
<a href="http://arxiv.org/abs/2101.08783" target="_blank">arXiv:2101.08783</a> [<a href="http://arxiv.org/pdf/2101.08783" target="_blank">pdf</a>]

<h2>PyGlove: Symbolic Programming for Automated Machine Learning. (arXiv:2101.08809v1 [cs.LG])</h2>
<h3>Daiyi Peng, Xuanyi Dong, Esteban Real, Mingxing Tan, Yifeng Lu, Hanxiao Liu, Gabriel Bender, Adam Kraft, Chen Liang, Quoc V. Le</h3>
<p>Neural networks are sensitive to hyper-parameter and architecture choices.
Automated Machine Learning (AutoML) is a promising paradigm for automating
these choices. Current ML software libraries, however, are quite limited in
handling the dynamic interactions among the components of AutoML. For example,
efficientNAS algorithms, such as ENAS and DARTS, typically require an
implementation coupling between the search space and search algorithm, the two
key components in AutoML. Furthermore, implementing a complex search flow, such
as searching architectures within a loop of searching hardware configurations,
is difficult. To summarize, changing the search space, search algorithm, or
search flow in current ML libraries usually requires a significant change in
the program logic. In this paper, we introduce a new way of programming AutoML
based on symbolic programming. Under this paradigm, ML programs are mutable,
thus can be manipulated easily by another program. As a result, AutoML can be
reformulated as an automated process of symbolic manipulation. With this
formulation, we decouple the triangle of the search algorithm, the search space
and the child program. This decoupling makes it easy to change the search space
and search algorithm (without and with weight sharing), as well as to add
search capabilities to existing code and implement complex search flows. We
then introduce PyGlove, a new Python library that implements this paradigm.
Through case studies on ImageNet and NAS-Bench-101, we show that with PyGlove
users can easily convert a static program into a search space, quickly iterate
on the search spaces and search algorithms, and craft complex search flows to
achieve better results.
</p>
<a href="http://arxiv.org/abs/2101.08809" target="_blank">arXiv:2101.08809</a> [<a href="http://arxiv.org/pdf/2101.08809" target="_blank">pdf</a>]

<h2>Centralized Collision-free Polynomial Trajectories and Goal Assignment for Aerial Swarms. (arXiv:2101.08829v1 [cs.RO])</h2>
<h3>Benjamin Gravell, Tyler Summers</h3>
<p>Computationally tractable methods are developed for centralized goal
assignment and planning of collision-free polynomial-in-time trajectories for
systems of multiple aerial robots. The method first assigns robots to goals to
minimize total time-in-motion based on initial trajectories. By coupling the
assignment and trajectory generation, the initial motion plans tend to require
only limited collision resolution. The plans are then refined by checking for
potential collisions and resolving them using either start time delays or
altitude assignment. Numerical experiments using both methods show significant
reductions in the total time required for agents to arrive at goals with only
modest additional computational effort in comparison to state-of-the-art prior
work, enabling planning for thousands of agents.
</p>
<a href="http://arxiv.org/abs/2101.08829" target="_blank">arXiv:2101.08829</a> [<a href="http://arxiv.org/pdf/2101.08829" target="_blank">pdf</a>]

<h2>SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation. (arXiv:2101.08833v1 [cs.CV])</h2>
<h3>Brendan Duke, Abdalla Ahmed, Christian Wolf, Parham Aarabi, Graham W. Taylor</h3>
<p>In this paper we introduce a Transformer-based approach to video object
segmentation (VOS). To address compounding error and scalability issues of
prior work, we propose a scalable, end-to-end method for VOS called Sparse
Spatiotemporal Transformers (SST). SST extracts per-pixel representations for
each object in a video using sparse attention over spatiotemporal features. Our
attention-based formulation for VOS allows a model to learn to attend over a
history of multiple frames and provides suitable inductive bias for performing
correspondence-like computations necessary for solving motion segmentation. We
demonstrate the effectiveness of attention-based over recurrent networks in the
spatiotemporal domain. Our method achieves competitive results on YouTube-VOS
and DAVIS 2017 with improved scalability and robustness to occlusions compared
with the state of the art.
</p>
<a href="http://arxiv.org/abs/2101.08833" target="_blank">arXiv:2101.08833</a> [<a href="http://arxiv.org/pdf/2101.08833" target="_blank">pdf</a>]

<h2>Time-Correlated Sparsification for Communication-Efficient Federated Learning. (arXiv:2101.08837v1 [cs.LG])</h2>
<h3>Emre Ozfatura, Kerem Ozfatura, Deniz Gunduz</h3>
<p>Federated learning (FL) enables multiple clients to collaboratively train a
shared model without disclosing their local datasets. This is achieved by
exchanging local model updates with the help of a parameter server (PS).
However, due to the increasing size of the trained models, the communication
load due to the iterative exchanges between the clients and the PS often
becomes a bottleneck in the performance. Sparse communication is often employed
to reduce the communication load, where only a small subset of the model
updates are communicated from the clients to the PS. In this paper, we
introduce a novel time-correlated sparsification (TCS) scheme, which builds
upon the notion that sparse communication framework can be considered as
identifying the most significant elements of the underlying model. Hence, TCS
seeks a certain correlation between the sparse representations used at
consecutive iterations in FL, so that the overhead due to encoding and
transmission of the sparse representation can be significantly reduced without
compromising the test accuracy. Through extensive simulations on the CIFAR-10
dataset, we show that TCS can achieve centralized training accuracy with 100
times sparsification, and up to 2000 times reduction in the communication load
when employed together with quantization.
</p>
<a href="http://arxiv.org/abs/2101.08837" target="_blank">arXiv:2101.08837</a> [<a href="http://arxiv.org/pdf/2101.08837" target="_blank">pdf</a>]

<h2>Occlusion Handling in Generic Object Detection: A Review. (arXiv:2101.08845v1 [cs.CV])</h2>
<h3>Kaziwa Saleh, S&#xe1;ndor Sz&#xe9;n&#xe1;si, Zolt&#xe1;n V&#xe1;mossy</h3>
<p>The significant power of deep learning networks has led to enormous
development in object detection. Over the last few years, object detector
frameworks have achieved tremendous success in both accuracy and efficiency.
However, their ability is far from that of human beings due to several factors,
occlusion being one of them. Since occlusion can happen in various locations,
scale, and ratio, it is very difficult to handle. In this paper, we address the
challenges in occlusion handling in generic object detection in both outdoor
and indoor scenes, then we refer to the recent works that have been carried out
to overcome these challenges. Finally, we discuss some possible future
directions of research.
</p>
<a href="http://arxiv.org/abs/2101.08845" target="_blank">arXiv:2101.08845</a> [<a href="http://arxiv.org/pdf/2101.08845" target="_blank">pdf</a>]

<h2>A Spike Learning System for Event-driven Object Recognition. (arXiv:2101.08850v1 [cs.CV])</h2>
<h3>Shibo Zhou, Wei Wang, Xiaohua Li, Zhanpeng Jin</h3>
<p>Event-driven sensors such as LiDAR and dynamic vision sensor (DVS) have found
increased attention in high-resolution and high-speed applications. A lot of
work has been conducted to enhance recognition accuracy. However, the essential
topic of recognition delay or time efficiency is largely under-explored. In
this paper, we present a spiking learning system that uses the spiking neural
network (SNN) with a novel temporal coding for accurate and fast object
recognition. The proposed temporal coding scheme maps each event's arrival time
and data into SNN spike time so that asynchronously-arrived events are
processed immediately without delay. The scheme is integrated nicely with the
SNN's asynchronous processing capability to enhance time efficiency. A key
advantage over existing systems is that the event accumulation time for each
recognition task is determined automatically by the system rather than pre-set
by the user. The system can finish recognition early without waiting for all
the input events. Extensive experiments were conducted over a list of 7 LiDAR
and DVS datasets. The results demonstrated that the proposed system had
state-of-the-art recognition accuracy while achieving remarkable time
efficiency. Recognition delay was shown to reduce by 56.3% to 91.7% in various
experiment settings over the popular KITTI dataset.
</p>
<a href="http://arxiv.org/abs/2101.08850" target="_blank">arXiv:2101.08850</a> [<a href="http://arxiv.org/pdf/2101.08850" target="_blank">pdf</a>]

<h2>Bridging the gap between Human Action Recognition and Online Action Detection. (arXiv:2101.08851v1 [cs.CV])</h2>
<h3>Alban Main de Boissiere, Rita Noumeir</h3>
<p>Action recognition, early prediction, and online action detection are
complementary disciplines that are often studied independently. Most online
action detection networks use a pre-trained feature extractor, which might not
be optimal for its new task. We address the task-specific feature extraction
with a teacher-student framework between the aforementioned disciplines, and a
novel training strategy. Our network, Online Knowledge Distillation Action
Detection network (OKDAD), embeds online early prediction and online temporal
segment proposal subnetworks in parallel. Low interclass and high intraclass
similarity are encouraged during teacher training. Knowledge distillation to
the OKDAD network is ensured via layer reuse and cosine similarity between
teacher-student feature vectors. Layer reuse and similarity learning
significantly improve our baseline which uses a generic feature extractor. We
evaluate our framework on infrared videos from two popular datasets, NTU RGB+D
(action recognition, early prediction) and PKU MMD (action detection). Unlike
previous attempts on those datasets, our student networks perform without any
knowledge of the future. Even with this added difficulty, we achieve
state-of-the-art results on both datasets. Moreover, our networks use infrared
from RGB-D cameras, which we are the first to use for online action detection,
to our knowledge.
</p>
<a href="http://arxiv.org/abs/2101.08851" target="_blank">arXiv:2101.08851</a> [<a href="http://arxiv.org/pdf/2101.08851" target="_blank">pdf</a>]

<h2>Active Hybrid Classification. (arXiv:2101.08854v1 [cs.LG])</h2>
<h3>Evgeny Krivosheev, Fabio Casati, Alessandro Bozzon</h3>
<p>Hybrid crowd-machine classifiers can achieve superior performance by
combining the cost-effectiveness of automatic classification with the accuracy
of human judgment. This paper shows how crowd and machines can support each
other in tackling classification problems. Specifically, we propose an
architecture that orchestrates active learning and crowd classification and
combines them in a virtuous cycle. We show that when the pool of items to
classify is finite we face learning vs. exploitation trade-off in hybrid
classification, as we need to balance crowd tasks optimized for creating a
training dataset with tasks optimized for classifying items in the pool. We
define the problem, propose a set of heuristics and evaluate the approach on
three real-world datasets with different characteristics in terms of machine
and crowd classification performance, showing that our active hybrid approach
significantly outperforms baselines.
</p>
<a href="http://arxiv.org/abs/2101.08854" target="_blank">arXiv:2101.08854</a> [<a href="http://arxiv.org/pdf/2101.08854" target="_blank">pdf</a>]

<h2>Knowledge Generation -- Variational Bayes on Knowledge Graphs. (arXiv:2101.08857v1 [cs.LG])</h2>
<h3>Florian Wolf</h3>
<p>This thesis is a proof of concept for the potential of Variational
Auto-Encoder (VAE) on representation learning of real-world Knowledge Graphs
(KG). Inspired by successful approaches to the generation of molecular graphs,
we evaluate the capabilities of our model, the Relational Graph Variational
Auto-Encoder (RGVAE). The impact of the modular hyperparameter choices,
encoding through graph convolutions, graph matching and latent space prior, is
compared. The RGVAE is first evaluated on link prediction. The mean reciprocal
rank (MRR) scores on the two datasets FB15K-237 and WN18RR are compared to the
embedding-based model DistMult. A variational DistMult and a RGVAE without
latent space prior constraint are implemented as control models. The results
show that between different settings, the RGVAE with relaxed latent space,
scores highest on both datasets, yet does not outperform the DistMult. Further,
we investigate the latent space in a twofold experiment: first, linear
interpolation between the latent representation of two triples, then the
exploration of each latent dimension in a $95\%$ confidence interval. Both
interpolations show that the RGVAE learns to reconstruct the adjacency matrix
but fails to disentangle. For the last experiment we introduce a new validation
method for the FB15K-237 data set. The relation type-constrains of generated
triples are filtered and matched with entity types. The observed rate of valid
generated triples is insignificantly higher than the random threshold. All
generated and valid triples are unseen. A comparison between different latent
space priors, using the $\delta$-VAE method, reveals a decoder collapse.
Finally we analyze the limiting factors of our approach compared to molecule
generation and propose solutions for the decoder collapse and successful
representation learning of multi-relational KGs.
</p>
<a href="http://arxiv.org/abs/2101.08857" target="_blank">arXiv:2101.08857</a> [<a href="http://arxiv.org/pdf/2101.08857" target="_blank">pdf</a>]

<h2>Breaking the Deadly Triad with a Target Network. (arXiv:2101.08862v1 [cs.LG])</h2>
<h3>Shangtong Zhang, Hengshuai Yao, Shimon Whiteson</h3>
<p>The deadly triad refers to the instability of a reinforcement learning
algorithm when it employs off-policy learning, function approximation, and
bootstrapping simultaneously. In this paper, we investigate the target network
as a tool for breaking the deadly triad, providing theoretical support for the
conventional wisdom that a target network stabilizes training. We first propose
and analyze a novel target network update rule which augments the commonly used
Polyak-averaging style update with two projections. We then apply the target
network and ridge regularization in several divergent algorithms and show their
convergence to regularized TD fixed points. Those algorithms are off-policy
with linear function approximation and bootstrapping, spanning both policy
evaluation and control, as well as both discounted and average-reward settings.
In particular, we provide the first convergent linear $Q$-learning algorithms
under nonrestrictive and changing behavior policies without bi-level
optimization.
</p>
<a href="http://arxiv.org/abs/2101.08862" target="_blank">arXiv:2101.08862</a> [<a href="http://arxiv.org/pdf/2101.08862" target="_blank">pdf</a>]

<h2>Generative Replay-based Continual Zero-Shot Learning. (arXiv:2101.08894v1 [cs.CV])</h2>
<h3>Chandan Gautam, Sethupathy Parameswaran, Ashish Mishra, Suresh Sundaram</h3>
<p>Zero-shot learning is a new paradigm to classify objects from classes that
are not available at training time. Zero-shot learning (ZSL) methods have
attracted considerable attention in recent years because of their ability to
classify unseen/novel class examples. Most of the existing approaches on ZSL
works when all the samples from seen classes are available to train the model,
which does not suit real life. In this paper, we tackle this hindrance by
developing a generative replay-based continual ZSL (GRCZSL). The proposed
method endows traditional ZSL to learn from streaming data and acquire new
knowledge without forgetting the previous tasks' gained experience. We handle
catastrophic forgetting in GRCZSL by replaying the synthetic samples of seen
classes, which have appeared in the earlier tasks. These synthetic samples are
synthesized using the trained conditional variational autoencoder (VAE) over
the immediate past task. Moreover, we only require the current and immediate
previous VAE at any time for training and testing. The proposed GRZSL method is
developed for a single-head setting of continual learning, simulating a
real-world problem setting. In this setting, task identity is given during
training but unavailable during testing. GRCZSL performance is evaluated on
five benchmark datasets for the generalized setup of ZSL with fixed and
incremental class settings of continual learning. Experimental results show
that the proposed method significantly outperforms the baseline method and
makes it more suitable for real-world applications.
</p>
<a href="http://arxiv.org/abs/2101.08894" target="_blank">arXiv:2101.08894</a> [<a href="http://arxiv.org/pdf/2101.08894" target="_blank">pdf</a>]

<h2>Iterative Optimisation with an Innovation CNN for Pose Refinement. (arXiv:2101.08895v1 [cs.CV])</h2>
<h3>Gerard Kennedy, Zheyu Zhuang, Xin Yu, Robert Mahony</h3>
<p>Object pose estimation from a single RGB image is a challenging problem due
to variable lighting conditions and viewpoint changes. The most accurate pose
estimation networks implement pose refinement via reprojection of a known,
textured 3D model, however, such methods cannot be applied without high quality
3D models of the observed objects. In this work we propose an approach, namely
an Innovation CNN, to object pose estimation refinement that overcomes the
requirement for reprojecting a textured 3D model. Our approach improves initial
pose estimation progressively by applying the Innovation CNN iteratively in a
stochastic gradient descent (SGD) framework. We evaluate our method on the
popular LINEMOD and Occlusion LINEMOD datasets and obtain state-of-the-art
performance on both datasets.
</p>
<a href="http://arxiv.org/abs/2101.08895" target="_blank">arXiv:2101.08895</a> [<a href="http://arxiv.org/pdf/2101.08895" target="_blank">pdf</a>]

<h2>SGA: A Robust Algorithm for Partial Recovery of Tree-Structured Graphical Models with Noisy Samples. (arXiv:2101.08917v1 [stat.ML])</h2>
<h3>Anshoo Tandon, Aldric H. J. Yuan, Vincent Y. F. Tan</h3>
<p>We consider learning Ising tree models when the observations from the nodes
are corrupted by independent but non-identically distributed noise with unknown
statistics. Katiyar et al. (2020) showed that although the exact tree structure
cannot be recovered, one can recover a partial tree structure; that is, a
structure belonging to the equivalence class containing the true tree. This
paper presents a systematic improvement of Katiyar et al. (2020). First, we
present a novel impossibility result by deriving a bound on the necessary
number of samples for partial recovery. Second, we derive a significantly
improved sample complexity result in which the dependence on the minimum
correlation $\rho_{\min}$ is $\rho_{\min}^{-8}$ instead of $\rho_{\min}^{-24}$.
Finally, we propose Symmetrized Geometric Averaging (SGA), a more statistically
robust algorithm for partial tree recovery. We provide error exponent analyses
and extensive numerical results on a variety of trees to show that the sample
complexity of SGA is significantly better than the algorithm of Katiyar et al.
(2020). SGA can be readily extended to Gaussian models and is shown via
numerical experiments to be similarly superior.
</p>
<a href="http://arxiv.org/abs/2101.08917" target="_blank">arXiv:2101.08917</a> [<a href="http://arxiv.org/pdf/2101.08917" target="_blank">pdf</a>]

<h2>Differentially Private SGD with Non-Smooth Loss. (arXiv:2101.08925v1 [stat.ML])</h2>
<h3>Puyu Wang, Yunwen Lei, Yiming Ying, Hai Zhang</h3>
<p>In this paper, we are concerned with differentially private SGD algorithms in
the setting of stochastic convex optimization (SCO). Most of existing work
requires the loss to be Lipschitz continuous and strongly smooth, and the model
parameter to be uniformly bounded. However, these assumptions are restrictive
as many popular losses violate these conditions including the hinge loss for
SVM, the absolute loss in robust regression, and even the least square loss in
an unbounded domain. We significantly relax these restrictive assumptions and
establish privacy and generalization (utility) guarantees for private SGD
algorithms using output and gradient perturbations associated with non-smooth
convex losses. Specifically, the loss function is relaxed to have
$\alpha$-H\"{o}lder continuous gradient (referred to as $\alpha$-H\"{o}lder
smoothness) which instantiates the Lipschitz continuity ($\alpha=0$) and strong
smoothness ($\alpha=1$). We prove that noisy SGD with $\alpha$-H\"older smooth
losses using gradient perturbation can guarantee
$(\epsilon,\delta)$-differential privacy (DP) and attain optimal excess
population risk
$O\Big(\frac{\sqrt{d\log(1/\delta)}}{n\epsilon}+\frac{1}{\sqrt{n}}\Big)$, up to
logarithmic terms, with gradient complexity (i.e. the total number of
iterations) $T =O( n^{2-\alpha\over 1+\alpha}+ n).$ This shows an important
trade-off between $\alpha$-H\"older smoothness of the loss and the
computational complexity $T$ for private SGD with statistically optimal
performance. In particular, our results indicate that $\alpha$-H\"older
smoothness with $\alpha\ge {1/2}$ is sufficient to guarantee
$(\epsilon,\delta)$-DP of noisy SGD algorithms while achieving optimal excess
risk with linear gradient complexity $T = O(n).$
</p>
<a href="http://arxiv.org/abs/2101.08925" target="_blank">arXiv:2101.08925</a> [<a href="http://arxiv.org/pdf/2101.08925" target="_blank">pdf</a>]

<h2>A Two-stream Neural Network for Pose-based Hand Gesture Recognition. (arXiv:2101.08926v1 [cs.CV])</h2>
<h3>Chuankun Li, Shuai Li, Yanbo Gao, Xiang Zhang, Wanqing Li</h3>
<p>Pose based hand gesture recognition has been widely studied in the recent
years. Compared with full body action recognition, hand gesture involves joints
that are more spatially closely distributed with stronger collaboration. This
nature requires a different approach from action recognition to capturing the
complex spatial features. Many gesture categories, such as "Grab" and "Pinch",
have very similar motion or temporal patterns posing a challenge on temporal
processing. To address these challenges, this paper proposes a two-stream
neural network with one stream being a self-attention based graph convolutional
network (SAGCN) extracting the short-term temporal information and hierarchical
spatial information, and the other being a residual-connection enhanced
bidirectional Independently Recurrent Neural Network (RBi-IndRNN) for
extracting long-term temporal information. The self-attention based graph
convolutional network has a dynamic self-attention mechanism to adaptively
exploit the relationships of all hand joints in addition to the fixed topology
and local feature extraction in the GCN. On the other hand, the
residual-connection enhanced Bi-IndRNN extends an IndRNN with the capability of
bidirectional processing for temporal modelling. The two streams are fused
together for recognition. The Dynamic Hand Gesture dataset and First-Person
Hand Action dataset are used to validate its effectiveness, and our method
achieves state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2101.08926" target="_blank">arXiv:2101.08926</a> [<a href="http://arxiv.org/pdf/2101.08926" target="_blank">pdf</a>]

<h2>AS-Net: Fast Photoacoustic Reconstruction with Multi-feature Fusion from Sparse Data. (arXiv:2101.08934v1 [cs.CV])</h2>
<h3>Mengjie Guo, Hengrong Lan, Changchun Yang, Fei Gao</h3>
<p>Photoacoustic (PA) imaging is a biomedical imaging modality capable of
acquiring high contrast images of optical absorption at depths much greater
than traditional optical imaging techniques. However, practical instrumentation
and geometry limit the number of available acoustic sensors surrounding the
imaging target, which results in sparsity of sensor data. Conventional PA image
reconstruction methods give severe artifacts when they are applied directly to
these sparse data. In this paper, we first employ a novel signal processing
method to make sparse PA raw data more suitable for the neural network, and
concurrently speeding up image reconstruction. Then we propose Attention
Steered Network (AS-Net) for PA reconstruction with multi-feature fusion.
AS-Net is validated on different datasets, including simulated photoacoustic
data from fundus vasculature phantoms and real data from in vivo fish and mice
imaging experiments. Notably, the method is also able to eliminate some
artifacts present in the ground-truth for in vivo data. Results demonstrated
that our method provides superior reconstructions at a faster speed.
</p>
<a href="http://arxiv.org/abs/2101.08934" target="_blank">arXiv:2101.08934</a> [<a href="http://arxiv.org/pdf/2101.08934" target="_blank">pdf</a>]

<h2>Prior Preference Learning from Experts:Designing a Reward with Active Inference. (arXiv:2101.08937v1 [cs.LG])</h2>
<h3>Jinyoung Shin, Cheolhyeong Kim, Hyung Ju Hwang</h3>
<p>Active inference may be defined as Bayesian modeling of a brain with a
biologically plausible model of the agent. Its primary idea relies on the free
energy principle and the prior preference of the agent. An agent will choose an
action that leads to its prior preference for a future observation. In this
paper, we claim that active inference can be interpreted using reinforcement
learning (RL) algorithms and find a theoretical connection between them. We
extend the concept of expected free energy (EFE), which is a core quantity in
active inference, and claim that EFE can be treated as a negative value
function. Motivated by the concept of prior preference and a theoretical
connection, we propose a simple but novel method for learning a prior
preference from experts. This illustrates that the problem with inverse RL can
be approached with a new perspective of active inference. Experimental results
of prior preference learning show the possibility of active inference with
EFE-based rewards and its application to an inverse RL problem.
</p>
<a href="http://arxiv.org/abs/2101.08937" target="_blank">arXiv:2101.08937</a> [<a href="http://arxiv.org/pdf/2101.08937" target="_blank">pdf</a>]

<h2>Hessian-Aware Pruning and Optimal Neural Implant. (arXiv:2101.08940v1 [cs.CV])</h2>
<h3>Shixing Yu, Zhewei Yao, Amir Gholami, Zhen Dong, Michael W Mahoney, Kurt Keutzer</h3>
<p>Pruning is an effective method to reduce the memory footprint and FLOPs
associated with neural network models. However, existing pruning methods often
result in significant accuracy degradation for moderate pruning levels. To
address this problem, we introduce a new Hessian Aware Pruning (HAP) method
which uses second-order sensitivity as a metric for structured pruning. In
particular, we use the Hessian trace to find insensitive parameters in the
neural network. This is different than magnitude based pruning methods, which
prune small weight values. We also propose a new neural implant method, which
replaces pruned spatial convolutions with point-wise convolution. We show that
this method can improve the accuracy of pruned models while preserving the
model size. We test HAP on multiple models (ResNet56, WideResNet32,
PreResNet29, VGG16) on CIFAR-10 and (ResNet50) on ImageNet, and we achieve new
state-of-the-art results. Specifically, HAP achieves 94.3\% accuracy ($&lt;0.1\%$
degradation) on PreResNet29 (CIFAR-10), with more than 70\% of parameters
pruned. In comparison to EigenDamage~\cite{wang2019eigendamage}, we achieve up
to 1.2\% higher accuracy with fewer parameters and FLOPs. Moreover, for
ResNet50 HAP achieves 75.1\% top-1 accuracy (0.5\% degradation) on ImageNet,
after pruning more than half of the parameters. In comparison to prior
state-of-the-art of HRank~\cite{lin2020hrank}, we achieve up to 2\% higher
accuracy with fewer parameters and FLOPs. The framework has been open source
and available online.
</p>
<a href="http://arxiv.org/abs/2101.08940" target="_blank">arXiv:2101.08940</a> [<a href="http://arxiv.org/pdf/2101.08940" target="_blank">pdf</a>]

<h2>Human Interaction Recognition Framework based on Interacting Body Part Attention. (arXiv:2101.08967v1 [cs.CV])</h2>
<h3>Dong-Gyu Lee, Seong-Whan Lee</h3>
<p>Human activity recognition in videos has been widely studied and has recently
gained significant advances with deep learning approaches; however, it remains
a challenging task. In this paper, we propose a novel framework that
simultaneously considers both implicit and explicit representations of human
interactions by fusing information of local image where the interaction
actively occurred, primitive motion with the posture of individual subject's
body parts, and the co-occurrence of overall appearance change. Human
interactions change, depending on how the body parts of each human interact
with the other. The proposed method captures the subtle difference between
different interactions using interacting body part attention. Semantically
important body parts that interact with other objects are given more weight
during feature representation. The combined feature of interacting body part
attention-based individual representation and the co-occurrence descriptor of
the full-body appearance change is fed into long short-term memory to model the
temporal dynamics over time in a single framework. We validate the
effectiveness of the proposed method using four widely used public datasets by
outperforming the competing state-of-the-art method.
</p>
<a href="http://arxiv.org/abs/2101.08967" target="_blank">arXiv:2101.08967</a> [<a href="http://arxiv.org/pdf/2101.08967" target="_blank">pdf</a>]

<h2>Visual Question Answering based on Local-Scene-Aware Referring Expression Generation. (arXiv:2101.08978v1 [cs.CV])</h2>
<h3>Jung-Jun Kim, Dong-Gyu Lee, Jialin Wu, Hong-Gyu Jung, Seong-Whan Lee</h3>
<p>Visual question answering requires a deep understanding of both images and
natural language. However, most methods mainly focus on visual concept; such as
the relationships between various objects. The limited use of object categories
combined with their relationships or simple question embedding is insufficient
for representing complex scenes and explaining decisions. To address this
limitation, we propose the use of text expressions generated for images,
because such expressions have few structural constraints and can provide richer
descriptions of images. The generated expressions can be incorporated with
visual features and question embedding to obtain the question-relevant answer.
A joint-embedding multi-head attention network is also proposed to model three
different information modalities with co-attention. We quantitatively and
qualitatively evaluated the proposed method on the VQA v2 dataset and compared
it with state-of-the-art methods in terms of answer prediction. The quality of
the generated expressions was also evaluated on the RefCOCO, RefCOCO+, and
RefCOCOg datasets. Experimental results demonstrate the effectiveness of the
proposed method and reveal that it outperformed all of the competing methods in
terms of both quantitative and qualitative results.
</p>
<a href="http://arxiv.org/abs/2101.08978" target="_blank">arXiv:2101.08978</a> [<a href="http://arxiv.org/pdf/2101.08978" target="_blank">pdf</a>]

<h2>Nonstationary Stochastic Multiarmed Bandits: UCB Policies and Minimax Regret. (arXiv:2101.08980v1 [cs.LG])</h2>
<h3>Lai Wei, Vaibhav Srivastava</h3>
<p>We study the nonstationary stochastic Multi-Armed Bandit (MAB) problem in
which the distribution of rewards associated with each arm are assumed to be
time-varying and the total variation in the expected rewards is subject to a
variation budget. The regret of a policy is defined by the difference in the
expected cumulative rewards obtained using the policy and using an oracle that
selects the arm with the maximum mean reward at each time. We characterize the
performance of the proposed policies in terms of the worst-case regret, which
is the supremum of the regret over the set of reward distribution sequences
satisfying the variation budget. We extend Upper-Confidence Bound (UCB)-based
policies with three different approaches, namely, periodic resetting, sliding
observation window and discount factor and show that they are order-optimal
with respect to the minimax regret, i.e., the minimum worst-case regret
achieved by any policy. We also relax the sub-Gaussian assumption on reward
distributions and develop robust versions the proposed polices that can handle
heavy-tailed reward distributions and maintain their performance guarantees.
</p>
<a href="http://arxiv.org/abs/2101.08980" target="_blank">arXiv:2101.08980</a> [<a href="http://arxiv.org/pdf/2101.08980" target="_blank">pdf</a>]

<h2>Artificial intelligence prediction of stock prices using social media. (arXiv:2101.08986v1 [cs.AI])</h2>
<h3>Kavyashree Ranawat, Stefano Giani</h3>
<p>The primary objective of this work is to develop a Neural Network based on
LSTM to predict stock market movements using tweets. Word embeddings, used in
the LSTM network, are initialised using Stanford's GloVe embeddings, pretrained
specifically on 2 billion tweets. To overcome the limited size of the dataset,
an augmentation strategy is proposed to split each input sequence into 150
subsets. To achieve further improvements in the original configuration,
hyperparameter optimisation is performed. The effects of variation in
hyperparameters such as dropout rate, batch size, and LSTM hidden state output
size are assessed individually. Furthermore, an exhaustive set of parameter
combinations is examined to determine the optimal model configuration. The best
performance on the validation dataset is achieved by hyperparameter combination
0.4,8,100 for the dropout, batch size, and hidden units respectively. The final
testing accuracy of the model is 76.14%.
</p>
<a href="http://arxiv.org/abs/2101.08986" target="_blank">arXiv:2101.08986</a> [<a href="http://arxiv.org/pdf/2101.08986" target="_blank">pdf</a>]

<h2>Cross Chest Graph for Disease Diagnosis with Structural Relational Reasoning. (arXiv:2101.08992v1 [cs.CV])</h2>
<h3>Gangming Zhao, Baolian Qi, Jinpeng Li</h3>
<p>Locating lesions is important in the computer-aided diagnosis of X-ray
images. However, box-level annotation is time-consuming and laborious. How to
locate lesions accurately with few, or even without careful annotations is an
urgent problem. Although several works have approached this problem with
weakly-supervised methods, the performance needs to be improved. One obstacle
is that general weakly-supervised methods have failed to consider the
characteristics of X-ray images, such as the highly-structural attribute. We
therefore propose the Cross-chest Graph (CCG), which improves the performance
of automatic lesion detection by imitating doctor's training and
decision-making process. CCG models the intra-image relationship between
different anatomical areas by leveraging the structural information to simulate
the doctor's habit of observing different areas. Meanwhile, the relationship
between any pair of images is modeled by a knowledge-reasoning module to
simulate the doctor's habit of comparing multiple images. We integrate
intra-image and inter-image information into a unified end-to-end framework.
Experimental results on the NIH Chest-14 database (112,120 frontal-view X-ray
images with 14 diseases) demonstrate that the proposed method achieves
state-of-the-art performance in weakly-supervised localization of lesions by
absorbing professional knowledge in the medical field.
</p>
<a href="http://arxiv.org/abs/2101.08992" target="_blank">arXiv:2101.08992</a> [<a href="http://arxiv.org/pdf/2101.08992" target="_blank">pdf</a>]

<h2>Linear Regression with Distributed Learning: A Generalization Error Perspective. (arXiv:2101.09001v1 [stat.ML])</h2>
<h3>Martin Hellkvist, Ay&#xe7;a &#xd6;z&#xe7;elikkale, Anders Ahl&#xe9;n</h3>
<p>Distributed learning provides an attractive framework for scaling the
learning task by sharing the computational load over multiple nodes in a
network. Here, we investigate the performance of distributed learning for
large-scale linear regression where the model parameters, i.e., the unknowns,
are distributed over the network. We adopt a statistical learning approach. In
contrast to works that focus on the performance on the training data, we focus
on the generalization error, i.e., the performance on unseen data. We provide
high-probability bounds on the generalization error for both isotropic and
correlated Gaussian data as well as sub-gaussian data. These results reveal the
dependence of the generalization performance on the partitioning of the model
over the network. In particular, our results show that the generalization error
of the distributed solution can be substantially higher than that of the
centralized solution even when the error on the training data is at the same
level for both the centralized and distributed approaches. Our numerical
results illustrate the performance with both real-world image data as well as
synthetic data.
</p>
<a href="http://arxiv.org/abs/2101.09001" target="_blank">arXiv:2101.09001</a> [<a href="http://arxiv.org/pdf/2101.09001" target="_blank">pdf</a>]

<h2>Personal Fixations-Based Object Segmentation with Object Localization and Boundary Preservation. (arXiv:2101.09014v1 [cs.CV])</h2>
<h3>Gongyang Li, Zhi Liu, Ran Shi, Zheng Hu, Weijie Wei, Yong Wu, Mengke Huang, Haibin Ling</h3>
<p>As a natural way for human-computer interaction, fixation provides a
promising solution for interactive image segmentation. In this paper, we focus
on Personal Fixations-based Object Segmentation (PFOS) to address issues in
previous studies, such as the lack of appropriate dataset and the ambiguity in
fixations-based interaction. In particular, we first construct a new PFOS
dataset by carefully collecting pixel-level binary annotation data over an
existing fixation prediction dataset, such dataset is expected to greatly
facilitate the study along the line. Then, considering characteristics of
personal fixations, we propose a novel network based on Object Localization and
Boundary Preservation (OLBP) to segment the gazed objects. Specifically, the
OLBP network utilizes an Object Localization Module (OLM) to analyze personal
fixations and locates the gazed objects based on the interpretation. Then, a
Boundary Preservation Module (BPM) is designed to introduce additional boundary
information to guard the completeness of the gazed objects. Moreover, OLBP is
organized in the mixed bottom-up and top-down manner with multiple types of
deep supervision. Extensive experiments on the constructed PFOS dataset show
the superiority of the proposed OLBP network over 17 state-of-the-art methods,
and demonstrate the effectiveness of the proposed OLM and BPM components. The
constructed PFOS dataset and the proposed OLBP network are available at
https://github.com/MathLee/OLBPNet4PFOS.
</p>
<a href="http://arxiv.org/abs/2101.09014" target="_blank">arXiv:2101.09014</a> [<a href="http://arxiv.org/pdf/2101.09014" target="_blank">pdf</a>]

<h2>A Closer Look at Temporal Sentence Grounding in Videos: Datasets and Metrics. (arXiv:2101.09028v1 [cs.CV])</h2>
<h3>Yitian Yuan, Xiaohan Lan, Long Chen, Wei Liu, Wenwu Zhu</h3>
<p>Despite Temporal Sentence Grounding in Videos (TSGV) has realized impressive
progress over the last few years, current TSGV models tend to capture the
moment annotation biases and fail to take full advantage of multi-modal inputs.
Miraculously, some extremely simple TSGV baselines even without training can
also achieve state-of-the-art performance. In this paper, we first take a
closer look at the existing evaluation protocol, and argue that both the
prevailing datasets and metrics are the devils to cause the unreliable
benchmarking. To this end, we propose to re-organize two widely-used TSGV
datasets (Charades-STA and ActivityNet Captions), and deliberately
\textbf{C}hange the moment annotation \textbf{D}istribution of the test split
to make it different from the training split, dubbed as Charades-CD and
ActivityNet-CD, respectively. Meanwhile, we further introduce a new evaluation
metric "dR@$n$,IoU@$m$" to calibrate the basic IoU scores by penalizing more on
the over-long moment predictions and reduce the inflating performance caused by
the moment annotation biases. Under this new evaluation protocol, we conduct
extensive experiments and ablation studies on eight state-of-the-art TSGV
models. All the results demonstrate that the re-organized datasets and new
metric can better monitor the progress in TSGV, which is still far from
satisfactory. The repository of this work is at
\url{https://github.com/yytzsy/grounding_changing_distribution}.
</p>
<a href="http://arxiv.org/abs/2101.09028" target="_blank">arXiv:2101.09028</a> [<a href="http://arxiv.org/pdf/2101.09028" target="_blank">pdf</a>]

<h2>Selfish Sparse RNN Training. (arXiv:2101.09048v1 [cs.LG])</h2>
<h3>Shiwei Liu, Decebal Constantin Mocanu, Yulong Pei, Mykola Pechenizkiy</h3>
<p>Sparse neural networks have been widely applied to reduce the necessary
resource requirements to train and deploy over-parameterized deep neural
networks. For inference acceleration, methods that induce sparsity from a
pre-trained dense network (dense-to-sparse) work effectively. Recently, dynamic
sparse training (DST) has been proposed to train sparse neural networks without
pre-training a dense network (sparse-to-sparse), so that the training process
can also be accelerated. However, previous sparse-to-sparse methods mainly
focus on Multilayer Perceptron Networks (MLPs) and Convolutional Neural
Networks (CNNs), failing to match the performance of dense-to-sparse methods in
Recurrent Neural Networks (RNNs) setting. In this paper, we propose an approach
to train sparse RNNs with a fixed parameter count in one single run, without
compromising performance. During training, we allow RNN layers to have a
non-uniform redistribution across cell gates for a better regularization.
Further, we introduce SNT-ASGD, a variant of the averaged stochastic gradient
optimizer, which significantly improves the performance of all sparse training
methods for RNNs. Using these strategies, we achieve state-of-the-art sparse
training results with various types of RNNs on Penn TreeBank and Wikitext-2
datasets.
</p>
<a href="http://arxiv.org/abs/2101.09048" target="_blank">arXiv:2101.09048</a> [<a href="http://arxiv.org/pdf/2101.09048" target="_blank">pdf</a>]

<h2>Chemistry42: An AI-based platform for de novo molecular design. (arXiv:2101.09050v1 [cs.AI])</h2>
<h3>Yan A. Ivanenkov, Alex Zhebrak, Dmitry Bezrukov, Bogdan Zagribelnyy, Vladimir Aladinskiy, Daniil Polykovskiy, Evgeny Putin, Petrina Kamya, Alexander Aliper, Alex Zhavoronkov</h3>
<p>Chemistry42 is a software platform for de novo small molecule design that
integrates Artificial Intelligence (AI) techniques with computational and
medicinal chemistry methods. Chemistry42 is unique in its ability to generate
novel molecular structures with predefined properties validated through in
vitro and in vivo studies. Chemistry42 is a core component of Insilico Medicine
Pharma.ai drug discovery suite that also includes target discovery and
multi-omics data analysis (PandaOmics) and clinical trial outcomes predictions
(InClinico).
</p>
<a href="http://arxiv.org/abs/2101.09050" target="_blank">arXiv:2101.09050</a> [<a href="http://arxiv.org/pdf/2101.09050" target="_blank">pdf</a>]

<h2>Adversarial Laws of Large Numbers and Optimal Regret in Online Classification. (arXiv:2101.09054v1 [cs.LG])</h2>
<h3>Noga Alon, Omri Ben-Eliezer, Yuval Dagan, Shay Moran, Moni Naor, Eylon Yogev</h3>
<p>Laws of large numbers guarantee that given a large enough sample from some
population, the measure of any fixed sub-population is well-estimated by its
frequency in the sample. We study laws of large numbers in sampling processes
that can affect the environment they are acting upon and interact with it.
Specifically, we consider the sequential sampling model proposed by Ben-Eliezer
and Yogev (2020), and characterize the classes which admit a uniform law of
large numbers in this model: these are exactly the classes that are
\emph{online learnable}. Our characterization may be interpreted as an online
analogue to the equivalence between learnability and uniform convergence in
statistical (PAC) learning.

The sample-complexity bounds we obtain are tight for many parameter regimes,
and as an application, we determine the optimal regret bounds in online
learning, stated in terms of \emph{Littlestone's dimension}, thus resolving the
main open question from Ben-David, P\'al, and Shalev-Shwartz (2009), which was
also posed by Rakhlin, Sridharan, and Tewari (2015).
</p>
<a href="http://arxiv.org/abs/2101.09054" target="_blank">arXiv:2101.09054</a> [<a href="http://arxiv.org/pdf/2101.09054" target="_blank">pdf</a>]

<h2>A Few Good Counterfactuals: Generating Interpretable, Plausible and Diverse Counterfactual Explanations. (arXiv:2101.09056v1 [cs.AI])</h2>
<h3>Barry Smyth, Mark T Keane</h3>
<p>Counterfactual explanations provide a potentially significant solution to the
Explainable AI (XAI) problem, but good, native counterfactuals have been shown
to rarely occur in most datasets. Hence, the most popular methods generate
synthetic counterfactuals using blind perturbation. However, such methods have
several shortcomings: the resulting counterfactuals (i) may not be valid
data-points (they often use features that do not naturally occur), (ii) may
lack the sparsity of good counterfactuals (if they modify too many features),
and (iii) may lack diversity (if the generated counterfactuals are minimal
variants of one another). We describe a method designed to overcome these
problems, one that adapts native counterfactuals in the original dataset, to
generate sparse, diverse synthetic counterfactuals from naturally occurring
features. A series of experiments are reported that systematically explore
parametric variations of this novel method on common datasets to establish the
conditions for optimal performance.
</p>
<a href="http://arxiv.org/abs/2101.09056" target="_blank">arXiv:2101.09056</a> [<a href="http://arxiv.org/pdf/2101.09056" target="_blank">pdf</a>]

<h2>DSAL: Deeply Supervised Active Learning from Strong and Weak Labelers for Biomedical Image Segmentation. (arXiv:2101.09057v1 [cs.CV])</h2>
<h3>Ziyuan Zhao, Zeng Zeng, Kaixin Xu, Cen Chen, Cuntai Guan</h3>
<p>Image segmentation is one of the most essential biomedical image processing
problems for different imaging modalities, including microscopy and X-ray in
the Internet-of-Medical-Things (IoMT) domain. However, annotating biomedical
images is knowledge-driven, time-consuming, and labor-intensive, making it
difficult to obtain abundant labels with limited costs. Active learning
strategies come into ease the burden of human annotation, which queries only a
subset of training data for annotation. Despite receiving attention, most of
active learning methods generally still require huge computational costs and
utilize unlabeled data inefficiently. They also tend to ignore the intermediate
knowledge within networks. In this work, we propose a deep active
semi-supervised learning framework, DSAL, combining active learning and
semi-supervised learning strategies. In DSAL, a new criterion based on deep
supervision mechanism is proposed to select informative samples with high
uncertainties and low uncertainties for strong labelers and weak labelers
respectively. The internal criterion leverages the disagreement of intermediate
features within the deep learning network for active sample selection, which
subsequently reduces the computational costs. We use the proposed criteria to
select samples for strong and weak labelers to produce oracle labels and pseudo
labels simultaneously at each active learning iteration in an ensemble learning
manner, which can be examined with IoMT Platform. Extensive experiments on
multiple medical image datasets demonstrate the superiority of the proposed
method over state-of-the-art active learning methods.
</p>
<a href="http://arxiv.org/abs/2101.09057" target="_blank">arXiv:2101.09057</a> [<a href="http://arxiv.org/pdf/2101.09057" target="_blank">pdf</a>]

<h2>Rethinking Domain Generalization Baselines. (arXiv:2101.09060v1 [cs.CV])</h2>
<h3>Francesco Cappio Borlino, Antonio D&#x27;Innocente, Tatiana Tommasi</h3>
<p>Despite being very powerful in standard learning settings, deep learning
models can be extremely brittle when deployed in scenarios different from those
on which they were trained. Domain generalization methods investigate this
problem and data augmentation strategies have shown to be helpful tools to
increase data variability, supporting model robustness across domains. In our
work we focus on style transfer data augmentation and we present how it can be
implemented with a simple and inexpensive strategy to improve generalization.
Moreover, we analyze the behavior of current state of the art domain
generalization methods when integrated with this augmentation solution: our
thorough experimental evaluation shows that their original effect almost always
disappears with respect to the augmented baseline. This issue open new
scenarios for domain generalization research, highlighting the need of novel
methods properly able to take advantage of the introduced data variability.
</p>
<a href="http://arxiv.org/abs/2101.09060" target="_blank">arXiv:2101.09060</a> [<a href="http://arxiv.org/pdf/2101.09060" target="_blank">pdf</a>]

<h2>A shallow neural model for relation prediction. (arXiv:2101.09090v1 [cs.LG])</h2>
<h3>Caglar Demir, Diego Moussallem, Axel-Cyrille Ngonga Ngomo</h3>
<p>Knowledge graph completion refers to predicting missing triples. Most
approaches achieve this goal by predicting entities, given an entity and a
relation. We predict missing triples via the relation prediction. To this end,
we frame the relation prediction problem as a multi-label classification
problem and propose a shallow neural model (SHALLOM) that accurately infers
missing relations from entities. SHALLOM is analogous to C-BOW as both
approaches predict a central token (p) given surrounding tokens ((s,o)). Our
experiments indicate that SHALLOM outperforms state-of-the-art approaches on
the FB15K-237 and WN18RR with margins of up to $3\%$ and $8\%$ (absolute),
respectively, while requiring a maximum training time of 8 minutes on these
datasets. We ensure the reproducibility of our results by providing an
open-source implementation including training and evaluation scripts at
{\url{https://github.com/dice-group/Shallom}.}
</p>
<a href="http://arxiv.org/abs/2101.09090" target="_blank">arXiv:2101.09090</a> [<a href="http://arxiv.org/pdf/2101.09090" target="_blank">pdf</a>]

<h2>Towards Enhancing Fine-grained Details for Image Matting. (arXiv:2101.09095v1 [cs.CV])</h2>
<h3>Chang Liu, Henghui Ding, Xudong Jiang</h3>
<p>In recent years, deep natural image matting has been rapidly evolved by
extracting high-level contextual features into the model. However, most current
methods still have difficulties with handling tiny details, like hairs or furs.
In this paper, we argue that recovering these microscopic details relies on
low-level but high-definition texture features. However, {these features are
downsampled in a very early stage in current encoder-decoder-based models,
resulting in the loss of microscopic details}. To address this issue, we design
a deep image matting model {to enhance fine-grained details. Our model consists
of} two parallel paths: a conventional encoder-decoder Semantic Path and an
independent downsampling-free Textural Compensate Path (TCP). The TCP is
proposed to extract fine-grained details such as lines and edges in the
original image size, which greatly enhances the fineness of prediction.
Meanwhile, to leverage the benefits of high-level context, we propose a feature
fusion unit(FFU) to fuse multi-scale features from the semantic path and inject
them into the TCP. In addition, we have observed that poorly annotated trimaps
severely affect the performance of the model. Thus we further propose a novel
term in loss function and a trimap generation method to improve our model's
robustness to the trimaps. The experiments show that our method outperforms
previous start-of-the-art methods on the Composition-1k dataset.
</p>
<a href="http://arxiv.org/abs/2101.09095" target="_blank">arXiv:2101.09095</a> [<a href="http://arxiv.org/pdf/2101.09095" target="_blank">pdf</a>]

<h2>Adaptive Neighbourhoods for the Discovery of Adversarial Examples. (arXiv:2101.09108v1 [cs.LG])</h2>
<h3>Jay Morgan, Adeline Paiement, Arno Pauly, Monika Seisenberger</h3>
<p>Deep Neural Networks (DNNs) have often supplied state-of-the-art results in
pattern recognition tasks. Despite their advances, however, the existence of
adversarial examples have caught the attention of the community. Many existing
works have proposed methods for searching for adversarial examples within
fixed-sized regions around training points. Our work complements and improves
these existing approaches by adapting the size of these regions based on the
problem complexity and data sampling density. This makes such approaches more
appropriate for other types of data and may further improve adversarial
training methods by increasing the region sizes without creating incorrect
labels.
</p>
<a href="http://arxiv.org/abs/2101.09108" target="_blank">arXiv:2101.09108</a> [<a href="http://arxiv.org/pdf/2101.09108" target="_blank">pdf</a>]

<h2>Pareto GAN: Extending the Representational Power of GANs to Heavy-Tailed Distributions. (arXiv:2101.09113v1 [cs.LG])</h2>
<h3>Todd Huster, Jeremy E.J. Cohen, Zinan Lin, Kevin Chan, Charles Kamhoua, Nandi Leslie, Cho-Yu Jason Chiang, Vyas Sekar</h3>
<p>Generative adversarial networks (GANs) are often billed as "universal
distribution learners", but precisely what distributions they can represent and
learn is still an open question. Heavy-tailed distributions are prevalent in
many different domains such as financial risk-assessment, physics, and
epidemiology. We observe that existing GAN architectures do a poor job of
matching the asymptotic behavior of heavy-tailed distributions, a problem that
we show stems from their construction. Additionally, when faced with the
infinite moments and large distances between outlier points that are
characteristic of heavy-tailed distributions, common loss functions produce
unstable or near-zero gradients. We address these problems with the Pareto GAN.
A Pareto GAN leverages extreme value theory and the functional properties of
neural networks to learn a distribution that matches the asymptotic behavior of
the marginal distributions of the features. We identify issues with standard
loss functions and propose the use of alternative metric spaces that enable
stable and efficient learning. Finally, we evaluate our proposed approach on a
variety of heavy-tailed datasets.
</p>
<a href="http://arxiv.org/abs/2101.09113" target="_blank">arXiv:2101.09113</a> [<a href="http://arxiv.org/pdf/2101.09113" target="_blank">pdf</a>]

<h2>Hybrid Rotation Averaging: A Globally Guaranteed Fast and Robust Rotation Averaging Approach. (arXiv:2101.09116v1 [cs.CV])</h2>
<h3>Yu Chen, Ji Zhao, Laurent Kneip</h3>
<p>We address rotation averaging and its application to real-world 3D
reconstruction. Local optimisation based approaches are the defacto choice,
though they only guarantee a local optimum. Global optimizers ensure global
optimality in low noise conditions, but they are inefficient and may easily
deviate under the influence of outliers or elevated noise levels. We push the
envelope of global rotation averaging by formulating it as a semi-definite
program that can be solved efficiently by applying the Burer-Monteiro method.
Both memory and time requirements are thereby largely reduced through a
low-rank factorisation. Combined with a fast view graph filtering as
preprocessing, and a local optimiser as post-processing, the proposed hybrid
approach is robust to outliers. Compared against state-of-the-art globally
optimal methods, our approach is 1 ~ 2 orders of magnitude faster while
maintaining the same or better accuracy. We apply the proposed hybrid rotation
averaging approach to incremental Structure from Motion (SfM) by adding the
resulting global rotations as regularizers to bundle adjustment. Overall, we
demonstrate high practicality of the proposed method as bad camera poses are
effectively corrected and drift is reduced.
</p>
<a href="http://arxiv.org/abs/2101.09116" target="_blank">arXiv:2101.09116</a> [<a href="http://arxiv.org/pdf/2101.09116" target="_blank">pdf</a>]

<h2>Will Artificial Intelligence supersede Earth System and Climate Models?. (arXiv:2101.09126v1 [stat.ML])</h2>
<h3>Christopher Irrgang (1), Niklas Boers (2 and 3 and 4), Maike Sonnewald (5 and 6 and 7), Elizabeth A. Barnes (8), Christopher Kadow (9), Joanna Staneva (10), Jan Saynisch-Wagner (1) ((1) Helmholtz Centre Potsdam, German Research Centre for Geosciences GFZ, Potsdam, Germany, (2) Department of Mathematics and Computer Science, Free University of Berlin, Germany, (3) Potsdam Institute for Climate Impact Research, Potsdam, Germany (4) Department of Mathematics and Global Systems Institute, University of Exeter, Exeter, UK (5) Program in Atmospheric and Oceanic Sciences, Princeton University, Princeton, USA (6) NOAA/OAR Geophysical Fluid Dynamics Laboratory, Ocean and Cryosphere Division, Princeton, USA (7) University of Washington, School of Oceanography, Seattle, USA (8) Colorado State University, Fort Collins, USA (9) German Climate Computing Center DKRZ, Hamburg, Germany (10) Helmholtz-Zentrum Geesthacht, Center for Material and Coastal Research HZG, Geesthacht, Germany)</h3>
<p>We outline a perspective of an entirely new research branch in Earth and
climate sciences, where deep neural networks and Earth system models are
dismantled as individual methodological approaches and reassembled as learning,
self-validating, and interpretable Earth system model-network hybrids.
Following this path, we coin the term "Neural Earth System Modelling" (NESYM)
and highlight the necessity of a transdisciplinary discussion platform,
bringing together Earth and climate scientists, big data analysts, and AI
experts. We examine the concurrent potential and pitfalls of Neural Earth
System Modelling and discuss the open question whether artificial intelligence
will not only infuse Earth system modelling, but ultimately render them
obsolete.
</p>
<a href="http://arxiv.org/abs/2101.09126" target="_blank">arXiv:2101.09126</a> [<a href="http://arxiv.org/pdf/2101.09126" target="_blank">pdf</a>]

<h2>Solving the Same-Different Task with Convolutional Neural Networks. (arXiv:2101.09129v1 [cs.CV])</h2>
<h3>Nicola Messina, Giuseppe Amato, Fabio Carrara, Claudio Gennaro, Fabrizio Falchi</h3>
<p>Deep learning demonstrated major abilities in solving many kinds of different
real-world problems in computer vision literature. However, they are still
strained by simple reasoning tasks that humans consider easy to solve. In this
work, we probe current state-of-the-art convolutional neural networks on a
difficult set of tasks known as the same-different problems. All the problems
require the same prerequisite to be solved correctly: understanding if two
random shapes inside the same image are the same or not. With the experiments
carried out in this work, we demonstrate that residual connections, and more
generally the skip connections, seem to have only a marginal impact on the
learning of the proposed problems. In particular, we experiment with DenseNets,
and we examine the contribution of residual and recurrent connections in
already tested architectures, ResNet-18, and CorNet-S respectively. Our
experiments show that older feed-forward networks, AlexNet and VGG, are almost
unable to learn the proposed problems, except in some specific scenarios. We
show that recently introduced architectures can converge even in the cases
where the important parts of their architecture are removed. We finally carry
out some zero-shot generalization tests, and we discover that in these
scenarios residual and recurrent connections can have a stronger impact on the
overall test accuracy. On four difficult problems from the SVRT dataset, we can
reach state-of-the-art results with respect to the previous approaches,
obtaining super-human performances on three of the four problems.
</p>
<a href="http://arxiv.org/abs/2101.09129" target="_blank">arXiv:2101.09129</a> [<a href="http://arxiv.org/pdf/2101.09129" target="_blank">pdf</a>]

<h2>A Study of Continuous Vector Representationsfor Theorem Proving. (arXiv:2101.09142v1 [cs.LG])</h2>
<h3>Stanis&#x142;aw Purga&#x142;, Julian Parsert, Cezary Kaliszyk</h3>
<p>Applying machine learning to mathematical terms and formulas requires a
suitable representation of formulas that is adequate for AI methods. In this
paper, we develop an encoding that allows for logical properties to be
preserved and is additionally reversible. This means that the tree shape of a
formula including all symbols can be reconstructed from the dense vector
representation. We do that by training two decoders: one that extracts the top
symbol of the tree and one that extracts embedding vectors of subtrees. The
syntactic and semantic logical properties that we aim to reserve include both
structural formula properties, applicability of natural deduction steps, and
even more complex operations like unifiability. We propose datasets that can be
used to train these syntactic and semantic properties. We evaluate the
viability of the developed encoding across the proposed datasets as well as for
the practical theorem proving problem of premise selection in the Mizar corpus.
</p>
<a href="http://arxiv.org/abs/2101.09142" target="_blank">arXiv:2101.09142</a> [<a href="http://arxiv.org/pdf/2101.09142" target="_blank">pdf</a>]

<h2>Virtual laser scanning with HELIOS++: A novel take on ray tracing-based simulation of topographic 3D laser scanning. (arXiv:2101.09154v1 [cs.CV])</h2>
<h3>Lukas Winiwarter, Alberto Manuel Esmor&#xed;s Pena, Hannah Weiser, Katharina Anders, Jorge Mart&#xed;nez Sanchez, Mark Searle, Bernhard H&#xf6;fle</h3>
<p>Topographic laser scanning is a remote sensing method to create detailed 3D
point cloud representations of the Earth's surface. Since data acquisition is
expensive, simulations can complement real data given certain premises are
available: i) a model of 3D scene and scanner, ii) a model of the beam-scene
interaction, simplified to a computationally feasible while physically
realistic level, and iii) an application for which simulated data is fit for
use. A number of laser scanning simulators for different purposes exist, which
we enrich by presenting HELIOS++. HELIOS++ is an open-source simulation
framework for terrestrial static, mobile, UAV-based and airborne laser scanning
implemented in C++. The HELIOS++ concept provides a flexible solution for the
trade-off between physical accuracy (realism) and computational complexity
(runtime, memory footprint), as well as ease of use and of configuration.
Unique features of HELIOS++ include the availability of Python bindings
(pyhelios) for controlling simulations, and a range of model types for 3D scene
representation. HELIOS++ further allows the simulation of beam divergence using
a subsampling strategy, and is able to create full-waveform outputs as a basis
for detailed analysis. As generation and analysis of waveforms can strongly
impact runtimes, the user may set the level of detail for the subsampling, or
optionally disable full-waveform output altogether. A detailed assessment of
computational considerations and a comparison of HELIOS++ to its predecessor,
HELIOS, reveal reduced runtimes by up to 83 %. At the same time, memory
requirements are reduced by up to 94 %, allowing for much larger (i.e. more
complex) 3D scenes to be loaded into memory and hence to be virtually acquired
by laser scanning simulation.
</p>
<a href="http://arxiv.org/abs/2101.09154" target="_blank">arXiv:2101.09154</a> [<a href="http://arxiv.org/pdf/2101.09154" target="_blank">pdf</a>]

<h2>Improved Sensitivity of Base Layer on the Performance of Rigid Pavement. (arXiv:2101.09167v1 [cs.AI])</h2>
<h3>Sajib Saha, Fan Gu, Xue Luo, Robert L. Lytton</h3>
<p>The performance of rigid pavement is greatly affected by the properties of
base/subbase as well as subgrade layer. However, the performance predicted by
the AASHTOWare Pavement ME design shows low sensitivity to the properties of
base and subgrade layers. To improve the sensitivity and better reflect the
influence of unbound layers a new set of improved models i.e., resilient
modulus (MR) and modulus of subgrade reaction (k-value) are adopted in this
study. An Artificial Neural Network (ANN) model is developed to predict the
modified k-value based on finite element (FE) analysis. The training and
validation datasets in the ANN model consist of 27000 simulation cases with
different combinations of pavement layer thickness, layer modulus and slab-base
interface bond ratio. To examine the sensitivity of modified MR and k-values on
pavement response, eight pavement sections data are collected from the
Long-Term Pavement performance (LTPP) database and modeled by using the FE
software ISLAB2000. The computational results indicate that the modified MR
values have higher sensitivity to water content in base layer on critical
stress and deflection response of rigid pavements compared to the results using
the Pavement ME design model. It is also observed that the k-values using ANN
model has the capability of predicting critical pavement response at any
partially bonded conditions whereas the Pavement ME design model can only
calculate at two extreme bonding conditions (i.e., fully bonding and no
bonding).
</p>
<a href="http://arxiv.org/abs/2101.09167" target="_blank">arXiv:2101.09167</a> [<a href="http://arxiv.org/pdf/2101.09167" target="_blank">pdf</a>]

<h2>Sparsistent filtering of comovement networks from high-dimensional data. (arXiv:2101.09174v1 [stat.ML])</h2>
<h3>Arnab Chakrabarti, Anindya S. Chakrabarti</h3>
<p>Network filtering is an important form of dimension reduction to isolate the
core constituents of large and interconnected complex systems. We introduce a
new technique to filter large dimensional networks arising out of dynamical
behavior of the constituent nodes, exploiting their spectral properties. As
opposed to the well known network filters that rely on preserving key
topological properties of the realized network, our method treats the spectrum
as the fundamental object and preserves spectral properties. Applying
asymptotic theory for high dimensional data for the filter, we show that it can
be tuned to interpolate between zero filtering to maximal filtering that
induces sparsity and consistency while having the least spectral distance from
a linear shrinkage estimator. We apply our proposed filter to covariance
networks constructed from financial data, to extract the key subnetwork
embedded in the full sample network.
</p>
<a href="http://arxiv.org/abs/2101.09174" target="_blank">arXiv:2101.09174</a> [<a href="http://arxiv.org/pdf/2101.09174" target="_blank">pdf</a>]

<h2>Tensor-Train Networks for Learning Predictive Modeling of Multidimensional Data. (arXiv:2101.09184v1 [cs.LG])</h2>
<h3>M. Nazareth da Costa, R. Attux, A. Cichocki, J. M. T. Romano</h3>
<p>Deep neural networks have attracted the attention of the machine learning
community because of their appealing data-driven framework and of their
performance in several pattern recognition tasks. On the other hand, there are
many open theoretical problems regarding the internal operation of the network,
the necessity of certain layers, hyperparameter selection etc. A promising
strategy is based on tensor networks, which have been very successful in
physical and chemical applications. In general, higher-order tensors are
decomposed into sparsely interconnected lower-order tensors. This is a
numerically reliable way to avoid the curse of dimensionality and to provide
highly compressed representation of a data tensor, besides the good numerical
properties that allow to control the desired accuracy of approximation. In
order to compare tensor and neural networks, we first consider the
identification of the classical Multilayer Perceptron using Tensor-Train. A
comparative analysis is also carried out in the context of prediction of the
Mackey-Glass noisy chaotic time series and NASDAQ index. We have shown that the
weights of a multidimensional regression model can be learned by means of
tensor networks with the aim of performing a powerful compact representation
retaining the accuracy of neural networks. Furthermore, an algorithm based on
alternating least squares has been proposed for approximating the weights in
TT-format with a reduction of computational calculus. By means of a direct
expression, we have approximated the core estimation as the conventional
solution for a general regression model, which allows to extend the
applicability of tensor structures to different algorithms.
</p>
<a href="http://arxiv.org/abs/2101.09184" target="_blank">arXiv:2101.09184</a> [<a href="http://arxiv.org/pdf/2101.09184" target="_blank">pdf</a>]

<h2>Gravity Optimizer: a Kinematic Approach on Optimization in Deep Learning. (arXiv:2101.09192v1 [cs.LG])</h2>
<h3>Dariush Bahrami, Sadegh Pouriyan Zadeh</h3>
<p>We introduce Gravity, another algorithm for gradient-based optimization. In
this paper, we explain how our novel idea change parameters to reduce the deep
learning model's loss. It has three intuitive hyper-parameters that the best
values for them are proposed. Also, we propose an alternative to moving
average. To compare the performance of the Gravity optimizer with two common
optimizers, Adam and RMSProp, five standard datasets were trained on two VGGNet
models with a batch size of 128 for 100 epochs. Gravity hyper-parameters did
not need to be tuned for different models. As will be explained more in the
paper, to investigate the direct impact of the optimizer itself on loss
reduction no overfitting prevention technique was used. The obtained results
show that the Gravity optimizer has more stable performance than Adam and
RMSProp and gives greater values of validation accuracy for datasets with more
output classes like CIFAR-100 (Fine).
</p>
<a href="http://arxiv.org/abs/2101.09192" target="_blank">arXiv:2101.09192</a> [<a href="http://arxiv.org/pdf/2101.09192" target="_blank">pdf</a>]

<h2>Dense outlier detection and open-set recognition based on training with noisy negative images. (arXiv:2101.09193v1 [cs.CV])</h2>
<h3>Petra Bevandi&#x107;, Ivan Kre&#x161;o, Marin Or&#x161;i&#x107;, Sini&#x161;a &#x160;egvi&#x107;</h3>
<p>Deep convolutional models often produce inadequate predictions for inputs
foreign to the training distribution. Consequently, the problem of detecting
outlier images has recently been receiving a lot of attention. Unlike most
previous work, we address this problem in the dense prediction context in order
to be able to locate outlier objects in front of in-distribution background.
Our approach is based on two reasonable assumptions. First, we assume that the
inlier dataset is related to some narrow application field (e.g.~road driving).
Second, we assume that there exists a general-purpose dataset which is much
more diverse than the inlier dataset (e.g.~ImageNet-1k). We consider pixels
from the general-purpose dataset as noisy negative training samples since most
(but not all) of them are outliers. We encourage the model to recognize borders
between known and unknown by pasting jittered negative patches over inlier
training images. Our experiments target two dense open-set recognition
benchmarks (WildDash 1 and Fishyscapes) and one dense open-set recognition
dataset (StreetHazard). Extensive performance evaluation indicates competitive
potential of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2101.09193" target="_blank">arXiv:2101.09193</a> [<a href="http://arxiv.org/pdf/2101.09193" target="_blank">pdf</a>]

<h2>Differentiable Trust Region Layers for Deep Reinforcement Learning. (arXiv:2101.09207v1 [cs.LG])</h2>
<h3>Fabian Otto, Philipp Becker, Ngo Anh Vien, Hanna Carolin Ziesche, Gerhard Neumann</h3>
<p>Trust region methods are a popular tool in reinforcement learning as they
yield robust policy updates in continuous and discrete action spaces. However,
enforcing such trust regions in deep reinforcement learning is difficult.
Hence, many approaches, such as Trust Region Policy Optimization (TRPO) and
Proximal Policy Optimization (PPO), are based on approximations. Due to those
approximations, they violate the constraints or fail to find the optimal
solution within the trust region. Moreover, they are difficult to implement,
lack sufficient exploration, and have been shown to depend on seemingly
unrelated implementation choices. In this work, we propose differentiable
neural network layers to enforce trust regions for deep Gaussian policies via
closed-form projections. Unlike existing methods, those layers formalize trust
regions for each state individually and can complement existing reinforcement
learning algorithms. We derive trust region projections based on the
Kullback-Leibler divergence, the Wasserstein L2 distance, and the Frobenius
norm for Gaussian distributions. We empirically demonstrate that those
projection layers achieve similar or better results than existing methods while
being almost agnostic to specific implementation choices.
</p>
<a href="http://arxiv.org/abs/2101.09207" target="_blank">arXiv:2101.09207</a> [<a href="http://arxiv.org/pdf/2101.09207" target="_blank">pdf</a>]

<h2>Graphical Models for Financial Time Series and Portfolio Selection. (arXiv:2101.09214v1 [cs.LG])</h2>
<h3>Ni Zhan, Yijia Sun, Aman Jakhar, He Liu</h3>
<p>We examine a variety of graphical models to construct optimal portfolios.
Graphical models such as PCA-KMeans, autoencoders, dynamic clustering, and
structural learning can capture the time varying patterns in the covariance
matrix and allow the creation of an optimal and robust portfolio. We compared
the resulting portfolios from the different models with baseline methods. In
many cases our graphical strategies generated steadily increasing returns with
low risk and outgrew the S&amp;P 500 index. This work suggests that graphical
models can effectively learn the temporal dependencies in time series data and
are proved useful in asset management.
</p>
<a href="http://arxiv.org/abs/2101.09214" target="_blank">arXiv:2101.09214</a> [<a href="http://arxiv.org/pdf/2101.09214" target="_blank">pdf</a>]

<h2>Computability-logic web: an alternative to deep learning. (arXiv:2101.09222v1 [cs.AI])</h2>
<h3>Keehang Kwon</h3>
<p>{\em Computability logic} (CoL) is a powerful, mathematically rigorous
computational model. In this paper, we show that CoL-web, a web extension to
CoL, naturally supports web programming where database updates are involved. To
be specific, we discuss an implementation of the AI ATM based on CoL (CL9 to be
exact). More importantly, we argue that CoL-web supports a general AI and,
therefore, is a good alternative to neural nets and deep learning. We also
discuss how to integrate neural nets into CoL-web.
</p>
<a href="http://arxiv.org/abs/2101.09222" target="_blank">arXiv:2101.09222</a> [<a href="http://arxiv.org/pdf/2101.09222" target="_blank">pdf</a>]

<h2>Continual Learning of Generative Models with Limited Data: From Wasserstein-1 Barycenter to Adaptive Coalescence. (arXiv:2101.09225v1 [cs.LG])</h2>
<h3>Mehmet Dedeoglu, Sen Lin, Zhaofeng Zhang, Junshan Zhang</h3>
<p>Learning generative models is challenging for a network edge node with
limited data and computing power. Since tasks in similar environments share
model similarity, it is plausible to leverage pre-trained generative models
from the cloud or other edge nodes. Appealing to optimal transport theory
tailored towards Wasserstein-1 generative adversarial networks (WGAN), this
study aims to develop a framework which systematically optimizes continual
learning of generative models using local data at the edge node while
exploiting adaptive coalescence of pre-trained generative models. Specifically,
by treating the knowledge transfer from other nodes as Wasserstein balls
centered around their pre-trained models, continual learning of generative
models is cast as a constrained optimization problem, which is further reduced
to a Wasserstein-1 barycenter problem. A two-stage approach is devised
accordingly: 1) The barycenters among the pre-trained models are computed
offline, where displacement interpolation is used as the theoretic foundation
for finding adaptive barycenters via a "recursive" WGAN configuration; 2) the
barycenter computed offline is used as meta-model initialization for continual
learning and then fast adaptation is carried out to find the generative model
using the local samples at the target edge node. Finally, a weight
ternarization method, based on joint optimization of weights and threshold for
quantization, is developed to compress the generative model further.
</p>
<a href="http://arxiv.org/abs/2101.09225" target="_blank">arXiv:2101.09225</a> [<a href="http://arxiv.org/pdf/2101.09225" target="_blank">pdf</a>]

<h2>Where does the Stimulus go? Deep Generative Model for Commercial Banking Deposits. (arXiv:2101.09230v1 [cs.LG])</h2>
<h3>Ni Zhan</h3>
<p>This paper examines deposits of individuals ("retail") and large companies
("wholesale") in the U.S. banking industry, and how these deposit types are
impacted by macroeconomic factors, such as quantitative easing (QE). Actual
data for deposits by holder are unavailable. We use a dataset on banks'
financial information and probabilistic generative model to predict industry
retail-wholesale deposit split from 2000 to 2020. Our model assumes account
balances arise from separate retail and wholesale lognormal distributions and
fit parameters of distributions by minimizing error between actual bank metrics
and simulated metrics using the model's generative process. We use time-series
regression to forward predict retail-wholesale deposits as function of loans,
retail loans, and reserve balances at Fed banks. We find increase in reserves
(representing QE) increases wholesale but not retail deposits, and increase in
loans increase both wholesale and retail deposits evenly. The result shows that
QE following the 2008 financial crisis benefited large companies more than
average individuals, a relevant finding for economic decision making. In
addition, this work benefits bank management strategy by providing forecasting
capability for retail-wholesale deposits.
</p>
<a href="http://arxiv.org/abs/2101.09230" target="_blank">arXiv:2101.09230</a> [<a href="http://arxiv.org/pdf/2101.09230" target="_blank">pdf</a>]

<h2>Expression Recognition Analysis in the Wild. (arXiv:2101.09231v1 [cs.CV])</h2>
<h3>Donato Cafarelli, Fabio Valerio Massoli, Fabrizio Falchi, Claudio Gennaro, Giuseppe Amato</h3>
<p>Facial Expression Recognition(FER) is one of the most important topic in
Human-Computer interactions(HCI). In this work we report details and
experimental results about a facial expression recognition method based on
state-of-the-art methods. We fine-tuned a SeNet deep learning architecture
pre-trained on the well-known VGGFace2 dataset, on the AffWild2 facial
expression recognition dataset. The main goal of this work is to define a
baseline for a novel method we are going to propose in the near future. This
paper is also required by the Affective Behavior Analysis in-the-wild (ABAW)
competition in order to evaluate on the test set this approach. The results
reported here are on the validation set and are related on the Expression
Challenge part (seven basic emotion recognition) of the competition. We will
update them as soon as the actual results on the test set will be published on
the leaderboard.
</p>
<a href="http://arxiv.org/abs/2101.09231" target="_blank">arXiv:2101.09231</a> [<a href="http://arxiv.org/pdf/2101.09231" target="_blank">pdf</a>]

<h2>On Maximum Likelihood Training of Score-Based Generative Models. (arXiv:2101.09258v1 [stat.ML])</h2>
<h3>Conor Durkan, Yang Song</h3>
<p>Score-based generative modeling has recently emerged as a promising
alternative to traditional likelihood-based or implicit approaches. Learning in
score-based models involves first perturbing data with a continuous-time
stochastic process, and then matching the time-dependent gradient of the
logarithm of the noisy data density - or score function - using a continuous
mixture of score matching losses. In this note, we show that such an objective
is equivalent to maximum likelihood for certain choices of mixture weighting.
This connection provides a principled way to weight the objective function, and
justifies its use for comparing different score-based generative models. Taken
together with previous work, our result reveals that both maximum likelihood
training and test-time log-likelihood evaluation can be achieved through
parameterization of the score function alone, without the need to explicitly
parameterize a density function.
</p>
<a href="http://arxiv.org/abs/2101.09258" target="_blank">arXiv:2101.09258</a> [<a href="http://arxiv.org/pdf/2101.09258" target="_blank">pdf</a>]

<h2>Predicting Autism Spectrum Disorder Using Machine Learning Classifiers. (arXiv:2101.09279v1 [cs.LG])</h2>
<h3>Koushik Chowdhury, Mir Ahmad Iraj</h3>
<p>Autism Spectrum Disorder (ASD) is on the rise and constantly growing. Earlier
identify of ASD with the best outcome will allow someone to be safe and healthy
by proper nursing. Humans can hardly estimate the present condition and stage
of ASD by measuring primary symptoms. Therefore, it is being necessary to
develop a method that will provide the best outcome and measurement of ASD.
This paper aims to show several measurements that implemented in several
classifiers. Among them, Support Vector Machine (SVM) provides the best result
and under SVM, there are also some kernels to perform. Among them, the Gaussian
Radial Kernel gives the best result. The proposed classifier achieves 95%
accuracy using the publicly available standard ASD dataset.
</p>
<a href="http://arxiv.org/abs/2101.09279" target="_blank">arXiv:2101.09279</a> [<a href="http://arxiv.org/pdf/2101.09279" target="_blank">pdf</a>]

<h2>Manipulating and Measuring Model Interpretability. (arXiv:1802.07810v4 [cs.AI] UPDATED)</h2>
<h3>Forough Poursabzi-Sangdeh, Daniel G. Goldstein, Jake M. Hofman, Jennifer Wortman Vaughan, Hanna Wallach</h3>
<p>With machine learning models being increasingly used to aid decision making
even in high-stakes domains, there has been a growing interest in developing
interpretable models. Although many supposedly interpretable models have been
proposed, there have been relatively few experimental studies investigating
whether these models achieve their intended effects, such as making people more
closely follow a model's predictions when it is beneficial for them to do so or
enabling them to detect when a model has made a mistake. We present a sequence
of pre-registered experiments(N=3,800) in which we showed participants
functionally identical models that varied only in two factors commonly thought
to make machine learning models more or less interpretable: the number of
features and the transparency of the model (i.e., whether the model internals
are clear or black box). Predictably, participants who saw a clear model with
few features could better simulate the model's predictions. However, we did not
find that participants more closely followed its predictions. Furthermore,
showing participants a clear model meant that they were less able to detect and
correct for the model's sizable mistakes, seemingly due to information
overload. These counterintuitive findings emphasize the importance of testing
over intuition when developing interpretable models.
</p>
<a href="http://arxiv.org/abs/1802.07810" target="_blank">arXiv:1802.07810</a> [<a href="http://arxiv.org/pdf/1802.07810" target="_blank">pdf</a>]

<h2>Inverse Optimal Control from Incomplete Trajectory Observations. (arXiv:1803.07696v4 [cs.RO] UPDATED)</h2>
<h3>Wanxin Jin, Dana Kuli&#x107;, Shaoshuai Mou, Sandra Hirche</h3>
<p>This article develops a methodology that enables learning an objective
function of an optimal control system from incomplete trajectory observations.
The objective function is assumed to be a weighted sum of features (or basis
functions) with unknown weights, and the observed data is a segment of a
trajectory of system states and inputs. The proposed technique introduces the
concept of the recovery matrix to establish the relationship between any
available segment of the trajectory and the weights of given candidate
features. The rank of the recovery matrix indicates whether a subset of
relevant features can be found among the candidate features and the
corresponding weights can be learned from the segment data. The recovery matrix
can be obtained iteratively and its rank non-decreasing property shows that
additional observations may contribute to the objective learning. Based on the
recovery matrix, a method for using incomplete trajectory observations to learn
the weights of selected features is established, and an incremental inverse
optimal control algorithm is developed by automatically finding the minimal
required observation. The effectiveness of the proposed method is demonstrated
on a linear quadratic regulator system and a simulated robot manipulator.
</p>
<a href="http://arxiv.org/abs/1803.07696" target="_blank">arXiv:1803.07696</a> [<a href="http://arxiv.org/pdf/1803.07696" target="_blank">pdf</a>]

<h2>Backdoor Decomposable Monotone Circuits and their Propagation Complete Encodings. (arXiv:1811.09435v4 [cs.AI] UPDATED)</h2>
<h3>Petr Ku&#x10d;era, Petr Savick&#xfd;</h3>
<p>We describe a compilation language of backdoor decomposable monotone circuits
(BDMCs) which generalizes several concepts appearing in the literature, e.g.
DNNFs and backdoor trees. A $\mathcal{C}$-BDMC sentence is a monotone circuit
which satisfies decomposability property (such as in DNNF) in which the inputs
(or leaves) are associated with CNF encodings from a given base class
$\mathcal{C}$. We consider the class of propagation complete (PC) encodings as
a base class and we show that PC-BDMCs are polynomially equivalent to PC
encodings. Additionally, we use this to determine the properties of PC-BDMCs
and PC encodings with respect to the knowledge compilation map including the
list of efficient operations on the languages.
</p>
<a href="http://arxiv.org/abs/1811.09435" target="_blank">arXiv:1811.09435</a> [<a href="http://arxiv.org/pdf/1811.09435" target="_blank">pdf</a>]

<h2>Towards Practical Lipschitz Bandits. (arXiv:1901.09277v7 [stat.ML] UPDATED)</h2>
<h3>Tianyu Wang, Weicheng Ye, Dawei Geng, Cynthia Rudin</h3>
<p>Stochastic Lipschitz bandit algorithms balance exploration and exploitation,
and have been used for a variety of important task domains. In this paper, we
present a framework for Lipschitz bandit methods that adaptively learns
partitions of context- and arm-space. Due to this flexibility, the algorithm is
able to efficiently optimize rewards and minimize regret, by focusing on the
portions of the space that are most relevant. In our analysis, we link
tree-based methods to Gaussian processes. In light of our analysis, we design a
novel hierarchical Bayesian model for Lipschitz bandit problems. Our
experiments show that our algorithms can achieve state-of-the-art performance
in challenging real-world tasks such as neural network hyperparameter tuning.
</p>
<a href="http://arxiv.org/abs/1901.09277" target="_blank">arXiv:1901.09277</a> [<a href="http://arxiv.org/pdf/1901.09277" target="_blank">pdf</a>]

<h2>Energy-Based Continuous Inverse Optimal Control. (arXiv:1904.05453v5 [cs.LG] UPDATED)</h2>
<h3>Yifei Xu, Jianwen Xie, Tianyang Zhao, Chris Baker, Yibiao Zhao, Ying Nian Wu</h3>
<p>The problem of continuous optimal control (over finite time horizon) is to
minimize a given cost function over the sequence of continuous control
variables. The problem of continuous inverse optimal control is to learn the
unknown cost function from expert demonstrations. In this article, we study
this fundamental problem in the framework of energy-based model, where the
observed expert trajectories are assumed to be random samples from a
probability density function defined as the exponential of the negative cost
function up to a normalizing constant. The parameters of the cost function are
learned by maximum likelihood via an "analysis by synthesis" scheme, which
iterates the following two steps: (1) Synthesis step: sample the synthesized
trajectories from the current probability density using the Langevin dynamics
via back-propagation through time. (2) Analysis step: update the model
parameters based on the statistical difference between the synthesized
trajectories and the observed trajectories. Given the fact that an efficient
optimization algorithm is usually available for an optimal control problem, we
also consider a convenient approximation of the above learning method, where we
replace the sampling in the synthesis step by optimization. To make the
sampling or optimization more efficient, we propose to train the energy-based
model simultaneously with a top-down trajectory generator via cooperative
learning, where the trajectory generator is used to fast initialize the
sampling step or optimization step of the energy-based model. We demonstrate
the proposed methods on autonomous driving tasks, and show that it can learn
suitable cost functions for optimal control.
</p>
<a href="http://arxiv.org/abs/1904.05453" target="_blank">arXiv:1904.05453</a> [<a href="http://arxiv.org/pdf/1904.05453" target="_blank">pdf</a>]

<h2>Information-Theoretic Registration with Explicit Reorientation of Diffusion-Weighted Images. (arXiv:1905.12056v3 [cs.CV] UPDATED)</h2>
<h3>Henrik Gr&#xf8;nholt Jensen, Fran&#xe7;ois Lauze, Sune Darkner</h3>
<p>We present an information-theoretic appro\-ach to the registration of images
with directional information, and especially for diffusion-Weighted Images
(DWI), with explicit optimization over the directional scale. We call it
Locally Orderless Registration with Directions (LORD). We focus on normalized
mutual information as a robust information-theoretic similarity measure for
DWI. The framework is an extension of the LOR-DWI density-based hierarchical
scale-space model that varies and optimizes the integration, spatial,
directional, and intensity scales. As affine transformations are insufficient
for inter-subject registration, we extend the model to non-rigid deformations.
We show that the formulation provides intrinsic regularization through the
orientational information. We illustrate that the proposed model deforms
orientation distribution functions (ODFs) correctly and is capable of handling
the classic complex challenges in DWI-registrations, such as the registration
of fiber-crossings along with kissing, fanning, and interleaving fibers. Our
results clearly illustrate a novel promising regularizing effect, that comes
from the nonlinear orientation-based cost function. We show the properties of
the different image scales and, we show that including orientational
information in our model makes the model better at retrieving deformations in
contrast to standard scalar-based registration.
</p>
<a href="http://arxiv.org/abs/1905.12056" target="_blank">arXiv:1905.12056</a> [<a href="http://arxiv.org/pdf/1905.12056" target="_blank">pdf</a>]

<h2>Imitation Learning of Neural Spatio-Temporal Point Processes. (arXiv:1906.05467v4 [cs.LG] UPDATED)</h2>
<h3>Shixiang Zhu, Shuang Li, Zhigang Peng, Yao Xie</h3>
<p>We present a novel Neural Embedding Spatio-Temporal (NEST) point process
model for spatio-temporal discrete event data and develop an efficient
imitation learning (a type of reinforcement learning) based approach for model
fitting. Despite the rapid development of one-dimensional temporal point
processes for discrete event data, the study of spatial-temporal aspects of
such data is relatively scarce. Our model captures complex spatio-temporal
dependence between discrete events by carefully design a mixture of
heterogeneous Gaussian diffusion kernels, whose parameters are parameterized by
neural networks. This new kernel is the key that our model can capture
intricate spatial dependence patterns and yet still lead to interpretable
results as we examine maps of Gaussian diffusion kernel parameters. The
imitation learning model fitting for the NEST is more robust than the maximum
likelihood estimate. It directly measures the divergence between the empirical
distributions between the training data and the model-generated data. Moreover,
our imitation learning-based approach enjoys computational efficiency due to
the explicit characterization of the reward function related to the likelihood
function; furthermore, the likelihood function under our model enjoys tractable
expression due to Gaussian kernel parameterization. Experiments based on real
data show our method's good performance relative to the state-of-the-art and
the good interpretability of NEST's result.
</p>
<a href="http://arxiv.org/abs/1906.05467" target="_blank">arXiv:1906.05467</a> [<a href="http://arxiv.org/pdf/1906.05467" target="_blank">pdf</a>]

<h2>LassoNet: A Neural Network with Feature Sparsity. (arXiv:1907.12207v8 [stat.ML] UPDATED)</h2>
<h3>Ismael Lemhadri, Feng Ruan, Robert Tibshirani</h3>
<p>Much work has been done recently to make neural networks more interpretable,
and one obvious approach is to arrange for the network to use only a subset of
the available features. In linear models, Lasso (or $\ell_1$-regularized)
regression assigns zero weights to the most irrelevant or redundant features,
and is widely used in data science. However the Lasso only applies to linear
models. Here we introduce LassoNet, a neural network framework with global
feature selection. Our approach enforces a hierarchy: specifically a feature
can participate in a hidden unit only if its linear representative is active.
Unlike other approaches to feature selection for neural nets, our method uses a
modified objective function with constraints, and so integrates feature
selection with the parameter learning directly. As a result, it delivers an
entire regularization path of solutions with a range of feature sparsity. On
systematic experiments, LassoNet significantly outperforms state-of-the-art
methods for feature selection and regression. The LassoNet method uses
projected proximal gradient descent, and generalizes directly to deep networks.
It can be implemented by adding just a few lines of code to a standard neural
network.
</p>
<a href="http://arxiv.org/abs/1907.12207" target="_blank">arXiv:1907.12207</a> [<a href="http://arxiv.org/pdf/1907.12207" target="_blank">pdf</a>]

<h2>Simplified Decision Making in the Belief Space using Belief Sparsification. (arXiv:1909.00885v3 [cs.AI] UPDATED)</h2>
<h3>Khen Elimelech, Vadim Indelman</h3>
<p>In this work, we introduce a new approach for the efficient solution of
autonomous decision and planning problems, with a special focus on decision
making under uncertainty and belief space planning (BSP) in high-dimensional
state spaces. Usually, to solve the decision problem, we identify the optimal
action, according to some objective function. We claim that we can sometimes
generate and solve an analogous yet simplified decision problem, which can be
solved more efficiently; a wise simplification method can lead to the same
action selection, or one for which the maximal loss can be guaranteed.
Furthermore, such simplification is separated from the state inference, and
does not compromise its accuracy, as the selected action would finally be
applied on the original state. First, we present the concept for general
decision problems, and provide a theoretical framework for a coherent
formulation of the approach. We then practically apply these ideas to BSP
problems, which can be simplified by considering a sparse approximation of the
initial (Gaussian) belief. The scalable belief sparsification algorithm we
provide is able to yield solutions which are guaranteed to be consistent with
the original problem. We demonstrate the benefits of the approach in the
solution of a highly realistic active-SLAM problem, and manage to significantly
reduce computation time, with practically no loss in the quality of solution.
This work is conceptual and fundamental, and holds numerous possible
extensions.
</p>
<a href="http://arxiv.org/abs/1909.00885" target="_blank">arXiv:1909.00885</a> [<a href="http://arxiv.org/pdf/1909.00885" target="_blank">pdf</a>]

<h2>Learning Maximally Predictive Prototypes in Multiple Instance Learning. (arXiv:1910.00965v4 [cs.LG] UPDATED)</h2>
<h3>Mert Yuksekgonul, Ozgur Emre Sivrikaya, Mustafa Gokce Baydogan</h3>
<p>In this work, we propose a simple model that provides permutation invariant
maximally predictive prototype generator from a given dataset, which leads to
interpretability of the solution and concrete insights to the nature and the
solution of a problem. Our aim is to find out prototypes in the feature space
to map the collection of instances (i.e. bags) to a distance feature space and
simultaneously learn a linear classifier for multiple instance learning (MIL).
Our experiments on classical MIL benchmark datasets demonstrate that proposed
framework is an accurate and efficient classifier compared to the existing
approaches.
</p>
<a href="http://arxiv.org/abs/1910.00965" target="_blank">arXiv:1910.00965</a> [<a href="http://arxiv.org/pdf/1910.00965" target="_blank">pdf</a>]

<h2>The Restless Hidden Markov Bandit with Linear Rewards and Side Information. (arXiv:1910.10271v4 [cs.LG] UPDATED)</h2>
<h3>Michal Yemini, Amir Leshem, Anelia Somekh-Baruch</h3>
<p>In this paper we present a model for the hidden Markovian bandit problem with
linear rewards. As opposed to current work on Markovian bandits, we do not
assume that the state is known to the decision maker before making the
decision. Furthermore, we assume structural side information where the decision
maker knows in advance that there are two types of hidden states; one is common
to all arms and evolves according to a Markovian distribution, and the other is
unique to each arm and is distributed according to an i.i.d. process that is
unique to each arm. We present an algorithm and regret analysis to this
problem. Surprisingly, we can recover the hidden states and maintain
logarithmic regret in the case of a convex polytope action set. Furthermore, we
show that the structural side information leads to expected regret that does
not depend on the number of extreme points in the action space. Therefore, we
obtain practical solutions even in high dimensional problems.
</p>
<a href="http://arxiv.org/abs/1910.10271" target="_blank">arXiv:1910.10271</a> [<a href="http://arxiv.org/pdf/1910.10271" target="_blank">pdf</a>]

<h2>Implementations in Machine Ethics: A Survey. (arXiv:2001.07573v2 [cs.AI] UPDATED)</h2>
<h3>Suzanne Tolmeijer, Markus Kneer, Cristina Sarasua, Markus Christen, Abraham Bernstein</h3>
<p>Increasingly complex and autonomous systems require machine ethics to
maximize the benefits and minimize the risks to society arising from the new
technology. It is challenging to decide which type of ethical theory to employ
and how to implement it effectively. This survey provides a threefold
contribution. First, it introduces a trimorphic taxonomy to analyze machine
ethics implementations with respect to their object (ethical theories), as well
as their nontechnical and technical aspects. Second, an exhaustive selection
and description of relevant works is presented. Third, applying the new
taxonomy to the selected works, dominant research patterns, and lessons for the
field are identified, and future directions for research are suggested.
</p>
<a href="http://arxiv.org/abs/2001.07573" target="_blank">arXiv:2001.07573</a> [<a href="http://arxiv.org/pdf/2001.07573" target="_blank">pdf</a>]

<h2>Knowledge Graph Embedding for Link Prediction: A Comparative Analysis. (arXiv:2002.00819v4 [cs.LG] UPDATED)</h2>
<h3>Andrea Rossi, Donatella Firmani, Antonio Matinata, Paolo Merialdo, Denilson Barbosa</h3>
<p>Knowledge Graphs (KGs) have found many applications in industry and academic
settings, which in turn, have motivated considerable research efforts towards
large-scale information extraction from a variety of sources. Despite such
efforts, it is well known that even state-of-the-art KGs suffer from
incompleteness. Link Prediction (LP), the task of predicting missing facts
among entities already a KG, is a promising and widely studied task aimed at
addressing KG incompleteness. Among the recent LP techniques, those based on KG
embeddings have achieved very promising performances in some benchmarks.
Despite the fast growing literature in the subject, insufficient attention has
been paid to the effect of the various design choices in those methods.
Moreover, the standard practice in this area is to report accuracy by
aggregating over a large number of test facts in which some entities are
over-represented; this allows LP methods to exhibit good performance by just
attending to structural properties that include such entities, while ignoring
the remaining majority of the KG. This analysis provides a comprehensive
comparison of embedding-based LP methods, extending the dimensions of analysis
beyond what is commonly available in the literature. We experimentally compare
effectiveness and efficiency of 16 state-of-the-art methods, consider a
rule-based baseline, and report detailed analysis over the most popular
benchmarks in the literature.
</p>
<a href="http://arxiv.org/abs/2002.00819" target="_blank">arXiv:2002.00819</a> [<a href="http://arxiv.org/pdf/2002.00819" target="_blank">pdf</a>]

<h2>Forecasting adverse surgical events using self-supervised transfer learning for physiological signals. (arXiv:2002.04770v2 [cs.LG] UPDATED)</h2>
<h3>Hugh Chen, Scott Lundberg, Gabe Erion, Jerry H. Kim, Su-In Lee</h3>
<p>Hundreds of millions of surgical procedures take place annually across the
world, which generate a prevalent type of electronic health record (EHR) data
comprising time series physiological signals. Here, we present a transferable
embedding method (i.e., a method to transform time series signals into input
features for predictive machine learning models) named PHASE (PHysiologicAl
Signal Embeddings) that enables us to more accurately forecast adverse surgical
outcomes based on physiological signals. We evaluate PHASE on minute-by-minute
EHR data of more than 50,000 surgeries from two operating room (OR) datasets
and patient stays in an intensive care unit (ICU) dataset. PHASE outperforms
other state-of-the-art approaches, such as long-short term memory networks
trained on raw data and gradient boosted trees trained on handcrafted features,
in predicting five distinct outcomes: hypoxemia, hypocapnia, hypotension,
hypertension, and phenylephrine administration. In a transfer learning setting
where we train embedding models in one dataset then embed signals and predict
adverse events in unseen data, PHASE achieves significantly higher prediction
accuracy at lower computational cost compared to conventional approaches.
Finally, given the importance of understanding models in clinical applications
we demonstrate that PHASE is explainable and validate our predictive models
using local feature attribution methods.
</p>
<a href="http://arxiv.org/abs/2002.04770" target="_blank">arXiv:2002.04770</a> [<a href="http://arxiv.org/pdf/2002.04770" target="_blank">pdf</a>]

<h2>DeepSign: Deep On-Line Signature Verification. (arXiv:2002.10119v3 [cs.CV] UPDATED)</h2>
<h3>Ruben Tolosana, Ruben Vera-Rodriguez, Julian Fierrez, Javier Ortega-Garcia</h3>
<p>Deep learning has become a breathtaking technology in the last years,
overcoming traditional handcrafted approaches and even humans for many
different tasks. However, in some tasks, such as the verification of
handwritten signatures, the amount of publicly available data is scarce, what
makes difficult to test the real limits of deep learning. In addition to the
lack of public data, it is not easy to evaluate the improvements of novel
proposed approaches as different databases and experimental protocols are
usually considered.

The main contributions of this study are: i) we provide an in-depth analysis
of state-of-the-art deep learning approaches for on-line signature
verification, ii) we present and describe the new DeepSignDB on-line
handwritten signature biometric public database, iii) we propose a standard
experimental protocol and benchmark to be used for the research community in
order to perform a fair comparison of novel approaches with the state of the
art, and iv) we adapt and evaluate our recent deep learning approach named
Time-Aligned Recurrent Neural Networks (TA-RNNs) for the task of on-line
handwritten signature verification. This approach combines the potential of
Dynamic Time Warping and Recurrent Neural Networks to train more robust systems
against forgeries. Our proposed TA-RNN system outperforms the state of the art,
achieving results even below 2.0% EER when considering skilled forgery
impostors and just one training signature per user.
</p>
<a href="http://arxiv.org/abs/2002.10119" target="_blank">arXiv:2002.10119</a> [<a href="http://arxiv.org/pdf/2002.10119" target="_blank">pdf</a>]

<h2>Fully Asynchronous Policy Evaluation in Distributed Reinforcement Learning over Networks. (arXiv:2003.00433v3 [cs.LG] UPDATED)</h2>
<h3>Xingyu Sha, Jiaqi Zhang, Keyou You, Kaiqing Zhang, Tamer Ba&#x15f;ar</h3>
<p>This paper proposes a \emph{fully asynchronous} scheme for the policy
evaluation problem of distributed reinforcement learning (DisRL) over directed
peer-to-peer networks. Without waiting for any other node of the network, each
node can locally update its value function at any time by using (possibly
delayed) information from its neighbors. This is in sharp contrast to the
gossip-based scheme where a pair of nodes concurrently update. Though the fully
asynchronous setting involves a difficult multi-timescale decision problem, we
design a novel stochastic average gradient (SAG) based distributed algorithm
and develop a push-pull augmented graph approach to prove its exact convergence
at a linear rate of $\mathcal{O}(c^k)$ where $c\in(0,1)$ and $k$ increases by
one no matter on which node updates. Finally, numerical experiments validate
that our method speeds up linearly with respect to the number of nodes, and is
robust to straggler nodes.
</p>
<a href="http://arxiv.org/abs/2003.00433" target="_blank">arXiv:2003.00433</a> [<a href="http://arxiv.org/pdf/2003.00433" target="_blank">pdf</a>]

<h2>A new method to compare the interpretability of rule-based algorithms. (arXiv:2004.01570v4 [stat.ML] UPDATED)</h2>
<h3>Vincent Margot, George Luta</h3>
<p>Interpretability is becoming increasingly important for predictive model
analysis. Unfortunately, as remarked by many authors, there is still no
consensus regarding this notion. The goal of this article is to propose a
definition of the notion of interpretability that allows comparisons of
rule-based algorithms. This definition consists of three terms, each one being
quantitatively measured with a simple formula: predictivity, stability and
simplicity. While predictivity has been extensively studied to measure the
accuracy of predictive algorithms, stability is based on the Dice-Sorensen
index for comparing two sets of rules generated by an algorithm using two
independent samples. The simplicity is based on the sum of the length of the
rules derived from the predictive model. The new measure for the
interpretability of a rule-based algorithm is a weighted sum of the three terms
mentioned above. We use the new measure to compare the interpretability of
several rule-based algorithms, specifically CART, RuleFit, Node Harvest,
Covering algorithm and SIRUS for the regression case, and CART, PART and RIPPER
for the classification case
</p>
<a href="http://arxiv.org/abs/2004.01570" target="_blank">arXiv:2004.01570</a> [<a href="http://arxiv.org/pdf/2004.01570" target="_blank">pdf</a>]

<h2>Model-based actor-critic: GAN (model generator) + DRL (actor-critic) => AGI. (arXiv:2004.04574v6 [cs.AI] UPDATED)</h2>
<h3>Aras Dargazany</h3>
<p>Our effort is toward unifying GAN and DRL algorithms into a unifying AI model
(AGI or general-purpose AI or artificial general intelligence which has
general-purpose applications to: (A) offline learning (of stored data) like GAN
in (un/semi-/fully-)SL setting such as big data analytics (mining) and
visualization; (B) online learning (of real or simulated devices) like DRL in
RL setting (with/out environment reward) such as (real or simulated) robotics
and control; Our core proposal is adding an (generative/predictive) environment
model to the actor-critic (model-free) architecture which results in a
model-based actor-critic architecture with temporal-differencing (TD) error and
an episodic memory. The proposed AI model is similar to (model-free) DDPG and
therefore it's called model-based DDPG. To evaluate it, we compare it with
(model-free) DDPG by applying them both to a variety (wide range) of
independent simulated robotic and control task environments in OpenAI Gym and
Unity Agents. Our initial limited experiments show that DRL and GAN in
model-based actor-critic results in an incremental goal-driven intellignce
required to solve each task with similar performance to (model-free) DDPG. Our
future focus is to investigate the proposed AI model potential to: (A) unify
DRL field inside AI by producing competitive performance compared to the best
of model-based (PlaNet) and model-free (D4PG) approaches; (B) bridge the gap
between AI and robotics communities by solving the important problem of reward
engineering with learning the reward function by demonstration.
</p>
<a href="http://arxiv.org/abs/2004.04574" target="_blank">arXiv:2004.04574</a> [<a href="http://arxiv.org/pdf/2004.04574" target="_blank">pdf</a>]

<h2>Simple Multi-Resolution Representation Learning for Human Pose Estimation. (arXiv:2004.06366v2 [cs.CV] UPDATED)</h2>
<h3>Trung Q. Tran, Giang V. Nguyen, Daeyoung Kim</h3>
<p>Human pose estimation - the process of recognizing human keypoints in a given
image - is one of the most important tasks in computer vision and has a wide
range of applications including movement diagnostics, surveillance, or
self-driving vehicle. The accuracy of human keypoint prediction is increasingly
improved thanks to the burgeoning development of deep learning. Most existing
methods solved human pose estimation by generating heatmaps in which the ith
heatmap indicates the location confidence of the ith keypoint. In this paper,
we introduce novel network structures referred to as multi-resolution
representation learning for human keypoint prediction. At different resolutions
in the learning process, our networks branch off and use extra layers to learn
heatmap generation. We firstly consider the architectures for generating the
multi-resolution heatmaps after obtaining the lowest-resolution feature maps.
Our second approach allows learning during the process of feature extraction in
which the heatmaps are generated at each resolution of the feature extractor.
The first and second approaches are referred to as multi-resolution heatmap
learning and multi-resolution feature map learning respectively. Our
architectures are simple yet effective, achieving good performance. We
conducted experiments on two common benchmarks for human pose estimation:
MSCOCO and MPII dataset. The code is made publicly available at
https://github.com/tqtrunghnvn/SimMRPose.
</p>
<a href="http://arxiv.org/abs/2004.06366" target="_blank">arXiv:2004.06366</a> [<a href="http://arxiv.org/pdf/2004.06366" target="_blank">pdf</a>]

<h2>Single Pair Cross-Modality Super Resolution. (arXiv:2004.09965v4 [cs.CV] UPDATED)</h2>
<h3>Guy Shacht, Sharon Fogel, Dov Danon, Daniel Cohen-Or, Ilya Leizerson</h3>
<p>Non-visual imaging sensors are widely used in the industry for different
purposes. Those sensors are more expensive than visual (RGB) sensors, and
usually produce images with lower resolution. To this end, Cross-Modality
Super-Resolution methods were introduced, where an RGB image of a
high-resolution assists in increasing the resolution of the low-resolution
modality. However, fusing images from different modalities is not a trivial
task; the output must be artifact-free and remain loyal to the characteristics
of the target modality. Moreover, the input images are never perfectly aligned,
which results in further artifacts during the fusion process.

We present CMSR, a deep network for Cross-Modality Super-Resolution, which
unlike previous methods, is designed to deal with weakly aligned images. The
network is trained on the two input images only, learns their internal
statistics and correlations, and applies them to up-sample the target modality.
CMSR contains an internal transformer that is trained on-the-fly together with
the up-sampling process itself, without explicit supervision. We show that CMSR
succeeds to increase the resolution of the input image, gaining valuable
information from its RGB counterpart, yet in a conservative way, without
introducing artifacts or irrelevant details.
</p>
<a href="http://arxiv.org/abs/2004.09965" target="_blank">arXiv:2004.09965</a> [<a href="http://arxiv.org/pdf/2004.09965" target="_blank">pdf</a>]

<h2>Range Conditioned Dilated Convolutions for Scale Invariant 3D Object Detection. (arXiv:2005.09927v3 [cs.CV] UPDATED)</h2>
<h3>Alex Bewley, Pei Sun, Thomas Mensink, Dragomir Anguelov, Cristian Sminchisescu</h3>
<p>This paper presents a novel 3D object detection framework that processes
LiDAR data directly on its native representation: range images. Benefiting from
the compactness of range images, 2D convolutions can efficiently process dense
LiDAR data of a scene. To overcome scale sensitivity in this perspective view,
a novel range-conditioned dilation (RCD) layer is proposed to dynamically
adjust a continuous dilation rate as a function of the measured range.
Furthermore, localized soft range gating combined with a 3D box-refinement
stage improves robustness in occluded areas, and produces overall more accurate
bounding box predictions. On the public large-scale Waymo Open Dataset, our
method sets a new baseline for range-based 3D detection, outperforming
multiview and voxel-based methods over all ranges with unparalleled performance
at long range detection.
</p>
<a href="http://arxiv.org/abs/2005.09927" target="_blank">arXiv:2005.09927</a> [<a href="http://arxiv.org/pdf/2005.09927" target="_blank">pdf</a>]

<h2>Scalable Plug-and-Play ADMM with Convergence Guarantees. (arXiv:2006.03224v2 [cs.LG] UPDATED)</h2>
<h3>Yu Sun, Zihui Wu, Xiaojian Xu, Brendt Wohlberg, Ulugbek S. Kamilov</h3>
<p>Plug-and-play priors (PnP) is a broadly applicable methodology for solving
inverse problems by exploiting statistical priors specified as denoisers.
Recent work has reported the state-of-the-art performance of PnP algorithms
using pre-trained deep neural nets as denoisers in a number of imaging
applications. However, current PnP algorithms are impractical in large-scale
settings due to their heavy computational and memory requirements. This work
addresses this issue by proposing an incremental variant of the widely used
PnP-ADMM algorithm, making it scalable to large-scale datasets. We
theoretically analyze the convergence of the algorithm under a set of explicit
assumptions, extending recent theoretical results in the area. Additionally, we
show the effectiveness of our algorithm with nonsmooth data-fidelity terms and
deep neural net priors, its fast convergence compared to existing PnP
algorithms, and its scalability in terms of speed and memory.
</p>
<a href="http://arxiv.org/abs/2006.03224" target="_blank">arXiv:2006.03224</a> [<a href="http://arxiv.org/pdf/2006.03224" target="_blank">pdf</a>]

<h2>A conditional one-output likelihood formulation for multitask Gaussian processes. (arXiv:2006.03495v2 [cs.LG] UPDATED)</h2>
<h3>&#xd3;scar Garc&#xed;a-Hinde, Vanessa G&#xf3;mez-Verdejo, Manel Mart&#xed;nez-Ram&#xf3;n</h3>
<p>Multitask Gaussian processes (MTGP) are the Gaussian process (GP) framework's
solution for multioutput regression problems in which the $T$ elements of the
regressors cannot be considered conditionally independent given the
observations. Standard MTGP models assume that there exist both a multitask
covariance matrix as a function of an intertask matrix, and a noise covariance
matrix. These matrices need to be approximated by a low rank simplification of
order $P$ in order to reduce the number of parameters to be learnt from $T^2$
to $TP$. Here we introduce a novel approach that simplifies the multitask
learning by reducing it to a set of conditioned univariate GPs without the need
for any low rank approximations, therefore completely eliminating the
requirement to select an adequate value for hyperparameter $P$. At the same
time, by extending this approach with both a hierarchical and an approximate
model, the proposed extensions are capable of recovering the multitask
covariance and noise matrices after learning only $2T$ parameters, avoiding the
validation of any model hyperparameter and reducing the overall complexity of
the model as well as the risk of overfitting. Experimental results over
synthetic and real problems confirm the advantages of this inference approach
in its ability to accurately recover the original noise and signal matrices, as
well as the achieved performance improvement in comparison to other state of
art MTGP approaches. We have also integrated the model with standard GP
toolboxes, showing that it is computationally competitive with state of the art
options.
</p>
<a href="http://arxiv.org/abs/2006.03495" target="_blank">arXiv:2006.03495</a> [<a href="http://arxiv.org/pdf/2006.03495" target="_blank">pdf</a>]

<h2>Adaptive Universal Generalized PageRank Graph Neural Network. (arXiv:2006.07988v3 [cs.LG] UPDATED)</h2>
<h3>Eli Chien, Jianhao Peng, Pan Li, Olgica Milenkovic</h3>
<p>In many important graph data processing applications the acquired information
includes both node features and observations of the graph topology. Graph
neural networks (GNNs) are designed to exploit both sources of evidence but
they do not optimally trade-off their utility and integrate them in a manner
that is also universal. Here, universality refers to independence on homophily
or heterophily graph assumptions. We address these issues by introducing a new
Generalized PageRank (GPR) GNN architecture that adaptively learns the GPR
weights so as to jointly optimize node feature and topological information
extraction, regardless of the extent to which the node labels are homophilic or
heterophilic. Learned GPR weights automatically adjust to the node label
pattern, irrelevant on the type of initialization, and thereby guarantee
excellent learning performance for label patterns that are usually hard to
handle. Furthermore, they allow one to avoid feature over-smoothing, a process
which renders feature information nondiscriminative, without requiring the
network to be shallow. Our accompanying theoretical analysis of the GPR-GNN
method is facilitated by novel synthetic benchmark datasets generated by the
so-called contextual stochastic block model. We also compare the performance of
our GNN architecture with that of several state-of-the-art GNNs on the problem
of node-classification, using well-known benchmark homophilic and heterophilic
datasets. The results demonstrate that GPR-GNN offers significant performance
improvement compared to existing techniques on both synthetic and benchmark
data.
</p>
<a href="http://arxiv.org/abs/2006.07988" target="_blank">arXiv:2006.07988</a> [<a href="http://arxiv.org/pdf/2006.07988" target="_blank">pdf</a>]

<h2>Mitigating Gender Bias in Captioning Systems. (arXiv:2006.08315v5 [cs.CV] UPDATED)</h2>
<h3>Ruixiang Tang, Mengnan Du, Yuening Li, Zirui Liu, Na Zou, Xia Hu</h3>
<p>Image captioning has made substantial progress with huge supporting image
collections sourced from the web. However, recent studies have pointed out that
captioning datasets, such as COCO, contain gender bias found in web corpora. As
a result, learning models could heavily rely on the learned priors and image
context for gender identification, leading to incorrect or even offensive
errors. To encourage models to learn correct gender features, we reorganize the
COCO dataset and present two new splits COCO-GB V1 and V2 datasets where the
train and test sets have different gender-context joint distribution. Models
relying on contextual cues will suffer from huge gender prediction errors on
the anti-stereotypical test data. Benchmarking experiments reveal that most
captioning models learn gender bias, leading to high gender prediction errors,
especially for women. To alleviate the unwanted bias, we propose a new Guided
Attention Image Captioning model (GAIC) which provides self-guidance on visual
attention to encourage the model to capture correct gender visual evidence.
Experimental results validate that GAIC can significantly reduce gender
prediction errors with a competitive caption quality. Our codes and the
designed benchmark datasets are available at
https://github.com/CaptionGenderBias2020.
</p>
<a href="http://arxiv.org/abs/2006.08315" target="_blank">arXiv:2006.08315</a> [<a href="http://arxiv.org/pdf/2006.08315" target="_blank">pdf</a>]

<h2>Tractable Fragments of Temporal Sequences of Topological Information. (arXiv:2007.07711v2 [cs.AI] UPDATED)</h2>
<h3>Quentin Cohen-Solal</h3>
<p>In this paper, we focus on qualitative temporal sequences of topological
information. We firstly consider the context of topological temporal sequences
of length greater than 3 describing the evolution of regions at consecutive
time points. We show that there is no Cartesian subclass containing all the
basic relations and the universal relation for which the algebraic closure
decides satisfiability. However, we identify some tractable subclasses, by
giving up the relations containing the non-tangential proper part relation and
not containing the tangential proper part relation. We then formalize an
alternative semantics for temporal sequences. We place ourselves in the context
of the topological temporal sequences describing the evolution of regions on a
partition of time (i.e. an alternation of instants and intervals). In this
context, we identify large tractable fragments.
</p>
<a href="http://arxiv.org/abs/2007.07711" target="_blank">arXiv:2007.07711</a> [<a href="http://arxiv.org/pdf/2007.07711" target="_blank">pdf</a>]

<h2>Bayesian Few-Shot Classification with One-vs-Each P\'olya-Gamma Augmented Gaussian Processes. (arXiv:2007.10417v2 [cs.LG] UPDATED)</h2>
<h3>Jake Snell, Richard Zemel</h3>
<p>Few-shot classification (FSC), the task of adapting a classifier to unseen
classes given a small labeled dataset, is an important step on the path toward
human-like machine learning. Bayesian methods are well-suited to tackling the
fundamental issue of overfitting in the few-shot scenario because they allow
practitioners to specify prior beliefs and update those beliefs in light of
observed data. Contemporary approaches to Bayesian few-shot classification
maintain a posterior distribution over model parameters, which is slow and
requires storage that scales with model size. Instead, we propose a Gaussian
process classifier based on a novel combination of P\'olya-Gamma augmentation
and the one-vs-each softmax approximation that allows us to efficiently
marginalize over functions rather than model parameters. We demonstrate
improved accuracy and uncertainty quantification on both standard few-shot
classification benchmarks and few-shot domain transfer tasks.
</p>
<a href="http://arxiv.org/abs/2007.10417" target="_blank">arXiv:2007.10417</a> [<a href="http://arxiv.org/pdf/2007.10417" target="_blank">pdf</a>]

<h2>TriFinger: An Open-Source Robot for Learning Dexterity. (arXiv:2008.03596v2 [cs.RO] UPDATED)</h2>
<h3>Manuel W&#xfc;thrich, Felix Widmaier, Felix Grimminger, Joel Akpo, Shruti Joshi, Vaibhav Agrawal, Bilal Hammoud, Majid Khadiv, Miroslav Bogdanovic, Vincent Berenz, Julian Viereck, Maximilien Naveau, Ludovic Righetti, Bernhard Sch&#xf6;lkopf, Stefan Bauer</h3>
<p>Dexterous object manipulation remains an open problem in robotics, despite
the rapid progress in machine learning during the past decade. We argue that a
hindrance is the high cost of experimentation on real systems, in terms of both
time and money. We address this problem by proposing an open-source robotic
platform which can safely operate without human supervision. The hardware is
inexpensive (about \SI{5000}[\$]{}) yet highly dynamic, robust, and capable of
complex interaction with external objects. The software operates at 1-kilohertz
and performs safety checks to prevent the hardware from breaking. The
easy-to-use front-end (in C++ and Python) is suitable for real-time control as
well as deep reinforcement learning. In addition, the software framework is
largely robot-agnostic and can hence be used independently of the hardware
proposed herein. Finally, we illustrate the potential of the proposed platform
through a number of experiments, including real-time optimal control, deep
reinforcement learning from scratch, throwing, and writing.
</p>
<a href="http://arxiv.org/abs/2008.03596" target="_blank">arXiv:2008.03596</a> [<a href="http://arxiv.org/pdf/2008.03596" target="_blank">pdf</a>]

<h2>Applications of Deep Neural Networks. (arXiv:2009.05673v2 [cs.LG] UPDATED)</h2>
<h3>Jeff Heaton</h3>
<p>Deep learning is a group of exciting new technologies for neural networks.
Through a combination of advanced training techniques and neural network
architectural components, it is now possible to create neural networks that can
handle tabular data, images, text, and audio as both input and output. Deep
learning allows a neural network to learn hierarchies of information in a way
that is like the function of the human brain. This course will introduce the
student to classic neural network structures, Convolution Neural Networks
(CNN), Long Short-Term Memory (LSTM), Gated Recurrent Neural Networks (GRU),
General Adversarial Networks (GAN), and reinforcement learning. Application of
these architectures to computer vision, time series, security, natural language
processing (NLP), and data generation will be covered. High-Performance
Computing (HPC) aspects will demonstrate how deep learning can be leveraged
both on graphical processing units (GPUs), as well as grids. Focus is primarily
upon the application of deep learning to problems, with some introduction to
mathematical foundations. Readers will use the Python programming language to
implement deep learning using Google TensorFlow and Keras. It is not necessary
to know Python prior to this book; however, familiarity with at least one
programming language is assumed.
</p>
<a href="http://arxiv.org/abs/2009.05673" target="_blank">arXiv:2009.05673</a> [<a href="http://arxiv.org/pdf/2009.05673" target="_blank">pdf</a>]

<h2>How Does Mixup Help With Robustness and Generalization?. (arXiv:2010.04819v2 [cs.LG] UPDATED)</h2>
<h3>Linjun Zhang, Zhun Deng, Kenji Kawaguchi, Amirata Ghorbani, James Zou</h3>
<p>Mixup is a popular data augmentation technique based on taking convex
combinations of pairs of examples and their labels. This simple technique has
been shown to substantially improve both the robustness and the generalization
of the trained model. However, it is not well-understood why such improvement
occurs. In this paper, we provide theoretical analysis to demonstrate how using
Mixup in training helps model robustness and generalization. For robustness, we
show that minimizing the Mixup loss corresponds to approximately minimizing an
upper bound of the adversarial loss. This explains why models obtained by Mixup
training exhibits robustness to several kinds of adversarial attacks such as
Fast Gradient Sign Method (FGSM). For generalization, we prove that Mixup
augmentation corresponds to a specific type of data-adaptive regularization
which reduces overfitting. Our analysis provides new insights and a framework
to understand Mixup.
</p>
<a href="http://arxiv.org/abs/2010.04819" target="_blank">arXiv:2010.04819</a> [<a href="http://arxiv.org/pdf/2010.04819" target="_blank">pdf</a>]

<h2>Deep Graph Matching and Searching for Semantic Code Retrieval. (arXiv:2010.12908v2 [cs.AI] UPDATED)</h2>
<h3>Xiang Ling, Lingfei Wu, Saizhuo Wang, Gaoning Pan, Tengfei Ma, Fangli Xu, Alex X. Liu, Chunming Wu, Shouling Ji</h3>
<p>Code retrieval is to find the code snippet from a large corpus of source code
repositories that highly matches the query of natural language description.
Recent work mainly uses natural language processing techniques to process both
query texts (i.e., human natural language) and code snippets (i.e., machine
programming language), however neglecting the deep structured features of query
texts and source codes, both of which contain rich semantic information. In
this paper, we propose an end-to-end deep graph matching and searching (DGMS)
model based on graph neural networks for the task of semantic code retrieval.
To this end, we first represent both natural language query texts and
programming language code snippets with the unified graph-structured data, and
then use the proposed graph matching and searching model to retrieve the best
matching code snippet. In particular, DGMS not only captures more structural
information for individual query texts or code snippets but also learns the
fine-grained similarity between them by cross-attention based semantic matching
operations. We evaluate the proposed DGMS model on two public code retrieval
datasets with two representative programming languages (i.e., Java and Python).
Experiment results demonstrate that DGMS significantly outperforms
state-of-the-art baseline models by a large margin on both datasets. Moreover,
our extensive ablation studies systematically investigate and illustrate the
impact of each part of DGMS.
</p>
<a href="http://arxiv.org/abs/2010.12908" target="_blank">arXiv:2010.12908</a> [<a href="http://arxiv.org/pdf/2010.12908" target="_blank">pdf</a>]

<h2>Re-Assessing the "Classify and Count" Quantification Method. (arXiv:2011.02552v2 [cs.LG] UPDATED)</h2>
<h3>Alejandro Moreo, Fabrizio Sebastiani</h3>
<p>Learning to quantify (a.k.a.\ quantification) is a task concerned with
training unbiased estimators of class prevalence via supervised learning. This
task originated with the observation that "Classify and Count" (CC), the
trivial method of obtaining class prevalence estimates, is often a biased
estimator, and thus delivers suboptimal quantification accuracy; following this
observation, several methods for learning to quantify have been proposed that
have been shown to outperform CC. In this work we contend that previous works
have failed to use properly optimised versions of CC. We thus reassess the real
merits of CC (and its variants), and argue that, while still inferior to some
cutting-edge methods, they deliver near-state-of-the-art accuracy once (a)
hyperparameter optimisation is performed, and (b) this optimisation is
performed by using a true quantification loss instead of a standard
classification-based loss. Experiments on three publicly available binary
sentiment classification datasets support these conclusions.
</p>
<a href="http://arxiv.org/abs/2011.02552" target="_blank">arXiv:2011.02552</a> [<a href="http://arxiv.org/pdf/2011.02552" target="_blank">pdf</a>]

<h2>Predictive Process Model Monitoring using Recurrent Neural Networks. (arXiv:2011.02819v2 [cs.LG] UPDATED)</h2>
<h3>Johannes De Smedt, Jochen De Weerdt, Junichiro Mori, Masanao Ochi</h3>
<p>The field of predictive process monitoring focuses on modelling future
characteristics of running business process instances, typically by either
predicting the outcome of particular objectives (e.g. completion (time), cost),
or next-in-sequence prediction (e.g. what is the next activity to execute).
This paper introduces Processes-As-Movies (PAM), a technique that provides a
middle ground between these predictive monitoring. It does so by capturing
declarative process constraints between activities in various windows of a
process execution trace, which represent a declarative process model at
subsequent stages of execution. This high-dimensional representation of a
process model allows the application of predictive modelling on how such
constraints appear and vanish throughout a process' execution. Various
recurrent neural network topologies tailored to high-dimensional input are used
to model the process model evolution with windows as time steps, including
encoder-decoder long short-term memory networks, and convolutional long
short-term memory networks. Results show that these topologies are very
effective in terms of accuracy and precision to predict a process model's
future state, which allows process owners to simultaneously verify what linear
temporal logic rules hold in a predicted process window (objective-based), and
verify what future execution traces are allowed by all the constraints together
(trace-based).
</p>
<a href="http://arxiv.org/abs/2011.02819" target="_blank">arXiv:2011.02819</a> [<a href="http://arxiv.org/pdf/2011.02819" target="_blank">pdf</a>]

<h2>Generalized Continual Zero-Shot Learning. (arXiv:2011.08508v2 [cs.CV] UPDATED)</h2>
<h3>Chandan Gautam, Sethupathy Parameswaran, Ashish Mishra, Suresh Sundaram</h3>
<p>Recently, zero-shot learning (ZSL) emerged as an exciting topic and attracted
a lot of attention. ZSL aims to classify unseen classes by transferring the
knowledge from seen classes to unseen classes based on the class description.
Despite showing promising performance, ZSL approaches assume that the training
samples from all seen classes are available during the training, which is
practically not feasible. To address this issue, we propose a more generalized
and practical setup for ZSL, i.e., continual ZSL (CZSL), where classes arrive
sequentially in the form of a task and it actively learns from the changing
environment by leveraging the past experience. Further, to enhance the
reliability, we develop CZSL for a single head continual learning setting where
task identity is revealed during the training process but not during the
testing. To avoid catastrophic forgetting and intransigence, we use knowledge
distillation and storing and replay the few samples from previous tasks using a
small episodic memory. We develop baselines and evaluate generalized CZSL on
five ZSL benchmark datasets for two different settings of continual learning:
with and without class incremental. Moreover, CZSL is developed for two types
of variational autoencoders, which generates two types of features for
classification: (i) generated features at output space and (ii) generated
discriminative features at the latent space. The experimental results clearly
indicate the single head CZSL is more generalizable and suitable for practical
applications.
</p>
<a href="http://arxiv.org/abs/2011.08508" target="_blank">arXiv:2011.08508</a> [<a href="http://arxiv.org/pdf/2011.08508" target="_blank">pdf</a>]

<h2>TinaFace: Strong but Simple Baseline for Face Detection. (arXiv:2011.13183v3 [cs.CV] UPDATED)</h2>
<h3>Yanjia Zhu, Hongxiang Cai, Shuhan Zhang, Chenhao Wang, Yichao Xiong</h3>
<p>Face detection has received intensive attention in recent years. Many works
present lots of special methods for face detection from different perspectives
like model architecture, data augmentation, label assignment and etc., which
make the overall algorithm and system become more and more complex. In this
paper, we point out that \textbf{there is no gap between face detection and
generic object detection}. Then we provide a strong but simple baseline method
to deal with face detection named TinaFace. We use ResNet-50 \cite{he2016deep}
as backbone, and all modules and techniques in TinaFace are constructed on
existing modules, easily implemented and based on generic object detection. On
the hard test set of the most popular and challenging face detection benchmark
WIDER FACE \cite{yang2016wider}, with single-model and single-scale, our
TinaFace achieves 92.1\% average precision (AP), which exceeds most of the
recent face detectors with larger backbone. And after using test time
augmentation (TTA), our TinaFace outperforms the current state-of-the-art
method and achieves 92.4\% AP. The code will be available at
\url{https://github.com/Media-Smart/vedadet}.
</p>
<a href="http://arxiv.org/abs/2011.13183" target="_blank">arXiv:2011.13183</a> [<a href="http://arxiv.org/pdf/2011.13183" target="_blank">pdf</a>]

<h2>Channel-wise Distillation for Semantic Segmentation. (arXiv:2011.13256v2 [cs.CV] UPDATED)</h2>
<h3>Changyong Shu, Yifan Liu, Jianfei Gao, Lin Xu, Chunhua Shen</h3>
<p>Knowledge distillation (KD) has been proven to be a simple and effective tool
for training compact models. Almost all KD variants for semantic segmentation
align the student and teacher networks' feature maps in the spatial domain,
typically by minimizing point-wise and/or pair-wise discrepancy. Observing that
in semantic segmentation, some layers' feature activations of each channel tend
to encode saliency of scene categories (analogue to class activation mapping),
we propose to align features channel-wise between the student and teacher
networks. To this end, we first transform the feature map of each channel into
a distribution using softmax normalization, and then minimize the
Kullback-Leibler (KL) divergence of the corresponding channels of the two
networks. By doing so, our method focuses on mimicking the soft distributions
of channels between networks. In particular, the KL divergence enables learning
to pay more attention to the most salient regions of the channel-wise maps,
presumably corresponding to the most useful signals for semantic segmentation.
Experiments demonstrate that our channel-wise distillation outperforms almost
all existing spatial distillation methods for semantic segmentation
considerably, and requires less computational cost during training. We
consistently achieve superior performance on three benchmarks with various
network structures. Code is available at: https://git.io/ChannelDis
</p>
<a href="http://arxiv.org/abs/2011.13256" target="_blank">arXiv:2011.13256</a> [<a href="http://arxiv.org/pdf/2011.13256" target="_blank">pdf</a>]

<h2>Complex Coordinate-Based Meta-Analysis with Probabilistic Programming. (arXiv:2012.01303v2 [cs.AI] UPDATED)</h2>
<h3>Valentin Iovene (NEUROSPIN, PARIETAL), Gaston Zanitti (NEUROSPIN, PARIETAL), Demian Wassermann (NEUROSPIN, PARIETAL)</h3>
<p>With the growing number of published functional magnetic resonance imaging
(fMRI) studies, meta-analysis databases and models have become an integral part
of brain mapping research. Coordinate-based meta-analysis (CBMA) databases are
built by automatically extracting both coordinates of reported peak activations
and term associations using natural language processing (NLP) techniques.
Solving term-based queries on these databases make it possible to obtain
statistical maps of the brain related to specific cognitive processes. However,
with tools like Neurosynth, only singleterm queries lead to statistically
reliable results. When solving richer queries, too few studies from the
database contribute to the statistical estimations. We design a probabilistic
domain-specific language (DSL) standing on Datalog and one of its probabilistic
extensions, CP-Logic, for expressing and solving rich logic-based queries. We
encode a CBMA database into a probabilistic program. Using the joint
distribution of its Bayesian network translation, we show that solutions of
queries on this program compute the right probability distributions of voxel
activations. We explain how recent lifted query processing algorithms make it
possible to scale to the size of large neuroimaging data, where state of the
art knowledge compilation (KC) techniques fail to solve queries fast enough for
practical applications. Finally, we introduce a method for relating studies to
terms probabilistically, leading to better solutions for conjunctive queries on
smaller databases. We demonstrate results for two-term conjunctive queries,
both on simulated meta-analysis databases and on the widely-used Neurosynth
database.
</p>
<a href="http://arxiv.org/abs/2012.01303" target="_blank">arXiv:2012.01303</a> [<a href="http://arxiv.org/pdf/2012.01303" target="_blank">pdf</a>]

<h2>Class-incremental Learning with Rectified Feature-Graph Preservation. (arXiv:2012.08129v2 [cs.CV] UPDATED)</h2>
<h3>Cheng-Hsun Lei, Yi-Hsin Chen, Wen-Hsiao Peng, Wei-Chen Chiu</h3>
<p>In this paper, we address the problem of distillation-based class-incremental
learning with a single head. A central theme of this task is to learn new
classes that arrive in sequential phases over time while keeping the model's
capability of recognizing seen classes with only limited memory for preserving
seen data samples. Many regularization strategies have been proposed to
mitigate the phenomenon of catastrophic forgetting. To understand better the
essence of these regularizations, we introduce a feature-graph preservation
perspective. Insights into their merits and faults motivate our
weighted-Euclidean regularization for old knowledge preservation. We further
propose rectified cosine normalization and show how it can work with binary
cross-entropy to increase class separation for effective learning of new
classes. Experimental results on both CIFAR-100 and ImageNet datasets
demonstrate that our method outperforms the state-of-the-art approaches in
reducing classification error, easing catastrophic forgetting, and encouraging
evenly balanced accuracy over different classes. Our project page is at :
https://github.com/yhchen12101/FGP-ICL.
</p>
<a href="http://arxiv.org/abs/2012.08129" target="_blank">arXiv:2012.08129</a> [<a href="http://arxiv.org/pdf/2012.08129" target="_blank">pdf</a>]

<h2>Assessing Pattern Recognition Performance of Neuronal Cultures through Accurate Simulation. (arXiv:2012.10355v2 [cs.CV] UPDATED)</h2>
<h3>Gabriele Lagani, Raffaele Mazziotti, Fabrizio Falchi, Claudio Gennaro, Guido Marco Cicchini, Tommaso Pizzorusso, Federico Cremisi, Giuseppe Amato</h3>
<p>Previous work has shown that it is possible to train neuronal cultures on
Multi-Electrode Arrays (MEAs), to recognize very simple patterns. However, this
work was mainly focused to demonstrate that it is possible to induce plasticity
in cultures, rather than performing a rigorous assessment of their pattern
recognition performance. In this paper, we address this gap by developing a
methodology that allows us to assess the performance of neuronal cultures on a
learning task. Specifically, we propose a digital model of the real cultured
neuronal networks; we identify biologically plausible simulation parameters
that allow us to reliably reproduce the behavior of real cultures; we use the
simulated culture to perform handwritten digit recognition and rigorously
evaluate its performance; we also show that it is possible to find improved
simulation parameters for the specific task, which can guide the creation of
real cultures.
</p>
<a href="http://arxiv.org/abs/2012.10355" target="_blank">arXiv:2012.10355</a> [<a href="http://arxiv.org/pdf/2012.10355" target="_blank">pdf</a>]

<h2>Humanoid Robot Pitch Axis Stabilization using Linear Quadratic Regulator with Fuzzy Logic and Capture Point. (arXiv:2012.10867v3 [cs.RO] UPDATED)</h2>
<h3>Bagaskara Primastya Putra, Gabrielle Satya Mahardika, Muhammad Faris, Adha Imam Cahyadi</h3>
<p>This paper aims for a controller that can stabilize a position-controlled
humanoid robot when standing still or walking on synthetic grass even when
subjected to external disturbances. Two types of controllers are designed and
implemented: ankle strategy and stepping strategy. The robot's joints consist
of position-controlled servos which can be complicated to model analytically
due to nonlinearities and non-measurable parameters, hence the dynamic model of
the humanoid robot is acquired using a non-recursive least squares system
identification. This model is also used to design a Kalman Filter to estimate
the system states from noisy inertial measurement unit (IMU) sensor and design
a linear quadratic regulator (LQR) controller. To handle the nonlinearities,
the LQR controller is extended with fuzzy logic algorithm that changes the LQR
gain value based on angle and angular velocity membership functions. The
proposed control system can maintain the humanoid robot's stability around the
pitch axis when subject to pendulum disturbances or even restraining force from
a spring balance.
</p>
<a href="http://arxiv.org/abs/2012.10867" target="_blank">arXiv:2012.10867</a> [<a href="http://arxiv.org/pdf/2012.10867" target="_blank">pdf</a>]

<h2>Temporal Contrastive Graph for Self-supervised Video Representation Learning. (arXiv:2101.00820v2 [cs.CV] UPDATED)</h2>
<h3>Yang Liu, Keze Wang, Haoyuan Lan, Liang Lin</h3>
<p>Attempt to fully explore the fine-grained temporal structure and global-local
chronological characteristics for self-supervised video representation
learning, this work takes a closer look at exploiting the temporal structure of
videos and further proposes a novel self-supervised method named Temporal
Contrastive Graph (TCG). In contrast to the existing methods that randomly
shuffle the video frames or video snippets within a video, our proposed TCG
roots in a hybrid graph contrastive learning strategy to regard the
inter-snippet and intra-snippet temporal relationships as self-supervision
signals for temporal representation learning. Inspired by the neuroscience
studies that the human visual system is sensitive to both local and global
temporal changes, our proposed TCG integrates the prior knowledge about the
frame and snippet orders into temporal contrastive graph structures, i.e., the
intra-/inter- snippet temporal contrastive graph modules, to well preserve the
local and global temporal relationships among video frame-sets and snippets. By
randomly removing edges and masking node features of the intra-snippet graphs
or inter-snippet graphs, our TCG can generate different correlated graph views.
Then, specific contrastive losses are designed to maximize the agreement
between node embeddings in different views. To learn the global context
representation and recalibrate the channel-wise features adaptively, we
introduce an adaptive video snippet order prediction module, which leverages
the relational knowledge among video snippets to predict the actual snippet
orders. Extensive experimental results demonstrate the superiority of our TCG
over the state-of-the-art methods on large-scale action recognition and video
retrieval benchmarks.
</p>
<a href="http://arxiv.org/abs/2101.00820" target="_blank">arXiv:2101.00820</a> [<a href="http://arxiv.org/pdf/2101.00820" target="_blank">pdf</a>]

<h2>Multimodal Engagement Analysis from Facial Videos in the Classroom. (arXiv:2101.04215v2 [cs.CV] UPDATED)</h2>
<h3>&#xd6;mer S&#xfc;mer, Patricia Goldberg, Sidney D&#x27;Mello, Peter Gerjets, Ulrich Trautwein, Enkelejda Kasneci</h3>
<p>Student engagement is a key construct for learning and teaching. While most
of the literature explored the student engagement analysis on computer-based
settings, this paper extends that focus to classroom instruction. To best
examine student visual engagement in the classroom, we conducted a study
utilizing the audiovisual recordings of classes at a secondary school over one
and a half month's time, acquired continuous engagement labeling per student
(N=15) in repeated sessions, and explored computer vision methods to classify
engagement levels from faces in the classroom. We trained deep embeddings for
attentional and emotional features, training Attention-Net for head pose
estimation and Affect-Net for facial expression recognition. We additionally
trained different engagement classifiers, consisting of Support Vector
Machines, Random Forest, Multilayer Perceptron, and Long Short-Term Memory, for
both features. The best performing engagement classifiers achieved AUCs of .620
and .720 in Grades 8 and 12, respectively. We further investigated fusion
strategies and found score-level fusion either improves the engagement
classifiers or is on par with the best performing modality. We also
investigated the effect of personalization and found that using only 60-seconds
of person-specific data selected by margin uncertainty of the base classifier
yielded an average AUC improvement of .084. 4.Our main aim with this work is to
provide the technical means to facilitate the manual data analysis of classroom
videos in research on teaching quality and in the context of teacher training.
</p>
<a href="http://arxiv.org/abs/2101.04215" target="_blank">arXiv:2101.04215</a> [<a href="http://arxiv.org/pdf/2101.04215" target="_blank">pdf</a>]

<h2>Predictive Processing in Cognitive Robotics: a Review. (arXiv:2101.06611v2 [cs.RO] UPDATED)</h2>
<h3>Alejandra Ciria, Guido Schillaci, Giovanni Pezzulo, Verena V. Hafner, Bruno Lara</h3>
<p>Predictive processing has become an influential framework in cognitive
sciences. This framework turns the traditional view of perception upside down,
claiming that the main flow of information processing is realized in a top-down
hierarchical manner. Furthermore, it aims at unifying perception, cognition,
and action as a single inferential process. However, in the related literature,
the predictive processing framework and its associated schemes such as
predictive coding, active inference, perceptual inference, free-energy
principle, tend to be used interchangeably.

In the field of cognitive robotics there is no clear-cut distinction on which
schemes have been implemented and under which assumptions. In this paper,
working definitions are set with the main aim of analyzing the state of the art
in cognitive robotics research working under the predictive processing
framework as well as some related non-robotic models.

The analysis suggests that, first, both research in cognitive robotics
implementations and non-robotic models needs to be extended to the study of how
multiple exteroceptive modalities can be integrated into prediction error
minimization schemes. Second, a relevant distinction found here is that
cognitive robotics implementations tend to emphasize the learning of a
generative model, while in non-robotics models it is almost absent. Third,
despite the relevance for active inference, few cognitive robotics
implementations examine the issues around control and whether it should result
from the substitution of inverse models with proprioceptive predictions.

Finally, limited attention has been placed on precision weighting and the
tracking of prediction error dynamics. These mechanisms should help to explore
more complex behaviors and tasks in cognitive robotics research under the
predictive processing framework.
</p>
<a href="http://arxiv.org/abs/2101.06611" target="_blank">arXiv:2101.06611</a> [<a href="http://arxiv.org/pdf/2101.06611" target="_blank">pdf</a>]

<h2>DyLoc: Dynamic Localization for Massive MIMO Using Predictive Recurrent Neural Networks. (arXiv:2101.07848v2 [cs.CV] UPDATED)</h2>
<h3>Farzam Hejazi, Katarina Vuckovic, Nazanin Rahnavard</h3>
<p>This paper presents a data-driven localization framework with high precision
in time-varying complex multipath environments, such as dense urban areas and
indoors, where GPS and model-based localization techniques come short. We
consider the angle-delay profile (ADP), a linear transformation of channel
state information (CSI), in massive MIMO systems and show that ADPs preserve
users' motion when stacked temporally. We discuss that given a static
environment, future frames of ADP time-series are predictable employing a video
frame prediction algorithm. We express that a deep convolutional neural network
(DCNN) can be employed to learn the background static scattering environment.
To detect foreground changes in the environment, corresponding to path blockage
or addition, we introduce an algorithm taking advantage of the trained DCNN.
Furthermore, we present DyLoc, a data-driven framework to recover distorted
ADPs due to foreground changes and to obtain precise location estimations. We
evaluate the performance of DyLoc in several dynamic scenarios employing
DeepMIMO dataset to generate geo-tagged CSI datasets for indoor and outdoor
environments. We show that previous DCNN-based techniques fail to perform with
desirable accuracy in dynamic environments, while DyLoc pursues localization
precisely. Moreover, simulations show that as the environment gets richer in
terms of the number of multipath, DyLoc gets more robust to foreground changes.
</p>
<a href="http://arxiv.org/abs/2101.07848" target="_blank">arXiv:2101.07848</a> [<a href="http://arxiv.org/pdf/2101.07848" target="_blank">pdf</a>]

<h2>Directed Acyclic Graph Neural Networks. (arXiv:2101.07965v2 [cs.LG] UPDATED)</h2>
<h3>Veronika Thost, Jie Chen</h3>
<p>Graph-structured data ubiquitously appears in science and engineering. Graph
neural networks (GNNs) are designed to exploit the relational inductive bias
exhibited in graphs; they have been shown to outperform other forms of neural
networks in scenarios where structure information supplements node features.
The most common GNN architecture aggregates information from neighborhoods
based on message passing. Its generality has made it broadly applicable. In
this paper, we focus on a special, yet widely used, type of graphs -- DAGs --
and inject a stronger inductive bias -- partial ordering -- into the neural
network design. We propose the \emph{directed acyclic graph neural network},
DAGNN, an architecture that processes information according to the flow defined
by the partial order. DAGNN can be considered a framework that entails earlier
works as special cases (e.g., models for trees and models updating node
representations recurrently), but we identify several crucial components that
prior architectures lack. We perform comprehensive experiments, including
ablation studies, on representative DAG datasets (i.e., source code, neural
architectures, and probabilistic graphical models) and demonstrate the
superiority of DAGNN over simpler DAG architectures as well as general graph
architectures.
</p>
<a href="http://arxiv.org/abs/2101.07965" target="_blank">arXiv:2101.07965</a> [<a href="http://arxiv.org/pdf/2101.07965" target="_blank">pdf</a>]

<h2>UPDeT: Universal Multi-agent Reinforcement Learning via Policy Decoupling with Transformers. (arXiv:2101.08001v2 [cs.LG] UPDATED)</h2>
<h3>Siyi Hu, Fengda Zhu, Xiaojun Chang, Xiaodan Liang</h3>
<p>Recent advances in multi-agent reinforcement learning have been largely
limited in training one model from scratch for every new task. The limitation
is due to the restricted model architecture related to fixed input and output
dimensions. This hinders the experience accumulation and transfer of the
learned agent over tasks with diverse levels of difficulty (e.g. 3 vs 3 or 5 vs
6 multi-agent games). In this paper, we make the first attempt to explore a
universal multi-agent reinforcement learning pipeline, designing one single
architecture to fit tasks with the requirement of different observation and
action configurations. Unlike previous RNN-based models, we utilize a
transformer-based model to generate a flexible policy by decoupling the policy
distribution from the intertwined input observation with an importance weight
measured by the merits of the self-attention mechanism. Compared to a standard
transformer block, the proposed model, named as Universal Policy Decoupling
Transformer (UPDeT), further relaxes the action restriction and makes the
multi-agent task's decision process more explainable. UPDeT is general enough
to be plugged into any multi-agent reinforcement learning pipeline and equip
them with strong generalization abilities that enables the handling of multiple
tasks at a time. Extensive experiments on large-scale SMAC multi-agent
competitive games demonstrate that the proposed UPDeT-based multi-agent
reinforcement learning achieves significant results relative to
state-of-the-art approaches, demonstrating advantageous transfer capability in
terms of both performance and training speed (10 times faster).
</p>
<a href="http://arxiv.org/abs/2101.08001" target="_blank">arXiv:2101.08001</a> [<a href="http://arxiv.org/pdf/2101.08001" target="_blank">pdf</a>]

<h2>Scalable Deep Compressive Sensing. (arXiv:2101.08024v2 [cs.CV] UPDATED)</h2>
<h3>Zhonghao Zhang, Yipeng Liu, Xingyu Cao, Fei Wen, Ce Zhu</h3>
<p>Deep learning has been used to image compressive sensing (CS) for enhanced
reconstruction performance. However, most existing deep learning methods train
different models for different subsampling ratios, which brings additional
hardware burden. In this paper, we develop a general framework named scalable
deep compressive sensing (SDCS) for the scalable sampling and reconstruction
(SSR) of all existing end-to-end-trained models. In the proposed way, images
are measured and initialized linearly. Two sampling masks are introduced to
flexibly control the subsampling ratios used in sampling and reconstruction,
respectively. To make the reconstruction model adapt to any subsampling ratio,
a training strategy dubbed scalable training is developed. In scalable
training, the model is trained with the sampling matrix and the initialization
matrix at various subsampling ratios by integrating different sampling matrix
masks. Experimental results show that models with SDCS can achieve SSR without
changing their structure while maintaining good performance, and SDCS
outperforms other SSR methods.
</p>
<a href="http://arxiv.org/abs/2101.08024" target="_blank">arXiv:2101.08024</a> [<a href="http://arxiv.org/pdf/2101.08024" target="_blank">pdf</a>]

<h2>Shielding Atari Games with Bounded Prescience. (arXiv:2101.08153v2 [cs.AI] UPDATED)</h2>
<h3>Mirco Giacobbe, Mohammadhosein Hasanbeig, Daniel Kroening, Hjalmar Wijk</h3>
<p>Deep reinforcement learning (DRL) is applied in safety-critical domains such
as robotics and autonomous driving. It achieves superhuman abilities in many
tasks, however whether DRL agents can be shown to act safely is an open
problem. Atari games are a simple yet challenging exemplar for evaluating the
safety of DRL agents and feature a diverse portfolio of game mechanics. The
safety of neural agents has been studied before using methods that either
require a model of the system dynamics or an abstraction; unfortunately, these
are unsuitable to Atari games because their low-level dynamics are complex and
hidden inside their emulator. We present the first exact method for analysing
and ensuring the safety of DRL agents for Atari games. Our method only requires
access to the emulator. First, we give a set of 43 properties that characterise
"safe behaviour" for 30 games. Second, we develop a method for exploring all
traces induced by an agent and a game and consider a variety of sources of game
non-determinism. We observe that the best available DRL agents reliably satisfy
only very few properties; several critical properties are violated by all
agents. Finally, we propose a countermeasure that combines a bounded
explicit-state exploration with shielding. We demonstrate that our method
improves the safety of all agents over multiple properties.
</p>
<a href="http://arxiv.org/abs/2101.08153" target="_blank">arXiv:2101.08153</a> [<a href="http://arxiv.org/pdf/2101.08153" target="_blank">pdf</a>]

<h2>How can I choose an explainer? An Application-grounded Evaluation of Post-hoc Explanations. (arXiv:2101.08758v2 [cs.AI] UPDATED)</h2>
<h3>S&#xe9;rgio Jesus, Catarina Bel&#xe9;m, Vladimir Balayan, Jo&#xe3;o Bento, Pedro Saleiro, Pedro Bizarro, Jo&#xe3;o Gama</h3>
<p>There have been several research works proposing new Explainable AI (XAI)
methods designed to generate model explanations having specific properties, or
desiderata, such as fidelity, robustness, or human-interpretability. However,
explanations are seldom evaluated based on their true practical impact on
decision-making tasks. Without that assessment, explanations might be chosen
that, in fact, hurt the overall performance of the combined system of ML model
+ end-users. This study aims to bridge this gap by proposing XAI Test, an
application-grounded evaluation methodology tailored to isolate the impact of
providing the end-user with different levels of information. We conducted an
experiment following XAI Test to evaluate three popular post-hoc explanation
methods -- LIME, SHAP, and TreeInterpreter -- on a real-world fraud detection
task, with real data, a deployed ML model, and fraud analysts. During the
experiment, we gradually increased the information provided to the fraud
analysts in three stages: Data Only, i.e., just transaction data without access
to model score nor explanations, Data + ML Model Score, and Data + ML Model
Score + Explanations. Using strong statistical analysis, we show that, in
general, these popular explainers have a worse impact than desired. Some of the
conclusion highlights include: i) showing Data Only results in the highest
decision accuracy and the slowest decision time among all variants tested, ii)
all the explainers improve accuracy over the Data + ML Model Score variant but
still result in lower accuracy when compared with Data Only; iii) LIME was the
least preferred by users, probably due to its substantially lower variability
of explanations from case to case.
</p>
<a href="http://arxiv.org/abs/2101.08758" target="_blank">arXiv:2101.08758</a> [<a href="http://arxiv.org/pdf/2101.08758" target="_blank">pdf</a>]

<h2>Through the Data Management Lens: Experimental Analysis and Evaluation of Fair Classification. (arXiv:2101.07361v1 [cs.LG] CROSS LISTED)</h2>
<h3>Maliha Tashfia Islam, Anna Fariha, Alexandra Meliou</h3>
<p>Classification, a heavily-studied data-driven machine learning task, drives
an increasing number of prediction systems involving critical human decisions
such as loan approval and criminal risk assessment. However, classifiers often
demonstrate discriminatory behavior, especially when presented with biased
data. Consequently, fairness in classification has emerged as a high-priority
research area. Data management research is showing an increasing presence and
interest in topics related to data and algorithmic fairness, including the
topic of fair classification. The interdisciplinary efforts in fair
classification, with machine learning research having the largest presence,
have resulted in a large number of fairness notions and a wide range of
approaches that have not been systematically evaluated and compared. In this
paper, we contribute a broad analysis of 13 fair classification approaches and
additional variants, over their correctness, fairness, efficiency, scalability,
and stability, using a variety of metrics and real-world datasets. Our analysis
highlights novel insights on the impact of different metrics and high-level
approach characteristics on different aspects of performance. We also discuss
general principles for choosing approaches suitable for different practical
settings, and identify areas where data-management-centric solutions are likely
to have the most impact.
</p>
<a href="http://arxiv.org/abs/2101.07361" target="_blank">arXiv:2101.07361</a> [<a href="http://arxiv.org/pdf/2101.07361" target="_blank">pdf</a>]

<h2>Disentangled Generative Causal Representation Learning. (arXiv:2010.02637v2 [cs.LG] CROSS LISTED)</h2>
<h3>Xinwei Shen, Furui Liu, Hanze Dong, Qing Lian, Zhitang Chen, Tong Zhang</h3>
<p>This paper proposes a Disentangled gEnerative cAusal Representation (DEAR)
learning method. Unlike existing disentanglement methods that enforce
independence of the latent variables, we consider the general case where the
underlying factors of interests can be causally correlated. We show that
previous methods with independent priors fail to disentangle causally
correlated factors. Motivated by this finding, we propose a new disentangled
learning method called DEAR that enables causal controllable generation and
causal representation learning. The key ingredient of this new formulation is
to use a structural causal model (SCM) as the prior for a bidirectional
generative model. The prior is then trained jointly with a generator and an
encoder using a suitable GAN loss incorporated with supervision. We provide
theoretical justification on the identifiability and asymptotic consistency of
the proposed method, which guarantees disentangled causal representation
learning under appropriate conditions. We conduct extensive experiments on both
synthesized and real data sets to demonstrate the effectiveness of DEAR in
causal controllable generation, and the benefits of the learned representations
for downstream tasks in terms of sample efficiency and distributional
robustness.
</p>
<a href="http://arxiv.org/abs/2010.02637" target="_blank">arXiv:2010.02637</a> [<a href="http://arxiv.org/pdf/2010.02637" target="_blank">pdf</a>]

