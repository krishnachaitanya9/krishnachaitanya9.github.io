---
title: Latest Deep Learning Papers
date: 2021-01-17 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (127 Articles)</h1>
<h2>Exploration of Visual Features and their weighted-additive fusion for Video Captioning. (arXiv:2101.05806v1 [cs.CV])</h2>
<h3>Praveen S V, Akhilesh Bharadwaj, Harsh Raj, Janhavi Dadhania, Ganesh Samarth C.A, Nikhil Pareek, S R M Prasanna</h3>
<p>Video captioning is a popular task that challenges models to describe events
in videos using natural language. In this work, we investigate the ability of
various visual feature representations derived from state-of-the-art
convolutional neural networks to capture high-level semantic context. We
introduce the Weighted Additive Fusion Transformer with Memory Augmented
Encoders (WAFTM), a captioning model that incorporates memory in a transformer
encoder and uses a novel method, to fuse features, that ensures due importance
is given to more significant representations. We illustrate a gain in
performance realized by applying Word-Piece Tokenization and a popular
REINFORCE algorithm. Finally, we benchmark our model on two datasets and obtain
a CIDEr of 92.4 on MSVD and a METEOR of 0.091 on the ActivityNet Captions
Dataset.
</p>
<a href="http://arxiv.org/abs/2101.05806" target="_blank">arXiv:2101.05806</a> [<a href="http://arxiv.org/pdf/2101.05806" target="_blank">pdf</a>]

<h2>Context-Aware Image Denoising with Auto-Threshold Canny Edge Detection to Suppress Adversarial Perturbation. (arXiv:2101.05833v1 [cs.CV])</h2>
<h3>Li-Yun Wang, Yeganeh Jalalpour, Wu-chi Feng</h3>
<p>This paper presents a novel context-aware image denoising algorithm that
combines an adaptive image smoothing technique and color reduction techniques
to remove perturbation from adversarial images. Adaptive image smoothing is
achieved using auto-threshold canny edge detection to produce an accurate edge
map used to produce a blurred image that preserves more edge features. The
proposed algorithm then uses color reduction techniques to reconstruct the
image using only a few representative colors. Through this technique, the
algorithm can reduce the effects of adversarial perturbations on images. We
also discuss experimental data on classification accuracy. Our results showed
that the proposed approach reduces adversarial perturbation in adversarial
attacks and increases the robustness of the deep convolutional neural network
models.
</p>
<a href="http://arxiv.org/abs/2101.05833" target="_blank">arXiv:2101.05833</a> [<a href="http://arxiv.org/pdf/2101.05833" target="_blank">pdf</a>]

<h2>Physics-aware, probabilistic model order reduction with guaranteed stability. (arXiv:2101.05834v1 [stat.ML])</h2>
<h3>Sebastian Kaltenbach, Phaedon-Stelios Koutsourelakis</h3>
<p>Given (small amounts of) time-series' data from a high-dimensional,
fine-grained, multiscale dynamical system, we propose a generative framework
for learning an effective, lower-dimensional, coarse-grained dynamical model
that is predictive of the fine-grained system's long-term evolution but also of
its behavior under different initial conditions. We target fine-grained models
as they arise in physical applications (e.g. molecular dynamics, agent-based
models), the dynamics of which are strongly non-stationary but their transition
to equilibrium is governed by unknown slow processes which are largely
inaccessible by brute-force simulations. Approaches based on domain knowledge
heavily rely on physical insight in identifying temporally slow features and
fail to enforce the long-term stability of the learned dynamics. On the other
hand, purely statistical frameworks lack interpretability and rely on large
amounts of expensive simulation data (long and multiple trajectories) as they
cannot infuse domain knowledge. The generative framework proposed achieves the
aforementioned desiderata by employing a flexible prior on the complex plane
for the latent, slow processes, and an intermediate layer of physics-motivated
latent variables that reduces reliance on data and imbues inductive bias. In
contrast to existing schemes, it does not require the a priori definition of
projection operators from the fine-grained description and addresses
simultaneously the tasks of dimensionality reduction and model estimation. We
demonstrate its efficacy and accuracy in multiscale physical systems of
particle dynamics where probabilistic, long-term predictions of phenomena not
contained in the training data are produced.
</p>
<a href="http://arxiv.org/abs/2101.05834" target="_blank">arXiv:2101.05834</a> [<a href="http://arxiv.org/pdf/2101.05834" target="_blank">pdf</a>]

<h2>A Neophyte With AutoML: Evaluating the Promises of Automatic Machine Learning Tools. (arXiv:2101.05840v1 [cs.LG])</h2>
<h3>Oleg Bezrukavnikov, Rhema Linder</h3>
<p>This paper discusses modern Auto Machine Learning (AutoML) tools from the
perspective of a person with little prior experience in Machine Learning (ML).
There are many AutoML tools both ready-to-use and under development, which are
created to simplify and democratize usage of ML technologies in everyday life.
Our position is that ML should be easy to use and available to a greater number
of people. Prior research has identified the need for intuitive AutoML tools.
This work seeks to understand how well AutoML tools have achieved that goal in
practice. We evaluate three AutoML Tools to evaluate the end-user experience
and system performance. We evaluate the tools by having them create models from
a competition dataset on banking data. We report on their performance and the
details of our experience. This process provides a unique understanding of the
state of the art of AutoML tools. Finally, we use these experiences to inform a
discussion on how future AutoML tools can improve the user experience for
neophytes of Machine Learning.
</p>
<a href="http://arxiv.org/abs/2101.05840" target="_blank">arXiv:2101.05840</a> [<a href="http://arxiv.org/pdf/2101.05840" target="_blank">pdf</a>]

<h2>Scaling the Convex Barrier with Active Sets. (arXiv:2101.05844v1 [cs.LG])</h2>
<h3>Alessandro De Palma, Harkirat Singh Behl, Rudy Bunel, Philip H.S. Torr, M. Pawan Kumar</h3>
<p>Tight and efficient neural network bounding is of critical importance for the
scaling of neural network verification systems. A number of efficient
specialised dual solvers for neural network bounds have been presented
recently, but they are often too loose to verify more challenging properties.
This lack of tightness is linked to the weakness of the employed relaxation,
which is usually a linear program of size linear in the number of neurons.
While a tighter linear relaxation for piecewise linear activations exists, it
comes at the cost of exponentially many constraints and thus currently lacks an
efficient customised solver. We alleviate this deficiency via a novel dual
algorithm that realises the full potential of the new relaxation by operating
on a small active set of dual variables. Our method recovers the strengths of
the new relaxation in the dual space: tightness and a linear separation oracle.
At the same time, it shares the benefits of previous dual approaches for weaker
relaxations: massive parallelism, GPU implementation, low cost per iteration
and valid bounds at any time. As a consequence, we obtain better bounds than
off-the-shelf solvers in only a fraction of their running time and recover the
speed-accuracy trade-offs of looser dual solvers if the computational budget is
small. We demonstrate that this results in significant formal verification
speed-ups.
</p>
<a href="http://arxiv.org/abs/2101.05844" target="_blank">arXiv:2101.05844</a> [<a href="http://arxiv.org/pdf/2101.05844" target="_blank">pdf</a>]

<h2>How Shift Equivariance Impacts Metric Learning for Instance Segmentation. (arXiv:2101.05846v1 [cs.CV])</h2>
<h3>Josef Lorenz Rumberger, Xiaoyan Yu, Peter Hirsch, Melanie Dohmen, Vanessa Emanuela Guarino, Ashkan Mokarian, Lisa Mais, Jan Funke, Dagmar Kainmueller</h3>
<p>Metric learning has received conflicting assessments concerning its
suitability for solving instance segmentation tasks. It has been dismissed as
theoretically flawed due to the shift equivariance of the employed CNNs and
their respective inability to distinguish same-looking objects. Yet it has been
shown to yield state of the art results for a variety of tasks, and practical
issues have mainly been reported in the context of tile-and-stitch approaches,
where discontinuities at tile boundaries have been observed. To date, neither
of the reported issues have undergone thorough formal analysis. In our work, we
contribute a comprehensive formal analysis of the shift equivariance properties
of encoder-decoder-style CNNs, which yields a clear picture of what can and
cannot be achieved with metric learning in the face of same-looking objects. In
particular, we prove that a standard encoder-decoder network that takes
$d$-dimensional images as input, with $l$ pooling layers and pooling factor
$f$, has the capacity to distinguish at most $f^{dl}$ same-looking objects, and
we show that this upper limit can be reached. Furthermore, we show that to
avoid discontinuities in a tile-and-stitch approach, assuming standard batch
size 1, it is necessary to employ valid convolutions in combination with a
training output window size strictly greater than $f^l$, while at test-time it
is necessary to crop tiles to size $n\cdot f^l$ before stitching, with $n\geq
1$. We complement these theoretical findings by discussing a number of
insightful special cases for which we show empirical results on synthetic data.
</p>
<a href="http://arxiv.org/abs/2101.05846" target="_blank">arXiv:2101.05846</a> [<a href="http://arxiv.org/pdf/2101.05846" target="_blank">pdf</a>]

<h2>Continual Learning of Knowledge Graph Embeddings. (arXiv:2101.05850v1 [cs.RO])</h2>
<h3>Angel Daruna, Mehul Gupta, Mohan Sridharan, Sonia Chernova</h3>
<p>In recent years, there has been a resurgence in methods that use distributed
(neural) representations to represent and reason about semantic knowledge for
robotics applications. However, while robots often observe previously unknown
concepts, these representations typically assume that all concepts are known a
priori, and incorporating new information requires all concepts to be learned
afresh. Our work relaxes the static assumptions of these representations to
tackle the incremental knowledge graph embedding problem by leveraging
principles of a range of continual learning methods. Through an experimental
evaluation with several knowledge graphs and embedding representations, we
provide insights about trade-offs for practitioners to match a semantics-driven
robotics application to a suitable continual knowledge graph embedding method.
</p>
<a href="http://arxiv.org/abs/2101.05850" target="_blank">arXiv:2101.05850</a> [<a href="http://arxiv.org/pdf/2101.05850" target="_blank">pdf</a>]

<h2>A Subjective Model of Human Decision Making Based on Quantum Decision Theory. (arXiv:2101.05851v1 [cs.AI])</h2>
<h3>Chenda Zhang, Hedvig Kjellstr&#xf6;m</h3>
<p>Computer modeling of human decision making is of large importance for, e.g.,
sustainable transport, urban development, and online recommendation systems. In
this paper we present a model for predicting the behavior of an individual
during a binary game under different amounts of risk, gain, and time pressure.
The model is based on Quantum Decision Theory (QDT), which has been shown to
enable modeling of the irrational and subjective aspects of the decision
making, not accounted for by the classical Cumulative Prospect Theory (CPT).
Experiments on two different datasets show that our QDT-based approach
outperforms both a CPT-based approach and data driven approaches such as
feed-forward neural networks and random forests.
</p>
<a href="http://arxiv.org/abs/2101.05851" target="_blank">arXiv:2101.05851</a> [<a href="http://arxiv.org/pdf/2101.05851" target="_blank">pdf</a>]

<h2>Comparisons of Graph Neural Networks on Cancer Classification Leveraging a Joint of Phenotypic and Genetic Features. (arXiv:2101.05866v1 [cs.LG])</h2>
<h3>David Oniani, Chen Wang, Yiqing Zhao, Andrew Wen, Hongfang Liu, Feichen Shen</h3>
<p>Cancer is responsible for millions of deaths worldwide every year. Although
significant progress hasbeen achieved in cancer medicine, many issues remain to
be addressed for improving cancer therapy.Appropriate cancer patient
stratification is the prerequisite for selecting appropriate treatment plan,
ascancer patients are of known heterogeneous genetic make-ups and phenotypic
differences. In thisstudy, built upon deep phenotypic characterizations
extractable from Mayo Clinic electronic healthrecords (EHRs) and genetic test
reports for a collection of cancer patients, we evaluated variousgraph neural
networks (GNNs) leveraging a joint of phenotypic and genetic features for
cancer typeclassification. Models were applied and fine-tuned on the Mayo
Clinic cancer disease dataset. Theassessment was done through the reported
accuracy, precision, recall, and F1 values as well as throughF1 scores based on
the disease class. Per our evaluation results, GNNs on average outperformed
thebaseline models with mean statistics always being higher that those of the
baseline models (0.849 vs0.772 for accuracy, 0.858 vs 0.794 for precision,
0.843 vs 0.759 for recall, and 0.843 vs 0.855 for F1score). Among GNNs,
ChebNet, GraphSAGE, and TAGCN showed the best performance, while GATshowed the
worst. We applied and compared eight GNN models including AGNN, ChebNet,
GAT,GCN, GIN, GraphSAGE, SGC, and TAGCN on the Mayo Clinic cancer disease
dataset and assessedtheir performance as well as compared them with each other
and with more conventional machinelearning models such as decision tree,
gradient boosting, multi-layer perceptron, naive bayes, andrandom forest which
we used as the baselines.
</p>
<a href="http://arxiv.org/abs/2101.05866" target="_blank">arXiv:2101.05866</a> [<a href="http://arxiv.org/pdf/2101.05866" target="_blank">pdf</a>]

<h2>Auto-weighted Robust Federated Learning with Corrupted Data Sources. (arXiv:2101.05880v1 [cs.LG])</h2>
<h3>Shenghui Li, Edith Ngai, Fanghua Ye, Thiemo Voigt</h3>
<p>Federated learning provides a communication-efficient and privacy-preserving
training process by enabling learning statistical models with massive
participants while keeping their data in local clients. However, standard
federated learning techniques that naively minimize an average loss function
are vulnerable to data corruptions from outliers, systematic mislabeling, or
even adversaries. In addition, it is often prohibited for service providers to
verify the quality of data samples due to the increasing concern of user data
privacy. In this paper, we address this challenge by proposing Auto-weighted
Robust Federated Learning (arfl), a novel approach that jointly learns the
global model and the weights of local updates to provide robustness against
corrupted data sources. We prove a learning bound on the expected risk with
respect to the predictor and the weights of clients, which guides the
definition of the objective for robust federated learning. The weights are
allocated by comparing the empirical loss of a client with the average loss of
the best p clients (p-average), thus we can downweight the clients with
significantly high losses, thereby lower their contributions to the global
model. We show that this approach achieves robustness when the data of
corrupted clients is distributed differently from benign ones. To optimize the
objective function, we propose a communication-efficient algorithm based on the
blockwise minimization paradigm. We conduct experiments on multiple benchmark
datasets, including CIFAR-10, FEMNIST and Shakespeare, considering different
deep neural network models. The results show that our solution is robust
against different scenarios including label shuffling, label flipping and noisy
features, and outperforms the state-of-the-art methods in most scenarios.
</p>
<a href="http://arxiv.org/abs/2101.05880" target="_blank">arXiv:2101.05880</a> [<a href="http://arxiv.org/pdf/2101.05880" target="_blank">pdf</a>]

<h2>A Deep Learning Based Ternary Task Classification System Using Gramian Angular Summation Field in fNIRS Neuroimaging Data. (arXiv:2101.05891v1 [cs.LG])</h2>
<h3>Sajila D. Wickramaratne, Md Shaad Mahmud</h3>
<p>Functional near-infrared spectroscopy (fNIRS) is a non-invasive, economical
method used to study its blood flow pattern. These patterns can be used to
classify tasks a subject is performing. Currently, most of the classification
systems use simple machine learning solutions for the classification of tasks.
These conventional machine learning methods, which are easier to implement and
interpret, usually suffer from low accuracy and undergo a complex preprocessing
phase before network training. The proposed method converts the raw fNIRS time
series data into an image using Gramian Angular Summation Field. A Deep
Convolutional Neural Network (CNN) based architecture is then used for task
classification, including mental arithmetic, motor imagery, and idle state.
Further, this method can eliminate the feature selection stage, which affects
the traditional classifiers' performance. This system obtained 87.14% average
classification accuracy higher than any other method for the dataset.
</p>
<a href="http://arxiv.org/abs/2101.05891" target="_blank">arXiv:2101.05891</a> [<a href="http://arxiv.org/pdf/2101.05891" target="_blank">pdf</a>]

<h2>A Ternary Bi-Directional LSTM Classification for Brain Activation Pattern Recognition Using fNIRS. (arXiv:2101.05892v1 [cs.LG])</h2>
<h3>Sajila D. Wickramaratne, MD Shaad Mahmud</h3>
<p>Functional near-infrared spectroscopy (fNIRS) is a non-invasive, low-cost
method used to study the brain's blood flow pattern. Such patterns can enable
us to classify performed by a subject. In recent research, most classification
systems use traditional machine learning algorithms for the classification of
tasks. These methods, which are easier to implement, usually suffer from low
accuracy. Further, a complex pre-processing phase is required for data
preparation before implementing traditional machine learning methods. The
proposed system uses a Bi-Directional LSTM based deep learning architecture for
task classification, including mental arithmetic, motor imagery, and idle state
using fNIRS data. Further, this system will require less pre-processing than
the traditional approach, saving time and computational resources while
obtaining an accuracy of 81.48\%, which is considerably higher than the
accuracy obtained using conventional machine learning algorithms for the same
data set.
</p>
<a href="http://arxiv.org/abs/2101.05892" target="_blank">arXiv:2101.05892</a> [<a href="http://arxiv.org/pdf/2101.05892" target="_blank">pdf</a>]

<h2>Instance-Aware Predictive Navigation in Multi-Agent Environments. (arXiv:2101.05893v1 [cs.RO])</h2>
<h3>Jinkun Cao, Xin Wang, Trevor Darrell, Fisher Yu</h3>
<p>In this work, we aim to achieve efficient end-to-end learning of driving
policies in dynamic multi-agent environments. Predicting and anticipating
future events at the object level are critical for making informed driving
decisions. We propose an Instance-Aware Predictive Control (IPC) approach,
which forecasts interactions between agents as well as future scene structures.
We adopt a novel multi-instance event prediction module to estimate the
possible interaction among agents in the ego-centric view, conditioned on the
selected action sequence of the ego-vehicle. To decide the action at each step,
we seek the action sequence that can lead to safe future states based on the
prediction module outputs by repeatedly sampling likely action sequences. We
design a sequential action sampling strategy to better leverage predicted
states on both scene-level and instance-level. Our method establishes a new
state of the art in the challenging CARLA multi-agent driving simulation
environments without expert demonstration, giving better explainability and
sample efficiency.
</p>
<a href="http://arxiv.org/abs/2101.05893" target="_blank">arXiv:2101.05893</a> [<a href="http://arxiv.org/pdf/2101.05893" target="_blank">pdf</a>]

<h2>Supervised Transfer Learning at Scale for Medical Imaging. (arXiv:2101.05913v1 [cs.CV])</h2>
<h3>Basil Mustafa, Aaron Loh, Jan Freyberg, Patricia MacWilliams, Alan Karthikesalingam, Neil Houlsby, Vivek Natarajan</h3>
<p>Transfer learning is a standard technique to improve performance on tasks
with limited data. However, for medical imaging, the value of transfer learning
is less clear. This is likely due to the large domain mismatch between the
usual natural-image pre-training (e.g. ImageNet) and medical images. However,
recent advances in transfer learning have shown substantial improvements from
scale. We investigate whether modern methods can change the fortune of transfer
learning for medical imaging. For this, we study the class of large-scale
pre-trained networks presented by Kolesnikov et al. on three diverse imaging
tasks: chest radiography, mammography, and dermatology. We study both transfer
performance and critical properties for the deployment in the medical domain,
including: out-of-distribution generalization, data-efficiency, sub-group
fairness, and uncertainty estimation. Interestingly, we find that for some of
these properties transfer from natural to medical images is indeed extremely
effective, but only when performed at sufficient scale.
</p>
<a href="http://arxiv.org/abs/2101.05913" target="_blank">arXiv:2101.05913</a> [<a href="http://arxiv.org/pdf/2101.05913" target="_blank">pdf</a>]

<h2>Scalable Learning of Safety Guarantees for Autonomous Systems using Hamilton-Jacobi Reachability. (arXiv:2101.05916v1 [cs.RO])</h2>
<h3>Sylvia Herbert, Jason J. Choi, Suvansh Qazi, Marsalis Gibson, Koushil Sreenath, Claire J. Tomlin</h3>
<p>Autonomous systems like aircraft and assistive robots often operate in
scenarios where guaranteeing safety is critical. Methods like Hamilton-Jacobi
reachability can provide guaranteed safe sets and controllers for such systems.
However, often these same scenarios have unknown or uncertain environments,
system dynamics, or predictions of other agents. As the system is operating, it
may learn new knowledge about these uncertainties and should therefore update
its safety analysis accordingly. However, work to learn and update safety
analysis is limited to small systems of about two dimensions due to the
computational complexity of the analysis. In this paper we synthesize several
techniques to speed up computation: decomposition, warm-starting, and adaptive
grids. Using this new framework we can update safe sets by one or more orders
of magnitude faster than prior work, making this technique practical for many
realistic systems. We demonstrate our results on simulated 2D and 10D
near-hover quadcopters operating in a windy environment.
</p>
<a href="http://arxiv.org/abs/2101.05916" target="_blank">arXiv:2101.05916</a> [<a href="http://arxiv.org/pdf/2101.05916" target="_blank">pdf</a>]

<h2>DiffPD: Differentiable Projective Dynamics with Contact. (arXiv:2101.05917v1 [cs.LG])</h2>
<h3>Tao Du, Kui Wu, Pingchuan Ma, Sebastien Wah, Andrew Spielberg, Daniela Rus, Wojciech Matusik</h3>
<p>We present a novel, fast differentiable simulator for soft-body learning and
control applications. Existing differentiable soft-body simulators can be
classified into two categories based on their time integration methods.
Simulators using explicit time-stepping scheme require tiny time steps to avoid
numerical instabilities in gradient computation, and simulators using implicit
time integration typically compute gradients by employing the adjoint method to
solve the expensive linearized dynamics. Inspired by Projective Dynamics (PD),
we present DiffPD, an efficient differentiable soft-body simulator with
implicit time integration. The key idea in DiffPD is to speed up
backpropagation by exploiting the prefactorized Cholesky decomposition in PD to
achieve a super-linear convergence rate. To handle contacts, DiffPD solves
contact forces by analyzing a linear complementarity problem (LCP) and its
gradients. With the assumption that contacts occur on a small number of nodes,
we develop an efficient method for gradient computation by exploring the
low-rank structure in the linearized dynamics. We evaluate the performance of
DiffPD and observe a speedup of 4-19 times compared to the standard Newton's
method in various applications including system identification, inverse design
problems, trajectory optimization, and closed-loop control.
</p>
<a href="http://arxiv.org/abs/2101.05917" target="_blank">arXiv:2101.05917</a> [<a href="http://arxiv.org/pdf/2101.05917" target="_blank">pdf</a>]

<h2>Image Enhancement using Fuzzy Intensity Measure and Adaptive Clipping Histogram Equalization. (arXiv:2101.05922v1 [cs.CV])</h2>
<h3>Xiangyuan Zhu, Xiaoming Xiao, Tardi Tjahjadi, Zhihu Wu, Jin Tang</h3>
<p>Image enhancement aims at processing an input image so that the visual
content of the output image is more pleasing or more useful for certain
applications. Although histogram equalization is widely used in image
enhancement due to its simplicity and effectiveness, it changes the mean
brightness of the enhanced image and introduces a high level of noise and
distortion. To address these problems, this paper proposes image enhancement
using fuzzy intensity measure and adaptive clipping histogram equalization
(FIMHE). FIMHE uses fuzzy intensity measure to first segment the histogram of
the original image, and then clip the histogram adaptively in order to prevent
excessive image enhancement. Experiments on the Berkeley database and
CVF-UGR-Image database show that FIMHE outperforms state-of-the-art histogram
equalization based methods.
</p>
<a href="http://arxiv.org/abs/2101.05922" target="_blank">arXiv:2101.05922</a> [<a href="http://arxiv.org/pdf/2101.05922" target="_blank">pdf</a>]

<h2>Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks. (arXiv:2101.05930v1 [cs.LG])</h2>
<h3>Yige Li, Nodens Koren, Lingjuan Lyu, Xixiang Lyu, Bo Li, Xingjun Ma</h3>
<p>Deep neural networks (DNNs) are known vulnerable to backdoor attacks, a
training time attack that injects a trigger pattern into a small proportion of
training data so as to control the model's prediction at the test time.
Backdoor attacks are notably dangerous since they do not affect the model's
performance on clean examples, yet can fool the model to make incorrect
prediction whenever the trigger pattern appears during testing. In this paper,
we propose a novel defense framework Neural Attention Distillation (NAD) to
erase backdoor triggers from backdoored DNNs. NAD utilizes a teacher network to
guide the finetuning of the backdoored student network on a small clean subset
of data such that the intermediate-layer attention of the student network
aligns with that of the teacher network. The teacher network can be obtained by
an independent finetuning process on the same clean subset. We empirically
show, against 6 state-of-the-art backdoor attacks, NAD can effectively erase
the backdoor triggers using only 5\% clean training data without causing
obvious performance degradation on clean examples.
</p>
<a href="http://arxiv.org/abs/2101.05930" target="_blank">arXiv:2101.05930</a> [<a href="http://arxiv.org/pdf/2101.05930" target="_blank">pdf</a>]

<h2>Differentiable Nonparametric Belief Propagation. (arXiv:2101.05948v1 [cs.RO])</h2>
<h3>Anthony Opipari (1), Chao Chen (1), Shoutian Wang (1), Jana Pavlasek (1), Karthik Desingh (2), Odest Chadwicke Jenkins (1) ((1) Robotics Institute, University of Michigan, Ann Arbor, (2) Department of Computer Science and Engineering, University of Washington, Seattle)</h3>
<p>We present a differentiable approach to learn the probabilistic factors used
for inference by a nonparametric belief propagation algorithm. Existing
nonparametric belief propagation methods rely on domain-specific features
encoded in the probabilistic factors of a graphical model. In this work, we
replace each crafted factor with a differentiable neural network enabling the
factors to be learned using an efficient optimization routine from labeled
data. By combining differentiable neural networks with an efficient belief
propagation algorithm, our method learns to maintain a set of marginal
posterior samples using end-to-end training. We evaluate our differentiable
nonparametric belief propagation (DNBP) method on a set of articulated pose
tracking tasks and compare performance with a recurrent neural network. Results
from this comparison demonstrate the effectiveness of using learned factors for
tracking and suggest the practical advantage over hand-crafted approaches. The
project webpage is available at: progress.eecs.umich.edu/projects/dnbp.
</p>
<a href="http://arxiv.org/abs/2101.05948" target="_blank">arXiv:2101.05948</a> [<a href="http://arxiv.org/pdf/2101.05948" target="_blank">pdf</a>]

<h2>Robusta: Robust AutoML for Feature Selection via Reinforcement Learning. (arXiv:2101.05950v1 [cs.LG])</h2>
<h3>Xiaoyang Wang, Bo Li, Yibo Zhang, Bhavya Kailkhura, Klara Nahrstedt</h3>
<p>Several AutoML approaches have been proposed to automate the machine learning
(ML) process, such as searching for the ML model architectures and
hyper-parameters. However, these AutoML pipelines only focus on improving the
learning accuracy of benign samples while ignoring the ML model robustness
under adversarial attacks. As ML systems are increasingly being used in a
variety of mission-critical applications, improving the robustness of ML
systems has become of utmost importance. In this paper, we propose the first
robust AutoML framework, Robusta--based on reinforcement learning (RL)--to
perform feature selection, aiming to select features that lead to both accurate
and robust ML systems. We show that a variation of the 0-1 robust loss can be
directly optimized via an RL-based combinatorial search in the feature
selection scenario. In addition, we employ heuristics to accelerate the search
procedure based on feature scoring metrics, which are mutual information
scores, tree-based classifiers feature importance scores, F scores, and
Integrated Gradient (IG) scores, as well as their combinations. We conduct
extensive experiments and show that the proposed framework is able to improve
the model robustness by up to 22% while maintaining competitive accuracy on
benign samples compared with other feature selection methods.
</p>
<a href="http://arxiv.org/abs/2101.05950" target="_blank">arXiv:2101.05950</a> [<a href="http://arxiv.org/pdf/2101.05950" target="_blank">pdf</a>]

<h2>Recent Advances in Video Question Answering: A Review of Datasets and Methods. (arXiv:2101.05954v1 [cs.CV])</h2>
<h3>Devshree Patel, Ratnam Parikh, Yesha Shastri</h3>
<p>Video Question Answering (VQA) is a recent emerging challenging task in the
field of Computer Vision. Several visual information retrieval techniques like
Video Captioning/Description and Video-guided Machine Translation have preceded
the task of VQA. VQA helps to retrieve temporal and spatial information from
the video scenes and interpret it. In this survey, we review a number of
methods and datasets for the task of VQA. To the best of our knowledge, no
previous survey has been conducted for the VQA task.
</p>
<a href="http://arxiv.org/abs/2101.05954" target="_blank">arXiv:2101.05954</a> [<a href="http://arxiv.org/pdf/2101.05954" target="_blank">pdf</a>]

<h2>DeepWaste: Applying Deep Learning to Waste Classification for a Sustainable Planet. (arXiv:2101.05960v1 [cs.LG])</h2>
<h3>Yash Narayan</h3>
<p>Accurate waste disposal, at the point of disposal, is crucial to fighting
climate change. When materials that could be recycled or composted get diverted
into landfills, they cause the emission of potent greenhouse gases such as
methane. Current attempts to reduce erroneous waste disposal are expensive,
inaccurate, and confusing. In this work, we propose DeepWaste, an easy-to-use
mobile app, that utilizes highly optimized deep learning techniques to provide
users instantaneous waste classification into trash, recycling, and compost. We
experiment with several convolution neural network architectures to detect and
classify waste items. Our best model, a deep learning residual neural network
with 50 layers, achieves an average precision of 0.881 on the test set. We
demonstrate the performance and efficiency of our app on a set of real-world
images.
</p>
<a href="http://arxiv.org/abs/2101.05960" target="_blank">arXiv:2101.05960</a> [<a href="http://arxiv.org/pdf/2101.05960" target="_blank">pdf</a>]

<h2>Responsible AI Challenges in End-to-end Machine Learning. (arXiv:2101.05967v1 [cs.LG])</h2>
<h3>Steven Euijong Whang, Ki Hyun Tae, Yuji Roh, Geon Heo</h3>
<p>Responsible AI is becoming critical as AI is widely used in our everyday
lives. Many companies that deploy AI publicly state that when training a model,
we not only need to improve its accuracy, but also need to guarantee that the
model does not discriminate against users (fairness), is resilient to noisy or
poisoned data (robustness), is explainable, and more. In addition, these
objectives are not only relevant to model training, but to all steps of
end-to-end machine learning, which include data collection, data cleaning and
validation, model training, model evaluation, and model management and serving.
Finally, responsible AI is conceptually challenging, and supporting all the
objectives must be as easy as possible. We thus propose three key research
directions towards this vision - depth, breadth, and usability - to measure
progress and introduce our ongoing research. First, responsible AI must be
deeply supported where multiple objectives like fairness and robust must be
handled together. To this end, we propose FR-Train, a holistic framework for
fair and robust model training in the presence of data bias and poisoning.
Second, responsible AI must be broadly supported, preferably in all steps of
machine learning. Currently we focus on the data pre-processing steps and
propose Slice Tuner, a selective data acquisition framework for training fair
and accurate models, and MLClean, a data cleaning framework that also improves
fairness and robustness. Finally, responsible AI must be usable where the
techniques must be easy to deploy and actionable. We propose FairBatch, a batch
selection approach for fairness that is effective and simple to use, and Slice
Finder, a model evaluation tool that automatically finds problematic slices. We
believe we scratched the surface of responsible AI for end-to-end machine
learning and suggest research challenges moving forward.
</p>
<a href="http://arxiv.org/abs/2101.05967" target="_blank">arXiv:2101.05967</a> [<a href="http://arxiv.org/pdf/2101.05967" target="_blank">pdf</a>]

<h2>Affordance-based Reinforcement Learning for Urban Driving. (arXiv:2101.05970v1 [cs.LG])</h2>
<h3>Tanmay Agarwal, Hitesh Arora, Jeff Schneider</h3>
<p>Traditional autonomous vehicle pipelines that follow a modular approach have
been very successful in the past both in academia and industry, which has led
to autonomy deployed on road. Though this approach provides ease of
interpretation, its generalizability to unseen environments is limited and
hand-engineering of numerous parameters is required, especially in the
prediction and planning systems. Recently, deep reinforcement learning has been
shown to learn complex strategic games and perform challenging robotic tasks,
which provides an appealing framework for learning to drive. In this work, we
propose a deep reinforcement learning framework to learn optimal control policy
using waypoints and low-dimensional visual representations, also known as
affordances. We demonstrate that our agents when trained from scratch learn the
tasks of lane-following, driving around inter-sections as well as stopping in
front of other actors or traffic lights even in the dense traffic setting. We
note that our method achieves comparable or better performance than the
baseline methods on the original and NoCrash benchmarks on the CARLA simulator.
</p>
<a href="http://arxiv.org/abs/2101.05970" target="_blank">arXiv:2101.05970</a> [<a href="http://arxiv.org/pdf/2101.05970" target="_blank">pdf</a>]

<h2>Inductive Representation Learning in Temporal Networks via Causal Anonymous Walks. (arXiv:2101.05974v1 [cs.LG])</h2>
<h3>Yanbang Wang, Yen-Yu Chang, Yunyu Liu, Jure Leskovec, Pan Li</h3>
<p>Temporal networks serve as abstractions of many real-world dynamic systems.
These networks typically evolve according to certain laws, such as the law of
triadic closure, which is universal in social networks. Inductive
representation learning of temporal networks should be able to capture such
laws and further be applied to systems that follow the same laws but have not
been unseen during the training stage. Previous works in this area depend on
either network node identities or rich edge attributes and typically fail to
extract these laws. Here, we propose Causal Anonymous Walks (CAWs) to
inductively represent a temporal network. CAWs are extracted by temporal random
walks and work as automatic retrieval of temporal network motifs to represent
network dynamics while avoiding the time-consuming selection and counting of
those motifs. CAWs adopt a novel anonymization strategy that replaces node
identities with the hitting counts of the nodes based on a set of sampled walks
to keep the method inductive, and simultaneously establish the correlation
between motifs. We further propose a neural-network model CAW-N to encode CAWs,
and pair it with a CAW sampling strategy with constant memory and time cost to
support online training and inference. CAW-N is evaluated to predict links over
6 real temporal networks and uniformly outperforms previous SOTA methods by
averaged 15% AUC gain in the inductive setting. CAW-N also outperforms previous
methods in 5 out of the 6 networks in the transductive setting.
</p>
<a href="http://arxiv.org/abs/2101.05974" target="_blank">arXiv:2101.05974</a> [<a href="http://arxiv.org/pdf/2101.05974" target="_blank">pdf</a>]

<h2>Randomized Ensembled Double Q-Learning: Learning Fast Without a Model. (arXiv:2101.05982v1 [cs.LG])</h2>
<h3>Xinyue Chen, Che Wang, Zijian Zhou, Keith Ross</h3>
<p>Using a high Update-To-Data (UTD) ratio, model-based methods have recently
achieved much higher sample efficiency than previous model-free methods for
continuous-action DRL benchmarks. In this paper, we introduce a simple
model-free algorithm, Randomized Ensembled Double Q-Learning (REDQ), and show
that its performance is just as good as, if not better than, a state-of-the-art
model-based algorithm for the MuJoCo benchmark. Moreover, REDQ can achieve this
performance using fewer parameters than the model-based method, and with less
wall-clock run time. REDQ has three carefully integrated ingredients which
allow it to achieve its high performance: (i) a UTD ratio &gt;&gt; 1; (ii) an
ensemble of Q functions; (iii) in-target minimization across a random subset of
Q functions from the ensemble. Through carefully designed experiments, we
provide a detailed analysis of REDQ and related model-free algorithms. To our
knowledge, REDQ is the first successful model-free DRL algorithm for
continuous-action spaces using a UTD ratio &gt;&gt; 1.
</p>
<a href="http://arxiv.org/abs/2101.05982" target="_blank">arXiv:2101.05982</a> [<a href="http://arxiv.org/pdf/2101.05982" target="_blank">pdf</a>]

<h2>Interaction-Aware Behavior Planning for Autonomous Vehicles Validated with Real Traffic Data. (arXiv:2101.05985v1 [cs.RO])</h2>
<h3>Jinning Li, Liting Sun, Wei Zhan, Masayoshi Tomizuka</h3>
<p>Autonomous vehicles (AVs) need to interact with other traffic participants
who can be either cooperative or aggressive, attentive or inattentive. Such
different characteristics can lead to quite different interactive behaviors.
Hence, to achieve safe and efficient autonomous driving, AVs need to be aware
of such uncertainties when they plan their own behaviors. In this paper, we
formulate such a behavior planning problem as a partially observable Markov
Decision Process (POMDP) where the cooperativeness of other traffic
participants is treated as an unobservable state. Under different
cooperativeness levels, we learn the human behavior models from real traffic
data via the principle of maximum likelihood. Based on that, the POMDP problem
is solved by Monte-Carlo Tree Search. We verify the proposed algorithm in both
simulations and real traffic data on a lane change scenario, and the results
show that the proposed algorithm can successfully finish the lane changes
without collisions.
</p>
<a href="http://arxiv.org/abs/2101.05985" target="_blank">arXiv:2101.05985</a> [<a href="http://arxiv.org/pdf/2101.05985" target="_blank">pdf</a>]

<h2>Quality meets Diversity: A Model-Agnostic Framework for Computerized Adaptive Testing. (arXiv:2101.05986v1 [cs.AI])</h2>
<h3>Haoyang Bi, Haiping Ma, Zhenya Huang, Yu Yin, Qi Liu, Enhong Chen, Yu Su, Shijin Wang</h3>
<p>Computerized Adaptive Testing (CAT) is emerging as a promising testing
application in many scenarios, such as education, game and recruitment, which
targets at diagnosing the knowledge mastery levels of examinees on required
concepts. It shows the advantage of tailoring a personalized testing procedure
for each examinee, which selects questions step by step, depending on her
performance. While there are many efforts on developing CAT systems, existing
solutions generally follow an inflexible model-specific fashion. That is, they
need to observe a specific cognitive model which can estimate examinee's
knowledge levels and design the selection strategy according to the model
estimation. In this paper, we study a novel model-agnostic CAT problem, where
we aim to propose a flexible framework that can adapt to different cognitive
models. Meanwhile, this work also figures out CAT solution with addressing the
problem of how to generate both high-quality and diverse questions
simultaneously, which can give a comprehensive knowledge diagnosis for each
examinee. Inspired by Active Learning, we propose a novel framework, namely
Model-Agnostic Adaptive Testing (MAAT) for CAT solution, where we design three
sophisticated modules including Quality Module, Diversity Module and Importance
Module. Extensive experimental results on two real-world datasets clearly
demonstrate that our MAAT can support CAT with guaranteeing both quality and
diversity perspectives.
</p>
<a href="http://arxiv.org/abs/2101.05986" target="_blank">arXiv:2101.05986</a> [<a href="http://arxiv.org/pdf/2101.05986" target="_blank">pdf</a>]

<h2>Accurate and Robust Scale Recovery for Monocular Visual Odometry Based on Plane Geometry. (arXiv:2101.05995v1 [cs.CV])</h2>
<h3>Rui Tian, Yunzhou Zhang, Delong Zhu, Shiwen Liang, Sonya Coleman, Dermot Kerr</h3>
<p>Scale ambiguity is a fundamental problem in monocular visual odometry.
Typical solutions include loop closure detection and environment information
mining. For applications like self-driving cars, loop closure is not always
available, hence mining prior knowledge from the environment becomes a more
promising approach. In this paper, with the assumption of a constant height of
the camera above the ground, we develop a light-weight scale recovery framework
leveraging an accurate and robust estimation of the ground plane. The framework
includes a ground point extraction algorithm for selecting high-quality points
on the ground plane, and a ground point aggregation algorithm for joining the
extracted ground points in a local sliding window. Based on the aggregated
data, the scale is finally recovered by solving a least-squares problem using a
RANSAC-based optimizer. Sufficient data and robust optimizer enable a highly
accurate scale recovery. Experiments on the KITTI dataset show that the
proposed framework can achieve state-of-the-art accuracy in terms of
translation errors, while maintaining competitive performance on the rotation
error. Due to the light-weight design, our framework also demonstrates a high
frequency of 20Hz on the dataset.
</p>
<a href="http://arxiv.org/abs/2101.05995" target="_blank">arXiv:2101.05995</a> [<a href="http://arxiv.org/pdf/2101.05995" target="_blank">pdf</a>]

<h2>Convolutional Neural Network with Pruning Method for Handwritten Digit Recognition. (arXiv:2101.05996v1 [cs.CV])</h2>
<h3>Mengyu Chen</h3>
<p>CNN model is a popular method for imagery analysis, so it could be utilized
to recognize handwritten digits based on MNIST datasets. For higher recognition
accuracy, various CNN models with different fully connected layer sizes are
exploited to figure out the relationship between the CNN fully connected layer
size and the recognition accuracy. Inspired by previous pruning work, we
performed pruning methods of distinctiveness on CNN models and compared the
pruning performance with NN models. For better pruning performances on CNN, the
effect of angle threshold on the pruning performance was explored. The
evaluation results show that: for the fully connected layer size, there is a
threshold, so that when the layer size increases, the recognition accuracy
grows if the layer size smaller than the threshold, and falls if the layer size
larger than the threshold; the performance of pruning performed on CNN is worse
than on NN; as pruning angle threshold increases, the fully connected layer
size and the recognition accuracy decreases. This paper also shows that for CNN
models trained by the MNIST dataset, they are capable of handwritten digit
recognition and achieve the highest recognition accuracy with fully connected
layer size 400. In addition, for same dataset MNIST, CNN models work better
than big, deep, simple NN models in a published paper.
</p>
<a href="http://arxiv.org/abs/2101.05996" target="_blank">arXiv:2101.05996</a> [<a href="http://arxiv.org/pdf/2101.05996" target="_blank">pdf</a>]

<h2>SimGAN: Hybrid Simulator Identification for Domain Adaptation via Adversarial Reinforcement Learning. (arXiv:2101.06005v1 [cs.RO])</h2>
<h3>Yifeng Jiang, Tingnan Zhang, Daniel Ho, Yunfei Bai, C. Karen Liu, Sergey Levine, Jie Tan</h3>
<p>As learning-based approaches progress towards automating robot controllers
design, transferring learned policies to new domains with different dynamics
(e.g. sim-to-real transfer) still demands manual effort. This paper introduces
SimGAN, a framework to tackle domain adaptation by identifying a hybrid physics
simulator to match the simulated trajectories to the ones from the target
domain, using a learned discriminative loss to address the limitations
associated with manual loss design. Our hybrid simulator combines neural
networks and traditional physics simulaton to balance expressiveness and
generalizability, and alleviates the need for a carefully selected parameter
set in System ID. Once the hybrid simulator is identified via adversarial
reinforcement learning, it can be used to refine policies for the target
domain, without the need to collect more data. We show that our approach
outperforms multiple strong baselines on six robotic locomotion tasks for
domain adaptation.
</p>
<a href="http://arxiv.org/abs/2101.06005" target="_blank">arXiv:2101.06005</a> [<a href="http://arxiv.org/pdf/2101.06005" target="_blank">pdf</a>]

<h2>The Geometry of Deep Generative Image Models and its Applications. (arXiv:2101.06006v1 [cs.LG])</h2>
<h3>Binxu Wang, Carlos R. Ponce</h3>
<p>Generative adversarial networks (GANs) have emerged as a powerful
unsupervised method to model the statistical patterns of real-world data sets,
such as natural images. These networks are trained to map random inputs in
their latent space to new samples representative of the learned data. However,
the structure of the latent space is hard to intuit due to its high
dimensionality and the non-linearity of the generator, which limits the
usefulness of the models. Understanding the latent space requires a way to
identify input codes for existing real-world images (inversion), and a way to
identify directions with known image transformations (interpretability). Here,
we use a geometric framework to address both issues simultaneously. We develop
an architecture-agnostic method to compute the Riemannian metric of the image
manifold created by GANs. The eigen-decomposition of the metric isolates axes
that account for different levels of image variability. An empirical analysis
of several pretrained GANs shows that image variation around each position is
concentrated along surprisingly few major axes (the space is highly
anisotropic) and the directions that create this large variation are similar at
different positions in the space (the space is homogeneous). We show that many
of the top eigenvectors correspond to interpretable transforms in the image
space, with a substantial part of eigenspace corresponding to minor transforms
which could be compressed out. This geometric understanding unifies key
previous results related to GAN interpretability. We show that the use of this
metric allows for more efficient optimization in the latent space (e.g. GAN
inversion) and facilitates unsupervised discovery of interpretable axes. Our
results illustrate that defining the geometry of the GAN image manifold can
serve as a general framework for understanding GANs.
</p>
<a href="http://arxiv.org/abs/2101.06006" target="_blank">arXiv:2101.06006</a> [<a href="http://arxiv.org/pdf/2101.06006" target="_blank">pdf</a>]

<h2>Reasoning over Vision and Language: Exploring the Benefits of Supplemental Knowledge. (arXiv:2101.06013v1 [cs.CV])</h2>
<h3>Violetta Shevchenko, Damien Teney, Anthony Dick, Anton van den Hengel</h3>
<p>The limits of applicability of vision-and-language models are defined by the
coverage of their training data. Tasks like vision question answering (VQA)
often require commonsense and factual information beyond what can be learned
from task-specific datasets. This paper investigates the injection of knowledge
from general-purpose knowledge bases (KBs) into vision-and-language
transformers. We use an auxiliary training objective that encourages the
learned representations to align with graph embeddings of matching entities in
a KB. We empirically study the relevance of various KBs to multiple tasks and
benchmarks. The technique brings clear benefits to knowledge-demanding question
answering tasks (OK-VQA, FVQA) by capturing semantic and relational knowledge
absent from existing models. More surprisingly, the technique also benefits
visual reasoning tasks (NLVR2, SNLI-VE). We perform probing experiments and
show that the injection of additional knowledge regularizes the space of
embeddings, which improves the representation of lexical and semantic
similarities. The technique is model-agnostic and can expand the applicability
of any vision-and-language transformer with minimal computational overhead.
</p>
<a href="http://arxiv.org/abs/2101.06013" target="_blank">arXiv:2101.06013</a> [<a href="http://arxiv.org/pdf/2101.06013" target="_blank">pdf</a>]

<h2>Non-uniform Motion Deblurring with Blurry Component Divided Guidance. (arXiv:2101.06021v1 [cs.CV])</h2>
<h3>Pei Wang, Wei Sun, Qingsen Yan, Axi Niu, Rui Li, Yu Zhu, Jinqiu Sun, Yanning Zhang</h3>
<p>Blind image deblurring is a fundamental and challenging computer vision
problem, which aims to recover both the blur kernel and the latent sharp image
from only a blurry observation. Despite the superiority of deep learning
methods in image deblurring have displayed, there still exists major challenge
with various non-uniform motion blur. Previous methods simply take all the
image features as the input to the decoder, which handles different degrees
(e.g. large blur, small blur) simultaneously, leading to challenges for sharp
image generation. To tackle the above problems, we present a deep two-branch
network to deal with blurry images via a component divided module, which
divides an image into two components based on the representation of blurry
degree. Specifically, two component attentive blocks are employed to learn
attention maps to exploit useful deblurring feature representations on both
large and small blurry regions. Then, the blur-aware features are fed into
two-branch reconstruction decoders respectively. In addition, a new feature
fusion mechanism, orientation-based feature fusion, is proposed to merge sharp
features of the two branches. Both qualitative and quantitative experimental
results show that our method performs favorably against the state-of-the-art
approaches.
</p>
<a href="http://arxiv.org/abs/2101.06021" target="_blank">arXiv:2101.06021</a> [<a href="http://arxiv.org/pdf/2101.06021" target="_blank">pdf</a>]

<h2>Motion-Based Handwriting Recognition. (arXiv:2101.06022v1 [cs.CV])</h2>
<h3>Junshen Kevin Chen, Wanze Xie, Yutong He</h3>
<p>We attempt to overcome the restriction of requiring a writing surface for
handwriting recognition. In this study, we design a prototype of a stylus
equipped with motion sensor, and utilizes gyroscopic and acceleration sensor
reading to perform written letter classification using various deep learning
techniques such as CNN and RNNs. We also explore various data augmentation
techniques and their effects, reaching up to 86% accuracy.
</p>
<a href="http://arxiv.org/abs/2101.06022" target="_blank">arXiv:2101.06022</a> [<a href="http://arxiv.org/pdf/2101.06022" target="_blank">pdf</a>]

<h2>Motion-Based Handwriting Recognition and Word Reconstruction. (arXiv:2101.06025v1 [cs.CV])</h2>
<h3>Junshen Kevin Chen, Wanze Xie, Yutong He</h3>
<p>In this project, we leverage a trained single-letter classifier to predict
the written word from a continuously written word sequence, by designing a word
reconstruction pipeline consisting of a dynamic-programming algorithm and an
auto-correction model. We conduct experiments to optimize models in this
pipeline, then employ domain adaptation to explore using this pipeline on
unseen data distributions.
</p>
<a href="http://arxiv.org/abs/2101.06025" target="_blank">arXiv:2101.06025</a> [<a href="http://arxiv.org/pdf/2101.06025" target="_blank">pdf</a>]

<h2>Towards a Computed-Aided Diagnosis System in Colonoscopy: Automatic Polyp Segmentation Using Convolution Neural Networks. (arXiv:2101.06040v1 [cs.CV])</h2>
<h3>Patrick Brandao, Odysseas Zisimopoulos, Evangelos Mazomenos, Gastone Ciuti, Jorge Bernal, Marco Visentini-Scarzanella, Arianna Menciassi, Paolo Dario, Anastasios Koulaouzidis, Alberto Arezzo, David J Hawkes, Danail Stoyanov</h3>
<p>Early diagnosis is essential for the successful treatment of bowel cancers
including colorectal cancer (CRC) and capsule endoscopic imaging with robotic
actuation can be a valuable diagnostic tool when combined with automated image
analysis. We present a deep learning rooted detection and segmentation
framework for recognizing lesions in colonoscopy and capsule endoscopy images.
We restructure established convolution architectures, such as VGG and ResNets,
by converting them into fully-connected convolution networks (FCNs), fine-tune
them and study their capabilities for polyp segmentation and detection. We
additionally use Shape from-Shading (SfS) to recover depth and provide a richer
representation of the tissue's structure in colonoscopy images. Depth is
incorporated into our network models as an additional input channel to the RGB
information and we demonstrate that the resulting network yields improved
performance. Our networks are tested on publicly available datasets and the
most accurate segmentation model achieved a mean segmentation IU of 47.78% and
56.95% on the ETIS-Larib and CVC-Colon datasets, respectively. For polyp
detection, the top performing models we propose surpass the current state of
the art with detection recalls superior to 90% for all datasets tested. To our
knowledge, we present the first work to use FCNs for polyp segmentation in
addition to proposing a novel combination of SfS and RGB that boosts
performance
</p>
<a href="http://arxiv.org/abs/2101.06040" target="_blank">arXiv:2101.06040</a> [<a href="http://arxiv.org/pdf/2101.06040" target="_blank">pdf</a>]

<h2>A Particle Filtering Framework for Integrity Risk of GNSS-Camera Sensor Fusion. (arXiv:2101.06044v1 [cs.RO])</h2>
<h3>Adyasha Mohanty, Shubh Gupta, Grace Xingxin Gao</h3>
<p>Adopting a joint approach towards state estimation and integrity monitoring
results in unbiased integrity monitoring unlike traditional approaches. So far,
a joint approach was used in Particle RAIM [l] for GNSS measurements only. In
our work, we extend Particle RAIM to a GNSS-camera fused system for joint state
estimation and integrity monitoring. To account for vision faults, we derive a
probability distribution over position from camera images using map-matching.
We formulate a Kullback-Leibler Divergence metric to assess the consistency of
GNSS and camera measurements and mitigate faults during sensor fusion. The
derived integrity risk upper bounds the probability of Hazardously Misleading
Information (HMI). Experimental validation on a real-world dataset shows that
our algorithm produces less than 11 m position error and the integrity risk
over bounds the probability of HMI with 0.11 failure rate for an 8 m Alert
Limit in an urban scenario.
</p>
<a href="http://arxiv.org/abs/2101.06044" target="_blank">arXiv:2101.06044</a> [<a href="http://arxiv.org/pdf/2101.06044" target="_blank">pdf</a>]

<h2>Counterfactual Generative Networks. (arXiv:2101.06046v1 [cs.LG])</h2>
<h3>Axel Sauer, Andreas Geiger</h3>
<p>Neural networks are prone to learning shortcuts -- they often model simple
correlations, ignoring more complex ones that potentially generalize better.
Prior works on image classification show that instead of learning a connection
to object shape, deep classifiers tend to exploit spurious correlations with
low-level texture or the background for solving the classification task. In
this work, we take a step towards more robust and interpretable classifiers
that explicitly expose the task's causal structure. Building on current
advances in deep generative modeling, we propose to decompose the image
generation process into independent causal mechanisms that we train without
direct supervision. By exploiting appropriate inductive biases, these
mechanisms disentangle object shape, object texture, and background; hence,
they allow for generating counterfactual images. We demonstrate the ability of
our model to generate such images on MNIST and ImageNet. Further, we show that
the counterfactual images can improve out-of-distribution robustness with a
marginal drop in performance on the original classification task, despite being
synthetic. Lastly, our generative model can be trained efficiently on a single
GPU, exploiting common pre-trained models as inductive biases.
</p>
<a href="http://arxiv.org/abs/2101.06046" target="_blank">arXiv:2101.06046</a> [<a href="http://arxiv.org/pdf/2101.06046" target="_blank">pdf</a>]

<h2>Artificial Intelligence for IT Operations (AIOPS) Workshop White Paper. (arXiv:2101.06054v1 [cs.LG])</h2>
<h3>Jasmin Bogatinovski, Sasho Nedelkoski, Alexander Acker, Florian Schmidt, Thorsten Wittkopp, Soeren Becker, Jorge Cardoso, Odej Kao</h3>
<p>Artificial Intelligence for IT Operations (AIOps) is an emerging
interdisciplinary field arising in the intersection between the research areas
of machine learning, big data, streaming analytics, and the management of IT
operations. AIOps, as a field, is a candidate to produce the future standard
for IT operation management. To that end, AIOps has several challenges. First,
it needs to combine separate research branches from other research fields like
software reliability engineering. Second, novel modelling techniques are needed
to understand the dynamics of different systems. Furthermore, it requires to
lay out the basis for assessing: time horizons and uncertainty for imminent SLA
violations, the early detection of emerging problems, autonomous remediation,
decision making, support of various optimization objectives. Moreover, a good
understanding and interpretability of these aiding models are important for
building trust between the employed tools and the domain experts. Finally, all
this will result in faster adoption of AIOps, further increase the interest in
this research field and contribute to bridging the gap towards fully-autonomous
operating IT systems.

The main aim of the AIOPS workshop is to bring together researchers from both
academia and industry to present their experiences, results, and work in
progress in this field. The workshop aims to strengthen the community and unite
it towards the goal of joining the efforts for solving the main challenges the
field is currently facing. A consensus and adoption of the principles of
openness and reproducibility will boost the research in this emerging area
significantly.
</p>
<a href="http://arxiv.org/abs/2101.06054" target="_blank">arXiv:2101.06054</a> [<a href="http://arxiv.org/pdf/2101.06054" target="_blank">pdf</a>]

<h2>Heating up decision boundaries: isocapacitory saturation, adversarial scenarios and generalization bounds. (arXiv:2101.06061v1 [cs.LG])</h2>
<h3>Bogdan Georgiev, Lukas Franken, Mayukh Mukherjee</h3>
<p>In the present work we study classifiers' decision boundaries via Brownian
motion processes in ambient data space and associated probabilistic techniques.
Intuitively, our ideas correspond to placing a heat source at the decision
boundary and observing how effectively the sample points warm up. We are
largely motivated by the search for a soft measure that sheds further light on
the decision boundary's geometry. En route, we bridge aspects of potential
theory and geometric analysis (Mazya, 2011, Grigoryan-Saloff-Coste, 2002) with
active fields of ML research such as adversarial examples and generalization
bounds. First, we focus on the geometric behavior of decision boundaries in the
light of adversarial attack/defense mechanisms. Experimentally, we observe a
certain capacitory trend over different adversarial defense strategies:
decision boundaries locally become flatter as measured by isoperimetric
inequalities (Ford et al, 2019); however, our more sensitive heat-diffusion
metrics extend this analysis and further reveal that some non-trivial geometry
invisible to plain distance-based methods is still preserved. Intuitively, we
provide evidence that the decision boundaries nevertheless retain many
persistent "wiggly and fuzzy" regions on a finer scale. Second, we show how
Brownian hitting probabilities translate to soft generalization bounds which
are in turn connected to compression and noise stability (Arora et al, 2018),
and these bounds are significantly stronger if the decision boundary has
controlled geometric features.
</p>
<a href="http://arxiv.org/abs/2101.06061" target="_blank">arXiv:2101.06061</a> [<a href="http://arxiv.org/pdf/2101.06061" target="_blank">pdf</a>]

<h2>Constraint Handling in Continuous-Time DDP-Based Model Predictive Control. (arXiv:2101.06067v1 [cs.RO])</h2>
<h3>Jean-Pierre Sleiman, Farbod Farshidian, Marco Hutter</h3>
<p>The Sequential Linear Quadratic (SLQ) algorithm is a continuous-time variant
of the well-known Differential Dynamic Programming (DDP) technique with a
Gauss-Newton Hessian approximation. This family of methods has gained
popularity in the robotics community due to its efficiency in solving complex
trajectory optimization problems. However, one major drawback of DDP-based
formulations is their inability to properly incorporate path constraints. In
this paper, we address this issue by devising a constrained SLQ algorithm that
handles a mixture of constraints with a previously implemented projection
technique and a new augmented-Lagrangian approach. By providing an appropriate
multiplier update law, and by solving a single inner and outer loop iteration,
we are able to retrieve suboptimal solutions at rates suitable for real-time
model-predictive control applications. We particularly focus on the
inequality-constrained case, where three augmented-Lagrangian penalty functions
are introduced, along with their corresponding multiplier update rules. These
are then benchmarked against a relaxed log-barrier formulation in a cart-pole
swing up example, an obstacle-avoidance task, and an object-pushing task with a
quadrupedal mobile manipulator.
</p>
<a href="http://arxiv.org/abs/2101.06067" target="_blank">arXiv:2101.06067</a> [<a href="http://arxiv.org/pdf/2101.06067" target="_blank">pdf</a>]

<h2>Data Impressions: Mining Deep Models to Extract Samples for Data-free Applications. (arXiv:2101.06069v1 [cs.CV])</h2>
<h3>Gaurav Kumar Nayak, Konda Reddy Mopuri, Saksham Jain, Anirban Chakraborty</h3>
<p>Pretrained deep models hold their learnt knowledge in the form of the model
parameters. These parameters act as memory for the trained models and help them
generalize well on unseen data. However, in absence of training data, the
utility of a trained model is merely limited to either inference or better
initialization towards a target task. In this paper, we go further and extract
synthetic data by leveraging the learnt model parameters. We dub them "Data
Impressions", which act as proxy to the training data and can be used to
realize a variety of tasks. These are useful in scenarios where only the
pretrained models are available and the training data is not shared (e.g., due
to privacy or sensitivity concerns). We show the applicability of data
impressions in solving several computer vision tasks such as unsupervised
domain adaptation, continual learning as well as knowledge distillation. We
also study the adversarial robustness of the lightweight models trained via
knowledge distillation using these data impressions. Further, we demonstrate
the efficacy of data impressions in generating UAPs with better fooling rates.
Extensive experiments performed on several benchmark datasets demonstrate
competitive performance achieved using data impressions in absence of the
original training data.
</p>
<a href="http://arxiv.org/abs/2101.06069" target="_blank">arXiv:2101.06069</a> [<a href="http://arxiv.org/pdf/2101.06069" target="_blank">pdf</a>]

<h2>Efficient Semi-Implicit Variational Inference. (arXiv:2101.06070v1 [cs.LG])</h2>
<h3>Vincent Moens, Hang Ren, Alexandre Maraval, Rasul Tutunov, Jun Wang, Haitham Ammar</h3>
<p>In this paper, we propose CI-VI an efficient and scalable solver for
semi-implicit variational inference (SIVI). Our method, first, maps SIVI's
evidence lower bound (ELBO) to a form involving a nonlinear functional nesting
of expected values and then develops a rigorous optimiser capable of correctly
handling bias inherent to nonlinear nested expectations using an
extrapolation-smoothing mechanism coupled with gradient sketching. Our
theoretical results demonstrate convergence to a stationary point of the ELBO
in general non-convex settings typically arising when using deep network models
and an order of $O(t^{-\frac{4}{5}})$ gradient-bias-vanishing rate. We believe
these results generalise beyond the specific nesting arising from SIVI to other
forms. Finally, in a set of experiments, we demonstrate the effectiveness of
our algorithm in approximating complex posteriors on various data-sets
including those from natural language processing.
</p>
<a href="http://arxiv.org/abs/2101.06070" target="_blank">arXiv:2101.06070</a> [<a href="http://arxiv.org/pdf/2101.06070" target="_blank">pdf</a>]

<h2>Video Summarization Using Deep Neural Networks: A Survey. (arXiv:2101.06072v1 [cs.CV])</h2>
<h3>Evlampios Apostolidis, Eleni Adamantidou, Alexandros I. Metsai, Vasileios Mezaris, Ioannis Patras</h3>
<p>Video summarization technologies aim to create a concise and complete
synopsis by selecting the most informative parts of the video content. Several
approaches have been developed over the last couple of decades and the current
state of the art is represented by methods that rely on modern deep neural
network architectures. This work focuses on the recent advances in the area and
provides a comprehensive survey of the existing deep-learning-based methods for
generic video summarization. After presenting the motivation behind the
development of technologies for video summarization, we formulate the video
summarization task and discuss the main characteristics of a typical
deep-learning-based analysis pipeline. Then, we suggest a taxonomy of the
existing algorithms and provide a systematic review of the relevant literature
that shows the evolution of the deep-learning-based video summarization
technologies and leads to suggestions for future developments. We then report
on protocols for the objective evaluation of video summarization algorithms and
we compare the performance of several deep-learning-based approaches. Based on
the outcomes of these comparisons, as well as some documented considerations
about the suitability of evaluation protocols, we indicate potential future
research directions.
</p>
<a href="http://arxiv.org/abs/2101.06072" target="_blank">arXiv:2101.06072</a> [<a href="http://arxiv.org/pdf/2101.06072" target="_blank">pdf</a>]

<h2>Dynamic Normalization. (arXiv:2101.06073v1 [cs.CV])</h2>
<h3>Chuan Liu, Yi Gao, Jiancheng Lv</h3>
<p>Batch Normalization has become one of the essential components in CNN. It
allows the network to use a higher learning rate and speed up training. And the
network doesn't need to be initialized carefully. However, in our work, we find
that a simple extension of BN can increase the performance of the network.
First, we extend BN to adaptively generate scale and shift parameters for each
mini-batch data, called DN-C (Batch-shared and Channel-wise). We use the
statistical characteristics of mini-batch data ($E[X],
Std[X]\in\mathbb{R}^{c}$) as the input of SC module. Then we extend BN to
adaptively generate scale and shift parameters for each channel of each sample,
called DN-B (Batch and Channel-wise). Our experiments show that DN-C model
can't train normally, but DN-B model has very good robustness. In
classification task, DN-B can improve the accuracy of the MobileNetV2 on
ImageNet-100 more than 2% with only 0.6% additional Mult-Adds. In detection
task, DN-B can improve the accuracy of the SSDLite on MS-COCO nearly 4% mAP
with the same settings. Compared with BN, DN-B has stable performance when
using higher learning rate or smaller batch size.
</p>
<a href="http://arxiv.org/abs/2101.06073" target="_blank">arXiv:2101.06073</a> [<a href="http://arxiv.org/pdf/2101.06073" target="_blank">pdf</a>]

<h2>Deep Dual-resolution Networks for Real-time and Accurate Semantic Segmentation of Road Scenes. (arXiv:2101.06085v1 [cs.CV])</h2>
<h3>Yuanduo Hong, Huihui Pan, Weichao Sun, Senior Member, IEEE, Yisong Jia</h3>
<p>Semantic segmentation is a critical technology for autonomous vehicles to
understand surrounding scenes. For practical autonomous vehicles, it is
undesirable to spend a considerable amount of inference time to achieve
high-accuracy segmentation results. Using light-weight architectures
(encoder-decoder or two-pathway) or reasoning on low-resolution images, recent
methods realize very fast scene parsing which even run at more than 100 FPS on
single 1080Ti GPU. However, there are still evident gaps in performance between
these real-time methods and models based on dilation backbones. To tackle this
problem, we propose novel deep dual-resolution networks (DDRNets) for real-time
semantic segmentation of road scenes. Besides, we design a new contextual
information extractor named Deep Aggregation Pyramid Pooling Module (DAPPM) to
enlarge effective receptive fields and fuse multi-scale context. Our method
achieves new state-of-the-art trade-off between accuracy and speed on both
Cityscapes and CamVid dataset. Specially, on single 2080Ti GPU, DDRNet-23-slim
yields 77.4% mIoU at 109 FPS on Cityscapes test set and 74.4% mIoU at 230 FPS
on CamVid test set. Without utilizing attention mechanism, pre-training on
larger semantic segmentation dataset or inference acceleration, DDRNet-39
attains 80.4% test mIoU at 23 FPS on Cityscapes. With widely used test
augmentation, our method is still superior to most state-of-the-art models,
requiring much less computation. Codes and trained models will be made publicly
available.
</p>
<a href="http://arxiv.org/abs/2101.06085" target="_blank">arXiv:2101.06085</a> [<a href="http://arxiv.org/pdf/2101.06085" target="_blank">pdf</a>]

<h2>On the Verification and Validation of AI Navigation Algorithms. (arXiv:2101.06091v1 [cs.AI])</h2>
<h3>Ivan Porres, Sepinoud Azimi, S&#xe9;bastien Lafond, Johan Lilius, Johanna Salokannel, Mirva Salokorpi</h3>
<p>This paper explores the state of the art on to methods to verify and validate
navigation algorithms for autonomous surface ships. We perform a systematic
mapping study to find research works published in the last 10 years proposing
new algorithms for autonomous navigation and collision avoidance and we have
extracted what verification and validation approaches have been applied on
these algorithms. We observe that most research works use simulations to
validate their algorithms. However, these simulations often involve just a few
scenarios designed manually. This raises the question if the algorithms have
been validated properly. To remedy this, we propose the use of a systematic
scenario-based testing approach to validate navigation algorithms extensively.
</p>
<a href="http://arxiv.org/abs/2101.06091" target="_blank">arXiv:2101.06091</a> [<a href="http://arxiv.org/pdf/2101.06091" target="_blank">pdf</a>]

<h2>Black-box Adversarial Attacks in Autonomous Vehicle Technology. (arXiv:2101.06092v1 [cs.CV])</h2>
<h3>K Naveen Kumar, C Vishnu, Reshmi Mitra, C Krishna Mohan</h3>
<p>Despite the high quality performance of the deep neural network in real-world
applications, they are susceptible to minor perturbations of adversarial
attacks. This is mostly undetectable to human vision. The impact of such
attacks has become extremely detrimental in autonomous vehicles with real-time
"safety" concerns. The black-box adversarial attacks cause drastic
misclassification in critical scene elements such as road signs and traffic
lights leading the autonomous vehicle to crash into other vehicles or
pedestrians. In this paper, we propose a novel query-based attack method called
Modified Simple black-box attack (M-SimBA) to overcome the use of a white-box
source in transfer based attack method. Also, the issue of late convergence in
a Simple black-box attack (SimBA) is addressed by minimizing the loss of the
most confused class which is the incorrect class predicted by the model with
the highest probability, instead of trying to maximize the loss of the correct
class. We evaluate the performance of the proposed approach to the German
Traffic Sign Recognition Benchmark (GTSRB) dataset. We show that the proposed
model outperforms the existing models like Transfer-based projected gradient
descent (T-PGD), SimBA in terms of convergence time, flattening the
distribution of confused class probability, and producing adversarial samples
with least confidence on the true class.
</p>
<a href="http://arxiv.org/abs/2101.06092" target="_blank">arXiv:2101.06092</a> [<a href="http://arxiv.org/pdf/2101.06092" target="_blank">pdf</a>]

<h2>Approximations with deep neural networks in Sobolev time-space. (arXiv:2101.06115v1 [cs.LG])</h2>
<h3>Ahmed Abdeljawad, Philipp Grohs</h3>
<p>Solutions of evolution equation generally lies in certain Bochner-Sobolev
spaces, in which the solution may has regularity and integrability properties
for the time variable that can be different for the space variables. Therefore,
in this paper, we develop a framework shows that deep neural networks can
approximate Sobolev-regular functions with respect to Bochner-Sobolev spaces.
In our work we use the so-called Rectified Cubic Unit (ReCU) as an activation
function in our networks, which allows us to deduce approximation results of
the neural networks while avoiding issues caused by the non regularity of the
most commonly used Rectivied Linear Unit (ReLU) activation function.
</p>
<a href="http://arxiv.org/abs/2101.06115" target="_blank">arXiv:2101.06115</a> [<a href="http://arxiv.org/pdf/2101.06115" target="_blank">pdf</a>]

<h2>EAGER: Embedding-Assisted Entity Resolution for Knowledge Graphs. (arXiv:2101.06126v1 [cs.LG])</h2>
<h3>Daniel Obraczka, Jonathan Schuchart, Erhard Rahm</h3>
<p>Entity Resolution (ER) is a constitutional part for integrating different
knowledge graphs in order to identify entities referring to the same real-world
object. A promising approach is the use of graph embeddings for ER in order to
determine the similarity of entities based on the similarity of their graph
neighborhood. The similarity computations for such embeddings translates to
calculating the distance between them in the embedding space which is
comparatively simple. However, previous work has shown that the use of graph
embeddings alone is not sufficient to achieve high ER quality. We therefore
propose a more comprehensive ER approach for knowledge graphs called EAGER
(Embedding-Assisted Knowledge Graph Entity Resolution) to flexibly utilize both
the similarity of graph embeddings and attribute values within a supervised
machine learning approach. We evaluate our approach on 23 benchmark datasets
with differently sized and structured knowledge graphs and use hypothesis tests
to ensure statistical significance of our results. Furthermore we compare our
approach with state-of-the-art ER solutions, where our approach yields
competitive results for table-oriented ER problems and shallow knowledge graphs
but much better results for deeper knowledge graphs.
</p>
<a href="http://arxiv.org/abs/2101.06126" target="_blank">arXiv:2101.06126</a> [<a href="http://arxiv.org/pdf/2101.06126" target="_blank">pdf</a>]

<h2>Vision-based Vehicle Speed Estimation for ITS: A Survey. (arXiv:2101.06159v1 [cs.CV])</h2>
<h3>David Fern&#xe1;ndez Llorca, Antonio Hern&#xe1;ndez Mart&#xed;nez, Iv&#xe1;n Garc&#xed;a Daza</h3>
<p>The need to accurately estimate the speed of road vehicles is becoming
increasingly important for at least two main reasons. First, the number of
speed cameras installed worldwide has been growing in recent years, as the
introduction and enforcement of appropriate speed limits is considered one of
the most effective means to increase the road safety. Second, traffic
monitoring and forecasting in road networks plays a fundamental role to enhance
traffic, emissions and energy consumption in smart cities, being the speed of
the vehicles one of the most relevant parameters of the traffic state. Among
the technologies available for the accurate detection of vehicle speed, the use
of vision-based systems brings great challenges to be solved, but also great
potential advantages, such as the drastic reduction of costs due to the absence
of expensive range sensors, and the possibility of identifying vehicles
accurately. This paper provides a review of vision-based vehicle speed
estimation. We describe the terminology, the application domains, and propose a
complete taxonomy of a large selection of works that categorizes all stages
involved. An overview of performance evaluation metrics and available datasets
is provided. Finally, we discuss current limitations and future directions.
</p>
<a href="http://arxiv.org/abs/2101.06159" target="_blank">arXiv:2101.06159</a> [<a href="http://arxiv.org/pdf/2101.06159" target="_blank">pdf</a>]

<h2>Learning Invariant Representation for Continual Learning. (arXiv:2101.06162v1 [cs.LG])</h2>
<h3>Ghada Sokar, Decebal Constantin Mocanu, Mykola Pechenizkiy</h3>
<p>Continual learning aims to provide intelligent agents that are capable of
learning continually a sequence of tasks, building on previously learned
knowledge. A key challenge in this learning paradigm is catastrophically
forgetting previously learned tasks when the agent faces a new one. Current
rehearsal-based methods show their success in mitigating the catastrophic
forgetting problem by replaying samples from previous tasks during learning a
new one. However, these methods are infeasible when the data of previous tasks
is not accessible. In this work, we propose a new pseudo-rehearsal-based
method, named learning Invariant Representation for Continual Learning (IRCL),
in which class-invariant representation is disentangled from a conditional
generative model and jointly used with class-specific representation to learn
the sequential tasks. Disentangling the shared invariant representation helps
to learn continually a sequence of tasks, while being more robust to forgetting
and having better knowledge transfer. We focus on class incremental learning
where there is no knowledge about task identity during inference. We
empirically evaluate our proposed method on two well-known benchmarks for
continual learning: split MNIST and split Fashion MNIST. The experimental
results show that our proposed method outperforms regularization-based methods
by a big margin and is better than the state-of-the-art pseudo-rehearsal-based
method. Finally, we analyze the role of the shared invariant representation in
mitigating the forgetting problem especially when the number of replayed
samples for each previous task is small.
</p>
<a href="http://arxiv.org/abs/2101.06162" target="_blank">arXiv:2101.06162</a> [<a href="http://arxiv.org/pdf/2101.06162" target="_blank">pdf</a>]

<h2>A General Framework for Hypercomplex-valued Extreme Learning Machines. (arXiv:2101.06166v1 [cs.LG])</h2>
<h3>Guilherme Vieira, Marcos Eduardo Valle</h3>
<p>This paper aims to establish a framework for extreme learning machines (ELMs)
on general hypercomplex algebras. Hypercomplex neural networks are machine
learning models that feature higher-dimension numbers as parameters, inputs,
and outputs. Firstly, we review broad hypercomplex algebras and show a
framework to operate in these algebras through real-valued linear algebra
operations in a robust manner. We proceed to explore a handful of well-known
four-dimensional examples. Then, we propose the hypercomplex-valued ELMs and
derive their learning using a hypercomplex-valued least-squares problem.
Finally, we compare real and hypercomplex-valued ELM models' performance in an
experiment on time-series prediction and another on color image auto-encoding.
The computational experiments highlight the excellent performance of
hypercomplex-valued ELMs to treat high-dimensional data, including models based
on unusual hypercomplex algebras.
</p>
<a href="http://arxiv.org/abs/2101.06166" target="_blank">arXiv:2101.06166</a> [<a href="http://arxiv.org/pdf/2101.06166" target="_blank">pdf</a>]

<h2>Probabilistic Inference for Learning from Untrusted Sources. (arXiv:2101.06171v1 [cs.LG])</h2>
<h3>Duc Thien Nguyen, Shiau Hoong Lim, Laura Wynter, Desmond Cai</h3>
<p>Federated learning brings potential benefits of faster learning, better
solutions, and a greater propensity to transfer when heterogeneous data from
different parties increases diversity. However, because federated learning
tasks tend to be large and complex, and training times non-negligible, it is
important for the aggregation algorithm to be robust to non-IID data and
corrupted parties. This robustness relies on the ability to identify, and
appropriately weight, incompatible parties. Recent work assumes that a
\textit{reference dataset} is available through which to perform the
identification. We consider settings where no such reference dataset is
available; rather, the quality and suitability of the parties needs to be
\textit{inferred}. We do so by bringing ideas from crowdsourced predictions and
collaborative filtering, where one must infer an unknown ground truth given
proposals from participants with unknown quality. We propose novel federated
learning aggregation algorithms based on Bayesian inference that adapt to the
quality of the parties. Empirically, we show that the algorithms outperform
standard and robust aggregation in federated learning on both synthetic and
real data.
</p>
<a href="http://arxiv.org/abs/2101.06171" target="_blank">arXiv:2101.06171</a> [<a href="http://arxiv.org/pdf/2101.06171" target="_blank">pdf</a>]

<h2>PaddleSeg: A High-Efficient Development Toolkit for Image Segmentation. (arXiv:2101.06175v1 [cs.CV])</h2>
<h3>Yi Liu, Lutao Chu, Guowei Chen, Zewu Wu, Zeyu Chen, Baohua Lai, Yuying Hao</h3>
<p>Image Segmentation plays an essential role in computer vision and image
processing with various applications from medical diagnosis to autonomous car
driving. A lot of segmentation algorithms have been proposed for addressing
specific problems. In recent years, the success of deep learning techniques has
tremendously influenced a wide range of computer vision areas, and the modern
approaches of image segmentation based on deep learning are becoming prevalent.
In this article, we introduce a high-efficient development toolkit for image
segmentation, named PaddleSeg. The toolkit aims to help both developers and
researchers in the whole process of designing segmentation models, training
models, optimizing performance and inference speed, and deploying models.
Currently, PaddleSeg supports around 20 popular segmentation models and more
than 50 pre-trained models from real-time and high-accuracy levels. With
modular components and backbone networks, users can easily build over one
hundred models for different requirements. Furthermore, we provide
comprehensive benchmarks and evaluations to show that these segmentation
algorithms trained on our toolkit have more competitive accuracy. Also, we
provide various real industrial applications and practical cases based on
PaddleSeg. All codes and examples of PaddleSeg are available at
https://github.com/PaddlePaddle/PaddleSeg.
</p>
<a href="http://arxiv.org/abs/2101.06175" target="_blank">arXiv:2101.06175</a> [<a href="http://arxiv.org/pdf/2101.06175" target="_blank">pdf</a>]

<h2>Hierarchical Width-Based Planning and Learning. (arXiv:2101.06177v1 [cs.AI])</h2>
<h3>Miquel Junyent, Vicen&#xe7; G&#xf3;mez, Anders Jonsson</h3>
<p>Width-based search methods have demonstrated state-of-the-art performance in
a wide range of testbeds, from classical planning problems to image-based
simulators such as Atari games. These methods scale independently of the size
of the state-space, but exponentially in the problem width. In practice,
running the algorithm with a width larger than 1 is computationally
intractable, prohibiting IW from solving higher width problems. In this paper,
we present a hierarchical algorithm that plans at two levels of abstraction. A
high-level planner uses abstract features that are incrementally discovered
from low-level pruning decisions. We illustrate this algorithm in classical
planning PDDL domains as well as in pixel-based simulator domains. In classical
planning, we show how IW(1) at two levels of abstraction can solve problems of
width 2. For pixel-based domains, we show how in combination with a learned
policy and a learned value function, the proposed hierarchical IW can
outperform current flat IW-based planners in Atari games with sparse rewards.
</p>
<a href="http://arxiv.org/abs/2101.06177" target="_blank">arXiv:2101.06177</a> [<a href="http://arxiv.org/pdf/2101.06177" target="_blank">pdf</a>]

<h2>Learning to Sample from Censored Markov Random Fields. (arXiv:2101.06178v1 [cs.LG])</h2>
<h3>Ankur Moitra, Elchanan Mossel, Colin Sandon</h3>
<p>We study learning Censor Markov Random Fields (abbreviated CMRFs). These are
Markov Random Fields where some of the nodes are censored (not observed). We
present an algorithm for learning high-temperature CMRFs within o(n)
transportation distance. Crucially our algorithm makes no assumption about the
structure of the graph or the number or location of the observed nodes. We
obtain stronger results for high girth high-temperature CMRFs as well as
computational lower bounds indicating that our results can not be qualitatively
improved.
</p>
<a href="http://arxiv.org/abs/2101.06178" target="_blank">arXiv:2101.06178</a> [<a href="http://arxiv.org/pdf/2101.06178" target="_blank">pdf</a>]

<h2>Temporal-Relational CrossTransformers for Few-Shot Action Recognition. (arXiv:2101.06184v1 [cs.CV])</h2>
<h3>Toby Perrett, Alessandro Masullo, Tilo Burghardt, Majid Mirmehdi, Dima Damen</h3>
<p>We propose a novel approach to few-shot action recognition, finding
temporally-corresponding frame tuples between the query and videos in the
support set. Distinct from previous few-shot action recognition works, we
construct class prototypes using the CrossTransformer attention mechanism to
observe relevant sub-sequences of all support videos, rather than using class
averages or single best matches. Video representations are formed from ordered
tuples of varying numbers of frames, which allows sub-sequences of actions at
different speeds and temporal offsets to be compared.

Our proposed Temporal-Relational CrossTransformers achieve state-of-the-art
results on both Kinetics and Something-Something V2 (SSv2), outperforming prior
work on SSv2 by a wide margin (6.8%) due to the method's ability to model
temporal relations. A detailed ablation showcases the importance of matching to
multiple support set videos and learning higher-order relational
CrossTransformers. Code is available at https://github.com/tobyperrett/trx
</p>
<a href="http://arxiv.org/abs/2101.06184" target="_blank">arXiv:2101.06184</a> [<a href="http://arxiv.org/pdf/2101.06184" target="_blank">pdf</a>]

<h2>Hybrid Quantum-Classical Graph Convolutional Network. (arXiv:2101.06189v1 [cs.LG])</h2>
<h3>Samuel Yen-Chi Chen, Tzu-Chieh Wei, Chao Zhang, Haiwang Yu, Shinjae Yoo</h3>
<p>The high energy physics (HEP) community has a long history of dealing with
large-scale datasets. To manage such voluminous data, classical machine
learning and deep learning techniques have been employed to accelerate physics
discovery. Recent advances in quantum machine learning (QML) have indicated the
potential of applying these techniques in HEP. However, there are only limited
results in QML applications currently available. In particular, the challenge
of processing sparse data, common in HEP datasets, has not been extensively
studied in QML models. This research provides a hybrid quantum-classical graph
convolutional network (QGCNN) for learning HEP data. The proposed framework
demonstrates an advantage over classical multilayer perceptron and
convolutional neural networks in the aspect of number of parameters. Moreover,
in terms of testing accuracy, the QGCNN shows comparable performance to a
quantum convolutional neural network on the same HEP dataset while requiring
less than $50\%$ of the parameters. Based on numerical simulation results,
studying the application of graph convolutional operations and other QML models
may prove promising in advancing HEP research and other scientific fields.
</p>
<a href="http://arxiv.org/abs/2101.06189" target="_blank">arXiv:2101.06189</a> [<a href="http://arxiv.org/pdf/2101.06189" target="_blank">pdf</a>]

<h2>Deciding What to Learn: A Rate-Distortion Approach. (arXiv:2101.06197v1 [cs.LG])</h2>
<h3>Dilip Arumugam, Benjamin Van Roy</h3>
<p>Agents that learn to select optimal actions represent a prominent focus of
the sequential decision-making literature. In the face of a complex environment
or constraints on time and resources, however, aiming to synthesize such an
optimal policy can become infeasible. These scenarios give rise to an important
trade-off between the information an agent must acquire to learn and the
sub-optimality of the resulting policy. While an agent designer has a
preference for how this trade-off is resolved, existing approaches further
require that the designer translate these preferences into a fixed learning
target for the agent. In this work, leveraging rate-distortion theory, we
automate this process such that the designer need only express their
preferences via a single hyperparameter and the agent is endowed with the
ability to compute its own learning targets that best achieve the desired
trade-off. We establish a general bound on expected discounted regret for an
agent that decides what to learn in this manner along with computational
experiments that illustrate the expressiveness of designer preferences and even
show improvements over Thompson sampling in identifying an optimal policy.
</p>
<a href="http://arxiv.org/abs/2101.06197" target="_blank">arXiv:2101.06197</a> [<a href="http://arxiv.org/pdf/2101.06197" target="_blank">pdf</a>]

<h2>A Novel Prediction Approach for Exploring PM2.5 Spatiotemporal Propagation Based on Convolutional Recursive Neural Networks. (arXiv:2101.06213v1 [cs.LG])</h2>
<h3>Hsing-Chung Chen, Karisma Trinanda Putra, Jerry Chun-WeiLin</h3>
<p>The spread of PM2.5 pollutants that endanger health is difficult to predict
because it involves many atmospheric variables. These micron particles can
spread rapidly from their source to residential areas, increasing the risk of
respiratory disease if exposed for long periods. The prediction system of PM2.5
propagation provides more detailed and accurate information as an early warning
system to reduce health impacts on the community. According to the idea of
transformative computing, the approach we propose in this paper allows
computation on the dataset obtained from massive-scale PM2.5 sensor nodes via
wireless sensor network. In the scheme, the deep learning model is implemented
on the server nodes to extract spatiotemporal features on these datasets. This
research was conducted by using dataset of air quality monitoring systems in
Taiwan. This study presents a new model based on the convolutional recursive
neural network to generate the prediction map. In general, the model is able to
provide accurate predictive results by considering the bonds among measurement
nodes in both spatially and temporally. Therefore, the particulate pollutant
propagation of PM2.5 could be precisely monitored by using the model we propose
in this paper.
</p>
<a href="http://arxiv.org/abs/2101.06213" target="_blank">arXiv:2101.06213</a> [<a href="http://arxiv.org/pdf/2101.06213" target="_blank">pdf</a>]

<h2>APEX-Net: Automatic Plot Extractor Network. (arXiv:2101.06217v1 [cs.CV])</h2>
<h3>Aalok Gangopadhyay, Prajwal Singh, Shanmuganathan Raman</h3>
<p>Automatic extraction of raw data from 2D line plot images is a problem of
great importance having many real-world applications. Several algorithms have
been proposed for solving this problem. However, these algorithms involve a
significant amount of human intervention. To minimize this intervention, we
propose APEX-Net, a deep learning based framework with novel loss functions for
solving the plot extraction problem. We introduce APEX-1M, a new large scale
dataset which contains both the plot images and the raw data. We demonstrate
the performance of APEX-Net on the APEX-1M test set and show that it obtains
impressive accuracy. We also show visual results of our network on unseen plot
images and demonstrate that it extracts the shape of the plots to a great
extent. Finally, we develop a GUI based software for plot extraction that can
benefit the community at large. The dataset and code will be made publicly
available.
</p>
<a href="http://arxiv.org/abs/2101.06217" target="_blank">arXiv:2101.06217</a> [<a href="http://arxiv.org/pdf/2101.06217" target="_blank">pdf</a>]

<h2>LIME: Learning Inductive Bias for Primitives of Mathematical Reasoning. (arXiv:2101.06223v1 [cs.LG])</h2>
<h3>Yuhuai Wu, Markus Rabe, Wenda Li, Jimmy Ba, Roger Grosse, Christian Szegedy</h3>
<p>While designing inductive bias in neural architectures has been widely
studied, we hypothesize that transformer networks are flexible enough to learn
inductive bias from suitable generic tasks. Here, we replace architecture
engineering by encoding inductive bias in the form of datasets. Inspired by
Peirce's view that deduction, induction, and abduction form an irreducible set
of reasoning primitives, we design three synthetic tasks that are intended to
require the model to have these three abilities. We specifically design these
synthetic tasks in a way that they are devoid of mathematical knowledge to
ensure that only the fundamental reasoning biases can be learned from these
tasks. This defines a new pre-training methodology called "LIME" (Learning
Inductive bias for Mathematical rEasoning). Models trained with LIME
significantly outperform vanilla transformers on three very different large
mathematical reasoning benchmarks. Unlike dominating the computation cost as
traditional pre-training approaches, LIME requires only a small fraction of the
computation cost of the typical downstream task.
</p>
<a href="http://arxiv.org/abs/2101.06223" target="_blank">arXiv:2101.06223</a> [<a href="http://arxiv.org/pdf/2101.06223" target="_blank">pdf</a>]

<h2>Multi-point dimensionality reduction to improve projection layout reliability. (arXiv:2101.06224v1 [cs.CV])</h2>
<h3>Farshad Barahimi, Fernando Paulovich</h3>
<p>In ordinary Dimensionality Reduction (DR), each data instance in an
m-dimensional space (original space) is mapped to one point in a d-dimensional
space (visual space), preserving as much as possible distance and/or
neighborhood relationships. Despite their popularity, even for simple datasets,
the existing DR techniques unavoidably may produce misleading visual
representations. The problem is not with the existing solutions but with
problem formulation. For two dimensional visual space, if data instances are
not co-planar or do not lie on a 2D manifold, there is no solution for the
problem, and the possible approximations usually result in layouts with
inaccuracies in the distance preservation and overlapped neighborhoods. In this
paper, we elaborate on the concept of Multi-point Dimensionality Reduction
where each data instance can be mapped to possibly more than one point in the
visual space by providing the first general solution to it as a step toward
mitigating this issue. By duplicating points, background information is added
to the visual representation making local neighborhoods in the visual space
more faithful to the original space. Our solution, named Red Gray Plus, is
built upon and extends a combination of ordinary DR and graph drawing
techniques. We show that not only Multi-point Dimensionality Reduction can be
one of the potential directions to improve DR layouts' reliability but also
that our initial solution to the problem outperforms popular ordinary DR
methods quantitatively.
</p>
<a href="http://arxiv.org/abs/2101.06224" target="_blank">arXiv:2101.06224</a> [<a href="http://arxiv.org/pdf/2101.06224" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning for Haptic Shared Control in Unknown Tasks. (arXiv:2101.06227v1 [cs.RO])</h2>
<h3>Franklin Carde&#xf1;oso Fernandez, Wouter Caarls</h3>
<p>Recent years have shown a growing interest in using haptic shared control
(HSC) in teleoperated systems. In HSC, the application of virtual guiding
forces decreases the user's control effort and improves execution time in
various tasks, presenting a good alternative in comparison with direct
teleoperation. HSC, despite demonstrating good performance, opens a new gap:
how to design the guiding forces. For this reason, the challenge lies in
developing controllers to provide the optimal guiding forces for the tasks that
are being performed. This work addresses this challenge by designing a
controller based on the deep deterministic policy gradient (DDPG) algorithm to
provide the assistance, and a convolutional neural network (CNN) to perform the
task detection, called TAHSC (Task Agnostic Haptic Shared Controller). The
agent learns to minimize the time it takes the human to execute the desired
task, while simultaneously minimizing their resistance to the provided
feedback. This resistance thus provides the learning algorithm with information
about which direction the human is trying to follow, in this case, the
pick-and-place task. Diverse results demonstrate the successful application of
the proposed approach by learning custom policies for each user who was asked
to test the system. It exhibits stable convergence and aids the user in
completing the task with the least amount of time possible.
</p>
<a href="http://arxiv.org/abs/2101.06227" target="_blank">arXiv:2101.06227</a> [<a href="http://arxiv.org/pdf/2101.06227" target="_blank">pdf</a>]

<h2>Predictive Optimization with Zero-Shot Domain Adaptation. (arXiv:2101.06233v1 [cs.LG])</h2>
<h3>Tomoya Sakai, Naoto Ohsaka</h3>
<p>Prediction in a new domain without any training sample, called zero-shot
domain adaptation (ZSDA), is an important task in domain adaptation. While
prediction in a new domain has gained much attention in recent years, in this
paper, we investigate another potential of ZSDA. Specifically, instead of
predicting responses in a new domain, we find a description of a new domain
given a prediction. The task is regarded as predictive optimization, but
existing predictive optimization methods have not been extended to handling
multiple domains. We propose a simple framework for predictive optimization
with ZSDA and analyze the condition in which the optimization problem becomes
convex optimization. We also discuss how to handle the interaction of
characteristics of a domain in predictive optimization. Through numerical
experiments, we demonstrate the potential usefulness of our proposed framework.
</p>
<a href="http://arxiv.org/abs/2101.06233" target="_blank">arXiv:2101.06233</a> [<a href="http://arxiv.org/pdf/2101.06233" target="_blank">pdf</a>]

<h2>Blind Image Deblurring based on Kernel Mixture. (arXiv:2101.06241v1 [cs.CV])</h2>
<h3>Sajjad Amrollahi Biyouki, Hoon Hwangbo</h3>
<p>Blind Image deblurring tries to estimate blurriness and a latent image out of
a blurred image. This estimation, as being an ill-posed problem, requires
imposing restrictions on the latent image or a blur kernel that represents
blurriness. Different from recent studies that impose some priors on the latent
image, this paper regulates the structure of the blur kernel. We propose a
kernel mixture structure while using the Gaussian kernel as a base kernel. By
combining multiple Gaussian kernels structurally enhanced in terms of scales
and centers, the kernel mixture becomes capable of modeling nearly
non-parametric shape of blurriness. A data-driven decision for the number of
base kernels to combine makes the structure even more flexible. We apply this
approach to a remote sensing problem to recover images from blurry images of
satellite. This case study shows the superiority of the proposed method
regulating the blur kernel in comparison with state-of-the-art methods that
regulates the latent image.
</p>
<a href="http://arxiv.org/abs/2101.06241" target="_blank">arXiv:2101.06241</a> [<a href="http://arxiv.org/pdf/2101.06241" target="_blank">pdf</a>]

<h2>Local Navigation and Docking of an Autonomous Robot Mower using Reinforcement Learning and Computer Vision. (arXiv:2101.06248v1 [cs.RO])</h2>
<h3>Ali Taghibakhshi, Nathan Ogden, Matthew West</h3>
<p>We demonstrate a successful navigation and docking control system for the
John Deere Tango autonomous mower, using only a single camera as the input.
This vision-only system is of interest because it is inexpensive, simple for
production, and requires no external sensing. This is in contrast to existing
systems that rely on integrated position sensors and global positioning system
(GPS) technologies. To produce our system we combined a state-of-the-art object
detection architecture, YOLO, with a reinforcement learning (RL) architecture,
Double Deep QNetworks (Double DQN). The object detection network identifies
features on the mower and passes its output to the RL network, providing it
with a low-dimensional representation that enables rapid and robust training.
Finally, the RL network learns how to navigate the machine to the desired spot
in a custom simulation environment. When tested on mower hardware the system is
able to dock with centimeter-level accuracy from arbitrary initial locations
and orientations.
</p>
<a href="http://arxiv.org/abs/2101.06248" target="_blank">arXiv:2101.06248</a> [<a href="http://arxiv.org/pdf/2101.06248" target="_blank">pdf</a>]

<h2>Harmonization and the Worst Scanner Syndrome. (arXiv:2101.06255v1 [cs.LG])</h2>
<h3>Daniel Moyer, Polina Golland</h3>
<p>We show that for a wide class of harmonization/domain-invariance schemes
several undesirable properties are unavoidable. If a predictive machine is made
invariant to a set of domains, the accuracy of the output predictions (as
measured by mutual information) is limited by the domain with the least amount
of information to begin with. If a real label value is highly informative about
the source domain, it cannot be accurately predicted by an invariant predictor.
These results are simple and intuitive, but we believe that it is beneficial to
state them for medical imaging harmonization.
</p>
<a href="http://arxiv.org/abs/2101.06255" target="_blank">arXiv:2101.06255</a> [<a href="http://arxiv.org/pdf/2101.06255" target="_blank">pdf</a>]

<h2>Internet of Robotic Things: Current Technologies, Applications, Challenges and Future Directions. (arXiv:2101.06256v1 [cs.RO])</h2>
<h3>Davide Villa, Xinchao Song, Matthew Heim, Liangshe Li</h3>
<p>Nowadays, the Internet of Things (IoT) concept is gaining more and more
notoriety bringing the number of connected devices to reach the order of
billion units. Its smart technology is influencing the research and
developments of advanced solutions in many areas. This paper focuses on the
merger between the IoT and robotics named the Internet of Robotic Things
(IoRT). Allowing robotic systems to communicate over the internet at a minimal
cost is an important technological opportunity. Robots can use the cloud to
improve the overall performance and for offloading demanding tasks. Since
communicating to the cloud results in latency, data loss, and energy loss,
finding efficient techniques is a concern that can be addressed with current
machine learning methodologies. Moreover, the use of robotic generates ethical
and regulation questions that should be answered for a proper coexistence
between humans and robots. This paper aims at providing a better understanding
of the new concept of IoRT with its benefits and limitations, as well as
guidelines and directions for future research and studies.
</p>
<a href="http://arxiv.org/abs/2101.06256" target="_blank">arXiv:2101.06256</a> [<a href="http://arxiv.org/pdf/2101.06256" target="_blank">pdf</a>]

<h2>Local Search Algorithms for Rank-Constrained Convex Optimization. (arXiv:2101.06262v1 [cs.LG])</h2>
<h3>Kyriakos Axiotis, Maxim Sviridenko</h3>
<p>We propose greedy and local search algorithms for rank-constrained convex
optimization, namely solving $\underset{\mathrm{rank}(A)\leq r^*}{\min}\, R(A)$
given a convex function $R:\mathbb{R}^{m\times n}\rightarrow \mathbb{R}$ and a
parameter $r^*$. These algorithms consist of repeating two steps: (a) adding a
new rank-1 matrix to $A$ and (b) enforcing the rank constraint on $A$. We
refine and improve the theoretical analysis of Shalev-Shwartz et al. (2011),
and show that if the rank-restricted condition number of $R$ is $\kappa$, a
solution $A$ with rank $O(r^*\cdot \min\{\kappa \log
\frac{R(\mathbf{0})-R(A^*)}{\epsilon}, \kappa^2\})$ and $R(A) \leq R(A^*) +
\epsilon$ can be recovered, where $A^*$ is the optimal solution. This
significantly generalizes associated results on sparse convex optimization, as
well as rank-constrained convex optimization for smooth functions. We then
introduce new practical variants of these algorithms that have superior runtime
and recover better solutions in practice. We demonstrate the versatility of
these methods on a wide range of applications involving matrix completion and
robust principal component analysis.
</p>
<a href="http://arxiv.org/abs/2101.06262" target="_blank">arXiv:2101.06262</a> [<a href="http://arxiv.org/pdf/2101.06262" target="_blank">pdf</a>]

<h2>Bayesian Approaches to Distribution Regression. (arXiv:1705.04293v4 [stat.ML] UPDATED)</h2>
<h3>Ho Chung Leon Law, Danica J. Sutherland, Dino Sejdinovic, Seth Flaxman</h3>
<p>Distribution regression has recently attracted much interest as a generic
solution to the problem of supervised learning where labels are available at
the group level, rather than at the individual level. Current approaches,
however, do not propagate the uncertainty in observations due to sampling
variability in the groups. This effectively assumes that small and large groups
are estimated equally well, and should have equal weight in the final
regression. We account for this uncertainty with a Bayesian distribution
regression formalism, improving the robustness and performance of the model
when group sizes vary. We frame our models in a neural network style, allowing
for simple MAP inference using backpropagation to learn the parameters, as well
as MCMC-based inference which can fully propagate uncertainty. We demonstrate
our approach on illustrative toy datasets, as well as on a challenging problem
of predicting age from images.
</p>
<a href="http://arxiv.org/abs/1705.04293" target="_blank">arXiv:1705.04293</a> [<a href="http://arxiv.org/pdf/1705.04293" target="_blank">pdf</a>]

<h2>Learning to Seek: Autonomous Source Seeking with Deep Reinforcement Learning Onboard a Nano Drone Microcontroller. (arXiv:1909.11236v6 [cs.RO] UPDATED)</h2>
<h3>Bardienus P. Duisterhof, Srivatsan Krishnan, Jonathan J. Cruz, Colby R. Banbury, William Fu, Aleksandra Faust, Guido C. H. E. de Croon, Vijay Janapa Reddi</h3>
<p>We present fully autonomous source seeking onboard a highly constrained nano
quadcopter, by contributing application-specific system and observation feature
design to enable inference of a deep-RL policy onboard a nano quadcopter. Our
deep-RL algorithm finds a high-performance solution to a challenging problem,
even in presence of high noise levels and generalizes across real and
simulation environments with different obstacle configurations. We verify our
approach with simulation and in-field testing on a Bitcraze CrazyFlie using
only the cheap and ubiquitous Cortex-M4 microcontroller unit. The results show
that by end-to-end application-specific system design, our contribution
consumes almost three times less additional power, as compared to competing
learning-based navigation approach onboard a nano quadcopter. Thanks to our
observation space, which we carefully design within the resource constraints,
our solution achieves a 94% success rate in cluttered and randomized test
environments, as compared to the previously achieved 80%. We also compare our
strategy to a simple finite state machine (FSM), geared towards efficient
exploration, and demonstrate that our policy is more robust and resilient at
obstacle avoidance as well as up to 70% more efficient in source seeking. To
this end, we contribute a cheap and lightweight end-to-end tiny robot learning
(tinyRL) solution, running onboard a nano quadcopter, that proves to be robust
and efficient in a challenging task using limited sensory input.
</p>
<a href="http://arxiv.org/abs/1909.11236" target="_blank">arXiv:1909.11236</a> [<a href="http://arxiv.org/pdf/1909.11236" target="_blank">pdf</a>]

<h2>Any-Precision Deep Neural Networks. (arXiv:1911.07346v2 [cs.LG] UPDATED)</h2>
<h3>Haichao Yu, Haoxiang Li, Honghui Shi, Thomas S. Huang, Gang Hua</h3>
<p>We present any-precision deep neural networks (DNNs), which are trained with
a new method that allows the learned DNNs to be flexible in numerical precision
during inference. The same model in runtime can be flexibly and directly set to
different bit-widths, by truncating the least significant bits, to support
dynamic speed and accuracy trade-off. When all layers are set to low-bits, we
show that the model achieved accuracy comparable to dedicated models trained at
the same precision. This nice property facilitates flexible deployment of deep
learning models in real-world applications, where in practice trade-offs
between model accuracy and runtime efficiency are often sought. Previous
literature presents solutions to train models at each individual fixed
efficiency/accuracy trade-off point. But how to produce a model flexible in
runtime precision is largely unexplored. When the demand of efficiency/accuracy
trade-off varies from time to time or even dynamically changes in runtime, it
is infeasible to re-train models accordingly, and the storage budget may forbid
keeping multiple models. Our proposed framework achieves this flexibility
without performance degradation. More importantly, we demonstrate that this
achievement is agnostic to model architectures and applicable to multiple
vision tasks. Our code is released at
https://github.com/SHI-Labs/Any-Precision-DNNs.
</p>
<a href="http://arxiv.org/abs/1911.07346" target="_blank">arXiv:1911.07346</a> [<a href="http://arxiv.org/pdf/1911.07346" target="_blank">pdf</a>]

<h2>On-manifold Adversarial Data Augmentation Improves Uncertainty Calibration. (arXiv:1912.07458v5 [cs.LG] UPDATED)</h2>
<h3>Kanil Patel, William Beluch, Dan Zhang, Michael Pfeiffer, Bin Yang</h3>
<p>Uncertainty estimates help to identify ambiguous, novel, or anomalous inputs,
but the reliable quantification of uncertainty has proven to be challenging for
modern deep networks. In order to improve uncertainty estimation, we propose
On-Manifold Adversarial Data Augmentation or OMADA, which specifically attempts
to generate the most challenging examples by following an on-manifold
adversarial attack path in the latent space of an autoencoder-based generative
model that closely approximates decision boundaries between two or more
classes. On a variety of datasets as well as on multiple diverse network
architectures, OMADA consistently yields more accurate and better calibrated
classifiers than baseline models, and outperforms competing approaches such as
Mixup, as well as achieving similar performance to (at times better than)
post-processing calibration methods such as temperature scaling. Variants of
OMADA can employ different sampling schemes for ambiguous on-manifold examples
based on the entropy of their estimated soft labels, which exhibit specific
strengths for generalization, calibration of predicted uncertainty, or
detection of out-of-distribution inputs.
</p>
<a href="http://arxiv.org/abs/1912.07458" target="_blank">arXiv:1912.07458</a> [<a href="http://arxiv.org/pdf/1912.07458" target="_blank">pdf</a>]

<h2>Brainstorming Generative Adversarial Networks (BGANs): Towards Multi-Agent Generative Models with Distributed Private Datasets. (arXiv:2002.00306v2 [cs.LG] UPDATED)</h2>
<h3>Aidin Ferdowsi, Walid Saad</h3>
<p>To achieve a high learning accuracy, generative adversarial networks (GANs)
must be fed by large datasets that adequately represent the data space.
However, in many scenarios, the available datasets may be limited and
distributed across multiple agents, each of which is seeking to learn the
distribution of the data on its own. In such scenarios, the local datasets are
inherently private and agents often do not wish to share them. In this paper,
to address this multi-agent GAN problem, a novel brainstorming GAN (BGAN)
architecture is proposed using which multiple agents can generate real-like
data samples while operating in a fully distributed manner and preserving their
data privacy. BGAN allows the agents to gain information from other agents
without sharing their real datasets but by "brainstorming" via the sharing of
their generated data samples. In contrast to existing distributed GAN
solutions, the proposed BGAN architecture is designed to be fully distributed,
and it does not need any centralized controller. Moreover, BGANs are shown to
be scalable and not dependent on the hyperparameters of the agents' deep neural
networks (DNNs) thus enabling the agents to have different DNN architectures.
Theoretically, the interactions between BGAN agents are analyzed as a game
whose unique Nash equilibrium is derived. Experimental results show that BGAN
can generate real-like data samples with higher quality and lower
Jensen-Shannon divergence (JSD) and Fr\'echet Inception distance (FID) compared
to other distributed GAN architectures.
</p>
<a href="http://arxiv.org/abs/2002.00306" target="_blank">arXiv:2002.00306</a> [<a href="http://arxiv.org/pdf/2002.00306" target="_blank">pdf</a>]

<h2>A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient Descent Exponentially Favors Flat Minima. (arXiv:2002.03495v14 [cs.LG] UPDATED)</h2>
<h3>Zeke Xie, Issei Sato, Masashi Sugiyama</h3>
<p>Stochastic Gradient Descent (SGD) and its variants are mainstream methods for
training deep networks in practice. SGD is known to find a flat minimum that
often generalizes well. However, it is mathematically unclear how deep learning
can select a flat minimum among so many minima. To answer the question
quantitatively, we develop a density diffusion theory (DDT) to reveal how
minima selection quantitatively depends on the minima sharpness and the
hyperparameters. To the best of our knowledge, we are the first to
theoretically and empirically prove that, benefited from the Hessian-dependent
covariance of stochastic gradient noise, SGD favors flat minima exponentially
more than sharp minima, while Gradient Descent (GD) with injected white noise
favors flat minima only polynomially more than sharp minima. We also reveal
that either a small learning rate or large-batch training requires
exponentially many iterations to escape from minima in terms of the ratio of
the batch size and learning rate. Thus, large-batch training cannot search flat
minima efficiently in a realistic computational time.
</p>
<a href="http://arxiv.org/abs/2002.03495" target="_blank">arXiv:2002.03495</a> [<a href="http://arxiv.org/pdf/2002.03495" target="_blank">pdf</a>]

<h2>Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows. (arXiv:2002.06103v3 [cs.LG] UPDATED)</h2>
<h3>Kashif Rasul, Abdul-Saboor Sheikh, Ingmar Schuster, Urs Bergmann, Roland Vollgraf</h3>
<p>Time series forecasting is often fundamental to scientific and engineering
problems and enables decision making. With ever increasing data set sizes, a
trivial solution to scale up predictions is to assume independence between
interacting time series. However, modeling statistical dependencies can improve
accuracy and enable analysis of interaction effects. Deep learning methods are
well suited for this problem, but multivariate models often assume a simple
parametric distribution and do not scale to high dimensions. In this work we
model the multivariate temporal dynamics of time series via an autoregressive
deep learning model, where the data distribution is represented by a
conditioned normalizing flow. This combination retains the power of
autoregressive models, such as good performance in extrapolation into the
future, with the flexibility of flows as a general purpose high-dimensional
distribution model, while remaining computationally tractable. We show that it
improves over the state-of-the-art for standard metrics on many real-world data
sets with several thousand interacting time-series.
</p>
<a href="http://arxiv.org/abs/2002.06103" target="_blank">arXiv:2002.06103</a> [<a href="http://arxiv.org/pdf/2002.06103" target="_blank">pdf</a>]

<h2>Distance-Based Regularisation of Deep Networks for Fine-Tuning. (arXiv:2002.08253v3 [stat.ML] UPDATED)</h2>
<h3>Henry Gouk, Timothy M. Hospedales, Massimiliano Pontil</h3>
<p>We investigate approaches to regularisation during fine-tuning of deep neural
networks. First we provide a neural network generalisation bound based on
Rademacher complexity that uses the distance the weights have moved from their
initial values. This bound has no direct dependence on the number of weights
and compares favourably to other bounds when applied to convolutional networks.
Our bound is highly relevant for fine-tuning, because providing a network with
a good initialisation based on transfer learning means that learning can modify
the weights less, and hence achieve tighter generalisation. Inspired by this,
we develop a simple yet effective fine-tuning algorithm that constrains the
hypothesis class to a small sphere centred on the initial pre-trained weights,
thus obtaining provably better generalisation performance than conventional
transfer learning. Empirical evaluation shows that our algorithm works well,
corroborating our theoretical results. It outperforms both state of the art
fine-tuning competitors, and penalty-based alternatives that we show do not
directly constrain the radius of the search space.
</p>
<a href="http://arxiv.org/abs/2002.08253" target="_blank">arXiv:2002.08253</a> [<a href="http://arxiv.org/pdf/2002.08253" target="_blank">pdf</a>]

<h2>Residual Shuffle-Exchange Networks for Fast Processing of Long Sequences. (arXiv:2004.04662v4 [cs.LG] UPDATED)</h2>
<h3>Andis Draguns, Em&#x12b;ls Ozoli&#x146;&#x161;, Agris &#x160;ostaks, Mat&#x12b;ss Apinis, K&#x101;rlis Freivalds</h3>
<p>Attention is a commonly used mechanism in sequence processing, but it is of
O(n^2) complexity which prevents its application to long sequences. The
recently introduced neural Shuffle-Exchange network offers a
computation-efficient alternative, enabling the modelling of long-range
dependencies in O(n log n) time. The model, however, is quite complex,
involving a sophisticated gating mechanism derived from the Gated Recurrent
Unit. In this paper, we present a simple and lightweight variant of the
Shuffle-Exchange network, which is based on a residual network employing GELU
and Layer Normalization. The proposed architecture not only scales to longer
sequences but also converges faster and provides better accuracy. It surpasses
the Shuffle-Exchange network on the LAMBADA language modelling task and
achieves state-of-the-art performance on the MusicNet dataset for music
transcription while being efficient in the number of parameters. We show how to
combine the improved Shuffle-Exchange network with convolutional layers,
establishing it as a useful building block in long sequence processing
applications.
</p>
<a href="http://arxiv.org/abs/2004.04662" target="_blank">arXiv:2004.04662</a> [<a href="http://arxiv.org/pdf/2004.04662" target="_blank">pdf</a>]

<h2>Luring of transferable adversarial perturbations in the black-box paradigm. (arXiv:2004.04919v2 [cs.LG] UPDATED)</h2>
<h3>R&#xe9;mi Bernhard, Pierre-Alain Moellic, Jean-Max Dutertre</h3>
<p>The growing interest for adversarial examples, i.e. maliciously modified
examples which fool a classifier, has resulted in many defenses intended to
detect them, render them inoffensive or make the model more robust against
them. In this paper, we pave the way towards a new approach to improve the
robustness of a model against black-box transfer attacks. A removable
additional neural network is included in the target model, and is designed to
induce the \textit{luring effect}, which tricks the adversary into choosing
false directions to fool the target model. Training the additional model is
achieved thanks to a loss function acting on the logits sequence order. Our
deception-based method only needs to have access to the predictions of the
target model and does not require a labeled data set. We explain the luring
effect thanks to the notion of robust and non-robust useful features and
perform experiments on MNIST, SVHN and CIFAR10 to characterize and evaluate
this phenomenon. Additionally, we discuss two simple prediction schemes, and
verify experimentally that our approach can be used as a defense to efficiently
thwart an adversary using state-of-the-art attacks and allowed to perform large
perturbations.
</p>
<a href="http://arxiv.org/abs/2004.04919" target="_blank">arXiv:2004.04919</a> [<a href="http://arxiv.org/pdf/2004.04919" target="_blank">pdf</a>]

<h2>A novel embedded min-max approach for feature selection in nonlinear support vector machine classification. (arXiv:2004.09863v4 [cs.LG] UPDATED)</h2>
<h3>Asunci&#xf3;n Jim&#xe9;nez-Cordero, Juan Miguel Morales, Salvador Pineda</h3>
<p>In recent years, feature selection has become a challenging problem in
several machine learning fields, such as classification problems. Support
Vector Machine (SVM) is a well-known technique applied in classification tasks.
Various methodologies have been proposed in the literature to select the most
relevant features in SVM. Unfortunately, all of them either deal with the
feature selection problem in the linear classification setting or propose
ad-hoc approaches that are difficult to implement in practice. In contrast, we
propose an embedded feature selection method based on a min-max optimization
problem, where a trade-off between model complexity and classification accuracy
is sought. By leveraging duality theory, we equivalently reformulate the
min-max problem and solve it without further ado using off-the-shelf software
for nonlinear optimization. The efficiency and usefulness of our approach are
tested on several benchmark data sets in terms of accuracy, number of selected
features and interpretability.
</p>
<a href="http://arxiv.org/abs/2004.09863" target="_blank">arXiv:2004.09863</a> [<a href="http://arxiv.org/pdf/2004.09863" target="_blank">pdf</a>]

<h2>Filter Grafting for Deep Neural Networks: Reason, Method, and Cultivation. (arXiv:2004.12311v2 [cs.LG] UPDATED)</h2>
<h3>Hao Cheng, Fanxu Meng, Ke Li, Yuting Gao, Guangming Lu, Xing Sun, Rongrong Ji</h3>
<p>Filter is the key component in modern convolutional neural networks (CNNs).
However, since CNNs are usually over-parameterized, a pre-trained network
always contain some invalid (unimportant) filters. These filters have
relatively small $l_{1}$ norm and contribute little to the output
(\textbf{Reason}). While filter pruning removes these invalid filters for
efficiency consideration, we tend to reactivate them to improve the
representation capability of CNNs. In this paper, we introduce filter grafting
(\textbf{Method}) to achieve this goal. The activation is processed by grafting
external information (weights) into invalid filters. To better perform the
grafting, we develop a novel criterion to measure the information of filters
and an adaptive weighting strategy to balance the grafted information among
networks. After the grafting operation, the network has fewer invalid filters
compared with its initial state, enpowering the model with more representation
capacity. Meanwhile, since grafting is operated reciprocally on all networks
involved, we find that grafting may lose the information of valid filters when
improving invalid filters. To gain a universal improvement on both valid and
invalid filters, we compensate grafting with distillation
(\textbf{Cultivation}) to overcome the drawback of grafting . Extensive
experiments are performed on the classification and recognition tasks to show
the superiority of our method. Code is available at
\textcolor{black}{\emph{https://github.com/fxmeng/filter-grafting}}.
</p>
<a href="http://arxiv.org/abs/2004.12311" target="_blank">arXiv:2004.12311</a> [<a href="http://arxiv.org/pdf/2004.12311" target="_blank">pdf</a>]

<h2>Neural Computing for Online Arabic Handwriting Character Recognition using Hard Stroke Features Mining. (arXiv:2005.02171v3 [cs.CV] UPDATED)</h2>
<h3>Amjad Rehman (PSU and UTM)</h3>
<p>Online Arabic cursive character recognition is still a big challenge due to
the existing complexities including Arabic cursive script styles, writing
speed, writer mood and so forth. Due to these unavoidable constraints, the
accuracy of online Arabic character's recognition is still low and retain space
for improvement. In this research, an enhanced method of detecting the desired
critical points from vertical and horizontal direction-length of handwriting
stroke features of online Arabic script recognition is proposed. Each extracted
stroke feature divides every isolated character into some meaningful pattern
known as tokens. A minimum feature set is extracted from these tokens for
classification of characters using a multilayer perceptron with a
back-propagation learning algorithm and modified sigmoid function-based
activation function. In this work, two milestones are achieved; firstly, attain
a fixed number of tokens, secondly, minimize the number of the most repetitive
tokens. For experiments, handwritten Arabic characters are selected from the
OHASD benchmark dataset to test and evaluate the proposed method. The proposed
method achieves an average accuracy of 98.6% comparable in state of art
character recognition techniques.
</p>
<a href="http://arxiv.org/abs/2005.02171" target="_blank">arXiv:2005.02171</a> [<a href="http://arxiv.org/pdf/2005.02171" target="_blank">pdf</a>]

<h2>Information-Theoretic Generalization Bounds for Meta-Learning and Applications. (arXiv:2005.04372v4 [cs.LG] UPDATED)</h2>
<h3>Sharu Theresa Jose, Osvaldo Simeone</h3>
<p>Meta-learning, or "learning to learn", refers to techniques that infer an
inductive bias from data corresponding to multiple related tasks with the goal
of improving the sample efficiency for new, previously unobserved, tasks. A key
performance measure for meta-learning is the meta-generalization gap, that is,
the difference between the average loss measured on the meta-training data and
on a new, randomly selected task. This paper presents novel
information-theoretic upper bounds on the meta-generalization gap. Two broad
classes of meta-learning algorithms are considered that uses either separate
within-task training and test sets, like MAML, or joint within-task training
and test sets, like Reptile. Extending the existing work for conventional
learning, an upper bound on the meta-generalization gap is derived for the
former class that depends on the mutual information (MI) between the output of
the meta-learning algorithm and its input meta-training data. For the latter,
the derived bound includes an additional MI between the output of the per-task
learning procedure and corresponding data set to capture within-task
uncertainty. Tighter bounds are then developed, under given technical
conditions, for the two classes via novel Individual Task MI (ITMI) bounds.
Applications of the derived bounds are finally discussed, including a broad
class of noisy iterative algorithms for meta-learning.
</p>
<a href="http://arxiv.org/abs/2005.04372" target="_blank">arXiv:2005.04372</a> [<a href="http://arxiv.org/pdf/2005.04372" target="_blank">pdf</a>]

<h2>Locally Differentially Private (Contextual) Bandits Learning. (arXiv:2006.00701v4 [cs.LG] UPDATED)</h2>
<h3>Kai Zheng, Tianle Cai, Weiran Huang, Zhenguo Li, Liwei Wang</h3>
<p>We study locally differentially private (LDP) bandits learning in this paper.
First, we propose simple black-box reduction frameworks that can solve a large
family of context-free bandits learning problems with LDP guarantee. Based on
our frameworks, we can improve previous best results for private bandits
learning with one-point feedback, such as private Bandits Convex Optimization,
and obtain the first result for Bandits Convex Optimization (BCO) with
multi-point feedback under LDP. LDP guarantee and black-box nature make our
frameworks more attractive in real applications compared with previous
specifically designed and relatively weaker differentially private (DP)
context-free bandits algorithms. Further, we extend our $(\varepsilon,
\delta)$-LDP algorithm to Generalized Linear Bandits, which enjoys a sub-linear
regret $\tilde{O}(T^{3/4}/\varepsilon)$ and is conjectured to be nearly
optimal. Note that given the existing $\Omega(T)$ lower bound for DP contextual
linear bandits (Shariff &amp; Sheffe, 2018), our result shows a fundamental
difference between LDP and DP contextual bandits learning.
</p>
<a href="http://arxiv.org/abs/2006.00701" target="_blank">arXiv:2006.00701</a> [<a href="http://arxiv.org/pdf/2006.00701" target="_blank">pdf</a>]

<h2>Hidden Markov models as recurrent neural networks: An application to Alzheimer's disease. (arXiv:2006.03151v2 [stat.ML] UPDATED)</h2>
<h3>Matt Baucum, Anahita Khojandi, Theodore Papamarkou</h3>
<p>Hidden Markov models (HMMs) are commonly used for disease progression
modeling when the true patient health state is not fully known. Since HMMs may
have multiple local optima, performance can be improved by incorporating
additional patient covariates to inform estimation. To allow for this, we
develop hidden Markov recurrent neural networks (HMRNNs), a special case of
recurrent neural networks with the same likelihood function as a corresponding
discrete-observation HMM. The HMRNN can be combined with any other predictive
neural networks that take patient information as input, with all parameters
estimated simultaneously via gradient descent. Using a dataset of Alzheimer's
disease patients, we demonstrate how combining the HMRNN with other predictive
neural networks improves disease forecasting performance and offers a novel
clinical interpretation compared with a standard HMM trained via
expectation-maximization.
</p>
<a href="http://arxiv.org/abs/2006.03151" target="_blank">arXiv:2006.03151</a> [<a href="http://arxiv.org/pdf/2006.03151" target="_blank">pdf</a>]

<h2>Variational Auto-Encoder for Recommender Systems with Exploration-Exploitation. (arXiv:2006.03573v3 [stat.ML] UPDATED)</h2>
<h3>Yizi Zhang, Hongxia Yang, Meimei Liu</h3>
<p>Recent years have witnessed rapid developments on collaborative filtering
techniques for improving the performance of recommender systems due to the
growing need of companies to help users discover new and relevant items.
However, the majority of existing literature focuses on delivering items which
match the user model learned from users' past preferences. A good
recommendation model is expected to recommend items that are known to enjoy and
items that are novel to try. In this work, we introduce an
exploitation-exploration motivated variational auto-encoder (XploVAE) to
collaborative filtering. To facilitate personalized recommendations, we
construct user-specific subgraphs, which contain first-order proximity
capturing observed user-item interactions for exploitation and higher-order
proximity for exploration. A hierarchical latent space model is utilized to
learn the personalized item embedding for a given user, along with the
population distribution of all user subgraphs. Finally, experimental results on
various real-world datasets clearly demonstrate the effectiveness of our
proposed model on leveraging the exploitation and exploration recommendation
tasks.
</p>
<a href="http://arxiv.org/abs/2006.03573" target="_blank">arXiv:2006.03573</a> [<a href="http://arxiv.org/pdf/2006.03573" target="_blank">pdf</a>]

<h2>Parameter-based Value Functions. (arXiv:2006.09226v3 [cs.LG] UPDATED)</h2>
<h3>Francesco Faccio, Louis Kirsch, J&#xfc;rgen Schmidhuber</h3>
<p>Traditional off-policy actor-critic Reinforcement Learning (RL) algorithms
learn value functions of a single target policy. However, when value functions
are updated to track the learned policy, they forget potentially useful
information about old policies. We introduce a class of value functions called
Parameter-based Value Functions (PVFs) whose inputs include the policy
parameters. They can generalize across different policies. PVFs can evaluate
the performance of any policy given a state, a state-action pair, or a
distribution over the RL agent's initial states. First we show how PVFs yield
novel off-policy policy gradient theorems. Then we derive off-policy
actor-critic algorithms based on PVFs trained by Monte Carlo or Temporal
Difference methods. We show how learned PVFs can zero-shot learn new policies
that outperform any policy seen during training. Finally our algorithms are
evaluated on a selection of discrete and continuous control tasks using shallow
policies and deep neural networks. Their performance is comparable to
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2006.09226" target="_blank">arXiv:2006.09226</a> [<a href="http://arxiv.org/pdf/2006.09226" target="_blank">pdf</a>]

<h2>Evaluating Prediction-Time Batch Normalization for Robustness under Covariate Shift. (arXiv:2006.10963v3 [cs.LG] UPDATED)</h2>
<h3>Zachary Nado, Shreyas Padhy, D. Sculley, Alexander D&#x27;Amour, Balaji Lakshminarayanan, Jasper Snoek</h3>
<p>Covariate shift has been shown to sharply degrade both predictive accuracy
and the calibration of uncertainty estimates for deep learning models. This is
worrying, because covariate shift is prevalent in a wide range of real world
deployment settings. However, in this paper, we note that frequently there
exists the potential to access small unlabeled batches of the shifted data just
before prediction time. This interesting observation enables a simple but
surprisingly effective method which we call prediction-time batch
normalization, which significantly improves model accuracy and calibration
under covariate shift. Using this one line code change, we achieve
state-of-the-art on recent covariate shift benchmarks and an mCE of 60.28\% on
the challenging ImageNet-C dataset; to our knowledge, this is the best result
for any model that does not incorporate additional data augmentation or
modification of the training pipeline. We show that prediction-time batch
normalization provides complementary benefits to existing state-of-the-art
approaches for improving robustness (e.g. deep ensembles) and combining the two
further improves performance. Our findings are supported by detailed
measurements of the effect of this strategy on model behavior across rigorous
ablations on various dataset modalities. However, the method has mixed results
when used alongside pre-training, and does not seem to perform as well under
more natural types of dataset shift, and is therefore worthy of additional
study. We include links to the data in our figures to improve reproducibility,
including a Python notebooks that can be run to easily modify our analysis at
https://colab.research.google.com/drive/11N0wDZnMQQuLrRwRoumDCrhSaIhkqjof.
</p>
<a href="http://arxiv.org/abs/2006.10963" target="_blank">arXiv:2006.10963</a> [<a href="http://arxiv.org/pdf/2006.10963" target="_blank">pdf</a>]

<h2>Multi-Class Uncertainty Calibration via Mutual Information Maximization-based Binning. (arXiv:2006.13092v5 [cs.LG] UPDATED)</h2>
<h3>Kanil Patel, William Beluch, Bin Yang, Michael Pfeiffer, Dan Zhang</h3>
<p>Post-hoc multi-class calibration is a common approach for providing
high-quality confidence estimates of deep neural network predictions. Recent
work has shown that widely used scaling methods underestimate their calibration
error, while alternative Histogram Binning (HB) methods often fail to preserve
classification accuracy. When classes have small prior probabilities, HB also
faces the issue of severe sample-inefficiency after the conversion into K
one-vs-rest class-wise calibration problems. The goal of this paper is to
resolve the identified issues of HB in order to provide calibrated confidence
estimates using only a small holdout calibration dataset for bin optimization
while preserving multi-class ranking accuracy. From an information-theoretic
perspective, we derive the I-Max concept for binning, which maximizes the
mutual information between labels and quantized logits. This concept mitigates
potential loss in ranking performance due to lossy quantization, and by
disentangling the optimization of bin edges and representatives allows
simultaneous improvement of ranking and calibration performance. To improve the
sample efficiency and estimates from a small calibration set, we propose a
shared class-wise (sCW) calibration strategy, sharing one calibrator among
similar classes (e.g., with similar class priors) so that the training sets of
their class-wise calibration problems can be merged to train the single
calibrator. The combination of sCW and I-Max binning outperforms the state of
the art calibration methods on various evaluation metrics across different
benchmark datasets and models, using a small calibration set (e.g., 1k samples
for ImageNet).
</p>
<a href="http://arxiv.org/abs/2006.13092" target="_blank">arXiv:2006.13092</a> [<a href="http://arxiv.org/pdf/2006.13092" target="_blank">pdf</a>]

<h2>Rescaling Egocentric Vision. (arXiv:2006.13256v2 [cs.CV] UPDATED)</h2>
<h3>Dima Damen, Hazel Doughty, Giovanni Maria Farinella, Antonino Furnari, Evangelos Kazakos, Jian Ma, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, Michael Wray</h3>
<p>This paper introduces the pipeline to scale the largest dataset in egocentric
vision EPIC-KITCHENS. The effort culminates in EPIC-KITCHENS-100, a collection
of 100~hours, 20M frames, 90K actions in 700 variable-length videos, capturing
long-term unscripted activities in 45 environments, using head-mounted cameras.
Compared to its previous version, EPIC-KITCHENS-100 has been annotated using a
novel pipeline that allows denser (54\% more actions per minute) and more
complete annotations of fine-grained actions (+128\% more action segments).
This collection also enables evaluating the "test of time" - i.e. whether
models trained on data collected in 2018 can generalise to new footage
collected under the same hypotheses albeit "two years on".

The dataset is aligned with 6 challenges: action recognition (full and weak
supervision), action detection, action anticipation, cross-modal retrieval
(from captions), as well as unsupervised domain adaptation for action
recognition. For each challenge, we define the task, provide baselines and
evaluation metrics.
</p>
<a href="http://arxiv.org/abs/2006.13256" target="_blank">arXiv:2006.13256</a> [<a href="http://arxiv.org/pdf/2006.13256" target="_blank">pdf</a>]

<h2>Learning Potentials of Quantum Systems using Deep Neural Networks. (arXiv:2006.13297v3 [cs.LG] UPDATED)</h2>
<h3>Arijit Sehanobish, Hector H. Corzo, Onur Kara, David van Dijk</h3>
<p>Attempts to apply Neural Networks (NN) to a wide range of research problems
have been ubiquitous and plentiful in recent literature. Particularly, the use
of deep NNs for understanding complex physical and chemical phenomena has
opened a new niche of science where the analysis tools from Machine Learning
(ML) are combined with the computational concepts of the natural sciences.
Reports from this unification of ML have presented evidence that NNs can learn
classical Hamiltonian mechanics. This application of NNs to classical physics
and its results motivate the following question: Can NNs be endowed with
inductive biases through observation as means to provide insights into quantum
phenomena? In this work, this question is addressed by investigating possible
approximations for reconstructing the Hamiltonian of a quantum system in an
unsupervised manner by using only limited information obtained from the
system's probability distribution.
</p>
<a href="http://arxiv.org/abs/2006.13297" target="_blank">arXiv:2006.13297</a> [<a href="http://arxiv.org/pdf/2006.13297" target="_blank">pdf</a>]

<h2>Affinity Fusion Graph-based Framework for Natural Image Segmentation. (arXiv:2006.13542v3 [cs.CV] UPDATED)</h2>
<h3>Yang Zhang, Moyun Liu, Jingwu He, Fei Pan, Yanwen Guo</h3>
<p>This paper proposes an affinity fusion graph framework to effectively connect
different graphs with highly discriminating power and nonlinearity for natural
image segmentation. The proposed framework combines adjacency-graphs and kernel
spectral clustering based graphs (KSC-graphs) according to a new definition
named affinity nodes of multi-scale superpixels. These affinity nodes are
selected based on a better affiliation of superpixels, namely
subspace-preserving representation which is generated by sparse subspace
clustering based on subspace pursuit. Then a KSC-graph is built via a novel
kernel spectral clustering to explore the nonlinear relationships among these
affinity nodes. Moreover, an adjacency-graph at each scale is constructed,
which is further used to update the proposed KSC-graph at affinity nodes. The
fusion graph is built across different scales, and it is partitioned to obtain
final segmentation result. Experimental results on the Berkeley segmentation
dataset and Microsoft Research Cambridge dataset show the superiority of our
framework in comparison with the state-of-the-art methods. The code is
available at https://github.com/Yangzhangcst/AF-graph.
</p>
<a href="http://arxiv.org/abs/2006.13542" target="_blank">arXiv:2006.13542</a> [<a href="http://arxiv.org/pdf/2006.13542" target="_blank">pdf</a>]

<h2>Interpretable and Trustworthy Deepfake Detection via Dynamic Prototypes. (arXiv:2006.15473v2 [cs.CV] UPDATED)</h2>
<h3>Loc Trinh, Michael Tsang, Sirisha Rambhatla, Yan Liu</h3>
<p>In this paper we propose a novel human-centered approach for detecting
forgery in face images, using dynamic prototypes as a form of visual
explanations. Currently, most state-of-the-art deepfake detections are based on
black-box models that process videos frame-by-frame for inference, and few
closely examine their temporal inconsistencies. However, the existence of such
temporal artifacts within deepfake videos is key in detecting and explaining
deepfakes to a supervising human. To this end, we propose Dynamic Prototype
Network (DPNet) -- an interpretable and effective solution that utilizes
dynamic representations (i.e., prototypes) to explain deepfake temporal
artifacts. Extensive experimental results show that DPNet achieves competitive
predictive performance, even on unseen testing datasets such as Google's
DeepFakeDetection, DeeperForensics, and Celeb-DF, while providing easy
referential explanations of deepfake dynamics. On top of DPNet's prototypical
framework, we further formulate temporal logic specifications based on these
dynamics to check our model's compliance to desired temporal behaviors, hence
providing trustworthiness for such critical detection systems.
</p>
<a href="http://arxiv.org/abs/2006.15473" target="_blank">arXiv:2006.15473</a> [<a href="http://arxiv.org/pdf/2006.15473" target="_blank">pdf</a>]

<h2>VINNAS: Variational Inference-based Neural Network Architecture Search. (arXiv:2007.06103v5 [cs.LG] UPDATED)</h2>
<h3>Martin Ferianc, Hongxiang Fan, Miguel Rodrigues</h3>
<p>In recent years, neural architecture search (NAS) has received intensive
scientific and industrial interest due to its capability of finding a neural
architecture with high accuracy for various artificial intelligence tasks such
as image classification or object detection. In particular, gradient-based NAS
approaches have become one of the more popular approaches thanks to their
computational efficiency during the search. However, these methods often
experience a mode collapse, where the quality of the found architectures is
poor due to the algorithm resorting to choosing a single operation type for the
entire network, or stagnating at a local minima for various datasets or search
spaces.

To address these defects, we present a differentiable variational
inference-based NAS method for searching sparse convolutional neural networks.
Our approach finds the optimal neural architecture by dropping out candidate
operations in an over-parameterised supergraph using variational dropout with
automatic relevance determination prior, which makes the algorithm gradually
remove unnecessary operations and connections without risking mode collapse.
The evaluation is conducted through searching two types of convolutional cells
that shape the neural network for classifying different image datasets. Our
method finds diverse network cells, while showing state-of-the-art accuracy
with up to almost 2 times fewer non-zero parameters.
</p>
<a href="http://arxiv.org/abs/2007.06103" target="_blank">arXiv:2007.06103</a> [<a href="http://arxiv.org/pdf/2007.06103" target="_blank">pdf</a>]

<h2>Semi-supervised deep learning based on label propagation in a 2D embedded space. (arXiv:2008.00558v2 [cs.CV] UPDATED)</h2>
<h3>Barbara Caroline Benato, Jancarlo Ferreira Gomes, Alexandru Cristian Telea, Alexandre Xavier Falc&#xe3;o</h3>
<p>While convolutional neural networks need large labeled sets for training
images, expert human supervision of such datasets can be very laborious.
Proposed solutions propagate labels from a small set of supervised images to a
large set of unsupervised ones to obtain sufficient truly-and-artificially
labeled samples to train a deep neural network model. Yet, such solutions need
many supervised images for validation. We present a loop in which a deep neural
network (VGG-16) is trained from a set with more correctly labeled samples
along iterations, created by using t-SNE to project the features of its last
max-pooling layer into a 2D embedded space in which labels are propagated using
the Optimum-Path Forest semi-supervised classifier. As the labeled set improves
along iterations, it improves the features of the neural network. We show that
this can significantly improve classification results on test data (using only
1\% to 5\% of supervised samples) of three private challenging datasets and two
public ones.
</p>
<a href="http://arxiv.org/abs/2008.00558" target="_blank">arXiv:2008.00558</a> [<a href="http://arxiv.org/pdf/2008.00558" target="_blank">pdf</a>]

<h2>Graph Convolutional Networks for Hyperspectral Image Classification. (arXiv:2008.02457v2 [cs.CV] UPDATED)</h2>
<h3>Danfeng Hong, Lianru Gao, Jing Yao, Bing Zhang, Antonio Plaza, Jocelyn Chanussot</h3>
<p>To read the final version please go to IEEE TGRS on IEEE Xplore.
Convolutional neural networks (CNNs) have been attracting increasing attention
in hyperspectral (HS) image classification, owing to their ability to capture
spatial-spectral feature representations. Nevertheless, their ability in
modeling relations between samples remains limited. Beyond the limitations of
grid sampling, graph convolutional networks (GCNs) have been recently proposed
and successfully applied in irregular (or non-grid) data representation and
analysis. In this paper, we thoroughly investigate CNNs and GCNs (qualitatively
and quantitatively) in terms of HS image classification. Due to the
construction of the adjacency matrix on all the data, traditional GCNs usually
suffer from a huge computational cost, particularly in large-scale remote
sensing (RS) problems. To this end, we develop a new mini-batch GCN (called
miniGCN hereinafter) which allows to train large-scale GCNs in a mini-batch
fashion. More significantly, our miniGCN is capable of inferring out-of-sample
data without re-training networks and improving classification performance.
Furthermore, as CNNs and GCNs can extract different types of HS features, an
intuitive solution to break the performance bottleneck of a single model is to
fuse them. Since miniGCNs can perform batch-wise network training (enabling the
combination of CNNs and GCNs) we explore three fusion strategies: additive
fusion, element-wise multiplicative fusion, and concatenation fusion to measure
the obtained performance gain. Extensive experiments, conducted on three HS
datasets, demonstrate the advantages of miniGCNs over GCNs and the superiority
of the tested fusion strategies with regards to the single CNN or GCN models.
The codes of this work will be available at
https://github.com/danfenghong/IEEE_TGRS_GCN for the sake of reproducibility.
</p>
<a href="http://arxiv.org/abs/2008.02457" target="_blank">arXiv:2008.02457</a> [<a href="http://arxiv.org/pdf/2008.02457" target="_blank">pdf</a>]

<h2>Neighbourhood-Insensitive Point Cloud Normal Estimation Network. (arXiv:2008.09965v3 [cs.CV] UPDATED)</h2>
<h3>Zirui Wang, Victor Adrian Prisacariu</h3>
<p>We introduce a novel self-attention-based normal estimation network that is
able to focus softly on relevant points and adjust the softness by learning a
temperature parameter, making it able to work naturally and effectively within
a large neighbourhood range. As a result, our model outperforms all existing
normal estimation algorithms by a large margin, achieving 94.1% accuracy in
comparison with the previous state of the art of 91.2%, with a 25x smaller
model and 12x faster inference time. We also use point-to-plane Iterative
Closest Point (ICP) as an application case to show that our normal estimations
lead to faster convergence than normal estimations from other methods, without
manually fine-tuning neighbourhood range parameters. Code available at
https://code.active.vision.
</p>
<a href="http://arxiv.org/abs/2008.09965" target="_blank">arXiv:2008.09965</a> [<a href="http://arxiv.org/pdf/2008.09965" target="_blank">pdf</a>]

<h2>Video Interpolation via Generalized Deformable Convolution. (arXiv:2008.10680v2 [cs.CV] UPDATED)</h2>
<h3>Zhihao Shi, Xiaohong Liu, Kangdi Shi, Linhui Dai, Jun Chen</h3>
<p>Video frame interpolation aims at synthesizing intermediate frames from
nearby source frames while maintaining spatial and temporal consistencies. The
existing deep-learning-based video frame interpolation methods can be roughly
divided into two categories: flow-based methods and kernel-based methods. The
performance of flow-based methods is often jeopardized by the inaccuracy of
flow map estimation due to oversimplified motion models, while that of
kernel-based methods tends to be constrained by the rigidity of kernel shape.
To address these performance-limiting issues, a novel mechanism named
generalized deformable convolution is proposed, which can effectively learn
motion information in a data-driven manner and freely select sampling points in
space-time. We further develop a new video frame interpolation method based on
this mechanism. Our extensive experiments demonstrate that the new method
performs favorably against the state-of-the-art, especially when dealing with
complex motions.
</p>
<a href="http://arxiv.org/abs/2008.10680" target="_blank">arXiv:2008.10680</a> [<a href="http://arxiv.org/pdf/2008.10680" target="_blank">pdf</a>]

<h2>What is being transferred in transfer learning?. (arXiv:2008.11687v2 [cs.LG] UPDATED)</h2>
<h3>Behnam Neyshabur, Hanie Sedghi, Chiyuan Zhang</h3>
<p>One desired capability for machines is the ability to transfer their
knowledge of one domain to another where data is (usually) scarce. Despite
ample adaptation of transfer learning in various deep learning applications, we
yet do not understand what enables a successful transfer and which part of the
network is responsible for that. In this paper, we provide new tools and
analyses to address these fundamental questions. Through a series of analyses
on transferring to block-shuffled images, we separate the effect of feature
reuse from learning low-level statistics of data and show that some benefit of
transfer learning comes from the latter. We present that when training from
pre-trained weights, the model stays in the same basin in the loss landscape
and different instances of such model are similar in feature space and close in
parameter space.
</p>
<a href="http://arxiv.org/abs/2008.11687" target="_blank">arXiv:2008.11687</a> [<a href="http://arxiv.org/pdf/2008.11687" target="_blank">pdf</a>]

<h2>DARTS-: Robustly Stepping out of Performance Collapse Without Indicators. (arXiv:2009.01027v2 [cs.LG] UPDATED)</h2>
<h3>Xiangxiang Chu, Xiaoxing Wang, Bo Zhang, Shun Lu, Xiaolin Wei, Junchi Yan</h3>
<p>Despite the fast development of differentiable architecture search (DARTS),
it suffers from long-standing performance instability, which extremely limits
its application. Existing robustifying methods draw clues from the resulting
deteriorated behavior instead of finding out its causing factor. Various
indicators such as Hessian eigenvalues are proposed as a signal to stop
searching before the performance collapses. However, these indicator-based
methods tend to easily reject good architectures if the thresholds are
inappropriately set, let alone the searching is intrinsically noisy. In this
paper, we undertake a more subtle and direct approach to resolve the collapse.
We first demonstrate that skip connections have a clear advantage over other
candidate operations, where it can easily recover from a disadvantageous state
and become dominant. We conjecture that this privilege is causing degenerated
performance. Therefore, we propose to factor out this benefit with an auxiliary
skip connection, ensuring a fairer competition for all operations. We call this
approach DARTS-. Extensive experiments on various datasets verify that it can
substantially improve robustness. Our code is available at
https://github.com/Meituan-AutoML/DARTS- .
</p>
<a href="http://arxiv.org/abs/2009.01027" target="_blank">arXiv:2009.01027</a> [<a href="http://arxiv.org/pdf/2009.01027" target="_blank">pdf</a>]

<h2>Kernel-based parameter estimation of dynamical systems with unknown observation functions. (arXiv:2009.04142v2 [stat.ML] UPDATED)</h2>
<h3>Ofir Lindenbaum, Amir Sagiv, Gal Mishne, Ronen Talmon</h3>
<p>A low-dimensional dynamical system is observed in an experiment as a
high-dimensional signal; For example, a video of a chaotic pendulums system.
Assuming that we know the dynamical model up to some unknown parameters, can we
estimate the underlying system's parameters by measuring its time-evolution
only once? The key information for performing this estimation lies in the
temporal inter-dependencies between the signal and the model. We propose a
kernel-based score to compare these dependencies. Our score generalizes a
maximum likelihood estimator for a linear model to a general nonlinear setting
in an unknown feature space. We estimate the system's underlying parameters by
maximizing the proposed score. We demonstrate the accuracy and efficiency of
the method using two chaotic dynamical systems - the double pendulum and the
Lorenz '63 model.
</p>
<a href="http://arxiv.org/abs/2009.04142" target="_blank">arXiv:2009.04142</a> [<a href="http://arxiv.org/pdf/2009.04142" target="_blank">pdf</a>]

<h2>High-Resolution Deep Image Matting. (arXiv:2009.06613v2 [cs.CV] UPDATED)</h2>
<h3>Haichao Yu, Ning Xu, Zilong Huang, Yuqian Zhou, Humphrey Shi</h3>
<p>Image matting is a key technique for image and video editing and composition.
Conventionally, deep learning approaches take the whole input image and an
associated trimap to infer the alpha matte using convolutional neural networks.
Such approaches set state-of-the-arts in image matting; however, they may fail
in real-world matting applications due to hardware limitations, since
real-world input images for matting are mostly of very high resolution. In this
paper, we propose HDMatt, a first deep learning based image matting approach
for high-resolution inputs. More concretely, HDMatt runs matting in a
patch-based crop-and-stitch manner for high-resolution inputs with a novel
module design to address the contextual dependency and consistency issues
between different patches. Compared with vanilla patch-based inference which
computes each patch independently, we explicitly model the cross-patch
contextual dependency with a newly-proposed Cross-Patch Contextual module (CPC)
guided by the given trimap. Extensive experiments demonstrate the effectiveness
of the proposed method and its necessity for high-resolution inputs. Our HDMatt
approach also sets new state-of-the-art performance on Adobe Image Matting and
AlphaMatting benchmarks and produce impressive visual results on more
real-world high-resolution images.
</p>
<a href="http://arxiv.org/abs/2009.06613" target="_blank">arXiv:2009.06613</a> [<a href="http://arxiv.org/pdf/2009.06613" target="_blank">pdf</a>]

<h2>Recurrent autoencoder with sequence-aware encoding. (arXiv:2009.07349v3 [cs.LG] UPDATED)</h2>
<h3>Robert Susik</h3>
<p>Recurrent Neural Networks (RNN) received a vast amount of attention last
decade. Recently, the architectures of Recurrent AutoEncoders (RAE) found many
applications in practice. RAE can extract the semantically valuable
information, called context that represents a latent space useful for further
processing. Nevertheless, recurrent autoencoders are hard to train, and the
training process takes much time. In this paper, we propose an autoencoder
architecture with sequence-aware encoding, which employs 1D convolutional layer
to improve its performance in terms of model training time. We prove that the
recurrent autoencoder with sequence-aware encoding outperforms a standard RAE
in terms of training speed in most cases. The preliminary results show that the
proposed solution dominates over the standard RAE, and the training process is
order of magnitude faster.
</p>
<a href="http://arxiv.org/abs/2009.07349" target="_blank">arXiv:2009.07349</a> [<a href="http://arxiv.org/pdf/2009.07349" target="_blank">pdf</a>]

<h2>Remote Electrical Tilt Optimization via Safe Reinforcement Learning. (arXiv:2010.05842v2 [cs.LG] UPDATED)</h2>
<h3>Filippo Vannella, Grigorios Iakovidis, Ezeddin Al Hakim, Erik Aumayr, Saman Feghhi</h3>
<p>Remote Electrical Tilt (RET) optimization is an efficient method for
adjusting the vertical tilt angle of Base Stations (BSs) antennas in order to
optimize Key Performance Indicators (KPIs) of the network. Reinforcement
Learning (RL) provides a powerful framework for RET optimization because of its
self-learning capabilities and adaptivity to environmental changes. However, an
RL agent may execute unsafe actions during the course of its interaction, i.e.,
actions resulting in undesired network performance degradation. Since the
reliability of services is critical for Mobile Network Operators (MNOs), the
prospect of performance degradation has prohibited the real-world deployment of
RL methods for RET optimization. In this work, we model the RET optimization
problem in the Safe Reinforcement Learning (SRL) framework with the goal of
learning a tilt control strategy providing performance improvement guarantees
with respect to a safe baseline. We leverage a recent SRL method, namely Safe
Policy Improvement through Baseline Bootstrapping (SPIBB), to learn an improved
policy from an offline dataset of interactions collected by the safe baseline.
Our experiments show that the proposed approach is able to learn a safe and
improved tilt update policy, providing a higher degree of reliability and
potential for real-world network deployment.
</p>
<a href="http://arxiv.org/abs/2010.05842" target="_blank">arXiv:2010.05842</a> [<a href="http://arxiv.org/pdf/2010.05842" target="_blank">pdf</a>]

<h2>Error-guided likelihood-free MCMC. (arXiv:2010.06735v2 [stat.ML] UPDATED)</h2>
<h3>Volodimir Begy, Erich Schikuta</h3>
<p>This work presents a novel posterior inference method for models with
intractable evidence and likelihood functions. Error-guided likelihood-free
MCMC, or EG-LF-MCMC in short, has been developed for scientific applications,
where a researcher is interested in obtaining approximate posterior densities
over model parameters, while avoiding the need for expensive training of
component estimators on full observational data or the tedious design of
expressive summary statistics, as in related approaches. Our technique is based
on two phases. In the first phase, we draw samples from the prior, simulate
respective observations and record their errors $\epsilon$ in relation to the
true observation. We train a classifier to distinguish between corresponding
and non-corresponding $(\epsilon, \boldsymbol{\theta})$-tuples. In the second
stage the said classifier is conditioned on the smallest recorded $\epsilon$
value from the training set and employed for the calculation of transition
probabilities in a Markov Chain Monte Carlo sampling procedure. By conditioning
the MCMC on specific $\epsilon$ values, our method may also be used in an
amortized fashion to infer posterior densities for observations, which are
located a given distance away from the observed data. We evaluate the proposed
method on benchmark problems with semantically and structurally different data
and compare its performance against the state of the art approximate Bayesian
computation (ABC).
</p>
<a href="http://arxiv.org/abs/2010.06735" target="_blank">arXiv:2010.06735</a> [<a href="http://arxiv.org/pdf/2010.06735" target="_blank">pdf</a>]

<h2>Direct Policy Optimization using Deterministic Sampling and Collocation. (arXiv:2010.08506v2 [cs.RO] UPDATED)</h2>
<h3>Taylor A. Howell, Chunjiang Fu, Zachary Manchester</h3>
<p>We present an approach for approximately solving discrete-time stochastic
optimal-control problems by combining direct trajectory optimization,
deterministic sampling, and policy optimization. Our feedback motion-planning
algorithm uses a quasi-Newton method to simultaneously optimize a reference
trajectory, a set of deterministically chosen sample trajectories, and a
parameterized policy. We demonstrate that this approach exactly recovers LQR
policies in the case of linear dynamics, quadratic objective, and Gaussian
disturbances. We also demonstrate the algorithm on several nonlinear,
underactuated robotic systems to highlight its performance and ability to
handle control limits, safely avoid obstacles, and generate robust plans in the
presence of unmodeled dynamics.
</p>
<a href="http://arxiv.org/abs/2010.08506" target="_blank">arXiv:2010.08506</a> [<a href="http://arxiv.org/pdf/2010.08506" target="_blank">pdf</a>]

<h2>Optimization-Based Visual-Inertial SLAM Tightly Coupled with Raw GNSS Measurements. (arXiv:2010.11675v2 [cs.RO] UPDATED)</h2>
<h3>Jinxu Liu, Wei Gao, Zhanyi Hu</h3>
<p>Fusing vision, Inertial Measurement Unit (IMU) and Global Navigation
Satellite System (GNSS) information is a promising solution for accurate global
positioning in complex urban scenes, because of the complementarity of the
different sensors. Unlike the loose coupling approaches and the EKF-based
approaches in the literature, we propose an optimization-based visual-inertial
SLAM tightly coupled with raw GNSS measurements, including pseudoranges and
Doppler shift, which is the first of such approaches to our knowledge.
Reprojection error, IMU pre-integration error and raw GNSS measurement error
are jointly optimized using bundle adjustment in a sliding window, and the
asynchronism between images and raw GNSS measurements is considered.
Marginalization is performed in the sliding window, and some methods dealing
with noisy measurements and vulnerable situations are employed. Experimental
results on public dataset in complex urban scenes prove that our proposed
approach outperforms state-of-the-art visual-inertial SLAM, GNSS single point
positioning, as well as a loose coupling approach, both in the scenes that
mainly contain low-rise buildings and the scenes that contain urban canyons.
</p>
<a href="http://arxiv.org/abs/2010.11675" target="_blank">arXiv:2010.11675</a> [<a href="http://arxiv.org/pdf/2010.11675" target="_blank">pdf</a>]

<h2>Reliable Off-policy Evaluation for Reinforcement Learning. (arXiv:2011.04102v2 [cs.LG] UPDATED)</h2>
<h3>Jie Wang, Rui Gao, Hongyuan Zha</h3>
<p>In a sequential decision-making problem, off-policy evaluation estimates the
expected cumulative reward of a target policy using logged trajectory data
generated from a different behavior policy, without execution of the target
policy. Reinforcement learning in high-stake environments, such as healthcare
and education, is often limited to off-policy settings due to safety or ethical
concerns, or inability of exploration. Hence it is imperative to quantify the
uncertainty of the off-policy estimate before deployment of the target policy.
In this paper, we propose a novel framework that provides robust and optimistic
cumulative reward estimates using one or multiple logged trajectories data.
Leveraging methodologies from distributionally robust optimization, we show
that with proper selection of the size of the distributional uncertainty set,
these estimates serve as confidence bounds with non-asymptotic and asymptotic
guarantees under stochastic or adversarial environments. Our results are also
generalized to batch reinforcement learning and are supported by empirical
analysis.
</p>
<a href="http://arxiv.org/abs/2011.04102" target="_blank">arXiv:2011.04102</a> [<a href="http://arxiv.org/pdf/2011.04102" target="_blank">pdf</a>]

<h2>Continuous Emotion Recognition with Spatiotemporal Convolutional Neural Networks. (arXiv:2011.09280v2 [cs.CV] UPDATED)</h2>
<h3>Thomas Teixeira, Eric Granger, Alessandro Lameiras Koerich</h3>
<p>Facial expressions are one of the most powerful ways for depicting specific
patterns in human behavior and describing human emotional state. Despite the
impressive advances of affective computing over the last decade, automatic
video-based systems for facial expression recognition still cannot handle
properly variations in facial expression among individuals as well as
cross-cultural and demographic aspects. Nevertheless, recognizing facial
expressions is a difficult task even for humans. In this paper, we investigate
the suitability of state-of-the-art deep learning architectures based on
convolutional neural networks (CNNs) for continuous emotion recognition using
long video sequences captured in-the-wild. This study focuses on deep learning
models that allow encoding spatiotemporal relations in videos considering a
complex and multi-dimensional emotion space, where values of valence and
arousal must be predicted. We have developed and evaluated convolutional
recurrent neural networks combining 2D-CNNs and long short term-memory units,
and inflated 3D-CNN models, which are built by inflating the weights of a
pre-trained 2D-CNN model during fine-tuning, using application-specific videos.
Experimental results on the challenging SEWA-DB dataset have shown that these
architectures can effectively be fine-tuned to encode the spatiotemporal
information from successive raw pixel images and achieve state-of-the-art
results on such a dataset.
</p>
<a href="http://arxiv.org/abs/2011.09280" target="_blank">arXiv:2011.09280</a> [<a href="http://arxiv.org/pdf/2011.09280" target="_blank">pdf</a>]

<h2>Probabilistic Load Forecasting Based on Adaptive Online Learning. (arXiv:2011.14721v3 [cs.LG] UPDATED)</h2>
<h3>Ver&#xf3;nica &#xc1;lvarez, Santiago Mazuelas, Jos&#xe9; A. Lozano</h3>
<p>Load forecasting is crucial for multiple energy management tasks such as
scheduling generation capacity, planning supply and demand, and minimizing
energy trade costs. Such relevance has increased even more in recent years due
to the integration of renewable energies, electric cars, and microgrids.
Conventional load forecasting techniques obtain single-value load forecasts by
exploiting consumption patterns of past load demand. However, such techniques
cannot assess intrinsic uncertainties in load demand, and cannot capture
dynamic changes in consumption patterns. To address these problems, this paper
presents a method for probabilistic load forecasting based on the adaptive
online learning of hidden Markov models. We propose learning and forecasting
techniques with theoretical guarantees, and experimentally assess their
performance in multiple scenarios. In particular, we develop adaptive online
learning techniques that update model parameters recursively, and sequential
prediction techniques that obtain probabilistic forecasts using the most recent
parameters. The performance of the method is evaluated using multiple datasets
corresponding with regions that have different sizes and display assorted
time-varying consumption patterns. The results show that the proposed method
can significantly improve the performance of existing techniques for a wide
range of scenarios.
</p>
<a href="http://arxiv.org/abs/2011.14721" target="_blank">arXiv:2011.14721</a> [<a href="http://arxiv.org/pdf/2011.14721" target="_blank">pdf</a>]

<h2>Distributed Training and Optimization Of Neural Networks. (arXiv:2012.01839v2 [cs.LG] UPDATED)</h2>
<h3>Jean-Roch Vlimant, Junqi Yin</h3>
<p>Deep learning models are yielding increasingly better performances thanks to
multiple factors. To be successful, model may have large number of parameters
or complex architectures and be trained on large dataset. This leads to large
requirements on computing resource and turn around time, even more so when
hyper-parameter optimization is done (e.g search over model architectures).
While this is a challenge that goes beyond particle physics, we review the
various ways to do the necessary computations in parallel, and put it in the
context of high energy physics.
</p>
<a href="http://arxiv.org/abs/2012.01839" target="_blank">arXiv:2012.01839</a> [<a href="http://arxiv.org/pdf/2012.01839" target="_blank">pdf</a>]

<h2>Risk & returns around FOMC press conferences: a novel perspective from computer vision. (arXiv:2012.06573v2 [stat.ML] UPDATED)</h2>
<h3>Alexis Marchal</h3>
<p>I propose a new tool to characterize the resolution of uncertainty around
FOMC press conferences. It relies on the construction of a measure capturing
the level of discussion complexity between the Fed Chair and reporters during
the Q&amp;A sessions. I show that complex discussions are associated with higher
equity returns and a drop in realized volatility. The method creates an
attention score by quantifying how much the Chair needs to rely on reading
internal documents to be able to answer a question. This is accomplished by
building a novel dataset of video images of the press conferences and
leveraging recent deep learning algorithms from computer vision. This
alternative data provides new information on nonverbal communication that
cannot be extracted from the widely analyzed FOMC transcripts. This paper can
be seen as a proof of concept that certain videos contain valuable information
for the study of financial markets.
</p>
<a href="http://arxiv.org/abs/2012.06573" target="_blank">arXiv:2012.06573</a> [<a href="http://arxiv.org/pdf/2012.06573" target="_blank">pdf</a>]

<h2>End-to-End Deep Structured Models for Drawing Crosswalks. (arXiv:2012.11585v3 [cs.CV] UPDATED)</h2>
<h3>Justin Liang, Raquel Urtasun</h3>
<p>In this paper we address the problem of detecting crosswalks from LiDAR and
camera imagery. Towards this goal, given multiple LiDAR sweeps and the
corresponding imagery, we project both inputs onto the ground surface to
produce a top down view of the scene. We then leverage convolutional neural
networks to extract semantic cues about the location of the crosswalks. These
are then used in combination with road centerlines from freely available maps
(e.g., OpenStreetMaps) to solve a structured optimization problem which draws
the final crosswalk boundaries. Our experiments over crosswalks in a large city
area show that 96.6% automation can be achieved.
</p>
<a href="http://arxiv.org/abs/2012.11585" target="_blank">arXiv:2012.11585</a> [<a href="http://arxiv.org/pdf/2012.11585" target="_blank">pdf</a>]

<h2>A Survey on Visual Transformer. (arXiv:2012.12556v2 [cs.CV] UPDATED)</h2>
<h3>Kai Han, Yunhe Wang, Hanting Chen, Xinghao Chen, Jianyuan Guo, Zhenhua Liu, Yehui Tang, An Xiao, Chunjing Xu, Yixing Xu, Zhaohui Yang, Yiman Zhang, Dacheng Tao</h3>
<p>Transformer is a type of deep neural network mainly based on self-attention
mechanism which is originally applied in natural language processing field.
Inspired by the strong representation ability of transformer, researchers
propose to extend transformer for computer vision tasks. Transformer-based
models show competitive and even better performance on various visual
benchmarks compared to other network types such as convolutional networks and
recurrent networks. With high performance and without inductive bias defined by
human, transformer is receiving more and more attention from the visual
community. In this paper we provide a literature review of these visual
transformer models by categorizing them in different tasks and analyze the
advantages and disadvantages of these methods. In particular, the main
categories include the basic image classification, high-level vision, low-level
vision and video processing. The self-attention in computer vision is also
briefly revisited as self-attention is the base component in transformer.
Efficient transformer methods are included for pushing transformer into real
applications on the devices. Finally, we give a discussion about the challenges
and further research directions for visual transformers.
</p>
<a href="http://arxiv.org/abs/2012.12556" target="_blank">arXiv:2012.12556</a> [<a href="http://arxiv.org/pdf/2012.12556" target="_blank">pdf</a>]

<h2>Training data-efficient image transformers & distillation through attention. (arXiv:2012.12877v2 [cs.CV] UPDATED)</h2>
<h3>Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Herv&#xe9; J&#xe9;gou</h3>
<p>Recently, neural networks purely based on attention were shown to address
image understanding tasks such as image classification. However, these visual
transformers are pre-trained with hundreds of millions of images using an
expensive infrastructure, thereby limiting their adoption.

In this work, we produce a competitive convolution-free transformer by
training on Imagenet only. We train them on a single computer in less than 3
days. Our reference vision transformer (86M parameters) achieves top-1 accuracy
of 83.1% (single-crop evaluation) on ImageNet with no external data.

More importantly, we introduce a teacher-student strategy specific to
transformers. It relies on a distillation token ensuring that the student
learns from the teacher through attention. We show the interest of this
token-based distillation, especially when using a convnet as a teacher. This
leads us to report results competitive with convnets for both Imagenet (where
we obtain up to 85.2% accuracy) and when transferring to other tasks. We share
our code and models.
</p>
<a href="http://arxiv.org/abs/2012.12877" target="_blank">arXiv:2012.12877</a> [<a href="http://arxiv.org/pdf/2012.12877" target="_blank">pdf</a>]

<h2>A Tutorial on Sparse Gaussian Processes and Variational Inference. (arXiv:2012.13962v5 [cs.LG] UPDATED)</h2>
<h3>Felix Leibfried, Vincent Dutordoir, ST John, Nicolas Durrande</h3>
<p>Gaussian processes (GPs) provide a framework for Bayesian inference that can
offer principled uncertainty estimates for a large range of problems. For
example, if we consider regression problems with Gaussian likelihoods, a GP
model enjoys a posterior in closed form. However, identifying the posterior GP
scales cubically with the number of training examples and requires to store all
examples in memory. In order to overcome these obstacles, sparse GPs have been
proposed that approximate the true posterior GP with pseudo-training examples.
Importantly, the number of pseudo-training examples is user-defined and enables
control over computational and memory complexity. In the general case, sparse
GPs do not enjoy closed-form solutions and one has to resort to approximate
inference. In this context, a convenient choice for approximate inference is
variational inference (VI), where the problem of Bayesian inference is cast as
an optimization problem -- namely, to maximize a lower bound of the log
marginal likelihood. This paves the way for a powerful and versatile framework,
where pseudo-training examples are treated as optimization arguments of the
approximate posterior that are jointly identified together with hyperparameters
of the generative model (i.e. prior and likelihood). The framework can
naturally handle a wide scope of supervised learning problems, ranging from
regression with heteroscedastic and non-Gaussian likelihoods to classification
problems with discrete labels, but also multilabel problems. The purpose of
this tutorial is to provide access to the basic matter for readers without
prior knowledge in both GPs and VI. A proper exposition to the subject enables
also access to more recent advances (like importance-weighted VI as well as
inderdomain, multioutput and deep GPs) that can serve as an inspiration for new
research ideas.
</p>
<a href="http://arxiv.org/abs/2012.13962" target="_blank">arXiv:2012.13962</a> [<a href="http://arxiv.org/pdf/2012.13962" target="_blank">pdf</a>]

<h2>DeepTake: Prediction of Driver Takeover Behavior using Multimodal Data. (arXiv:2012.15441v2 [cs.LG] UPDATED)</h2>
<h3>Erfan Pakdamanian, Shili Sheng, Sonia Baee, Seongkook Heo, Sarit Kraus, Lu Feng</h3>
<p>Automated vehicles promise a future where drivers can engage in non-driving
tasks without hands on the steering wheels for a prolonged period.
Nevertheless, automated vehicles may still need to occasionally hand the
control back to drivers due to technology limitations and legal requirements.
While some systems determine the need for driver takeover using driver context
and road condition to initiate a takeover request, studies show that the driver
may not react to it. We present DeepTake, a novel deep neural network-based
framework that predicts multiple aspects of takeover behavior to ensure that
the driver is able to safely take over the control when engaged in non-driving
tasks. Using features from vehicle data, driver biometrics, and subjective
measurements, DeepTake predicts the driver's intention, time, and quality of
takeover. We evaluate DeepTake performance using multiple evaluation metrics.
Results show that DeepTake reliably predicts the takeover intention, time, and
quality, with an accuracy of 96%, 93%, and 83%, respectively. Results also
indicate that DeepTake outperforms previous state-of-the-art methods on
predicting driver takeover time and quality. Our findings have implications for
the algorithm development of driver monitoring and state detection.
</p>
<a href="http://arxiv.org/abs/2012.15441" target="_blank">arXiv:2012.15441</a> [<a href="http://arxiv.org/pdf/2012.15441" target="_blank">pdf</a>]

<h2>Likelihood Ratio Exponential Families. (arXiv:2012.15480v2 [cs.LG] UPDATED)</h2>
<h3>Rob Brekelmans, Frank Nielsen, Alireza Makhzani, Aram Galstyan, Greg Ver Steeg</h3>
<p>The exponential family is well known in machine learning and statistical
physics as the maximum entropy distribution subject to a set of observed
constraints, while the geometric mixture path is common in MCMC methods such as
annealed importance sampling. Linking these two ideas, recent work has
interpreted the geometric mixture path as an exponential family of
distributions to analyze the thermodynamic variational objective (TVO).

We extend these likelihood ratio exponential families to include solutions to
rate-distortion (RD) optimization, the information bottleneck (IB) method, and
recent rate-distortion-classification approaches which combine RD and IB. This
provides a common mathematical framework for understanding these methods via
the conjugate duality of exponential families and hypothesis testing. Further,
we collect existing results to provide a variational representation of
intermediate RD or TVO distributions as a minimizing an expectation of KL
divergences. This solution also corresponds to a size-power tradeoff using the
likelihood ratio test and the Neyman Pearson lemma. In thermodynamic
integration bounds such as the TVO, we identify the intermediate distribution
whose expected sufficient statistics match the log partition function.
</p>
<a href="http://arxiv.org/abs/2012.15480" target="_blank">arXiv:2012.15480</a> [<a href="http://arxiv.org/pdf/2012.15480" target="_blank">pdf</a>]

<h2>Synthetic Glacier SAR Image Generation from Arbitrary Masks Using Pix2Pix Algorithm. (arXiv:2101.03252v2 [cs.LG] UPDATED)</h2>
<h3>Rosanna Dietrich-Sussner, Amirabbas Davari, Thorsten Seehaus, Matthias Braun, Vincent Christlein, Andreas Maier, Christian Riess</h3>
<p>Supervised machine learning requires a large amount of labeled data to
achieve proper test results. However, generating accurately labeled
segmentation maps on remote sensing imagery, including images from synthetic
aperture radar (SAR), is tedious and highly subjective. In this work, we
propose to alleviate the issue of limited training data by generating synthetic
SAR images with the pix2pix algorithm. This algorithm uses conditional
Generative Adversarial Networks (cGANs) to generate an artificial image while
preserving the structure of the input. In our case, the input is a segmentation
mask, from which a corresponding synthetic SAR image is generated. We present
different models, perform a comparative study and demonstrate that this
approach synthesizes convincing glaciers in SAR images with promising
qualitative and quantitative results.
</p>
<a href="http://arxiv.org/abs/2101.03252" target="_blank">arXiv:2101.03252</a> [<a href="http://arxiv.org/pdf/2101.03252" target="_blank">pdf</a>]

<h2>Cross-Modal Contrastive Learning for Text-to-Image Generation. (arXiv:2101.04702v2 [cs.CV] UPDATED)</h2>
<h3>Han Zhang, Jing Yu Koh, Jason Baldridge, Honglak Lee, Yinfei Yang</h3>
<p>The output of text-to-image synthesis systems should be coherent, clear,
photo-realistic scenes with high semantic fidelity to their conditioned text
descriptions. Our Cross-Modal Contrastive Generative Adversarial Network
(XMC-GAN) addresses this challenge by maximizing the mutual information between
image and text. It does this via multiple contrastive losses which capture
inter-modality and intra-modality correspondences. XMC-GAN uses an attentional
self-modulation generator, which enforces strong text-image correspondence, and
a contrastive discriminator, which acts as a critic as well as a feature
encoder for contrastive learning. The quality of XMC-GAN's output is a major
step up from previous models, as we show on three challenging datasets. On
MS-COCO, not only does XMC-GAN improve state-of-the-art FID from 24.70 to 9.33,
but--more importantly--people prefer XMC-GAN by 77.3 for image quality and 74.1
for image-text alignment, compared to three other recent models. XMC-GAN also
generalizes to the challenging Localized Narratives dataset (which has longer,
more detailed descriptions), improving state-of-the-art FID from 48.70 to
14.12. Lastly, we train and evaluate XMC-GAN on the challenging Open Images
data, establishing a strong benchmark FID score of 26.91.
</p>
<a href="http://arxiv.org/abs/2101.04702" target="_blank">arXiv:2101.04702</a> [<a href="http://arxiv.org/pdf/2101.04702" target="_blank">pdf</a>]

<h2>Neural Volume Rendering: NeRF And Beyond. (arXiv:2101.05204v2 [cs.CV] UPDATED)</h2>
<h3>Frank Dellaert, Lin Yen-Chen</h3>
<p>Besides the COVID-19 pandemic and political upheaval in the US, 2020 was also
the year in which neural volume rendering exploded onto the scene, triggered by
the impressive NeRF paper by Mildenhall et al. (2020). Both of us have tried to
capture this excitement, Frank on a blog post (Dellaert, 2020) and Yen-Chen in
a Github collection (Yen-Chen, 2020). This note is an annotated bibliography of
the relevant papers, and we posted the associated bibtex file on the
repository.
</p>
<a href="http://arxiv.org/abs/2101.05204" target="_blank">arXiv:2101.05204</a> [<a href="http://arxiv.org/pdf/2101.05204" target="_blank">pdf</a>]

<h2>Adversarially robust and explainable model compression with on-device personalization for NLP applications. (arXiv:2101.05624v2 [cs.LG] UPDATED)</h2>
<h3>Yao Qiang, Supriya Tumkur Suresh Kumar, Marco Brocanelli, Dongxiao Zhu</h3>
<p>On-device Deep Neural Networks (DNNs) have recently gained more attention due
to the increasing computing power of the mobile devices and the number of
applications in Computer Vision (CV), Natural Language Processing (NLP), and
Internet of Things (IoTs). Unfortunately, the existing efficient convolutional
neural network (CNN) architectures designed for CV tasks are not directly
applicable to NLP tasks and the tiny Recurrent Neural Network (RNN)
architectures have been designed primarily for IoT applications. In NLP
applications, although model compression has seen initial success in on-device
text classification, there are at least three major challenges yet to be
addressed: adversarial robustness, explainability, and personalization. Here we
attempt to tackle these challenges by designing a new training scheme for model
compression and adversarial robustness, including the optimization of an
explainable feature mapping objective, a knowledge distillation objective, and
an adversarially robustness objective. The resulting compressed model is
personalized using on-device private training data via fine-tuning. We perform
extensive experiments to compare our approach with both compact RNN (e.g.,
FastGRNN) and compressed RNN (e.g., PRADO) architectures in both natural and
adversarial NLP test settings.
</p>
<a href="http://arxiv.org/abs/2101.05624" target="_blank">arXiv:2101.05624</a> [<a href="http://arxiv.org/pdf/2101.05624" target="_blank">pdf</a>]

<h2>A Recurrent Neural Network Approach to Roll Estimation for Needle Steering. (arXiv:2101.04856v1 [cs.RO] CROSS LISTED)</h2>
<h3>Maxwell Emerson, James M. Ferguson, Tayfun Efe Ertop, Margaret Rox, Josephine Granna, Michael Lester, Fabien Maldonado, Erin A. Gillaspie, Ron Alterovitz, Robert J. Webster III., Alan Kuntz</h3>
<p>Steerable needles are a promising technology for delivering targeted
therapies in the body in a minimally-invasive fashion, as they can curve around
anatomical obstacles and hone in on anatomical targets. In order to accurately
steer them, controllers must have full knowledge of the needle tip's
orientation. However, current sensors either do not provide full orientation
information or interfere with the needle's ability to deliver therapy. Further,
torsional dynamics can vary and depend on many parameters making steerable
needles difficult to accurately model, limiting the effectiveness of
traditional observer methods. To overcome these limitations, we propose a
model-free, learned-method that leverages LSTM neural networks to estimate the
needle tip's orientation online. We validate our method by integrating it into
a sliding-mode controller and steering the needle to targets in gelatin and ex
vivo ovine brain tissue. We compare our method's performance against an
Extended Kalman Filter, a model-based observer, achieving significantly lower
targeting errors.
</p>
<a href="http://arxiv.org/abs/2101.04856" target="_blank">arXiv:2101.04856</a> [<a href="http://arxiv.org/pdf/2101.04856" target="_blank">pdf</a>]

<h2>Anomaly Detection Support Using Process Classification. (arXiv:2101.05371v1 [cs.LG] CROSS LISTED)</h2>
<h3>Sebastian Eresheim, Lukas Daniel Klausner, Patrick Kochberger</h3>
<p>Anomaly detection systems need to consider a lot of information when scanning
for anomalies. One example is the context of the process in which an anomaly
might occur, because anomalies for one process might not be anomalies for a
different one. Therefore data -- such as system events -- need to be assigned
to the program they originate from. This paper investigates whether it is
possible to infer from a list of system events the program whose behavior
caused the occurrence of these system events. To that end, we model transition
probabilities between non-equivalent events and apply the $k$-nearest neighbors
algorithm. This system is evaluated on non-malicious, real-world data using
four different evaluation scores. Our results suggest that the approach
proposed in this paper is capable of correctly inferring program names from
system events.
</p>
<a href="http://arxiv.org/abs/2101.05371" target="_blank">arXiv:2101.05371</a> [<a href="http://arxiv.org/pdf/2101.05371" target="_blank">pdf</a>]

