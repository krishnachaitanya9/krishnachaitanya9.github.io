---
title: Latest Deep Learning Papers
date: 2021-02-17 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (162 Articles)</h1>
<h2>Evaluating Fairness of Machine Learning Models Under Uncertain and Incomplete Information. (arXiv:2102.08410v1 [cs.LG])</h2>
<h3>Pranjal Awasthi, Alex Beutel, Matthaeus Kleindessner, Jamie Morgenstern, Xuezhi Wang</h3>
<p>Training and evaluation of fair classifiers is a challenging problem. This is
partly due to the fact that most fairness metrics of interest depend on both
the sensitive attribute information and label information of the data points.
In many scenarios it is not possible to collect large datasets with such
information. An alternate approach that is commonly used is to separately train
an attribute classifier on data with sensitive attribute information, and then
use it later in the ML pipeline to evaluate the bias of a given classifier.
While such decoupling helps alleviate the problem of demographic scarcity, it
raises several natural questions such as: how should the attribute classifier
be trained?, and how should one use a given attribute classifier for accurate
bias estimation? In this work we study this question from both theoretical and
empirical perspectives.

We first experimentally demonstrate that the test accuracy of the attribute
classifier is not always correlated with its effectiveness in bias estimation
for a downstream model. In order to further investigate this phenomenon, we
analyze an idealized theoretical model and characterize the structure of the
optimal classifier. Our analysis has surprising and counter-intuitive
implications where in certain regimes one might want to distribute the error of
the attribute classifier as unevenly as possible among the different subgroups.
Based on our analysis we develop heuristics for both training and using
attribute classifiers for bias estimation in the data scarce regime. We
empirically demonstrate the effectiveness of our approach on real and simulated
data.
</p>
<a href="http://arxiv.org/abs/2102.08410" target="_blank">arXiv:2102.08410</a> [<a href="http://arxiv.org/pdf/2102.08410" target="_blank">pdf</a>]

<h2>Improving Visual Place Recognition Performance by Maximising Complementarity. (arXiv:2102.08416v1 [cs.CV])</h2>
<h3>Maria Waheed, Michael Milford, Klaus D. McDonald-Maier, Shoaib Ehsan</h3>
<p>Visual place recognition (VPR) is the problem of recognising a previously
visited location using visual information. Many attempts to improve the
performance of VPR methods have been made in the literature. One approach that
has received attention recently is the multi-process fusion where different VPR
methods run in parallel and their outputs are combined in an effort to achieve
better performance. The multi-process fusion, however, does not have a
well-defined criterion for selecting and combining different VPR methods from a
wide range of available options. To the best of our knowledge, this paper
investigates the complementarity of state-of-the-art VPR methods systematically
for the first time and identifies those combinations which can result in better
performance. The paper presents a well-defined framework which acts as a sanity
check to find the complementarity between two techniques by utilising a
McNemar's test-like approach. The framework allows estimation of upper and
lower complementarity bounds for the VPR techniques to be combined, along with
an estimate of maximum VPR performance that may be achieved. Based on this
framework, results are presented for eight state-of-the-art VPR methods on ten
widely-used VPR datasets showing the potential of different combinations of
techniques for achieving better performance.
</p>
<a href="http://arxiv.org/abs/2102.08416" target="_blank">arXiv:2102.08416</a> [<a href="http://arxiv.org/pdf/2102.08416" target="_blank">pdf</a>]

<h2>Evaluating Multi-label Classifiers with Noisy Labels. (arXiv:2102.08427v1 [cs.LG])</h2>
<h3>Wenting Zhao, Carla Gomes</h3>
<p>Multi-label classification (MLC) is a generalization of standard
classification where multiple labels may be assigned to a given sample. In the
real world, it is more common to deal with noisy datasets than clean datasets,
given how modern datasets are labeled by a large group of annotators on
crowdsourcing platforms, but little attention has been given to evaluating
multi-label classifiers with noisy labels. Exploiting label correlations now
becomes a standard component of a multi-label classifier to achieve competitive
performance. However, this component makes the classifier more prone to poor
generalization - it overfits labels as well as label dependencies. We identify
three common real-world label noise scenarios and show how previous approaches
per-form poorly with noisy labels. To address this issue, we present a
Context-Based Multi-LabelClassifier (CbMLC) that effectively handles noisy
labels when learning label dependencies, without requiring additional
supervision. We compare CbMLC against other domain-specific state-of-the-art
models on a variety of datasets, under both the clean and the noisy settings.
We show CbMLC yields substantial improvements over the previous methods in most
cases.
</p>
<a href="http://arxiv.org/abs/2102.08427" target="_blank">arXiv:2102.08427</a> [<a href="http://arxiv.org/pdf/2102.08427" target="_blank">pdf</a>]

<h2>Multi-Stage Transmission Line Flow Control Using Centralized and Decentralized Reinforcement Learning Agents. (arXiv:2102.08430v1 [cs.LG])</h2>
<h3>Xiumin Shang, Jinping Yang, Bingquan Zhu, Lin Ye, Jing Zhang, Jianping Xu, Qin Lyu, Ruisheng Diao</h3>
<p>Planning future operational scenarios of bulk power systems that meet
security and economic constraints typically requires intensive labor efforts in
performing massive simulations. To automate this process and relieve engineers'
burden, a novel multi-stage control approach is presented in this paper to
train centralized and decentralized reinforcement learning agents that can
automatically adjust grid controllers for regulating transmission line flows at
normal condition and under contingencies. The power grid flow control problem
is formulated as Markov Decision Process (MDP). At stage one, centralized soft
actor-critic (SAC) agent is trained to control generator active power outputs
in a wide area to control transmission line flows against specified security
limits. If line overloading issues remain unresolved, stage two is used to
train decentralized SAC agent via load throw-over at local substations. The
effectiveness of the proposed approach is verified on a series of actual
planning cases used for operating the power grid of SGCC Zhejiang Electric
Power Company.
</p>
<a href="http://arxiv.org/abs/2102.08430" target="_blank">arXiv:2102.08430</a> [<a href="http://arxiv.org/pdf/2102.08430" target="_blank">pdf</a>]

<h2>Complex Momentum for Learning in Games. (arXiv:2102.08431v1 [cs.LG])</h2>
<h3>Jonathan Lorraine, David Acuna, Paul Vicol, David Duvenaud</h3>
<p>We generalize gradient descent with momentum for learning in differentiable
games to have complex-valued momentum. We give theoretical motivation for our
method by proving convergence on bilinear zero-sum games for simultaneous and
alternating updates. Our method gives real-valued parameter updates, making it
a drop-in replacement for standard optimizers. We empirically demonstrate that
complex-valued momentum can improve convergence in adversarial games - like
generative adversarial networks - by showing we can find better solutions with
an almost identical computational cost. We also show a practical generalization
to a complex-valued Adam variant, which we use to train BigGAN to better
inception scores on CIFAR-10.
</p>
<a href="http://arxiv.org/abs/2102.08431" target="_blank">arXiv:2102.08431</a> [<a href="http://arxiv.org/pdf/2102.08431" target="_blank">pdf</a>]

<h2>Scaling Neuroscience Research using Federated Learning. (arXiv:2102.08440v1 [cs.LG])</h2>
<h3>Dimitris Stripelis, Jose Luis Ambite, Pradeep Lam, Paul Thompson</h3>
<p>The amount of biomedical data continues to grow rapidly. However, the ability
to analyze these data is limited due to privacy and regulatory concerns.
Machine learning approaches that require data to be copied to a single location
are hampered by the challenges of data sharing. Federated Learning is a
promising approach to learn a joint model over data silos. This architecture
does not share any subject data across sites, only aggregated parameters, often
in encrypted environments, thus satisfying privacy and regulatory requirements.
Here, we describe our Federated Learning architecture and training policies. We
demonstrate our approach on a brain age prediction model on structural MRI
scans distributed across multiple sites with diverse amounts of data and
subject (age) distributions. In these heterogeneous environments, our
Semi-Synchronous protocol provides faster convergence.
</p>
<a href="http://arxiv.org/abs/2102.08440" target="_blank">arXiv:2102.08440</a> [<a href="http://arxiv.org/pdf/2102.08440" target="_blank">pdf</a>]

<h2>SCAPE: Learning Stiffness Control from Augmented Position Control Experiences. (arXiv:2102.08442v1 [cs.RO])</h2>
<h3>Mincheol Kim, Scott Niekum, Ashish D. Deshpande</h3>
<p>We introduce a sample-efficient method for learning state-dependent stiffness
control policies for dexterous manipulation. The ability to control stiffness
facilitates safe and reliable manipulation by providing compliance and
robustness to uncertainties. So far, most current reinforcement learning
approaches to achieve robotic manipulation have exclusively focused on position
control, often due to the difficulty of learning high-dimensional stiffness
control policies. This difficulty can be partially mitigated via policy
guidance such as in imitation learning. However, expert stiffness control
demonstrations are often expensive or infeasible to record. Therefore, we
present an approach to learn Stiffness Control from Augmented Position control
Experiences (SCAPE) that bypasses this difficulty by transforming position
control demonstrations into approximate, suboptimal stiffness control
demonstrations. Then, the suboptimality of the augmented demonstrations is
addressed by using complementary techniques that help the agent safely learn
from both the demonstrations and reinforcement learning. By using simulation
tools and experiments on a robotic testbed, we show that the proposed approach
efficiently learns safe manipulation policies and outperforms learned position
control policies and several other baseline learning algorithms.
</p>
<a href="http://arxiv.org/abs/2102.08442" target="_blank">arXiv:2102.08442</a> [<a href="http://arxiv.org/pdf/2102.08442" target="_blank">pdf</a>]

<h2>Unsupervised Energy-based Out-of-distribution Detection using Stiefel-Restricted Kernel Machine. (arXiv:2102.08443v1 [cs.LG])</h2>
<h3>Francesco Tonin, Arun Pandey, Panagiotis Patrinos, Johan A. K. Suykens</h3>
<p>Detecting out-of-distribution (OOD) samples is an essential requirement for
the deployment of machine learning systems in the real world. Until now,
research on energy-based OOD detectors has focused on the softmax confidence
score from a pre-trained neural network classifier with access to class labels.
In contrast, we propose an unsupervised energy-based OOD detector leveraging
the Stiefel-Restricted Kernel Machine (St-RKM). Training requires minimizing an
objective function with an autoencoder loss term and the RKM energy where the
interconnection matrix lies on the Stiefel manifold. Further, we outline
multiple energy function definitions based on the RKM framework and discuss
their utility. In the experiments on standard datasets, the proposed method
improves over the existing energy-based OOD detectors and deep generative
models. Through several ablation studies, we further illustrate the merit of
each proposed energy function on the OOD detection performance.
</p>
<a href="http://arxiv.org/abs/2102.08443" target="_blank">arXiv:2102.08443</a> [<a href="http://arxiv.org/pdf/2102.08443" target="_blank">pdf</a>]

<h2>Smoothed Analysis with Adaptive Adversaries. (arXiv:2102.08446v1 [cs.LG])</h2>
<h3>Nika Haghtalab, Tim Roughgarden, Abhishek Shetty</h3>
<p>We prove novel algorithmic guarantees for several online problems in the
smoothed analysis model. In this model, at each time an adversary chooses an
input distribution with density function bounded above by $\tfrac{1}{\sigma}$
times that of the uniform distribution; nature then samples an input from this
distribution. Crucially, our results hold for {\em adaptive} adversaries that
can choose an input distribution based on the decisions of the algorithm and
the realizations of the inputs in the previous time steps.

This paper presents a general technique for proving smoothed algorithmic
guarantees against adaptive adversaries, in effect reducing the setting of
adaptive adversaries to the simpler case of oblivious adversaries. We apply
this technique to prove strong smoothed guarantees for three problems:

-Online learning: We consider the online prediction problem, where instances
are generated from an adaptive sequence of $\sigma$-smooth distributions and
the hypothesis class has VC dimension $d$. We bound the regret by
$\tilde{O}\big(\sqrt{T d\ln(1/\sigma)} + d\sqrt{\ln(T/\sigma)}\big)$. This
answers open questions of [RST11,Hag18].

-Online discrepancy minimization: We consider the online Koml\'os problem,
where the input is generated from an adaptive sequence of $\sigma$-smooth and
isotropic distributions on the $\ell_2$ unit ball. We bound the $\ell_\infty$
norm of the discrepancy vector by $\tilde{O}\big(\ln^2\!\big(
\frac{nT}{\sigma}\big) \big)$.

-Dispersion in online optimization: We consider online optimization of
piecewise Lipschitz functions where functions with $\ell$ discontinuities are
chosen by a smoothed adaptive adversary and show that the resulting sequence is
$\big( {\sigma}/{\sqrt{T\ell}}, \tilde O\big(\sqrt{T\ell}
\big)\big)$-dispersed. This matches the parameters of [BDV18] for oblivious
adversaries, up to log factors.
</p>
<a href="http://arxiv.org/abs/2102.08446" target="_blank">arXiv:2102.08446</a> [<a href="http://arxiv.org/pdf/2102.08446" target="_blank">pdf</a>]

<h2>Selfie Periocular Verification using an Efficient Super-Resolution Approach. (arXiv:2102.08449v1 [cs.CV])</h2>
<h3>Juan Tapia, Marta Gomez-Barrero, Rodrigo Lara, Andres Valenzuela, Christoph Busch</h3>
<p>Selfie-based biometrics has great potential for a wide range of applications
from marketing to higher security environments like online banking. This is now
especially relevant since e.g. periocular verification is contactless, and
thereby safe to use in pandemics such as COVID-19. However, selfie-based
biometrics faces some challenges since there is limited control over the data
acquisition conditions. Therefore, super-resolution has to be used to increase
the quality of the captured images. Most of the state of the art
super-resolution methods use deep networks with large filters, thereby needing
to train and store a correspondingly large number of parameters, and making
their use difficult for mobile devices commonly used for selfie-based.

In order to achieve an efficient super-resolution method, we propose an
Efficient Single Image Super-Resolution (ESISR) algorithm, which takes into
account a trade-off between the efficiency of the deep neural network and the
size of its filters. To that end, the method implements a novel loss function
based on the Sharpness metric. This metric turns out to be more suitable for
increasing the quality of the eye images. Our method drastically reduces the
number of parameters when compared with Deep CNNs with Skip Connection and
Network (DCSCN): from 2,170,142 to 28,654 parameters when the image size is
increased by a factor of x3. Furthermore, the proposed method keeps the sharp
quality of the images, which is highly relevant for biometric recognition
purposes. The results on remote verification systems with raw images reached an
Equal Error Rate (EER) of 8.7% for FaceNet and 10.05% for VGGFace. Where
embedding vectors were used from periocular images the best results reached an
EER of 8.9% (x3) for FaceNet and 9.90% (x4) for VGGFace.
</p>
<a href="http://arxiv.org/abs/2102.08449" target="_blank">arXiv:2102.08449</a> [<a href="http://arxiv.org/pdf/2102.08449" target="_blank">pdf</a>]

<h2>Globally-Robust Neural Networks. (arXiv:2102.08452v1 [cs.LG])</h2>
<h3>Klas Leino, Zifan Wang, Matt Fredrikson</h3>
<p>The threat of adversarial examples has motivated work on training certifiably
robust neural networks, to facilitate efficient verification of local
robustness at inference time. We formalize a notion of global robustness, which
captures the operational properties of on-line local robustness certification
while yielding a natural learning objective for robust training. We show that
widely-used architectures can be easily adapted to this objective by
incorporating efficient global Lipschitz bounds into the network, yielding
certifiably-robust models by construction that achieve state-of-the-art
verifiable and clean accuracy. Notably, this approach requires significantly
less time and memory than recent certifiable training methods, and leads to
negligible costs when certifying points on-line; for example, our evaluation
shows that it is possible to train a large tiny-imagenet model in a matter of
hours. We posit that this is possible using inexpensive global bounds --
despite prior suggestions that tighter local bounds are needed for good
performance -- because these models are trained to achieve tighter global
bounds. Namely, we prove that the maximum achievable verifiable accuracy for a
given dataset is not improved by using a local bound.
</p>
<a href="http://arxiv.org/abs/2102.08452" target="_blank">arXiv:2102.08452</a> [<a href="http://arxiv.org/pdf/2102.08452" target="_blank">pdf</a>]

<h2>Towards the Right Kind of Fairness in AI. (arXiv:2102.08453v1 [cs.AI])</h2>
<h3>Boris Ruf, Marcin Detyniecki</h3>
<p>To implement fair machine learning in a sustainable way, identifying the
right fairness definition is key. However, fairness is a concept of justice,
and various definitions exist. Some of them are in conflict with each other and
there is no uniformly accepted notion of fairness. The most appropriate
fairness definition for an artificial intelligence system is often a matter of
application and the right choice depends on ethical standards and legal
requirements. In the absence of officially binding rules, the objective of this
document is to structure the complex landscape of existing fairness
definitions. We propose the "Fairness Compass", a tool which formalises the
selection process and makes identifying the most appropriate fairness metric
for a given system a simple, straightforward procedure. We further argue that
documenting the reasoning behind the respective decisions in the course of this
process can help to build trust from the user through explaining and justifying
the implemented fairness.
</p>
<a href="http://arxiv.org/abs/2102.08453" target="_blank">arXiv:2102.08453</a> [<a href="http://arxiv.org/pdf/2102.08453" target="_blank">pdf</a>]

<h2>Lexicographically Fair Learning: Algorithms and Generalization. (arXiv:2102.08454v1 [cs.LG])</h2>
<h3>Emily Diana, Wesley Gill, Ira Globus-Harris, Michael Kearns, Aaron Roth, Saeed Sharifi-Malvajerdi</h3>
<p>We extend the notion of minimax fairness in supervised learning problems to
its natural conclusion: lexicographic minimax fairness (or lexifairness for
short). Informally, given a collection of demographic groups of interest,
minimax fairness asks that the error of the group with the highest error be
minimized. Lexifairness goes further and asks that amongst all minimax fair
solutions, the error of the group with the second highest error should be
minimized, and amongst all of those solutions, the error of the group with the
third highest error should be minimized, and so on. Despite its naturalness,
correctly defining lexifairness is considerably more subtle than minimax
fairness, because of inherent sensitivity to approximation error. We give a
notion of approximate lexifairness that avoids this issue, and then derive
oracle-efficient algorithms for finding approximately lexifair solutions in a
very general setting. When the underlying empirical risk minimization problem
absent fairness constraints is convex (as it is, for example, with linear and
logistic regression), our algorithms are provably efficient even in the worst
case. Finally, we show generalization bounds -- approximate lexifairness on the
training sample implies approximate lexifairness on the true distribution with
high probability. Our ability to prove generalization bounds depends on our
choosing definitions that avoid the instability of naive definitions.
</p>
<a href="http://arxiv.org/abs/2102.08454" target="_blank">arXiv:2102.08454</a> [<a href="http://arxiv.org/pdf/2102.08454" target="_blank">pdf</a>]

<h2>A Review of Testing Object-Based Environment Perception for Safe Automated Driving. (arXiv:2102.08460v1 [cs.RO])</h2>
<h3>Michael Hoss, Maike Scholtes, Lutz Eckstein</h3>
<p>Safety assurance of automated driving systems must consider uncertain
environment perception. This paper reviews literature addressing how perception
testing is realized as part of safety assurance. We focus on testing for
verification and validation purposes at the interface between perception and
planning, and structure our analysis along the three axes 1) test criteria and
metrics, 2) test scenarios, and 3) reference data. Furthermore, the analyzed
literature includes related safety standards, safety-independent perception
algorithm benchmarking, and sensor modeling. We find that the realization of
safety-aware perception testing remains an open issue since challenges
concerning the three testing axes and their interdependencies currently do not
appear to be sufficiently solved.
</p>
<a href="http://arxiv.org/abs/2102.08460" target="_blank">arXiv:2102.08460</a> [<a href="http://arxiv.org/pdf/2102.08460" target="_blank">pdf</a>]

<h2>Multi-Agent Multi-Armed Bandits with Limited Communication. (arXiv:2102.08462v1 [cs.LG])</h2>
<h3>Mridul Agarwal, Vaneet Aggarwal, Kamyar Azizzadenesheli</h3>
<p>We consider the problem where $N$ agents collaboratively interact with an
instance of a stochastic $K$ arm bandit problem for $K \gg N$. The agents aim
to simultaneously minimize the cumulative regret over all the agents for a
total of $T$ time steps, the number of communication rounds, and the number of
bits in each communication round. We present Limited Communication
Collaboration - Upper Confidence Bound (LCC-UCB), a doubling-epoch based
algorithm where each agent communicates only after the end of the epoch and
shares the index of the best arm it knows. With our algorithm, LCC-UCB, each
agent enjoys a regret of $\tilde{O}\left(\sqrt{({K/N}+ N)T}\right)$,
communicates for $O(\log T)$ steps and broadcasts $O(\log K)$ bits in each
communication step. We extend the work to sparse graphs with maximum degree
$K_G$, and diameter $D$ and propose LCC-UCB-GRAPH which enjoys a regret bound
of $\tilde{O}\left(D\sqrt{(K/N+ K_G)DT}\right)$. Finally, we empirically show
that the LCC-UCB and the LCC-UCB-GRAPH algorithm perform well and outperform
strategies that communicate through a central node
</p>
<a href="http://arxiv.org/abs/2102.08462" target="_blank">arXiv:2102.08462</a> [<a href="http://arxiv.org/pdf/2102.08462" target="_blank">pdf</a>]

<h2>Robust Factorization of Real-world Tensor Streams with Patterns, Missing Values, and Outliers. (arXiv:2102.08466v1 [cs.LG])</h2>
<h3>Dongjin Lee, Kijung Shin</h3>
<p>Consider multiple seasonal time series being collected in real-time, in the
form of a tensor stream. Real-world tensor streams often include missing
entries (e.g., due to network disconnection) and at the same time unexpected
outliers (e.g., due to system errors). Given such a real-world tensor stream,
how can we estimate missing entries and predict future evolution accurately in
real-time? In this work, we answer this question by introducing SOFIA, a robust
factorization method for real-world tensor streams. In a nutshell, SOFIA
smoothly and tightly integrates tensor factorization, outlier removal, and
temporal-pattern detection, which naturally reinforce each other. Moreover,
SOFIA integrates them in linear time, in an online manner, despite the presence
of missing entries. We experimentally show that SOFIA is (a) robust and
accurate: yielding up to 76% lower imputation error and 71% lower forecasting
error; (b) fast: up to 935X faster than the second-most accurate competitor;
and (c) scalable: scaling linearly with the number of new entries per time
step.
</p>
<a href="http://arxiv.org/abs/2102.08466" target="_blank">arXiv:2102.08466</a> [<a href="http://arxiv.org/pdf/2102.08466" target="_blank">pdf</a>]

<h2>From Majorization to Interpolation: Distributionally Robust Learning using Kernel Smoothing. (arXiv:2102.08474v1 [cs.LG])</h2>
<h3>Jia-Jie Zhu, Yassine Nemmour, Bernhard Sch&#xf6;lkopf</h3>
<p>We study the function approximation aspect of distributionally robust
optimization (DRO) based on probability metrics, such as the Wasserstein and
the maximum mean discrepancy. Our analysis leverages the insight that existing
DRO paradigms hinge on function majorants such as the Moreau-Yosida
regularization (supremal convolution). Deviating from those, this paper instead
proposes robust learning algorithms based on smooth function approximation and
interpolation. Our methods are simple in forms and apply to general loss
functions without knowing functional norms a priori. Furthermore, we analyze
the DRO risk bound decomposition by leveraging smooth function approximators
and the convergence rate for empirical kernel mean embedding.
</p>
<a href="http://arxiv.org/abs/2102.08474" target="_blank">arXiv:2102.08474</a> [<a href="http://arxiv.org/pdf/2102.08474" target="_blank">pdf</a>]

<h2>Finding the Ground-Truth from Multiple Labellers: Why Parameters of the Task Matter. (arXiv:2102.08482v1 [cs.AI])</h2>
<h3>Robert McCluskey, Amir Enshaei, Bashar Awwad Shiekh Hasan</h3>
<p>Employing multiple workers to label data for machine learning models has
become increasingly important in recent years with greater demand to collect
huge volumes of labelled data to train complex models while mitigating the risk
of incorrect and noisy labelling. Whether it is large scale data gathering on
popular crowd-sourcing platforms or smaller sets of workers in high-expertise
labelling exercises, there are various methods recommended to gather a
consensus from employed workers and establish ground-truth labels. However,
there is very little research on how the various parameters of a labelling task
can impact said methods. These parameters include the number of workers, worker
expertise, number of labels in a taxonomy and sample size. In this paper,
Majority Vote, CrowdTruth and Binomial Expectation Maximisation are
investigated against the permutations of these parameters in order to provide
better understanding of the parameter settings to give an advantage in
ground-truth inference. Findings show that both Expectation Maximisation and
CrowdTruth are only likely to give an advantage over majority vote under
certain parameter conditions, while there are many cases where the methods can
be shown to have no major impact. Guidance is given as to what parameters
methods work best under, while the experimental framework provides a way of
testing other established methods and also testing new methods that can attempt
to provide advantageous performance where the methods in this paper did not. A
greater level of understanding regarding optimal crowd-sourcing parameters is
also achieved.
</p>
<a href="http://arxiv.org/abs/2102.08482" target="_blank">arXiv:2102.08482</a> [<a href="http://arxiv.org/pdf/2102.08482" target="_blank">pdf</a>]

<h2>Reward Poisoning in Reinforcement Learning: Attacks Against Unknown Learners in Unknown Environments. (arXiv:2102.08492v1 [cs.LG])</h2>
<h3>Amin Rakhsha, Xuezhou Zhang, Xiaojin Zhu, Adish Singla</h3>
<p>We study black-box reward poisoning attacks against reinforcement learning
(RL), in which an adversary aims to manipulate the rewards to mislead a
sequence of RL agents with unknown algorithms to learn a nefarious policy in an
environment unknown to the adversary a priori. That is, our attack makes
minimum assumptions on the prior knowledge of the adversary: it has no initial
knowledge of the environment or the learner, and neither does it observe the
learner's internal mechanism except for its performed actions. We design a
novel black-box attack, U2, that can provably achieve a near-matching
performance to the state-of-the-art white-box attack, demonstrating the
feasibility of reward poisoning even in the most challenging black-box setting.
</p>
<a href="http://arxiv.org/abs/2102.08492" target="_blank">arXiv:2102.08492</a> [<a href="http://arxiv.org/pdf/2102.08492" target="_blank">pdf</a>]

<h2>Shape-Tailored Deep Neural Networks. (arXiv:2102.08497v1 [cs.CV])</h2>
<h3>Naeemullah Khan, Angira Sharma, Ganesh Sundaramoorthi, Philip H. S. Torr</h3>
<p>We present Shape-Tailored Deep Neural Networks (ST-DNN). ST-DNN extend
convolutional networks (CNN), which aggregate data from fixed shape (square)
neighborhoods, to compute descriptors defined on arbitrarily shaped regions.
This is natural for segmentation, where descriptors should describe regions
(e.g., of objects) that have diverse shape. We formulate these descriptors
through the Poisson partial differential equation (PDE), which can be used to
generalize convolution to arbitrary regions. We stack multiple PDE layers to
generalize a deep CNN to arbitrary regions, and apply it to segmentation. We
show that ST-DNN are covariant to translations and rotations and robust to
domain deformations, natural for segmentation, which existing CNN based methods
lack. ST-DNN are 3-4 orders of magnitude smaller then CNNs used for
segmentation. We show that they exceed segmentation performance compared to
state-of-the-art CNN-based descriptors using 2-3 orders smaller training sets
on the texture segmentation problem.
</p>
<a href="http://arxiv.org/abs/2102.08497" target="_blank">arXiv:2102.08497</a> [<a href="http://arxiv.org/pdf/2102.08497" target="_blank">pdf</a>]

<h2>Pattern Sampling for Shapelet-based Time Series Classification. (arXiv:2102.08498v1 [cs.LG])</h2>
<h3>Atif Raza, Stefan Kramer</h3>
<p>Subsequence-based time series classification algorithms provide accurate and
interpretable models, but training these models is extremely computation
intensive. The asymptotic time complexity of subsequence-based algorithms
remains a higher-order polynomial, because these algorithms are based on
exhaustive search for highly discriminative subsequences. Pattern sampling has
been proposed as an effective alternative to mitigate the pattern explosion
phenomenon. Therefore, we employ pattern sampling to extract discriminative
features from discretized time series data. A weighted trie is created based on
the discretized time series data to sample highly discriminative patterns.
These sampled patterns are used to identify the shapelets which are used to
transform the time series classification problem into a feature-based
classification problem. Finally, a classification model can be trained using
any off-the-shelf algorithm. Creating a pattern sampler requires a small number
of patterns to be evaluated compared to an exhaustive search as employed by
previous approaches. Compared to previously proposed algorithms, our approach
requires considerably less computational and memory resources. Experiments
demonstrate how the proposed approach fares in terms of classification accuracy
and runtime performance.
</p>
<a href="http://arxiv.org/abs/2102.08498" target="_blank">arXiv:2102.08498</a> [<a href="http://arxiv.org/pdf/2102.08498" target="_blank">pdf</a>]

<h2>DEUP: Direct Epistemic Uncertainty Prediction. (arXiv:2102.08501v1 [cs.LG])</h2>
<h3>Moksh Jain, Salem Lahlou, Hadi Nekoei, Victor Butoi, Paul Bertin, Jarrid Rector-Brooks, Maksym Korablyov, Yoshua Bengio</h3>
<p>Epistemic uncertainty is the part of out-of-sample prediction error due to
the lack of knowledge of the learner. Whereas previous work was focusing on
model variance, we propose a principled approach for directly estimating
epistemic uncertainty by learning to predict generalization error and
subtracting an estimate of aleatoric uncertainty, i.e., intrinsic
unpredictability. This estimator of epistemic uncertainty includes the effect
of model bias and can be applied in non-stationary learning environments
arising in active learning or reinforcement learning. In addition to
demonstrating these properties of Direct Epistemic Uncertainty Prediction
(DEUP), we illustrate its advantage against existing methods for uncertainty
estimation on downstream tasks including sequential model optimization and
reinforcement learning. We also evaluate the quality of uncertainty estimates
from DEUP for probabilistic classification of images and for estimating
uncertainty about synergistic drug combinations.
</p>
<a href="http://arxiv.org/abs/2102.08501" target="_blank">arXiv:2102.08501</a> [<a href="http://arxiv.org/pdf/2102.08501" target="_blank">pdf</a>]

<h2>Federated Evaluation and Tuning for On-Device Personalization: System Design & Applications. (arXiv:2102.08503v1 [cs.LG])</h2>
<h3>Matthias Paulik, Matt Seigel, Henry Mason, Dominic Telaar, Joris Kluivers, Rogier van Dalen, Chi Wai Lau, Luke Carlson, Filip Granqvist, Chris Vandevelde, Sudeep Agarwal, Julien Freudiger, Andrew Byde, Abhishek Bhowmick, Gaurav Kapoor, Si Beaumont, &#xc1;ine Cahill, Dominic Hughes, Omid Javidbakht, Fei Dong, Rehan Rishi, Stanley Hung</h3>
<p>We describe the design of our federated task processing system. Originally,
the system was created to support two specific federated tasks: evaluation and
tuning of on-device ML systems, primarily for the purpose of personalizing
these systems. In recent years, support for an additional federated task has
been added: federated learning (FL) of deep neural networks. To our knowledge,
only one other system has been described in literature that supports FL at
scale. We include comparisons to that system to help discuss design decisions
and attached trade-offs. Finally, we describe two specific large scale
personalization use cases in detail to showcase the applicability of federated
tuning to on-device personalization and to highlight application specific
solutions.
</p>
<a href="http://arxiv.org/abs/2102.08503" target="_blank">arXiv:2102.08503</a> [<a href="http://arxiv.org/pdf/2102.08503" target="_blank">pdf</a>]

<h2>Label Leakage and Protection in Two-party Split Learning. (arXiv:2102.08504v1 [cs.LG])</h2>
<h3>Oscar Li, Jiankai Sun, Xin Yang, Weihao Gao, Hongyi Zhang, Junyuan Xie, Virginia Smith, Chong Wang</h3>
<p>In vertical federated learning, two-party split learning has become an
important topic and has found many applications in real business scenarios.
However, how to prevent the participants' ground-truth labels from possible
leakage is not well studied. In this paper, we consider answering this question
in an imbalanced binary classification setting, a common case in online
business applications. We first show that, norm attack, a simple method that
uses the norm of the communicated gradients between the parties, can largely
reveal the ground-truth labels from the participants. We then discuss several
protection techniques to mitigate this issue. Among them, we have designed a
principled approach that directly maximizes the worst-case error of label
detection. This is proved to be more effective in countering norm attack and
beyond. We experimentally demonstrate the competitiveness of our proposed
method compared to several other baselines.
</p>
<a href="http://arxiv.org/abs/2102.08504" target="_blank">arXiv:2102.08504</a> [<a href="http://arxiv.org/pdf/2102.08504" target="_blank">pdf</a>]

<h2>Towards an AI Coach to Infer Team Mental Model Alignment in Healthcare. (arXiv:2102.08507v1 [cs.AI])</h2>
<h3>Sangwon Seo, Lauren R. Kennedy-Metz, Marco A. Zenati, Julie A. Shah, Roger D. Dias, Vaibhav V. Unhelkar</h3>
<p>Shared mental models are critical to team success; however, in practice, team
members may have misaligned models due to a variety of factors. In
safety-critical domains (e.g., aviation, healthcare), lack of shared mental
models can lead to preventable errors and harm. Towards the goal of mitigating
such preventable errors, here, we present a Bayesian approach to infer
misalignment in team members' mental models during complex healthcare task
execution. As an exemplary application, we demonstrate our approach using two
simulated team-based scenarios, derived from actual teamwork in cardiac
surgery. In these simulated experiments, our approach inferred model
misalignment with over 75% recall, thereby providing a building block for
enabling computer-assisted interventions to augment human cognition in the
operating room and improve teamwork.
</p>
<a href="http://arxiv.org/abs/2102.08507" target="_blank">arXiv:2102.08507</a> [<a href="http://arxiv.org/pdf/2102.08507" target="_blank">pdf</a>]

<h2>Fast Graph Learning with Unique Optimal Solutions. (arXiv:2102.08530v1 [cs.LG])</h2>
<h3>Sami Abu-El-Haija, Valentino Crespi, Greg Ver Steeg, Aram Galstyan</h3>
<p>Graph Representation Learning (GRL) has been advancing at an unprecedented
rate. However, many results rely on careful design and tuning of architectures,
objectives, and training schemes. We propose efficient GRL methods that
optimize convexified objectives with known closed form solutions. Guaranteed
convergence to a global optimum releases practitioners from hyper-parameter and
architecture tuning. Nevertheless, our proposed method achieves competitive or
state-of-the-art performance on popular GRL tasks while providing orders of
magnitude speedup. Although the design matrix ($\mathbf{M}$) of our objective
is expensive to compute, we exploit results from random matrix theory to
approximate solutions in linear time while avoiding an explicit calculation of
$\mathbf{M}$. Our code is online: this http URL
</p>
<a href="http://arxiv.org/abs/2102.08530" target="_blank">arXiv:2102.08530</a> [<a href="http://arxiv.org/pdf/2102.08530" target="_blank">pdf</a>]

<h2>DeepWalking Backwards: From Embeddings Back to Graphs. (arXiv:2102.08532v1 [cs.LG])</h2>
<h3>Sudhanshu Chanpuriya, Cameron Musco, Konstantinos Sotiropoulos, Charalampos E. Tsourakakis</h3>
<p>Low-dimensional node embeddings play a key role in analyzing graph datasets.
However, little work studies exactly what information is encoded by popular
embedding methods, and how this information correlates with performance in
downstream machine learning tasks. We tackle this question by studying whether
embeddings can be inverted to (approximately) recover the graph used to
generate them. Focusing on a variant of the popular DeepWalk method (Perozzi et
al., 2014; Qiu et al., 2018), we present algorithms for accurate embedding
inversion - i.e., from the low-dimensional embedding of a graph G, we can find
a graph H with a very similar embedding. We perform numerous experiments on
real-world networks, observing that significant information about G, such as
specific edges and bulk properties like triangle density, is often lost in H.
However, community structure is often preserved or even enhanced. Our findings
are a step towards a more rigorous understanding of exactly what information
embeddings encode about the input graph, and why this information is useful for
learning tasks.
</p>
<a href="http://arxiv.org/abs/2102.08532" target="_blank">arXiv:2102.08532</a> [<a href="http://arxiv.org/pdf/2102.08532" target="_blank">pdf</a>]

<h2>StatEcoNet: Statistical Ecology Neural Networks for Species Distribution Modeling. (arXiv:2102.08534v1 [cs.LG])</h2>
<h3>Eugene Seo, Rebecca A. Hutchinson, Xiao Fu, Chelsea Li, Tyler A. Hallman, John Kilbride, W. Douglas Robinson</h3>
<p>This paper focuses on a core task in computational sustainability and
statistical ecology: species distribution modeling (SDM). In SDM, the
occurrence pattern of a species on a landscape is predicted by environmental
features based on observations at a set of locations. At first, SDM may appear
to be a binary classification problem, and one might be inclined to employ
classic tools (e.g., logistic regression, support vector machines, neural
networks) to tackle it. However, wildlife surveys introduce structured noise
(especially under-counting) in the species observations. If unaccounted for,
these observation errors systematically bias SDMs. To address the unique
challenges of SDM, this paper proposes a framework called StatEcoNet.
Specifically, this work employs a graphical generative model in statistical
ecology to serve as the skeleton of the proposed computational framework and
carefully integrates neural networks under the framework. The advantages of
StatEcoNet over related approaches are demonstrated on simulated datasets as
well as bird species data. Since SDMs are critical tools for ecological science
and natural resource management, StatEcoNet may offer boosted computational and
analytical powers to a wide range of applications that have significant social
impacts, e.g., the study and conservation of threatened species.
</p>
<a href="http://arxiv.org/abs/2102.08534" target="_blank">arXiv:2102.08534</a> [<a href="http://arxiv.org/pdf/2102.08534" target="_blank">pdf</a>]

<h2>Separated Proportional-Integral Lagrangian for Chance Constrained Reinforcement Learning. (arXiv:2102.08539v1 [cs.LG])</h2>
<h3>Baiyu Peng, Yao Mu, Jingliang Duan, Yang Guan, Shengbo Eben Li, Jianyu Chen</h3>
<p>Safety is essential for reinforcement learning (RL) applied in real-world
tasks like autonomous driving. Chance constraints which guarantee the
satisfaction of state constraints at a high probability are suitable to
represent the requirements in real-world environment with uncertainty. Existing
chance constrained RL methods like the penalty method and the Lagrangian method
either exhibit periodic oscillations or cannot satisfy the constraints. In this
paper, we address these shortcomings by proposing a separated
proportional-integral Lagrangian (SPIL) algorithm. Taking a control
perspective, we first interpret the penalty method and the Lagrangian method as
proportional feedback and integral feedback control, respectively. Then, a
proportional-integral Lagrangian method is proposed to steady learning process
while improving safety. To prevent integral overshooting and reduce
conservatism, we introduce the integral separation technique inspired by PID
control. Finally, an analytical gradient of the chance constraint is utilized
for model-based policy optimization. The effectiveness of SPIL is demonstrated
by a narrow car-following task. Experiments indicate that compared with
previous methods, SPIL improves the performance while guaranteeing safety, with
a steady learning process.
</p>
<a href="http://arxiv.org/abs/2102.08539" target="_blank">arXiv:2102.08539</a> [<a href="http://arxiv.org/pdf/2102.08539" target="_blank">pdf</a>]

<h2>Active Face Frontalization using Commodity Unmanned Aerial Vehicles. (arXiv:2102.08542v1 [cs.CV])</h2>
<h3>Nagashri Lakshminarayana, Yifang Liu, Karthik Dantu, Venu Govindaraju, Nils Napp</h3>
<p>This paper describes a system by which Unmanned Aerial Vehicles (UAVs) can
gather high-quality face images that can be used in biometric identification
tasks. Success in face-based identification depends in large part on the image
quality, and a major factor is how frontal the view is. Face recognition
software pipelines can improve identification rates by synthesizing frontal
views from non-frontal views by a process call {\em frontalization}. Here we
exploit the high mobility of UAVs to actively gather frontal images using
components of a synthetic frontalization pipeline. We define a frontalization
error and show that it can be used to guide an UAVs to capture frontal views.
Further, we show that the resulting image stream improves matching quality of a
typical face recognition similarity metric. The system is implemented using an
off-the-shelf hardware and software components and can be easily transfered to
any ROS enabled UAVs.
</p>
<a href="http://arxiv.org/abs/2102.08542" target="_blank">arXiv:2102.08542</a> [<a href="http://arxiv.org/pdf/2102.08542" target="_blank">pdf</a>]

<h2>Robust Estimation of Tree Structured Markov Random Fields. (arXiv:2102.08554v1 [stat.ML])</h2>
<h3>Ashish Katiyar, Soumya Basu, Vatsal Shah, Constantine Caramanis</h3>
<p>We study the problem of learning tree-structured Markov random fields (MRF)
on discrete random variables with common support when the observations are
corrupted by unknown noise. As the presence of noise in the observations
obfuscates the original tree structure, the extent of recoverability of the
tree-structured MRFs under noisy observations is brought into question.

We show that in a general noise model, the underlying tree structure can be
recovered only up to an equivalence class where each of the leaf nodes is
indistinguishable from its parent and siblings, forming a leaf cluster. As the
indistinguishability arises due to contrived noise models, we study the natural
k-ary symmetric channel noise model where the value of each node is changed to
a uniform value in the support with an unequal and unknown probability. Here,
the answer becomes much more nuanced. We show that with a support size of 2,
and the binary symmetric channel noise model, the leaf clusters remain
indistinguishable. From support size 3 and up, the recoverability of a leaf
cluster is dictated by the joint probability mass function of the nodes within
it. We provide a precise characterization of recoverability by deriving a
necessary and sufficient condition for the recoverability of a leaf cluster. We
provide an algorithm that recovers the tree if this condition is satisfied, and
recovers the tree up to the leaf clusters failing this condition.
</p>
<a href="http://arxiv.org/abs/2102.08554" target="_blank">arXiv:2102.08554</a> [<a href="http://arxiv.org/pdf/2102.08554" target="_blank">pdf</a>]

<h2>Re-identification of Individuals in Genomic Datasets Using Public Face Images. (arXiv:2102.08557v1 [cs.LG])</h2>
<h3>Rajagopal Venkatesaramani, Bradley A. Malin, Yevgeniy Vorobeychik</h3>
<p>DNA sequencing is becoming increasingly commonplace, both in medical and
direct-to-consumer settings. To promote discovery, collected genomic data is
often de-identified and shared, either in public repositories, such as OpenSNP,
or with researchers through access-controlled repositories. However, recent
studies have suggested that genomic data can be effectively matched to
high-resolution three-dimensional face images, which raises a concern that the
increasingly ubiquitous public face images can be linked to shared genomic
data, thereby re-identifying individuals in the genomic data. While these
investigations illustrate the possibility of such an attack, they assume that
those performing the linkage have access to extremely well-curated data. Given
that this is unlikely to be the case in practice, it calls into question the
pragmatic nature of the attack. As such, we systematically study this
re-identification risk from two perspectives: first, we investigate how
successful such linkage attacks can be when real face images are used, and
second, we consider how we can empower individuals to have better control over
the associated re-identification risk. We observe that the true risk of
re-identification is likely substantially smaller for most individuals than
prior literature suggests. In addition, we demonstrate that the addition of a
small amount of carefully crafted noise to images can enable a controlled
trade-off between re-identification success and the quality of shared images,
with risk typically significantly lowered even with noise that is imperceptible
to humans.
</p>
<a href="http://arxiv.org/abs/2102.08557" target="_blank">arXiv:2102.08557</a> [<a href="http://arxiv.org/pdf/2102.08557" target="_blank">pdf</a>]

<h2>Mode-Assisted Joint Training of Deep Boltzmann Machines. (arXiv:2102.08562v1 [cs.LG])</h2>
<h3>Haik Manukian, Massimiliano Di Ventra</h3>
<p>The deep extension of the restricted Boltzmann machine (RBM), known as the
deep Boltzmann machine (DBM), is an expressive family of machine learning
models which can serve as compact representations of complex probability
distributions. However, jointly training DBMs in the unsupervised setting has
proven to be a formidable task. A recent technique we have proposed, called
mode-assisted training, has shown great success in improving the unsupervised
training of RBMs. Here, we show that the performance gains of the mode-assisted
training are even more dramatic for DBMs. In fact, DBMs jointly trained with
the mode-assisted algorithm can represent the same data set with orders of
magnitude lower number of total parameters compared to state-of-the-art
training procedures and even with respect to RBMs, provided a fan-in network
topology is also introduced. This substantial saving in number of parameters
makes this training method very appealing also for hardware implementations.
</p>
<a href="http://arxiv.org/abs/2102.08562" target="_blank">arXiv:2102.08562</a> [<a href="http://arxiv.org/pdf/2102.08562" target="_blank">pdf</a>]

<h2>Ensemble Transfer Learning of Elastography and B-mode Breast Ultrasound Images. (arXiv:2102.08567v1 [cs.CV])</h2>
<h3>Sampa Misra, Seungwan Jeon, Ravi Managuli, Seiyon Lee, Gyuwon Kim, Seungchul Lee, Richard G Barr, Chulhong Kim</h3>
<p>Computer-aided detection (CAD) of benign and malignant breast lesions becomes
increasingly essential in breast ultrasound (US) imaging. The CAD systems rely
on imaging features identified by the medical experts for their performance,
whereas deep learning (DL) methods automatically extract features from the
data. The challenge of the DL is the insufficiency of breast US images
available to train the DL models. Here, we present an ensemble transfer
learning model to classify benign and malignant breast tumors using B-mode
breast US (B-US) and strain elastography breast US (SE-US) images. This model
combines semantic features from AlexNet &amp; ResNet models to classify benign from
malignant tumors. We use both B-US and SE-US images to train the model and
classify the tumors. We retrospectively gathered 85 patients' data, with 42
benign and 43 malignant cases confirmed with the biopsy. Each patient had
multiple B-US and their corresponding SE-US images, and the total dataset
contained 261 B-US images and 261 SE-US images. Experimental results show that
our ensemble model achieves a sensitivity of 88.89% and specificity of 91.10%.
These diagnostic performances of the proposed method are equivalent to or
better than manual identification. Thus, our proposed ensemble learning method
would facilitate detecting early breast cancer, reliably improving patient
care.
</p>
<a href="http://arxiv.org/abs/2102.08567" target="_blank">arXiv:2102.08567</a> [<a href="http://arxiv.org/pdf/2102.08567" target="_blank">pdf</a>]

<h2>Outside the Echo Chamber: Optimizing the Performative Risk. (arXiv:2102.08570v1 [cs.LG])</h2>
<h3>John Miller, Juan C. Perdomo, Tijana Zrnic</h3>
<p>In performative prediction, predictions guide decision-making and hence can
influence the distribution of future data. To date, work on performative
prediction has focused on finding performatively stable models, which are the
fixed points of repeated retraining. However, stable solutions can be far from
optimal when evaluated in terms of the performative risk, the loss experienced
by the decision maker when deploying a model. In this paper, we shift attention
beyond performative stability and focus on optimizing the performative risk
directly. We identify a natural set of properties of the loss function and
model-induced distribution shift under which the performative risk is convex, a
property which does not follow from convexity of the loss alone. Furthermore,
we develop algorithms that leverage our structural assumptions to optimize the
performative risk with better sample efficiency than generic methods for
derivative-free convex optimization.
</p>
<a href="http://arxiv.org/abs/2102.08570" target="_blank">arXiv:2102.08570</a> [<a href="http://arxiv.org/pdf/2102.08570" target="_blank">pdf</a>]

<h2>Firefly Neural Architecture Descent: a General Approach for Growing Neural Networks. (arXiv:2102.08574v1 [cs.LG])</h2>
<h3>Lemeng Wu, Bo Liu, Peter Stone, Qiang Liu</h3>
<p>We propose firefly neural architecture descent, a general framework for
progressively and dynamically growing neural networks to jointly optimize the
networks' parameters and architectures. Our method works in a steepest descent
fashion, which iteratively finds the best network within a functional
neighborhood of the original network that includes a diverse set of candidate
network structures. By using Taylor approximation, the optimal network
structure in the neighborhood can be found with a greedy selection procedure.
We show that firefly descent can flexibly grow networks both wider and deeper,
and can be applied to learn accurate but resource-efficient neural
architectures that avoid catastrophic forgetting in continual learning.
Empirically, firefly descent achieves promising results on both neural
architecture search and continual learning. In particular, on a challenging
continual image classification task, it learns networks that are smaller in
size but have higher average accuracy than those learned by the
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.08574" target="_blank">arXiv:2102.08574</a> [<a href="http://arxiv.org/pdf/2102.08574" target="_blank">pdf</a>]

<h2>DO-GAN: A Double Oracle Framework for Generative Adversarial Networks. (arXiv:2102.08577v1 [cs.LG])</h2>
<h3>Aye Phyu Phyu Aung, Xinrun Wang, Runsheng Yu, Bo An, Senthilnath Jayavelu, Xiaoli Li</h3>
<p>In this paper, we propose a new approach to train Generative Adversarial
Networks (GANs) where we deploy a double-oracle framework using the generator
and discriminator oracles. GAN is essentially a two-player zero-sum game
between the generator and the discriminator. Training GANs is challenging as a
pure Nash equilibrium may not exist and even finding the mixed Nash equilibrium
is difficult as GANs have a large-scale strategy space. In DO-GAN, we extend
the double oracle framework to GANs. We first generalize the players'
strategies as the trained models of generator and discriminator from the best
response oracles. We then compute the meta-strategies using a linear program.
For scalability of the framework where multiple generators and discriminator
best responses are stored in the memory, we propose two solutions: 1) pruning
the weakly-dominated players' strategies to keep the oracles from becoming
intractable; 2) applying continual learning to retain the previous knowledge of
the networks. We apply our framework to established GAN architectures such as
vanilla GAN, Deep Convolutional GAN, Spectral Normalization GAN and Stacked
GAN. Finally, we conduct experiments on MNIST, CIFAR-10 and CelebA datasets and
show that DO-GAN variants have significant improvements in both subjective
qualitative evaluation and quantitative metrics, compared with their respective
GAN architectures.
</p>
<a href="http://arxiv.org/abs/2102.08577" target="_blank">arXiv:2102.08577</a> [<a href="http://arxiv.org/pdf/2102.08577" target="_blank">pdf</a>]

<h2>Time Matters in Using Data Augmentation for Vision-based Deep Reinforcement Learning. (arXiv:2102.08581v1 [cs.LG])</h2>
<h3>Byungchan Ko, Jungseul Ok</h3>
<p>Data augmentation technique from computer vision has been widely considered
as a regularization method to improve data efficiency and generalization
performance in vision-based reinforcement learning. We variate the timing of
using augmentation, which is, in turn, critical depending on tasks to be solved
in training and testing. According to our experiments on Open AI Procgen
Benchmark, if the regularization imposed by augmentation is helpful only in
testing, it is better to procrastinate the augmentation after training than to
use it during training in terms of sample and computation complexity. We note
that some of such augmentations can disturb the training process. Conversely,
an augmentation providing regularization useful in training needs to be used
during the whole training period to fully utilize its benefit in terms of not
only generalization but also data efficiency. These phenomena suggest a useful
timing control of data augmentation in reinforcement learning.
</p>
<a href="http://arxiv.org/abs/2102.08581" target="_blank">arXiv:2102.08581</a> [<a href="http://arxiv.org/pdf/2102.08581" target="_blank">pdf</a>]

<h2>NODE-SELECT: A Graph Neural Network Based On A Selective Propagation Technique. (arXiv:2102.08588v1 [cs.LG])</h2>
<h3>Steph-Yves Louis, Alireza Nasiri, Fatima J. Rolland, Cameron Mitro, Jianjun Hu</h3>
<p>While there exists a wide variety of graph neural networks (GNN) for node
classification, only a minority of them adopt mechanisms that effectively
target noise propagation during the message-passing procedure. Additionally, a
very important challenge that significantly affects graph neural networks is
the issue of scalability which limits their application to larger graphs. In
this paper we propose our method named NODE-SELECT: an efficient graph neural
network that uses subsetting layers which only allow the best sharing-fitting
nodes to propagate their information. By having a selection mechanism within
each layer which we stack in parallel, our proposed method NODE-SELECT is able
to both reduce the amount noise propagated and adapt the restrictive sharing
concept observed in real world graphs. Our NODE-SELECT significantly
outperformed existing GNN frameworks in noise experiments and matched
state-of-the art results in experiments without noise over different benchmark
datasets.
</p>
<a href="http://arxiv.org/abs/2102.08588" target="_blank">arXiv:2102.08588</a> [<a href="http://arxiv.org/pdf/2102.08588" target="_blank">pdf</a>]

<h2>Consistent Right-Invariant Fixed-Lag Smoother with Application to Visual Inertial SLAM. (arXiv:2102.08596v1 [cs.RO])</h2>
<h3>Jianzhu Huai, Yukai Lin, Yuan Zhuang, Min Shi</h3>
<p>State estimation problems that use relative observations routinely arise in
navigation of unmanned aerial vehicles, autonomous ground vehicles, \etc whose
proper operation relies on accurate state estimates and reliable covariances.
These problems have immanent unobservable directions. Traditional causal
estimators, however, usually gain spurious information on the unobservable
directions, leading to over confident covariance inconsistent with the actual
estimator errors. The consistency problem of fixed-lag smoothers (FLSs) has
only been attacked by the first estimate Jacobian (FEJ) technique because of
the complexity to analyze their observability property. But the FEJ has several
drawbacks hampering its wide adoption. To ensure the consistency of a FLS, this
paper introduces the right invariant error formulation into the FLS framework.
To our knowledge, we are the first to analyze the observability of a FLS with
the right invariant error. Our main contributions are twofold. As the first
novelty, to bypass the complexity of analysis with the classic observability
matrix, we show that observability analysis of FLSs can be done equivalently on
the linearized system. Second, we prove that the inconsistency issue in the
traditional FLS can be elegantly solved by the right invariant error
formulation without artificially correcting Jacobians. By applying the proposed
FLS to the monocular visual inertial simultaneous localization and mapping
(SLAM) problem, we confirm that the method consistently estimates covariance
similarly to a batch smoother in simulation and that our method achieved
comparable accuracy as traditional FLSs on real data.
</p>
<a href="http://arxiv.org/abs/2102.08596" target="_blank">arXiv:2102.08596</a> [<a href="http://arxiv.org/pdf/2102.08596" target="_blank">pdf</a>]

<h2>Beyond Fully-Connected Layers with Quaternions: Parameterization of Hypercomplex Multiplications with $1/n$ Parameters. (arXiv:2102.08597v1 [cs.LG])</h2>
<h3>Aston Zhang, Yi Tay, Shuai Zhang, Alvin Chan, Anh Tuan Luu, Siu Cheung Hui, Jie Fu</h3>
<p>Recent works have demonstrated reasonable success of representation learning
in hypercomplex space. Specifically, "fully-connected layers with Quaternions"
(4D hypercomplex numbers), which replace real-valued matrix multiplications in
fully-connected layers with Hamilton products of Quaternions, both enjoy
parameter savings with only 1/4 learnable parameters and achieve comparable
performance in various applications. However, one key caveat is that
hypercomplex space only exists at very few predefined dimensions (4D, 8D, and
16D). This restricts the flexibility of models that leverage hypercomplex
multiplications. To this end, we propose parameterizing hypercomplex
multiplications, allowing models to learn multiplication rules from data
regardless of whether such rules are predefined. As a result, our method not
only subsumes the Hamilton product, but also learns to operate on any arbitrary
nD hypercomplex space, providing more architectural flexibility using
arbitrarily $1/n$ learnable parameters compared with the fully-connected layer
counterpart. Experiments of applications to the LSTM and Transformer models on
natural language inference, machine translation, text style transfer, and
subject verb agreement demonstrate architectural flexibility and effectiveness
of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2102.08597" target="_blank">arXiv:2102.08597</a> [<a href="http://arxiv.org/pdf/2102.08597" target="_blank">pdf</a>]

<h2>Leveraging Public Data for Practical Private Query Release. (arXiv:2102.08598v1 [cs.LG])</h2>
<h3>Terrance Liu, Giuseppe Vietri, Thomas Steinke, Jonathan Ullman, Zhiwei Steven Wu</h3>
<p>In many statistical problems, incorporating priors can significantly improve
performance. However, the use of prior knowledge in differentially private
query release has remained underexplored, despite such priors commonly being
available in the form of public datasets, such as previous US Census releases.
With the goal of releasing statistics about a private dataset, we present
PMW^Pub, which -- unlike existing baselines -- leverages public data drawn from
a related distribution as prior information. We provide a theoretical analysis
and an empirical evaluation on the American Community Survey (ACS) and ADULT
datasets, which shows that our method outperforms state-of-the-art methods.
Furthermore, PMW^Pub scales well to high-dimensional data domains, where
running many existing methods would be computationally infeasible.
</p>
<a href="http://arxiv.org/abs/2102.08598" target="_blank">arXiv:2102.08598</a> [<a href="http://arxiv.org/pdf/2102.08598" target="_blank">pdf</a>]

<h2>LambdaNetworks: Modeling Long-Range Interactions Without Attention. (arXiv:2102.08602v1 [cs.CV])</h2>
<h3>Irwan Bello</h3>
<p>We present lambda layers -- an alternative framework to self-attention -- for
capturing long-range interactions between an input and structured contextual
information (e.g. a pixel surrounded by other pixels). Lambda layers capture
such interactions by transforming available contexts into linear functions,
termed lambdas, and applying these linear functions to each input separately.
Similar to linear attention, lambda layers bypass expensive attention maps, but
in contrast, they model both content and position-based interactions which
enables their application to large structured inputs such as images. The
resulting neural network architectures, LambdaNetworks, significantly
outperform their convolutional and attentional counterparts on ImageNet
classification, COCO object detection and COCO instance segmentation, while
being more computationally efficient. Additionally, we design LambdaResNets, a
family of hybrid architectures across different scales, that considerably
improves the speed-accuracy tradeoff of image classification models.
LambdaResNets reach excellent accuracies on ImageNet while being 3.2 - 4.4x
faster than the popular EfficientNets on modern machine learning accelerators.
When training with an additional 130M pseudo-labeled images, LambdaResNets
achieve up to a 9.5x speed-up over the corresponding EfficientNet checkpoints.
</p>
<a href="http://arxiv.org/abs/2102.08602" target="_blank">arXiv:2102.08602</a> [<a href="http://arxiv.org/pdf/2102.08602" target="_blank">pdf</a>]

<h2>Domain Generalization Needs Stochastic Weight Averaging for Robustness on Domain Shifts. (arXiv:2102.08604v1 [cs.LG])</h2>
<h3>Junbum Cha, Hancheol Cho, Kyungjae Lee, Seunghyun Park, Yunsung Lee, Sungrae Park</h3>
<p>Domain generalization aims to learn a generalizable model to unseen target
domains from multiple source domains. Various approaches have been proposed to
address this problem. However, recent benchmarks show that most of them do not
provide significant improvements compared to the simple empirical risk
minimization (ERM) in practical cases. In this paper, we analyze how ERM works
in views of domain-invariant feature learning and domain-specific gradient
normalization. In addition, we observe that ERM converges to a loss valley
shared over multiple training domains and obtain an insight that a center of
the valley generalizes better. To estimate the center, we employ stochastic
weight averaging (SWA) and provide theoretical analysis describing how SWA
supports the generalization bound for an unseen domain. As a result, we achieve
state-of-the-art performances over all of widely used domain generalization
benchmarks, namely PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet with
large margins. Further analysis reveals how SWA operates on domain
generalization tasks.
</p>
<a href="http://arxiv.org/abs/2102.08604" target="_blank">arXiv:2102.08604</a> [<a href="http://arxiv.org/pdf/2102.08604" target="_blank">pdf</a>]

<h2>Centroid Transformers: Learning to Abstract with Attention. (arXiv:2102.08606v1 [cs.LG])</h2>
<h3>Lemeng Wu, Xingchao Liu, Qiang Liu</h3>
<p>Self-attention, as the key block of transformers, is a powerful mechanism for
extracting features from the inputs. In essence, what self-attention does to
infer the pairwise relations between the elements of the inputs, and modify the
inputs by propagating information between input pairs. As a result, it maps
inputs to N outputs and casts a quadratic $O(N^2)$ memory and time complexity.
We propose centroid attention, a generalization of self-attention that maps N
inputs to M outputs $(M\leq N)$, such that the key information in the inputs
are summarized in the smaller number of outputs (called centroids). We design
centroid attention by amortizing the gradient descent update rule of a
clustering objective function on the inputs, which reveals an underlying
connection between attention and clustering. By compressing the inputs to the
centroids, we extract the key information useful for prediction and also reduce
the computation of the attention module and the subsequent layers. We apply our
method to various applications, including abstractive text summarization, 3D
vision, and image processing. Empirical results demonstrate the effectiveness
of our method over the standard transformers.
</p>
<a href="http://arxiv.org/abs/2102.08606" target="_blank">arXiv:2102.08606</a> [<a href="http://arxiv.org/pdf/2102.08606" target="_blank">pdf</a>]

<h2>On the Convergence and Sample Efficiency of Variance-Reduced Policy Gradient Method. (arXiv:2102.08607v1 [cs.LG])</h2>
<h3>Junyu Zhang, Chengzhuo Ni, Zheng Yu, Csaba Szepesvari, Mengdi Wang</h3>
<p>Policy gradient gives rise to a rich class of reinforcement learning (RL)
methods, for example the REINFORCE. Yet the best known sample complexity result
for such methods to find an $\epsilon$-optimal policy is
$\mathcal{O}(\epsilon^{-3})$, which is suboptimal. In this paper, we study the
fundamental convergence properties and sample efficiency of first-order policy
optimization method. We focus on a generalized variant of policy gradient
method, which is able to maximize not only a cumulative sum of rewards but also
a general utility function over a policy's long-term visiting distribution. By
exploiting the problem's hidden convex nature and leveraging techniques from
composition optimization, we propose a Stochastic Incremental Variance-Reduced
Policy Gradient (SIVR-PG) approach that improves a sequence of policies to
provably converge to the global optimal solution and finds an
$\epsilon$-optimal policy using $\tilde{\mathcal{O}}(\epsilon^{-2})$ samples.
</p>
<a href="http://arxiv.org/abs/2102.08607" target="_blank">arXiv:2102.08607</a> [<a href="http://arxiv.org/pdf/2102.08607" target="_blank">pdf</a>]

<h2>Rethinking Co-design of Neural Architectures and Hardware Accelerators. (arXiv:2102.08619v1 [cs.LG])</h2>
<h3>Yanqi Zhou, Xuanyi Dong, Berkin Akin, Mingxing Tan, Daiyi Peng, Tianjian Meng, Amir Yazdanbakhsh, Da Huang, Ravi Narayanaswami, James Laudon</h3>
<p>Neural architectures and hardware accelerators have been two driving forces
for the progress in deep learning. Previous works typically attempt to optimize
hardware given a fixed model architecture or model architecture given fixed
hardware. And the dominant hardware architecture explored in this prior work is
FPGAs. In our work, we target the optimization of hardware and software
configurations on an industry-standard edge accelerator. We systematically
study the importance and strategies of co-designing neural architectures and
hardware accelerators. We make three observations: 1) the software search space
has to be customized to fully leverage the targeted hardware architecture, 2)
the search for the model architecture and hardware architecture should be done
jointly to achieve the best of both worlds, and 3) different use cases lead to
very different search outcomes. Our experiments show that the joint search
method consistently outperforms previous platform-aware neural architecture
search, manually crafted models, and the state-of-the-art EfficientNet on all
latency targets by around 1% on ImageNet top-1 accuracy. Our method can reduce
energy consumption of an edge accelerator by up to 2x under the same accuracy
constraint, when co-adapting the model architecture and hardware accelerator
configurations.
</p>
<a href="http://arxiv.org/abs/2102.08619" target="_blank">arXiv:2102.08619</a> [<a href="http://arxiv.org/pdf/2102.08619" target="_blank">pdf</a>]

<h2>Sinkhorn Label Allocation: Semi-Supervised Classification via Annealed Self-Training. (arXiv:2102.08622v1 [cs.LG])</h2>
<h3>Kai Sheng Tai, Peter Bailis, Gregory Valiant</h3>
<p>Self-training is a standard approach to semi-supervised learning where the
learner's own predictions on unlabeled data are used as supervision during
training. In this paper, we reinterpret this label assignment process as an
optimal transportation problem between examples and classes, wherein the cost
of assigning an example to a class is mediated by the current predictions of
the classifier. This formulation facilitates a practical annealing strategy for
label assignment and allows for the inclusion of prior knowledge on class
proportions via flexible upper bound constraints. The solutions to these
assignment problems can be efficiently approximated using Sinkhorn iteration,
thus enabling their use in the inner loop of standard stochastic optimization
algorithms. We demonstrate the effectiveness of our algorithm on the CIFAR-10,
CIFAR-100, and SVHN datasets in comparison with FixMatch, a state-of-the-art
self-training algorithm. Additionally, we elucidate connections between our
proposed algorithm and existing confidence thresholded self-training approaches
in the context of homotopy methods in optimization. Our code is available at
https://github.com/stanford-futuredata/sinkhorn-label-allocation.
</p>
<a href="http://arxiv.org/abs/2102.08622" target="_blank">arXiv:2102.08622</a> [<a href="http://arxiv.org/pdf/2102.08622" target="_blank">pdf</a>]

<h2>Knowledge discovery from emergency ambulance dispatch during COVID-19: A case study of Nagoya City, Japan. (arXiv:2102.08628v1 [cs.AI])</h2>
<h3>Essam A. Rashed, Sachiko Kodera, Hidenobu Shirakami, Ryotetsu Kawaguchi, Kazuhiro Watanabe, Akimasa Hirata</h3>
<p>Accurate forecasting of medical service requirements is an important big data
problem that is crucial for resource management in critical times such as
natural disasters and pandemics. With the global spread of coronavirus disease
2019 (COVID-19), several concerns have been raised regarding the ability of
medical systems to handle sudden changes in the daily routines of healthcare
providers. One significant problem is the management of ambulance dispatch and
control during a pandemic. To help address this problem, we first analyze
ambulance dispatch data records from April 2014 to August 2020 for Nagoya City,
Japan. Significant changes were observed in the data during the pandemic,
including the state of emergency (SoE) declared across Japan. In this study, we
propose a deep learning framework based on recurrent neural networks to
estimate the number of emergency ambulance dispatches (EADs) during a SoE. The
fusion of data includes environmental factors, the localization data of mobile
phone users, and the past history of EADs, thereby providing a general
framework for knowledge discovery and better resource management. The results
indicate that the proposed blend of training data can be used efficiently in a
real-world estimation of EAD requirements during periods of high uncertainties
such as pandemics.
</p>
<a href="http://arxiv.org/abs/2102.08628" target="_blank">arXiv:2102.08628</a> [<a href="http://arxiv.org/pdf/2102.08628" target="_blank">pdf</a>]

<h2>A Safety and Passivity Filter for Robot Teleoperation Systems. (arXiv:2102.08630v1 [cs.RO])</h2>
<h3>Gennaro Notomista, Xiaoyi Cai</h3>
<p>In this paper, we present a way of enforcing safety and passivity properties
of robot teleoperation systems, where a human operator interacts with a
dynamical system modeling the robot. The approach does so in a holistic
fashion, by combining safety and passivity constraints in a single
optimization-based controller which effectively filters the desired control
input before supplying it to the system. The result is a safety and passivity
filter implemented as a convex quadratic program which can be solved
efficiently and employed in an online fashion in many robotic teleoperation
applications. Simulation results show the benefits of the approach developed in
this paper applied to the human teleoperation of a second-order dynamical
system.
</p>
<a href="http://arxiv.org/abs/2102.08630" target="_blank">arXiv:2102.08630</a> [<a href="http://arxiv.org/pdf/2102.08630" target="_blank">pdf</a>]

<h2>On the Post-hoc Explainability of Deep Echo State Networks for Time Series Forecasting, Image and Video Classification. (arXiv:2102.08634v1 [cs.LG])</h2>
<h3>Alejandro Barredo Arrieta, Sergio Gil-Lopez, Ibai La&#xf1;a, Miren Nekane Bilbao, Javier Del Ser</h3>
<p>Since their inception, learning techniques under the Reservoir Computing
paradigm have shown a great modeling capability for recurrent systems without
the computing overheads required for other approaches. Among them, different
flavors of echo state networks have attracted many stares through time, mainly
due to the simplicity and computational efficiency of their learning algorithm.
However, these advantages do not compensate for the fact that echo state
networks remain as black-box models whose decisions cannot be easily explained
to the general audience. This work addresses this issue by conducting an
explainability study of Echo State Networks when applied to learning tasks with
time series, image and video data. Specifically, the study proposes three
different techniques capable of eliciting understandable information about the
knowledge grasped by these recurrent models, namely, potential memory, temporal
patterns and pixel absence effect. Potential memory addresses questions related
to the effect of the reservoir size in the capability of the model to store
temporal information, whereas temporal patterns unveils the recurrent
relationships captured by the model over time. Finally, pixel absence effect
attempts at evaluating the effect of the absence of a given pixel when the echo
state network model is used for image and video classification. We showcase the
benefits of our proposed suite of techniques over three different domains of
applicability: time series modeling, image and, for the first time in the
related literature, video classification. Our results reveal that the proposed
techniques not only allow for a informed understanding of the way these models
work, but also serve as diagnostic tools capable of detecting issues inherited
from data (e.g. presence of hidden bias).
</p>
<a href="http://arxiv.org/abs/2102.08634" target="_blank">arXiv:2102.08634</a> [<a href="http://arxiv.org/pdf/2102.08634" target="_blank">pdf</a>]

<h2>Coupled Feature Learning for Multimodal Medical Image Fusion. (arXiv:2102.08641v1 [cs.CV])</h2>
<h3>Farshad G. Veshki, Nora Ouzir, Sergiy A. Vorobyov, Esa Ollila</h3>
<p>Multimodal image fusion aims to combine relevant information from images
acquired with different sensors. In medical imaging, fused images play an
essential role in both standard and automated diagnosis. In this paper, we
propose a novel multimodal image fusion method based on coupled dictionary
learning. The proposed method is general and can be employed for different
medical imaging modalities. Unlike many current medical fusion methods, the
proposed approach does not suffer from intensity attenuation nor loss of
critical information. Specifically, the images to be fused are decomposed into
coupled and independent components estimated using sparse representations with
identical supports and a Pearson correlation constraint, respectively. An
alternating minimization algorithm is designed to solve the resulting
optimization problem. The final fusion step uses the max-absolute-value rule.
Experiments are conducted using various pairs of multimodal inputs, including
real MR-CT and MR-PET images. The resulting performance and execution times
show the competitiveness of the proposed method in comparison with
state-of-the-art medical image fusion methods.
</p>
<a href="http://arxiv.org/abs/2102.08641" target="_blank">arXiv:2102.08641</a> [<a href="http://arxiv.org/pdf/2102.08641" target="_blank">pdf</a>]

<h2>Temporal Memory Attention for Video Semantic Segmentation. (arXiv:2102.08643v1 [cs.CV])</h2>
<h3>Hao Wang, Weining Wang, Jing Liu</h3>
<p>Video semantic segmentation requires to utilize the complex temporal
relations between frames of the video sequence. Previous works usually exploit
accurate optical flow to leverage the temporal relations, which suffer much
from heavy computational cost. In this paper, we propose a Temporal Memory
Attention Network (TMANet) to adaptively integrate the long-range temporal
relations over the video sequence based on the self-attention mechanism without
exhaustive optical flow prediction. Specially, we construct a memory using
several past frames to store the temporal information of the current frame. We
then propose a temporal memory attention module to capture the relation between
the current frame and the memory to enhance the representation of the current
frame. Our method achieves new state-of-the-art performances on two challenging
video semantic segmentation datasets, particularly 80.3% mIoU on Cityscapes and
76.5% mIoU on CamVid with ResNet-50.
</p>
<a href="http://arxiv.org/abs/2102.08643" target="_blank">arXiv:2102.08643</a> [<a href="http://arxiv.org/pdf/2102.08643" target="_blank">pdf</a>]

<h2>A General Framework for the Derandomization of PAC-Bayesian Bounds. (arXiv:2102.08649v1 [stat.ML])</h2>
<h3>Paul Viallard (LHC), Pascal Germain, Amaury Habrard (LHC), Emilie Morvant (LHC)</h3>
<p>PAC-Bayesian bounds are known to be tight and informative when studying the
generalization ability of randomized classifiers. However, when applied to some
family of deterministic models such as neural networks, they require a loose
and costly derandomization step. As an alternative to this step, we introduce
three new PAC-Bayesian generalization bounds that have the originality to be
pointwise, meaning that they provide guarantees over one single hypothesis
instead of the usual averaged analysis. Our bounds are rather general,
potentially parameterizable, and provide novel insights for various machine
learning settings that rely on randomized algorithms. We illustrate the
interest of our theoretical result for the analysis of neural network training.
</p>
<a href="http://arxiv.org/abs/2102.08649" target="_blank">arXiv:2102.08649</a> [<a href="http://arxiv.org/pdf/2102.08649" target="_blank">pdf</a>]

<h2>Unbiased Estimations based on Binary Classifiers: A Maximum Likelihood Approach. (arXiv:2102.08659v1 [stat.ML])</h2>
<h3>Marco J.H. Puts, Piet J.H. Daas</h3>
<p>Binary classifiers trained on a certain proportion of positive items
introduce a bias when applied to data sets with different proportions of
positive items. Most solutions for dealing with this issue assume that some
information on the latter distribution is known. However, this is not always
the case, certainly when this proportion is the target variable. In this paper
a maximum likelihood estimator for the true proportion of positives in data
sets is suggested and tested on synthetic and real world data.
</p>
<a href="http://arxiv.org/abs/2102.08659" target="_blank">arXiv:2102.08659</a> [<a href="http://arxiv.org/pdf/2102.08659" target="_blank">pdf</a>]

<h2>Preventing Posterior Collapse Induced by Oversmoothing in Gaussian VAE. (arXiv:2102.08663v1 [cs.LG])</h2>
<h3>Yuhta Takida, Wei-Hsiang Liao, Toshimitsu Uesaka, Shusuke Takahashi, Yuki Mitsufuji</h3>
<p>Variational autoencoders (VAEs) often suffer from posterior collapse, which
is a phenomenon in which the learned latent space becomes uninformative. This
is often related to a hyperparameter resembling the data variance. It can be
shown that an inappropriate choice of this parameter causes oversmoothness and
leads to posterior collapse in the linearly approximated case and can be
empirically verified for the general cases. Therefore, we propose AR-ELBO
(Adaptively Regularized Evidence Lower BOund), which controls the smoothness of
the model by adapting this variance parameter. In addition, we extend VAE with
alternative parameterizations on the variance parameter to deal with
non-uniform or conditional data variance. The proposed VAE extensions trained
with AR-ELBO show improved Fr\'echet inception distance (FID) on images
generated from the MNIST and CelebA datasets.
</p>
<a href="http://arxiv.org/abs/2102.08663" target="_blank">arXiv:2102.08663</a> [<a href="http://arxiv.org/pdf/2102.08663" target="_blank">pdf</a>]

<h2>Cardiac Motion Modeling with Parallel Transport and Shape Splines. (arXiv:2102.08665v1 [cs.CV])</h2>
<h3>Nicolas Guigui (UCA, EPIONE), Pamela Moceri (URRIS UR2CA), Maxime Sermesant (UCA, EPIONE), Xavier Pennec (UCA, EPIONE)</h3>
<p>In cases of pressure or volume overload, probing cardiac function may be
difficult because of the interactions between shape and deformations.In this
work, we use the LDDMM framework and parallel transport to estimate and
reorient deformations of the right ventricle. We then propose a normalization
procedure for the amplitude of the deformation, and a second-order spline model
to represent the full cardiac contraction. The method is applied to 3D meshes
of the right ventricle extracted from echocardiographic sequences of 314
patients divided into three disease categories and a control group. We find
significant differences between pathologies in the model parameters, revealing
insights into the dynamics of each disease.
</p>
<a href="http://arxiv.org/abs/2102.08665" target="_blank">arXiv:2102.08665</a> [<a href="http://arxiv.org/pdf/2102.08665" target="_blank">pdf</a>]

<h2>Fully General Online Imitation Learning. (arXiv:2102.08686v1 [cs.LG])</h2>
<h3>Michael K. Cohen, Marcus Hutter, Neel Nanda</h3>
<p>In imitation learning, imitators and demonstrators are policies for picking
actions given past interactions with the environment. If we run an imitator, we
probably want events to unfold similarly to the way they would have if the
demonstrator had been acting the whole time. No existing work provides formal
guidance in how this might be accomplished, instead restricting focus to
environments that restart, making learning unusually easy, and conveniently
limiting the significance of any mistake. We address a fully general setting,
in which the (stochastic) environment and demonstrator never reset, not even
for training purposes. Our new conservative Bayesian imitation learner
underestimates the probabilities of each available action, and queries for more
data with the remaining probability. Our main result: if an event would have
been unlikely had the demonstrator acted the whole time, that event's
likelihood can be bounded above when running the (initially totally ignorant)
imitator instead. Meanwhile, queries to the demonstrator rapidly diminish in
frequency.
</p>
<a href="http://arxiv.org/abs/2102.08686" target="_blank">arXiv:2102.08686</a> [<a href="http://arxiv.org/pdf/2102.08686" target="_blank">pdf</a>]

<h2>Switch Spaces: Learning Product Spaces with Sparse Gating. (arXiv:2102.08688v1 [cs.LG])</h2>
<h3>Shuai Zhang, Yi Tay, Wenqi Jiang, Da-cheng Juan, Ce Zhang</h3>
<p>Learning embedding spaces of suitable geometry is critical for representation
learning. In order for learned representations to be effective and efficient,
it is ideal that the geometric inductive bias aligns well with the underlying
structure of the data. In this paper, we propose Switch Spaces, a data-driven
approach for learning representations in product space. Specifically, product
spaces (or manifolds) are spaces of mixed curvature, i.e., a combination of
multiple euclidean and non-euclidean (hyperbolic, spherical) manifolds. To this
end, we introduce sparse gating mechanisms that learn to choose, combine and
switch spaces, allowing them to be switchable depending on the input data with
specialization. Additionally, the proposed method is also efficient and has a
constant computational complexity regardless of the model size. Experiments on
knowledge graph completion and item recommendations show that the proposed
switch space achieves new state-of-the-art performances, outperforming pure
product spaces and recently proposed task-specific models.
</p>
<a href="http://arxiv.org/abs/2102.08688" target="_blank">arXiv:2102.08688</a> [<a href="http://arxiv.org/pdf/2102.08688" target="_blank">pdf</a>]

<h2>Symmetry Breaking for k-Robust Multi-Agent Path Finding. (arXiv:2102.08689v1 [cs.AI])</h2>
<h3>Zhe Chen, Daniel Harabor, Jiaoyang Li, Peter J. Stuckey</h3>
<p>During Multi-Agent Path Finding (MAPF) problems, agents can be delayed by
unexpected events. To address such situations recent work describes k-Robust
Conflict-BasedSearch (k-CBS): an algorithm that produces coordinated and
collision-free plan that is robust for up to k delays. In this work we
introducing a variety of pairwise symmetry breaking constraints, specific to
k-robust planning, that can efficiently find compatible and optimal paths for
pairs of conflicting agents. We give a thorough description of the new
constraints and report large improvements to success rate ina range of domains
including: (i) classic MAPF benchmarks;(ii) automated warehouse domains and;
(iii) on maps from the 2019 Flatland Challenge, a recently introduced railway
domain where k-robust planning can be fruitfully applied to schedule trains.
</p>
<a href="http://arxiv.org/abs/2102.08689" target="_blank">arXiv:2102.08689</a> [<a href="http://arxiv.org/pdf/2102.08689" target="_blank">pdf</a>]

<h2>Training Aware Sigmoidal Optimizer. (arXiv:2102.08716v1 [cs.LG])</h2>
<h3>David Mac&#xea;do, Pedro Dreyer, Teresa Ludermir, Cleber Zanchettin</h3>
<p>Proper optimization of deep neural networks is an open research question
since an optimal procedure to change the learning rate throughout training is
still unknown. Manually defining a learning rate schedule involves troublesome
time-consuming try and error procedures to determine hyperparameters such as
learning rate decay epochs and learning rate decay rates. Although adaptive
learning rate optimizers automatize this process, recent studies suggest they
may produce overffiting and reduce performance when compared to fine-tuned
learning rate schedules. Considering that deep neural networks loss functions
present landscapes with much more saddle points than local minima, we proposed
the Training Aware Sigmoidal Optimizer (TASO), which consists of a two-phases
automated learning rate schedule. The first phase uses a high learning rate to
fast traverse the numerous saddle point, while the second phase uses low
learning rate to slowly approach the center of the local minimum previously
found. We compared the proposed approach with commonly used adaptive learning
rate schedules such as Adam, RMSProp, and Adagrad. Our experiments showed that
TASO outperformed all competing methods in both optimal (i.e., performing
hyperparameter validation) and suboptimal (i.e., using default hyperparameters)
scenarios.
</p>
<a href="http://arxiv.org/abs/2102.08716" target="_blank">arXiv:2102.08716</a> [<a href="http://arxiv.org/pdf/2102.08716" target="_blank">pdf</a>]

<h2>Ego-based Entropy Measures for Structural Representations on Graphs. (arXiv:2102.08735v1 [cs.LG])</h2>
<h3>George Dasoulas, Giannis Nikolentzos, Kevin Scaman, Aladin Virmaux, Michalis Vazirgiannis</h3>
<p>Machine learning on graph-structured data has attracted high research
interest due to the emergence of Graph Neural Networks (GNNs). Most of the
proposed GNNs are based on the node homophily, i.e neighboring nodes share
similar characteristics. However, in many complex networks, nodes that lie to
distant parts of the graph share structurally equivalent characteristics and
exhibit similar roles (e.g chemical properties of distant atoms in a molecule,
type of social network users). A growing literature proposed representations
that identify structurally equivalent nodes. However, most of the existing
methods require high time and space complexity. In this paper, we propose
VNEstruct, a simple approach, based on entropy measures of the neighborhood's
topology, for generating low-dimensional structural representations, that is
time-efficient and robust to graph perturbations. Empirically, we observe that
VNEstruct exhibits robustness on structural role identification tasks.
Moreover, VNEstruct can achieve state-of-the-art performance on graph
classification, without incorporating the graph structure information in the
optimization, in contrast to GNN competitors.
</p>
<a href="http://arxiv.org/abs/2102.08735" target="_blank">arXiv:2102.08735</a> [<a href="http://arxiv.org/pdf/2102.08735" target="_blank">pdf</a>]

<h2>SPAN: a Simple Predict & Align Network for Handwritten Paragraph Recognition. (arXiv:2102.08742v1 [cs.CV])</h2>
<h3>Denis Coquenet, Cl&#xe9;ment Chatelain, Thierry Paquet</h3>
<p>Unconstrained handwriting recognition is an essential task in document
analysis. It is usually carried out in two steps. First, the document is
segmented into text lines. Second, an Optical Character Recognition model is
applied on these line images. We propose the Simple Predict &amp; Align Network: an
end-to-end recurrence-free Fully Convolutional Network performing OCR at
paragraph level without any prior segmentation stage. The framework is as
simple as the one used for the recognition of isolated lines and we achieve
competitive results on three popular datasets: RIMES, IAM and READ 2016. The
proposed model does not require any dataset adaptation, it can be trained from
scratch, without segmentation labels, and it does not require line breaks in
the transcription labels. Our code and trained model weights are available at
https://github.com/FactoDeepLearning/SPAN.
</p>
<a href="http://arxiv.org/abs/2102.08742" target="_blank">arXiv:2102.08742</a> [<a href="http://arxiv.org/pdf/2102.08742" target="_blank">pdf</a>]

<h2>Learning Occupancy Priors of Human Motion from Semantic Maps of Urban Environments. (arXiv:2102.08745v1 [cs.RO])</h2>
<h3>Andrey Rudenko, Luigi Palmieri, Johannes Doellinger, Achim J. Lilienthal, Kai O. Arras</h3>
<p>Understanding and anticipating human activity is an important capability for
intelligent systems in mobile robotics, autonomous driving, and video
surveillance. While learning from demonstrations with on-site collected
trajectory data is a powerful approach to discover recurrent motion patterns,
generalization to new environments, where sufficient motion data are not
readily available, remains a challenge. In many cases, however, semantic
information about the environment is a highly informative cue for the
prediction of pedestrian motion or the estimation of collision risks. In this
work, we infer occupancy priors of human motion using only semantic environment
information as input. To this end we apply and discuss a traditional Inverse
Optimal Control approach, and propose a novel one based on Convolutional Neural
Networks (CNN) to predict future occupancy maps. Our CNN method produces
flexible context-aware occupancy estimations for semantically uniform map
regions and generalizes well already with small amounts of training data.
Evaluated on synthetic and real-world data, it shows superior results compared
to several baselines, marking a qualitative step-up in semantic environment
assessment.
</p>
<a href="http://arxiv.org/abs/2102.08745" target="_blank">arXiv:2102.08745</a> [<a href="http://arxiv.org/pdf/2102.08745" target="_blank">pdf</a>]

<h2>ConTraKG: Contrastive-based Transfer Learning for Visual Object Recognition using Knowledge Graphs. (arXiv:2102.08747v1 [cs.CV])</h2>
<h3>Sebastian Monka, Lavdim Halilaj, Stefan Schmid, Achim Rettinger</h3>
<p>Deep learning techniques achieve high accuracy in computer vision tasks.
However, their accuracy suffers considerably when they face a domain change,
i.e., as soon as they are used in a domain that differs from their training
domain. For example, a road sign recognition model trained to recognize road
signs in Germany performs poorly in countries with different road sign
standards like China. We propose ConTraKG, a neuro-symbolic approach that
enables cross-domain transfer learning based on prior knowledge about the
domain or context. A knowledge graph serves as a medium for encoding such prior
knowledge, which is then transformed into a dense vector representation via
embedding methods. Using a five-phase training pipeline, we train the deep
neural network to adjust its visual embedding space according to the
domain-invariant embedding space of the knowledge graph based on a contrastive
loss function. This allows the neural network to incorporate training data from
different target domains that are already represented in the knowledge graph.
We conduct a series of empirical evaluations to determine the accuracy of our
approach. The results show that ConTraKG is significantly more accurate than
the conventional approach for dealing with domain changes. In a transfer
learning setup, where the network is trained on both domains, ConTraKG achieves
21% higher accuracy when tested on the source domain and 15% when tested on the
target domain compared to the standard approach. Moreover, with only 10% of the
target data for training, it achieves the same accuracy as the
cross-entropy-based model trained on the full target data.
</p>
<a href="http://arxiv.org/abs/2102.08747" target="_blank">arXiv:2102.08747</a> [<a href="http://arxiv.org/pdf/2102.08747" target="_blank">pdf</a>]

<h2>A Regret Analysis of Bilateral Trade. (arXiv:2102.08754v1 [cs.LG])</h2>
<h3>Nicol&#xf2; Cesa-Bianchi, Tommaso Cesari (TSE), Roberto Colomboni (IIT), Federico Fusco, Stefano Leonardi</h3>
<p>Bilateral trade, a fundamental topic in economics, models the problem of
intermediating between two strategic agents, a seller and a buyer, willing to
trade a good for which they hold private valuations. Despite the simplicity of
this problem, a classical result by Myerson and Satterthwaite (1983) affirms
the impossibility of designing a mechanism which is simultaneously efficient,
incentive compatible, individually rational, and budget balanced. This
impossibility result fostered an intense investigation of meaningful trade-offs
between these desired properties. Much work has focused on approximately
efficient fixed-price mechanisms, i.e., Blumrosen and Dobzinski (2014; 2016),
Colini-Baldeschi et al. (2016), which have been shown to fully characterize
strong budget balanced and ex-post individually rational direct revelation
mechanisms. All these results, however, either assume some knowledge on the
priors of the seller/buyer valuations, or a black box access to some samples of
the distributions, as in D{\"u}tting et al. (2021). In this paper, we cast for
the first time the bilateral trade problem in a regret minimization framework
over rounds of seller/buyer interactions, with no prior knowledge on the
private seller/buyer valuations. Our main contribution is a complete
characterization of the regret regimes for fixed-price mechanisms with
different models of feedback and private valuations, using as benchmark the
best fixed price in hindsight. More precisely, we prove the following bounds on
the regret:

$\bullet$ $\widetilde{\Theta}(\sqrt{T})$ for full-feedback (i.e., direct
revelation mechanisms);

$\bullet$ $\widetilde{\Theta}(T^{2/3})$ for realistic feedback (i.e.,
posted-price mechanisms) and independent seller/buyer valuations with bounded
densities;

$\bullet$ $\Theta(T)$ for realistic feedback and seller/buyer valuations with
bounded densities;

$\bullet$ $\Theta(T)$ for realistic feedback and independent seller/buyer
valuations;

$\bullet$ $\Theta(T)$ for the adversarial setting.
</p>
<a href="http://arxiv.org/abs/2102.08754" target="_blank">arXiv:2102.08754</a> [<a href="http://arxiv.org/pdf/2102.08754" target="_blank">pdf</a>]

<h2>Autonomous Navigation in Dynamic Environments: Deep Learning-Based Approach. (arXiv:2102.08758v1 [cs.RO])</h2>
<h3>Omar Mohamed, Zeyad Mohsen, Mohamed Wageeh, Mohamed Hegazy</h3>
<p>Mobile robotics is a research area that has witnessed incredible advances for
the last decades. Robot navigation is an essential task for mobile robots. Many
methods are proposed for allowing robots to navigate within different
environments. This thesis studies different deep learning-based approaches,
highlighting the advantages and disadvantages of each scheme. In fact, these
approaches are promising that some of them can navigate the robot in unknown
and dynamic environments. In this thesis, one of the deep learning methods
based on convolutional neural network (CNN) is realized by software
implementations. There are different preparation studies to complete this
thesis such as introduction to Linux, robot operating system (ROS), C++,
python, and GAZEBO simulator. Within this work, we modified the drone network
(namely, DroNet) approach to be used in an indoor environment by using a ground
robot in different cases. Indeed, the DroNet approach suffers from the absence
of goal-oriented motion. Therefore, this thesis mainly focuses on tackling this
problem via mapping using simultaneous localization and mapping (SLAM) and path
planning techniques using Dijkstra. Afterward, the combination between the
DroNet ground robot-based, mapping, and path planning leads to a goal-oriented
motion, following the shortest path while avoiding the dynamic obstacle.
Finally, we propose a low-cost approach, for indoor applications such as
restaurants, museums, etc, on the base of using a monocular camera instead of a
laser scanner.
</p>
<a href="http://arxiv.org/abs/2102.08758" target="_blank">arXiv:2102.08758</a> [<a href="http://arxiv.org/pdf/2102.08758" target="_blank">pdf</a>]

<h2>Group Equivariant Conditional Neural Processes. (arXiv:2102.08759v1 [cs.LG])</h2>
<h3>Makoto Kawano, Wataru Kumagai, Akiyoshi Sannai, Yusuke Iwasawa, Yutaka Matsuo</h3>
<p>We present the group equivariant conditional neural process (EquivCNP), a
meta-learning method with permutation invariance in a data set as in
conventional conditional neural processes (CNPs), and it also has
transformation equivariance in data space. Incorporating group equivariance,
such as rotation and scaling equivariance, provides a way to consider the
symmetry of real-world data. We give a decomposition theorem for
permutation-invariant and group-equivariant maps, which leads us to construct
EquivCNPs with an infinite-dimensional latent space to handle group symmetries.
In this paper, we build architecture using Lie group convolutional layers for
practical implementation. We show that EquivCNP with translation equivariance
achieves comparable performance to conventional CNPs in a 1D regression task.
Moreover, we demonstrate that incorporating an appropriate Lie group
equivariance, EquivCNP is capable of zero-shot generalization for an
image-completion task by selecting an appropriate Lie group equivariance.
</p>
<a href="http://arxiv.org/abs/2102.08759" target="_blank">arXiv:2102.08759</a> [<a href="http://arxiv.org/pdf/2102.08759" target="_blank">pdf</a>]

<h2>Using exoskeletons to assist medical staff during prone positioning of mechanically ventilated COVID-19 patients: a pilot study. (arXiv:2102.08760v1 [cs.RO])</h2>
<h3>Serena Ivaldi (LARSEN), Pauline Maurice (LORIA), Waldez Gomes (LORIA), Jean Theurel (INRS (Vandoeuvre l&#xe8;s Nancy)), Li&#xea;n Wioland (INRS (Vandoeuvre l&#xe8;s Nancy)), Jean-Jacques Atain-Kouadio (INRS (Vandoeuvre l&#xe8;s Nancy)), Laurent Claudon (INRS (Vandoeuvre l&#xe8;s Nancy)), Hind Hani (CUESim), Antoine Kimmoun (CHRU Nancy), Jean-Marc Sellal (CHRU Nancy), Bruno Levy (CHRU Nancy), Jean Paysant (CHRU Nancy), Sergue&#xef; Malikov (CHRU Nancy), Bruno Chenuel (CHRU Nancy), Nicla Settembre (CHRU Nancy)</h3>
<p>We conducted a pilot study to evaluate the potential and feasibility of
back-support exoskeletons to help the caregivers in the Intensive Care Unit
(ICU) of the University Hospital of Nancy (France) executing Prone Positioning
(PP) maneuvers on patients suffering from severe COVID-19-related Acute
Respiratory Distress Syndrome. After comparing four commercial exoskeletons,
the Laevo passive exoskeleton was selected and used in the ICU in April 2020.
The first volunteers using the Laevo reported very positive feedback and
reduction of effort, confirmed by EMG and ECG analysis. Laevo has been since
used to physically assist during PP in the ICU of the Hospital of Nancy,
following the recrudescence of COVID-19, with an overall positive feedback.
</p>
<a href="http://arxiv.org/abs/2102.08760" target="_blank">arXiv:2102.08760</a> [<a href="http://arxiv.org/pdf/2102.08760" target="_blank">pdf</a>]

<h2>Visualization of Deep Reinforcement Autonomous Aerial Mobility Learning Simulations. (arXiv:2102.08761v1 [cs.RO])</h2>
<h3>Gusang Lee, Won Joon Yun, Soyi Jung, Joongheon Kim, Jae-Hyun Kim</h3>
<p>This demo abstract presents the visualization of deep reinforcement learning
(DRL)-based autonomous aerial mobility simulations. In order to implement the
software, Unity-RL is used and additional buildings are introduced for urban
environment. On top of the implementation, DRL algorithms are used and we
confirm it works well in terms of trajectory and 3D visualization.
</p>
<a href="http://arxiv.org/abs/2102.08761" target="_blank">arXiv:2102.08761</a> [<a href="http://arxiv.org/pdf/2102.08761" target="_blank">pdf</a>]

<h2>Heuristic Algorithms for Co-scheduling of Edge Analytics and Routes for UAV Fleet Missions. (arXiv:2102.08768v1 [cs.RO])</h2>
<h3>Aakash Khochare, Yogesh Simmhan, Francesco Betti Sorbelli, Sajal K. Das</h3>
<p>Unmanned Aerial Vehicles (UAVs) or drones are increasingly used for urban
applications like traffic monitoring and construction surveys. Autonomous
navigation allows drones to visit waypoints and accomplish activities as part
of their mission. A common activity is to hover and observe a location using
on-board cameras. Advances in Deep Neural Networks (DNNs) allow such videos to
be analyzed for automated decision making. UAVs also host edge computing
capability for on-board inferencing by such DNNs. To this end, for a fleet of
drones, we propose a novel Mission Scheduling Problem (MSP) that co-schedules
the flight routes to visit and record video at waypoints, and their subsequent
on-board edge analytics. The proposed schedule maximizes the utility from the
activities while meeting activity deadlines as well as energy and computing
constraints. We first prove that MSP is NP-hard and then optimally solve it by
formulating a mixed integer linear programming (MILP) problem. Next, we design
two efficient heuristic algorithms, JSC and VRC, that provide fast sub-optimal
solutions. Evaluation of these three schedulers using real drone traces
demonstrate utility-runtime trade-offs under diverse workloads.
</p>
<a href="http://arxiv.org/abs/2102.08768" target="_blank">arXiv:2102.08768</a> [<a href="http://arxiv.org/pdf/2102.08768" target="_blank">pdf</a>]

<h2>Muddling Labels for Regularization, a novel approach to generalization. (arXiv:2102.08769v1 [stat.ML])</h2>
<h3>Karim Lounici, Katia Meziani, Benjamin Riu</h3>
<p>Generalization is a central problem in Machine Learning. Indeed most
prediction methods require careful calibration of hyperparameters usually
carried out on a hold-out \textit{validation} dataset to achieve
generalization. The main goal of this paper is to introduce a novel approach to
achieve generalization without any data splitting, which is based on a new risk
measure which directly quantifies a model's tendency to overfit. To fully
understand the intuition and advantages of this new approach, we illustrate it
in the simple linear regression model ($Y=X\beta+\xi$) where we develop a new
criterion. We highlight how this criterion is a good proxy for the true
generalization risk. Next, we derive different procedures which tackle several
structures simultaneously (correlation, sparsity,...). Noticeably, these
procedures \textbf{concomitantly} train the model and calibrate the
hyperparameters. In addition, these procedures can be implemented via classical
gradient descent methods when the criterion is differentiable w.r.t. the
hyperparameters. Our numerical experiments reveal that our procedures are
computationally feasible and compare favorably to the popular approach (Ridge,
LASSO and Elastic-Net combined with grid-search cross-validation) in term of
generalization. They also outperform the baseline on two additional tasks:
estimation and support recovery of $\beta$. Moreover, our procedures do not
require any expertise for the calibration of the initial parameters which
remain the same for all the datasets we experimented on.
</p>
<a href="http://arxiv.org/abs/2102.08769" target="_blank">arXiv:2102.08769</a> [<a href="http://arxiv.org/pdf/2102.08769" target="_blank">pdf</a>]

<h2>Comparing and Combining Approximate Computing Frameworks. (arXiv:2102.08771v1 [cs.AI])</h2>
<h3>Saeid Barati, Gordon Kindlmann, Hank Hoffmann</h3>
<p>Approximate computing frameworks configure applications so they can operate
at a range of points in an accuracy-performance trade-off space. Prior work has
introduced many frameworks to create approximate programs. As approximation
frameworks proliferate, it is natural to ask how they can be compared and
combined to create even larger, richer trade-off spaces. We address these
questions by presenting VIPER and BOA. VIPER compares trade-off spaces induced
by different approximation frameworks by visualizing performance improvements
across the full range of possible accuracies. BOA is a family of exploration
techniques that quickly locate Pareto-efficient points in the immense trade-off
space produced by the combination of two or more approximation frameworks. We
use VIPER and BOA to compare and combine three different approximation
frameworks from across the system stack, including: one that changes numerical
precision, one that skips loop iterations, and one that manipulates existing
application parameters. Compared to simply looking at Pareto-optimal curves, we
find VIPER's visualizations provide a quicker and more convenient way to
determine the best approximation technique for any accuracy loss. Compared to a
state-of-the-art evolutionary algorithm, we find that BOA explores 14x fewer
configurations yet locates 35% more Pareto-efficient points.
</p>
<a href="http://arxiv.org/abs/2102.08771" target="_blank">arXiv:2102.08771</a> [<a href="http://arxiv.org/pdf/2102.08771" target="_blank">pdf</a>]

<h2>Graph Learning with 1D Convolutions on Random Walks. (arXiv:2102.08786v1 [cs.LG])</h2>
<h3>Jan Toenshoff, Martin Ritzert, Hinrikus Wolf, Martin Grohe</h3>
<p>We propose CRaWl (CNNs for Random Walks), a novel neural network architecture
for graph learning. It is based on processing sequences of small subgraphs
induced by random walks with standard 1D CNNs. Thus, CRaWl is fundamentally
different from typical message passing graph neural network architectures. It
is inspired by techniques counting small subgraphs, such as the graphlet kernel
and motif counting, and combines them with random walk based techniques in a
highly efficient and scalable neural architecture. We demonstrate empirically
that CRaWl matches or outperforms state-of-the-art GNN architectures across a
multitude of benchmark datasets for graph learning.
</p>
<a href="http://arxiv.org/abs/2102.08786" target="_blank">arXiv:2102.08786</a> [<a href="http://arxiv.org/pdf/2102.08786" target="_blank">pdf</a>]

<h2>ppAUC: Privacy Preserving Area Under the Curve with Secure 3-Party Computation. (arXiv:2102.08788v1 [cs.LG])</h2>
<h3>Ali Burak &#xdc;nal, Nico Pfeifer, Mete Akg&#xfc;n</h3>
<p>Computing an AUC as a performance measure to compare the quality of different
machine learning models is one of the final steps of many research projects.
Many of these methods are trained on privacy-sensitive data and there are
several different approaches like $\epsilon$-differential privacy, federated
machine learning and methods based on cryptographic approaches if the datasets
cannot be shared or evaluated jointly at one place. In this setting, it can
also be a problem to compute the global AUC, since the labels might also
contain privacy-sensitive information. There have been approaches based on
$\epsilon$-differential privacy to deal with this problem, but to the best of
our knowledge, no exact privacy preserving solution has been introduced. In
this paper, we propose an MPC-based framework, called privacy preserving AUC
(ppAUC), with novel methods for comparing two secret-shared values, selecting
between two secret-shared values, converting the modulus and performing
division to compute the exact AUC as one could obtain on the pooled original
test samples. We employ ppAUC in the computation of the exact area under
precision-recall curve and receiver operating characteristic curve even for
ties between prediction confidence values. To prove the correctness of ppAUC,
we apply it to evaluate a model trained to predict acute myeloid leukemia
therapy response and we also assess its scalability via experiments on
synthetic data. The experiments show that we efficiently compute exactly the
same AUC with both evaluation metrics in a privacy preserving manner as one can
obtain on the pooled test samples in the plaintext domain. Our solution
provides security against semi-honest corruption of at most one of the servers
performing the secure computation.
</p>
<a href="http://arxiv.org/abs/2102.08788" target="_blank">arXiv:2102.08788</a> [<a href="http://arxiv.org/pdf/2102.08788" target="_blank">pdf</a>]

<h2>Geostatistical Learning: Challenges and Opportunities. (arXiv:2102.08791v1 [stat.ML])</h2>
<h3>J&#xfa;lio Hoffimann, Maciel Zortea, Breno de Carvalho, Bianca Zadrozny</h3>
<p>Statistical learning theory provides the foundation to applied machine
learning, and its various successful applications in computer vision, natural
language processing and other scientific domains. The theory, however, does not
take into account the unique challenges of performing statistical learning in
geospatial settings. For instance, it is well known that model errors cannot be
assumed to be independent and identically distributed in geospatial (a.k.a.
regionalized) variables due to spatial correlation; and trends caused by
geophysical processes lead to covariate shifts between the domain where the
model was trained and the domain where it will be applied, which in turn harm
the use of classical learning methodologies that rely on random samples of the
data. In this work, we introduce the geostatistical (transfer) learning
problem, and illustrate the challenges of learning from geospatial data by
assessing widely-used methods for estimating generalization error of learning
models, under covariate shift and spatial correlation. Experiments with
synthetic Gaussian process data as well as with real data from geophysical
surveys in New Zealand indicate that none of the methods are adequate for model
selection in a geospatial context. We provide general guidelines regarding the
choice of these methods in practice while new methods are being actively
researched.
</p>
<a href="http://arxiv.org/abs/2102.08791" target="_blank">arXiv:2102.08791</a> [<a href="http://arxiv.org/pdf/2102.08791" target="_blank">pdf</a>]

<h2>Chance-Constrained Active Inference. (arXiv:2102.08792v1 [stat.ML])</h2>
<h3>Thijs van de Laar, Ismail Senoz, Ay&#xe7;a &#xd6;z&#xe7;elikkale, Henk Wymeersch</h3>
<p>Active Inference (ActInf) is an emerging theory that explains perception and
action in biological agents, in terms of minimizing a free energy bound on
Bayesian surprise. Goal-directed behavior is elicited by introducing prior
beliefs on the underlying generative model. In contrast to prior beliefs, which
constrain all realizations of a random variable, we propose an alternative
approach through chance constraints, which allow for a (typically small)
probability of constraint violation, and demonstrate how such constraints can
be used as intrinsic drivers for goal-directed behavior in ActInf. We
illustrate how chance-constrained ActInf weights all imposed (prior)
constraints on the generative model, allowing e.g., for a trade-off between
robust control and empirical chance constraint violation. Secondly, we
interpret the proposed solution within a message passing framework.
Interestingly, the message passing interpretation is not only relevant to the
context of ActInf, but also provides a general purpose approach that can
account for chance constraints on graphical models. The chance constraint
message updates can then be readily combined with other pre-derived message
update rules, without the need for custom derivations. The proposed
chance-constrained message passing framework thus accelerates the search for
workable models in general, and can be used to complement message-passing
formulations on generative neural models.
</p>
<a href="http://arxiv.org/abs/2102.08792" target="_blank">arXiv:2102.08792</a> [<a href="http://arxiv.org/pdf/2102.08792" target="_blank">pdf</a>]

<h2>Dissecting Supervised Constrastive Learning. (arXiv:2102.08817v1 [stat.ML])</h2>
<h3>Florian Graf, Christoph D. Hofer, Marc Niethammer, Roland Kwitt</h3>
<p>Minimizing cross-entropy over the softmax scores of a linear map composed
with a high-capacity encoder is arguably the most popular choice for training
neural networks on supervised learning tasks. However, recent works show that
one can directly optimize the encoder instead, to obtain equally (or even more)
discriminative representations via a supervised variant of a contrastive
objective. In this work, we address the question whether there are fundamental
differences in the sought-for representation geometry in the output space of
the encoder at minimal loss. Specifically, we prove, under mild assumptions,
that both losses attain their minimum once the representations of each class
collapse to the vertices of a regular simplex, inscribed in a hypersphere. We
provide empirical evidence that this configuration is attained in practice and
that reaching a close-to-optimal state typically indicates good generalization
performance. Yet, the two losses show remarkably different optimization
behavior. The number of iterations required to perfectly fit to data scales
superlinearly with the amount of randomly flipped labels for the supervised
contrastive loss. This is in contrast to the approximately linear scaling
previously reported for networks trained with cross-entropy.
</p>
<a href="http://arxiv.org/abs/2102.08817" target="_blank">arXiv:2102.08817</a> [<a href="http://arxiv.org/pdf/2102.08817" target="_blank">pdf</a>]

<h2>Crop mapping from image time series: deep learning with multi-scale label hierarchies. (arXiv:2102.08820v1 [cs.CV])</h2>
<h3>Mehmet Ozgur Turkoglu, Stefano D&#x27;Aronco, Gregor Perich, Frank Liebisch, Constantin Streit, Konrad Schindler, Jan Dirk Wegner</h3>
<p>The aim of this paper is to map agricultural crops by classifying satellite
image time series. Domain experts in agriculture work with crop type labels
that are organised in a hierarchical tree structure, where coarse classes (like
orchards) are subdivided into finer ones (like apples, pears, vines, etc.). We
develop a crop classification method that exploits this expert knowledge and
significantly improves the mapping of rare crop types. The three-level label
hierarchy is encoded in a convolutional, recurrent neural network (convRNN),
such that for each pixel the model predicts three labels at different level of
granularity. This end-to-end trainable, hierarchical network architecture
allows the model to learn joint feature representations of rare classes (e.g.,
apples, pears) at a coarser level (e.g., orchard), thereby boosting
classification performance at the fine-grained level. Additionally, labelling
at different granularity also makes it possible to adjust the output according
to the classification scores; as coarser labels with high confidence are
sometimes more useful for agricultural practice than fine-grained but very
uncertain labels. We validate the proposed method on a new, large dataset that
we make public. ZueriCrop covers an area of 50 km x 48 km in the Swiss cantons
of Zurich and Thurgau with a total of 116'000 individual fields spanning 48
crop classes, and 28,000 (multi-temporal) image patches from Sentinel-2. We
compare our proposed hierarchical convRNN model with several baselines,
including methods designed for imbalanced class distributions. The hierarchical
approach performs superior by at least 9.9 percentage points in F1-score.
</p>
<a href="http://arxiv.org/abs/2102.08820" target="_blank">arXiv:2102.08820</a> [<a href="http://arxiv.org/pdf/2102.08820" target="_blank">pdf</a>]

<h2>A Knowledge-based Approach for the Automatic Construction of Skill Graphs for Online Monitoring. (arXiv:2102.08827v1 [cs.AI])</h2>
<h3>Inga Jatzkowski, Till Menzel, Markus Maurer</h3>
<p>Automated vehicles need to be aware of the capabilities they currently
possess. Skill graphs are directed acylic graphs in which a vehicle's
capabilities and the dependencies between these capabilities are modeled. The
skills a vehicle requires depend on the behaviors the vehicle has to perform
and the operational design domain (ODD) of the vehicle. Skill graphs were
originally proposed for online monitoring of the current capabilities of an
automated vehicle. They have also been shown to be useful during other parts of
the development process, e.g. system design, system verification. Skill graph
construction is an iterative, expert-based, manual process with little to no
guidelines. This process is, thus, prone to errors and inconsistencies
especially regarding the propagation of changes in the vehicle's intended ODD
into the skill graphs. In order to circumnavigate this problem, we propose to
formalize expert knowledge regarding skill graph construction into a knowledge
base and automate the construction process. Thus, all changes in the vehicle's
ODD are reflected in the skill graphs automatically leading to a reduction in
inconsistencies and errors in the constructed skill graphs.
</p>
<a href="http://arxiv.org/abs/2102.08827" target="_blank">arXiv:2102.08827</a> [<a href="http://arxiv.org/pdf/2102.08827" target="_blank">pdf</a>]

<h2>Genetically Optimized Prediction of Remaining Useful Life. (arXiv:2102.08845v1 [cs.AI])</h2>
<h3>Shaashwat Agrawal, Sagnik Sarkar, Gautam Srivastava, Praveen Kumar Reddy Maddikunta, Thippa Reddy Gadekallu</h3>
<p>The application of remaining useful life (RUL) prediction has taken great
importance in terms of energy optimization, cost-effectiveness, and risk
mitigation. The existing RUL prediction algorithms mostly constitute deep
learning frameworks. In this paper, we implement LSTM and GRU models and
compare the obtained results with a proposed genetically trained neural
network. The current models solely depend on Adam and SGD for optimization and
learning. Although the models have worked well with these optimizers, even
little uncertainties in prognostics prediction can result in huge losses. We
hope to improve the consistency of the predictions by adding another layer of
optimization using Genetic Algorithms. The hyper-parameters - learning rate and
batch size are optimized beyond manual capacity. These models and the proposed
architecture are tested on the NASA Turbofan Jet Engine dataset. The optimized
architecture can predict the given hyper-parameters autonomously and provide
superior results.
</p>
<a href="http://arxiv.org/abs/2102.08845" target="_blank">arXiv:2102.08845</a> [<a href="http://arxiv.org/pdf/2102.08845" target="_blank">pdf</a>]

<h2>Contrastive Learning Inverts the Data Generating Process. (arXiv:2102.08850v1 [cs.LG])</h2>
<h3>Roland S. Zimmermann, Yash Sharma, Steffen Schneider, Matthias Bethge, Wieland Brendel</h3>
<p>Contrastive learning has recently seen tremendous success in self-supervised
learning. So far, however, it is largely unclear why the learned
representations generalize so effectively to a large variety of downstream
tasks. We here prove that feedforward models trained with objectives belonging
to the commonly used InfoNCE family learn to implicitly invert the underlying
generative model of the observed data. While the proofs make certain
statistical assumptions about the generative model, we observe empirically that
our findings hold even if these assumptions are severely violated. Our theory
highlights a fundamental connection between contrastive learning, generative
modeling, and nonlinear independent component analysis, thereby furthering our
understanding of the learned representations as well as providing a theoretical
foundation to derive more effective contrastive losses.
</p>
<a href="http://arxiv.org/abs/2102.08850" target="_blank">arXiv:2102.08850</a> [<a href="http://arxiv.org/pdf/2102.08850" target="_blank">pdf</a>]

<h2>ShaRF: Shape-conditioned Radiance Fields from a Single View. (arXiv:2102.08860v1 [cs.CV])</h2>
<h3>Konstantinos Rematas, Ricardo Martin-Brualla, Vittorio Ferrari</h3>
<p>We present a method for estimating neural scenes representations of objects
given only a single image. The core of our method is the estimation of a
geometric scaffold for the object and its use as a guide for the reconstruction
of the underlying radiance field. Our formulation is based on a generative
process that first maps a latent code to a voxelized shape, and then renders it
to an image, with the object appearance being controlled by a second latent
code. During inference, we optimize both the latent codes and the networks to
fit a test image of a new object. The explicit disentanglement of shape and
appearance allows our model to be fine-tuned given a single image. We can then
render new views in a geometrically consistent manner and they represent
faithfully the input object. Additionally, our method is able to generalize to
images outside of the training domain (more realistic renderings and even real
photographs). Finally, the inferred geometric scaffold is itself an accurate
estimate of the object's 3D shape. We demonstrate in several experiments the
effectiveness of our approach in both synthetic and real images.
</p>
<a href="http://arxiv.org/abs/2102.08860" target="_blank">arXiv:2102.08860</a> [<a href="http://arxiv.org/pdf/2102.08860" target="_blank">pdf</a>]

<h2>A Graph Neural Network to Model User Comfort in Robot Navigation. (arXiv:2102.08863v1 [cs.RO])</h2>
<h3>Pilar Bachiller, Daniel Rodriguez-Criado, Ronit R. Jorvekar, Pablo Bustos, Diego R. Faria, Luis J. Manso</h3>
<p>Autonomous navigation is a key skill for assistive and service robots. To be
successful, robots have to minimise the disruption caused to humans while
moving. This implies predicting how people will move and complying with social
conventions. Avoiding disrupting personal spaces, people's paths and
interactions are examples of these social conventions. This paper leverages
Graph Neural Networks to model robot disruption considering the movement of the
humans and the robot so that the model built can be used by path planning
algorithms. Along with the model, this paper presents an evolution of the
dataset SocNav1 which considers the movement of the robot and the humans, and
an updated scenario-to-graph transformation which is tested using different
Graph Neural Network blocks. The model trained achieves close-to-human
performance in the dataset. In addition to its accuracy, the main advantage of
the approach is its scalability in terms of the number of social factors that
can be considered in comparison with handcrafted models.
</p>
<a href="http://arxiv.org/abs/2102.08863" target="_blank">arXiv:2102.08863</a> [<a href="http://arxiv.org/pdf/2102.08863" target="_blank">pdf</a>]

<h2>Bridging the Gap Between Adversarial Robustness and Optimization Bias. (arXiv:2102.08868v1 [cs.LG])</h2>
<h3>Fartash Faghri, Cristina Vasconcelos, David J. Fleet, Fabian Pedregosa, Nicolas Le Roux</h3>
<p>Adversarial robustness is an open challenge in deep learning, most often
tackled using adversarial training. Adversarial training is computationally
costly, involving alternated optimization with a trade-off between standard
generalization and adversarial robustness. We explore training robust models
without adversarial training by revisiting a known result linking maximally
robust classifiers and minimum norm solutions, and combining it with recent
results on the implicit bias of optimizers. First, we show that, under certain
conditions, it is possible to achieve both perfect standard accuracy and a
certain degree of robustness without a trade-off, simply by training an
overparameterized model using the implicit bias of the optimization. In that
regime, there is a direct relationship between the type of the optimizer and
the attack to which the model is robust. Second, we investigate the role of the
architecture in designing robust models. In particular, we characterize the
robustness of linear convolutional models, showing that they resist attacks
subject to a constraint on the Fourier-$\ell_\infty$ norm. This result explains
the property of $\ell_p$-bounded adversarial perturbations that tend to be
concentrated in the Fourier domain. This leads us to a novel attack in the
Fourier domain that is inspired by the well-known frequency-dependent
sensitivity of human perception. We evaluate Fourier-$\ell_\infty$ robustness
of recent CIFAR-10 models with robust training and visualize adversarial
perturbations.
</p>
<a href="http://arxiv.org/abs/2102.08868" target="_blank">arXiv:2102.08868</a> [<a href="http://arxiv.org/pdf/2102.08868" target="_blank">pdf</a>]

<h2>Online Co-movement Pattern Prediction in Mobility Data. (arXiv:2102.08870v1 [cs.LG])</h2>
<h3>Andreas Tritsarolis, Eva Chondrodima, Panagiotis Tampakis, Aggelos Pikrakis</h3>
<p>Predictive analytics over mobility data are of great importance since they
can assist an analyst to predict events, such as collisions, encounters,
traffic jams, etc. A typical example of such analytics is future location
prediction, where the goal is to predict the future location of a moving
object,given a look-ahead time. What is even more challenging is being able to
accurately predict collective behavioural patterns of movement, such as
co-movement patterns. In this paper, we provide an accurate solution to the
problem of Online Prediction of Co-movement Patterns. In more detail, we split
the original problem into two sub-problems, namely Future Location Prediction
and Evolving Cluster Detection. Furthermore, in order to be able to calculate
the accuracy of our solution, we propose a co-movement pattern similarity
measure, which facilitates us to match the predicted clusters with the actual
ones. Finally, the accuracy of our solution is demonstrated experimentally over
a real dataset from the maritime domain.
</p>
<a href="http://arxiv.org/abs/2102.08870" target="_blank">arXiv:2102.08870</a> [<a href="http://arxiv.org/pdf/2102.08870" target="_blank">pdf</a>]

<h2>I Want This Product but Different : Multimodal Retrieval with Synthetic Query Expansion. (arXiv:2102.08871v1 [cs.CV])</h2>
<h3>Ivona Tautkute, Tomasz Trzcinski</h3>
<p>This paper addresses the problem of media retrieval using a multimodal query
(a query which combines visual input with additional semantic information in
natural language feedback). We propose a SynthTriplet GAN framework which
resolves this task by expanding the multimodal query with a synthetically
generated image that captures semantic information from both image and text
input. We introduce a novel triplet mining method that uses a synthetic image
as an anchor to directly optimize for embedding distances of generated and
target images. We demonstrate that apart from the added value of retrieval
illustration with synthetic image with the focus on customization and user
feedback, the proposed method greatly surpasses other multimodal generation
methods and achieves state of the art results in the multimodal retrieval task.
We also show that in contrast to other retrieval methods, our method provides
explainable embeddings.
</p>
<a href="http://arxiv.org/abs/2102.08871" target="_blank">arXiv:2102.08871</a> [<a href="http://arxiv.org/pdf/2102.08871" target="_blank">pdf</a>]

<h2>A Simple and Effective Use of Object-Centric Images for Long-Tailed Object Detection. (arXiv:2102.08884v1 [cs.CV])</h2>
<h3>Cheng Zhang, Tai-Yu Pan, Yandong Li, Hexiang Hu, Dong Xuan, Soravit Changpinyo, Boqing Gong, Wei-Lun Chao</h3>
<p>Object frequencies in daily scenes follow a long-tailed distribution. Many
objects do not appear frequently enough in scene-centric images (e.g.,
sightseeing, street views) for us to train accurate object detectors. In
contrast, these objects are captured at a higher frequency in object-centric
images, which are intended to picture the objects of interest. Motivated by
this phenomenon, we propose to take advantage of the object-centric images to
improve object detection in scene-centric images. We present a simple yet
surprisingly effective framework to do so. On the one hand, our approach turns
an object-centric image into a useful training example for object detection in
scene-centric images by mitigating the domain gap between the two image sources
in both the input and label space. On the other hand, our approach employs a
multi-stage procedure to train the object detector, such that the detector
learns the diverse object appearances from object-centric images while being
tied to the application domain of scene-centric images. On the LVIS dataset,
our approach can improve the object detection (and instance segmentation)
accuracy of rare objects by 50% (and 33%) relatively, without sacrificing the
performance of other classes.
</p>
<a href="http://arxiv.org/abs/2102.08884" target="_blank">arXiv:2102.08884</a> [<a href="http://arxiv.org/pdf/2102.08884" target="_blank">pdf</a>]

<h2>Differentially Private Correlation Clustering. (arXiv:2102.08885v1 [cs.LG])</h2>
<h3>Mark Bun, Marek Eli&#xe1;&#x161;, Janardhan Kulkarni</h3>
<p>Correlation clustering is a widely used technique in unsupervised machine
learning. Motivated by applications where individual privacy is a concern, we
initiate the study of differentially private correlation clustering. We propose
an algorithm that achieves subquadratic additive error compared to the optimal
cost. In contrast, straightforward adaptations of existing non-private
algorithms all lead to a trivial quadratic error. Finally, we give a lower
bound showing that any pure differentially private algorithm for correlation
clustering requires additive error of $\Omega(n)$.
</p>
<a href="http://arxiv.org/abs/2102.08885" target="_blank">arXiv:2102.08885</a> [<a href="http://arxiv.org/pdf/2102.08885" target="_blank">pdf</a>]

<h2>On the Fundamental Limits of Exact Inference in Structured Prediction. (arXiv:2102.08895v1 [stat.ML])</h2>
<h3>Hanbyul Lee, Kevin Bello, Jean Honorio</h3>
<p>Inference is a main task in structured prediction and it is naturally modeled
with a graph. In the context of Markov random fields, noisy observations
corresponding to nodes and edges are usually involved, and the goal of exact
inference is to recover the unknown true label for each node precisely. The
focus of this paper is on the fundamental limits of exact recovery irrespective
of computational efficiency, assuming the generative process proposed by
Globerson et al. (2015). We derive the necessary condition for any algorithm
and the sufficient condition for maximum likelihood estimation to achieve exact
recovery with high probability, and reveal that the sufficient and necessary
conditions are tight up to a logarithmic factor for a wide range of graphs.
Finally, we show that there exists a gap between the fundamental limits and the
performance of the computationally tractable method of Bello and Honorio
(2019), which implies the need for further development of algorithms for exact
inference.
</p>
<a href="http://arxiv.org/abs/2102.08895" target="_blank">arXiv:2102.08895</a> [<a href="http://arxiv.org/pdf/2102.08895" target="_blank">pdf</a>]

<h2>Robust Domain-Free Domain Generalization with Class-aware Alignment. (arXiv:2102.08897v1 [cs.LG])</h2>
<h3>Wenyu Zhang, Mohamed Ragab, Ramon Sagarna</h3>
<p>While deep neural networks demonstrate state-of-the-art performance on a
variety of learning tasks, their performance relies on the assumption that
train and test distributions are the same, which may not hold in real-world
applications. Domain generalization addresses this issue by employing multiple
source domains to build robust models that can generalize to unseen target
domains subject to shifts in data distribution. In this paper, we propose
Domain-Free Domain Generalization (DFDG), a model-agnostic method to achieve
better generalization performance on the unseen test domain without the need
for source domain labels. DFDG uses novel strategies to learn domain-invariant
class-discriminative features. It aligns class relationships of samples through
class-conditional soft labels, and uses saliency maps, traditionally developed
for post-hoc analysis of image classification networks, to remove superficial
observations from training inputs. DFDG obtains competitive performance on both
time series sensor and image classification public datasets.
</p>
<a href="http://arxiv.org/abs/2102.08897" target="_blank">arXiv:2102.08897</a> [<a href="http://arxiv.org/pdf/2102.08897" target="_blank">pdf</a>]

<h2>Few-shot Conformal Prediction with Auxiliary Tasks. (arXiv:2102.08898v1 [cs.LG])</h2>
<h3>Adam Fisch, Tal Schuster, Tommi Jaakkola, Regina Barzilay</h3>
<p>We develop a novel approach to conformal prediction when the target task has
limited data available for training. Conformal prediction identifies a small
set of promising output candidates in place of a single prediction, with
guarantees that the set contains the correct answer with high probability. When
training data is limited, however, the predicted set can easily become unusably
large. In this work, we obtain substantially tighter prediction sets while
maintaining desirable marginal guarantees by casting conformal prediction as a
meta-learning paradigm over exchangeable collections of auxiliary tasks. Our
conformalization algorithm is simple, fast, and agnostic to the choice of
underlying model, learning algorithm, or dataset. We demonstrate the
effectiveness of this approach across a number of few-shot classification and
regression tasks in natural language processing, computer vision, and
computational chemistry for drug discovery.
</p>
<a href="http://arxiv.org/abs/2102.08898" target="_blank">arXiv:2102.08898</a> [<a href="http://arxiv.org/pdf/2102.08898" target="_blank">pdf</a>]

<h2>Provably Efficient Policy Gradient Methods for Two-Player Zero-Sum Markov Games. (arXiv:2102.08903v1 [cs.LG])</h2>
<h3>Yulai Zhao, Yuandong Tian, Jason D. Lee, Simon S. Du</h3>
<p>Policy gradient methods are widely used in solving two-player zero-sum games
to achieve superhuman performance in practice. However, it remains elusive when
they can provably find a near-optimal solution and how many samples and
iterations are needed. The current paper studies natural extensions of Natural
Policy Gradient algorithm for solving two-player zero-sum games where function
approximation is used for generalization across states. We thoroughly
characterize the algorithms' performance in terms of the number of samples,
number of iterations, concentrability coefficients, and approximation error. To
our knowledge, this is the first quantitative analysis of policy gradient
methods with function approximation for two-player zero-sum Markov games.
</p>
<a href="http://arxiv.org/abs/2102.08903" target="_blank">arXiv:2102.08903</a> [<a href="http://arxiv.org/pdf/2102.08903" target="_blank">pdf</a>]

<h2>POLA: Online Time Series Prediction by Adaptive Learning Rates. (arXiv:2102.08907v1 [cs.LG])</h2>
<h3>Wenyu Zhang</h3>
<p>Online prediction for streaming time series data has practical use for many
real-world applications where downstream decisions depend on accurate forecasts
for the future. Deployment in dynamic environments requires models to adapt
quickly to changing data distributions without overfitting. We propose POLA
(Predicting Online by Learning rate Adaptation) to automatically regulate the
learning rate of recurrent neural network models to adapt to changing time
series patterns across time. POLA meta-learns the learning rate of the
stochastic gradient descent (SGD) algorithm by assimilating the prequential or
interleaved-test-then-train evaluation scheme for online prediction. We
evaluate POLA on two real-world datasets across three commonly-used recurrent
neural network models. POLA demonstrates overall comparable or better
predictive performance over other online prediction methods.
</p>
<a href="http://arxiv.org/abs/2102.08907" target="_blank">arXiv:2102.08907</a> [<a href="http://arxiv.org/pdf/2102.08907" target="_blank">pdf</a>]

<h2>How Faithful is your Synthetic Data? Sample-level Metrics for Evaluating and Auditing Generative Models. (arXiv:2102.08921v1 [cs.LG])</h2>
<h3>Ahmed M. Alaa, Boris van Breugel, Evgeny Saveliev, Mihaela van der Schaar</h3>
<p>Devising domain- and model-agnostic evaluation metrics for generative models
is an important and as yet unresolved problem. Most existing metrics, which
were tailored solely to the image synthesis setup, exhibit a limited capacity
for diagnosing the different modes of failure of generative models across
broader application domains. In this paper, we introduce a 3-dimensional
evaluation metric, ($\alpha$-Precision, $\beta$-Recall, Authenticity), that
characterizes the fidelity, diversity and generalization performance of any
generative model in a domain-agnostic fashion. Our metric unifies statistical
divergence measures with precision-recall analysis, enabling sample- and
distribution-level diagnoses of model fidelity and diversity. We introduce
generalization as an additional, independent dimension (to the
fidelity-diversity trade-off) that quantifies the extent to which a model
copies training data -- a crucial performance indicator when modeling sensitive
data with requirements on privacy. The three metric components correspond to
(interpretable) probabilistic quantities, and are estimated via sample-level
binary classification. The sample-level nature of our metric inspires a novel
use case which we call model auditing, wherein we judge the quality of
individual samples generated by a (black-box) model, discarding low-quality
samples and hence improving the overall model performance in a post-hoc manner.
</p>
<a href="http://arxiv.org/abs/2102.08921" target="_blank">arXiv:2102.08921</a> [<a href="http://arxiv.org/pdf/2102.08921" target="_blank">pdf</a>]

<h2>An Objective Laboratory Protocol for Evaluating Cognition of Non-Human Systems Against Human Cognition. (arXiv:2102.08933v1 [cs.AI])</h2>
<h3>David J. Jilk</h3>
<p>In this paper I describe and reduce to practice an objective protocol for
evaluating the cognitive capabilities of a non-human system against human
cognition in a laboratory environment. This is important because the existence
of a non-human system with cognitive capabilities comparable to those of humans
might make once-philosophical questions of safety and ethics immediate and
urgent. Past attempts to devise evaluation methods, such as the Turing Test and
many others, have not met this need; most of them either emphasize a single
aspect of human cognition or a single theory of intelligence, fail to capture
the human capacity for generality and novelty, or require success in the
physical world. The protocol is broadly Bayesian, in that its primary output is
a confidence statistic in relation to a claim. Further, it provides insight
into the areas where and to what extent a particular system falls short of
human cognition, which can help to drive further progress or precautions.
</p>
<a href="http://arxiv.org/abs/2102.08933" target="_blank">arXiv:2102.08933</a> [<a href="http://arxiv.org/pdf/2102.08933" target="_blank">pdf</a>]

<h2>Nearly Optimal Regret for Learning Adversarial MDPs with Linear Function Approximation. (arXiv:2102.08940v1 [cs.LG])</h2>
<h3>Jiafan He, Dongruo Zhou, Quanquan Gu</h3>
<p>We study the reinforcement learning for finite-horizon episodic Markov
decision processes with adversarial reward and full information feedback, where
the unknown transition probability function is a linear function of a given
feature mapping. We propose an optimistic policy optimization algorithm with
Bernstein bonus and show that it can achieve $\tilde{O}(dH\sqrt{T})$ regret,
where $H$ is the length of the episode, $T$ is the number of interaction with
the MDP and $d$ is the dimension of the feature mapping. Furthermore, we also
prove a matching lower bound of $\tilde{\Omega}(dH\sqrt{T})$ up to logarithmic
factors. To the best of our knowledge, this is the first computationally
efficient, nearly minimax optimal algorithm for adversarial Markov decision
processes with linear function approximation.
</p>
<a href="http://arxiv.org/abs/2102.08940" target="_blank">arXiv:2102.08940</a> [<a href="http://arxiv.org/pdf/2102.08940" target="_blank">pdf</a>]

<h2>Automatic Face Understanding: Recognizing Families in Photos. (arXiv:2102.08941v1 [cs.CV])</h2>
<h3>Joseph P Robinson</h3>
<p>We built the largest database for kinship recognition. The data were labeled
using a novel clustering algorithm that used label proposals as side
information to guide more accurate clusters. Great savings in time and human
input was had. Statistically, FIW shows enormous gains over its predecessors.
We have several benchmarks in kinship verification, family classification,
tri-subject verification, and large-scale search and retrieval. We also trained
CNNs on FIW and deployed the model on the renowned KinWild I and II to gain
SOTA. Most recently, we further augmented FIW with MM. Now, video dynamics,
audio, and text captions can be used in the decision making of kinship
recognition systems. We expect FIW will significantly impact research and
reality. Additionally, we tackled the classic problem of facial landmark
localization. A majority of these networks have objectives based on L1 or L2
norms, which inherit several disadvantages. The locations of landmarks are
determined from generated heatmaps from which predicted landmark locations get
penalized without accounting for the spread: a high scatter corresponds to low
confidence and vice-versa. To address this, we introduced an objective that
penalizes for low confidence. Another issue is a dependency on labeled data,
which is expensive to collect and susceptible to error. We addressed both
issues by proposing an adversarial training framework that leverages unlabeled
data to improve model performance. Our method claims SOTA on renowned
benchmarks. Furthermore, our model is robust with a reduced size: 1/8 the
number of channels is comparable to SOTA in real-time on a CPU. Finally, we
built BFW to serve as a proxy to measure bias across ethnicity and gender
subgroups, allowing us to characterize FR performances per subgroup. We show
performances are non-optimal when a single threshold is used to determine
whether sample pairs are genuine.
</p>
<a href="http://arxiv.org/abs/2102.08941" target="_blank">arXiv:2102.08941</a> [<a href="http://arxiv.org/pdf/2102.08941" target="_blank">pdf</a>]

<h2>Weakly Supervised Learning of Rigid 3D Scene Flow. (arXiv:2102.08945v1 [cs.CV])</h2>
<h3>Zan Gojcic, Or Litany, Andreas Wieser, Leonidas J. Guibas, Tolga Birdal</h3>
<p>We propose a data-driven scene flow estimation algorithm exploiting the
observation that many 3D scenes can be explained by a collection of agents
moving as rigid bodies. At the core of our method lies a deep architecture able
to reason at the \textbf{object-level} by considering 3D scene flow in
conjunction with other 3D tasks. This object level abstraction, enables us to
relax the requirement for dense scene flow supervision with simpler binary
background segmentation mask and ego-motion annotations. Our mild supervision
requirements make our method well suited for recently released massive data
collections for autonomous driving, which do not contain dense scene flow
annotations. As output, our model provides low-level cues like pointwise flow
and higher-level cues such as holistic scene understanding at the level of
rigid objects. We further propose a test-time optimization refining the
predicted rigid scene flow. We showcase the effectiveness and generalization
capacity of our method on four different autonomous driving datasets. We
release our source code and pre-trained models under
\url{github.com/zgojcic/Rigid3DSceneFlow}.
</p>
<a href="http://arxiv.org/abs/2102.08945" target="_blank">arXiv:2102.08945</a> [<a href="http://arxiv.org/pdf/2102.08945" target="_blank">pdf</a>]

<h2>S2-BNN: Bridging the Gap Between Self-Supervised Real and 1-bit Neural Networks via Guided Distribution Calibration. (arXiv:2102.08946v1 [cs.CV])</h2>
<h3>Zhiqiang Shen, Zechun Liu, Jie Qin, Lei Huang, Kwang-Ting Cheng, Marios Savvides</h3>
<p>Previous studies dominantly target at self-supervised learning on real-valued
networks and have achieved many promising results. However, on the more
challenging binary neural networks (BNNs), this task has not yet been fully
explored in the community. In this paper, we focus on this more difficult
scenario: learning networks where both weights and activations are binary,
meanwhile, without any human annotated labels. We observe that the commonly
used contrastive objective is not satisfying on BNNs for competitive accuracy,
since the backbone network contains relatively limited capacity and
representation ability. Hence instead of directly applying existing
self-supervised methods, which cause a severe decline in performance, we
present a novel guided learning paradigm from real-valued to distill binary
networks on the final prediction distribution, to minimize the loss and obtain
desirable accuracy. Our proposed method can boost the simple contrastive
learning baseline by an absolute gain of 5.5~15% on BNNs. We further reveal
that it is difficult for BNNs to recover the similar predictive distributions
as real-valued models when training without labels. Thus, how to calibrate them
is key to address the degradation in performance. Extensive experiments are
conducted on the large-scale ImageNet and downstream datasets. Our method
achieves substantial improvement over the simple contrastive learning baseline,
and is even comparable to many mainstream supervised BNN methods. Code will be
made available.
</p>
<a href="http://arxiv.org/abs/2102.08946" target="_blank">arXiv:2102.08946</a> [<a href="http://arxiv.org/pdf/2102.08946" target="_blank">pdf</a>]

<h2>Faster Neural Network Training with Approximate Tensor Operations. (arXiv:1805.08079v2 [cs.LG] UPDATED)</h2>
<h3>Menachem Adelman, Kfir Y. Levy, Ido Hakimi, Mark Silberstein</h3>
<p>We propose a novel technique for faster DNN training which systematically
applies sample-based approximation to the constituent tensor operations, i.e.,
matrix multiplications and convolutions. We introduce new sampling techniques,
study their theoretical properties, and prove that they provide the same
convergence guarantees when applied to SGD DNN training. We apply approximate
tensor operations to single and multi-node training of MLP and CNN networks on
MNIST, CIFAR-10 and ImageNet datasets. We demonstrate up to 66% reduction in
the amount of computations and communication, and up to 1.37x faster training
time while maintaining negligible or no impact on the final test accuracy.
</p>
<a href="http://arxiv.org/abs/1805.08079" target="_blank">arXiv:1805.08079</a> [<a href="http://arxiv.org/pdf/1805.08079" target="_blank">pdf</a>]

<h2>Predictive Learning on Hidden Tree-Structured Ising Models. (arXiv:1812.04700v4 [stat.ML] UPDATED)</h2>
<h3>Konstantinos E. Nikolakakis, Dionysios S. Kalogerias, Anand D. Sarwate</h3>
<p>We provide high-probability sample complexity guarantees for exact structure
recovery and accurate predictive learning using noise-corrupted samples from an
acyclic (tree-shaped) graphical model. The hidden variables follow a
tree-structured Ising model distribution, whereas the observable variables are
generated by a binary symmetric channel taking the hidden variables as its
input (flipping each bit independently with some constant probability $q\in
[0,1/2)$). In the absence of noise, predictive learning on Ising models was
recently studied by Bresler and Karzand (2020); this paper quantifies how noise
in the hidden model impacts the tasks of structure recovery and marginal
distribution estimation by proving upper and lower bounds on the sample
complexity. Our results generalize state-of-the-art bounds reported in prior
work, and they exactly recover the noiseless case ($q=0$). In fact, for any
tree with $p$ vertices and probability of incorrect recovery $\delta&gt;0$, the
sufficient number of samples remains logarithmic as in the noiseless case,
i.e., $\mathcal{O}(\log(p/\delta))$, while the dependence on $q$ is
$\mathcal{O}\big( 1/(1-2q)^{4} \big)$, for both aforementioned tasks. We also
present a new equivalent of Isserlis' Theorem for sign-valued tree-structured
distributions, yielding a new low-complexity algorithm for higher-order moment
estimation.
</p>
<a href="http://arxiv.org/abs/1812.04700" target="_blank">arXiv:1812.04700</a> [<a href="http://arxiv.org/pdf/1812.04700" target="_blank">pdf</a>]

<h2>Handheld Multi-Frame Super-Resolution. (arXiv:1905.03277v2 [cs.CV] UPDATED)</h2>
<h3>Bartlomiej Wronski, Ignacio Garcia-Dorado, Manfred Ernst, Damien Kelly, Michael Krainin, Chia-Kai Liang, Marc Levoy, Peyman Milanfar</h3>
<p>Compared to DSLR cameras, smartphone cameras have smaller sensors, which
limits their spatial resolution; smaller apertures, which limits their light
gathering ability; and smaller pixels, which reduces their signal-to noise
ratio. The use of color filter arrays (CFAs) requires demosaicing, which
further degrades resolution. In this paper, we supplant the use of traditional
demosaicing in single-frame and burst photography pipelines with a multiframe
super-resolution algorithm that creates a complete RGB image directly from a
burst of CFA raw images. We harness natural hand tremor, typical in handheld
photography, to acquire a burst of raw frames with small offsets. These frames
are then aligned and merged to form a single image with red, green, and blue
values at every pixel site. This approach, which includes no explicit
demosaicing step, serves to both increase image resolution and boost signal to
noise ratio. Our algorithm is robust to challenging scene conditions: local
motion, occlusion, or scene changes. It runs at 100 milliseconds per
12-megapixel RAW input burst frame on mass-produced mobile phones.
Specifically, the algorithm is the basis of the Super-Res Zoom feature, as well
as the default merge method in Night Sight mode (whether zooming or not) on
Google's flagship phone.
</p>
<a href="http://arxiv.org/abs/1905.03277" target="_blank">arXiv:1905.03277</a> [<a href="http://arxiv.org/pdf/1905.03277" target="_blank">pdf</a>]

<h2>Quantifying the Privacy Risks of Learning High-Dimensional Graphical Models. (arXiv:1905.12774v3 [stat.ML] UPDATED)</h2>
<h3>Sasi Kumar Murakonda, Reza Shokri, George Theodorakopoulos</h3>
<p>Models leak information about their training data. This enables attackers to
infer sensitive information about their training sets, notably determine if a
data sample was part of the model's training set. The existing works
empirically show the possibility of these membership inference (tracing)
attacks against complex deep learning models. However, the attack results are
dependent on the specific training data, can be obtained only after the tedious
process of training the model and performing the attack, and are missing any
measure of the confidence and unused potential power of the attack.

In this paper, we theoretically analyze the maximum power of tracing attacks
against high-dimensional graphical models, with the focus on Bayesian networks.
We provide a tight upper bound on the power (true positive rate) of these
attacks, with respect to their error (false positive rate), for a given model
structure even before learning its parameters. As it should be, the bound is
independent of the knowledge and algorithm of any specific attack. It can help
in identifying which model structures leak more information, how adding new
parameters to the model increases its privacy risk, and what can be gained by
adding new data points to decrease the overall information leakage. It provides
a measure of the potential leakage of a model given its structure, as a
function of the model complexity and the size of the training set.
</p>
<a href="http://arxiv.org/abs/1905.12774" target="_blank">arXiv:1905.12774</a> [<a href="http://arxiv.org/pdf/1905.12774" target="_blank">pdf</a>]

<h2>Geomorphological Analysis Using Unpiloted Aircraft Systems, Structure from Motion, and Deep Learning. (arXiv:1909.12874v5 [cs.RO] UPDATED)</h2>
<h3>Zhiang Chen, Tyler R. Scott, Sarah Bearman, Harish Anand, Devin Keating, Chelsea Scott, J Ramon Arrowsmith, Jnaneshwar Das</h3>
<p>We present a pipeline for geomorphological analysis that uses structure from
motion (SfM) and deep learning on close-range aerial imagery to estimate
spatial distributions of rock traits (size, roundness, and orientation) along a
tectonic fault scarp. The properties of the rocks on the fault scarp derive
from the combination of initial volcanic fracturing and subsequent tectonic and
geomorphic fracturing, and our pipeline allows scientists to leverage UAS-based
imagery to gain a better understanding of such surface processes. We start by
using SfM on aerial imagery to produce georeferenced orthomosaics and digital
elevation models (DEM). A human expert then annotates rocks on a set of image
tiles sampled from the orthomosaics, and these annotations are used to train a
deep neural network to detect and segment individual rocks in the entire site.
The extracted semantic information (rock masks) on large volumes of unlabeled,
high-resolution SfM products allows subsequent structural analysis and shape
descriptors to estimate rock size, roundness, and orientation. We present
results of two experiments conducted along a fault scarp in the Volcanic
Tablelands near Bishop, California. We conducted the first, proof-of-concept
experiment with a DJI Phantom 4 Pro equipped with an RGB camera and inspected
if elevation information assisted instance segmentation from RGB channels.
Rock-trait histograms along and across the fault scarp were obtained with the
neural network inference. In the second experiment, we deployed a hexrotor and
a multispectral camera to produce a DEM and five spectral orthomosaics in red,
green, blue, red edge, and near infrared. We focused on examining the
effectiveness of different combinations of input channels in instance
segmentation.
</p>
<a href="http://arxiv.org/abs/1909.12874" target="_blank">arXiv:1909.12874</a> [<a href="http://arxiv.org/pdf/1909.12874" target="_blank">pdf</a>]

<h2>Influence-aware Memory Architectures for Deep Reinforcement Learning. (arXiv:1911.07643v4 [cs.LG] UPDATED)</h2>
<h3>Miguel Suau, Jinke He, Elena Congeduti, Rolf A.N. Starre, Aleksander Czechowski, Frans A. Oliehoek</h3>
<p>Due to its perceptual limitations, an agent may have too little information
about the state of the environment to act optimally. In such cases, it is
important to keep track of the observation history to uncover hidden state.
Recent deep reinforcement learning methods use recurrent neural networks (RNN)
to memorize past observations. However, these models are expensive to train and
have convergence difficulties, especially when dealing with high dimensional
input spaces. In this paper, we propose influence-aware memory (IAM), a
theoretically inspired memory architecture that tries to alleviate the training
difficulties by restricting the input of the recurrent layers to those
variables that influence the hidden state information. Moreover, as opposed to
standard RNNs, in which every piece of information used for estimating Q values
is inevitably fed back into the network for the next prediction, our model
allows information to flow without being necessarily stored in the RNN's
internal memory. Results indicate that, by letting the recurrent layers focus
on a small fraction of the observation variables while processing the rest of
the information with a feedforward neural network, we can outperform standard
recurrent architectures both in training speed and policy performance. This
approach also reduces runtime and obtains better scores than methods that stack
multiple observations to remove partial observability.
</p>
<a href="http://arxiv.org/abs/1911.07643" target="_blank">arXiv:1911.07643</a> [<a href="http://arxiv.org/pdf/1911.07643" target="_blank">pdf</a>]

<h2>MetaCI: Meta-Learning for Causal Inference in a Heterogeneous Population. (arXiv:1912.03960v6 [cs.LG] UPDATED)</h2>
<h3>Ankit Sharma, Garima Gupta, Ranjitha Prasad, Arnab Chatterjee, Lovekesh Vig, Gautam Shroff</h3>
<p>Performing inference on data obtained through observational studies is
becoming extremely relevant due to the widespread availability of data in
fields such as healthcare, education, retail, etc. Furthermore, this data is
accrued from multiple homogeneous subgroups of a heterogeneous population, and
hence, generalizing the inference mechanism over such data is essential. We
propose the MetaCI framework with the goal of answering counterfactual
questions in the context of causal inference (CI), where the factual
observations are obtained from several homogeneous subgroups. While the CI
network is designed to generalize from factual to counterfactual distribution
in order to tackle covariate shift, MetaCI employs the meta-learning paradigm
to tackle the shift in data distributions between training and test phase due
to the presence of heterogeneity in the population, and due to drifts in the
target distribution, also known as concept shift. We benchmark the performance
of the MetaCI algorithm using the mean absolute percentage error over the
average treatment effect as the metric, and demonstrate that meta
initialization has significant gains compared to randomly initialized networks,
and other methods.
</p>
<a href="http://arxiv.org/abs/1912.03960" target="_blank">arXiv:1912.03960</a> [<a href="http://arxiv.org/pdf/1912.03960" target="_blank">pdf</a>]

<h2>A Deep Conditioning Treatment of Neural Networks. (arXiv:2002.01523v3 [cs.LG] UPDATED)</h2>
<h3>Naman Agarwal, Pranjal Awasthi, Satyen Kale</h3>
<p>We study the role of depth in training randomly initialized overparameterized
neural networks. We give a general result showing that depth improves
trainability of neural networks by improving the conditioning of certain kernel
matrices of the input data. This result holds for arbitrary non-linear
activation functions under a certain normalization. We provide versions of the
result that hold for training just the top layer of the neural network, as well
as for training all layers, via the neural tangent kernel. As applications of
these general results, we provide a generalization of the results of Das et al.
(2019) showing that learnability of deep random neural networks with a large
class of non-linear activations degrades exponentially with depth. We also show
how benign overfitting can occur in deep neural networks via the results of
Bartlett et al. (2019b). We also give experimental evidence that normalized
versions of ReLU are a viable alternative to more complex operations like Batch
Normalization in training deep neural networks.
</p>
<a href="http://arxiv.org/abs/2002.01523" target="_blank">arXiv:2002.01523</a> [<a href="http://arxiv.org/pdf/2002.01523" target="_blank">pdf</a>]

<h2>Discriminative Multi-level Reconstruction under Compact Latent Space for One-Class Novelty Detection. (arXiv:2003.01665v3 [cs.LG] UPDATED)</h2>
<h3>Jaewoo Park, Yoon Gyo Jung, Andrew Beng Jin Teoh</h3>
<p>In one-class novelty detection, a model learns solely on the in-class data to
single out out-class instances. Autoencoder (AE) variants aim to compactly
model the in-class data to reconstruct it exclusively, thus differentiating the
in-class from out-class by the reconstruction error. However, compact modeling
in an improper way might collapse the latent representations of the in-class
data and thus their reconstruction, which would lead to performance
deterioration. Moreover, to properly measure the reconstruction error of
high-dimensional data, a metric is required that captures high-level semantics
of the data. To this end, we propose Discriminative Compact AE (DCAE) that
learns both compact and collapse-free latent representations of the in-class
data, thereby reconstructing them both finely and exclusively. In DCAE, (a) we
force a compact latent space to bijectively represent the in-class data by
reconstructing them through internal discriminative layers of generative
adversarial nets. (b) Based on the deep encoder's vulnerability to open set
risk, out-class instances are encoded into the same compact latent space and
reconstructed poorly without sacrificing the quality of in-class data
reconstruction. (c) In inference, the reconstruction error is measured by a
novel metric that computes the dissimilarity between a query and its
reconstruction based on the class semantics captured by the internal
discriminator. Extensive experiments on public image datasets validate the
effectiveness of our proposed model on both novelty and adversarial example
detection, delivering state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2003.01665" target="_blank">arXiv:2003.01665</a> [<a href="http://arxiv.org/pdf/2003.01665" target="_blank">pdf</a>]

<h2>The Role of the Hercules Autonomous Vehicle During the COVID-19 Pandemic: An Autonomous Logistic Vehicle for Contactless Goods Transportation. (arXiv:2004.07480v2 [cs.RO] UPDATED)</h2>
<h3>Tianyu Liu, Qinghai Liao, Lu Gan, Fulong Ma, Jie Cheng, Xupeng Xie, Zhe Wang, Yingbing Chen, Yilong Zhu, Shuyang Zhang, Zhengyong Chen, Yang Liu, Meng Xie, Yang Yu, Zitong Guo, Guang Li, Peidong Yuan, Dong Han, Yuying Chen, Haoyang Ye, Jianhao Jiao, Peng Yun, Zhenhua Xu, Hengli Wang, Huaiyang Huang, Sukai Wang, Peide Cai, Yuxiang Sun, Yandong Liu, Lujia Wang, Ming Liu</h3>
<p>Since early 2020, the coronavirus disease 2019 (COVID-19) has spread rapidly
across the world. As at the date of writing this article, the disease has been
globally reported in 223 countries and regions, infected over 108 million
people and caused over 2.4 million deaths (https://covid19.who.int/, accessed
on Feb. 17, 2021). Avoiding person-to-person transmission is an effective
approach to control and prevent the pandemic. However, many daily activities,
such as transporting goods in our daily life, inevitably involve
person-to-person contact. Using an autonomous logistic vehicle to achieve
contact-less goods transportation could alleviate this issue. For example, it
can reduce the risk of virus transmission between the driver and customers.
Moreover, many countries have imposed tough lockdown measures to reduce the
virus transmission (e.g., retail, catering) during the pandemic, which causes
inconveniences for human daily life. Autonomous vehicle can deliver the goods
bought by humans, so that humans can get the goods without going out. These
demands motivate us to develop an autonomous vehicle, named as Hercules, for
contact-less goods transportation during the COVID-19 pandemic. The vehicle is
evaluated through real-world delivering tasks under various traffic conditions.
</p>
<a href="http://arxiv.org/abs/2004.07480" target="_blank">arXiv:2004.07480</a> [<a href="http://arxiv.org/pdf/2004.07480" target="_blank">pdf</a>]

<h2>OT-Flow: Fast and Accurate Continuous Normalizing Flows via Optimal Transport. (arXiv:2006.00104v4 [cs.LG] UPDATED)</h2>
<h3>Derek Onken, Samy Wu Fung, Xingjian Li, Lars Ruthotto</h3>
<p>A normalizing flow is an invertible mapping between an arbitrary probability
distribution and a standard normal distribution; it can be used for density
estimation and statistical inference. Computing the flow follows the change of
variables formula and thus requires invertibility of the mapping and an
efficient way to compute the determinant of its Jacobian. To satisfy these
requirements, normalizing flows typically consist of carefully chosen
components. Continuous normalizing flows (CNFs) are mappings obtained by
solving a neural ordinary differential equation (ODE). The neural ODE's
dynamics can be chosen almost arbitrarily while ensuring invertibility.
Moreover, the log-determinant of the flow's Jacobian can be obtained by
integrating the trace of the dynamics' Jacobian along the flow. Our proposed
OT-Flow approach tackles two critical computational challenges that limit a
more widespread use of CNFs. First, OT-Flow leverages optimal transport (OT)
theory to regularize the CNF and enforce straight trajectories that are easier
to integrate. Second, OT-Flow features exact trace computation with time
complexity equal to trace estimators used in existing CNFs. On five
high-dimensional density estimation and generative modeling tasks, OT-Flow
performs competitively to state-of-the-art CNFs while on average requiring
one-fourth of the number of weights with an 8x speedup in training time and 24x
speedup in inference.
</p>
<a href="http://arxiv.org/abs/2006.00104" target="_blank">arXiv:2006.00104</a> [<a href="http://arxiv.org/pdf/2006.00104" target="_blank">pdf</a>]

<h2>Markov Random Geometric Graph (MRGG): A Growth Model for Temporal Dynamic Networks. (arXiv:2006.07001v2 [cs.LG] UPDATED)</h2>
<h3>Yohann de Castro (ICJ), Quentin Duchemin (LAMA)</h3>
<p>We introduce Markov Random Geometric Graphs (MRGGs), a growth model for
temporal dynamic networks. It is based on a Markovian latent space dynamic:
consecutive latent points are sampled on the Euclidean Sphere using an unknown
Markov kernel; and two nodes are connected with a probability depending on a
unknown function of their latent geodesic distance. More precisely, at each
stamp-time k we add a latent point X k sampled by jumping from the previous one
X k--1 in a direction chosen uniformly Y k and with a length r k drawn from an
unknown distribution called the latitude function. The connection probabilities
between each pair of nodes are equal to the envelope function of the distance
between these two latent points. We provide theoretical guarantees for the
non-parametric estimation of the latitude and the envelope functions. We
propose an efficient algorithm that achieves those non-parametric estimation
tasks based on an ad-hoc Hierarchical Agglomerative Clustering approach, and we
deploy this analysis on a real data-set given by exchange of messages on a
social network.
</p>
<a href="http://arxiv.org/abs/2006.07001" target="_blank">arXiv:2006.07001</a> [<a href="http://arxiv.org/pdf/2006.07001" target="_blank">pdf</a>]

<h2>A Comparative Study of Gamma Markov Chains for Temporal Non-Negative Matrix Factorization. (arXiv:2006.12843v4 [stat.ML] UPDATED)</h2>
<h3>Louis Filstroff, Olivier Gouvert, C&#xe9;dric F&#xe9;votte, Olivier Capp&#xe9;</h3>
<p>Non-negative matrix factorization (NMF) has become a well-established class
of methods for the analysis of non-negative data. In particular, a lot of
effort has been devoted to probabilistic NMF, namely estimation or inference
tasks in probabilistic models describing the data, based for example on Poisson
or exponential likelihoods. When dealing with time series data, several works
have proposed to model the evolution of the activation coefficients as a
non-negative Markov chain, most of the time in relation with the Gamma
distribution, giving rise to so-called temporal NMF models. In this paper, we
review four Gamma Markov chains of the NMF literature, and show that they all
share the same drawback: the absence of a well-defined stationary distribution.
We then introduce a fifth process, an overlooked model of the time series
literature named BGAR(1), which overcomes this limitation. These temporal NMF
models are then compared in a MAP framework on a prediction task, in the
context of the Poisson likelihood.
</p>
<a href="http://arxiv.org/abs/2006.12843" target="_blank">arXiv:2006.12843</a> [<a href="http://arxiv.org/pdf/2006.12843" target="_blank">pdf</a>]

<h2>Near-Optimal Entrywise Anomaly Detection for Low-Rank Matrices with Sub-Exponential Noise. (arXiv:2006.13126v2 [stat.ML] UPDATED)</h2>
<h3>Vivek F. Farias, Andrew A. Li, Tianyi Peng</h3>
<p>We study the problem of identifying anomalies in a low-rank matrix observed
with sub-exponential noise, motivated by applications in retail and inventory
management. State of the art approaches to anomaly detection in low-rank
matrices apparently fall short, since they require that non-anomalous entries
be observed with vanishingly small noise (which is not the case in our problem,
and indeed in many applications). So motivated, we propose a conceptually
simple entrywise approach to anomaly detection in low-rank matrices. Our
approach accommodates a general class of probabilistic anomaly models. We
extend recent work on entrywise error guarantees for matrix completion,
establishing such guarantees for sub-exponential matrices, where in addition to
missing entries, a fraction of entries are corrupted by (an also unknown)
anomaly model. Viewing the anomaly detection as a classification task, to the
best of our knowledge, we are the first to achieve the min-max optimal
detection rate (up to log factors). Using data from a massive consumer goods
retailer, we show that our approach provides significant improvements over
incumbent approaches to anomaly detection.
</p>
<a href="http://arxiv.org/abs/2006.13126" target="_blank">arXiv:2006.13126</a> [<a href="http://arxiv.org/pdf/2006.13126" target="_blank">pdf</a>]

<h2>Learning to search efficiently for causally near-optimal treatments. (arXiv:2007.00973v2 [cs.LG] UPDATED)</h2>
<h3>Samuel H&#xe5;kansson, Viktor Lindblom, Omer Gottesman, Fredrik D. Johansson</h3>
<p>Finding an effective medical treatment often requires a search by trial and
error. Making this search more efficient by minimizing the number of
unnecessary trials could lower both costs and patient suffering. We formalize
this problem as learning a policy for finding a near-optimal treatment in a
minimum number of trials using a causal inference framework. We give a
model-based dynamic programming algorithm which learns from observational data
while being robust to unmeasured confounding. To reduce time complexity, we
suggest a greedy algorithm which bounds the near-optimality constraint. The
methods are evaluated on synthetic and real-world healthcare data and compared
to model-free reinforcement learning. We find that our methods compare
favorably to the model-free baseline while offering a more transparent
trade-off between search time and treatment efficacy.
</p>
<a href="http://arxiv.org/abs/2007.00973" target="_blank">arXiv:2007.00973</a> [<a href="http://arxiv.org/pdf/2007.00973" target="_blank">pdf</a>]

<h2>CrossTransformers: spatially-aware few-shot transfer. (arXiv:2007.11498v5 [cs.CV] UPDATED)</h2>
<h3>Carl Doersch, Ankush Gupta, Andrew Zisserman</h3>
<p>Given new tasks with very little data$-$such as new classes in a
classification problem or a domain shift in the input$-$performance of modern
vision systems degrades remarkably quickly. In this work, we illustrate how the
neural network representations which underpin modern vision systems are subject
to supervision collapse, whereby they lose any information that is not
necessary for performing the training task, including information that may be
necessary for transfer to new tasks or domains. We then propose two methods to
mitigate this problem. First, we employ self-supervised learning to encourage
general-purpose features that transfer better. Second, we propose a novel
Transformer based neural network architecture called CrossTransformers, which
can take a small number of labeled images and an unlabeled query, find coarse
spatial correspondence between the query and the labeled images, and then infer
class membership by computing distances between spatially-corresponding
features. The result is a classifier that is more robust to task and domain
shift, which we demonstrate via state-of-the-art performance on Meta-Dataset, a
recent dataset for evaluating transfer from ImageNet to many other vision
datasets.
</p>
<a href="http://arxiv.org/abs/2007.11498" target="_blank">arXiv:2007.11498</a> [<a href="http://arxiv.org/pdf/2007.11498" target="_blank">pdf</a>]

<h2>Ortus: an Emotion-Driven Approach to (artificial) Biological Intelligence. (arXiv:2008.04875v2 [cs.AI] UPDATED)</h2>
<h3>Andrew W.E. McDonald, Sean Grimes, David E. Breen</h3>
<p>Ortus is a simple virtual organism that also serves as an initial framework
for investigating and developing biologically-based artificial intelligence.
Born from a goal to create complex virtual intelligence and an initial attempt
to model C. elegans, Ortus implements a number of mechanisms observed in
organic nervous systems, and attempts to fill in unknowns based upon plausible
biological implementations and psychological observations. Implemented
mechanisms include excitatory and inhibitory chemical synapses, bidirectional
gap junctions, and Hebbian learning with its Stentian extension. We present an
initial experiment that showcases Ortus' fundamental principles; specifically,
a cyclic respiratory circuit, and emotionally-driven associative learning with
respect to an input stimulus. Finally, we discuss the implications and future
directions for Ortus and similar systems.
</p>
<a href="http://arxiv.org/abs/2008.04875" target="_blank">arXiv:2008.04875</a> [<a href="http://arxiv.org/pdf/2008.04875" target="_blank">pdf</a>]

<h2>Exploration with Intrinsic Motivation using Object-Action-Outcome Latent Space. (arXiv:2008.11503v2 [cs.RO] UPDATED)</h2>
<h3>Melisa Sener, Yukie Nagai, Erhan Oztop, Emre Ugur</h3>
<p>One effective approach for equipping artificial agents with sensorimotor
skills is to use self-exploration. To do this efficiently is critical, as time
and data collection are costly. In this study, we propose an exploration
mechanism that blends action, object, and action outcome representations into a
latent space, where local regions are formed to host forward model learning.
The agent uses intrinsic motivation to select the forward model with the
highest learning progress to adopt at a given exploration step. This parallels
how infants learn, as high learning progress indicates that the learning
problem is neither too easy nor too difficult in the selected region. The
proposed approach is validated with a simulated robot in a table-top
environment. The simulation scene comprises a robot and various objects, where
the robot interacts with one of them each time using a set of parameterized
actions and learns the outcomes of these interactions. With the proposed
approach, the robot organizes its curriculum of learning as in existing
intrinsic motivation approaches and outperforms them in learning speed.
Moreover, the learning regime demonstrates features that partially match infant
development; in particular, the proposed system learns to predict the outcomes
of different skills in a staged manner.
</p>
<a href="http://arxiv.org/abs/2008.11503" target="_blank">arXiv:2008.11503</a> [<a href="http://arxiv.org/pdf/2008.11503" target="_blank">pdf</a>]

<h2>Continual Prototype Evolution: Learning Online from Non-Stationary Data Streams. (arXiv:2009.00919v3 [cs.CV] UPDATED)</h2>
<h3>Matthias De Lange, Tinne Tuytelaars</h3>
<p>Attaining prototypical features to represent class distributions is well
established in representation learning. However, learning prototypes online
from streams of data proves a challenging endeavor as they rapidly become
outdated, caused by an ever-changing parameter space in the learning process.
Additionally, continual learning does not assume the data stream to be
stationary, typically resulting in catastrophic forgetting of previous
knowledge. As a first, we introduce a system addressing both problems, where
prototypes evolve continually in a shared latent space, enabling learning and
prediction at any point in time. In contrast to the major body of work in
continual learning, data streams are processed in an online fashion, without
additional task-information, and an efficient memory scheme provides robustness
to imbalanced data streams. Besides nearest neighbor based prediction, learning
is facilitated by a novel objective function, encouraging cluster density about
the class prototype and increased inter-class variance. Furthermore, the latent
space quality is elevated by pseudo-prototypes in each batch, constituted by
replay of exemplars from memory. We generalize the existing paradigms in
continual learning to incorporate data incremental learning from data streams
by formalizing a two-agent learner-evaluator framework, and obtain
state-of-the-art performance by a significant margin on eight benchmarks,
including three highly imbalanced data streams.
</p>
<a href="http://arxiv.org/abs/2009.00919" target="_blank">arXiv:2009.00919</a> [<a href="http://arxiv.org/pdf/2009.00919" target="_blank">pdf</a>]

<h2>Zero-shot Synthesis with Group-Supervised Learning. (arXiv:2009.06586v3 [cs.CV] UPDATED)</h2>
<h3>Yunhao Ge, Sami Abu-El-Haija, Gan Xin, Laurent Itti</h3>
<p>Visual cognition of primates is superior to that of artificial neural
networks in its ability to 'envision' a visual object, even a newly-introduced
one, in different attributes including pose, position, color, texture, etc. To
aid neural networks to envision objects with different attributes, we propose a
family of objective functions, expressed on groups of examples, as a novel
learning framework that we term Group-Supervised Learning (GSL). GSL allows us
to decompose inputs into a disentangled representation with swappable
components, that can be recombined to synthesize new samples. For instance,
images of red boats &amp; blue cars can be decomposed and recombined to synthesize
novel images of red cars. We propose an implementation based on auto-encoder,
termed group-supervised zero-shot synthesis network (GZS-Net) trained with our
learning framework, that can produce a high-quality red car even if no such
example is witnessed during training. We test our model and learning framework
on existing benchmarks, in addition to anew dataset that we open-source. We
qualitatively and quantitatively demonstrate that GZS-Net trained with GSL
outperforms state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2009.06586" target="_blank">arXiv:2009.06586</a> [<a href="http://arxiv.org/pdf/2009.06586" target="_blank">pdf</a>]

<h2>Discovering Dynamic Salient Regions with Spatio-Temporal Graph Neural Networks. (arXiv:2009.08427v2 [cs.CV] UPDATED)</h2>
<h3>Iulia Duta, Andrei Nicolicioiu, Marius Leordeanu</h3>
<p>Graph Neural Networks are perfectly suited to capture latent interactions
between various entities in the spatio-temporal domain (e.g. videos). However,
when an explicit structure is not available, it is not obvious what atomic
elements should be represented as nodes. Current works generally use
pre-trained object detectors or fixed, predefined regions to extract graph
nodes. In turn, our proposed model learns nodes that dynamically attach to
salient space-time regions, which are relevant for a higher-level task, without
using any object-level supervision. Constructing these localised, adaptive
nodes gives our model inductive bias towards object-centric representations and
we show that it discovers regions that are well correlated with objects in the
video. The localised nodes are the key components of the method and visualising
their regions leads to a more explainable model. In extensive ablation studies
and experiments on two challenging datasets we show superior performance to
previous graph neural networks models for video classification.
</p>
<a href="http://arxiv.org/abs/2009.08427" target="_blank">arXiv:2009.08427</a> [<a href="http://arxiv.org/pdf/2009.08427" target="_blank">pdf</a>]

<h2>Rethinking Attention with Performers. (arXiv:2009.14794v2 [cs.LG] UPDATED)</h2>
<h3>Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin, Lukasz Kaiser, David Belanger, Lucy Colwell, Adrian Weller</h3>
<p>We introduce Performers, Transformer architectures which can estimate regular
(softmax) full-rank-attention Transformers with provable accuracy, but using
only linear (as opposed to quadratic) space and time complexity, without
relying on any priors such as sparsity or low-rankness. To approximate softmax
attention-kernels, Performers use a novel Fast Attention Via positive
Orthogonal Random features approach (FAVOR+), which may be of independent
interest for scalable kernel methods. FAVOR+ can be also used to efficiently
model kernelizable attention mechanisms beyond softmax. This representational
power is crucial to accurately compare softmax with other kernels for the first
time on large-scale tasks, beyond the reach of regular Transformers, and
investigate optimal attention-kernels. Performers are linear architectures
fully compatible with regular Transformers and with strong theoretical
guarantees: unbiased or nearly-unbiased estimation of the attention matrix,
uniform convergence and low estimation variance. We tested Performers on a rich
set of tasks stretching from pixel-prediction through text models to protein
sequence modeling. We demonstrate competitive results with other examined
efficient sparse and dense attention methods, showcasing effectiveness of the
novel attention-learning paradigm leveraged by Performers.
</p>
<a href="http://arxiv.org/abs/2009.14794" target="_blank">arXiv:2009.14794</a> [<a href="http://arxiv.org/pdf/2009.14794" target="_blank">pdf</a>]

<h2>Approximate Message Passing with Spectral Initialization for Generalized Linear Models. (arXiv:2010.03460v2 [stat.ML] UPDATED)</h2>
<h3>Marco Mondelli, Ramji Venkataramanan</h3>
<p>We consider the problem of estimating a signal from measurements obtained via
a generalized linear model. We focus on estimators based on approximate message
passing (AMP), a family of iterative algorithms with many appealing features:
the performance of AMP in the high-dimensional limit can be succinctly
characterized under suitable model assumptions; AMP can also be tailored to the
empirical distribution of the signal entries, and for a wide class of
estimation problems, AMP is conjectured to be optimal among all polynomial-time
algorithms.

However, a major issue of AMP is that in many models (such as phase
retrieval), it requires an initialization correlated with the ground-truth
signal and independent from the measurement matrix. Assuming that such an
initialization is available is typically not realistic. In this paper, we solve
this problem by proposing an AMP algorithm initialized with a spectral
estimator. With such an initialization, the standard AMP analysis fails since
the spectral estimator depends in a complicated way on the design matrix. Our
main contribution is a rigorous characterization of the performance of AMP with
spectral initialization in the high-dimensional limit. The key technical idea
is to define and analyze a two-phase artificial AMP algorithm that first
produces the spectral estimator, and then closely approximates the iterates of
the true AMP. We also provide numerical results that demonstrate the validity
of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2010.03460" target="_blank">arXiv:2010.03460</a> [<a href="http://arxiv.org/pdf/2010.03460" target="_blank">pdf</a>]

<h2>An Active Sense and Avoid System for Flying Robots in Dynamic Environments. (arXiv:2010.04977v2 [cs.RO] UPDATED)</h2>
<h3>Gang Chen, Wei Dong, Xinjun Sheng, Xiangyang Zhu, Han Ding</h3>
<p>This paper investigates a novel active-sensing-based obstacle avoidance
paradigm for flying robots in dynamic environments. Instead of fusing multiple
sensors to enlarge the field of view (FOV), we introduce an alternative
approach that utilizes a stereo camera with an independent rotational DOF to
sense the obstacles actively. In particular, the sensing direction is planned
heuristically by multiple objectives, including tracking dynamic obstacles,
observing the heading direction, and exploring the previously unseen area. With
the sensing result, a flight path is then planned based on real-time sampling
and uncertainty-aware collision checking in the state space, which constitutes
an active sense and avoid (ASAA) system. Experiments in both simulation and the
real world demonstrate that this system can well cope with dynamic obstacles
and abrupt goal direction changes. Since only one stereo camera is utilized,
this system provides a low-cost and effective approach to overcome the FOV
limitation in visual navigation.
</p>
<a href="http://arxiv.org/abs/2010.04977" target="_blank">arXiv:2010.04977</a> [<a href="http://arxiv.org/pdf/2010.04977" target="_blank">pdf</a>]

<h2>Deep learning for detection and segmentation of artefact and disease instances in gastrointestinal endoscopy. (arXiv:2010.06034v2 [cs.CV] UPDATED)</h2>
<h3>Sharib Ali, Mariia Dmitrieva, Noha Ghatwary, Sophia Bano, Gorkem Polat, Alptekin Temizel, Adrian Krenzer, Amar Hekalo, Yun Bo Guo, Bogdan Matuszewski, Mourad Gridach, Irina Voiculescu, Vishnusai Yoganand, Arnav Chavan, Aryan Raj, Nhan T. Nguyen, Dat Q. Tran, Le Duy Huynh, Nicolas Boutry, Shahadate Rezvy, Haijian Chen, Yoon Ho Choi, Anand Subramanian, Velmurugan Balasubramanian, Xiaohong W. Gao, Hongyu Hu, Yusheng Liao, Danail Stoyanov, Christian Daul, Stefano Realdon, Renato Cannizzaro, Dominique Lamarque, Terry Tran-Nguyen, Adam Bailey, Barbara Braden, James East, Jens Rittscher</h3>
<p>The Endoscopy Computer Vision Challenge (EndoCV) is a crowd-sourcing
initiative to address eminent problems in developing reliable computer aided
detection and diagnosis endoscopy systems and suggest a pathway for clinical
translation of technologies. Whilst endoscopy is a widely used diagnostic and
treatment tool for hollow-organs, there are several core challenges often faced
by endoscopists, mainly: 1) presence of multi-class artefacts that hinder their
visual interpretation, and 2) difficulty in identifying subtle precancerous
precursors and cancer abnormalities. Artefacts often affect the robustness of
deep learning methods applied to the gastrointestinal tract organs as they can
be confused with tissue of interest. EndoCV2020 challenges are designed to
address research questions in these remits. In this paper, we present a summary
of methods developed by the top 17 teams and provide an objective comparison of
state-of-the-art methods and methods designed by the participants for two
sub-challenges: i) artefact detection and segmentation (EAD2020), and ii)
disease detection and segmentation (EDD2020). Multi-center, multi-organ,
multi-class, and multi-modal clinical endoscopy datasets were compiled for both
EAD2020 and EDD2020 sub-challenges. The out-of-sample generalization ability of
detection algorithms was also evaluated. Whilst most teams focused on accuracy
improvements, only a few methods hold credibility for clinical usability. The
best performing teams provided solutions to tackle class imbalance, and
variabilities in size, origin, modality and occurrences by exploring data
augmentation, data fusion, and optimal class thresholding techniques.
</p>
<a href="http://arxiv.org/abs/2010.06034" target="_blank">arXiv:2010.06034</a> [<a href="http://arxiv.org/pdf/2010.06034" target="_blank">pdf</a>]

<h2>Deep Conditional Transformation Models. (arXiv:2010.07860v3 [cs.LG] UPDATED)</h2>
<h3>Philipp F.M. Baumann, Torsten Hothorn, David R&#xfc;gamer</h3>
<p>Learning the cumulative distribution function (CDF) of an outcome variable
conditional on a set of features remains challenging, especially in
high-dimensional settings. Conditional transformation models provide a
semi-parametric approach that allows to model a large class of conditional CDFs
without an explicit parametric distribution assumption and with only a few
parameters. Existing estimation approaches within this class are, however,
either limited in their complexity and applicability to unstructured data
sources such as images or text, lack interpretability, or are restricted to
certain types of outcomes. We close this gap by introducing the class of deep
conditional transformation models which unifies existing approaches and allows
to learn both interpretable (non-)linear model terms and more complex neural
network predictors in one holistic framework. To this end we propose a novel
network architecture, provide details on different model definitions and derive
suitable constraints as well as network regularization terms. We demonstrate
the efficacy of our approach through numerical experiments and applications.
</p>
<a href="http://arxiv.org/abs/2010.07860" target="_blank">arXiv:2010.07860</a> [<a href="http://arxiv.org/pdf/2010.07860" target="_blank">pdf</a>]

<h2>From Local Structures to Size Generalization in Graph Neural Networks. (arXiv:2010.08853v2 [cs.LG] UPDATED)</h2>
<h3>Gilad Yehudai, Ethan Fetaya, Eli Meirom, Gal Chechik, Haggai Maron</h3>
<p>Graph neural networks (GNNs) can process graphs of different sizes, but their
ability to generalize across sizes, specifically from small to large graphs, is
still not well understood. In this paper, we identify an important type of data
where generalization from small to large graphs is challenging: graph
distributions for which the local structure depends on the graph size. This
effect occurs in multiple important graph learning domains, including social
and biological networks. We first prove that when there is a difference between
the local structures, GNNs are not guaranteed to generalize across sizes: there
are "bad" global minima that do well on small graphs but fail on large graphs.
We then study the size-generalization problem empirically and demonstrate that
when there is a discrepancy in local structure, GNNs tend to converge to
non-generalizing solutions in practice. Finally, we suggest two approaches for
improving size generalization, motivated by our findings. Notably, we propose a
novel Self-Supervised Learning (SSL) task aimed at learning meaningful
representations of local structures that appear in large graphs. Our SSL task
improves classification accuracy on several popular datasets.
</p>
<a href="http://arxiv.org/abs/2010.08853" target="_blank">arXiv:2010.08853</a> [<a href="http://arxiv.org/pdf/2010.08853" target="_blank">pdf</a>]

<h2>Planning with Learned Dynamics: Guaranteed Safety and Reachability via Lipschitz Constants. (arXiv:2010.08993v2 [cs.RO] UPDATED)</h2>
<h3>Craig Knuth, Glen Chou, Necmiye Ozay, Dmitry Berenson</h3>
<p>We present an approach for feedback motion planning of systems with unknown
dynamics which provides guarantees on safety, reachability, and stability about
the goal. Given a learned control-affine approximation of the true dynamics, we
estimate the Lipschitz constant of the difference between the true and learned
dynamics to determine a trusted domain for our learned model. Provided the
system has at least as many controls as states, we further derive the
conditions under which a one-step feedback law exists. This allows fora small
bound on the tracking error when the trajectory is executed on the real system.
Our method imposes a check for the existence of the feedback law as constraints
in a sampling-based planner, which returns a feedback policy ensuring that
under the true dynamics, the goal is reachable, the path is safe in execution,
and the closed-loop system is invariant in a small set about the goal. We
demonstrate our approach by planning using learned models of a 6D quadrotor and
a 7DOF Kuka arm.We show that a baseline which plans using the same learned
dynamics without considering the error bound or the existence of the feedback
law can fail to stabilize around the plan and become unsafe.
</p>
<a href="http://arxiv.org/abs/2010.08993" target="_blank">arXiv:2010.08993</a> [<a href="http://arxiv.org/pdf/2010.08993" target="_blank">pdf</a>]

<h2>Pathfinder Discovery Networks for Neural Message Passing. (arXiv:2010.12878v2 [cs.LG] UPDATED)</h2>
<h3>Benedek Rozemberczki, Peter Englert, Amol Kapoor, Martin Blais, Bryan Perozzi</h3>
<p>In this work we propose Pathfinder Discovery Networks (PDNs), a method for
jointly learning a message passing graph over a multiplex network with a
downstream semi-supervised model. PDNs inductively learn an aggregated weight
for each edge, optimized to produce the best outcome for the downstream
learning task. PDNs are a generalization of attention mechanisms on graphs
which allow flexible construction of similarity functions between nodes, edge
convolutions, and cheap multiscale mixing layers. We show that PDNs overcome
weaknesses of existing methods for graph attention (e.g. Graph Attention
Networks), such as the diminishing weight problem. Our experimental results
demonstrate competitive predictive performance on academic node classification
tasks. Additional results from a challenging suite of node classification
experiments show how PDNs can learn a wider class of functions than existing
baselines. We analyze the relative computational complexity of PDNs, and show
that PDN runtime is not considerably higher than static-graph models. Finally,
we discuss how PDNs can be used to construct an easily interpretable attention
mechanism that allows users to understand information propagation in the graph.
</p>
<a href="http://arxiv.org/abs/2010.12878" target="_blank">arXiv:2010.12878</a> [<a href="http://arxiv.org/pdf/2010.12878" target="_blank">pdf</a>]

<h2>Saddle-Point Problems, Lower Bounds, GANs, Distributed Learning, Federated Learning. (arXiv:2010.13112v3 [cs.LG] UPDATED)</h2>
<h3>Aleksandr Beznosikov, Valentin Samokhin, Alexander Gasnikov</h3>
<p>GAN is one of the most popular and commonly used neural network models. When
the model is large and there is a lot of data, the learning process can be
delayed. The standard way out is to use multiple devices. Therefore, the
methods of distributed and federated training for GANs are an important
question. But from an optimization point of view, GANs are saddle-point
problems: $\min_x \max_y f(x,y)$. Therefore, this paper focuses on the
distributed optimization of smooth stochastic saddle-point problems. The first
part of the paper is devoted to lower bounds for the distributed methods for
saddle-point problems as well as the optimal algorithms by which these bounds
are achieved. Next, we present a new algorithm for distributed saddle-point
problems - Extra Step Local SGD. In the experimental part of the paper, we use
the Local SGD technique in practice. In particular, we train GANs in a
distributed manner.
</p>
<a href="http://arxiv.org/abs/2010.13112" target="_blank">arXiv:2010.13112</a> [<a href="http://arxiv.org/pdf/2010.13112" target="_blank">pdf</a>]

<h2>Biases in Generative Art -- A Causal Look from the Lens of Art History. (arXiv:2010.13266v2 [cs.AI] UPDATED)</h2>
<h3>Ramya Srinivasan, Kanji Uchino</h3>
<p>With rapid progress in artificial intelligence (AI), popularity of generative
art has grown substantially. From creating paintings to generating novel art
styles, AI based generative art has showcased a variety of applications.
However, there has been little focus concerning the ethical impacts of AI based
generative art. In this work, we investigate biases in the generative art AI
pipeline right from those that can originate due to improper problem
formulation to those related to algorithm design. Viewing from the lens of art
history, we discuss the socio-cultural impacts of these biases. Leveraging
causal models, we highlight how current methods fall short in modeling the
process of art creation and thus contribute to various types of biases. We
illustrate the same through case studies, in particular those related to style
transfer. To the best of our knowledge, this is the first extensive analysis
that investigates biases in the generative art AI pipeline from the perspective
of art history. We hope our work sparks interdisciplinary discussions related
to accountability of generative art.
</p>
<a href="http://arxiv.org/abs/2010.13266" target="_blank">arXiv:2010.13266</a> [<a href="http://arxiv.org/pdf/2010.13266" target="_blank">pdf</a>]

<h2>Graph embedding using multi-layer adjacent point merging model. (arXiv:2010.14773v2 [cs.LG] UPDATED)</h2>
<h3>Jianming Huang, Hiroyuki Kasai</h3>
<p>For graph classification tasks, many traditional kernel methods focus on
measuring the similarity between graphs. These methods have achieved great
success on resolving graph isomorphism problems. However, in some
classification problems, the graph class depends on not only the topological
similarity of the whole graph, but also constituent subgraph patterns. To this
end, we propose a novel graph embedding method using a multi-layer adjacent
point merging model. This embedding method allows us to extract different
subgraph patterns from train-data. Then we present a flexible loss function for
feature selection which enhances the robustness of our method for different
classification problems. Finally, numerical evaluations demonstrate that our
proposed method outperforms many state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.14773" target="_blank">arXiv:2010.14773</a> [<a href="http://arxiv.org/pdf/2010.14773" target="_blank">pdf</a>]

<h2>Affordance-Aware Handovers with Human Arm Mobility Constraints. (arXiv:2010.15436v2 [cs.RO] UPDATED)</h2>
<h3>Paola Ard&#xf3;n, Maria E. Cabrera, &#xc8;ric Pairet, Ronald P. A. Petrick, Subramanian Ramamoorthy, Katrin S. Lohan, Maya Cakmak</h3>
<p>Reasoning about object handover configurations allows an assistive agent to
estimate the appropriateness of handover for a receiver with different arm
mobility capacities. While there are existing approaches for estimating the
effectiveness of handovers, their findings are limited to users without arm
mobility impairments and to specific objects. Therefore, current
state-of-the-art approaches are unable to hand over novel objects to receivers
with different arm mobility capacities. We propose a method that generalises
handover behaviours to previously unseen objects, subject to the constraint of
a user's arm mobility levels and the task context. We propose a
heuristic-guided hierarchically optimised cost whose optimisation adapts object
configurations for receivers with low arm mobility. This also ensures that the
robot grasps consider the context of the user's upcoming task, i.e., the usage
of the object. To understand preferences over handover configurations, we
report on the findings of an online study, wherein we presented different
handover methods, including ours, to $259$ users with different levels of arm
mobility. We find that people's preferences over handover methods are
correlated to their arm mobility capacities. We encapsulate these preferences
in a statistical relational model (SRL) that is able to reason about the most
suitable handover configuration given a receiver's arm mobility and upcoming
task. Using our SRL model, we obtained an average handover accuracy of $90.8\%$
when generalising handovers to novel objects.
</p>
<a href="http://arxiv.org/abs/2010.15436" target="_blank">arXiv:2010.15436</a> [<a href="http://arxiv.org/pdf/2010.15436" target="_blank">pdf</a>]

<h2>Fair Classification with Group-Dependent Label Noise. (arXiv:2011.00379v2 [cs.LG] UPDATED)</h2>
<h3>Jialu Wang, Yang Liu, Caleb Levy</h3>
<p>This work examines how to train fair classifiers in settings where training
labels are corrupted with random noise, and where the error rates of corruption
depend both on the label class and on the membership function for a protected
subgroup. Heterogeneous label noise models systematic biases towards particular
groups when generating annotations. We begin by presenting analytical results
which show that naively imposing parity constraints on demographic disparity
measures, without accounting for heterogeneous and group-dependent error rates,
can decrease both the accuracy and the fairness of the resulting classifier.
Our experiments demonstrate these issues arise in practice as well. We address
these problems by performing empirical risk minimization with carefully defined
surrogate loss functions and surrogate constraints that help avoid the pitfalls
introduced by heterogeneous label noise. We provide both theoretical and
empirical justifications for the efficacy of our methods. We view our results
as an important example of how imposing fairness on biased data sets without
proper care can do at least as much harm as it does good.
</p>
<a href="http://arxiv.org/abs/2011.00379" target="_blank">arXiv:2011.00379</a> [<a href="http://arxiv.org/pdf/2011.00379" target="_blank">pdf</a>]

<h2>Semi-Structured Deep Piecewise Exponential Models. (arXiv:2011.05824v2 [cs.LG] UPDATED)</h2>
<h3>Philipp Kopper, Sebastian P&#xf6;lsterl, Christian Wachinger, Bernd Bischl, Andreas Bender, David R&#xfc;gamer</h3>
<p>We propose a versatile framework for survival analysis that combines advanced
concepts from statistics with deep learning. The presented framework is based
on piecewise exponential models and thereby supports various survival tasks,
such as competing risks and multi-state modeling, and further allows for
estimation of time-varying effects and time-varying features. To also include
multiple data sources and higher-order interaction effects into the model, we
embed the model class in a neural network and thereby enable the simultaneous
estimation of both inherently interpretable structured regression inputs as
well as deep neural network components which can potentially process additional
unstructured data sources. A proof of concept is provided by using the
framework to predict Alzheimer's disease progression based on tabular and 3D
point cloud data and applying it to synthetic data.
</p>
<a href="http://arxiv.org/abs/2011.05824" target="_blank">arXiv:2011.05824</a> [<a href="http://arxiv.org/pdf/2011.05824" target="_blank">pdf</a>]

<h2>Unified Multi-Modal Landmark Tracking for Tightly Coupled Lidar-Visual-Inertial Odometry. (arXiv:2011.06838v3 [cs.RO] UPDATED)</h2>
<h3>David Wisth, Marco Camurri, Sandipan Das, Maurice Fallon</h3>
<p>We present an efficient multi-sensor odometry system for mobile platforms
that jointly optimizes visual, lidar, and inertial information within a single
integrated factor graph. This runs in real-time at full framerate using fixed
lag smoothing. To perform such tight integration, a new method to extract 3D
line and planar primitives from lidar point clouds is presented. This approach
overcomes the suboptimality of typical frame-to-frame tracking methods by
treating the primitives as landmarks and tracking them over multiple scans.
True integration of lidar features with standard visual features and IMU is
made possible using a subtle passive synchronization of lidar and camera
frames. The lightweight formulation of the 3D features allows for real-time
execution on a single CPU. Our proposed system has been tested on a variety of
platforms and scenarios, including underground exploration with a legged robot
and outdoor scanning with a dynamically moving handheld device, for a total
duration of 96 min and 2.4 km traveled distance. In these test sequences, using
only one exteroceptive sensor leads to failure due to either underconstrained
geometry (affecting lidar) or textureless areas caused by aggressive lighting
changes (affecting vision). In these conditions, our factor graph naturally
uses the best information available from each sensor modality without any hard
switches.
</p>
<a href="http://arxiv.org/abs/2011.06838" target="_blank">arXiv:2011.06838</a> [<a href="http://arxiv.org/pdf/2011.06838" target="_blank">pdf</a>]

<h2>Your "Labrador" is My "Dog": Fine-Grained, or Not. (arXiv:2011.09040v2 [cs.CV] UPDATED)</h2>
<h3>Dongliang Chang, Kaiyue Pang, Yixiao Zheng, Zhanyu Ma, Yi-Zhe Song, Jun Guo</h3>
<p>Whether what you see in Figure 1 is a "labrador" or a "dog", is the question
we ask in this paper. While fine-grained visual classification (FGVC) strives
to arrive at the former, for the majority of us non-experts just "dog" would
probably suffice. The real question is therefore -- how can we tailor for
different fine-grained definitions under divergent levels of expertise. For
that, we re-envisage the traditional setting of FGVC, from single-label
classification, to that of top-down traversal of a pre-defined coarse-to-fine
label hierarchy -- so that our answer becomes "dog"--&gt;"gun
dog"--&gt;"retriever"--&gt;"labrador". To approach this new problem, we first conduct
a comprehensive human study where we confirm that most participants prefer
multi-granularity labels, regardless whether they consider themselves experts.
We then discover the key intuition that: coarse-level label prediction
exacerbates fine-grained feature learning, yet fine-level feature betters the
learning of coarse-level classifier. This discovery enables us to design a very
simple albeit surprisingly effective solution to our new problem, where we (i)
leverage level-specific classification heads to disentangle coarse-level
features with fine-grained ones, and (ii) allow finer-grained features to
participate in coarser-grained label predictions, which in turn helps with
better disentanglement. Experiments show that our method achieves superior
performance in the new FGVC setting, and performs better than state-of-the-art
on traditional single-label FGVC problem as well. Thanks to its simplicity, our
method can be easily implemented on top of any existing FGVC frameworks and is
parameter-free.
</p>
<a href="http://arxiv.org/abs/2011.09040" target="_blank">arXiv:2011.09040</a> [<a href="http://arxiv.org/pdf/2011.09040" target="_blank">pdf</a>]

<h2>QuerYD: A video dataset with high-quality text and audio narrations. (arXiv:2011.11071v2 [cs.CV] UPDATED)</h2>
<h3>Andreea-Maria Oncescu, Jo&#xe3;o F. Henriques, Yang Liu, Andrew Zisserman, Samuel Albanie</h3>
<p>We introduce QuerYD, a new large-scale dataset for retrieval and event
localisation in video. A unique feature of our dataset is the availability of
two audio tracks for each video: the original audio, and a high-quality spoken
description of the visual content. The dataset is based on YouDescribe, a
volunteer project that assists visually-impaired people by attaching voiced
narrations to existing YouTube videos. This ever-growing collection of videos
contains highly detailed, temporally aligned audio and text annotations. The
content descriptions are more relevant than dialogue, and more detailed than
previous description attempts, which can be observed to contain many
superficial or uninformative descriptions. To demonstrate the utility of the
QuerYD dataset, we show that it can be used to train and benchmark strong
models for retrieval and event localisation. Data, code and models are made
publicly available, and we hope that QuerYD inspires further research on video
understanding with written and spoken natural language.
</p>
<a href="http://arxiv.org/abs/2011.11071" target="_blank">arXiv:2011.11071</a> [<a href="http://arxiv.org/pdf/2011.11071" target="_blank">pdf</a>]

<h2>Improving Makespan in Dynamic Task Allocation for Cloud Robotic Systems with Time Window Constraints. (arXiv:2012.03555v2 [cs.RO] UPDATED)</h2>
<h3>Saeid Alirezazadeh, Lu&#xed;s A. Alexandre</h3>
<p>A scheduling method in a robotic network cloud system with minimal makespan
is beneficial because the system can complete all tasks assigned to it in the
fastest way. Robotic network cloud systems can be translated into graphs, where
nodes represent hardware with independent computing power and edges represent
data transmissions between nodes. Time-window constraints on tasks are a
natural way to order tasks. The makespan is the maximum amount of time between
when a node starts executing its first scheduled task and when all nodes have
completed their last scheduled task. The load balancing scheduling ensures that
the time between when the first node completes its scheduled tasks and when all
other nodes complete their scheduled tasks is as short as possible. We propose
a new load balancing algorithm for task scheduling with minimal makespan. We
prove the correctness of the proposed algorithm and present simulations
illustrating the obtained results.
</p>
<a href="http://arxiv.org/abs/2012.03555" target="_blank">arXiv:2012.03555</a> [<a href="http://arxiv.org/pdf/2012.03555" target="_blank">pdf</a>]

<h2>Adversarial Linear Contextual Bandits with Graph-Structured Side Observations. (arXiv:2012.05756v3 [cs.LG] UPDATED)</h2>
<h3>Lingda Wang, Bingcong Li, Huozhi Zhou, Georgios B. Giannakis, Lav R. Varshney, Zhizhen Zhao</h3>
<p>This paper studies the adversarial graphical contextual bandits, a variant of
adversarial multi-armed bandits that leverage two categories of the most common
side information: \emph{contexts} and \emph{side observations}. In this
setting, a learning agent repeatedly chooses from a set of $K$ actions after
being presented with a $d$-dimensional context vector. The agent not only
incurs and observes the loss of the chosen action, but also observes the losses
of its neighboring actions in the observation structures, which are encoded as
a series of feedback graphs. This setting models a variety of applications in
social networks, where both contexts and graph-structured side observations are
available. Two efficient algorithms are developed based on \texttt{EXP3}. Under
mild conditions, our analysis shows that for undirected feedback graphs the
first algorithm, \texttt{EXP3-LGC-U}, achieves the regret of order
$\mathcal{O}(\sqrt{(K+\alpha(G)d)T\log{K}})$ over the time horizon $T$, where
$\alpha(G)$ is the average \emph{independence number} of the feedback graphs. A
slightly weaker result is presented for the directed graph setting as well. The
second algorithm, \texttt{EXP3-LGC-IX}, is developed for a special class of
problems, for which the regret is reduced to
$\mathcal{O}(\sqrt{\alpha(G)dT\log{K}\log(KT)})$ for both directed as well as
undirected feedback graphs. Numerical tests corroborate the efficiency of
proposed algorithms.
</p>
<a href="http://arxiv.org/abs/2012.05756" target="_blank">arXiv:2012.05756</a> [<a href="http://arxiv.org/pdf/2012.05756" target="_blank">pdf</a>]

<h2>Information-Preserving Contrastive Learning for Self-Supervised Representations. (arXiv:2012.09962v2 [cs.LG] UPDATED)</h2>
<h3>Tianhong Li, Lijie Fan, Yuan Yuan, Hao He, Yonglong Tian, Dina Katabi</h3>
<p>Contrastive learning is very effective at learning useful representations
without supervision. Yet contrastive learning has its limitations. It may learn
a shortcut that is irrelevant to the downstream task, and discard relevant
information. Past work has addressed this limitation via custom data
augmentations that eliminate the shortcut. This solution however does not work
for data modalities that are not interpretable by humans, e.g., radio signals.
For such modalities, it is hard for a human to guess which shortcuts may exist
in the signal, or how they can be eliminated. Even for interpretable data,
sometimes eliminating the shortcut may be undesirable. The shortcut may be
irrelevant to one downstream task but important to another. In this case, it is
desirable to learn a representation that captures both the shortcut information
and the information relevant to the other downstream task. This paper presents
information-preserving contrastive learning (IPCL), a new framework for
unsupervised representation learning that preserves relevant information even
in the presence of shortcuts. We empirically show that the representations
learned by IPCL outperforms contrastive learning in supporting different
modalities and multiple diverse downstream tasks.
</p>
<a href="http://arxiv.org/abs/2012.09962" target="_blank">arXiv:2012.09962</a> [<a href="http://arxiv.org/pdf/2012.09962" target="_blank">pdf</a>]

<h2>CIZSL++: Creativity Inspired Generative Zero-Shot Learning. (arXiv:2101.00173v2 [cs.CV] UPDATED)</h2>
<h3>Mohamed Elhoseiny, Kai Yi, Mohamed Elfeki</h3>
<p>Zero-shot learning (ZSL) aims at understanding unseen categories with no
training examples from class-level descriptions. To improve the discriminative
power of ZSL, we model the visual learning process of unseen categories with
inspiration from the psychology of human creativity for producing novel art.
First, we propose CIZSL-v1 as a creativity inspired model for generative ZSL.
We relate ZSL to human creativity by observing that ZSL is about recognizing
the unseen, and creativity is about creating a likable unseen. We introduce a
learning signal inspired by creativity literature that explores the unseen
space with hallucinated class-descriptions and encourages careful deviation of
their visual feature generations from seen classes while allowing knowledge
transfer from seen to unseen classes. Second, CIZSL-v2 is proposed as an
improved version of CIZSL-v1 for generative zero-shot learning. CIZSL-v2
consists of an investigation of additional inductive losses for unseen classes
along with a semantic guided discriminator. Empirically, we show consistently
that CIZSL losses can improve generative ZSL models on the challenging task of
generalized ZSL from a noisy text on CUB and NABirds datasets. We also show the
advantage of our approach to Attribute-based ZSL on AwA2, aPY, and SUN
datasets. We also show that CIZSL-v2 has improved performance compared to
CIZSL-v1.
</p>
<a href="http://arxiv.org/abs/2101.00173" target="_blank">arXiv:2101.00173</a> [<a href="http://arxiv.org/pdf/2101.00173" target="_blank">pdf</a>]

<h2>CLeaR: An Adaptive Continual Learning Framework for Regression Tasks. (arXiv:2101.00926v2 [cs.LG] UPDATED)</h2>
<h3>Yujiang He, Bernhard Sick</h3>
<p>Catastrophic forgetting means that a trained neural network model gradually
forgets the previously learned tasks when being retrained on new tasks.
Overcoming the forgetting problem is a major problem in machine learning.
Numerous continual learning algorithms are very successful in incremental
learning of classification tasks, where new samples with their labels appear
frequently. However, there is currently no research that addresses the
catastrophic forgetting problem in regression tasks as far as we know. This
problem has emerged as one of the primary constraints in some applications,
such as renewable energy forecasts. This article clarifies problem-related
definitions and proposes a new methodological framework that can forecast
targets and update itself by means of continual learning. The framework
consists of forecasting neural networks and buffers, which store newly
collected data from a non-stationary data stream in an application. The changed
probability distribution of the data stream, which the framework has
identified, will be learned sequentially. The framework is called CLeaR
(Continual Learning for Regression Tasks), where components can be flexibly
customized for a specific application scenario. We design two sets of
experiments to evaluate the CLeaR framework concerning fitting error
(training), prediction error (test), and forgetting ratio. The first one is
based on an artificial time series to explore how hyperparameters affect the
CLeaR framework. The second one is designed with data collected from European
wind farms to evaluate the CLeaR framework's performance in a real-world
application. The experimental results demonstrate that the CLeaR framework can
continually acquire knowledge in the data stream and improve the prediction
accuracy. The article concludes with further research issues arising from
requirements to extend the framework.
</p>
<a href="http://arxiv.org/abs/2101.00926" target="_blank">arXiv:2101.00926</a> [<a href="http://arxiv.org/pdf/2101.00926" target="_blank">pdf</a>]

<h2>Hyperbolic Deep Neural Networks: A Survey. (arXiv:2101.04562v3 [cs.LG] UPDATED)</h2>
<h3>Wei Peng, Tuomas Varanka, Abdelrahman Mostafa, Henglin Shi, Guoying Zhao</h3>
<p>Recently, there has been a rising surge of momentum for deep representation
learning in hyperbolic spaces due to theirhigh capacity of modeling data like
knowledge graphs or synonym hierarchies, possessing hierarchical structure. We
refer to the model as hyperbolic deep neural network in this paper. Such a
hyperbolic neural architecture potentially leads to drastically compact model
withmuch more physical interpretability than its counterpart in Euclidean
space. To stimulate future research, this paper presents acoherent and
comprehensive review of the literature around the neural components in the
construction of hyperbolic deep neuralnetworks, as well as the generalization
of the leading deep approaches to the Hyperbolic space. It also presents
current applicationsaround various machine learning tasks on several publicly
available datasets, together with insightful observations and identifying
openquestions and promising future directions.
</p>
<a href="http://arxiv.org/abs/2101.04562" target="_blank">arXiv:2101.04562</a> [<a href="http://arxiv.org/pdf/2101.04562" target="_blank">pdf</a>]

<h2>Intact-VAE: Estimating Treatment Effects under Unobserved Confounding. (arXiv:2101.06662v2 [stat.ML] UPDATED)</h2>
<h3>Pengzhou Wu, Kenji Fukumizu</h3>
<p>As an important problem of causal inference, we discuss the identification
and estimation of treatment effects under unobserved confounding. Representing
the confounder as a latent variable, we propose Intact-VAE, a new variant of
variational autoencoder (VAE), motivated by the prognostic score that is
sufficient for identifying treatment effects. We theoretically show that, under
certain settings, treatment effects are identified by our model, and further,
based on the identifiability of our model (i.e., determinacy of
representation), our VAE is a consistent estimator with representation balanced
for treatment groups. Experiments on (semi-)synthetic datasets show
state-of-the-art performance under diverse settings.
</p>
<a href="http://arxiv.org/abs/2101.06662" target="_blank">arXiv:2101.06662</a> [<a href="http://arxiv.org/pdf/2101.06662" target="_blank">pdf</a>]

<h2>Stochastic High Fidelity Simulation and Scenarios for Testing of Fixed Wing Autonomous GNSS-Denied Navigation Algorithms. (arXiv:2102.00883v2 [cs.RO] UPDATED)</h2>
<h3>Eduardo Gallo</h3>
<p>Autonomous unmanned aerial vehicle (UAV) inertial navigation exhibits an
extreme dependency on the availability of global navigation satellite systems
(GNSS) signals, without which it incurs in a slow but unavoidable position
drift that may ultimately lead to the loss of the platform if the GNSS signals
are not restored or the aircraft does not reach a location from which it can be
recovered by remote control. This article describes an stochastic high fidelity
simulation of the flight of a fixed wing low SWaP (size, weight, and power)
autonomous UAV in turbulent and varying weather intended to test and validate
the GNSS-Denied performance of different navigation algorithms. Its open-source
\nm{\CC} implementation has been released and is publicly available.

Onboard sensors include accelerometers, gyroscopes, magnetometers, a Pitot
tube, an air data system, a GNSS receiver, and a digital camera, so the
simulation is valid for inertial, visual, and visual inertial navigation
systems. Two scenarios involving the loss of GNSS signals are considered: the
first represents the challenges involved in aborting the mission and heading
towards a remote recovery location while experiencing varying weather, and the
second models the continuation of the mission based on a series of closely
spaced bearing changes.

All simulation modules have been modeled with as few simplifications as
possible to increase the realism of the results. While the implementation of
the aircraft performances and its control system is deterministic, that of all
other modules, including the mission, sensors, weather, wind, turbulence, and
initial estimations, is fully stochastic. This enables a robust evaluation of
each proposed navigation system by means of Monte-Carlo simulations that rely
on a high number of executions of both scenarios.
</p>
<a href="http://arxiv.org/abs/2102.00883" target="_blank">arXiv:2102.00883</a> [<a href="http://arxiv.org/pdf/2102.00883" target="_blank">pdf</a>]

<h2>Keep it Simple: Data-efficient Learning for Controlling Complex Systems with Simple Models. (arXiv:2102.02493v3 [cs.RO] UPDATED)</h2>
<h3>Thomas Power, Dmitry Berenson</h3>
<p>When manipulating a novel object with complex dynamics, a state
representation is not always available, for example for deformable objects.
Learning both a representation and dynamics from observations requires large
amounts of data. We propose Learned Visual Similarity Predictive Control
(LVSPC), a novel method for data-efficient learning to control systems with
complex dynamics and high-dimensional state spaces from images. LVSPC leverages
a given simple model approximation from which image observations can be
generated. We use these images to train a perception model that estimates the
simple model state from observations of the complex system online. We then use
data from the complex system to fit the parameters of the simple model and
learn where this model is inaccurate, also online. Finally, we use Model
Predictive Control and bias the controller away from regions where the simple
model is inaccurate and thus where the controller is less reliable. We evaluate
LVSPC on two tasks; manipulating a tethered mass and a rope. We find that our
method performs comparably to state-of-the-art reinforcement learning methods
with an order of magnitude less data. LVSPC also completes the rope
manipulation task on a real robot with 80% success rate after only 10 trials,
despite using a perception system trained only on images from simulation.
</p>
<a href="http://arxiv.org/abs/2102.02493" target="_blank">arXiv:2102.02493</a> [<a href="http://arxiv.org/pdf/2102.02493" target="_blank">pdf</a>]

<h2>Intensity-SLAM: Intensity Assisted Localization and Mapping for Large Scale Environment. (arXiv:2102.03798v2 [cs.RO] UPDATED)</h2>
<h3>Han Wang, Chen Wang, Lihua Xie</h3>
<p>Simultaneous Localization And Mapping (SLAM) is a task to estimate the robot
location and to reconstruct the environment based on observation from sensors
such as LIght Detection And Ranging (LiDAR) and camera. It is widely used in
robotic applications such as autonomous driving and drone delivery. Traditional
LiDAR-based SLAM algorithms mainly leverage the geometric features from the
scene context, while the intensity information from LiDAR is ignored. Some
recent deep-learning-based SLAM algorithms consider intensity features and
train the pose estimation network in an end-to-end manner. However, they
require significant data collection effort and their generalizability to
environments other than the trained one remains unclear. In this paper we
introduce intensity features to a SLAM system. And we propose a novel full SLAM
framework that leverages both geometry and intensity features. The proposed
SLAM involves both intensity-based front-end odometry estimation and
intensity-based back-end optimization. Thorough experiments are performed
including both outdoor autonomous driving and indoor warehouse robot
manipulation. The results show that the proposed method outperforms existing
geometric-only LiDAR SLAM methods.
</p>
<a href="http://arxiv.org/abs/2102.03798" target="_blank">arXiv:2102.03798</a> [<a href="http://arxiv.org/pdf/2102.03798" target="_blank">pdf</a>]

<h2>Lightweight 3-D Localization and Mapping for Solid-State LiDAR. (arXiv:2102.03800v2 [cs.RO] UPDATED)</h2>
<h3>Han Wang, Chen Wang, Lihua Xie</h3>
<p>The LIght Detection And Ranging (LiDAR) sensor has become one of the most
important perceptual devices due to its important role in simultaneous
localization and mapping (SLAM). Existing SLAM methods are mainly developed for
mechanical LiDAR sensors, which are often adopted by large scale robots.
Recently, the solid-state LiDAR is introduced and becomes popular since it
provides a cost-effective and lightweight solution for small scale robots.
Compared to mechanical LiDAR, solid-state LiDAR sensors have higher update
frequency and angular resolution, but also have smaller field of view (FoV),
which is very challenging for existing LiDAR SLAM algorithms. Therefore, it is
necessary to have a more robust and computationally efficient SLAM method for
this new sensing device. To this end, we propose a new SLAM framework for
solid-state LiDAR sensors, which involves feature extraction, odometry
estimation, and probability map building. The proposed method is evaluated on a
warehouse robot and a hand-held device. In the experiments, we demonstrate both
the accuracy and efficiency of our method using an Intel L515 solid-state
LiDAR. The results show that our method is able to provide precise localization
and high quality mapping. We made the source codes public at
\url{https://github.com/wh200720041/SSL_SLAM}.
</p>
<a href="http://arxiv.org/abs/2102.03800" target="_blank">arXiv:2102.03800</a> [<a href="http://arxiv.org/pdf/2102.03800" target="_blank">pdf</a>]

<h2>Behavioral Economics Approach to Interpretable Deep Image Classification. Rationally Inattentive Utility Maximization Explains Deep Image Classification. (arXiv:2102.04594v2 [cs.LG] UPDATED)</h2>
<h3>Kunal Pattanayak, Vikram Krishnamurthy</h3>
<p>Are deep convolutional neural networks (CNNs) for image classification
consistent with utility maximization behavior with information acquisition
costs? This paper demonstrates the remarkable result that a deep CNN behaves
equivalently (in terms of necessary and sufficient conditions) to a rationally
inattentive utility maximizer, a model extensively used in behavioral economics
to explain human decision making. This implies that a deep CNN has a
parsimonious representation in terms of simple intuitive human-like decision
parameters, namely, a utility function and an information acquisition cost.
Also the reconstructed utility function that rationalizes the decisions of the
deep CNNs, yields a useful preference order amongst the image classes
(hypotheses).
</p>
<a href="http://arxiv.org/abs/2102.04594" target="_blank">arXiv:2102.04594</a> [<a href="http://arxiv.org/pdf/2102.04594" target="_blank">pdf</a>]

<h2>AttDMM: An Attentive Deep Markov Model for Risk Scoring in Intensive Care Units. (arXiv:2102.04702v2 [cs.LG] UPDATED)</h2>
<h3>Yilmazcan &#xd6;zyurt, Mathias Kraus, Tobias Hatt, Stefan Feuerriegel</h3>
<p>Clinical practice in intensive care units (ICUs) requires early warnings when
a patient's condition is about to deteriorate so that preventive measures can
be undertaken. To this end, prediction algorithms have been developed that
estimate the risk of mortality in ICUs. In this work, we propose a novel
generative deep probabilistic model for real-time risk scoring in ICUs.
Specifically, we develop an attentive deep Markov model called AttDMM. To the
best of our knowledge, AttDMM is the first ICU prediction model that jointly
learns both long-term disease dynamics (via attention) and different disease
states in health trajectory (via a latent variable model). Our evaluations were
based on an established baseline dataset (MIMIC-III) with 53,423 ICU stays. The
results confirm that compared to state-of-the-art baselines, our AttDMM was
superior: AttDMM achieved an area under the receiver operating characteristic
curve (AUROC) of 0.876, which yielded an improvement over the state-of-the-art
method by 2.2%. In addition, the risk score from the AttDMM provided warnings
several hours earlier. Thereby, our model shows a path towards identifying
patients at risk so that health practitioners can intervene early and save
patient lives.
</p>
<a href="http://arxiv.org/abs/2102.04702" target="_blank">arXiv:2102.04702</a> [<a href="http://arxiv.org/pdf/2102.04702" target="_blank">pdf</a>]

<h2>A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes. (arXiv:2102.06356v2 [cs.LG] UPDATED)</h2>
<h3>Zachary Nado, Justin M. Gilmer, Christopher J. Shallue, Rohan Anil, George E. Dahl</h3>
<p>Recently the LARS and LAMB optimizers have been proposed for training neural
networks faster using large batch sizes. LARS and LAMB add layer-wise
normalization to the update rules of Heavy-ball momentum and Adam,
respectively, and have become popular in prominent benchmarks and deep learning
libraries. However, without fair comparisons to standard optimizers, it remains
an open question whether LARS and LAMB have any benefit over traditional,
generic algorithms. In this work we demonstrate that standard optimization
algorithms such as Nesterov momentum and Adam can match or exceed the results
of LARS and LAMB at large batch sizes. Our results establish new, stronger
baselines for future comparisons at these batch sizes and shed light on the
difficulties of comparing optimizers for neural network training more
generally.
</p>
<a href="http://arxiv.org/abs/2102.06356" target="_blank">arXiv:2102.06356</a> [<a href="http://arxiv.org/pdf/2102.06356" target="_blank">pdf</a>]

<h2>Supervised training of spiking neural networks for robust deployment on mixed-signal neuromorphic processors. (arXiv:2102.06408v2 [cs.LG] UPDATED)</h2>
<h3>Julian B&#xfc;chel, Dmitrii Zendrikov, Sergio Solinas, Giacomo Indiveri, Dylan R. Muir</h3>
<p>Mixed-signal analog/digital circuits can emulate spiking neurons and synapses
with extremely high energy efficiency, an approach known as "neuromorphic
engineering". However, analog circuits are sensitive to process-induced
variation among transistors in a chip ("device mismatch"). For neuromorphic
implementation of Spiking Neural Networks (SNNs), mismatch causes parameter
variation between identically-configured neurons and synapses. Each chip
therefore exhibits a different distribution of neural parameters, causing
deployed networks to respond differently between chips. Current solutions to
mitigate mismatch based on per-chip calibration or on-chip learning entail
increased design complexity, area and cost, making deployment of neuromorphic
devices expensive and difficult. Here we present a supervised learning approach
that addresses this challenge by maximizing robustness to mismatch and other
common sources of noise. Our method trains SNNs to perform temporal
classification tasks by mimicking a pre-trained dynamical system, using a local
learning rule adapted from non-linear control theory. We demonstrate our method
on two tasks requiring memory, and measure the robustness of our approach to
several forms of noise and mismatch. We show that our approach is more robust
than several common alternatives for training SNNs. Our method provides a
viable way to robustly deploy pre-trained networks on mixed-signal neuromorphic
hardware, without requiring per-device training or calibration.
</p>
<a href="http://arxiv.org/abs/2102.06408" target="_blank">arXiv:2102.06408</a> [<a href="http://arxiv.org/pdf/2102.06408" target="_blank">pdf</a>]

<h2>Jacobian Determinant of Normalizing Flows. (arXiv:2102.06539v2 [cs.LG] UPDATED)</h2>
<h3>Huadong Liao, Jiawei He</h3>
<p>Normalizing flows learn a diffeomorphic mapping between the target and base
distribution, while the Jacobian determinant of that mapping forms another
real-valued function. In this paper, we show that the Jacobian determinant
mapping is unique for the given distributions, hence the likelihood objective
of flows has a unique global optimum. In particular, the likelihood for a class
of flows is explicitly expressed by the eigenvalues of the auto-correlation
matrix of individual data point, and independent of the parameterization of
neural network, which provides a theoretical optimal value of likelihood
objective and relates to probabilistic PCA. Additionally, Jacobian determinant
is a measure of local volume change and is maximized when MLE is used for
optimization. To stabilize normalizing flows training, it is required to
maintain a balance between the expansiveness and contraction of volume, meaning
Lipschitz constraint on the diffeomorphic mapping and its inverse. With these
theoretical results, several principles of designing normalizing flow were
proposed. And numerical experiments on highdimensional datasets (such as
CelebA-HQ 1024x1024) were conducted to show the improved stability of training.
</p>
<a href="http://arxiv.org/abs/2102.06539" target="_blank">arXiv:2102.06539</a> [<a href="http://arxiv.org/pdf/2102.06539" target="_blank">pdf</a>]

<h2>Robust White Matter Hyperintensity Segmentation on Unseen Domain. (arXiv:2102.06650v2 [cs.CV] UPDATED)</h2>
<h3>Xingchen Zhao, Anthony Sicilia, Davneet Minhas, Erin O&#x27;Connor, Howard Aizenstein, William Klunk, Dana Tudorascu, Seong Jae Hwang</h3>
<p>Typical machine learning frameworks heavily rely on an underlying assumption
that training and test data follow the same distribution. In medical imaging
which increasingly begun acquiring datasets from multiple sites or scanners,
this identical distribution assumption often fails to hold due to systematic
variability induced by site or scanner dependent factors. Therefore, we cannot
simply expect a model trained on a given dataset to consistently work well, or
generalize, on a dataset from another distribution. In this work, we address
this problem, investigating the application of machine learning models to
unseen medical imaging data. Specifically, we consider the challenging case of
Domain Generalization (DG) where we train a model without any knowledge about
the testing distribution. That is, we train on samples from a set of
distributions (sources) and test on samples from a new, unseen distribution
(target). We focus on the task of white matter hyperintensity (WMH) prediction
using the multi-site WMH Segmentation Challenge dataset and our local in-house
dataset. We identify how two mechanically distinct DG approaches, namely domain
adversarial learning and mix-up, have theoretical synergy. Then, we show
drastic improvements of WMH prediction on an unseen target domain.
</p>
<a href="http://arxiv.org/abs/2102.06650" target="_blank">arXiv:2102.06650</a> [<a href="http://arxiv.org/pdf/2102.06650" target="_blank">pdf</a>]

<h2>Tight lower bounds for Dynamic Time Warping. (arXiv:2102.07076v2 [cs.LG] UPDATED)</h2>
<h3>Geoffrey I. Webb, Francois Petitjean</h3>
<p>Dynamic Time Warping (DTW) is a popular similarity measure for aligning and
comparing time series. Due to DTW's high computation time, lower bounds are
often employed to screen poor matches. Many alternative lower bounds have been
proposed, providing a range of different trade-offs between tightness and
computational efficiency. LB Keogh provides a useful trade-off in many
applications. Two recent lower bounds, LB Improved and LB Enhanced, are
substantially tighter than LB Keogh. All three have the same worst case
computational complexity - linear with respect to series length and constant
with respect to window size. We present four new DTW lower bounds in the same
complexity class. LB Petitjean is substantially tighter than LB Improved, with
only modest additional computational overhead. LB Webb is more efficient than
LB Improved, while often providing a tighter bound. LB Webb is always tighter
than LB Keogh. The parameter free LB Webb is usually tighter than LB Enhanced.
A parameterized variant, LB Webb Enhanced, is always tighter than LB Enhanced.
A further variant, LB Webb*, is useful for some constrained distance functions.
In extensive experiments, LB Webb proves to be very effective for nearest
neighbor search.
</p>
<a href="http://arxiv.org/abs/2102.07076" target="_blank">arXiv:2102.07076</a> [<a href="http://arxiv.org/pdf/2102.07076" target="_blank">pdf</a>]

<h2>Efficient Designs of SLOPE Penalty Sequences in Finite Dimension. (arXiv:2102.07211v2 [stat.ML] UPDATED)</h2>
<h3>Yiliang Zhang, Zhiqi Bu</h3>
<p>In linear regression, SLOPE is a new convex analysis method that generalizes
the Lasso via the sorted L1 penalty: larger fitted coefficients are penalized
more heavily. This magnitude-dependent regularization requires an input of
penalty sequence $\lambda$, instead of a scalar penalty as in the Lasso case,
thus making the design extremely expensive in computation. In this paper, we
propose two efficient algorithms to design the possibly high-dimensional SLOPE
penalty, in order to minimize the mean squared error. For Gaussian data
matrices, we propose a first order Projected Gradient Descent (PGD) under the
Approximate Message Passing regime. For general data matrices, we present a
zero-th order Coordinate Descent (CD) to design a sub-class of SLOPE, referred
to as the k-level SLOPE. Our CD allows a useful trade-off between the accuracy
and the computation speed. We demonstrate the performance of SLOPE with our
designs via extensive experiments on synthetic data and real-world datasets.
</p>
<a href="http://arxiv.org/abs/2102.07211" target="_blank">arXiv:2102.07211</a> [<a href="http://arxiv.org/pdf/2102.07211" target="_blank">pdf</a>]

<h2>CAP-GAN: Towards Adversarial Robustness with Cycle-consistent Attentional Purification. (arXiv:2102.07304v2 [cs.LG] UPDATED)</h2>
<h3>Mingu Kang, Trung Quang Tran, Seungju Cho, Daeyoung Kim</h3>
<p>Adversarial attack is aimed at fooling the target classifier with
imperceptible perturbation. Adversarial examples, which are carefully crafted
with a malicious purpose, can lead to erroneous predictions, resulting in
catastrophic accidents. To mitigate the effects of adversarial attacks, we
propose a novel purification model called CAP-GAN. CAP-GAN takes account of the
idea of pixel-level and feature-level consistency to achieve reasonable
purification under cycle-consistent learning. Specifically, we utilize the
guided attention module and knowledge distillation to convey meaningful
information to the purification model. Once a model is fully trained, inputs
would be projected into the purification model and transformed into clean-like
images. We vary the capacity of the adversary to argue the robustness against
various types of attack strategies. On the CIFAR-10 dataset, CAP-GAN
outperforms other pre-processing based defenses under both black-box and
white-box settings.
</p>
<a href="http://arxiv.org/abs/2102.07304" target="_blank">arXiv:2102.07304</a> [<a href="http://arxiv.org/pdf/2102.07304" target="_blank">pdf</a>]

<h2>Spatio-temporal Graph-RNN for Point Cloud Prediction. (arXiv:2102.07482v2 [cs.CV] UPDATED)</h2>
<h3>Pedro Gomes, Silvia Rossi, Laura Toni</h3>
<p>In this paper, we propose an end-to-end learning network to predict future
point cloud frames. As main novelty, an initial layer learns topological
information of point clouds as geometric features, to form representative
spatio-temporal neighborhoods. This module is followed by multiple Graph-RNN
cells. Each cell learns points dynamics (i.e., RNN states) processing each
point jointly with the spatio-temporal neighbouring points. We tested the
network performance with a MINST dataset of moving digits, a synthetic human
bodies motions and JPEG dynamic bodies datasets. Simulation results demonstrate
that our method outperforms baseline ones that neglect geometry features
information.
</p>
<a href="http://arxiv.org/abs/2102.07482" target="_blank">arXiv:2102.07482</a> [<a href="http://arxiv.org/pdf/2102.07482" target="_blank">pdf</a>]

<h2>End-to-End Egospheric Spatial Memory. (arXiv:2102.07764v2 [cs.RO] UPDATED)</h2>
<h3>Daniel Lenton, Stephen James, Ronald Clark, Andrew J. Davison</h3>
<p>Spatial memory, or the ability to remember and recall specific locations and
objects, is central to autonomous agents' ability to carry out tasks in real
environments. However, most existing artificial memory modules are not very
adept at storing spatial information. We propose a parameter-free module,
Egospheric Spatial Memory (ESM), which encodes the memory in an ego-sphere
around the agent, enabling expressive 3D representations. ESM can be trained
end-to-end via either imitation or reinforcement learning, and improves both
training efficiency and final performance against other memory baselines on
both drone and manipulator visuomotor control tasks. The explicit egocentric
geometry also enables us to seamlessly combine the learned controller with
other non-learned modalities, such as local obstacle avoidance. We further show
applications to semantic segmentation on the ScanNet dataset, where ESM
naturally combines image-level and map-level inference modalities. Through our
broad set of experiments, we show that ESM provides a general computation graph
for embodied spatial reasoning, and the module forms a bridge between real-time
mapping systems and differentiable memory architectures. Implementation at:
https://github.com/ivy-dl/memory.
</p>
<a href="http://arxiv.org/abs/2102.07764" target="_blank">arXiv:2102.07764</a> [<a href="http://arxiv.org/pdf/2102.07764" target="_blank">pdf</a>]

<h2>RMIX: Learning Risk-Sensitive Policies for Cooperative Reinforcement Learning Agents. (arXiv:2102.08159v2 [cs.LG] UPDATED)</h2>
<h3>Wei Qiu, Xinrun Wang, Runsheng Yu, Xu He, Rundong Wang, Bo An, Svetlana Obraztsova, Zinovi Rabinovich</h3>
<p>Current value-based multi-agent reinforcement learning methods optimize
individual Q values to guide individuals' behaviours via centralized training
with decentralized execution (CTDE). However, such expected, i.e.,
risk-neutral, Q value is not sufficient even with CTDE due to the randomness of
rewards and the uncertainty in environments, which causes the failure of these
methods to train coordinating agents in complex environments. To address these
issues, we propose RMIX, a novel cooperative MARL method with the Conditional
Value at Risk (CVaR) measure over the learned distributions of individuals' Q
values. Specifically, we first learn the return distributions of individuals to
analytically calculate CVaR for decentralized execution. Then, to handle the
temporal nature of the stochastic outcomes during executions, we propose a
dynamic risk level predictor for risk level tuning. Finally, we optimize the
CVaR policies with CVaR values used to estimate the target in TD error during
centralized training and the CVaR values are used as auxiliary local rewards to
update the local distribution via Quantile Regression loss. Empirically, we
show that our method significantly outperforms state-of-the-art methods on
challenging StarCraft II tasks, demonstrating enhanced coordination and
improved sample efficiency.
</p>
<a href="http://arxiv.org/abs/2102.08159" target="_blank">arXiv:2102.08159</a> [<a href="http://arxiv.org/pdf/2102.08159" target="_blank">pdf</a>]

<h2>Ivy: Templated Deep Learning for Inter-Framework Portability. (arXiv:2102.02886v2 [cs.LG] CROSS LISTED)</h2>
<h3>Daniel Lenton, Fabio Pardo, Fabian Falck, Stephen James, Ronald Clark</h3>
<p>We introduce Ivy, a templated Deep Learning (DL) framework which abstracts
existing DL frameworks such that their core functions all exhibit consistent
call signatures, syntax and input-output behaviour. Ivy allows high-level
framework-agnostic functions to be implemented through the use of framework
templates. The framework templates act as placeholders for the specific
framework at development time, which are then determined at runtime. The
portability of Ivy functions enables their use in projects of any supported
framework. Ivy currently supports TensorFlow, PyTorch, MXNet, Jax and NumPy.
Alongside Ivy, we release four pure-Ivy libraries for mechanics, 3D vision,
robotics, and differentiable environments. Through our evaluations, we show
that Ivy can significantly reduce lines of code with a runtime overhead of less
than 1% in most cases. We welcome developers to join the Ivy community by
writing their own functions, layers and libraries in Ivy, maximizing their
audience and helping to accelerate DL research through the creation of lifelong
inter-framework codebases. More information can be found at https://ivy-dl.org.
</p>
<a href="http://arxiv.org/abs/2102.02886" target="_blank">arXiv:2102.02886</a> [<a href="http://arxiv.org/pdf/2102.02886" target="_blank">pdf</a>]

