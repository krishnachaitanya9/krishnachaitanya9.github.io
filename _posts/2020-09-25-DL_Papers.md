---
title: Latest Deep Learning Papers
date: 2021-01-21 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (130 Articles)</h1>
<h2>Can stable and accurate neural networks be computed? -- On the barriers of deep learning and Smale's 18th problem. (arXiv:2101.08286v1 [cs.LG])</h2>
<h3>Vegard Antun, Matthew J. Colbrook, Anders C. Hansen</h3>
<p>Deep learning (DL) has had unprecedented success and is now entering
scientific computing with full force. However, DL suffers from a universal
phenomenon: instability, despite universal approximating properties that often
guarantee the existence of stable neural networks (NNs). We show the following
paradox. There are basic well-conditioned problems in scientific computing
where one can prove the existence of NNs with great approximation qualities,
however, there does not exist any algorithm, even randomised, that can train
(or compute) such a NN. Indeed, for any positive integers $K &gt; 2$ and $L$,
there are cases where simultaneously: (a) no randomised algorithm can compute a
NN correct to $K$ digits with probability greater than $1/2$, (b) there exists
a deterministic algorithm that computes a NN with $K-1$ correct digits, but any
such (even randomised) algorithm needs arbitrarily many training data, (c)
there exists a deterministic algorithm that computes a NN with $K-2$ correct
digits using no more than $L$ training samples. These results provide basic
foundations for Smale's 18th problem and imply a potentially vast, and crucial,
classification theory describing conditions under which (stable) NNs with a
given accuracy can be computed by an algorithm. We begin this theory by
initiating a unified theory for compressed sensing and DL, leading to
sufficient conditions for the existence of algorithms that compute stable NNs
in inverse problems. We introduce Fast Iterative REstarted NETworks (FIRENETs),
which we prove and numerically verify are stable. Moreover, we prove that only
$\mathcal{O}(|\log(\epsilon)|)$ layers are needed for an $\epsilon$ accurate
solution to the inverse problem (exponential convergence), and that the inner
dimensions in the layers do not exceed the dimension of the inverse problem.
Thus, FIRENETs are computationally very efficient.
</p>
<a href="http://arxiv.org/abs/2101.08286" target="_blank">arXiv:2101.08286</a> [<a href="http://arxiv.org/pdf/2101.08286" target="_blank">pdf</a>]

<h2>Text Line Segmentation for Challenging Handwritten Document Images Using Fully Convolutional Network. (arXiv:2101.08299v1 [cs.CV])</h2>
<h3>Berat Barakat, Ahmad Droby, Majeed Kassis, Jihad El-Sana</h3>
<p>This paper presents a method for text line segmentation of challenging
historical manuscript images. These manuscript images contain narrow interline
spaces with touching components, interpenetrating vowel signs and inconsistent
font types and sizes. In addition, they contain curved, multi-skewed and
multi-directed side note lines within a complex page layout. Therefore,
bounding polygon labeling would be very difficult and time consuming. Instead
we rely on line masks that connect the components on the same text line. Then
these line masks are predicted using a Fully Convolutional Network (FCN). In
the literature, FCN has been successfully used for text line segmentation of
regular handwritten document images. The present paper shows that FCN is useful
with challenging manuscript images as well. Using a new evaluation metric that
is sensitive to over segmentation as well as under segmentation, testing
results on a publicly available challenging handwritten dataset are comparable
with the results of a previous work on the same dataset.
</p>
<a href="http://arxiv.org/abs/2101.08299" target="_blank">arXiv:2101.08299</a> [<a href="http://arxiv.org/pdf/2101.08299" target="_blank">pdf</a>]

<h2>Aesthetics, Personalization and Recommendation: A survey on Deep Learning in Fashion. (arXiv:2101.08301v1 [cs.CV])</h2>
<h3>Wei Gong, Laila Khalid</h3>
<p>Machine learning is completely changing the trends in the fashion industry.
From big to small every brand is using machine learning techniques in order to
improve their revenue, increase customers and stay ahead of the trend. People
are into fashion and they want to know what looks best and how they can improve
their style and elevate their personality. Using Deep learning technology and
infusing it with Computer Vision techniques one can do so by utilizing
Brain-inspired Deep Networks, and engaging into Neuroaesthetics, working with
GANs and Training them, playing around with Unstructured Data,and infusing the
transformer architecture are just some highlights which can be touched with the
Fashion domain. Its all about designing a system that can tell us information
regarding the fashion aspect that can come in handy with the ever growing
demand. Personalization is a big factor that impacts the spending choices of
customers.The survey also shows remarkable approaches that encroach the subject
of achieving that by divulging deep into how visual data can be interpreted and
leveraged into different models and approaches. Aesthetics play a vital role in
clothing recommendation as users' decision depends largely on whether the
clothing is in line with their aesthetics, however the conventional image
features cannot portray this directly. For that the survey also highlights
remarkable models like tensor factorization model, conditional random field
model among others to cater the need to acknowledge aesthetics as an important
factor in Apparel recommendation.These AI inspired deep models can pinpoint
exactly which certain style resonates best with their customers and they can
have an understanding of how the new designs will set in with the community.
With AI and machine learning your businesses can stay ahead of the fashion
trends.
</p>
<a href="http://arxiv.org/abs/2101.08301" target="_blank">arXiv:2101.08301</a> [<a href="http://arxiv.org/pdf/2101.08301" target="_blank">pdf</a>]

<h2>From Local Pseudorandom Generators to Hardness of Learning. (arXiv:2101.08303v1 [cs.LG])</h2>
<h3>Amit Daniely, Gal Vardi</h3>
<p>We prove hardness-of-learning results under a well-studied assumption on the
existence of local pseudorandom generators. As we show, this assumption allows
us to surpass the current state of the art, and prove hardness of various basic
problems, with no hardness results to date.

Our results include: hardness of learning shallow ReLU neural networks under
the Gaussian distribution and other distributions; hardness of learning
intersections of $\omega(1)$ halfspaces, DNF formulas with $\omega(1)$ terms,
and ReLU networks with $\omega(1)$ hidden neurons; hardness of weakly learning
deterministic finite automata under the uniform distribution; hardness of
weakly learning depth-$3$ Boolean circuits under the uniform distribution, as
well as distribution-specific hardness results for learning DNF formulas and
intersections of halfspaces. We also establish lower bounds on the complexity
of learning intersections of a constant number of halfspaces, and ReLU networks
with a constant number of hidden neurons. Moreover, our results imply the
hardness of virtually all improper PAC-learning problems (both
distribution-free and distribution-specific) that were previously shown hard
under other assumptions.
</p>
<a href="http://arxiv.org/abs/2101.08303" target="_blank">arXiv:2101.08303</a> [<a href="http://arxiv.org/pdf/2101.08303" target="_blank">pdf</a>]

<h2>Non-Convex Compressed Sensing with Training Data. (arXiv:2101.08310v1 [cs.LG])</h2>
<h3>G. Welper</h3>
<p>Efficient algorithms for the sparse solution of under-determined linear
systems $Ax = b$ are known for matrices $A$ satisfying suitable assumptions
like the restricted isometry property (RIP). Without such assumptions little is
known and without any assumptions on $A$ the problem is $NP$-hard. A common
approach is to replace $\ell_1$ by $\ell_p$ minimization for $0 &lt; p &lt; 1$, which
is no longer convex and typically requires some form of local initial values
for provably convergent algorithms.

In this paper, we consider an alternative, where instead of suitable initial
values we are provided with extra training problems $Ax = B_l$, $l=1, \dots, p$
that are related to our compressed sensing problem. They allow us to find the
solution of the original problem $Ax = b$ with high probability in the range of
a one layer linear neural network with comparatively few assumptions on the
matrix $A$.
</p>
<a href="http://arxiv.org/abs/2101.08310" target="_blank">arXiv:2101.08310</a> [<a href="http://arxiv.org/pdf/2101.08310" target="_blank">pdf</a>]

<h2>Ensemble manifold based regularized multi-modal graph convolutional network for cognitive ability prediction. (arXiv:2101.08316v1 [cs.LG])</h2>
<h3>Gang Qu, Li Xiao, Wenxing Hu, Kun Zhang, Vince D. Calhoun, Yu-Ping Wang</h3>
<p>Objective: Multi-modal functional magnetic resonance imaging (fMRI) can be
used to make predictions about individual behavioral and cognitive traits based
on brain connectivity networks. Methods: To take advantage of complementary
information from multi-modal fMRI, we propose an interpretable multi-modal
graph convolutional network (MGCN) model, incorporating the fMRI time series
and the functional connectivity (FC) between each pair of brain regions.
Specifically, our model learns a graph embedding from individual brain networks
derived from multi-modal data. A manifold-based regularization term is then
enforced to consider the relationships of subjects both within and between
modalities. Furthermore, we propose the gradient-weighted regression activation
mapping (Grad-RAM) and the edge mask learning to interpret the model, which is
used to identify significant cognition-related biomarkers. Results: We validate
our MGCN model on the Philadelphia Neurodevelopmental Cohort to predict
individual wide range achievement test (WRAT) score. Our model obtains superior
predictive performance over GCN with a single modality and other competing
approaches. The identified biomarkers are cross-validated from different
approaches. Conclusion and Significance: This paper develops a new
interpretable graph deep learning framework for cognitive ability prediction,
with the potential to overcome the limitations of several current data-fusion
models. The results demonstrate the power of MGCN in analyzing multi-modal fMRI
and discovering significant biomarkers for human brain studies.
</p>
<a href="http://arxiv.org/abs/2101.08316" target="_blank">arXiv:2101.08316</a> [<a href="http://arxiv.org/pdf/2101.08316" target="_blank">pdf</a>]

<h2>Nonparametric clustering for image segmentation. (arXiv:2101.08345v1 [cs.CV])</h2>
<h3>Giovanna Menardi</h3>
<p>Image segmentation aims at identifying regions of interest within an image,
by grouping pixels according to their properties. This task resembles the
statistical one of clustering, yet many standard clustering methods fail to
meet the basic requirements of image segmentation: segment shapes are often
biased toward predetermined shapes and their number is rarely determined
automatically. Nonparametric clustering is, in principle, free from these
limitations and turns out to be particularly suitable for the task of image
segmentation. This is also witnessed by several operational analogies, as, for
instance, the resort to topological data analysis and spatial tessellation in
both the frameworks. We discuss the application of nonparametric clustering to
image segmentation and provide an algorithm specific for this task. Pixel
similarity is evaluated in terms of density of the color representation and the
adjacency structure of the pixels is exploited to introduce a simple, yet
effective method to identify image segments as disconnected high-density
regions. The proposed method works both to segment an image and to detect its
boundaries and can be seen as a generalization to color images of the class of
thresholding methods.
</p>
<a href="http://arxiv.org/abs/2101.08345" target="_blank">arXiv:2101.08345</a> [<a href="http://arxiv.org/pdf/2101.08345" target="_blank">pdf</a>]

<h2>Physical Reservoir Computing with Origami and its Application to Robotic Crawling. (arXiv:2101.08348v1 [cs.RO])</h2>
<h3>Priyanka Bhovad, Suyi Li</h3>
<p>A new paradigm called physical reservoir computing has recently emerged,
where the nonlinear dynamics of high-dimensional and fixed physical systems are
harnessed as a computational resource to achieve complex tasks. Via extensive
simulations based on a dynamic truss-frame model, this study shows that an
origami structure can perform as a dynamic reservoir with sufficient computing
power to emulate high-order nonlinear systems, generate stable limit cycles,
and modulate outputs according to dynamic inputs. This study also uncovers the
linkages between the origami reservoir's physical designs and its computing
power, offering a guideline to optimize the computing performance.
Comprehensive parametric studies show that selecting optimal feedback crease
distribution and fine-tuning the underlying origami folding designs are the
most effective approach to improve computing performance. Furthermore, this
study shows how origami's physical reservoir computing power can apply to soft
robotic control problems by a case study of earthworm-like peristaltic crawling
without traditional controllers. These results can pave the way for
origami-based robots with embodied mechanical intelligence.
</p>
<a href="http://arxiv.org/abs/2101.08348" target="_blank">arXiv:2101.08348</a> [<a href="http://arxiv.org/pdf/2101.08348" target="_blank">pdf</a>]

<h2>Do we need to go Deep? Knowledge Tracing with Big Data. (arXiv:2101.08349v1 [cs.LG])</h2>
<h3>Varun Mandalapu, Jiaqi Gong, Lujie Chen</h3>
<p>Interactive Educational Systems (IES) enabled researchers to trace student
knowledge in different skills and provide recommendations for a better learning
path. To estimate the student knowledge and further predict their future
performance, the interest in utilizing the student interaction data captured by
IES to develop learner performance models is increasing rapidly. Moreover, with
the advances in computing systems, the amount of data captured by these IES
systems is also increasing that enables deep learning models to compete with
traditional logistic models and Markov processes. However, it is still not
empirically evident if these deep models outperform traditional models on the
current scale of datasets with millions of student interactions. In this work,
we adopt EdNet, the largest student interaction dataset publicly available in
the education domain, to understand how accurately both deep and traditional
models predict future student performances. Our work observes that logistic
regression models with carefully engineered features outperformed deep models
from extensive experimentation. We follow this analysis with interpretation
studies based on Locally Interpretable Model-agnostic Explanation (LIME) to
understand the impact of various features on best performing model
pre-dictions.
</p>
<a href="http://arxiv.org/abs/2101.08349" target="_blank">arXiv:2101.08349</a> [<a href="http://arxiv.org/pdf/2101.08349" target="_blank">pdf</a>]

<h2>Learning Massive Graph Embeddings on a Single Machine. (arXiv:2101.08358v1 [cs.LG])</h2>
<h3>Jason Mohoney, Roger Waleffe, Yiheng Xu, Theodoros Rekatsinas, Shivaram Venkataraman</h3>
<p>We propose a new framework for computing the embeddings of large-scale graphs
on a single machine. A graph embedding is a fixed length vector representation
for each node (and/or edge-type) in a graph and has emerged as the de-facto
approach to apply modern machine learning on graphs. We identify that current
systems for learning the embeddings of large-scale graphs are bottlenecked by
data movement, which results in poor resource utilization and inefficient
training. These limitations require state-of-the-art systems to distribute
training across multiple machines. We propose Gaius, a system for efficient
training of graph embeddings that leverages partition caching and buffer-aware
data orderings to minimize disk access and interleaves data movement with
computation to maximize utilization. We compare Gaius against two
state-of-the-art industrial systems on a diverse array of benchmarks. We
demonstrate that Gaius achieves the same level of accuracy but is up to one
order-of magnitude faster. We also show that Gaius can scale training to
datasets an order of magnitude beyond a single machine's GPU and CPU memory
capacity, enabling training of configurations with more than a billion edges
and 550GB of total parameters on a single AWS P3.2xLarge instance.
</p>
<a href="http://arxiv.org/abs/2101.08358" target="_blank">arXiv:2101.08358</a> [<a href="http://arxiv.org/pdf/2101.08358" target="_blank">pdf</a>]

<h2>Quadratic Residual Networks: A New Class of Neural Networks for Solving Forward and Inverse Problems in Physics Involving PDEs. (arXiv:2101.08366v1 [cs.LG])</h2>
<h3>Jie Bu, Anuj Karpatne</h3>
<p>We propose quadratic residual networks (QRes) as a new type of
parameter-efficient neural network architecture, by adding a quadratic residual
term to the weighted sum of inputs before applying activation functions. With
sufficiently high functional capacity (or expressive power), we show that it is
especially good for solving forward and inverse physics problems involving
partial differential equations (PDEs). Using tools from algebraic geometry, we
theoretically demonstrate that, in contrast to plain neural networks, QRes
shows better parameter efficiency in terms of network width and depth thanks to
higher non-linearity in every neuron. Finally, we empirically show that QRes
shows faster convergence speed in terms of number of training epochs especially
in learning complex patterns.
</p>
<a href="http://arxiv.org/abs/2101.08366" target="_blank">arXiv:2101.08366</a> [<a href="http://arxiv.org/pdf/2101.08366" target="_blank">pdf</a>]

<h2>Influence Estimation for Generative Adversarial Networks. (arXiv:2101.08367v1 [stat.ML])</h2>
<h3>Naoyuki Terashita, Hiroki Ohashi, Yuichi Nonaka, Takashi Kanemaru</h3>
<p>Identifying harmful instances, whose absence in a training dataset improves
model performance, is important for building better machine learning models.
Although previous studies have succeeded in estimating harmful instances under
supervised settings, they cannot be trivially extended to generative
adversarial networks (GANs). This is because previous approaches require that
(1) the absence of a training instance directly affects the loss value and that
(2) the change in the loss directly measures the harmfulness of the instance
for the performance of a model. In GAN training, however, neither of the
requirements is satisfied. This is because, (1) the generator's loss is not
directly affected by the training instances as they are not part of the
generator's training steps, and (2) the values of GAN's losses normally do not
capture the generative performance of a model. To this end, (1) we propose an
influence estimation method that uses the Jacobian of the gradient of the
generator's loss with respect to the discriminator's parameters (and vice
versa) to trace how the absence of an instance in the discriminator's training
affects the generator's parameters, and (2) we propose a novel evaluation
scheme, in which we assess harmfulness of each training instance on the basis
of how GAN evaluation metric (e.g., inception score) is expect to change due to
the removal of the instance. We experimentally verified that our influence
estimation method correctly inferred the changes in GAN evaluation metrics.
Further, we demonstrated that the removal of the identified harmful instances
effectively improved the model's generative performance with respect to various
GAN evaluation metrics.
</p>
<a href="http://arxiv.org/abs/2101.08367" target="_blank">arXiv:2101.08367</a> [<a href="http://arxiv.org/pdf/2101.08367" target="_blank">pdf</a>]

<h2>Better Short than Greedy: Interpretable Models through Optimal Rule Boosting. (arXiv:2101.08380v1 [cs.LG])</h2>
<h3>Mario Boley, Simon Teshuva, Pierre Le Bodic, Geoffrey I Webb</h3>
<p>Rule ensembles are designed to provide a useful trade-off between predictive
accuracy and model interpretability. However, the myopic and random search
components of current rule ensemble methods can compromise this goal: they
often need more rules than necessary to reach a certain accuracy level or can
even outright fail to accurately model a distribution that can actually be
described well with a few rules. Here, we present a novel approach aiming to
fit rule ensembles of maximal predictive power for a given ensemble size (and
thus model comprehensibility). In particular, we present an efficient
branch-and-bound algorithm that optimally solves the per-rule objective
function of the popular second-order gradient boosting framework. Our main
insight is that the boosting objective can be tightly bounded in linear time of
the number of covered data points. Along with an additional novel pruning
technique related to rule redundancy, this leads to a computationally feasible
approach for boosting optimal rules that, as we demonstrate on a wide range of
common benchmark problems, consistently outperforms the predictive performance
of boosting greedy rules.
</p>
<a href="http://arxiv.org/abs/2101.08380" target="_blank">arXiv:2101.08380</a> [<a href="http://arxiv.org/pdf/2101.08380" target="_blank">pdf</a>]

<h2>Invariance, encodings, and generalization: learning identity effects with neural networks. (arXiv:2101.08386v1 [cs.LG])</h2>
<h3>S. Brugiapaglia, M. Liu, P. Tupper</h3>
<p>Often in language and other areas of cognition, whether two components of an
object are identical or not determines if it is well formed. We call such
constraints identity effects. When developing a system to learn well-formedness
from examples, it is easy enough to build in an identify effect. But can
identity effects be learned from the data without explicit guidance? We provide
a framework in which we can rigorously prove that algorithms satisfying simple
criteria cannot make the correct inference. We then show that a broad class of
learning algorithms including deep feedforward neural networks trained via
gradient-based algorithms (such as stochastic gradient descent or the Adam
method) satisfy our criteria, dependent on the encoding of inputs. In some
broader circumstances we are able to provide of adversarial examples that the
network necessarily classifies incorrectly. Finally, we demonstrate our theory
with computational experiments in which we explore the effect of different
input encodings on the ability of algorithms to generalize to novel inputs.
</p>
<a href="http://arxiv.org/abs/2101.08386" target="_blank">arXiv:2101.08386</a> [<a href="http://arxiv.org/pdf/2101.08386" target="_blank">pdf</a>]

<h2>Discussion of Ensemble Learning under the Era of Deep Learning. (arXiv:2101.08387v1 [cs.LG])</h2>
<h3>Yongquan Yang, Haijun Lv</h3>
<p>Due to the dominant position of deep learning (mostly deep neural networks)
in various artificial intelligence applications, recently, ensemble learning
based on deep neural networks (ensemble deep learning) has shown significant
performances in improving the generalization of learning system. However, since
modern deep neural networks usually have millions to billions of parameters,
the time and space overheads for training multiple base deep learners and
testing with the ensemble deep learner are far greater than that of traditional
ensemble learning. Though several algorithms of fast ensemble deep learning
have been proposed to promote the deployment of ensemble deep learning in some
applications, further advances still need to be made for many applications in
specific fields, where the developing time and computing resources are usually
restricted or the data to be processed is of large dimensionality. An urgent
problem needs to be solved is how to take the significant advantages of
ensemble deep learning while reduce the required time and space overheads so
that many more applications in specific fields can benefit from it. For the
alleviation of this problem, it is necessary to know about how ensemble
learning has developed under the era of deep learning. Thus, in this article,
we present discussion focusing on data analyses of published works, the
methodology and unattainability of traditional ensemble learning, and recent
developments of ensemble deep learning. We hope this article will be helpful to
realize the technical challenges faced by future developments of ensemble
learning under the era of deep learning.
</p>
<a href="http://arxiv.org/abs/2101.08387" target="_blank">arXiv:2101.08387</a> [<a href="http://arxiv.org/pdf/2101.08387" target="_blank">pdf</a>]

<h2>An Information-Theoretic Analysis of the Impact of Task Similarity on Meta-Learning. (arXiv:2101.08390v1 [cs.LG])</h2>
<h3>Sharu Theresa Jose, Osvaldo Simeone</h3>
<p>Meta-learning aims at optimizing the hyperparameters of a model class or
training algorithm from the observation of data from a number of related tasks.
Following the setting of Baxter [1], the tasks are assumed to belong to the
same task environment, which is defined by a distribution over the space of
tasks and by per-task data distributions. The statistical properties of the
task environment thus dictate the similarity of the tasks. The goal of the
meta-learner is to ensure that the hyperparameters obtain a small loss when
applied for training of a new task sampled from the task environment. The
difference between the resulting average loss, known as meta-population loss,
and the corresponding empirical loss measured on the available data from
related tasks, known as meta-generalization gap, is a measure of the
generalization capability of the meta-learner. In this paper, we present novel
information-theoretic bounds on the average absolute value of the
meta-generalization gap. Unlike prior work [2], our bounds explicitly capture
the impact of task relatedness, the number of tasks, and the number of data
samples per task on the meta-generalization gap. Task similarity is gauged via
the Kullback-Leibler (KL) and Jensen-Shannon (JS) divergences. We illustrate
the proposed bounds on the example of ridge regression with meta-learned bias.
</p>
<a href="http://arxiv.org/abs/2101.08390" target="_blank">arXiv:2101.08390</a> [<a href="http://arxiv.org/pdf/2101.08390" target="_blank">pdf</a>]

<h2>Distilling Interpretable Models into Human-Readable Code. (arXiv:2101.08393v1 [cs.LG])</h2>
<h3>Walker Ravina, Ethan Sterling, Olexiy Oryeshko, Nathan Bell, Honglei Zhuang, Xuanhui Wang, Yonghui Wu, Alexander Grushetsky</h3>
<p>The goal of model distillation is to faithfully transfer teacher model
knowledge to a model which is faster, more generalizable, more interpretable,
or possesses other desirable characteristics. Human-readability is an important
and desirable standard for machine-learned model interpretability. Readable
models are transparent and can be reviewed, manipulated, and deployed like
traditional source code. As a result, such models can be improved outside the
context of machine learning and manually edited if desired. Given that directly
training such models is difficult, we propose to train interpretable models
using conventional methods, and then distill them into concise, human-readable
code.

The proposed distillation methodology approximates a model's univariate
numerical functions with piecewise-linear curves in a localized manner. The
resulting curve model representations are accurate, concise, human-readable,
and well-regularized by construction. We describe a piecewise-linear
curve-fitting algorithm that produces high-quality results efficiently and
reliably across a broad range of use cases. We demonstrate the effectiveness of
the overall distillation technique and our curve-fitting algorithm using three
publicly available datasets COMPAS, FICO, and MSLR-WEB30K.
</p>
<a href="http://arxiv.org/abs/2101.08393" target="_blank">arXiv:2101.08393</a> [<a href="http://arxiv.org/pdf/2101.08393" target="_blank">pdf</a>]

<h2>TDA-Net: Fusion of Persistent Homology and Deep Learning Features for COVID-19 Detection in Chest X-Ray Images. (arXiv:2101.08398v1 [cs.CV])</h2>
<h3>Mustafa Hajij, Ghada Zamzmi, Fawwaz Batayneh</h3>
<p>Topological Data Analysis (TDA) has emerged recently as a robust tool to
extract and compare the structure of datasets. TDA identifies features in data
such as connected components and holes and assigns a quantitative measure to
these features. Several studies reported that topological features extracted by
TDA tools provide unique information about the data, discover new insights, and
determine which feature is more related to the outcome. On the other hand, the
overwhelming success of deep neural networks in learning patterns and
relationships has been proven on a vast array of data applications, images in
particular. To capture the characteristics of both powerful tools, we propose
\textit{TDA-Net}, a novel ensemble network that fuses topological and deep
features for the purpose of enhancing model generalizability and accuracy. We
apply the proposed \textit{TDA-Net} to a critical application, which is the
automated detection of COVID-19 from CXR images. The experimental results
showed that the proposed network achieved excellent performance and suggests
the applicability of our method in practice.
</p>
<a href="http://arxiv.org/abs/2101.08398" target="_blank">arXiv:2101.08398</a> [<a href="http://arxiv.org/pdf/2101.08398" target="_blank">pdf</a>]

<h2>MoG-QSM: Model-based Generative Adversarial Deep Learning Network for Quantitative Susceptibility Mapping. (arXiv:2101.08413v1 [cs.CV])</h2>
<h3>Ruimin Feng, Jiayi Zhao, He Wang, Baofeng Yang, Jie Feng, Yuting Shi, Ming Zhang, Chunlei Liu, Yuyao Zhang, Jie Zhuang, Hongjiang Wei</h3>
<p>Quantitative susceptibility mapping (QSM) estimates the underlying tissue
magnetic susceptibility from the MRI gradient-echo phase signal and has
demonstrated great potential in quantifying tissue susceptibility in various
brain diseases. However, the intrinsic ill-posed inverse problem relating the
tissue phase to the underlying susceptibility distribution affects the accuracy
for quantifying tissue susceptibility. The resulting susceptibility map is
known to suffer from noise amplification and streaking artifacts. To address
these challenges, we propose a model-based framework that permeates benefits
from generative adversarial networks to train a regularization term that
contains prior information to constrain the solution of the inverse problem,
referred to as MoG-QSM. A residual network leveraging a mixture of
least-squares (LS) GAN and the L1 cost was trained as the generator to learn
the prior information in susceptibility maps. A multilayer convolutional neural
network was jointly trained to discriminate the quality of output images.
MoG-QSM generates highly accurate susceptibility maps from single orientation
phase maps. Quantitative evaluation parameters were compared with recently
developed deep learning QSM methods and the results showed MoG-QSM achieves the
best performance. Furthermore, a higher intraclass correlation coefficient
(ICC) was obtained from MoG-QSM maps of the traveling subjects, demonstrating
its potential for future applications, such as large cohorts of multi-center
studies. MoG-QSM is also helpful for reliable longitudinal measurement of
susceptibility time courses, enabling more precise monitoring for metal ion
accumulation in neurodegenerative disorders.
</p>
<a href="http://arxiv.org/abs/2101.08413" target="_blank">arXiv:2101.08413</a> [<a href="http://arxiv.org/pdf/2101.08413" target="_blank">pdf</a>]

<h2>Finger Vein Recognition by Generating Code. (arXiv:2101.08415v1 [cs.CV])</h2>
<h3>Zhongxia Zhang, Mingwen Wang</h3>
<p>Finger vein recognition has drawn increasing attention as one of the most
popular and promising biometrics due to its high distinguishes ability,
security and non-invasive procedure. The main idea of traditional schemes is to
directly extract features from finger vein images or patterns and then compare
features to find the best match. However, the features extracted from images
contain much redundant data, while the features extracted from patterns are
greatly influenced by image segmentation methods. To tack these problems, this
paper proposes a new finger vein recognition by generating code. The proposed
method does not require an image segmentation algorithm, is simple to calculate
and has a small amount of data. Firstly, the finger vein images were divided
into blocks to calculate the mean value. Then the centrosymmetric coding is
performed by using the generated eigenmatrix. The obtained codewords are
concatenated as the feature codewords of the image. The similarity between vein
codes is measured by the ratio of minimum Hamming distance to codeword length.
Extensive experiments on two public finger vein databases verify the
effectiveness of the proposed method. The results indicate that our method
outperforms the state-of-theart methods and has competitive potential in
performing the matching task.
</p>
<a href="http://arxiv.org/abs/2101.08415" target="_blank">arXiv:2101.08415</a> [<a href="http://arxiv.org/pdf/2101.08415" target="_blank">pdf</a>]

<h2>Rethinking Semantic Segmentation Evaluation for Explainability and Model Selection. (arXiv:2101.08418v1 [cs.CV])</h2>
<h3>Yuxiang Zhang, Sachin Mehta, Anat Caspi</h3>
<p>Semantic segmentation aims to robustly predict coherent class labels for
entire regions of an image. It is a scene understanding task that powers
real-world applications (e.g., autonomous navigation). One important
application, the use of imagery for automated semantic understanding of
pedestrian environments, provides remote mapping of accessibility features in
street environments. This application (and others like it) require detailed
geometric information of geographical objects. Semantic segmentation is a
prerequisite for this task since it maps contiguous regions of the same class
as single entities. Importantly, semantic segmentation uses like ours are not
pixel-wise outcomes; however, most of their quantitative evaluation metrics
(e.g., mean Intersection Over Union) are based on pixel-wise similarities to a
ground-truth, which fails to emphasize over- and under-segmentation properties
of a segmentation model. Here, we introduce a new metric to assess region-based
over- and under-segmentation. We analyze and compare it to other metrics,
demonstrating that the use of our metric lends greater explainability to
semantic segmentation model performance in real-world applications.
</p>
<a href="http://arxiv.org/abs/2101.08418" target="_blank">arXiv:2101.08418</a> [<a href="http://arxiv.org/pdf/2101.08418" target="_blank">pdf</a>]

<h2>Analysis of Information Flow Through U-Nets. (arXiv:2101.08427v1 [cs.LG])</h2>
<h3>Suemin Lee, Ivan V. Baji&#x107;</h3>
<p>Deep Neural Networks (DNNs) have become ubiquitous in medical image
processing and analysis. Among them, U-Nets are very popular in various image
segmentation tasks. Yet, little is known about how information flows through
these networks and whether they are indeed properly designed for the tasks they
are being proposed for. In this paper, we employ information-theoretic tools in
order to gain insight into information flow through U-Nets. In particular, we
show how mutual information between input/output and an intermediate layer can
be a useful tool to understand information flow through various portions of a
U-Net, assess its architectural efficiency, and even propose more efficient
designs.
</p>
<a href="http://arxiv.org/abs/2101.08427" target="_blank">arXiv:2101.08427</a> [<a href="http://arxiv.org/pdf/2101.08427" target="_blank">pdf</a>]

<h2>Generative Zero-shot Network Quantization. (arXiv:2101.08430v1 [cs.CV])</h2>
<h3>Xiangyu He, Qinghao Hu, Peisong Wang, Jian Cheng</h3>
<p>Convolutional neural networks are able to learn realistic image priors from
numerous training samples in low-level image generation and restoration. We
show that, for high-level image recognition tasks, we can further reconstruct
"realistic" images of each category by leveraging intrinsic Batch Normalization
(BN) statistics without any training data. Inspired by the popular VAE/GAN
methods, we regard the zero-shot optimization process of synthetic images as
generative modeling to match the distribution of BN statistics. The generated
images serve as a calibration set for the following zero-shot network
quantizations. Our method meets the needs for quantizing models based on
sensitive information, \textit{e.g.,} due to privacy concerns, no data is
available. Extensive experiments on benchmark datasets show that, with the help
of generated data, our approach consistently outperforms existing data-free
quantization methods.
</p>
<a href="http://arxiv.org/abs/2101.08430" target="_blank">arXiv:2101.08430</a> [<a href="http://arxiv.org/pdf/2101.08430" target="_blank">pdf</a>]

<h2>Video Summarization: Study of various techniques. (arXiv:2101.08434v1 [cs.CV])</h2>
<h3>Ravi Raj, Varad Bhatnagar, Aman Kumar Singh, Sneha Mane, Nilima Walde</h3>
<p>A comparative study of various techniques which can be used for summarization
of Videos i.e. Video to Video conversion is presented along with respective
architecture, results, strengths and shortcomings. In all approaches, a lengthy
video is converted into a shorter video which aims to capture all important
events that are present in the original video. The definition of 'important
event' may vary according to the context, such as a sports video and a
documentary may have different events which are classified as important.
</p>
<a href="http://arxiv.org/abs/2101.08434" target="_blank">arXiv:2101.08434</a> [<a href="http://arxiv.org/pdf/2101.08434" target="_blank">pdf</a>]

<h2>Learning based signal detection for MIMO systems with unknown noise statistics. (arXiv:2101.08435v1 [cs.LG])</h2>
<h3>Ke He, Le He, Lisheng Fan, Yansha Deng, George K. Karagiannidis, Arumugam Nallanathan</h3>
<p>This paper aims to devise a generalized maximum likelihood (ML) estimator to
robustly detect signals with unknown noise statistics in multiple-input
multiple-output (MIMO) systems. In practice, there is little or even no
statistical knowledge on the system noise, which in many cases is non-Gaussian,
impulsive and not analyzable. Existing detection methods have mainly focused on
specific noise models, which are not robust enough with unknown noise
statistics. To tackle this issue, we propose a novel ML detection framework to
effectively recover the desired signal. Our framework is a fully probabilistic
one that can efficiently approximate the unknown noise distribution through a
normalizing flow. Importantly, this framework is driven by an unsupervised
learning approach, where only the noise samples are required. To reduce the
computational complexity, we further present a low-complexity version of the
framework, by utilizing an initial estimation to reduce the search space.
Simulation results show that our framework outperforms other existing
algorithms in terms of bit error rate (BER) in non-analytical noise
environments, while it can reach the ML performance bound in analytical noise
environments. The code of this paper is available at
https://github.com/skypitcher/manfe.
</p>
<a href="http://arxiv.org/abs/2101.08435" target="_blank">arXiv:2101.08435</a> [<a href="http://arxiv.org/pdf/2101.08435" target="_blank">pdf</a>]

<h2>All-Day Object Tracking for Unmanned Aerial Vehicle. (arXiv:2101.08446v1 [cs.CV])</h2>
<h3>Bowen Li, Changhon Fu, Fangqiang Ding, Junjie Ye, Fuling Lin</h3>
<p>Visual object tracking, which is representing a major interest in image
processing field, has facilitated numerous real world applications. Among them,
equipping unmanned aerial vehicle (UAV) with real time robust visual trackers
for all day aerial maneuver, is currently attracting incremental attention and
has remarkably broadened the scope of applications of object tracking. However,
prior tracking methods have merely focused on robust tracking in the
well-illuminated scenes, while ignoring trackers' capabilities to be deployed
in the dark. In darkness, the conditions can be more complex and harsh, easily
posing inferior robust tracking or even tracking failure. To this end, this
work proposed a novel discriminative correlation filter based tracker with
illumination adaptive and anti dark capability, namely ADTrack. ADTrack firstly
exploits image illuminance information to enable adaptability of the model to
the given light condition. Then, by virtue of an efficient and effective image
enhancer, ADTrack carries out image pretreatment, where a target aware mask is
generated. Benefiting from the mask, ADTrack aims to solve a dual regression
problem where dual filters, i.e., the context filter and target focused filter,
are trained with mutual constraint. Thus ADTrack is able to maintain
continuously favorable performance in all-day conditions. Besides, this work
also constructed one UAV nighttime tracking benchmark UAVDark135, comprising of
more than 125k manually annotated frames, which is also very first UAV
nighttime tracking benchmark. Exhaustive experiments are extended on
authoritative daytime benchmarks, i.e., UAV123 10fps, DTB70, and the newly
built dark benchmark UAVDark135, which have validated the superiority of
ADTrack in both bright and dark conditions on a single CPU.
</p>
<a href="http://arxiv.org/abs/2101.08446" target="_blank">arXiv:2101.08446</a> [<a href="http://arxiv.org/pdf/2101.08446" target="_blank">pdf</a>]

<h2>Robust Reinforcement Learning on State Observations with Learned Optimal Adversary. (arXiv:2101.08452v1 [cs.LG])</h2>
<h3>Huan Zhang, Hongge Chen, Duane Boning, Cho-Jui Hsieh</h3>
<p>We study the robustness of reinforcement learning (RL) with adversarially
perturbed state observations, which aligns with the setting of many adversarial
attacks to deep reinforcement learning (DRL) and is also important for rolling
out real-world RL agent under unpredictable sensing noise. With a fixed agent
policy, we demonstrate that an optimal adversary to perturb state observations
can be found, which is guaranteed to obtain the worst case agent reward. For
DRL settings, this leads to a novel empirical adversarial attack to RL agents
via a learned adversary that is much stronger than previous ones. To enhance
the robustness of an agent, we propose a framework of alternating training with
learned adversaries (ATLA), which trains an adversary online together with the
agent using policy gradient following the optimal adversarial attack framework.
Additionally, inspired by the analysis of state-adversarial Markov decision
process (SA-MDP), we show that past states and actions (history) can be useful
for learning a robust agent, and we empirically find a LSTM based policy can be
more robust under adversaries. Empirical evaluations on a few continuous
control environments show that ATLA achieves state-of-the-art performance under
strong adversaries. Our code is available at
https://github.com/huanzhang12/ATLA_robust_RL.
</p>
<a href="http://arxiv.org/abs/2101.08452" target="_blank">arXiv:2101.08452</a> [<a href="http://arxiv.org/pdf/2101.08452" target="_blank">pdf</a>]

<h2>Fire Threat Detection From Videos with Q-Rough Sets. (arXiv:2101.08459v1 [cs.CV])</h2>
<h3>Debarati B. Chakrabortya, Vinay Detania, Shah Parshv Jigneshkumar</h3>
<p>This article defines new methods for unsupervised fire region segmentation
and fire threat detection from video stream. Fire in control serves a number of
purposes to human civilization, but it could simultaneously be a threat once
its spread becomes uncontrolled. There exists many methods on fire region
segmentation and fire non-fire classification. But the approaches to determine
the threat associated with fire is relatively scare, and no such unsupervised
method has been formulated yet. Here we focus on developing an unsupervised
method with which the threat of fire can be quantified and accordingly generate
an alarm in automated surveillance systems in indoor as well as in outdoors.
Fire region segmentation without any manual intervention/ labelled data set is
a major challenge while formulating such a method. Here we have used rough
approximations to approximate the fire region, and to manage the incompleteness
of the knowledge base, due to absence of any prior information. Utility
maximization of Q-learning has been used to minimize ambiguities in the rough
approximations. The new set approximation method, thus developed here, is named
as Q-rough set. It is used for fire region segmentation from video frames. The
threat index of fire flame over the input video stream has been defined in sync
with the relative growth in the fire segments on the recent frames. All
theories and indices defined here have been experimentally validated with
different types of fire videos, through demonstrations and comparisons, as
superior to the state of the art.
</p>
<a href="http://arxiv.org/abs/2101.08459" target="_blank">arXiv:2101.08459</a> [<a href="http://arxiv.org/pdf/2101.08459" target="_blank">pdf</a>]

<h2>Segmenting Transparent Object in the Wild with Transformer. (arXiv:2101.08461v1 [cs.CV])</h2>
<h3>Enze Xie, Wenjia Wang, Wenhai Wang, Peize Sun, Hang Xu, Ding Liang, Ping Luo</h3>
<p>This work presents a new fine-grained transparent object segmentation
dataset, termed Trans10K-v2, extending Trans10K-v1, the first large-scale
transparent object segmentation dataset. Unlike Trans10K-v1 that only has two
limited categories, our new dataset has several appealing benefits. (1) It has
11 fine-grained categories of transparent objects, commonly occurring in the
human domestic environment, making it more practical for real-world
application. (2) Trans10K-v2 brings more challenges for the current advanced
segmentation methods than its former version. Furthermore, a novel
transformer-based segmentation pipeline termed Trans2Seg is proposed. Firstly,
the transformer encoder of Trans2Seg provides the global receptive field in
contrast to CNN's local receptive field, which shows excellent advantages over
pure CNN architectures. Secondly, by formulating semantic segmentation as a
problem of dictionary look-up, we design a set of learnable prototypes as the
query of Trans2Seg's transformer decoder, where each prototype learns the
statistics of one category in the whole dataset. We benchmark more than 20
recent semantic segmentation methods, demonstrating that Trans2Seg
significantly outperforms all the CNN-based methods, showing the proposed
algorithm's potential ability to solve transparent object segmentation.
</p>
<a href="http://arxiv.org/abs/2101.08461" target="_blank">arXiv:2101.08461</a> [<a href="http://arxiv.org/pdf/2101.08461" target="_blank">pdf</a>]

<h2>COLLIDE-PRED: Prediction of On-Road Collision From Surveillance Videos. (arXiv:2101.08463v1 [cs.CV])</h2>
<h3>Deesha Chavan, Dev Saad, Debarati B. Chakraborty</h3>
<p>Predicting on-road abnormalities such as road accidents or traffic violations
is a challenging task in traffic surveillance. If such predictions can be done
in advance, many damages can be controlled. Here in our wok, we tried to
formulate a solution for automated collision prediction in traffic surveillance
videos with computer vision and deep networks. It involves object detection,
tracking, trajectory estimation, and collision prediction. We propose an
end-to-end collision prediction system, named as COLLIDE-PRED, that
intelligently integrates the information of past and future trajectories of
moving objects to predict collisions in videos. It is a pipeline that starts
with object detection, which is used for object tracking, and then trajectory
prediction is performed which concludes by collision detection. The probable
place of collision, and the objects those may cause the collision, both can be
identified correctly with COLLIDE-PRED. The proposed method is experimentally
validated with a number of different videos and proves to be effective in
identifying accident in advance.
</p>
<a href="http://arxiv.org/abs/2101.08463" target="_blank">arXiv:2101.08463</a> [<a href="http://arxiv.org/pdf/2101.08463" target="_blank">pdf</a>]

<h2>FWB-Net:Front White Balance Network for Color Shift Correction in Single Image Dehazing via Atmospheric Light Estimation. (arXiv:2101.08465v1 [cs.CV])</h2>
<h3>Cong Wang, Yan Huang, Yuexian Zou, Yong Xu</h3>
<p>In recent years, single image dehazing deep models based on Atmospheric
Scattering Model (ASM) have achieved remarkable results. But the dehazing
outputs of those models suffer from color shift. Analyzing the ASM model shows
that the atmospheric light factor (ALF) is set as a scalar which indicates ALF
is constant for whole image. However, for images taken in real-world, the
illumination is not uniformly distributed over whole image which brings model
mismatch and possibly results in color shift of the deep models using ASM.
Bearing this in mind, in this study, first, a new non-homogeneous atmospheric
scattering model (NH-ASM) is proposed for improving image modeling of hazy
images taken under complex illumination conditions. Second, a new U-Net based
front white balance module (FWB-Module) is dedicatedly designed to correct
color shift before generating dehazing result via atmospheric light estimation.
Third, a new FWB loss is innovatively developed for training FWB-Module, which
imposes penalty on color shift. In the end, based on NH-ASM and front white
balance technology, an end-to-end CNN-based color-shift-restraining dehazing
network is developed, termed as FWB-Net. Experimental results demonstrate the
effectiveness and superiority of our proposed FWB-Net for dehazing on both
synthetic and real-world images.
</p>
<a href="http://arxiv.org/abs/2101.08465" target="_blank">arXiv:2101.08465</a> [<a href="http://arxiv.org/pdf/2101.08465" target="_blank">pdf</a>]

<h2>Anti-UAV: A Large Multi-Modal Benchmark for UAV Tracking. (arXiv:2101.08466v1 [cs.CV])</h2>
<h3>Nan Jiang, Kuiran Wang, Xiaoke Peng, Xuehui Yu, Qiang Wang, Junliang Xing, Guorong Li, Guodong Guo, Jian Zhao, Zhenjun Han</h3>
<p>Unmanned Aerial Vehicle (UAV) offers lots of applications in both commerce
and recreation. With this, monitoring the operation status of UAVs is crucially
important. In this work, we consider the task of tracking UAVs, providing rich
information such as location and trajectory. To facilitate research in this
topic, we propose a dataset, Anti-UAV, with more than 300 video pairs
containing over 580k manually annotated bounding boxes. The releasing of such a
large-scale dataset could be a useful initial step in research of tracking
UAVs. Furthermore, the advancement of addressing research challenges in
Anti-UAV can help the design of anti-UAV systems, leading to better
surveillance of UAVs. Besides, a novel approach named dual-flow semantic
consistency (DFSC) is proposed for UAV tracking. Modulated by the semantic flow
across video sequences, the tracker learns more robust class-level semantic
information and obtains more discriminative instance-level features.
Experimental results demonstrate that Anti-UAV is very challenging, and the
proposed method can effectively improve the tracker's performance. The Anti-UAV
benchmark and the code of the proposed approach will be publicly available at
https://github.com/ucas-vg/Anti-UAV.
</p>
<a href="http://arxiv.org/abs/2101.08466" target="_blank">arXiv:2101.08466</a> [<a href="http://arxiv.org/pdf/2101.08466" target="_blank">pdf</a>]

<h2>CM-NAS: Rethinking Cross-Modality Neural Architectures for Visible-Infrared Person Re-Identification. (arXiv:2101.08467v1 [cs.CV])</h2>
<h3>Chaoyou Fu, Yibo Hu, Xiang Wu, Hailin Shi, Tao Mei, Ran He</h3>
<p>Visible-Infrared person re-identification (VI-ReID) aims at matching
cross-modality pedestrian images, breaking through the limitation of
single-modality person ReID in dark environment. In order to mitigate the
impact of large modality discrepancy, existing works manually design various
two-stream architectures to separately learn modality-specific and
modality-sharable representations. Such a manual design routine, however,
highly depends on massive experiments and empirical practice, which is time
consuming and labor intensive. In this paper, we systematically study the
manually designed architectures, and identify that appropriately splitting
Batch Normalization (BN) layers to learn modality-specific representations will
bring a great boost towards cross-modality matching. Based on this observation,
the essential objective is to find the optimal splitting scheme for each BN
layer. To this end, we propose a novel method, named Cross-Modality Neural
Architecture Search (CM-NAS). It consists of a BN-oriented search space in
which the standard optimization can be fulfilled subject to the cross-modality
task. Besides, in order to better guide the search process, we further
formulate a new Correlation Consistency based Class-specific Maximum Mean
Discrepancy (C3MMD) loss. Apart from the modality discrepancy, it also concerns
the similarity correlations, which have been overlooked before, in the two
modalities. Resorting to these advantages, our method outperforms
state-of-the-art counterparts in extensive experiments, improving the
Rank-1/mAP by 6.70%/6.13% on SYSU-MM01 and 12.17%/11.23% on RegDB. The source
code will be released soon.
</p>
<a href="http://arxiv.org/abs/2101.08467" target="_blank">arXiv:2101.08467</a> [<a href="http://arxiv.org/pdf/2101.08467" target="_blank">pdf</a>]

<h2>Collaborative Teacher-Student Learning via Multiple Knowledge Transfer. (arXiv:2101.08471v1 [cs.LG])</h2>
<h3>Liyuan Sun, Jianping Gou, Lan Du, Dacheng Tao</h3>
<p>Knowledge distillation (KD), as an efficient and effective model compression
technique, has been receiving considerable attention in deep learning. The key
to its success is to transfer knowledge from a large teacher network to a small
student one. However, most of the existing knowledge distillation methods
consider only one type of knowledge learned from either instance features or
instance relations via a specific distillation strategy in teacher-student
learning. There are few works that explore the idea of transferring different
types of knowledge with different distillation strategies in a unified
framework. Moreover, the frequently used offline distillation suffers from a
limited learning capacity due to the fixed teacher-student architecture. In
this paper we propose a collaborative teacher-student learning via multiple
knowledge transfer (CTSL-MKT) that prompts both self-learning and collaborative
learning. It allows multiple students learn knowledge from both individual
instances and instance relations in a collaborative way. While learning from
themselves with self-distillation, they can also guide each other via online
distillation. The experiments and ablation studies on four image datasets
demonstrate that the proposed CTSL-MKT significantly outperforms the
state-of-the-art KD methods.
</p>
<a href="http://arxiv.org/abs/2101.08471" target="_blank">arXiv:2101.08471</a> [<a href="http://arxiv.org/pdf/2101.08471" target="_blank">pdf</a>]

<h2>Unifying Cardiovascular Modelling with Deep Reinforcement Learning for Uncertainty Aware Control of Sepsis Treatment. (arXiv:2101.08477v1 [cs.LG])</h2>
<h3>Thesath Nanayakkara, Gilles Clermont, Christopher James Langmead, David Swigon</h3>
<p>Sepsis is the leading cause of mortality in the the ICU, responsible for 6%
of all hospitalizations and 35% of all in-hospital deaths in USA. However,
there is no universally agreed upon strategy for vasopressor and fluid
administration. It has also been observed that different patients respond
differently to treatment, highlighting the need for individualized treatment.
Vasopressors and fluids are administrated with specific effects to
cardiovascular physiology in mind and medical research has suggested that
physiologic, hemodynamically guided, approaches to treatment. Thus we propose a
novel approach, exploiting and unifying complementary strengths of Mathematical
Modelling, Deep Learning, Reinforcement Learning and Uncertainty
Quantification, to learn individualized, safe, and uncertainty aware treatment
strategies. We first infer patient-specific, dynamic cardiovascular states
using a novel physiology-driven recurrent neural network trained in an
unsupervised manner. This information, along with a learned low dimensional
representation of the patient's lab history and observable data, is then used
to derive value distributions using Batch Distributional Reinforcement
Learning. Moreover in a safety critical domain it is essential to know what our
agent does and does not know, for this we also quantity the model uncertainty
associated with each patient state and action, and propose a general framework
for uncertainty aware, interpretable treatment policies. This framework can be
tweaked easily, to reflect a clinician's own confidence of of the framework,
and can be easily modified to factor in human expert opinion, whenever it's
accessible. Using representative patients and a validation cohort, we show that
our method has learned physiologically interpretable generalizable policies.
</p>
<a href="http://arxiv.org/abs/2101.08477" target="_blank">arXiv:2101.08477</a> [<a href="http://arxiv.org/pdf/2101.08477" target="_blank">pdf</a>]

<h2>Exponential Moving Average Normalization for Self-supervised and Semi-supervised Learning. (arXiv:2101.08482v1 [cs.LG])</h2>
<h3>Zhaowei Cai, Avinash Ravichandran, Subhransu Maji, Charless Fowlkes, Zhuowen Tu, Stefano Soatto</h3>
<p>We present a plug-in replacement for batch normalization (BN) called
exponential moving average normalization (EMAN), which improves the performance
of existing student-teacher based self- and semi-supervised learning
techniques. Unlike the standard BN, where the statistics are computed within
each batch, EMAN, used in the teacher, updates its statistics by exponential
moving average from the BN statistics of the student. This design reduces the
intrinsic cross-sample dependency of BN and enhance the generalization of the
teacher. EMAN improves strong baselines for self-supervised learning by 4-6/1-2
points and semi-supervised learning by about 7/2 points, when 1%/10% supervised
labels are available on ImageNet. These improvements are consistent across
methods, network architectures, training duration, and datasets, demonstrating
the general effectiveness of this technique.
</p>
<a href="http://arxiv.org/abs/2101.08482" target="_blank">arXiv:2101.08482</a> [<a href="http://arxiv.org/pdf/2101.08482" target="_blank">pdf</a>]

<h2>Differential Euler: Designing a Neural Network approximator to solve the Chaotic Three Body Problem. (arXiv:2101.08486v1 [cs.LG])</h2>
<h3>Pratyush Kumar, Aishwarya Das, Debayan Gupta</h3>
<p>The three body problem is a special case of the n body problem where one
takes the initial positions and velocities of three point masses and attempts
to predict their motion over time according to Newtonian laws of motion and
universal gravitation. Though analytical solutions have been found for special
cases, the general problem remains unsolved; the solutions that do exist are
impractical. Fortunately, for many applications, we may not need to solve the
problem completely, i.e., predicting with reasonable accuracy for some time
steps, may be sufficient. Recently, Breen et al attempted to approximately
solve the three body problem using a simple neural network. Although their
methods appear to achieve some success in reducing the computational overhead,
their model is extremely restricted, applying to a specialized 2D case. The
authors do not provide explanations for critical decisions taken in their
experimental design, no details on their model or architecture, and nor do they
publish their code. Moreover, the model does not generalize well to unseen
cases. In this paper, we propose a detailed experimental setup to determine the
feasibility of using neural networks to solve the three body problem up to a
certain number of time steps. We establish a benchmark on the dataset size and
set an accuracy threshold to measure the viability of our results for practical
applications. Then, we build our models according to the listed class of NNs
using a dataset generated from standard numerical integrators. We gradually
increase the complexity of our data set to determine whether NNs can learn a
representation of the chaotic three body problem well enough to replace
numerical integrators in real life scenarios.
</p>
<a href="http://arxiv.org/abs/2101.08486" target="_blank">arXiv:2101.08486</a> [<a href="http://arxiv.org/pdf/2101.08486" target="_blank">pdf</a>]

<h2>Estimating Average Treatment Effects via Orthogonal Regularization. (arXiv:2101.08490v1 [cs.LG])</h2>
<h3>Tobias Hatt, Stefan Feuerriegel</h3>
<p>Decision-making often requires accurate estimation of treatment effects from
observational data. This is challenging as outcomes of alternative decisions
are not observed and have to be estimated. Previous methods estimate outcomes
based on unconfoundedness but neglect any constraints that unconfoundedness
imposes on the outcomes. In this paper, we propose a novel regularization
framework for estimating average treatment effects that exploits
unconfoundedness. To this end, we formalize unconfoundedness as an
orthogonality constraint, which ensures that the outcomes are orthogonal to the
treatment assignment. This orthogonality constraint is then included in the
loss function via a regularization. Based on our regularization framework, we
develop deep orthogonal networks for unconfounded treatments (DONUT), which
learn outcomes that are orthogonal to the treatment assignment. Using a variety
of benchmark datasets for estimating average treatment effects, we demonstrate
that DONUT outperforms the state-of-the-art substantially.
</p>
<a href="http://arxiv.org/abs/2101.08490" target="_blank">arXiv:2101.08490</a> [<a href="http://arxiv.org/pdf/2101.08490" target="_blank">pdf</a>]

<h2>Boosting in Univariate Nonparametric Maximum Likelihood Estimation. (arXiv:2101.08505v1 [stat.ML])</h2>
<h3>YunPeng Li, ZhaoHui Ye</h3>
<p>Nonparametric maximum likelihood estimation is intended to infer the unknown
density distribution while making as few assumptions as possible. To alleviate
the over parameterization in nonparametric data fitting, smoothing assumptions
are usually merged into the estimation. In this paper a novel boosting-based
method is introduced to the nonparametric estimation in univariate cases. We
deduce the boosting algorithm by the second-order approximation of
nonparametric log-likelihood. Gaussian kernel and smooth spline are chosen as
weak learners in boosting to satisfy the smoothing assumptions. Simulations and
real data experiments demonstrate the efficacy of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2101.08505" target="_blank">arXiv:2101.08505</a> [<a href="http://arxiv.org/pdf/2101.08505" target="_blank">pdf</a>]

<h2>Pre-training without Natural Images. (arXiv:2101.08515v1 [cs.CV])</h2>
<h3>Hirokatsu Kataoka, Kazushige Okayasu, Asato Matsumoto, Eisuke Yamagata, Ryosuke Yamada, Nakamasa Inoue, Akio Nakamura, Yutaka Satoh</h3>
<p>Is it possible to use convolutional neural networks pre-trained without any
natural images to assist natural image understanding? The paper proposes a
novel concept, Formula-driven Supervised Learning. We automatically generate
image patterns and their category labels by assigning fractals, which are based
on a natural law existing in the background knowledge of the real world.
Theoretically, the use of automatically generated images instead of natural
images in the pre-training phase allows us to generate an infinite scale
dataset of labeled images. Although the models pre-trained with the proposed
Fractal DataBase (FractalDB), a database without natural images, does not
necessarily outperform models pre-trained with human annotated datasets at all
settings, we are able to partially surpass the accuracy of ImageNet/Places
pre-trained models. The image representation with the proposed FractalDB
captures a unique feature in the visualization of convolutional layers and
attentions.
</p>
<a href="http://arxiv.org/abs/2101.08515" target="_blank">arXiv:2101.08515</a> [<a href="http://arxiv.org/pdf/2101.08515" target="_blank">pdf</a>]

<h2>Out-of-Distribution Generalization Analysis via Influence Function. (arXiv:2101.08521v1 [cs.LG])</h2>
<h3>Haotian Ye, Chuanlong Xie, Yue Liu, Zhenguo Li</h3>
<p>The mismatch between training and target data is one major challenge for
current machine learning systems. When training data is collected from multiple
domains and the target domains include all training domains and other new
domains, we are facing an Out-of-Distribution (OOD) generalization problem that
aims to find a model with the best OOD accuracy. One of the definitions of OOD
accuracy is worst-domain accuracy. In general, the set of target domains is
unknown, and the worst over target domains may be unseen when the number of
observed domains is limited. In this paper, we show that the worst accuracy
over the observed domains may dramatically fail to identify the OOD accuracy.
To this end, we introduce Influence Function, a classical tool from robust
statistics, into the OOD generalization problem and suggest the variance of
influence function to monitor the stability of a model on training domains. We
show that the accuracy on test domains and the proposed index together can help
us discern whether OOD algorithms are needed and whether a model achieves good
OOD generalization.
</p>
<a href="http://arxiv.org/abs/2101.08521" target="_blank">arXiv:2101.08521</a> [<a href="http://arxiv.org/pdf/2101.08521" target="_blank">pdf</a>]

<h2>Fast and Robust Certifiable Estimation of the Relative Pose Between Two Calibrated Cameras. (arXiv:2101.08524v1 [cs.CV])</h2>
<h3>Mercedes Garcia-Salguero, Javier Gonzalez-Jimenez</h3>
<p>The Relative Pose problem (RPp) for cameras aims to estimate the relative
orientation and translation (pose) given a set of pair-wise feature
correspondences between two central and calibrated cameras. The RPp is stated
as an optimization problem where the squared, normalized epipolar error is
minimized over the set of normalized essential matrices. In this work, we
contribute an efficient and complete algorithm based on results from duality
theory that is able to certify whether the solution to a RPp instance is the
global optimum. Specifically, we present a family of certifiers that is shown
to increase the ratio of detected optimal solutions. This set of certifiers is
incorporated into an efficient essential matrix estimation pipeline that, given
any initial guess for the RPp, refines it iteratively on the product space of
3D rotations and 2-sphere and thereupon, certifies the optimality of the
solution.

We integrate our fast certifiable pipeline into a robust framework that
combines Graduated Non-convexity and the Black-Rangarajan duality between
robust functions and line processes. This combination has been shown in the
literature to outperform the robustness to outliers provided by approaches
based on RANSAC.

We proved through extensive experiments on synthetic and real data that the
proposed framework provides a fast and robust relative pose estimation. We
compare our proposal against the state-of-the-art methods on both accuracy and
computational cost, and show that our estimations improve the output of the
gold-standard approach for the RPp, the 2-view Bundle-Adjustment.

We make the code publicly available
\url{https://github.com/mergarsal/FastCertRelPose.git}.
</p>
<a href="http://arxiv.org/abs/2101.08524" target="_blank">arXiv:2101.08524</a> [<a href="http://arxiv.org/pdf/2101.08524" target="_blank">pdf</a>]

<h2>Progressive Co-Attention Network for Fine-grained Visual Classification. (arXiv:2101.08527v1 [cs.CV])</h2>
<h3>Tian Zhang, Dongliang Chang, Zhanyu Ma, Jun Guo</h3>
<p>Fine-grained visual classification aims to recognize images belonging to
multiple sub-categories within a same category. It is a challenging task due to
the inherently subtle variations among highly-confused categories. Most
existing methods only take individual image as input, which may limit the
ability of models to recognize contrastive clues from different images. In this
paper, we propose an effective method called progressive co-attention network
(PCA-Net) to tackle this problem. Specifically, we calculate the channel-wise
similarity by interacting the feature channels within same-category images to
capture the common discriminative features. Considering that complementary
imformation is also crucial for recognition, we erase the prominent areas
enhanced by the channel interaction to force the network to focus on other
discriminative regions. The proposed model can be trained in an end-to-end
manner, and only requires image-level label supervision. It has achieved
competitive results on three fine-grained visual classification benchmark
datasets: CUB-200-2011, Stanford Cars, and FGVC Aircraft.
</p>
<a href="http://arxiv.org/abs/2101.08527" target="_blank">arXiv:2101.08527</a> [<a href="http://arxiv.org/pdf/2101.08527" target="_blank">pdf</a>]

<h2>An Effective Data Augmentation for Person Re-identification. (arXiv:2101.08533v1 [cs.CV])</h2>
<h3>Yunpeng Gong, Zhiyong Zeng</h3>
<p>In order to make full use of structural information of grayscale images and
reduce adverse impact of illumination variation for person re-identification
(ReID), an effective data augmentation method is proposed in this paper, which
includes Random Grayscale Transformation, Random Grayscale Patch Replacement
and their combination. It is discovered that structural information has a
significant effect on the ReID model performance, and it is very important
complementary to RGB images ReID. During ReID model training, on the one hand,
we randomly selected a rectangular area in the RGB image and replace its color
with the same rectangular area grayscale in corresponding grayscale image, thus
we generate a training image with different grayscale areas; On the other hand,
we convert an image into a grayscale image. These two methods will reduce the
risk of overfitting the model due to illumination variations and make the model
more robust to cross-camera. The experimental results show that our method
achieves a performance improvement of up to 3.3%, achieving the highest
retrieval accuracy currently on multiple datasets.
</p>
<a href="http://arxiv.org/abs/2101.08533" target="_blank">arXiv:2101.08533</a> [<a href="http://arxiv.org/pdf/2101.08533" target="_blank">pdf</a>]

<h2>Efficient Pure Exploration for Combinatorial Bandits with Semi-Bandit Feedback. (arXiv:2101.08534v1 [stat.ML])</h2>
<h3>Marc Jourdan, Mojm&#xed;r Mutn&#xfd;, Johannes Kirschner, Andreas Krause</h3>
<p>Combinatorial bandits with semi-bandit feedback generalize multi-armed
bandits, where the agent chooses sets of arms and observes a noisy reward for
each arm contained in the chosen set. The action set satisfies a given
structure such as forming a base of a matroid or a path in a graph. We focus on
the pure-exploration problem of identifying the best arm with fixed confidence,
as well as a more general setting, where the structure of the answer set
differs from the one of the action set. Using the recently popularized game
framework, we interpret this problem as a sequential zero-sum game and develop
a CombGame meta-algorithm whose instances are asymptotically optimal algorithms
with finite time guarantees. In addition to comparing two families of learners
to instantiate our meta-algorithm, the main contribution of our work is a
specific oracle efficient instance for best-arm identification with
combinatorial actions. Based on a projection-free online learning algorithm for
convex polytopes, it is the first computationally efficient algorithm which is
asymptotically optimal and has competitive empirical performance.
</p>
<a href="http://arxiv.org/abs/2101.08534" target="_blank">arXiv:2101.08534</a> [<a href="http://arxiv.org/pdf/2101.08534" target="_blank">pdf</a>]

<h2>Orthogonal Least Squares Based Fast Feature Selection for Linear Classification. (arXiv:2101.08539v1 [cs.LG])</h2>
<h3>Sikai Zhang, Zi-Qiang Lang</h3>
<p>An Orthogonal Least Squares (OLS) based feature selection method is proposed
for both binomial and multinomial classification. The novel Squared Orthogonal
Correlation Coefficient (SOCC) is defined based on Error Reduction Ratio (ERR)
in OLS and used as the feature ranking criterion. The equivalence between the
canonical correlation coefficient, Fisher's criterion, and the sum of the SOCCs
is revealed, which unveils the statistical implication of ERR in OLS for the
first time. It is also shown that the OLS based feature selection method has
speed advantages when applied for greedy search. The proposed method is
comprehensively compared with the mutual information based feature selection
methods in 2 synthetic and 7 real world datasets. The results show that the
proposed method is always in the top 5 among the 10 candidate methods. Besides,
the proposed method can be directly applied to continuous features without
discretisation, which is another significant advantage over mutual information
based methods.
</p>
<a href="http://arxiv.org/abs/2101.08539" target="_blank">arXiv:2101.08539</a> [<a href="http://arxiv.org/pdf/2101.08539" target="_blank">pdf</a>]

<h2>Activity Graph Transformer for Temporal Action Localization. (arXiv:2101.08540v1 [cs.CV])</h2>
<h3>Megha Nawhal, Greg Mori</h3>
<p>We introduce Activity Graph Transformer, an end-to-end learnable model for
temporal action localization, that receives a video as input and directly
predicts a set of action instances that appear in the video. Detecting and
localizing action instances in untrimmed videos requires reasoning over
multiple action instances in a video. The dominant paradigms in the literature
process videos temporally to either propose action regions or directly produce
frame-level detections. However, sequential processing of videos is problematic
when the action instances have non-sequential dependencies and/or non-linear
temporal ordering, such as overlapping action instances or re-occurrence of
action instances over the course of the video. In this work, we capture this
non-linear temporal structure by reasoning over the videos as non-sequential
entities in the form of graphs. We evaluate our model on challenging datasets:
THUMOS14, Charades, and EPIC-Kitchens-100. Our results show that our proposed
model outperforms the state-of-the-art by a considerable margin.
</p>
<a href="http://arxiv.org/abs/2101.08540" target="_blank">arXiv:2101.08540</a> [<a href="http://arxiv.org/pdf/2101.08540" target="_blank">pdf</a>]

<h2>Boost then Convolve: Gradient Boosting Meets Graph Neural Networks. (arXiv:2101.08543v1 [cs.LG])</h2>
<h3>Sergei Ivanov, Liudmila Prokhorenkova</h3>
<p>Graph neural networks (GNNs) are powerful models that have been successful in
various graph representation learning tasks. Whereas gradient boosted decision
trees (GBDT) often outperform other machine learning methods when faced with
heterogeneous tabular data. But what approach should be used for graphs with
tabular node features? Previous GNN models have mostly focused on networks with
homogeneous sparse features and, as we show, are suboptimal in the
heterogeneous setting. In this work, we propose a novel architecture that
trains GBDT and GNN jointly to get the best of both worlds: the GBDT model
deals with heterogeneous features, while GNN accounts for the graph structure.
Our model benefits from end-to-end optimization by allowing new trees to fit
the gradient updates of GNN. With an extensive experimental comparison to the
leading GBDT and GNN models, we demonstrate a significant increase in
performance on a variety of graphs with tabular features. The code is
available: https://github.com/nd7141/bgnn.
</p>
<a href="http://arxiv.org/abs/2101.08543" target="_blank">arXiv:2101.08543</a> [<a href="http://arxiv.org/pdf/2101.08543" target="_blank">pdf</a>]

<h2>Discovering Multi-Label Actor-Action Association in a Weakly Supervised Setting. (arXiv:2101.08567v1 [cs.CV])</h2>
<h3>Sovan Biswas, Juergen Gall</h3>
<p>Since collecting and annotating data for spatio-temporal action detection is
very expensive, there is a need to learn approaches with less supervision.
Weakly supervised approaches do not require any bounding box annotations and
can be trained only from labels that indicate whether an action occurs in a
video clip. Current approaches, however, cannot handle the case when there are
multiple persons in a video that perform multiple actions at the same time. In
this work, we address this very challenging task for the first time. We propose
a baseline based on multi-instance and multi-label learning. Furthermore, we
propose a novel approach that uses sets of actions as representation instead of
modeling individual action classes. Since computing, the probabilities for the
full power set becomes intractable as the number of action classes increases,
we assign an action set to each detected person under the constraint that the
assignment is consistent with the annotation of the video clip. We evaluate the
proposed approach on the challenging AVA dataset where the proposed approach
outperforms the MIML baseline and is competitive to fully supervised
approaches.
</p>
<a href="http://arxiv.org/abs/2101.08567" target="_blank">arXiv:2101.08567</a> [<a href="http://arxiv.org/pdf/2101.08567" target="_blank">pdf</a>]

<h2>A Note on Connectivity of Sublevel Sets in Deep Learning. (arXiv:2101.08576v1 [cs.LG])</h2>
<h3>Quynh Nguyen</h3>
<p>It is shown that for deep neural networks, a single wide layer of width $N+1$
($N$ being the number of training samples) suffices to prove the connectivity
of sublevel sets of the training loss function. In the two-layer setting, the
same property may not hold even if one has just one neuron less (i.e. width $N$
can lead to disconnected sublevel sets).
</p>
<a href="http://arxiv.org/abs/2101.08576" target="_blank">arXiv:2101.08576</a> [<a href="http://arxiv.org/pdf/2101.08576" target="_blank">pdf</a>]

<h2>Hierarchical Graph-RNNs for Action Detection of Multiple Activities. (arXiv:2101.08581v1 [cs.CV])</h2>
<h3>Sovan Biswas, Yaser Souri, Juergen Gall</h3>
<p>In this paper, we propose an approach that spatially localizes the activities
in a video frame where each person can perform multiple activities at the same
time. Our approach takes the temporal scene context as well as the relations of
the actions of detected persons into account. While the temporal context is
modeled by a temporal recurrent neural network (RNN), the relations of the
actions are modeled by a graph RNN. Both networks are trained together and the
proposed approach achieves state of the art results on the AVA dataset.
</p>
<a href="http://arxiv.org/abs/2101.08581" target="_blank">arXiv:2101.08581</a> [<a href="http://arxiv.org/pdf/2101.08581" target="_blank">pdf</a>]

<h2>Crossbreeding in Random Forest. (arXiv:2101.08585v1 [cs.LG])</h2>
<h3>Abolfazl Nadi, Hadi Moradi, Khalil Taheri</h3>
<p>Ensemble learning methods are designed to benefit from multiple learning
algorithms for better predictive performance. The tradeoff of this improved
performance is slower speed and larger size of ensemble learning systems
compared to single learning systems. In this paper, we present a novel approach
to deal with this problem in Random Forest (RF) as one of the most powerful
ensemble methods. The method is based on crossbreeding of the best tree
branches to increase the performance of RF in space and speed while keeping the
performance in the classification measures. The proposed approach has been
tested on a group of synthetic and real datasets and compared to the standard
RF approach. Several evaluations have been conducted to determine the effects
of the Crossbred RF (CRF) on the accuracy and the number of trees in a forest.
The results show better performance of CRF compared to RF.
</p>
<a href="http://arxiv.org/abs/2101.08585" target="_blank">arXiv:2101.08585</a> [<a href="http://arxiv.org/pdf/2101.08585" target="_blank">pdf</a>]

<h2>Stress Testing of Meta-learning Approaches for Few-shot Learning. (arXiv:2101.08587v1 [cs.LG])</h2>
<h3>Aroof Aimen, Sahil Sidheekh, Vineet Madan, Narayanan C. Krishnan</h3>
<p>Meta-learning (ML) has emerged as a promising learning method under resource
constraints such as few-shot learning. ML approaches typically propose a
methodology to learn generalizable models. In this work-in-progress paper, we
put the recent ML approaches to a stress test to discover their limitations.
Precisely, we measure the performance of ML approaches for few-shot learning
against increasing task complexity. Our results show a quick degradation in the
performance of initialization strategies for ML (MAML, TAML, and MetaSGD),
while surprisingly, approaches that use an optimization strategy (MetaLSTM)
perform significantly better. We further demonstrate the effectiveness of an
optimization strategy for ML (MetaLSTM++) trained in a MAML manner over a pure
optimization strategy. Our experiments also show that the optimization
strategies for ML achieve higher transferability from simple to complex tasks.
</p>
<a href="http://arxiv.org/abs/2101.08587" target="_blank">arXiv:2101.08587</a> [<a href="http://arxiv.org/pdf/2101.08587" target="_blank">pdf</a>]

<h2>MPASNET: Motion Prior-Aware Siamese Network for Unsupervised Deep Crowd Segmentation in Video Scenes. (arXiv:2101.08609v1 [cs.CV])</h2>
<h3>Jinhai Yang, Hua Yang</h3>
<p>Crowd segmentation is a fundamental task serving as the basis of crowded
scene analysis, and it is highly desirable to obtain refined pixel-level
segmentation maps. However, it remains a challenging problem, as existing
approaches either require dense pixel-level annotations to train deep learning
models or merely produce rough segmentation maps from optical or particle flows
with physical models. In this paper, we propose the Motion Prior-Aware Siamese
Network (MPASNET) for unsupervised crowd semantic segmentation. This model not
only eliminates the need for annotation but also yields high-quality
segmentation maps. Specially, we first analyze the coherent motion patterns
across the frames and then apply a circular region merging strategy on the
collective particles to generate pseudo-labels. Moreover, we equip MPASNET with
siamese branches for augmentation-invariant regularization and siamese feature
aggregation. Experiments over benchmark datasets indicate that our model
outperforms the state-of-the-arts by more than 12% in terms of mIoU.
</p>
<a href="http://arxiv.org/abs/2101.08609" target="_blank">arXiv:2101.08609</a> [<a href="http://arxiv.org/pdf/2101.08609" target="_blank">pdf</a>]

<h2>Learning rich touch representations through cross-modal self-supervision. (arXiv:2101.08616v1 [cs.RO])</h2>
<h3>Martina Zambelli, Yusuf Aytar, Francesco Visin, Yuxiang Zhou, Raia Hadsell</h3>
<p>The sense of touch is fundamental in several manipulation tasks, but rarely
used in robot manipulation. In this work we tackle the problem of learning rich
touch features from cross-modal self-supervision. We evaluate them identifying
objects and their properties in a few-shot classification setting. Two new
datasets are introduced using a simulated anthropomorphic robotic hand equipped
with tactile sensors on both synthetic and daily life objects. Several
self-supervised learning methods are benchmarked on these datasets, by
evaluating few-shot classification on unseen objects and poses. Our experiments
indicate that cross-modal self-supervision effectively improves touch
representation, and in turn has great potential to enhance robot manipulation
skills.
</p>
<a href="http://arxiv.org/abs/2101.08616" target="_blank">arXiv:2101.08616</a> [<a href="http://arxiv.org/pdf/2101.08616" target="_blank">pdf</a>]

<h2>Image-to-Image Translation: Methods and Applications. (arXiv:2101.08629v1 [cs.CV])</h2>
<h3>Yingxue Pang, Jianxin Lin, Tao Qin, Zhibo Chen</h3>
<p>Image-to-image translation (I2I) aims to transfer images from a source domain
to a target domain while preserving the content representations. I2I has drawn
increasing attention and made tremendous progress in recent years because of
its wide range of applications in many computer vision and image processing
problems, such as image synthesis, segmentation, style transfer, restoration,
and pose estimation. In this paper, we provide an overview of the I2I works
developed in recent years. We will analyze the key techniques of the existing
I2I works and clarify the main progress the community has made. Additionally,
we will elaborate on the effect of I2I on the research and industry community
and point out remaining challenges in related fields.
</p>
<a href="http://arxiv.org/abs/2101.08629" target="_blank">arXiv:2101.08629</a> [<a href="http://arxiv.org/pdf/2101.08629" target="_blank">pdf</a>]

<h2>Dive into Decision Trees and Forests: A Theoretical Demonstration. (arXiv:2101.08656v1 [cs.LG])</h2>
<h3>Jinxiong Zhang</h3>
<p>Based on decision trees, many fields have arguably made tremendous progress
in recent years. In simple words, decision trees use the strategy of
"divide-and-conquer" to divide the complex problem on the dependency between
input features and labels into smaller ones. While decision trees have a long
history, recent advances have greatly improved their performance in
computational advertising, recommender system, information retrieval, etc. We
introduce common tree-based models (e.g., Bayesian CART, Bayesian regression
splines) and training techniques (e.g., mixed integer programming, alternating
optimization, gradient descent). Along the way, we highlight probabilistic
characteristics of tree-based models and explain their practical and
theoretical benefits. Except machine learning and data mining, we try to show
theoretical advances on tree-based models from other fields such as statistics
and operation research. We list the reproducible resource at the end of each
method.
</p>
<a href="http://arxiv.org/abs/2101.08656" target="_blank">arXiv:2101.08656</a> [<a href="http://arxiv.org/pdf/2101.08656" target="_blank">pdf</a>]

<h2>Fidelity and Privacy of Synthetic Medical Data. (arXiv:2101.08658v1 [cs.LG])</h2>
<h3>Ofer Mendelevitch, Michael D. Lesh</h3>
<p>The digitization of medical records ushered in a new era of big data to
clinical science, and with it the possibility that data could be shared, to
multiply insights beyond what investigators could abstract from paper records.
The need to share individual-level medical data to accelerate innovation in
precision medicine continues to grow, and has never been more urgent, as
scientists grapple with the COVID-19 pandemic. However, enthusiasm for the use
of big data has been tempered by a fully appropriate concern for patient
autonomy and privacy. That is, the ability to extract private or confidential
information about an individual, in practice, renders it difficult to share
data, since significant infrastructure and data governance must be established
before data can be shared. Although HIPAA provided de-identification as an
approved mechanism for data sharing, linkage attacks were identified as a major
vulnerability. A variety of mechanisms have been established to avoid leaking
private information, such as field suppression or abstraction, strictly
limiting the amount of information that can be shared, or employing
mathematical techniques such as differential privacy. Another approach, which
we focus on here, is creating synthetic data that mimics the underlying data.
For synthetic data to be a useful mechanism in support of medical innovation
and a proxy for real-world evidence, one must demonstrate two properties of the
synthetic dataset: (1) any analysis on the real data must be matched by
analysis of the synthetic data (statistical fidelity) and (2) the synthetic
data must preserve privacy, with minimal risk of re-identification (privacy
guarantee). In this paper we propose a framework for quantifying the
statistical fidelity and privacy preservation properties of synthetic datasets
and demonstrate these metrics for synthetic data generated by Syntegra
technology.
</p>
<a href="http://arxiv.org/abs/2101.08658" target="_blank">arXiv:2101.08658</a> [<a href="http://arxiv.org/pdf/2101.08658" target="_blank">pdf</a>]

<h2>Free congruence: an exploration of expanded similarity measures for time series data. (arXiv:2101.08659v1 [cs.LG])</h2>
<h3>Lucas Cassiel Jacaruso</h3>
<p>Time series similarity measures are highly relevant in a wide range of
emerging applications including training machine learning models,
classification, and predictive modeling. Standard similarity measures for time
series most often involve point-to-point distance measures including Euclidean
distance and Dynamic Time Warping. Such similarity measures fundamentally
require the fluctuation of values in the time series being compared to follow a
corresponding order or cadence for similarity to be established. This paper is
spurred by the exploration of a broader definition of similarity, namely one
that takes into account the sheer numerical resemblance between sets of
statistical properties for time series segments irrespectively of value
labeling. Further, the presence of common pattern components between time
series segments was examined even if they occur in a permuted order, which
would not necessarily satisfy the criteria of more conventional point-to-point
distance measures. Results were compared with those of Dynamic Time Warping on
the same data for context. Surprisingly, the test for the numerical resemblance
between sets of statistical properties established a stronger resemblance for
pairings of decline years with greater statistical significance than Dynamic
Time Warping on the particular data and sample size used.
</p>
<a href="http://arxiv.org/abs/2101.08659" target="_blank">arXiv:2101.08659</a> [<a href="http://arxiv.org/pdf/2101.08659" target="_blank">pdf</a>]

<h2>Regularization via deep generative models: an analysis point of view. (arXiv:2101.08661v1 [cs.CV])</h2>
<h3>Thomas Oberlin, Mathieu Verm</h3>
<p>This paper proposes a new way of regularizing an inverse problem in imaging
(e.g., deblurring or inpainting) by means of a deep generative neural network.
Compared to end-to-end models, such approaches seem particularly interesting
since the same network can be used for many different problems and experimental
conditions, as soon as the generative model is suited to the data. Previous
works proposed to use a synthesis framework, where the estimation is performed
on the latent vector, the solution being obtained afterwards via the decoder.
Instead, we propose an analysis formulation where we directly optimize the
image itself and penalize the latent vector. We illustrate the interest of such
a formulation by running experiments of inpainting, deblurring and
super-resolution. In many cases our technique achieves a clear improvement of
the performance and seems to be more robust, in particular with respect to
initialization.
</p>
<a href="http://arxiv.org/abs/2101.08661" target="_blank">arXiv:2101.08661</a> [<a href="http://arxiv.org/pdf/2101.08661" target="_blank">pdf</a>]

<h2>DAF:re: A Challenging, Crowd-Sourced, Large-Scale, Long-Tailed Dataset For Anime Character Recognition. (arXiv:2101.08674v1 [cs.CV])</h2>
<h3>Edwin Arkel Rios, Wen-Huang Cheng, Bo-Cheng Lai</h3>
<p>In this work we tackle the challenging problem of anime character
recognition. Anime, referring to animation produced within Japan and work
derived or inspired from it. For this purpose we present DAF:re
(DanbooruAnimeFaces:revamped), a large-scale, crowd-sourced, long-tailed
dataset with almost 500 K images spread across more than 3000 classes.
Additionally, we conduct experiments on DAF:re and similar datasets using a
variety of classification models, including CNN based ResNets and
self-attention based Vision Transformer (ViT). Our results give new insights
into the generalization and transfer learning properties of ViT models on
substantially different domain datasets from those used for the upstream
pre-training, including the influence of batch and image size in their
training. Additionally, we share our dataset, source-code, pre-trained
checkpoints and results, as Animesion, the first end-to-end framework for
large-scale anime character recognition: https://github.com/arkel23/animesion
</p>
<a href="http://arxiv.org/abs/2101.08674" target="_blank">arXiv:2101.08674</a> [<a href="http://arxiv.org/pdf/2101.08674" target="_blank">pdf</a>]

<h2>Adversarial Machine Learning in Text Analysis and Generation. (arXiv:2101.08675v1 [cs.LG])</h2>
<h3>Izzat Alsmadi</h3>
<p>The research field of adversarial machine learning witnessed a significant
interest in the last few years. A machine learner or model is secure if it can
deliver main objectives with acceptable accuracy, efficiency, etc. while at the
same time, it can resist different types and/or attempts of adversarial
attacks. This paper focuses on studying aspects and research trends in
adversarial machine learning specifically in text analysis and generation. The
paper summarizes main research trends in the field such as GAN algorithms,
models, types of attacks, and defense against those attacks.
</p>
<a href="http://arxiv.org/abs/2101.08675" target="_blank">arXiv:2101.08675</a> [<a href="http://arxiv.org/pdf/2101.08675" target="_blank">pdf</a>]

<h2>A two-stage data association approach for 3D Multi-object Tracking. (arXiv:2101.08684v1 [cs.CV])</h2>
<h3>Minh-Quan Dao, Vincent Fr&#xe9;mont</h3>
<p>Multi-object tracking (MOT) is an integral part of any autonomous driving
pipelines because itproduces trajectories which has been taken by other moving
objects in the scene and helps predicttheir future motion. Thanks to the recent
advances in 3D object detection enabled by deep learning,track-by-detection has
become the dominant paradigm in 3D MOT. In this paradigm, a MOT systemis
essentially made of an object detector and a data association algorithm which
establishes track-to-detection correspondence. While 3D object detection has
been actively researched, associationalgorithms for 3D MOT seem to settle at a
bipartie matching formulated as a linear assignmentproblem (LAP) and solved by
the Hungarian algorithm. In this paper, we adapt a two-stage dataassociation
method which was successful in image-based tracking to the 3D setting, thus
providingan alternative for data association for 3D MOT. Our method outperforms
the baseline using one-stagebipartie matching for data association by achieving
0.587 AMOTA in NuScenes validation set.
</p>
<a href="http://arxiv.org/abs/2101.08684" target="_blank">arXiv:2101.08684</a> [<a href="http://arxiv.org/pdf/2101.08684" target="_blank">pdf</a>]

<h2>ItNet: iterative neural networks with tiny graphs for accurate and efficient anytime prediction. (arXiv:2101.08685v1 [cs.LG])</h2>
<h3>Thomas Pfeil</h3>
<p>Deep neural networks have usually to be compressed and accelerated for their
usage in low-power, e.g. mobile, devices. Recently, massively-parallel hardware
accelerators were developed that offer high throughput and low latency at low
power by utilizing in-memory computation. However, to exploit these benefits
the computational graph of a neural network has to fit into the in-computation
memory of these hardware systems that is usually rather limited in size. In
this study, we introduce a class of network models that have a tiny memory
footprint in terms of their computational graphs. To this end, the graph is
designed to contain loops by iteratively executing a single network building
block. Furthermore, the trade-off between accuracy and latency of these
so-called iterative neural networks is improved by adding multiple intermediate
outputs both during training and inference. We show state-of-the-art results
for semantic segmentation on the CamVid and Cityscapes datasets that are
especially demanding in terms of computational resources. In ablation studies,
the improvement of network training by intermediate network outputs as well as
the trade-off between weight sharing over iterations and the network size are
investigated.
</p>
<a href="http://arxiv.org/abs/2101.08685" target="_blank">arXiv:2101.08685</a> [<a href="http://arxiv.org/pdf/2101.08685" target="_blank">pdf</a>]

<h2>Overfitting for Fun and Profit: Instance-Adaptive Data Compression. (arXiv:2101.08687v1 [cs.LG])</h2>
<h3>Ties van Rozendaal, Iris A.M. Huijben, Taco S. Cohen</h3>
<p>Neural data compression has been shown to outperform classical methods in
terms of $RD$ performance, with results still improving rapidly. At a high
level, neural compression is based on an autoencoder that tries to reconstruct
the input instance from a (quantized) latent representation, coupled with a
prior that is used to losslessly compress these latents. Due to limitations on
model capacity and imperfect optimization and generalization, such models will
suboptimally compress test data in general. However, one of the great strengths
of learned compression is that if the test-time data distribution is known and
relatively low-entropy (e.g. a camera watching a static scene, a dash cam in an
autonomous car, etc.), the model can easily be finetuned or adapted to this
distribution, leading to improved $RD$ performance. In this paper we take this
concept to the extreme, adapting the full model to a single video, and sending
model updates (quantized and compressed using a parameter-space prior) along
with the latent representation. Unlike previous work, we finetune not only the
encoder/latents but the entire model, and - during finetuning - take into
account both the effect of model quantization and the additional costs incurred
by sending the model updates. We evaluate an image compression model on
I-frames (sampled at 2 fps) from videos of the Xiph dataset, and demonstrate
that full-model adaptation improves $RD$ performance by ~1 dB, with respect to
encoder-only finetuning.
</p>
<a href="http://arxiv.org/abs/2101.08687" target="_blank">arXiv:2101.08687</a> [<a href="http://arxiv.org/pdf/2101.08687" target="_blank">pdf</a>]

<h2>Characterizing signal propagation to close the performance gap in unnormalized ResNets. (arXiv:2101.08692v1 [cs.LG])</h2>
<h3>Andrew Brock, Soham De, Samuel L. Smith</h3>
<p>Batch Normalization is a key component in almost all state-of-the-art image
classifiers, but it also introduces practical challenges: it breaks the
independence between training examples within a batch, can incur compute and
memory overhead, and often results in unexpected bugs. Building on recent
theoretical analyses of deep ResNets at initialization, we propose a simple set
of analysis tools to characterize signal propagation on the forward pass, and
leverage these tools to design highly performant ResNets without activation
normalization layers. Crucial to our success is an adapted version of the
recently proposed Weight Standardization. Our analysis tools show how this
technique preserves the signal in networks with ReLU or Swish activation
functions by ensuring that the per-channel activation means do not grow with
depth. Across a range of FLOP budgets, our networks attain performance
competitive with the state-of-the-art EfficientNets on ImageNet.
</p>
<a href="http://arxiv.org/abs/2101.08692" target="_blank">arXiv:2101.08692</a> [<a href="http://arxiv.org/pdf/2101.08692" target="_blank">pdf</a>]

<h2>Multi-robot energy autonomy with wind and constrained resources. (arXiv:2101.08697v1 [cs.RO])</h2>
<h3>Hassan Fouad, Giovanni Beltrame</h3>
<p>One aspect of the ever-growing need for long term autonomy of multi-robot
systems, is ensuring energy sufficiency. In particular, in scenarios where
charging facilities are limited, battery-powered robots need to coordinate to
share access. In this work we extend previous results by considering robots
that carry out a generic mission while sharing a single charging station, while
being affected by air drag and wind fields. Our mission-agnostic framework
based on control barrier functions (CBFs) ensures energy sufficiency (i.e.,
maintaining all robots above a certain voltage threshold) and proper
coordination (i.e., ensuring mutually exclusive use of the available charging
station). Moreover, we investigate the feasibility requirements of the system
in relation to individual robots' properties, as well as air drag and wind
effects. We show simulation results that demonstrate the effectiveness of the
proposed framework.
</p>
<a href="http://arxiv.org/abs/2101.08697" target="_blank">arXiv:2101.08697</a> [<a href="http://arxiv.org/pdf/2101.08697" target="_blank">pdf</a>]

<h2>An empirical evaluation of active inference in multi-armed bandits. (arXiv:2101.08699v1 [cs.LG])</h2>
<h3>Dimitrije Markovic, Hrvoje Stojic, Sarah Schwoebel, Stefan J. Kiebel</h3>
<p>A key feature of sequential decision making under uncertainty is a need to
balance between exploiting--choosing the best action according to the current
knowledge, and exploring--obtaining information about values of other actions.
The multi-armed bandit problem, a classical task that captures this trade-off,
served as a vehicle in machine learning for developing bandit algorithms that
proved to be useful in numerous industrial applications. The active inference
framework, an approach to sequential decision making recently developed in
neuroscience for understanding human and animal behaviour, is distinguished by
its sophisticated strategy for resolving the exploration-exploitation
trade-off. This makes active inference an exciting alternative to already
established bandit algorithms. Here we derive an efficient and scalable
approximate active inference algorithm and compare it to two state-of-the-art
bandit algorithms: Bayesian upper confidence bound and optimistic Thompson
sampling, on two types of bandit problems: a stationary and a dynamic switching
bandit. Our empirical evaluation shows that the active inference algorithm does
not produce efficient long-term behaviour in stationary bandits. However, in
more challenging switching bandit problem active inference performs
substantially better than the two bandit algorithms. The results open exciting
venues for further research in theoretical and applied machine learning, as
well as lend additional credibility to active inference as a general framework
for studying human and animal behaviour.
</p>
<a href="http://arxiv.org/abs/2101.08699" target="_blank">arXiv:2101.08699</a> [<a href="http://arxiv.org/pdf/2101.08699" target="_blank">pdf</a>]

<h2>Self-Adaptive Training: Bridging the Supervised and Self-Supervised Learning. (arXiv:2101.08732v1 [cs.LG])</h2>
<h3>Lang Huang, Chao Zhang, Hongyang Zhang</h3>
<p>We propose self-adaptive training -- a unified training algorithm that
dynamically calibrates and enhances training process by model predictions
without incurring extra computational cost -- to advance both supervised and
self-supervised learning of deep neural networks. We analyze the training
dynamics of deep networks on training data that are corrupted by, e.g., random
noise and adversarial examples. Our analysis shows that model predictions are
able to magnify useful underlying information in data and this phenomenon
occurs broadly even in the absence of \emph{any} label information,
highlighting that model predictions could substantially benefit the training
process: self-adaptive training improves the generalization of deep networks
under noise and enhances the self-supervised representation learning. The
analysis also sheds light on understanding deep learning, e.g., a potential
explanation of the recently-discovered double-descent phenomenon in empirical
risk minimization and the collapsing issue of the state-of-the-art
self-supervised learning algorithms. Experiments on the CIFAR, STL and ImageNet
datasets verify the effectiveness of our approach in three applications:
classification with label noise, selective classification and linear
evaluation. To facilitate future research, the code has been made public
available at https://github.com/LayneH/self-adaptive-training.
</p>
<a href="http://arxiv.org/abs/2101.08732" target="_blank">arXiv:2101.08732</a> [<a href="http://arxiv.org/pdf/2101.08732" target="_blank">pdf</a>]

<h2>Model-based Policy Search for Partially Measurable Systems. (arXiv:2101.08740v1 [cs.RO])</h2>
<h3>Fabio Amadio, Alberto Dalla Libera, Ruggero Carli, Daniel Nikovski, Diego Romeres</h3>
<p>In this paper, we propose a Model-Based Reinforcement Learning (MBRL)
algorithm for Partially Measurable Systems (PMS), i.e., systems where the state
can not be directly measured, but must be estimated through proper state
observers. The proposed algorithm, named Monte Carlo Probabilistic Inference
for Learning COntrol for Partially Measurable Systems (MC-PILCO4PMS), relies on
Gaussian Processes (GPs) to model the system dynamics, and on a Monte Carlo
approach to update the policy parameters. W.r.t. previous GP-based MBRL
algorithms, MC-PILCO4PMS models explicitly the presence of state observers
during policy optimization, allowing to deal PMS. The effectiveness of the
proposed algorithm has been tested both in simulation and in two real systems.
</p>
<a href="http://arxiv.org/abs/2101.08740" target="_blank">arXiv:2101.08740</a> [<a href="http://arxiv.org/pdf/2101.08740" target="_blank">pdf</a>]

<h2>Soft Genetic Programming Binary Classifiers. (arXiv:2101.08742v1 [cs.LG])</h2>
<h3>Ivan Gridin</h3>
<p>The study of the classifier's design and it's usage is one of the most
important machine learning areas. With the development of automatic machine
learning methods, various approaches are used to build a robust classifier
model. Due to some difficult implementation and customization complexity,
genetic programming (GP) methods are not often used to construct classifiers.
GP classifiers have several limitations and disadvantages. However, the concept
of "soft" genetic programming (SGP) has been developed, which allows the
logical operator tree to be more flexible and find dependencies in datasets,
which gives promising results in most cases. This article discusses a method
for constructing binary classifiers using the SGP technique. The test results
are presented. Source code - https://github.com/survexman/sgp_classifier.
</p>
<a href="http://arxiv.org/abs/2101.08742" target="_blank">arXiv:2101.08742</a> [<a href="http://arxiv.org/pdf/2101.08742" target="_blank">pdf</a>]

<h2>A New Knowledge Gradient-based Method for Constrained Bayesian Optimization. (arXiv:2101.08743v1 [cs.LG])</h2>
<h3>Wenjie Chen, Shengcai Liu, Ke Tang</h3>
<p>Black-box problems are common in real life like structural design, drug
experiments, and machine learning. When optimizing black-box systems,
decision-makers always consider multiple performances and give the final
decision by comprehensive evaluations. Motivated by such practical needs, we
focus on constrained black-box problems where the objective and constraints
lack known special structure, and evaluations are expensive and even with
noise. We develop a novel constrained Bayesian optimization approach based on
the knowledge gradient method ($c-\rm{KG}$). A new acquisition function is
proposed to determine the next batch of samples considering optimality and
feasibility. An unbiased estimator of the gradient of the new acquisition
function is derived to implement the $c-\rm{KG}$ approach.
</p>
<a href="http://arxiv.org/abs/2101.08743" target="_blank">arXiv:2101.08743</a> [<a href="http://arxiv.org/pdf/2101.08743" target="_blank">pdf</a>]

<h2>Knowledge-Preserving Incremental Social Event Detection via Heterogeneous GNNs. (arXiv:2101.08747v1 [cs.LG])</h2>
<h3>Yuwei Cao, Hao Peng, Jia Wu, Yingtong Dou, Jianxin Li, Philip S. Yu</h3>
<p>Social events provide valuable insights into group social behaviors and
public concerns and therefore have many applications in fields such as product
recommendation and crisis management. The complexity and streaming nature of
social messages make it appealing to address social event detection in an
incremental learning setting, where acquiring, preserving, and extending
knowledge are major concerns. Most existing methods, including those based on
incremental clustering and community detection, learn limited amounts of
knowledge as they ignore the rich semantics and structural information
contained in the social data. Moreover, they cannot memorize previously
acquired knowledge. In this paper, we propose a novel Knowledge-Preserving
Incremental Heterogeneous Graph Neural Network (KPGNN) for incremental social
event detection. To acquire more knowledge, KPGNN models complex social
messages into unified social graphs to facilitate data utilization and explores
the expressive power of GNNs for knowledge extraction. To continuously adapt to
the incoming data, KPGNN adopts contrastive loss terms that cope with a
changing number of event classes. It also leverages the inductive learning
ability of GNNs to efficiently detect events and extends its knowledge from the
previously unseen data. To deal with large social streams, KPGNN adopts a
mini-batch subgraph sampling strategy for scalable training, and periodically
removes obsolete data to maintain a dynamic embedding space. KPGNN requires no
feature engineering and has few hyperparameters to tune. Extensive experimental
results demonstrate the superiority of KPGNN over various baselines.
</p>
<a href="http://arxiv.org/abs/2101.08747" target="_blank">arXiv:2101.08747</a> [<a href="http://arxiv.org/pdf/2101.08747" target="_blank">pdf</a>]

<h2>How can I choose an explainer? An Application-grounded Evaluation of Post-hoc Explanations. (arXiv:2101.08758v1 [cs.AI])</h2>
<h3>S&#xe9;rgio Jesus, Catarina Bel&#xe9;m, Vladimir Balayan, Jo&#xe3;o Bento, Pedro Saleiro, Pedro Bizarro, Jo&#xe3;o Gama</h3>
<p>There have been several research works proposing new Explainable AI (XAI)
methods designed to generate model explanations having specific properties, or
desiderata, such as fidelity, robustness, or human-interpretability. However,
explanations are seldom evaluated based on their true practical impact on
decision-making tasks. Without that assessment, explanations might be chosen
that, in fact, hurt the overall performance of the combined system of ML model
+ end-users. This study aims to bridge this gap by proposing XAI Test, an
application-grounded evaluation methodology tailored to isolate the impact of
providing the end-user with different levels of information. We conducted an
experiment following XAI Test to evaluate three popular post-hoc explanation
methods -- LIME, SHAP, and TreeInterpreter -- on a real-world fraud detection
task, with real data, a deployed ML model, and fraud analysts. During the
experiment, we gradually increased the information provided to the fraud
analysts in three stages: Data Only, i.e., just transaction data without access
to model score nor explanations, Data + ML Model Score, and Data + ML Model
Score + Explanations. Using strong statistical analysis, we show that, in
general, these popular explainers have a worse impact than desired. Some of the
conclusion highlights include: i) showing Data Only results in the highest
decision accuracy and the slowest decision time among all variants tested, ii)
all the explainers improve accuracy over the Data + ML Model Score variant but
still result in lower accuracy when compared with Data Only; iii) LIME was the
least preferred by users, probably due to its substantially lower variability
of explanations from case to case.
</p>
<a href="http://arxiv.org/abs/2101.08758" target="_blank">arXiv:2101.08758</a> [<a href="http://arxiv.org/pdf/2101.08758" target="_blank">pdf</a>]

<h2>Learn to Dance with AIST++: Music Conditioned 3D Dance Generation. (arXiv:2101.08779v1 [cs.CV])</h2>
<h3>Ruilong Li, Shan Yang, David A. Ross, Angjoo Kanazawa</h3>
<p>In this paper, we present a transformer-based learning framework for 3D dance
generation conditioned on music. We carefully design our network architecture
and empirically study the keys for obtaining qualitatively pleasing results.
The critical components include a deep cross-modal transformer, which well
learns the correlation between the music and dance motion; and the
full-attention with future-N supervision mechanism which is essential in
producing long-range non-freezing motion. In addition, we propose a new dataset
of paired 3D motion and music called AIST++, which we reconstruct from the AIST
multi-view dance videos. This dataset contains 1.1M frames of 3D dance motion
in 1408 sequences, covering 10 genres of dance choreographies and accompanied
with multi-view camera parameters. To our knowledge it is the largest dataset
of this kind. Rich experiments on AIST++ demonstrate our method produces much
better results than the state-of-the-art methods both qualitatively and
quantitatively.
</p>
<a href="http://arxiv.org/abs/2101.08779" target="_blank">arXiv:2101.08779</a> [<a href="http://arxiv.org/pdf/2101.08779" target="_blank">pdf</a>]

<h2>Excitation Dropout: Encouraging Plasticity in Deep Neural Networks. (arXiv:1805.09092v3 [cs.CV] UPDATED)</h2>
<h3>Andrea Zunino, Sarah Adel Bargal, Pietro Morerio, Jianming Zhang, Stan Sclaroff, Vittorio Murino</h3>
<p>We propose a guided dropout regularizer for deep networks based on the
evidence of a network prediction defined as the firing of neurons in specific
paths. In this work, we utilize the evidence at each neuron to determine the
probability of dropout, rather than dropping out neurons uniformly at random as
in standard dropout. In essence, we dropout with higher probability those
neurons which contribute more to decision making at training time. This
approach penalizes high saliency neurons that are most relevant for model
prediction, i.e. those having stronger evidence. By dropping such high-saliency
neurons, the network is forced to learn alternative paths in order to maintain
loss minimization, resulting in a plasticity-like behavior, a characteristic of
human brains too. We demonstrate better generalization ability, an increased
utilization of network neurons, and a higher resilience to network compression
using several metrics over four image/video recognition benchmarks.
</p>
<a href="http://arxiv.org/abs/1805.09092" target="_blank">arXiv:1805.09092</a> [<a href="http://arxiv.org/pdf/1805.09092" target="_blank">pdf</a>]

<h2>Experimental Comparison of Open Source Visual-Inertial-Based State Estimation Algorithms in the Underwater Domain. (arXiv:1904.02215v2 [cs.RO] UPDATED)</h2>
<h3>Bharat Joshi, Sharmin Rahman, Michail Kalaitzakis, Brennan Cain, James Johnson, Marios Xanthidis, Nare Karapetyan, Alan Hernandez, Alberto Quattrini Li, Nikolaos Vitzilaios, Ioannis Rekleitis</h3>
<p>A plethora of state estimation techniques have appeared in the last decade
using visual data, and more recently with added inertial data. Datasets
typically used for evaluation include indoor and urban environments, where
supporting videos have shown impressive performance. However, such techniques
have not been fully evaluated in challenging conditions, such as the marine
domain. In this paper, we compare ten recent open-source packages to provide
insights on their performance and guidelines on addressing current challenges.
Specifically, we selected direct methods and tightly-coupled optimization
techniques that fuse camera and Inertial Measurement Unit (IMU) data together.
Experiments are conducted by testing all packages on datasets collected over
the years with underwater robots in our laboratory. All the datasets are made
available online.
</p>
<a href="http://arxiv.org/abs/1904.02215" target="_blank">arXiv:1904.02215</a> [<a href="http://arxiv.org/pdf/1904.02215" target="_blank">pdf</a>]

<h2>Bayesian Evidential Deep Learning with PAC Regularization. (arXiv:1906.00816v3 [stat.ML] UPDATED)</h2>
<h3>Manuel Haussmann, Sebastian Gerwinn, Melih Kandemir</h3>
<p>We propose a novel method for closed-form predictive distribution modeling
with neural nets. In quantifying prediction uncertainty, we build on Evidential
Deep Learning, which has been impactful as being both simple to implement and
giving closed-form access to predictive uncertainty. We employ it to model
aleatoric uncertainty and extend it to account also for epistemic uncertainty
by converting it to a Bayesian Neural Net. While extending its uncertainty
quantification capabilities, we maintain its analytically accessible predictive
distribution model by performing progressive moment matching for the first time
for approximate weight marginalization. The eventual model introduces a
prohibitively large number of hyperparameters for stable training. We overcome
this drawback by deriving a vacuous PAC bound that comprises the marginal
likelihood of the predictor and a complexity penalty. We observe on regression,
classification, and out-of-domain detection benchmarks that our method improves
model fit and uncertainty quantification.
</p>
<a href="http://arxiv.org/abs/1906.00816" target="_blank">arXiv:1906.00816</a> [<a href="http://arxiv.org/pdf/1906.00816" target="_blank">pdf</a>]

<h2>Privacy-Preserving Deep Action Recognition: An Adversarial Learning Framework and A New Dataset. (arXiv:1906.05675v5 [cs.CV] UPDATED)</h2>
<h3>Zhenyu Wu, Haotao Wang, Zhaowen Wang, Hailin Jin, Zhangyang Wang</h3>
<p>We investigate privacy-preserving, video-based action recognition in deep
learning, a problem with growing importance in smart camera applications. A
novel adversarial training framework is formulated to learn an anonymization
transform for input videos such that the trade-off between target utility task
performance and the associated privacy budgets is explicitly optimized on the
anonymized videos. Notably, the privacy budget, often defined and measured in
task-driven contexts, cannot be reliably indicated using any single model
performance because strong protection of privacy should sustain against any
malicious model that tries to steal private information. To tackle this
problem, we propose two new optimization strategies of model restarting and
model ensemble to achieve stronger universal privacy protection against any
attacker models. Extensive experiments have been carried out and analyzed. On
the other hand, given few public datasets available with both utility and
privacy labels, the data-driven (supervised) learning cannot exert its full
power on this task. We first discuss an innovative heuristic of cross-dataset
training and evaluation, enabling the use of multiple single-task datasets (one
with target task labels and the other with privacy labels) in our problem. To
further address this dataset challenge, we have constructed a new dataset,
termed PA-HMDB51, with both target task labels (action) and selected privacy
attributes (skin color, face, gender, nudity, and relationship) annotated on a
per-frame basis. This first-of-its-kind video dataset and evaluation protocol
can greatly facilitate visual privacy research and open up other opportunities.
Our codes, models, and the PA-HMDB51 dataset are available at
https://github.com/VITA-Group/PA-HMDB51.
</p>
<a href="http://arxiv.org/abs/1906.05675" target="_blank">arXiv:1906.05675</a> [<a href="http://arxiv.org/pdf/1906.05675" target="_blank">pdf</a>]

<h2>Min-max Entropy for Weakly Supervised Pointwise Localization. (arXiv:1907.12934v5 [cs.CV] UPDATED)</h2>
<h3>Soufiane Belharbi, J&#xe9;r&#xf4;me Rony, Jose Dolz, Ismail Ben Ayed, Luke McCaffrey, Eric Granger</h3>
<p>Pointwise localization allows more precise localization and accurate
interpretability, compared to bounding box, in applications where objects are
highly unstructured such as in medical domain. In this work, we focus on weakly
supervised localization (WSL) where a model is trained to classify an image and
localize regions of interest at pixel-level using only global image annotation.
Typical convolutional attentions maps are prune to high false positive regions.
To alleviate this issue, we propose a new deep learning method for WSL,
composed of a localizer and a classifier, where the localizer is constrained to
determine relevant and irrelevant regions using conditional entropy (CE) with
the aim to reduce false positive regions. Experimental results on a public
medical dataset and two natural datasets, using Dice index, show that, compared
to state of the art WSL methods, our proposal can provide significant
improvements in terms of image-level classification and pixel-level
localization (low false positive) with robustness to overfitting. A public
reproducible PyTorch implementation is provided in:
https://github.com/sbelharbi/wsol-min-max-entropy-interpretability .
</p>
<a href="http://arxiv.org/abs/1907.12934" target="_blank">arXiv:1907.12934</a> [<a href="http://arxiv.org/pdf/1907.12934" target="_blank">pdf</a>]

<h2>Where are the Keys? -- Learning Object-Centric Navigation Policies on Semantic Maps with Graph Convolutional Networks. (arXiv:1909.07376v2 [cs.LG] UPDATED)</h2>
<h3>Niko S&#xfc;nderhauf</h3>
<p>Emerging object-based SLAM algorithms can build a graph representation of an
environment comprising nodes for robot poses and object landmarks. However,
while this map will contain static objects such as furniture or appliances,
many moveable objects (e.g. the car keys, the glasses, or a magazine), are not
suitable as landmarks and will not be part of the map due to their non-static
nature. We show that Graph Convolutional Networks can learn navigation policies
to find such unmapped objects by learning to exploit the hidden probabilistic
model that governs where these objects appear in the environment. The learned
policies can generalise to object classes unseen during training by using word
vectors that express semantic similarity as representations for object nodes in
the graph. Furthermore, we show that the policies generalise to unseen
environments with only minimal loss of performance. We demonstrate that
pre-training the policy network with a proxy task can significantly speed up
learning, improving sample efficiency.
</p>
<a href="http://arxiv.org/abs/1909.07376" target="_blank">arXiv:1909.07376</a> [<a href="http://arxiv.org/pdf/1909.07376" target="_blank">pdf</a>]

<h2>Knowledge Distillation for Incremental Learning in Semantic Segmentation. (arXiv:1911.03462v4 [cs.CV] UPDATED)</h2>
<h3>Umberto Michieli, Pietro Zanuttigh</h3>
<p>Deep learning architectures have shown remarkable results in scene
understanding problems, however they exhibit a critical drop of performances
when they are required to learn incrementally new tasks without forgetting old
ones. This catastrophic forgetting phenomenon impacts on the deployment of
artificial intelligence in real world scenarios where systems need to learn new
and different representations over time. Current approaches for incremental
learning deal only with image classification and object detection tasks, while
in this work we formally introduce incremental learning for semantic
segmentation. We tackle the problem applying various knowledge distillation
techniques on the previous model. In this way, we retain the information about
learned classes, whilst updating the current model to learn the new ones. We
developed four main methodologies of knowledge distillation working on both
output layers and internal feature representations. We do not store any image
belonging to previous training stages and only the last model is used to
preserve high accuracy on previously learned classes. Extensive experimental
results on the Pascal VOC2012 and MSRC-v2 datasets show the effectiveness of
the proposed approaches in several incremental learning scenarios.
</p>
<a href="http://arxiv.org/abs/1911.03462" target="_blank">arXiv:1911.03462</a> [<a href="http://arxiv.org/pdf/1911.03462" target="_blank">pdf</a>]

<h2>Curriculum Self-Paced Learning for Cross-Domain Object Detection. (arXiv:1911.06849v4 [cs.CV] UPDATED)</h2>
<h3>Petru Soviany, Radu Tudor Ionescu, Paolo Rota, Nicu Sebe</h3>
<p>Training (source) domain bias affects state-of-the-art object detectors, such
as Faster R-CNN, when applied to new (target) domains. To alleviate this
problem, researchers proposed various domain adaptation methods to improve
object detection results in the cross-domain setting, e.g. by translating
images with ground-truth labels from the source domain to the target domain
using Cycle-GAN. On top of combining Cycle-GAN transformations and self-paced
learning in a smart and efficient way, in this paper, we propose a novel
self-paced algorithm that learns from easy to hard. Our method is simple and
effective, without any overhead during inference. It uses only pseudo-labels
for samples taken from the target domain, i.e. the domain adaptation is
unsupervised. We conduct experiments on four cross-domain benchmarks, showing
better results than the state of the art. We also perform an ablation study
demonstrating the utility of each component in our framework. Additionally, we
study the applicability of our framework to other object detectors.
Furthermore, we compare our difficulty measure with other measures from the
related literature, proving that it yields superior results and that it
correlates well with the performance metric.
</p>
<a href="http://arxiv.org/abs/1911.06849" target="_blank">arXiv:1911.06849</a> [<a href="http://arxiv.org/pdf/1911.06849" target="_blank">pdf</a>]

<h2>ShadingNet: Image Intrinsics by Fine-Grained Shading Decomposition. (arXiv:1912.04023v3 [cs.CV] UPDATED)</h2>
<h3>Anil S. Baslamisli, Partha Das, Hoang-An Le, Sezer Karaoglu, Theo Gevers</h3>
<p>In general, intrinsic image decomposition algorithms interpret shading as one
unified component including all photometric effects. As shading transitions are
generally smoother than reflectance (albedo) changes, these methods may fail in
distinguishing strong photometric effects from reflectance variations.
Therefore, in this paper, we propose to decompose the shading component into
direct (illumination) and indirect shading (ambient light and shadows)
subcomponents. The aim is to distinguish strong photometric effects from
reflectance variations. An end-to-end deep convolutional neural network
(ShadingNet) is proposed that operates in a fine-to-coarse manner with a
specialized fusion and refinement unit exploiting the fine-grained shading
model. It is designed to learn specific reflectance cues separated from
specific photometric effects to analyze the disentanglement capability. A
large-scale dataset of scene-level synthetic images of outdoor natural
environments is provided with fine-grained intrinsic image ground-truths. Large
scale experiments show that our approach using fine-grained shading
decompositions outperforms state-of-the-art algorithms utilizing unified
shading on NED, MPI Sintel, GTA V, IIW, MIT Intrinsic Images, 3DRMS and SRD
datasets.
</p>
<a href="http://arxiv.org/abs/1912.04023" target="_blank">arXiv:1912.04023</a> [<a href="http://arxiv.org/pdf/1912.04023" target="_blank">pdf</a>]

<h2>Copy Move Source-Target Disambiguation through Multi-Branch CNNs. (arXiv:1912.12640v2 [cs.CV] UPDATED)</h2>
<h3>Mauro Barni, Quoc-Tin Phan, Benedetta Tondi</h3>
<p>We propose a method to identify the source and target regions of a copy-move
forgery so allow a correct localisation of the tampered area. First, we cast
the problem into a hypothesis testing framework whose goal is to decide which
region between the two nearly-duplicate regions detected by a generic copy-move
detector is the original one. Then we design a multi-branch CNN architecture
that solves the hypothesis testing problem by learning a set of features
capable to reveal the presence of interpolation artefacts and boundary
inconsistencies in the copy-moved area. The proposed architecture, trained on a
synthetic dataset explicitly built for this purpose, achieves good results on
copy-move forgeries from both synthetic and realistic datasets. Based on our
tests, the proposed disambiguation method can reliably reveal the target region
even in realistic cases where an approximate version of the copy-move
localization mask is provided by a state-of-the-art copy-move detection
algorithm.
</p>
<a href="http://arxiv.org/abs/1912.12640" target="_blank">arXiv:1912.12640</a> [<a href="http://arxiv.org/pdf/1912.12640" target="_blank">pdf</a>]

<h2>DeepURL: Deep Pose Estimation Framework for Underwater Relative Localization. (arXiv:2003.05523v4 [cs.RO] UPDATED)</h2>
<h3>Bharat Joshi, Md Modasshir, Travis Manderson, Hunter Damron, Marios Xanthidis, Alberto Quattrini Li, Ioannis Rekleitis, Gregory Dudek</h3>
<p>In this paper, we propose a real-time deep learning approach for determining
the 6D relative pose of Autonomous Underwater Vehicles (AUV) from a single
image. A team of autonomous robots localizing themselves in a
communication-constrained underwater environment is essential for many
applications such as underwater exploration, mapping, multi-robot convoying,
and other multi-robot tasks. Due to the profound difficulty of collecting
ground truth images with accurate 6D poses underwater, this work utilizes
rendered images from the Unreal Game Engine simulation for training. An
image-to-image translation network is employed to bridge the gap between the
rendered and the real images producing synthetic images for training. The
proposed method predicts the 6D pose of an AUV from a single image as 2D image
keypoints representing 8 corners of the 3D model of the AUV, and then the 6D
pose in the camera coordinates is determined using RANSAC-based PnP.
Experimental results in real-world underwater environments (swimming pool and
ocean) with different cameras demonstrate the robustness and accuracy of the
proposed technique in terms of translation error and orientation error over the
state-of-the-art methods. The code is publicly available.
</p>
<a href="http://arxiv.org/abs/2003.05523" target="_blank">arXiv:2003.05523</a> [<a href="http://arxiv.org/pdf/2003.05523" target="_blank">pdf</a>]

<h2>Online Fast Adaptation and Knowledge Accumulation: a New Approach to Continual Learning. (arXiv:2003.05856v3 [cs.AI] UPDATED)</h2>
<h3>Massimo Caccia, Pau Rodriguez, Oleksiy Ostapenko, Fabrice Normandin, Min Lin, Lucas Caccia, Issam Laradji, Irina Rish, Alexandre Lacoste, David Vazquez, Laurent Charlin</h3>
<p>Continual learning studies agents that learn from streams of tasks without
forgetting previous ones while adapting to new ones. Two recent
continual-learning scenarios have opened new avenues of research. In
meta-continual learning, the model is pre-trained to minimize catastrophic
forgetting of previous tasks. In continual-meta learning, the aim is to train
agents for faster remembering of previous tasks through adaptation. In their
original formulations, both methods have limitations. We stand on their
shoulders to propose a more general scenario, OSAKA, where an agent must
quickly solve new (out-of-distribution) tasks, while also requiring fast
remembering. We show that current continual learning, meta-learning,
meta-continual learning, and continual-meta learning techniques fail in this
new scenario. We propose Continual-MAML, an online extension of the popular
MAML algorithm as a strong baseline for this scenario. We empirically show that
Continual-MAML is better suited to the new scenario than the aforementioned
methodologies, as well as standard continual learning and meta-learning
approaches.
</p>
<a href="http://arxiv.org/abs/2003.05856" target="_blank">arXiv:2003.05856</a> [<a href="http://arxiv.org/pdf/2003.05856" target="_blank">pdf</a>]

<h2>Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations. (arXiv:2003.08938v6 [cs.LG] UPDATED)</h2>
<h3>Huan Zhang, Hongge Chen, Chaowei Xiao, Bo Li, Mingyan Liu, Duane Boning, Cho-Jui Hsieh</h3>
<p>A deep reinforcement learning (DRL) agent observes its states through
observations, which may contain natural measurement errors or adversarial
noises. Since the observations deviate from the true states, they can mislead
the agent into making suboptimal actions. Several works have shown this
vulnerability via adversarial attacks, but existing approaches on improving the
robustness of DRL under this setting have limited success and lack for
theoretical principles. We show that naively applying existing techniques on
improving robustness for classification tasks, like adversarial training, is
ineffective for many RL tasks. We propose the state-adversarial Markov decision
process (SA-MDP) to study the fundamental properties of this problem, and
develop a theoretically principled policy regularization which can be applied
to a large family of DRL algorithms, including proximal policy optimization
(PPO), deep deterministic policy gradient (DDPG) and deep Q networks (DQN), for
both discrete and continuous action control problems. We significantly improve
the robustness of PPO, DDPG and DQN agents under a suite of strong white box
adversarial attacks, including new attacks of our own. Additionally, we find
that a robust policy noticeably improves DRL performance even without an
adversary in a number of environments. Our code is available at
https://github.com/chenhongge/StateAdvDRL.
</p>
<a href="http://arxiv.org/abs/2003.08938" target="_blank">arXiv:2003.08938</a> [<a href="http://arxiv.org/pdf/2003.08938" target="_blank">pdf</a>]

<h2>Prune2Edge: A Multi-Phase Pruning Pipelines to Deep Ensemble Learning in IIoT. (arXiv:2004.04710v2 [cs.LG] UPDATED)</h2>
<h3>Besher Alhalabi, Mohamed Gaber, Shadi Basurra</h3>
<p>Most recently, with the proliferation of IoT devices, computational nodes in
manufacturing systems IIoT(Industrial-Internet-of-things) and the lunch of 5G
networks, there will be millions of connected devices generating a massive
amount of data. In such an environment, the controlling systems need to be
intelligent enough to deal with a vast amount of data to detect defects in a
real-time process. Driven by such a need, artificial intelligence models such
as deep learning have to be deployed into IIoT systems. However, learning and
using deep learning models are computationally expensive, so an IoT device with
limited computational power could not run such models. To tackle this issue,
edge intelligence had emerged as a new paradigm towards running Artificial
Intelligence models on edge devices. Although a considerable amount of studies
have been proposed in this area, the research is still in the early stages. In
this paper, we propose a novel edge-based multi-phase pruning pipelines to
ensemble learning on IIoT devices. In the first phase, we generate a diverse
ensemble of pruned models, then we apply integer quantisation, next we prune
the generated ensemble using a clustering-based technique. Finally, we choose
the best representative from each generated cluster to be deployed to a
distributed IoT environment. On CIFAR-100 and CIFAR-10, our proposed approach
was able to outperform the predictability levels of a baseline model (up to
7%), more importantly, the generated learners have small sizes (up to 90%
reduction in the model size) that minimise the required computational
capabilities to make an inference on the resource-constraint devices.
</p>
<a href="http://arxiv.org/abs/2004.04710" target="_blank">arXiv:2004.04710</a> [<a href="http://arxiv.org/pdf/2004.04710" target="_blank">pdf</a>]

<h2>On the Bottleneck of Graph Neural Networks and its Practical Implications. (arXiv:2006.05205v2 [cs.LG] UPDATED)</h2>
<h3>Uri Alon, Eran Yahav</h3>
<p>Since the proposal of the graph neural network (GNN) by Gori et al. (2005)
and Scarselli et al. (2008), one of the major problems in training GNNs was
their struggle to propagate information between distant nodes in the graph. We
propose a new explanation for this problem: GNNs are susceptible to a
bottleneck when aggregating messages across a long path. This bottleneck causes
the over-squashing of exponentially growing information into fixed-size
vectors. As a result, GNNs fail to propagate messages originating from distant
nodes and perform poorly when the prediction task depends on long-range
interaction. In this paper, we highlight the inherent problem of over-squashing
in GNNs. We demonstrate that the bottleneck hinders popular GNNs from fitting
long-range signals in the training data. We further show that GNNs that absorb
incoming edges equally, such as GCN and GIN, are more susceptible to
over-squashing than GAT and GGNN. Finally, we show that prior work, which
extensively tuned GNN models of long-range problems, suffer from
over-squashing, and that breaking the bottleneck improves their
state-of-the-art results without any tuning or additional weights. Our code is
available at https://github.com/tech-srl/bottleneck/ .
</p>
<a href="http://arxiv.org/abs/2006.05205" target="_blank">arXiv:2006.05205</a> [<a href="http://arxiv.org/pdf/2006.05205" target="_blank">pdf</a>]

<h2>Locally Private Graph Neural Networks. (arXiv:2006.05535v6 [cs.LG] UPDATED)</h2>
<h3>Sina Sajadmanesh, Daniel Gatica-Perez</h3>
<p>Graph Neural Networks (GNNs) have demonstrated superior performance in
learning node representations for various graph inference tasks. However,
learning over graph data can raise privacy concerns when nodes represent people
or human-related variables that involve sensitive or personal information.
While numerous techniques have been proposed for privacy-preserving deep
learning over non-relational data, such as image, audio, video, and text, there
is less work addressing the privacy issues pertained to applying deep learning
algorithms on graphs. As a result and for the first time, in this paper, we
study the problem of node-level privacy, where graph nodes have potentially
sensitive features that need to be kept private, but they could be beneficial
for a central server for training a GNN over the graph. To address this
problem, we develop a privacy-preserving GNN learning algorithm with formal
privacy guarantees based on Local Differential Privacy (LDP). Specifically, we
propose an optimized LDP encoder and an unbiased rectifier, using which the
server can communicate with the graph nodes to privately collect their data and
approximate the graph convolution layer of the GNN. To further reduce the
effect of the injected noise, we propose a simple graph convolution layer based
on the multi-hop aggregation of the nodes' features. We argue why LDP is a
better choice to tackle this problem compared to other privacy-preserving
learning paradigms, such as federated learning, and discuss how GNNs, due to
their unique internal structure, can be more robust to differentially private
input perturbations than other deep learning models. Extensive experiments
conducted over real-world datasets demonstrate the significant capability of
our method in maintaining an appropriate privacy-accuracy trade-off.
</p>
<a href="http://arxiv.org/abs/2006.05535" target="_blank">arXiv:2006.05535</a> [<a href="http://arxiv.org/pdf/2006.05535" target="_blank">pdf</a>]

<h2>Interpretable, similarity-driven multi-view embeddings from high-dimensional biomedical data. (arXiv:2006.06545v3 [stat.ML] UPDATED)</h2>
<h3>Brian B. Avants, Nicholas J. Tustison, James R. Stone</h3>
<p>Similarity-driven multi-view linear reconstruction (SiMLR) is an algorithm
that exploits inter-modality relationships to transform large scientific
datasets into smaller, more well-powered and interpretable low-dimensional
spaces. SiMLR contributes a novel objective function for identifying joint
signal, regularization based on sparse matrices representing prior
within-modality relationships and an implementation that permits application to
joint reduction of large data matrices, each of which may have millions of
entries. We demonstrate that SiMLR outperforms closely related methods on
supervised learning problems in simulation data, a multi-omics cancer survival
prediction dataset and multiple modality neuroimaging datasets. Taken together,
this collection of results shows that SiMLR may be applied with default
parameters to joint signal estimation from disparate modalities and may yield
practically useful results in a variety of application domains.
</p>
<a href="http://arxiv.org/abs/2006.06545" target="_blank">arXiv:2006.06545</a> [<a href="http://arxiv.org/pdf/2006.06545" target="_blank">pdf</a>]

<h2>Grounding Language to Autonomously-Acquired Skills via Goal Generation. (arXiv:2006.07185v2 [cs.AI] UPDATED)</h2>
<h3>Ahmed Akakzia, C&#xe9;dric Colas, Pierre-Yves Oudeyer, Mohamed Chetouani, Olivier Sigaud</h3>
<p>We are interested in the autonomous acquisition of repertoires of skills.
Language-conditioned reinforcement learning (LC-RL) approaches are great tools
in this quest, as they allow to express abstract goals as sets of constraints
on the states. However, most LC-RL agents are not autonomous and cannot learn
without external instructions and feedback. Besides, their direct language
condition cannot account for the goal-directed behavior of pre-verbal infants
and strongly limits the expression of behavioral diversity for a given language
input. To resolve these issues, we propose a new conceptual approach to
language-conditioned RL: the Language-Goal-Behavior architecture (LGB). LGB
decouples skill learning and language grounding via an intermediate semantic
representation of the world. To showcase the properties of LGB, we present a
specific implementation called DECSTR. DECSTR is an intrinsically motivated
learning agent endowed with an innate semantic representation describing
spatial relations between physical objects. In a first stage (G -&gt; B), it
freely explores its environment and targets self-generated semantic
configurations. In a second stage (L -&gt; G), it trains a language-conditioned
goal generator to generate semantic goals that match the constraints expressed
in language-based inputs. We showcase the additional properties of LGB w.r.t.
both an end-to-end LC-RL approach and a similar approach leveraging
non-semantic, continuous intermediate representations. Intermediate semantic
representations help satisfy language commands in a diversity of ways, enable
strategy switching after a failure and facilitate language grounding.
</p>
<a href="http://arxiv.org/abs/2006.07185" target="_blank">arXiv:2006.07185</a> [<a href="http://arxiv.org/pdf/2006.07185" target="_blank">pdf</a>]

<h2>Hausdorff Dimension, Heavy Tails, and Generalization in Neural Networks. (arXiv:2006.09313v2 [stat.ML] UPDATED)</h2>
<h3>Umut &#x15e;im&#x15f;ekli, Ozan Sener, George Deligiannidis, Murat A. Erdogdu</h3>
<p>Despite its success in a wide range of applications, characterizing the
generalization properties of stochastic gradient descent (SGD) in non-convex
deep learning problems is still an important challenge. While modeling the
trajectories of SGD via stochastic differential equations (SDE) under
heavy-tailed gradient noise has recently shed light over several peculiar
characteristics of SGD, a rigorous treatment of the generalization properties
of such SDEs in a learning theoretical framework is still missing. Aiming to
bridge this gap, in this paper, we prove generalization bounds for SGD under
the assumption that its trajectories can be well-approximated by a \emph{Feller
process}, which defines a rich class of Markov processes that include several
recent SDE representations (both Brownian or heavy-tailed) as its special case.
We show that the generalization error can be controlled by the \emph{Hausdorff
dimension} of the trajectories, which is intimately linked to the tail behavior
of the driving process. Our results imply that heavier-tailed processes should
achieve better generalization; hence, the tail-index of the process can be used
as a notion of "capacity metric". We support our theory with experiments on
deep neural networks illustrating that the proposed capacity metric accurately
estimates the generalization error, and it does not necessarily grow with the
number of parameters unlike the existing capacity metrics in the literature.
</p>
<a href="http://arxiv.org/abs/2006.09313" target="_blank">arXiv:2006.09313</a> [<a href="http://arxiv.org/pdf/2006.09313" target="_blank">pdf</a>]

<h2>Categorical Normalizing Flows via Continuous Transformations. (arXiv:2006.09790v3 [cs.LG] UPDATED)</h2>
<h3>Phillip Lippe, Efstratios Gavves</h3>
<p>Despite their popularity, to date, the application of normalizing flows on
categorical data stays limited. The current practice of using dequantization to
map discrete data to a continuous space is inapplicable as categorical data has
no intrinsic order. Instead, categorical data have complex and latent relations
that must be inferred, like the synonymy between words. In this paper, we
investigate \emph{Categorical Normalizing Flows}, that is normalizing flows for
categorical data. By casting the encoding of categorical data in continuous
space as a variational inference problem, we jointly optimize the continuous
representation and the model likelihood. Using a factorized decoder, we
introduce an inductive bias to model any interactions in the normalizing flow.
As a consequence, we do not only simplify the optimization compared to having a
joint decoder, but also make it possible to scale up to a large number of
categories that is currently impossible with discrete normalizing flows. Based
on Categorical Normalizing Flows, we propose GraphCNF a permutation-invariant
generative model on graphs. GraphCNF implements a three step approach modeling
the nodes, edges and adjacency matrix stepwise to increase efficiency. On
molecule generation, GraphCNF outperforms both one-shot and autoregressive
flow-based state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2006.09790" target="_blank">arXiv:2006.09790</a> [<a href="http://arxiv.org/pdf/2006.09790" target="_blank">pdf</a>]

<h2>Lookahead Adversarial Learning for Near Real-Time Semantic Segmentation. (arXiv:2006.11227v3 [cs.CV] UPDATED)</h2>
<h3>Hadi Jamali-Rad, Attila Szabo</h3>
<p>Semantic segmentation is one of the most fundamental problems in computer
vision with significant impact on a wide variety of applications. Adversarial
learning is shown to be an effective approach for improving semantic
segmentation quality by enforcing higher-level pixel correlations and
structural information. However, state-of-the-art semantic segmentation models
cannot be easily plugged into an adversarial setting because they are not
designed to accommodate convergence and stability issues in adversarial
networks. We bridge this gap by building a conditional adversarial network with
a state-of-the-art segmentation model (DeepLabv3+) at its core. To battle the
stability issues, we introduce a novel lookahead adversarial learning (LoAd)
approach with an embedded label map aggregation module. We focus on semantic
segmentation models that run fast at inference for near real-time field
applications. Through extensive experimentation, we demonstrate that the
proposed solution can alleviate divergence issues in an adversarial semantic
segmentation setting and results in considerable performance improvements (+5%
in some classes) on the baseline for three standard datasets.
</p>
<a href="http://arxiv.org/abs/2006.11227" target="_blank">arXiv:2006.11227</a> [<a href="http://arxiv.org/pdf/2006.11227" target="_blank">pdf</a>]

<h2>Safe Reinforcement Learning via Curriculum Induction. (arXiv:2006.12136v2 [cs.LG] UPDATED)</h2>
<h3>Matteo Turchetta, Andrey Kolobov, Shital Shah, Andreas Krause, Alekh Agarwal</h3>
<p>In safety-critical applications, autonomous agents may need to learn in an
environment where mistakes can be very costly. In such settings, the agent
needs to behave safely not only after but also while learning. To achieve this,
existing safe reinforcement learning methods make an agent rely on priors that
let it avoid dangerous situations during exploration with high probability, but
both the probabilistic guarantees and the smoothness assumptions inherent in
the priors are not viable in many scenarios of interest such as autonomous
driving. This paper presents an alternative approach inspired by human
teaching, where an agent learns under the supervision of an automatic
instructor that saves the agent from violating constraints during learning. In
this model, we introduce the monitor that neither needs to know how to do well
at the task the agent is learning nor needs to know how the environment works.
Instead, it has a library of reset controllers that it activates when the agent
starts behaving dangerously, preventing it from doing damage. Crucially, the
choices of which reset controller to apply in which situation affect the speed
of agent learning. Based on observing agents' progress, the teacher itself
learns a policy for choosing the reset controllers, a curriculum, to optimize
the agent's final policy reward. Our experiments use this framework in two
environments to induce curricula for safe and efficient learning.
</p>
<a href="http://arxiv.org/abs/2006.12136" target="_blank">arXiv:2006.12136</a> [<a href="http://arxiv.org/pdf/2006.12136" target="_blank">pdf</a>]

<h2>Fairness Through Robustness: Investigating Robustness Disparity in Deep Learning. (arXiv:2006.12621v4 [cs.LG] UPDATED)</h2>
<h3>Vedant Nanda, Samuel Dooley, Sahil Singla, Soheil Feizi, John P. Dickerson</h3>
<p>Deep neural networks (DNNs) are increasingly used in real-world applications
(e.g. facial recognition). This has resulted in concerns about the fairness of
decisions made by these models. Various notions and measures of fairness have
been proposed to ensure that a decision-making system does not
disproportionately harm (or benefit) particular subgroups of the population. In
this paper, we argue that traditional notions of fairness that are only based
on models' outputs are not sufficient when the model is vulnerable to
adversarial attacks. We argue that in some cases, it may be easier for an
attacker to target a particular subgroup, resulting in a form of
\textit{robustness bias}. We show that measuring robustness bias is a
challenging task for DNNs and propose two methods to measure this form of bias.
We then conduct an empirical study on state-of-the-art neural networks on
commonly used real-world datasets such as CIFAR-10, CIFAR-100, Adience, and
UTKFace and show that in almost all cases there are subgroups (in some cases
based on sensitive attributes like race, gender, etc) which are less robust and
are thus at a disadvantage. We argue that this kind of bias arises due to both
the data distribution and the highly complex nature of the learned decision
boundary in the case of DNNs, thus making mitigation of such biases a
non-trivial task. Our results show that robustness bias is an important
criterion to consider while auditing real-world systems that rely on DNNs for
decision making. Code to reproduce all our results can be found here:
\url{https://github.com/nvedant07/Fairness-Through-Robustness}
</p>
<a href="http://arxiv.org/abs/2006.12621" target="_blank">arXiv:2006.12621</a> [<a href="http://arxiv.org/pdf/2006.12621" target="_blank">pdf</a>]

<h2>A Comparative Study of Gamma Markov Chains for Temporal Non-Negative Matrix Factorization. (arXiv:2006.12843v3 [stat.ML] UPDATED)</h2>
<h3>Louis Filstroff, Olivier Gouvert, C&#xe9;dric F&#xe9;votte, Olivier Capp&#xe9;</h3>
<p>Non-negative matrix factorization (NMF) has become a well-established class
of methods for the analysis of non-negative data. In particular, a lot of
effort has been devoted to probabilistic NMF, namely estimation or inference
tasks in probabilistic models describing the data, based for example on Poisson
or exponential likelihoods. When dealing with time series data, several works
have proposed to model the evolution of the activation coefficients as a
non-negative Markov chain, most of the time in relation with the Gamma
distribution, giving rise to so-called temporal NMF models. In this paper, we
review four Gamma Markov chains of the NMF literature, and show that they all
share the same drawback: the absence of a well-defined stationary distribution.
We then introduce a fifth process, an overlooked model of the time series
literature named BGAR(1), which overcomes this limitation. These temporal NMF
models are then compared in a MAP framework on a prediction task, in the
context of the Poisson likelihood.
</p>
<a href="http://arxiv.org/abs/2006.12843" target="_blank">arXiv:2006.12843</a> [<a href="http://arxiv.org/pdf/2006.12843" target="_blank">pdf</a>]

<h2>The classification for High-dimension low-sample size data. (arXiv:2006.13018v3 [cs.LG] UPDATED)</h2>
<h3>Liran Shen, Meng Joo Er, Qingbo Yin</h3>
<p>Huge amount of applications in various fields, such as gene expression
analysis or computer vision, undergo data sets with high-dimensional
low-sample-size (HDLSS), which has putted forward great challenges for standard
statistical and modern machine learning methods. In this paper, we propose a
novel classification criterion on HDLSS, tolerance similarity, which emphasizes
the maximization of within-class variance on the premise of class separability.
According to this criterion, a novel linear binary classifier is designed,
denoted by No-separated Data Maximum Dispersion classifier (NPDMD). The
objective of NPDMD is to find a projecting direction w in which all of training
samples scatter in as large an interval as possible. NPDMD has several
characteristics compared to the state-of-the-art classification methods. First,
it works well on HDLSS. Second, it combines the sample statistical information
and local structural information (supporting vectors) into the objective
function to find the solution of projecting direction in the whole feature
spaces. Third, it solves the inverse of high dimensional matrix in low
dimensional space. Fourth, it is relatively simple to be implemented based on
Quadratic Programming. Fifth, it is robust to the model specification for
various real applications. The theoretical properties of NPDMD are deduced. We
conduct a series of evaluations on one simulated and six real-world benchmark
data sets, including face classification and mRNA classification. NPDMD
outperforms those widely used approaches in most cases, or at least obtains
comparable results.
</p>
<a href="http://arxiv.org/abs/2006.13018" target="_blank">arXiv:2006.13018</a> [<a href="http://arxiv.org/pdf/2006.13018" target="_blank">pdf</a>]

<h2>Maximizing Cohesion and Separation in Graph Representation Learning: A Distance-aware Negative Sampling Approach. (arXiv:2007.01423v2 [cs.LG] UPDATED)</h2>
<h3>M. Maruf, Anuj Karpatne</h3>
<p>The objective of unsupervised graph representation learning (GRL) is to learn
a low-dimensional space of node embeddings that reflect the structure of a
given unlabeled graph. Existing algorithms for this task rely on negative
sampling objectives that maximize the similarity in node embeddings at nearby
nodes (referred to as "cohesion") by maintaining positive and negative corpus
of node pairs. While positive samples are drawn from node pairs that co-occur
in short random walks, conventional approaches construct negative corpus by
uniformly sampling random pairs, thus ignoring valuable information about
structural dissimilarity among distant node pairs (referred to as
"separation"). In this paper, we present a novel Distance-aware Negative
Sampling (DNS) which maximizes the separation of distant node-pairs while
maximizing cohesion at nearby node-pairs by setting the negative sampling
probability proportional to the pair-wise shortest distances. Our approach can
be used in conjunction with any GRL algorithm and we demonstrate the efficacy
of our approach over baseline negative sampling methods over downstream node
classification tasks on a number of benchmark datasets and GRL algorithms. All
our codes and datasets are available at
https://github.com/Distance-awareNS/DNS/.
</p>
<a href="http://arxiv.org/abs/2007.01423" target="_blank">arXiv:2007.01423</a> [<a href="http://arxiv.org/pdf/2007.01423" target="_blank">pdf</a>]

<h2>Gradient Origin Networks. (arXiv:2007.02798v4 [cs.CV] UPDATED)</h2>
<h3>Sam Bond-Taylor, Chris G. Willcocks</h3>
<p>This paper proposes a new type of generative model that is able to quickly
learn a latent representation without an encoder. This is achieved using
empirical Bayes to calculate the expectation of the posterior, which is
implemented by initialising a latent vector with zeros, then using the gradient
of the log-likelihood of the data with respect to this zero vector as new
latent points. The approach has similar characteristics to autoencoders, but
with a simpler architecture, and is demonstrated in a variational autoencoder
equivalent that permits sampling. This also allows implicit representation
networks to learn a space of implicit functions without requiring a
hypernetwork, retaining their representation advantages across datasets. The
experiments show that the proposed method converges faster, with significantly
lower reconstruction error than autoencoders, while requiring half the
parameters.
</p>
<a href="http://arxiv.org/abs/2007.02798" target="_blank">arXiv:2007.02798</a> [<a href="http://arxiv.org/pdf/2007.02798" target="_blank">pdf</a>]

<h2>IGANI: Iterative Generative Adversarial Networks for Imputation Applied to Prediction of Traffic Data. (arXiv:2008.04847v2 [stat.ML] UPDATED)</h2>
<h3>Amir Kazemi, Hadi Meidani</h3>
<p>Increasing use of sensor data in intelligent transportation systems calls for
accurate imputation algorithms that can enable reliable traffic management in
the occasional absence of data. As one of the effective imputation approaches,
generative adversarial networks (GANs) are implicit generative models that can
be used for data imputation, which is formulated as an unsupervised learning
problem. This work introduces a novel iterative GAN architecture, called
Iterative Generative Adversarial Networks for Imputation (IGANI), for data
imputation. IGANI imputes data in two steps and maintains the invertibility of
the generative imputer, which will be shown to be a sufficient condition for
the convergence of the proposed GAN-based imputation. The performance of our
proposed method is evaluated on (1) the imputation of traffic speed data
collected in the city of Guangzhou in China, and (2) the training of short-term
traffic prediction models using imputed data. It is shown that our proposed
algorithm mostly produces more accurate results compared to those of previous
GAN-based imputation architectures.
</p>
<a href="http://arxiv.org/abs/2008.04847" target="_blank">arXiv:2008.04847</a> [<a href="http://arxiv.org/pdf/2008.04847" target="_blank">pdf</a>]

<h2>Indoor environment data time-series reconstruction using autoencoder neural networks. (arXiv:2009.08155v2 [stat.ML] UPDATED)</h2>
<h3>Antonio Liguori, Romana Markovic, Thi Thu Ha Dam, J&#xe9;r&#xf4;me Frisch, Christoph van Treeck, Francesco Causone</h3>
<p>As the number of installed meters in buildings increases, there is a growing
number of data time-series that could be used to develop data-driven models to
support and optimize building operation. However, building data sets are often
characterized by errors and missing values, which are considered, by the recent
research, among the main limiting factors on the performance of the proposed
models. Motivated by the need to address the problem of missing data in
building operation, this work presents a data-driven approach to fill these
gaps. In this study, three different autoencoder neural networks are trained to
reconstruct missing short-term indoor environment data time-series in a data
set collected in an office building in Aachen, Germany. This consisted of a
four year-long monitoring campaign in and between the years 2014 and 2017, of
84 different rooms. The models are applicable for different time-series
obtained from room automation, such as indoor air temperature, relative
humidity and $CO_{2}$ data streams. The results prove that the proposed methods
outperform classic numerical approaches and they result in reconstructing the
corresponding variables with average RMSEs of 0.42 {\deg}C, 1.30 % and 78.41
ppm, respectively.
</p>
<a href="http://arxiv.org/abs/2009.08155" target="_blank">arXiv:2009.08155</a> [<a href="http://arxiv.org/pdf/2009.08155" target="_blank">pdf</a>]

<h2>BNAS-v2: Memory-efficient and Performance-collapse-prevented Broad Neural Architecture Search. (arXiv:2009.08886v3 [cs.CV] UPDATED)</h2>
<h3>Zixiang Ding, Yaran Chen, Nannan Li, Dongbin Zhao</h3>
<p>In this paper, we propose BNAS-v2 to further improve the efficiency of NAS,
embodying both superiorities of BCNN simultaneously. To mitigate the unfair
training issue in BNAS, we employ continuous relaxation strategy to make each
edge of cell in BCNN relevant to all candidate operations, so that the
gradient-based optimization algorithm of BNAS-v2 can update every possible path
simultaneously rather than the single sampled one in BNAS. Moreover, the
continuous relaxation strategy relaxes the choice of a candidate operation as a
softmax over all predefined operations. However, continuous relaxation leads to
another issue named performance collapse, where those weight-free operations
are prone to be selected by the search strategy. For this consequent issue, two
solutions are given: 1) we propose Confident Learning Rate (CLR) that considers
the confidence of gradient for architecture weights update, increasing with the
training time of over-parameterized BCNN; 2) we introduce the combination of
partial channel connections and edge normalization that also can improve the
memory efficiency further. Moreover, we denote differentiable BNAS (i.e. BNAS
with continuous relaxation) as BNAS-D, BNAS-D with CLR as BNAS-v2-CLR, and
partial-connected BNAS-D as BNAS-v2-PC. Experimental results on CIFAR-10 and
ImageNet show that 1) BNAS-v2 delivers state-of-the-art search efficiency on
both CIFAR-10 (0.05 GPU days that is 4x faster than BNAS) and ImageNet (0.19
GPU days); and 2) the proposed CLR is effective to alleviate the performance
collapse issue in both BNAS-D and vanilla differentiable NAS framework.
</p>
<a href="http://arxiv.org/abs/2009.08886" target="_blank">arXiv:2009.08886</a> [<a href="http://arxiv.org/pdf/2009.08886" target="_blank">pdf</a>]

<h2>Solution Concepts in Hierarchical Games under Bounded Rationality with Applications to Autonomous Driving. (arXiv:2009.10033v4 [cs.AI] UPDATED)</h2>
<h3>Atrisha Sarkar, Krzysztof Czarnecki</h3>
<p>With autonomous vehicles (AV) set to integrate further into regular human
traffic, there is an increasing consensus of treating AV motion planning as a
multi-agent problem. However, the traditional game theoretic assumption of
complete rationality is too strong for the purpose of human driving, and there
is a need for understanding human driving as a \emph{bounded rational} activity
through a behavioral game theoretic lens. To that end, we adapt three
metamodels of bounded rational behavior; two based on Quantal level-k and one
based on Nash equilibrium with quantal errors. We formalize the different
solution concepts that can be applied in the context of hierarchical games, a
framework used in multi-agent motion planning, for the purpose of creating game
theoretic models of driving behavior. Furthermore, based on a contributed
dataset of human driving at a busy urban intersection with a total of ~4k
agents and ~44k decision points, we evaluate the behavior models on the basis
of model fit to naturalistic data, as well as their predictive capacity. Our
results suggest that among the behavior models evaluated, modeling driving
behavior as pure strategy NE with quantal errors at the level of maneuvers with
bounds sampling of actions at the level of trajectories provides the best fit
to naturalistic driving behavior, and there is a significant impact of
situational factors on the performance of behavior models.
</p>
<a href="http://arxiv.org/abs/2009.10033" target="_blank">arXiv:2009.10033</a> [<a href="http://arxiv.org/pdf/2009.10033" target="_blank">pdf</a>]

<h2>Disentangled Generative Causal Representation Learning. (arXiv:2010.02637v2 [cs.LG] UPDATED)</h2>
<h3>Xinwei Shen, Furui Liu, Hanze Dong, Qing Lian, Zhitang Chen, Tong Zhang</h3>
<p>This paper proposes a Disentangled gEnerative cAusal Representation (DEAR)
learning method. Unlike existing disentanglement methods that enforce
independence of the latent variables, we consider the general case where the
underlying factors of interests can be causally correlated. We show that
previous methods with independent priors fail to disentangle causally
correlated factors. Motivated by this finding, we propose a new disentangled
learning method called DEAR that enables causal controllable generation and
causal representation learning. The key ingredient of this new formulation is
to use a structural causal model (SCM) as the prior for a bidirectional
generative model. The prior is then trained jointly with a generator and an
encoder using a suitable GAN loss incorporated with supervision. We provide
theoretical justification on the identifiability and asymptotic consistency of
the proposed method, which guarantees disentangled causal representation
learning under appropriate conditions. We conduct extensive experiments on both
synthesized and real data sets to demonstrate the effectiveness of DEAR in
causal controllable generation, and the benefits of the learned representations
for downstream tasks in terms of sample efficiency and distributional
robustness.
</p>
<a href="http://arxiv.org/abs/2010.02637" target="_blank">arXiv:2010.02637</a> [<a href="http://arxiv.org/pdf/2010.02637" target="_blank">pdf</a>]

<h2>Gradient Aware Cascade Network for Multi-Focus Image Fusion. (arXiv:2010.08751v2 [cs.CV] UPDATED)</h2>
<h3>Boyuan Ma, Xiang Yin, Di Wu, Xiaojuan Ban, Haiyou Huang</h3>
<p>The general aim of multi-focus image fusion is to gather focused regions of
different images to generate a unique all-in-focus fused image. Deep learning
based methods become the mainstream of image fusion by virtue of its powerful
feature representation ability. However, most of the existing deep learning
structures failed to balance fusion quality and end-to-end implementation
convenience. End-to-end decoder design often leads to poor performance because
of its non-linear mapping mechanism. On the other hand, generating an
intermediate decision map achieves better quality for the fused image, but
relies on the rectification with empirical post-processing parameter choices.
In this work, to handle the requirements of both output image quality and
comprehensive simplicity of structure implementation, we propose a cascade
network to simultaneously generate decision map and fused result with an
end-to-end training procedure. It avoids the dependence on empirical
post-processing methods in the inference stage. To improve the fusion quality,
we introduce a gradient aware loss function to preserve gradient information in
output fused image. In addition, we design a decision calibration strategy to
decrease the time consumption in the application of multiple image fusion.
Extensive experiments are conducted to compare with 18 different
state-of-the-art multi-focus image fusion structures with 6 assessment metrics.
The results prove that our designed structure can generally ameliorate the
output fused image quality, while implementation efficiency increases over 30\%
for multiple image fusion.
</p>
<a href="http://arxiv.org/abs/2010.08751" target="_blank">arXiv:2010.08751</a> [<a href="http://arxiv.org/pdf/2010.08751" target="_blank">pdf</a>]

<h2>A Wigner-Eckart Theorem for Group Equivariant Convolution Kernels. (arXiv:2010.10952v4 [cs.LG] UPDATED)</h2>
<h3>Leon Lang, Maurice Weiler</h3>
<p>Group equivariant convolutional networks (GCNNs) endow classical
convolutional networks with additional symmetry priors, which can lead to a
considerably improved performance. Recent advances in the theoretical
description of GCNNs revealed that such models can generally be understood as
performing convolutions with G-steerable kernels, that is, kernels that satisfy
an equivariance constraint themselves. While the G-steerability constraint has
been derived, it has to date only been solved for specific use cases - a
general characterization of G-steerable kernel spaces is still missing. This
work provides such a characterization for the practically relevant case of G
being any compact group. Our investigation is motivated by a striking analogy
between the constraints underlying steerable kernels on the one hand and
spherical tensor operators from quantum mechanics on the other hand. By
generalizing the famous Wigner-Eckart theorem for spherical tensor operators,
we prove that steerable kernel spaces are fully understood and parameterized in
terms of 1) generalized reduced matrix elements, 2) Clebsch-Gordan
coefficients, and 3) harmonic basis functions on homogeneous spaces.
</p>
<a href="http://arxiv.org/abs/2010.10952" target="_blank">arXiv:2010.10952</a> [<a href="http://arxiv.org/pdf/2010.10952" target="_blank">pdf</a>]

<h2>In Search of Robust Measures of Generalization. (arXiv:2010.11924v2 [cs.LG] UPDATED)</h2>
<h3>Gintare Karolina Dziugaite, Alexandre Drouin, Brady Neal, Nitarshan Rajkumar, Ethan Caballero, Linbo Wang, Ioannis Mitliagkas, Daniel M. Roy</h3>
<p>One of the principal scientific challenges in deep learning is explaining
generalization, i.e., why the particular way the community now trains networks
to achieve small training error also leads to small error on held-out data from
the same population. It is widely appreciated that some worst-case theories --
such as those based on the VC dimension of the class of predictors induced by
modern neural network architectures -- are unable to explain empirical
performance. A large volume of work aims to close this gap, primarily by
developing bounds on generalization error, optimization error, and excess risk.
When evaluated empirically, however, most of these bounds are numerically
vacuous. Focusing on generalization bounds, this work addresses the question of
how to evaluate such bounds empirically. Jiang et al. (2020) recently described
a large-scale empirical study aimed at uncovering potential causal
relationships between bounds/measures and generalization. Building on their
study, we highlight where their proposed methods can obscure failures and
successes of generalization measures in explaining generalization. We argue
that generalization measures should instead be evaluated within the framework
of distributional robustness.
</p>
<a href="http://arxiv.org/abs/2010.11924" target="_blank">arXiv:2010.11924</a> [<a href="http://arxiv.org/pdf/2010.11924" target="_blank">pdf</a>]

<h2>Multi-Graph Tensor Networks. (arXiv:2010.13209v4 [cs.LG] UPDATED)</h2>
<h3>Yao Lei Xu, Kriton Konstantinidis, Danilo P. Mandic</h3>
<p>The irregular and multi-modal nature of numerous modern data sources poses
serious challenges for traditional deep learning algorithms. To this end,
recent efforts have generalized existing algorithms to irregular domains
through graphs, with the aim to gain additional insights from data through the
underlying graph topology. At the same time, tensor-based methods have
demonstrated promising results in bypassing the bottlenecks imposed by the
Curse of Dimensionality. In this paper, we introduce a novel Multi-Graph Tensor
Network (MGTN) framework, which exploits both the ability of graphs to handle
irregular data sources and the compression properties of tensor networks in a
deep learning setting. The potential of the proposed framework is demonstrated
through an MGTN based deep Q agent for Foreign Exchange (FOREX) algorithmic
trading. By virtue of the MGTN, a FOREX currency graph is leveraged to impose
an economically meaningful structure on this demanding task, resulting in a
highly superior performance against three competing models and at a drastically
lower complexity.
</p>
<a href="http://arxiv.org/abs/2010.13209" target="_blank">arXiv:2010.13209</a> [<a href="http://arxiv.org/pdf/2010.13209" target="_blank">pdf</a>]

<h2>Virtual Surfaces and Attitude Aware Planning and Behaviours for Negative Obstacle Navigation. (arXiv:2010.16018v2 [cs.RO] UPDATED)</h2>
<h3>Thomas Hines, Kazys Stepanas, Fletcher Talbot, Inkyu Sa, Jake Lewis, Emili Hernandez, Navinda Kottege, Nicolas Hudson</h3>
<p>This paper presents an autonomous navigation system for ground robots
traversing aggressive unstructured terrain through a cohesive arrangement of
mapping, deliberative planning and reactive behaviour modules. All systems are
aware of terrain slope, visibility and vehicle orientation, enabling robots to
recognize, plan and react around unobserved areas and overcome negative
obstacles, slopes, steps, overhangs and narrow passageways. This is one of
pioneer works to explicitly and simultaneously couple mapping, planning and
reactive components in dealing with negative obstacles. The system was deployed
on three heterogeneous ground robots for the DARPA Subterranean Challenge, and
we present results in Urban and Cave environments, along with simulated
scenarios, that demonstrate this approach.
</p>
<a href="http://arxiv.org/abs/2010.16018" target="_blank">arXiv:2010.16018</a> [<a href="http://arxiv.org/pdf/2010.16018" target="_blank">pdf</a>]

<h2>DeepWay: a Deep Learning Waypoint Estimator for Global Path Generation. (arXiv:2010.16322v2 [cs.RO] UPDATED)</h2>
<h3>Vittorio Mazzia, Francesco Salvetti, Diego Aghi, Marcello Chiaberge</h3>
<p>Agriculture 3.0 and 4.0 have gradually introduced service robotics and
automation into several agricultural processes, mostly improving crops quality
and seasonal yield. Row-based crops are the perfect settings to test and deploy
smart machines capable of monitoring and manage the harvest. In this context,
global path generation is essential either for ground or aerial vehicles, and
it is the starting point for every type of mission plan. Nevertheless, little
attention has been currently given to this problem by the research community
and global path generation automation is still far to be solved. In order to
generate a viable path for an autonomous machine, the presented research
proposes a feature learning fully convolutional model capable of estimating
waypoints given an occupancy grid map. In particular, we apply the proposed
data-driven methodology to the specific case of row-based crops with the
general objective to generate a global path able to cover the extension of the
crop completely. Extensive experimentation with a custom made synthetic dataset
and real satellite-derived images of different scenarios have proved the
effectiveness of our methodology and demonstrated the feasibility of an
end-to-end and completely autonomous global path planner.
</p>
<a href="http://arxiv.org/abs/2010.16322" target="_blank">arXiv:2010.16322</a> [<a href="http://arxiv.org/pdf/2010.16322" target="_blank">pdf</a>]

<h2>A Theoretical Computer Science Perspective on Consciousness. (arXiv:2011.09850v3 [cs.AI] UPDATED)</h2>
<h3>Manuel Blum, Lenore Blum</h3>
<p>The quest to understand consciousness, once the purview of philosophers and
theologians, is now actively pursued by scientists of many stripes. This paper
studies consciousness from the perspective of theoretical computer science. It
formalizes the Global Workspace Theory (GWT) originated by cognitive
neuroscientist Bernard Baars and further developed by him, Stanislas Dehaene,
and others. Our major contribution lies in the precise formal definition of a
Conscious Turing Machine (CTM), also called a Conscious AI. We define the CTM
in the spirit of Alan Turing's simple yet powerful definition of a computer,
the Turing Machine (TM). We are not looking for a complex model of the brain
nor of cognition but for a simple model of (the admittedly complex concept of)
consciousness. After formally defining CTM, we give a formal definition of
consciousness in CTM. We then suggest why the CTM has the feeling of
consciousness. The reasonableness of the definitions and explanations can be
judged by how well they agree with commonly accepted intuitive concepts of
human consciousness, the breadth of related concepts that the model explains
easily and naturally, and the extent of its agreement with scientific evidence.
</p>
<a href="http://arxiv.org/abs/2011.09850" target="_blank">arXiv:2011.09850</a> [<a href="http://arxiv.org/pdf/2011.09850" target="_blank">pdf</a>]

<h2>A Convenient Infinite Dimensional Framework for Generative Adversarial Learning. (arXiv:2011.12087v2 [cs.LG] UPDATED)</h2>
<h3>Hayk Asatryan, Hanno Gottschalk, Marieke Lippert, Matthias Rottmann</h3>
<p>In recent years, generative adversarial networks (GANs) have demonstrated
impressive experimental results while there are only a few works that foster
statistical learning theory for GANs. In this work, we propose an infinite
dimensional theoretical framework for generative adversarial learning. Assuming
the class of uniformly bounded $k$-times $\alpha$-H\"older differentiable and
uniformly positive densities, we show that the Rosenblatt transformation
induces an optimal generator, which is realizable in the hypothesis space of
$\alpha$-H\"older differentiable generators. With a consistent definition of
the hypothesis space of discriminators, we further show that in our framework
the Jensen-Shannon divergence between the distribution induced by the generator
from the adversarial learning procedure and the data generating distribution
converges to zero. Under sufficiently strict regularity assumptions on the
density of the data generating process, we also provide rates of convergence
based on concentration and chaining.
</p>
<a href="http://arxiv.org/abs/2011.12087" target="_blank">arXiv:2011.12087</a> [<a href="http://arxiv.org/pdf/2011.12087" target="_blank">pdf</a>]

<h2>Capturing Delayed Feedback in Conversion Rate Prediction via Elapsed-Time Sampling. (arXiv:2012.03245v2 [cs.LG] UPDATED)</h2>
<h3>Jia-Qi Yang, Xiang Li, Shuguang Han, Tao Zhuang, De-Chuan Zhan, Xiaoyi Zeng, Bin Tong</h3>
<p>Conversion rate (CVR) prediction is one of the most critical tasks for
digital display advertising. Commercial systems often require to update models
in an online learning manner to catch up with the evolving data distribution.
However, conversions usually do not happen immediately after a user click. This
may result in inaccurate labeling, which is called delayed feedback problem. In
previous studies, delayed feedback problem is handled either by waiting
positive label for a long period of time, or by consuming the negative sample
on its arrival and then insert a positive duplicate when a conversion happens
later. Indeed, there is a trade-off between waiting for more accurate labels
and utilizing fresh data, which is not considered in existing works. To strike
a balance in this trade-off, we propose Elapsed-Time Sampling Delayed Feedback
Model (ES-DFM), which models the relationship between the observed conversion
distribution and the true conversion distribution. Then we optimize the
expectation of true conversion distribution via importance sampling under the
elapsed-time sampling distribution. We further estimate the importance weight
for each instance, which is used as the weight of loss function in CVR
prediction. To demonstrate the effectiveness of ES-DFM, we conduct extensive
experiments on a public data and a private industrial dataset. Experimental
results confirm that our method consistently outperforms the previous
state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/2012.03245" target="_blank">arXiv:2012.03245</a> [<a href="http://arxiv.org/pdf/2012.03245" target="_blank">pdf</a>]

<h2>Low-Rank Tensor Recovery with Euclidean-Norm-Induced Schatten-p Quasi-Norm Regularization. (arXiv:2012.03436v2 [cs.LG] UPDATED)</h2>
<h3>Jicong Fan, Lijun Ding, Chengrun Yang, Madeleine Udell</h3>
<p>The nuclear norm and Schatten-$p$ quasi-norm of a matrix are popular rank
proxies in low-rank matrix recovery. Unfortunately, computing the nuclear norm
or Schatten-$p$ quasi-norm of a tensor is NP-hard, which is a pity for low-rank
tensor completion (LRTC) and tensor robust principal component analysis
(TRPCA). In this paper, we propose a new class of rank regularizers based on
the Euclidean norms of the CP component vectors of a tensor and show that these
regularizers are monotonic transformations of tensor Schatten-$p$ quasi-norm.
This connection enables us to minimize the Schatten-$p$ quasi-norm in LRTC and
TRPCA implicitly. The methods do not use the singular value decomposition and
hence scale to big tensors. Moreover, the methods are not sensitive to the
choice of initial rank and provide an arbitrarily sharper rank proxy for
low-rank tensor recovery compared to nuclear norm. We provide theoretical
guarantees in terms of recovery error for LRTC and TRPCA, which show relatively
smaller $p$ of Schatten-$p$ quasi-norm leads to tighter error bounds.
Experiments using LRTC and TRPCA on synthetic data and natural images verify
the effectiveness and superiority of our methods compared to baseline methods.
</p>
<a href="http://arxiv.org/abs/2012.03436" target="_blank">arXiv:2012.03436</a> [<a href="http://arxiv.org/pdf/2012.03436" target="_blank">pdf</a>]

<h2>Semi-Supervised Off Policy Reinforcement Learning. (arXiv:2012.04809v3 [cs.LG] UPDATED)</h2>
<h3>Aaron Sonabend-W, Nilanjana Laha, Tianxi Cai, Rajarshi Mukherjee</h3>
<p>Reinforcement learning (RL) has shown great success in estimating sequential
treatment strategies which account for patient heterogeneity. However,
health-outcome information is often not well coded but rather embedded in
clinical notes. Extracting precise outcome information is a resource intensive
task. This translates into only small well-annotated cohorts available. We
propose a semi-supervised learning (SSL) approach that can efficiently leverage
a small sized labeled data $\mathcal{L}$ with true outcome observed, and a
large sized unlabeled data $\mathcal{U}$ with outcome surrogates $\pmb W$. In
particular we propose a theoretically justified SSL approach to Q-learning and
develop a robust and efficient SSL approach to estimating the value function of
the derived optimal STR, defined as the expected counterfactual outcome under
the optimal STR. Generalizing SSL to learning STR brings interesting
challenges. First, the feature distribution for predicting $Y_t$ is unknown in
the $Q$-learning procedure, as it includes unknown $Y_{t-1}$ due to the
sequential nature. Our methods for estimating optimal STR and its associated
value function, carefully adapts to this sequentially missing data structure.
Second, we modify the SSL framework to handle the use of surrogate variables
$\pmb W$ which are predictive of the outcome through the joint law
$\mathbb{P}_{Y,\pmb O,\pmb W}$, but are not part of the conditional
distribution of interest $\mathbb{P}_{Y|\pmb O}$. We provide theoretical
results to understand when and to what degree efficiency can be gained from
$\pmb W$ and $\pmb O$. Our approach is robust to misspecification of the
imputation models. Further, we provide a doubly robust value function estimator
for the derived STR. If either the Q functions or the propensity score
functions are correctly specified, our value function estimators are consistent
for the true value function.
</p>
<a href="http://arxiv.org/abs/2012.04809" target="_blank">arXiv:2012.04809</a> [<a href="http://arxiv.org/pdf/2012.04809" target="_blank">pdf</a>]

<h2>Imitating Interactive Intelligence. (arXiv:2012.05672v2 [cs.LG] UPDATED)</h2>
<h3>Josh Abramson, Arun Ahuja, Iain Barr, Arthur Brussee, Federico Carnevale, Mary Cassin, Rachita Chhaparia, Stephen Clark, Bogdan Damoc, Andrew Dudzik, Petko Georgiev, Aurelia Guy, Tim Harley, Felix Hill, Alden Hung, Zachary Kenton, Jessica Landon, Timothy Lillicrap, Kory Mathewson, So&#x148;a Mokr&#xe1;, Alistair Muldal, Adam Santoro, Nikolay Savinov, Vikrant Varma, Greg Wayne, Duncan Williams, Nathaniel Wong, Chen Yan, Rui Zhu</h3>
<p>A common vision from science fiction is that robots will one day inhabit our
physical spaces, sense the world as we do, assist our physical labours, and
communicate with us through natural language. Here we study how to design
artificial agents that can interact naturally with humans using the
simplification of a virtual environment. This setting nevertheless integrates a
number of the central challenges of artificial intelligence (AI) research:
complex visual perception and goal-directed physical control, grounded language
comprehension and production, and multi-agent social interaction. To build
agents that can robustly interact with humans, we would ideally train them
while they interact with humans. However, this is presently impractical.
Therefore, we approximate the role of the human with another learned agent, and
use ideas from inverse reinforcement learning to reduce the disparities between
human-human and agent-agent interactive behaviour. Rigorously evaluating our
agents poses a great challenge, so we develop a variety of behavioural tests,
including evaluation by humans who watch videos of agents or interact directly
with them. These evaluations convincingly demonstrate that interactive training
and auxiliary losses improve agent behaviour beyond what is achieved by
supervised learning of actions alone. Further, we demonstrate that agent
capabilities generalise beyond literal experiences in the dataset. Finally, we
train evaluation models whose ratings of agents agree well with human
judgement, thus permitting the evaluation of new agent models without
additional effort. Taken together, our results in this virtual environment
provide evidence that large-scale human behavioural imitation is a promising
tool to create intelligent, interactive agents, and the challenge of reliably
evaluating such agents is possible to surmount.
</p>
<a href="http://arxiv.org/abs/2012.05672" target="_blank">arXiv:2012.05672</a> [<a href="http://arxiv.org/pdf/2012.05672" target="_blank">pdf</a>]

<h2>Using vis-NIRS and Machine Learning methods to diagnose sugarcane soil chemical properties. (arXiv:2012.12995v2 [cs.LG] UPDATED)</h2>
<h3>Diego A. Delgadillo-Duran, Cesar A. Vargas-Garc&#xed;a, Viviana M. Var&#xf3;n-Ram&#xed;rez, Francisco Calder&#xf3;n, Andrea C. Montenegro, Paula H. Reyes-Herrera</h3>
<p>Knowing chemical soil properties might be determinant in crop management and
total yield production. Traditional property estimation approaches are
time-consuming and require complex lab setups, refraining farmers from taking
steps towards optimal practices in their crops promptly. Property estimation
from spectral signals(vis-NIRS), emerged as a low-cost, non-invasive, and
non-destructive alternative. Current approaches use mathematical and
statistical techniques, avoiding machine learning framework. Here we propose
both regression and classification with machine learning techniques to assess
performance in the prediction and infer categories of common soil properties
(pH, soil organic matter, Ca, Na, K, and Mg), evaluated by the most common
metrics. In sugarcane soils, we use regression to estimate properties and
classification to assess soil's property status and report the direct relation
between spectra bands and direct measure of certain properties. In both cases,
we achieved similar performance on similar setups reported in the literature.
</p>
<a href="http://arxiv.org/abs/2012.12995" target="_blank">arXiv:2012.12995</a> [<a href="http://arxiv.org/pdf/2012.12995" target="_blank">pdf</a>]

<h2>Divergence Regulated Encoder Network for Joint Dimensionality Reduction and Classification. (arXiv:2012.15764v2 [cs.LG] UPDATED)</h2>
<h3>Joshua Peeples, Sarah Walker, Connor McCurley, Alina Zare, James Keller</h3>
<p>In this paper, we investigate performing joint dimensionality reduction and
classification using a novel histogram neural network. Motivated by a popular
dimensionality reduction approach, t-Distributed Stochastic Neighbor Embedding
(t-SNE), our proposed method incorporates a classification loss computed on
samples in a low-dimensional embedding space. We compare the learned sample
embeddings against coordinates found by t-SNE in terms of classification
accuracy and qualitative assessment. We also explore use of various divergence
measures in the t-SNE objective. The proposed method has several advantages
such as readily embedding out-of-sample points and reducing feature
dimensionality while retaining class discriminability. Our results show that
the proposed approach maintains and/or improves classification performance and
reveals characteristics of features produced by neural networks that may be
helpful for other applications.
</p>
<a href="http://arxiv.org/abs/2012.15764" target="_blank">arXiv:2012.15764</a> [<a href="http://arxiv.org/pdf/2012.15764" target="_blank">pdf</a>]

<h2>Towards Optimally Efficient Tree Search with Deep Temporal Difference Learning. (arXiv:2101.02420v2 [cs.LG] UPDATED)</h2>
<h3>Ke He, Lisheng Fan, George K. Karagiannidis</h3>
<p>This paper investigates the classical integer least-squares problem which
estimates integer signals from linear models. The problem is NP-hard and often
arises in diverse applications such as signal processing, bioinformatics,
communications and machine learning, to name a few. Since the existing optimal
search strategies involve prohibitive complexities, they are hard to be adopted
in large-scale problems. To address this issue, we propose a general
hyper-accelerated tree search (HATS) algorithm by employing a deep neural
network to estimate the optimal heuristic for the underlying simplified
memory-bounded A* algorithm, and the proposed algorithm can be easily
generalized with other heuristic search algorithms. Inspired by the temporal
difference learning, we further propose a training strategy which enables the
network to approach the optimal heuristic precisely and consistently, thus the
proposed algorithm can reach nearly the optimal efficiency when the estimation
error is small enough. Experiments show that the proposed algorithm can reach
almost the optimal maximum likelihood estimate performance in large-scale
problems, with a very low complexity in both time and space. The code of this
paper is avaliable at https://github.com/skypitcher/hats.
</p>
<a href="http://arxiv.org/abs/2101.02420" target="_blank">arXiv:2101.02420</a> [<a href="http://arxiv.org/pdf/2101.02420" target="_blank">pdf</a>]

<h2>Learning to Ignore: Fair and Task Independent Representations. (arXiv:2101.04047v2 [cs.LG] UPDATED)</h2>
<h3>Linda H. Boedi, Helmut Grabner</h3>
<p>Training fair machine learning models, aiming for their interpretability and
solving the problem of domain shift has gained a lot of interest in the last
years. There is a vast amount of work addressing these topics, mostly in
separation. In this work we show that they can be seen as a common framework of
learning invariant representations. The representations should allow to predict
the target while at the same time being invariant to sensitive attributes which
split the dataset into subgroups. Our approach is based on the simple
observation that it is impossible for any learning algorithm to differentiate
samples if they have the same feature representation. This is formulated as an
additional loss (regularizer) enforcing a common feature representation across
subgroups. We apply it to learn fair models and interpret the influence of the
sensitive attribute. Furthermore it can be used for domain adaptation,
transferring knowledge and learning effectively from very few examples. In all
applications it is essential not only to learn to predict the target, but also
to learn what to ignore.
</p>
<a href="http://arxiv.org/abs/2101.04047" target="_blank">arXiv:2101.04047</a> [<a href="http://arxiv.org/pdf/2101.04047" target="_blank">pdf</a>]

<h2>Quantum Mathematics in Artificial Intelligence. (arXiv:2101.04255v2 [cs.AI] UPDATED)</h2>
<h3>Dominic Widdows, Kirsty Kitto, Trevor Cohen</h3>
<p>In the decade since 2010, successes in artificial intelligence have been at
the forefront of computer science and technology, and vector space models have
solidified a position at the forefront of artificial intelligence. At the same
time, quantum computers have become much more powerful, and announcements of
major advances are frequently in the news.

The mathematical techniques underlying both these areas have more in common
than is sometimes realized. Vector spaces took a position at the axiomatic
heart of quantum mechanics in the 1930s, and this adoption was a key motivation
for the derivation of logic and probability from the linear geometry of vector
spaces. Quantum interactions between particles are modelled using the tensor
product, which is also used to express objects and operations in artificial
neural networks.

This paper describes some of these common mathematical areas, including
examples of how they are used in artificial intelligence (AI), particularly in
automated reasoning and natural language processing (NLP). Techniques discussed
include vector spaces, scalar products, subspaces and implication, orthogonal
projection and negation, dual vectors, density matrices, positive operators,
and tensor products. Application areas include information retrieval,
categorization and implication, modelling word-senses and disambiguation,
inference in knowledge bases, and semantic composition.

Some of these approaches can potentially be implemented on quantum hardware.
Many of the practical steps in this implementation are in early stages, and
some are already realized. Explaining some of the common mathematical tools can
help researchers in both AI and quantum computing further exploit these
overlaps, recognizing and exploring new directions along the way.
</p>
<a href="http://arxiv.org/abs/2101.04255" target="_blank">arXiv:2101.04255</a> [<a href="http://arxiv.org/pdf/2101.04255" target="_blank">pdf</a>]

<h2>Forecasting blood sugar levels in Diabetes with univariate algorithms. (arXiv:2101.04770v2 [cs.LG] UPDATED)</h2>
<h3>Ignacio Rodriguez</h3>
<p>AI procedures joined with wearable gadgets can convey exact transient blood
glucose level forecast models. Also, such models can learn customized
glucose-insulin elements dependent on the sensor information gathered by
observing a few parts of the physiological condition and every day movement of
a person. Up to this point, the predominant methodology for creating
information driven forecast models was to gather "however much information as
could be expected" to help doctors and patients ideally change treatment. The
goal of this work was to examine the base information assortment, volume, and
speed needed to accomplish exact individual driven diminutive term expectation
models. We built up a progression of these models utilizing distinctive AI time
arrangement guaging strategies that are appropriate for execution inside a
wearable processor. We completed a broad aloof patient checking concentrate in
genuine conditions to fabricate a strong informational collection. The
examination included a subset of type-1 diabetic subjects wearing a glimmer
glucose checking framework. We directed a relative quantitative assessment of
the presentation of the created information driven expectation models and
comparing AI methods. Our outcomes show that precise momentary forecast can be
accomplished by just checking interstitial glucose information over a brief
timeframe and utilizing a low examining recurrence. The models created can
anticipate glucose levels inside a 15-minute skyline with a normal mistake as
low as 15.43 mg/dL utilizing just 24 memorable qualities gathered inside a time
of 6 hours, and by expanding the inspecting recurrence to incorporate 72
qualities, the normal blunder is limited to 10.15 mg/dL. Our forecast models
are reasonable for execution inside a wearable gadget, requiring the base
equipment necessities while simultaneously accomplishing high expectation
precision.
</p>
<a href="http://arxiv.org/abs/2101.04770" target="_blank">arXiv:2101.04770</a> [<a href="http://arxiv.org/pdf/2101.04770" target="_blank">pdf</a>]

<h2>Supervised Transfer Learning at Scale for Medical Imaging. (arXiv:2101.05913v3 [cs.CV] UPDATED)</h2>
<h3>Basil Mustafa, Aaron Loh, Jan Freyberg, Patricia MacWilliams, Megan Wilson, Scott Mayer McKinney, Marcin Sieniek, Jim Winkens, Yuan Liu, Peggy Bui, Shruthi Prabhakara, Umesh Telang, Alan Karthikesalingam, Neil Houlsby, Vivek Natarajan</h3>
<p>Transfer learning is a standard technique to improve performance on tasks
with limited data. However, for medical imaging, the value of transfer learning
is less clear. This is likely due to the large domain mismatch between the
usual natural-image pre-training (e.g. ImageNet) and medical images. However,
recent advances in transfer learning have shown substantial improvements from
scale. We investigate whether modern methods can change the fortune of transfer
learning for medical imaging. For this, we study the class of large-scale
pre-trained networks presented by Kolesnikov et al. on three diverse imaging
tasks: chest radiography, mammography, and dermatology. We study both transfer
performance and critical properties for the deployment in the medical domain,
including: out-of-distribution generalization, data-efficiency, sub-group
fairness, and uncertainty estimation. Interestingly, we find that for some of
these properties transfer from natural to medical images is indeed extremely
effective, but only when performed at sufficient scale.
</p>
<a href="http://arxiv.org/abs/2101.05913" target="_blank">arXiv:2101.05913</a> [<a href="http://arxiv.org/pdf/2101.05913" target="_blank">pdf</a>]

<h2>Deep Learning based Virtual Point Tracking for Real-Time Target-less Dynamic Displacement Measurement in Railway Applications. (arXiv:2101.06702v2 [cs.CV] UPDATED)</h2>
<h3>Dachuan Shi, Eldar Sabanovic, Luca Rizzetto, Viktor Skrickij, Roberto Oliverio, Nadia Kaviani, Yunguang Ye, Gintautas Bureika, Stefano Ricci, Markus Hecht</h3>
<p>In the application of computer-vision based displacement measurement, an
optical target is usually required to prove the reference. In the case that the
optical target cannot be attached to the measuring objective, edge detection,
feature matching and template matching are the most common approaches in
target-less photogrammetry. However, their performance significantly relies on
parameter settings. This becomes problematic in dynamic scenes where
complicated background texture exists and varies over time. To tackle this
issue, we propose virtual point tracking for real-time target-less dynamic
displacement measurement, incorporating deep learning techniques and domain
knowledge. Our approach consists of three steps: 1) automatic calibration for
detection of region of interest; 2) virtual point detection for each video
frame using deep convolutional neural network; 3) domain-knowledge based rule
engine for point tracking in adjacent frames. The proposed approach can be
executed on an edge computer in a real-time manner (i.e. over 30 frames per
second). We demonstrate our approach for a railway application, where the
lateral displacement of the wheel on the rail is measured during operation. We
also implement an algorithm using template matching and line detection as the
baseline for comparison. The numerical experiments have been performed to
evaluate the performance and the latency of our approach in the harsh railway
environment with noisy and varying backgrounds.
</p>
<a href="http://arxiv.org/abs/2101.06702" target="_blank">arXiv:2101.06702</a> [<a href="http://arxiv.org/pdf/2101.06702" target="_blank">pdf</a>]

<h2>Deep Learning for Moving Blockage Prediction using Real Millimeter Wave Measurements. (arXiv:2101.06886v2 [cs.LG] UPDATED)</h2>
<h3>Shunyao Wu, Muhammad Alrabeiah, Andrew Hredzak, Chaitali Chakrabarti, Ahmed Alkhateeb</h3>
<p>Millimeter wave (mmWave) communication is a key component of 5G and beyond.
Harvesting the gains of the large bandwidth and low latency at mmWave systems,
however, is challenged by the sensitivity of mmWave signals to blockages; a
sudden blockage in the line of sight (LOS) link leads to abrupt disconnection,
which affects the reliability of the network. In addition, searching for an
alternative base station to re-establish the link could result in needless
latency overhead. In this paper, we address these challenges collectively by
utilizing machine learning to anticipate dynamic blockages proactively. The
proposed approach sees a machine learning algorithm learning to predict future
blockages by observing what we refer to as the \textit{pre-blockage signature}.
To evaluate our proposed approach, we build a mmWave communication setup with a
moving blockage and collect a dataset of received power sequences. Simulation
results on a real dataset show that blockage occurrence could be predicted with
more than 85\% accuracy and the exact time instance of blockage occurrence can
be obtained with low error. This highlights the potential of the proposed
solution for dynamic blockage prediction and proactive hand-off, which enhances
the reliability and latency of future wireless networks.
</p>
<a href="http://arxiv.org/abs/2101.06886" target="_blank">arXiv:2101.06886</a> [<a href="http://arxiv.org/pdf/2101.06886" target="_blank">pdf</a>]

<h2>Yet Another Representation of Binary Decision Trees: A Mathematical Demonstration. (arXiv:2101.07077v3 [cs.LG] UPDATED)</h2>
<h3>Jinxiong Zhang</h3>
<p>A decision tree looks like a simple computational graph without cycles, where
only the leaf nodes specify the output values and the non-terminals specify
their tests or split conditions. From the numerical perspective, we express
decision trees in the language of computational graph. We explicitly
parameterize the test phase, traversal phase and prediction phase of decision
trees based on the bitvectors of non-terminal nodes. As shown later, the
decision tree is a shallow binary network in some sense. Especially, we
introduce the bitvector matrix to implement the tree traversal in numerical
approach, where the core is to convert the logical `AND' operation to
arithmetic operations. And we apply this numerical representation to extend and
unify diverse decision trees in concept.
</p>
<a href="http://arxiv.org/abs/2101.07077" target="_blank">arXiv:2101.07077</a> [<a href="http://arxiv.org/pdf/2101.07077" target="_blank">pdf</a>]

<h2>Determining Structural Properties of Artificial Neural Networks Using Algebraic Topology. (arXiv:2101.07752v2 [cs.LG] UPDATED)</h2>
<h3>David P&#xe9;rez Fern&#xe1;ndez, Asier Guti&#xe9;rrez-Fandi&#xf1;o, Jordi Armengol-Estap&#xe9;, Marta Villegas</h3>
<p>Artificial Neural Networks (ANNs) are widely used for approximating complex
functions. The process that is usually followed to define the most appropriate
architecture for an ANN given a specific function is mostly empirical. Once
this architecture has been defined, weights are usually optimized according to
the error function. On the other hand, we observe that ANNs can be represented
as graphs and their topological 'fingerprints' can be obtained using Persistent
Homology (PH). In this paper, we describe a proposal focused on designing more
principled architecture search procedures. To do this, different architectures
for solving problems related to a heterogeneous set of datasets have been
analyzed. The results of the evaluation corroborate that PH effectively
characterizes the ANN invariants: when ANN density (layers and neurons) or
sample feeding order is the only difference, PH topological invariants appear;
in the opposite direction in different sub-problems (i.e. different labels), PH
varies. This approach based on topological analysis helps towards the goal of
designing more principled architecture search procedures and having a better
understanding of ANNs.
</p>
<a href="http://arxiv.org/abs/2101.07752" target="_blank">arXiv:2101.07752</a> [<a href="http://arxiv.org/pdf/2101.07752" target="_blank">pdf</a>]

