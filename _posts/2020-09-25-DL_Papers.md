---
title: Latest Deep Learning Papers
date: 2021-02-10 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (190 Articles)</h1>
<h2>Bounded Memory Active Learning through Enriched Queries. (arXiv:2102.05047v1 [cs.LG])</h2>
<h3>Max Hopkins, Daniel Kane, Shachar Lovett, Michal Moshkovitz</h3>
<p>The explosive growth of easily-accessible unlabeled data has lead to growing
interest in active learning, a paradigm in which data-hungry learning
algorithms adaptively select informative examples in order to lower
prohibitively expensive labeling costs. Unfortunately, in standard worst-case
models of learning, the active setting often provides no improvement over
non-adaptive algorithms. To combat this, a series of recent works have
considered a model in which the learner may ask enriched queries beyond labels.
While such models have seen success in drastically lowering label costs, they
tend to come at the expense of requiring large amounts of memory. In this work,
we study what families of classifiers can be learned in bounded memory. To this
end, we introduce a novel streaming-variant of enriched-query active learning
along with a natural combinatorial parameter called lossless sample compression
that is sufficient for learning not only with bounded memory, but in a
query-optimal and computationally efficient manner as well. Finally, we give
three fundamental examples of classifier families with small, easy to compute
lossless compression schemes when given access to basic enriched queries:
axis-aligned rectangles, decision trees, and halfspaces in two dimensions.
</p>
<a href="http://arxiv.org/abs/2102.05047" target="_blank">arXiv:2102.05047</a> [<a href="http://arxiv.org/pdf/2102.05047" target="_blank">pdf</a>]

<h2>The Role of the Input in Natural Language Video Description. (arXiv:2102.05067v1 [cs.CV])</h2>
<h3>Silvia Cascianelli, Gabriele Costante, Alessandro Devo, Thomas A. Ciarfuglia, Paolo Valigi, Mario L. Fravolini</h3>
<p>Natural Language Video Description (NLVD) has recently received strong
interest in the Computer Vision, Natural Language Processing (NLP), Multimedia,
and Autonomous Robotics communities. The State-of-the-Art (SotA) approaches
obtained remarkable results when tested on the benchmark datasets. However,
those approaches poorly generalize to new datasets. In addition, none of the
existing works focus on the processing of the input to the NLVD systems, which
is both visual and textual. In this work, it is presented an extensive study
dealing with the role of the visual input, evaluated with respect to the
overall NLP performance. This is achieved performing data augmentation of the
visual component, applying common transformations to model camera distortions,
noise, lighting, and camera positioning, that are typical in real-world
operative scenarios. A t-SNE based analysis is proposed to evaluate the effects
of the considered transformations on the overall visual data distribution. For
this study, it is considered the English subset of Microsoft Research Video
Description (MSVD) dataset, which is used commonly for NLVD. It was observed
that this dataset contains a relevant amount of syntactic and semantic errors.
These errors have been amended manually, and the new version of the dataset
(called MSVD-v2) is used in the experimentation. The MSVD-v2 dataset is
released to help to gain insight into the NLVD problem.
</p>
<a href="http://arxiv.org/abs/2102.05067" target="_blank">arXiv:2102.05067</a> [<a href="http://arxiv.org/pdf/2102.05067" target="_blank">pdf</a>]

<h2>Emotion Transfer Using Vector-Valued Infinite Task Learning. (arXiv:2102.05075v1 [stat.ML])</h2>
<h3>Alex Lambert, Sanjeel Parekh, Zolt&#xe1;n Szab&#xf3;, Florence d&#x27;Alch&#xe9;-Buc</h3>
<p>Style transfer is a significant problem of machine learning with numerous
successful applications. In this work, we present a novel style transfer
framework building upon infinite task learning and vector-valued reproducing
kernel Hilbert spaces. We instantiate the idea in emotion transfer where the
goal is to transform facial images to different target emotions. The proposed
approach provides a principled way to gain explicit control over the continuous
style space. We demonstrate the efficiency of the technique on popular facial
emotion benchmarks, achieving low reconstruction cost and high emotion
classification accuracy.
</p>
<a href="http://arxiv.org/abs/2102.05075" target="_blank">arXiv:2102.05075</a> [<a href="http://arxiv.org/pdf/2102.05075" target="_blank">pdf</a>]

<h2>Domain Invariant Representation Learning with Domain Density Transformations. (arXiv:2102.05082v1 [cs.LG])</h2>
<h3>A. Tuan Nguyen, Toan Tran, Yarin Gal, Atilim Gunes Baydin</h3>
<p>Domain generalization refers to the problem where we aim to train a model on
data from a set of source domains so that the model can generalize to unseen
target domains. Naively training a model on the aggregate set of data (pooled
from all source domains) has been shown to perform suboptimally, since the
information learned by that model might be domain-specific and generalize
imperfectly to target domains. To tackle this problem, a predominant approach
is to find and learn some domain-invariant information in order to use it for
the prediction task. In this paper, we propose a theoretically grounded method
to learn a domain-invariant representation by enforcing the representation
network to be invariant under all transformation functions among domains. We
also show how to use generative adversarial networks to learn such domain
transformations to implement our method in practice. We demonstrate the
effectiveness of our method on several widely used datasets for the domain
generalization problem, on all of which we achieve competitive results with
state-of-the-art models.
</p>
<a href="http://arxiv.org/abs/2102.05082" target="_blank">arXiv:2102.05082</a> [<a href="http://arxiv.org/pdf/2102.05082" target="_blank">pdf</a>]

<h2>Deep Multilabel CNN for Forensic Footwear Impression Descriptor Identification. (arXiv:2102.05090v1 [cs.CV])</h2>
<h3>Marcin Budka, Akanda Wahid Ul Ashraf, Scott Neville, Alun Mackrill, Matthew Bennett</h3>
<p>In recent years deep neural networks have become the workhorse of computer
vision. In this paper, we employ a deep learning approach to classify footwear
impression's features known as \emph{descriptors} for forensic use cases.
Within this process, we develop and evaluate an effective technique for feeding
downsampled greyscale impressions to a neural network pre-trained on data from
a different domain. Our approach relies on learnable preprocessing layer paired
with multiple interpolation methods used in parallel. We empirically show that
this technique outperforms using a single type of interpolated image without
learnable preprocessing, and can help to avoid the computational penalty
related to using high resolution inputs, by making more efficient use of the
low resolution inputs. We also investigate the effect of preserving the aspect
ratio of the inputs, which leads to considerable boost in accuracy without
increasing the computational budget with respect to squished rectangular
images. Finally, we formulate a set of best practices for transfer learning
with greyscale inputs, potentially widely applicable in computer vision tasks
ranging from footwear impression classification to medical imaging.
</p>
<a href="http://arxiv.org/abs/2102.05090" target="_blank">arXiv:2102.05090</a> [<a href="http://arxiv.org/pdf/2102.05090" target="_blank">pdf</a>]

<h2>Is Space-Time Attention All You Need for Video Understanding?. (arXiv:2102.05095v1 [cs.CV])</h2>
<h3>Gedas Bertasius, Heng Wang, Lorenzo Torresani</h3>
<p>We present a convolution-free approach to video classification built
exclusively on self-attention over space and time. Our method, named
"TimeSformer," adapts the standard Transformer architecture to video by
enabling spatiotemporal feature learning directly from a sequence of
frame-level patches. Our experimental study compares different self-attention
schemes and suggests that "divided attention," where temporal attention and
spatial attention are separately applied within each block, leads to the best
video classification accuracy among the design choices considered. Despite the
radically different design compared to the prominent paradigm of 3D
convolutional architectures for video, TimeSformer achieves state-of-the-art
results on several major action recognition benchmarks, including the best
reported accuracy on Kinetics-400 and Kinetics-600. Furthermore, our model is
faster to train and has higher test-time efficiency compared to competing
architectures. Code and pretrained models will be made publicly available.
</p>
<a href="http://arxiv.org/abs/2102.05095" target="_blank">arXiv:2102.05095</a> [<a href="http://arxiv.org/pdf/2102.05095" target="_blank">pdf</a>]

<h2>Adversarially Robust Classifier with Covariate Shift Adaptation. (arXiv:2102.05096v1 [cs.LG])</h2>
<h3>Jay Nandy, Sudipan Saha, Wynne Hsu, Mong Li Lee, Xiao Xiang Zhu</h3>
<p>Existing adversarially trained models typically perform inference on test
examples independently from each other. This mode of testing is unable to
handle covariate shift in the test samples. Due to this, the performance of
these models often degrades significantly. In this paper, we show that simple
adaptive batch normalization (BN) technique that involves re-estimating the
batch-normalization parameters during inference, can significantly improve the
robustness of these models for any random perturbations, including the Gaussian
noise. This simple finding enables us to transform adversarially trained models
into randomized smoothing classifiers to produce certified robustness to
$\ell_2$ noise. We show that we can achieve $\ell_2$ certified robustness even
for adversarially trained models using $\ell_{\infty}$-bounded adversarial
examples. We further demonstrate that adaptive BN technique significantly
improves robustness against common corruptions, while often enhancing
performance against adversarial attacks. This enables us to achieve both
adversarial and corruption robustness for the same classifier.
</p>
<a href="http://arxiv.org/abs/2102.05096" target="_blank">arXiv:2102.05096</a> [<a href="http://arxiv.org/pdf/2102.05096" target="_blank">pdf</a>]

<h2>"What's in the box?!": Deflecting Adversarial Attacks by Randomly Deploying Adversarially-Disjoint Models. (arXiv:2102.05104v1 [cs.LG])</h2>
<h3>Sahar Abdelnabi, Mario Fritz</h3>
<p>Machine learning models are now widely deployed in real-world applications.
However, the existence of adversarial examples has been long considered a real
threat to such models. While numerous defenses aiming to improve the robustness
have been proposed, many have been shown ineffective. As these vulnerabilities
are still nowhere near being eliminated, we propose an alternative
deployment-based defense paradigm that goes beyond the traditional white-box
and black-box threat models. Instead of training a single partially-robust
model, one could train a set of same-functionality, yet, adversarially-disjoint
models with minimal in-between attack transferability. These models could then
be randomly and individually deployed, such that accessing one of them
minimally affects the others. Our experiments on CIFAR-10 and a wide range of
attacks show that we achieve a significantly lower attack transferability
across our disjoint models compared to a baseline of ensemble diversity. In
addition, compared to an adversarially trained set, we achieve a higher average
robust accuracy while maintaining the accuracy of clean examples.
</p>
<a href="http://arxiv.org/abs/2102.05104" target="_blank">arXiv:2102.05104</a> [<a href="http://arxiv.org/pdf/2102.05104" target="_blank">pdf</a>]

<h2>Deep learning architectural designs for super-resolution of noisy images. (arXiv:2102.05105v1 [cs.CV])</h2>
<h3>Angel Villar-Corrales, Franziska Schirrmacher, Christian Riess</h3>
<p>Recent advances in deep learning have led to significant improvements in
single image super-resolution (SR) research. However, due to the amplification
of noise during the upsampling steps, state-of-the-art methods often fail at
reconstructing high-resolution images from noisy versions of their
low-resolution counterparts. However, this is especially important for images
from unknown cameras with unseen types of image degradation. In this work, we
propose to jointly perform denoising and super-resolution. To this end, we
investigate two architectural designs: "in-network" combines both tasks at
feature level, while "pre-network" first performs denoising and then
super-resolution. Our experiments show that both variants have specific
advantages: The in-network design obtains the strongest results when the type
of image corruption is aligned in the training and testing dataset, for any
choice of denoiser. The pre-network design exhibits superior performance on
unseen types of image corruption, which is a pathological failure case of
existing super-resolution models. We hope that these findings help to enable
super-resolution also in less constrained scenarios where source camera or
imaging conditions are not well controlled. Source code and pretrained models
are available at https://github.com/
angelvillar96/super-resolution-noisy-images.
</p>
<a href="http://arxiv.org/abs/2102.05105" target="_blank">arXiv:2102.05105</a> [<a href="http://arxiv.org/pdf/2102.05105" target="_blank">pdf</a>]

<h2>Adversarial Perturbations Are Not So Weird: Entanglement of Robust and Non-Robust Features in Neural Network Classifiers. (arXiv:2102.05110v1 [cs.LG])</h2>
<h3>Jacob M. Springer, Melanie Mitchell, Garrett T. Kenyon</h3>
<p>Neural networks trained on visual data are well-known to be vulnerable to
often imperceptible adversarial perturbations. The reasons for this
vulnerability are still being debated in the literature. Recently Ilyas et al.
(2019) showed that this vulnerability arises, in part, because neural network
classifiers rely on highly predictive but brittle "non-robust" features. In
this paper we extend the work of Ilyas et al. by investigating the nature of
the input patterns that give rise to these features. In particular, we
hypothesize that in a neural network trained in a standard way, non-robust
features respond to small, "non-semantic" patterns that are typically entangled
with larger, robust patterns, known to be more human-interpretable, as opposed
to solely responding to statistical artifacts in a dataset. Thus, adversarial
examples can be formed via minimal perturbations to these small, entangled
patterns. In addition, we demonstrate a corollary of our hypothesis: robust
classifiers are more effective than standard (non-robust) ones as a source for
generating transferable adversarial examples in both the untargeted and
targeted settings. The results we present in this paper provide new insight
into the nature of the non-robust features responsible for adversarial
vulnerability of neural network classifiers.
</p>
<a href="http://arxiv.org/abs/2102.05110" target="_blank">arXiv:2102.05110</a> [<a href="http://arxiv.org/pdf/2102.05110" target="_blank">pdf</a>]

<h2>Negative Data Augmentation. (arXiv:2102.05113v1 [cs.CV])</h2>
<h3>Abhishek Sinha, Kumar Ayush, Jiaming Song, Burak Uzkent, Hongxia Jin, Stefano Ermon</h3>
<p>Data augmentation is often used to enlarge datasets with synthetic samples
generated in accordance with the underlying data distribution. To enable a
wider range of augmentations, we explore negative data augmentation strategies
(NDA)that intentionally create out-of-distribution samples. We show that such
negative out-of-distribution samples provide information on the support of the
data distribution, and can be leveraged for generative modeling and
representation learning. We introduce a new GAN training objective where we use
NDA as an additional source of synthetic data for the discriminator. We prove
that under suitable conditions, optimizing the resulting objective still
recovers the true data distribution but can directly bias the generator towards
avoiding samples that lack the desired structure. Empirically, models trained
with our method achieve improved conditional/unconditional image generation
along with improved anomaly detection capabilities. Further, we incorporate the
same negative data augmentation strategy in a contrastive learning framework
for self-supervised representation learning on images and videos, achieving
improved performance on downstream image classification, object detection, and
action recognition tasks. These results suggest that prior knowledge on what
does not constitute valid data is an effective form of weak supervision across
a range of unsupervised learning tasks.
</p>
<a href="http://arxiv.org/abs/2102.05113" target="_blank">arXiv:2102.05113</a> [<a href="http://arxiv.org/pdf/2102.05113" target="_blank">pdf</a>]

<h2>DARE-SLAM: Degeneracy-Aware and Resilient Loop Closing in Perceptually-Degraded Environments. (arXiv:2102.05117v1 [cs.RO])</h2>
<h3>Kamak Ebadi, Matteo Palieri, Sally Wood, Curtis Padgett, Ali-akbar Agha-mohammadi</h3>
<p>Enabling fully autonomous robots capable of navigating and exploring
large-scale, unknown and complex environments has been at the core of robotics
research for several decades. A key requirement in autonomous exploration is
building accurate and consistent maps of the unknown environment that can be
used for reliable navigation. Loop closure detection, the ability to assert
that a robot has returned to a previously visited location, is crucial for
consistent mapping as it reduces the drift caused by error accumulation in the
estimated robot trajectory. Moreover, in multi-robot systems, loop closures
enable merging local maps obtained by a team of robots into a consistent global
map of the environment. In this paper, we present a degeneracy-aware and
drift-resilient loop closing method to improve place recognition and resolve 3D
location ambiguities for simultaneous localization and mapping (SLAM) in
GPS-denied, large-scale and perceptually-degraded environments. More
specifically, we focus on SLAM in subterranean environments (e.g., lava tubes,
caves, and mines) that represent examples of complex and ambiguous environments
where current methods have inadequate performance.
</p>
<a href="http://arxiv.org/abs/2102.05117" target="_blank">arXiv:2102.05117</a> [<a href="http://arxiv.org/pdf/2102.05117" target="_blank">pdf</a>]

<h2>Backdoor Scanning for Deep Neural Networks through K-Arm Optimization. (arXiv:2102.05123v1 [cs.LG])</h2>
<h3>Guangyu Shen, Yingqi Liu, Guanhong Tao, Shengwei An, Qiuling Xu, Siyuan Cheng, Shiqing Ma, Xiangyu Zhang</h3>
<p>Back-door attack poses a severe threat to deep learning systems. It injects
hidden malicious behaviors to a model such that any input stamped with a
special pattern can trigger such behaviors. Detecting back-door is hence of
pressing need. Many existing defense techniques use optimization to generate
the smallest input pattern that forces the model to misclassify a set of benign
inputs injected with the pattern to a target label. However, the complexity is
quadratic to the number of class labels such that they can hardly handle models
with many classes. Inspired by Multi-Arm Bandit in Reinforcement Learning, we
propose a K-Arm optimization method for backdoor detection. By iteratively and
stochastically selecting the most promising labels for optimization with the
guidance of an objective function, we substantially reduce the complexity,
allowing to handle models with many classes. Moreover, by iteratively refining
the selection of labels to optimize, it substantially mitigates the uncertainty
in choosing the right labels, improving detection accuracy. At the time of
submission, the evaluation of our method on over 4000 models in the IARPA
TrojAI competition from round 1 to the latest round 4 achieves top performance
on the leaderboard. Our technique also supersedes three state-of-the-art
techniques in terms of accuracy and the scanning time needed.
</p>
<a href="http://arxiv.org/abs/2102.05123" target="_blank">arXiv:2102.05123</a> [<a href="http://arxiv.org/pdf/2102.05123" target="_blank">pdf</a>]

<h2>Label Smoothed Embedding Hypothesis for Out-of-Distribution Detection. (arXiv:2102.05131v1 [cs.LG])</h2>
<h3>Dara Bahri, Heinrich Jiang, Yi Tay, Donald Metzler</h3>
<p>Detecting out-of-distribution (OOD) examples is critical in many
applications. We propose an unsupervised method to detect OOD samples using a
$k$-NN density estimate with respect to a classification model's intermediate
activations on in-distribution samples. We leverage a recent insight about
label smoothing, which we call the \emph{Label Smoothed Embedding Hypothesis},
and show that one of the implications is that the $k$-NN density estimator
performs better as an OOD detection method both theoretically and empirically
when the model is trained with label smoothing. Finally, we show that our
proposal outperforms many OOD baselines and also provide new finite-sample
high-probability statistical results for $k$-NN density estimation's ability to
detect OOD examples.
</p>
<a href="http://arxiv.org/abs/2102.05131" target="_blank">arXiv:2102.05131</a> [<a href="http://arxiv.org/pdf/2102.05131" target="_blank">pdf</a>]

<h2>Using Deep LSD to build operators in GANs latent space with meaning in real space. (arXiv:2102.05132v1 [cs.LG])</h2>
<h3>J. Quetzalcoatl Toledo-Marin, James A. Glazier</h3>
<p>Generative models rely on the key idea that data can be represented in terms
of latent variables which are uncorrelated by definition. Lack of correlation
is important because it suggests that the latent space manifold is simpler to
understand and manipulate. Generative models are widely used in deep learning,
e.g., variational autoencoders (VAEs) and generative adversarial networks
(GANs). Here we propose a method to build a set of linearly independent vectors
in the latent space of a GANs, which we call quasi-eigenvectors. These
quasi-eigenvectors have two key properties: i) They span all the latent space,
ii) A set of these quasi-eigenvectors map to each of the labeled features
one-on-one. We show that in the case of the MNIST, while the number of
dimensions in latent space is large by construction, 98% of the data in real
space map to a sub-domain of latent space of dimensionality equal to the number
of labels. We then show how the quasi-eigenvalues can be used for Latent
Spectral Decomposition (LSD), which has applications in denoising images and
for performing matrix operations in latent space that map to feature
transformations in real space. We show how this method provides insight into
the latent space topology. The key point is that the set of quasi-eigenvectors
form a basis set in latent space and each direction corresponds to a feature in
real space.
</p>
<a href="http://arxiv.org/abs/2102.05132" target="_blank">arXiv:2102.05132</a> [<a href="http://arxiv.org/pdf/2102.05132" target="_blank">pdf</a>]

<h2>Regularization Strategies for Quantile Regression. (arXiv:2102.05135v1 [stat.ML])</h2>
<h3>Taman Narayan, Serena Wang, Kevin Canini, Maya Gupta</h3>
<p>We investigate different methods for regularizing quantile regression when
predicting either a subset of quantiles or the full inverse CDF. We show that
minimizing an expected pinball loss over a continuous distribution of quantiles
is a good regularizer even when only predicting a specific quantile. For
predicting multiple quantiles, we propose achieving the classic goal of
non-crossing quantiles by using deep lattice networks that treat the quantile
as a monotonic input feature, and we discuss why monotonicity on other features
is an apt regularizer for quantile regression. We show that lattice models
enable regularizing the predicted distribution to a location-scale family.
Lastly, we propose applying rate constraints to improve the calibration of the
quantile predictions on specific subsets of interest and improve fairness
metrics. We demonstrate our contributions on simulations, benchmark datasets,
and real quantile regression problems.
</p>
<a href="http://arxiv.org/abs/2102.05135" target="_blank">arXiv:2102.05135</a> [<a href="http://arxiv.org/pdf/2102.05135" target="_blank">pdf</a>]

<h2>Locally Adaptive Label Smoothing for Predictive Churn. (arXiv:2102.05140v1 [cs.LG])</h2>
<h3>Dara Bahri, Heinrich Jiang</h3>
<p>Training modern neural networks is an inherently noisy process that can lead
to high \emph{prediction churn} -- disagreements between re-trainings of the
same model due to factors such as randomization in the parameter initialization
and mini-batches -- even when the trained models all attain similar accuracies.
Such prediction churn can be very undesirable in practice. In this paper, we
present several baselines for reducing churn and show that training on soft
labels obtained by adaptively smoothing each example's label based on the
example's neighboring labels often outperforms the baselines on churn while
improving accuracy on a variety of benchmark classification tasks and model
architectures.
</p>
<a href="http://arxiv.org/abs/2102.05140" target="_blank">arXiv:2102.05140</a> [<a href="http://arxiv.org/pdf/2102.05140" target="_blank">pdf</a>]

<h2>Classifier Calibration: with implications to threat scores in cybersecurity. (arXiv:2102.05143v1 [cs.LG])</h2>
<h3>Waleed A. Yousef, Issa Traore, William Briguglio</h3>
<p>This paper explores the calibration of a classifier output score in binary
classification problems. A calibrator is a function that maps the arbitrary
classifier score, of a testing observation, onto $[0,1]$ to provide an estimate
for the posterior probability of belonging to one of the two classes.
Calibration is important for two reasons; first, it provides a meaningful
score, that is the posterior probability; second, it puts the scores of
different classifiers on the same scale for comparable interpretation. The
paper presents three main contributions: (1) Introducing multi-score
calibration, when more than one classifier provides a score for a single
observation. (2) Introducing the idea that the classifier scores to a
calibration process are nothing but features to a classifier, hence proposing
extending the classifier scores to higher dimensions to boost the calibrator's
performance. (3) Conducting a massive simulation study, in the order of 24,000
experiments, that incorporates different configurations, in addition to
experimenting on two real datasets from the cybersecurity domain. The results
show that there is no overall winner among the different calibrators and
different configurations. However, general advices for practitioners include
the following: the Platt's
calibrator~\citep{Platt1999ProbabilisticOutputsForSupport}, a version of the
logistic regression that decreases bias for a small sample size, has a very
stable and acceptable performance among all experiments; our suggested
multi-score calibration provides better performance than single score
calibration in the majority of experiments, including the two real datasets. In
addition, extending the scores can help in some experiments.
</p>
<a href="http://arxiv.org/abs/2102.05143" target="_blank">arXiv:2102.05143</a> [<a href="http://arxiv.org/pdf/2102.05143" target="_blank">pdf</a>]

<h2>Toward Safe and Efficient Human-Robot Interaction via Behavior-Driven Danger Signaling. (arXiv:2102.05144v1 [cs.RO])</h2>
<h3>Mehdi Hosseinzadeh, Bruno Sinopoli, Aaron F. Bobick</h3>
<p>This paper introduces the notion of danger awareness in the context of
Human-Robot Interaction (HRI), which decodes whether a human is aware of the
existence of the robot, and illuminates whether the human is willing to engage
in enforcing the safety. This paper also proposes a method to quantify this
notion as a single binary variable, so-called danger awareness coefficient. By
analyzing the effect of this coefficient on the human's actions, an online
Bayesian learning method is proposed to update the belief about the value of
the coefficient. It is shown that based upon the danger awareness coefficient
and the proposed learning method, the robot can build a predictive human model
to anticipate the human's future actions. In order to create a communication
channel between the human and the robot, to enrich the observations and get
informative data about the human, and to improve the efficiency of the robot,
the robot is equipped with a danger signaling system. A predictive planning
scheme, coupled with the predictive human model, is also proposed to provide an
efficient and Probabilistically safe plan for the robot. The effectiveness of
the proposed scheme is demonstrated through simulation studies on an
interaction between a self-driving car and a pedestrian.
</p>
<a href="http://arxiv.org/abs/2102.05144" target="_blank">arXiv:2102.05144</a> [<a href="http://arxiv.org/pdf/2102.05144" target="_blank">pdf</a>]

<h2>Uncertainty Quantification and Propagation for Airline Disruption Management. (arXiv:2102.05147v1 [cs.AI])</h2>
<h3>Kolawole Ogunsina, Marios Papamichalis, Daniel DeLaurentis</h3>
<p>Disruption management during the airline scheduling process can be
compartmentalized into proactive and reactive processes depending upon the time
of schedule execution. The state of the art for decision-making in airline
disruption management involves a heuristic human-centric approach that does not
categorically study uncertainty in proactive and reactive processes for
managing airline schedule disruptions. Hence, this paper introduces an
uncertainty transfer function model (UTFM) framework that characterizes
uncertainty for proactive airline disruption management before schedule
execution, reactive airline disruption management during schedule execution,
and proactive airline disruption management after schedule execution to enable
the construction of quantitative tools that can allow an intelligent agent to
rationalize complex interactions and procedures for robust airline disruption
management. Specifically, we use historical scheduling and operations data from
a major U.S. airline to facilitate the development and assessment of the UTFM,
defined by hidden Markov models (a special class of probabilistic graphical
models) that can efficiently perform pattern learning and inference on portions
of large data sets.
</p>
<a href="http://arxiv.org/abs/2102.05147" target="_blank">arXiv:2102.05147</a> [<a href="http://arxiv.org/pdf/2102.05147" target="_blank">pdf</a>]

<h2>RODNet: A Real-Time Radar Object Detection Network Cross-Supervised by Camera-Radar Fused Object 3D Localization. (arXiv:2102.05150v1 [cs.CV])</h2>
<h3>Yizhou Wang, Zhongyu Jiang, Yudong Li, Jenq-Neng Hwang, Guanbin Xing, Hui Liu</h3>
<p>Various autonomous or assisted driving strategies have been facilitated
through the accurate and reliable perception of the environment around a
vehicle. Among the commonly used sensors, radar has usually been considered as
a robust and cost-effective solution even in adverse driving scenarios, e.g.,
weak/strong lighting or bad weather. Instead of considering to fuse the
unreliable information from all available sensors, perception from pure radar
data becomes a valuable alternative that is worth exploring. In this paper, we
propose a deep radar object detection network, named RODNet, which is
cross-supervised by a camera-radar fused algorithm without laborious annotation
efforts, to effectively detect objects from the radio frequency (RF) images in
real-time. First, the raw signals captured by millimeter-wave radars are
transformed to RF images in range-azimuth coordinates. Second, our proposed
RODNet takes a sequence of RF images as the input to predict the likelihood of
objects in the radar field of view (FoV). Two customized modules are also added
to handle multi-chirp information and object relative motion. Instead of using
human-labeled ground truth for training, the proposed RODNet is
cross-supervised by a novel 3D localization of detected objects using a
camera-radar fusion (CRF) strategy in the training stage. Finally, we propose a
method to evaluate the object detection performance of the RODNet. Due to no
existing public dataset available for our task, we create a new dataset, named
CRUW, which contains synchronized RGB and RF image sequences in various driving
scenarios. With intensive experiments, our proposed cross-supervised RODNet
achieves 86% average precision and 88% average recall of object detection
performance, which shows the robustness to noisy scenarios in various driving
conditions.
</p>
<a href="http://arxiv.org/abs/2102.05150" target="_blank">arXiv:2102.05150</a> [<a href="http://arxiv.org/pdf/2102.05150" target="_blank">pdf</a>]

<h2>On Explainability of Graph Neural Networks via Subgraph Explorations. (arXiv:2102.05152v1 [cs.LG])</h2>
<h3>Hao Yuan, Haiyang Yu, Jie Wang, Kang Li, Shuiwang Ji</h3>
<p>We consider the problem of explaining the predictions of graph neural
networks (GNNs), which otherwise are considered as black boxes. Existing
methods invariably focus on explaining the importance of graph nodes or edges
but ignore the substructures of graphs, which are more intuitive and
human-intelligible. In this work, we propose a novel method, known as
SubgraphX, to explain GNNs by identifying important subgraphs. Given a trained
GNN model and an input graph, our SubgraphX explains its predictions by
efficiently exploring different subgraphs with Monte Carlo tree search. To make
the tree search more effective, we propose to use Shapley values as a measure
of subgraph importance, which can also capture the interactions among different
subgraphs. To expedite computations, we propose efficient approximation schemes
to compute Shapley values for graph data. Our work represents the first attempt
to explain GNNs via identifying subgraphs explicitly. Experimental results show
that our SubgraphX achieves significantly improved explanations, while keeping
computations at a reasonable level.
</p>
<a href="http://arxiv.org/abs/2102.05152" target="_blank">arXiv:2102.05152</a> [<a href="http://arxiv.org/pdf/2102.05152" target="_blank">pdf</a>]

<h2>Nonstochastic Bandits with Infinitely Many Experts. (arXiv:2102.05164v1 [cs.LG])</h2>
<h3>X. Flora Meng, Tuhin Sarkar, Munther A. Dahleh</h3>
<p>We study the problem of nonstochastic bandits with infinitely many experts: A
learner aims to maximize the total reward by taking actions sequentially based
on bandit feedback while benchmarking against a countably infinite set of
experts. We propose a variant of Exp4.P that, for finitely many experts,
enables inference of correct expert rankings while preserving the order of the
regret upper bound. We then incorporate the variant into a meta-algorithm that
works on infinitely many experts. We prove a high-probability upper bound of
$\tilde{\mathcal{O}} \big( i^*K + \sqrt{KT} \big)$ on the regret, up to polylog
factors, where $i^*$ is the unknown position of the best expert, $K$ is the
number of actions, and $T$ is the time horizon. We also provide an example of
structured experts and discuss how to expedite learning in such case. Our
meta-learning algorithm achieves the tightest regret upper bound for the
setting considered when $i^* = \tilde{\mathcal{O}} \big( \sqrt{T/K} \big)$. If
a prior distribution is assumed to exist for $i^*$, the probability of
satisfying a tight regret bound increases with $T$, the rate of which can be
fast.
</p>
<a href="http://arxiv.org/abs/2102.05164" target="_blank">arXiv:2102.05164</a> [<a href="http://arxiv.org/pdf/2102.05164" target="_blank">pdf</a>]

<h2>Scheduling the NASA Deep Space Network with Deep Reinforcement Learning. (arXiv:2102.05167v1 [cs.LG])</h2>
<h3>Edwin Goh, Hamsa Shwetha Venkataram, Mark Hoffmann, Mark Johnston, Brian Wilson</h3>
<p>With three complexes spread evenly across the Earth, NASA's Deep Space
Network (DSN) is the primary means of communications as well as a significant
scientific instrument for dozens of active missions around the world. A rapidly
rising number of spacecraft and increasingly complex scientific instruments
with higher bandwidth requirements have resulted in demand that exceeds the
network's capacity across its 12 antennae. The existing DSN scheduling process
operates on a rolling weekly basis and is time-consuming; for a given week,
generation of the final baseline schedule of spacecraft tracking passes takes
roughly 5 months from the initial requirements submission deadline, with
several weeks of peer-to-peer negotiations in between. This paper proposes a
deep reinforcement learning (RL) approach to generate candidate DSN schedules
from mission requests and spacecraft ephemeris data with demonstrated
capability to address real-world operational constraints. A deep RL agent is
developed that takes mission requests for a given week as input, and interacts
with a DSN scheduling environment to allocate tracks such that its reward
signal is maximized. A comparison is made between an agent trained using
Proximal Policy Optimization and its random, untrained counterpart. The results
represent a proof-of-concept that, given a well-shaped reward signal, a deep RL
agent can learn the complex heuristics used by experts to schedule the DSN. A
trained agent can potentially be used to generate candidate schedules to
bootstrap the scheduling process and thus reduce the turnaround cycle for DSN
scheduling.
</p>
<a href="http://arxiv.org/abs/2102.05167" target="_blank">arXiv:2102.05167</a> [<a href="http://arxiv.org/pdf/2102.05167" target="_blank">pdf</a>]

<h2>Transfer learning based few-shot classification using optimal transport mapping from preprocessed latent space of backbone neural network. (arXiv:2102.05176v1 [cs.LG])</h2>
<h3>Tom&#xe1;&#x161; Chobola, Daniel Va&#x161;ata, Pavel Kord&#xed;k</h3>
<p>MetaDL Challenge 2020 focused on image classification tasks in few-shot
settings. This paper describes second best submission in the competition. Our
meta learning approach modifies the distribution of classes in a latent space
produced by a backbone network for each class in order to better follow the
Gaussian distribution. After this operation which we call Latent Space
Transform algorithm, centers of classes are further aligned in an iterative
fashion of the Expectation Maximisation algorithm to utilize information in
unlabeled data that are often provided on top of few labelled instances. For
this task, we utilize optimal transport mapping using the Sinkhorn algorithm.
Our experiments show that this approach outperforms previous works as well as
other variants of the algorithm, using K-Nearest Neighbour algorithm, Gaussian
Mixture Models, etc.
</p>
<a href="http://arxiv.org/abs/2102.05176" target="_blank">arXiv:2102.05176</a> [<a href="http://arxiv.org/pdf/2102.05176" target="_blank">pdf</a>]

<h2>Benchmarks, Algorithms, and Metrics for Hierarchical Disentanglement. (arXiv:2102.05185v1 [cs.LG])</h2>
<h3>Andrew Slavin Ross, Finale Doshi-Velez</h3>
<p>In representation learning, there has been recent interest in developing
algorithms to disentangle the ground-truth generative factors behind data, and
metrics to quantify how fully this occurs. However, these algorithms and
metrics often assume that both representations and ground-truth factors are
flat, continuous, and factorized, whereas many real-world generative processes
involve rich hierarchical structure, mixtures of discrete and continuous
variables with dependence between them, and even varying intrinsic
dimensionality. In this work, we develop benchmarks, algorithms, and metrics
for learning such hierarchical representations.
</p>
<a href="http://arxiv.org/abs/2102.05185" target="_blank">arXiv:2102.05185</a> [<a href="http://arxiv.org/pdf/2102.05185" target="_blank">pdf</a>]

<h2>CaPC Learning: Confidential and Private Collaborative Learning. (arXiv:2102.05188v1 [cs.LG])</h2>
<h3>Christopher A. Choquette-Choo, Natalie Dullerud, Adam Dziedzic, Yunxiang Zhang, Somesh Jha, Nicolas Papernot, Xiao Wang</h3>
<p>Machine learning benefits from large training datasets, which may not always
be possible to collect by any single entity, especially when using
privacy-sensitive data. In many contexts, such as healthcare and finance,
separate parties may wish to collaborate and learn from each other's data but
are prevented from doing so due to privacy regulations. Some regulations
prevent explicit sharing of data between parties by joining datasets in a
central location (confidentiality). Others also limit implicit sharing of data,
e.g., through model predictions (privacy). There is currently no method that
enables machine learning in such a setting, where both confidentiality and
privacy need to be preserved, to prevent both explicit and implicit sharing of
data. Federated learning only provides confidentiality, not privacy, since
gradients shared still contain private information. Differentially private
learning assumes unreasonably large datasets. Furthermore, both of these
learning paradigms produce a central model whose architecture was previously
agreed upon by all parties rather than enabling collaborative learning where
each party learns and improves their own local model. We introduce Confidential
and Private Collaborative (CaPC) learning, the first method provably achieving
both confidentiality and privacy in a collaborative setting. We leverage secure
multi-party computation (MPC), homomorphic encryption (HE), and other
techniques in combination with privately aggregated teacher models. We
demonstrate how CaPC allows participants to collaborate without having to
explicitly join their training sets or train a central model. Each party is
able to improve the accuracy and fairness of their model, even in settings
where each party has a model that performs well on their own dataset or when
datasets are not IID and model architectures are heterogeneous across parties.
</p>
<a href="http://arxiv.org/abs/2102.05188" target="_blank">arXiv:2102.05188</a> [<a href="http://arxiv.org/pdf/2102.05188" target="_blank">pdf</a>]

<h2>Boosting Template-based SSVEP Decoding by Cross-domain Transfer Learning. (arXiv:2102.05194v1 [cs.LG])</h2>
<h3>Kuan-Jung Chiang, Chun-Shu Wei, Masaki Nakanishi, Tzyy-Ping Jung</h3>
<p>Objective: This study aims to establish a generalized transfer-learning
framework for boosting the performance of steady-state visual evoked potential
(SSVEP)-based brain-computer interfaces (BCIs) by leveraging cross-domain data
transferring. Approach: We enhanced the state-of-the-art template-based SSVEP
decoding through incorporating a least-squares transformation (LST)-based
transfer learning to leverage calibration data across multiple domains
(sessions, subjects, and EEG montages). Main results: Study results verified
the efficacy of LST in obviating the variability of SSVEPs when transferring
existing data across domains. Furthermore, the LST-based method achieved
significantly higher SSVEP-decoding accuracy than the standard task-related
component analysis (TRCA)-based method and the non-LST naive transfer-learning
method. Significance: This study demonstrated the capability of the LST-based
transfer learning to leverage existing data across subjects and/or devices with
an in-depth investigation of its rationale and behavior in various
circumstances. The proposed framework significantly improved the SSVEP decoding
accuracy over the standard TRCA approach when calibration data are limited. Its
performance in calibration reduction could facilitate plug-and-play SSVEP-based
BCIs and further practical applications.
</p>
<a href="http://arxiv.org/abs/2102.05194" target="_blank">arXiv:2102.05194</a> [<a href="http://arxiv.org/pdf/2102.05194" target="_blank">pdf</a>]

<h2>Statistical Inference for Polyak-Ruppert Averaged Zeroth-order Stochastic Gradient Algorithm. (arXiv:2102.05198v1 [stat.ML])</h2>
<h3>Yanhao Jin, Tesi Xiao, Krishnakumar Balasubramanian</h3>
<p>As machine learning models are deployed in critical applications, it becomes
important to not just provide point estimators of the model parameters (or
subsequent predictions), but also quantify the uncertainty associated with
estimating the model parameters via confidence sets. In the last decade,
estimating or training in several machine learning models has become synonymous
with running stochastic gradient algorithms. However, computing the stochastic
gradients in several settings is highly expensive or even impossible at times.
An important question which has thus far not been addressed sufficiently in the
statistical machine learning literature is that of equipping zeroth-order
stochastic gradient algorithms with practical yet rigorous inferential
capabilities. Towards this, in this work, we first establish a central limit
theorem for Polyak-Ruppert averaged stochastic gradient algorithm in the
zeroth-order setting. We then provide online estimators of the asymptotic
covariance matrix appearing in the central limit theorem, thereby providing a
practical procedure for constructing asymptotically valid confidence sets (or
intervals) for parameter estimation (or prediction) in the zeroth-order
setting.
</p>
<a href="http://arxiv.org/abs/2102.05198" target="_blank">arXiv:2102.05198</a> [<a href="http://arxiv.org/pdf/2102.05198" target="_blank">pdf</a>]

<h2>Transfer Reinforcement Learning across Homotopy Classes. (arXiv:2102.05207v1 [cs.RO])</h2>
<h3>Zhangjie Cao, Minae Kwon, Dorsa Sadigh</h3>
<p>The ability for robots to transfer their learned knowledge to new tasks --
where data is scarce -- is a fundamental challenge for successful robot
learning. While fine-tuning has been well-studied as a simple but effective
transfer approach in the context of supervised learning, it is not as
well-explored in the context of reinforcement learning. In this work, we study
the problem of fine-tuning in transfer reinforcement learning when tasks are
parameterized by their reward functions, which are known beforehand. We
conjecture that fine-tuning drastically underperforms when source and target
trajectories are part of different \emph{homotopy classes}. We demonstrate that
fine-tuning policy parameters across homotopy classes compared to fine-tuning
within a homotopy class requires more interaction with the environment, and in
certain cases is impossible. We propose a novel fine-tuning algorithm, \ours,
that consists of a relaxing stage and a curriculum learning stage to enable
transfer learning across homotopy classes. Finally, we evaluate our approach on
several robotics-inspired simulated environments and empirically verify that
the \ours\ method can successfully fine-tune in a sample-efficient way compared
to existing baselines.
</p>
<a href="http://arxiv.org/abs/2102.05207" target="_blank">arXiv:2102.05207</a> [<a href="http://arxiv.org/pdf/2102.05207" target="_blank">pdf</a>]

<h2>Attentive Gaussian processes for probabilistic time-series generation. (arXiv:2102.05208v1 [cs.LG])</h2>
<h3>Kuilin Chen, Chi-Guhn Lee</h3>
<p>The transduction of sequence has been mostly done by recurrent networks,
which are computationally demanding and often underestimate uncertainty
severely. We propose a computationally efficient attention-based network
combined with the Gaussian process regression to generate real-valued sequence,
which we call the Attentive-GP. The proposed model not only improves the
training efficiency by dispensing recurrence and convolutions but also learns
the factorized generative distribution with Bayesian representation. However,
the presence of the GP precludes the commonly used mini-batch approach to the
training of the attention network. Therefore, we develop a block-wise training
algorithm to allow mini-batch training of the network while the GP is trained
using full-batch, resulting in a scalable training method. The algorithm has
been proved to converge and shows comparable, if not better, quality of the
found solution. As the algorithm does not assume any specific network
architecture, it can be used with a wide range of hybrid models such as neural
networks with kernel machine layers in the scarcity of resources for
computation and memory.
</p>
<a href="http://arxiv.org/abs/2102.05208" target="_blank">arXiv:2102.05208</a> [<a href="http://arxiv.org/pdf/2102.05208" target="_blank">pdf</a>]

<h2>Polarimetric Monocular Dense Mapping Using Relative Deep Depth Prior. (arXiv:2102.05212v1 [cs.CV])</h2>
<h3>Moein Shakeri, Shing Yan Loo, Hong Zhang</h3>
<p>This paper is concerned with polarimetric dense map reconstruction based on a
polarization camera with the help of relative depth information as a prior. In
general, polarization imaging is able to reveal information about surface
normal such as azimuth and zenith angles, which can support the development of
solutions to the problem of dense reconstruction, especially in texture-poor
regions. However, polarimetric shape cues are ambiguous due to two types of
polarized reflection (specular/diffuse). Although methods have been proposed to
address this issue, they either are offline and therefore not practical in
robotics applications, or use incomplete polarimetric cues, leading to
sub-optimal performance. In this paper, we propose an online reconstruction
method that uses full polarimetric cues available from the polarization camera.
With our online method, we can propagate sparse depth values both along and
perpendicular to iso-depth contours. Through comprehensive experiments on
challenging image sequences, we demonstrate that our method is able to
significantly improve the accuracy of the depthmap as well as increase its
density, specially in regions of poor texture.
</p>
<a href="http://arxiv.org/abs/2102.05212" target="_blank">arXiv:2102.05212</a> [<a href="http://arxiv.org/pdf/2102.05212" target="_blank">pdf</a>]

<h2>Task-Optimal Exploration in Linear Dynamical Systems. (arXiv:2102.05214v1 [cs.LG])</h2>
<h3>Andrew Wagenmaker, Max Simchowitz, Kevin Jamieson</h3>
<p>Exploration in unknown environments is a fundamental problem in reinforcement
learning and control. In this work, we study task-guided exploration and
determine what precisely an agent must learn about their environment in order
to complete a particular task. Formally, we study a broad class of
decision-making problems in the setting of linear dynamical systems, a class
that includes the linear quadratic regulator problem. We provide instance- and
task-dependent lower bounds which explicitly quantify the difficulty of
completing a task of interest. Motivated by our lower bound, we propose a
computationally efficient experiment-design based exploration algorithm. We
show that it optimally explores the environment, collecting precisely the
information needed to complete the task, and provide finite-time bounds
guaranteeing that it achieves the instance- and task-optimal sample complexity,
up to constant factors. Through several examples of the LQR problem, we show
that performing task-guided exploration provably improves on exploration
schemes which do not take into account the task of interest. Along the way, we
establish that certainty equivalence decision making is instance- and
task-optimal, and obtain the first algorithm for the linear quadratic regulator
problem which is instance-optimal. We conclude with several experiments
illustrating the effectiveness of our approach in practice.
</p>
<a href="http://arxiv.org/abs/2102.05214" target="_blank">arXiv:2102.05214</a> [<a href="http://arxiv.org/pdf/2102.05214" target="_blank">pdf</a>]

<h2>FLOP: Federated Learning on Medical Datasets using Partial Networks. (arXiv:2102.05218v1 [cs.LG])</h2>
<h3>Qian Yang, Jianyi Zhang, Weituo Hao, Gregory Spell, Lawrence Carin</h3>
<p>The outbreak of COVID-19 Disease due to the novel coronavirus has caused a
shortage of medical resources. To aid and accelerate the diagnosis process,
automatic diagnosis of COVID-19 via deep learning models has recently been
explored by researchers across the world. While different data-driven deep
learning models have been developed to mitigate the diagnosis of COVID-19, the
data itself is still scarce due to patient privacy concerns. Federated Learning
(FL) is a natural solution because it allows different organizations to
cooperatively learn an effective deep learning model without sharing raw data.
However, recent studies show that FL still lacks privacy protection and may
cause data leakage. We investigate this challenging problem by proposing a
simple yet effective algorithm, named \textbf{F}ederated \textbf{L}earning
\textbf{o}n Medical Datasets using \textbf{P}artial Networks (FLOP), that
shares only a partial model between the server and clients. Extensive
experiments on benchmark data and real-world healthcare tasks show that our
approach achieves comparable or better performance while reducing the privacy
and security risks. Of particular interest, we conduct experiments on the
COVID-19 dataset and find that our FLOP algorithm can allow different hospitals
to collaboratively and effectively train a partially shared model without
sharing local patients' data.
</p>
<a href="http://arxiv.org/abs/2102.05218" target="_blank">arXiv:2102.05218</a> [<a href="http://arxiv.org/pdf/2102.05218" target="_blank">pdf</a>]

<h2>Early Abandoning and Pruning for Elastic Distances. (arXiv:2102.05221v1 [cs.LG])</h2>
<h3>Matthieu Herrmann, Geoffrey I. Webb</h3>
<p>Elastic distances are key tools for time series analysis. Straightforward
implementations require O(n2)space and time complexities, preventing many
applications from scaling to long series. Much work hasbeen devoted in speeding
up these applications, mostly with the development of lower bounds, allowing to
avoid costly distance computations when a given threshold is exceeded. This
threshold also allows to early abandon the computation of the distance itself.
Another approach, developed for DTW, is to prune parts of the computation. All
these techniques are orthogonal to each other. In this work, we develop a new
generic strategy, "EAPruned", that tightly integrates pruning with early
abandoning. We apply it to DTW, CDTW, WDTW, ERP, MSM and TWE, showing
substantial speedup in NN1-like scenarios. Pruning also shows substantial
speedup for some distances, benefiting applications such as clustering where
all pairwise distances are required and hence early abandoning is not
applicable. We release our implementation as part of a new C++ library for time
series classification, along with easy to usePython/Numpy bindings.
</p>
<a href="http://arxiv.org/abs/2102.05221" target="_blank">arXiv:2102.05221</a> [<a href="http://arxiv.org/pdf/2102.05221" target="_blank">pdf</a>]

<h2>LIFT-CAM: Towards Better Explanations for Class Activation Mapping. (arXiv:2102.05228v1 [cs.CV])</h2>
<h3>Hyungsik Jung, Youngrock Oh</h3>
<p>Increasing demands for understanding the internal behaviors of convolutional
neural networks (CNNs) have led to remarkable improvements in explanation
methods. Particularly, several class activation mapping (CAM) based methods,
which generate visual explanation maps by a linear combination of activation
maps from CNNs, have been proposed. However, the majority of the methods lack a
theoretical basis in how to assign their weighted linear coefficients. In this
paper, we revisit the intrinsic linearity of CAM w.r.t. the activation maps.
Focusing on the linearity, we construct an explanation model as a linear
function of binary variables which denote the existence of the corresponding
activation maps. With this approach, the explanation model can be determined by
the class of additive feature attribution methods which adopts SHAP values as a
unified measure of feature importance. We then demonstrate the efficacy of the
SHAP values as the weight coefficients for CAM. However, the exact SHAP values
are incalculable. Hence, we introduce an efficient approximation method,
referred to as LIFT-CAM. On the basis of DeepLIFT, our proposed method can
estimate the true SHAP values quickly and accurately. Furthermore, it achieves
better performances than the other previous CAM-based methods in qualitative
and quantitative aspects.
</p>
<a href="http://arxiv.org/abs/2102.05228" target="_blank">arXiv:2102.05228</a> [<a href="http://arxiv.org/pdf/2102.05228" target="_blank">pdf</a>]

<h2>Sequential vessel segmentation via deep channel attention network. (arXiv:2102.05229v1 [cs.CV])</h2>
<h3>Dongdong Hao, Song Ding, Linwei Qiu, Yisong Lv, Baowei Fei, Yueqi Zhu, Binjie Qin</h3>
<p>This paper develops a novel encoder-decoder deep network architecture which
exploits the several contextual frames of 2D+t sequential images in a sliding
window centered at current frame to segment 2D vessel masks from the current
frame. The architecture is equipped with temporal-spatial feature extraction in
encoder stage, feature fusion in skip connection layers and channel attention
mechanism in decoder stage. In the encoder stage, a series of 3D convolutional
layers are employed to hierarchically extract temporal-spatial features. Skip
connection layers subsequently fuse the temporal-spatial feature maps and
deliver them to the corresponding decoder stages. To efficiently discriminate
vessel features from the complex and noisy backgrounds in the XCA images, the
decoder stage effectively utilizes channel attention blocks to refine the
intermediate feature maps from skip connection layers for subsequently decoding
the refined features in 2D ways to produce the segmented vessel masks.
Furthermore, Dice loss function is implemented to train the proposed deep
network in order to tackle the class imbalance problem in the XCA data due to
the wide distribution of complex background artifacts. Extensive experiments by
comparing our method with other state-of-the-art algorithms demonstrate the
proposed method's superior performance over other methods in terms of the
quantitative metrics and visual validation. The source codes are at
https://github.com/Binjie-Qin/SVS-net
</p>
<a href="http://arxiv.org/abs/2102.05229" target="_blank">arXiv:2102.05229</a> [<a href="http://arxiv.org/pdf/2102.05229" target="_blank">pdf</a>]

<h2>Culture-inspired Multi-modal Color Palette Generation and Colorization: A Chinese Youth Subculture Case. (arXiv:2102.05231v1 [cs.CV])</h2>
<h3>Yufan Li, Jinggang Zhuo, Ling Fan, Harry Jiannan Wang</h3>
<p>Color is an essential component of graphic design, acting not only as a
visual factor but also carrying cultural implications. However, existing
research on algorithmic color palette generation and colorization largely
ignores the cultural aspect. In this paper, we contribute to this line of
research by first constructing a unique color dataset inspired by a specific
culture, i.e., Chinese Youth Subculture (CYS), which is an vibrant and trending
cultural group especially for the Gen Z population. We show that the colors
used in CYS have special aesthetic and semantic characteristics that are
different from generic color theory. We then develop an interactive multi-modal
generative framework to create CYS-styled color palettes, which can be used to
put a CYS twist on images using our automatic colorization model. Our framework
is illustrated via a demo system designed with the human-in-the-loop principle
that constantly provides feedback to our algorithms. User studies are also
conducted to evaluate our generation results.
</p>
<a href="http://arxiv.org/abs/2102.05231" target="_blank">arXiv:2102.05231</a> [<a href="http://arxiv.org/pdf/2102.05231" target="_blank">pdf</a>]

<h2>Driver2vec: Driver Identification from Automotive Data. (arXiv:2102.05234v1 [cs.LG])</h2>
<h3>Jingbo Yang, Ruge Zhao, Meixian Zhu, David Hallac, Jaka Sodnik, Jure Leskovec</h3>
<p>With increasing focus on privacy protection, alternative methods to identify
vehicle operator without the use of biometric identifiers have gained traction
for automotive data analysis. The wide variety of sensors installed on modern
vehicles enable autonomous driving, reduce accidents and improve vehicle
handling. On the other hand, the data these sensors collect reflect drivers'
habit. Drivers' use of turn indicators, following distance, rate of
acceleration, etc. can be transformed to an embedding that is representative of
their behavior and identity. In this paper, we develop a deep learning
architecture (Driver2vec) to map a short interval of driving data into an
embedding space that represents the driver's behavior to assist in driver
identification. We develop a custom model that leverages performance gains of
temporal convolutional networks, embedding separation power of triplet loss and
classification accuracy of gradient boosting decision trees. Trained on a
dataset of 51 drivers provided by Nervtech, Driver2vec is able to accurately
identify the driver from a short 10-second interval of sensor data, achieving
an average pairwise driver identification accuracy of 83.1% from this 10-second
interval, which is remarkably higher than performance obtained in previous
studies. We then analyzed performance of Driver2vec to show that its
performance is consistent across scenarios and that modeling choices are sound.
</p>
<a href="http://arxiv.org/abs/2102.05234" target="_blank">arXiv:2102.05234</a> [<a href="http://arxiv.org/pdf/2102.05234" target="_blank">pdf</a>]

<h2>Advanced Ore Mine Optimisation under Uncertainty Using Evolution. (arXiv:2102.05235v1 [cs.LG])</h2>
<h3>William Reid, Aneta Neumann, Simon Ratcliffe, Frank Neumann</h3>
<p>In this paper, we investigate the impact of uncertainty in advanced ore mine
optimisation. We consider Maptek's software system Evolution which optimizes
extraction sequences based on evolutionary computation techniques and quantify
the uncertainty of the obtained solutions with respect to the ore deposit based
on predictions obtained by ensembles of neural networks. Furthermore, we
investigate the impact of staging on the obtained optimized solutions and
discuss a wide range of components for this large scale stochastic optimisation
problem which allow to mitigate the uncertainty in the ore deposit while
maintaining high profitability.
</p>
<a href="http://arxiv.org/abs/2102.05235" target="_blank">arXiv:2102.05235</a> [<a href="http://arxiv.org/pdf/2102.05235" target="_blank">pdf</a>]

<h2>Detecting Localized Adversarial Examples: A Generic Approach using Critical Region Analysis. (arXiv:2102.05241v1 [cs.CV])</h2>
<h3>Fengting Li, Xuankai Liu, Xiaoli Zhang, Qi Li, Kun Sun, Kang Li</h3>
<p>Deep neural networks (DNNs) have been applied in a wide range of
applications,e.g.,face recognition and image classification;however,they are
vulnerable to adversarial examples.By adding a small amount of imperceptible
perturbations,an attacker can easily manipulate the outputs of a
DNN.Particularly,the localized adversarial examples only perturb a small and
contiguous region of the target object,so that they are robust and effective in
both digital and physical worlds.Although the localized adversarial examples
have more severe real-world impacts than traditional pixel attacks,they have
not been well addressed in the literature.In this paper,we propose a generic
defense system called TaintRadar to accurately detect localized adversarial
examples via analyzing critical regions that have been manipulated by
attackers.The main idea is that when removing critical regions from input
images,the ranking changes of adversarial labels will be larger than those of
benign labels.Compared with existing defense solutions,TaintRadar can
effectively capture sophisticated localized partial attacks, e.g.,the
eye-glasses attack,while not requiring additional training or fine-tuning of
the original model's structure.Comprehensive experiments have been conducted in
both digital and physical worlds to verify the effectiveness and robustness of
our defense.
</p>
<a href="http://arxiv.org/abs/2102.05241" target="_blank">arXiv:2102.05241</a> [<a href="http://arxiv.org/pdf/2102.05241" target="_blank">pdf</a>]

<h2>Patterns, predictions, and actions: A story about machine learning. (arXiv:2102.05242v1 [cs.LG])</h2>
<h3>Moritz Hardt, Benjamin Recht</h3>
<p>This graduate textbook on machine learning tells a story of how patterns in
data support predictions and consequential actions. Starting with the
foundations of decision making, we cover representation, optimization, and
generalization as the constituents of supervised learning. A chapter on
datasets as benchmarks examines their histories and scientific bases.
Self-contained introductions to causality, the practice of causal inference,
sequential decision making, and reinforcement learning equip the reader with
concepts and tools to reason about actions and their consequences. Throughout,
the text discusses historical context and societal impact. We invite readers
from all backgrounds; some experience with probability, calculus, and linear
algebra suffices.
</p>
<a href="http://arxiv.org/abs/2102.05242" target="_blank">arXiv:2102.05242</a> [<a href="http://arxiv.org/pdf/2102.05242" target="_blank">pdf</a>]

<h2>Memory-Associated Differential Learning. (arXiv:2102.05246v1 [cs.LG])</h2>
<h3>Yi Luo, Aiguo Chen, Bei Hui, Ke Yan</h3>
<p>Conventional Supervised Learning approaches focus on the mapping from input
features to output labels. After training, the learnt models alone are adapted
onto testing features to predict testing labels in isolation, with training
data wasted and their associations ignored. To take full advantage of the vast
number of training data and their associations, we propose a novel learning
paradigm called Memory-Associated Differential (MAD) Learning. We first
introduce an additional component called Memory to memorize all the training
data. Then we learn the differences of labels as well as the associations of
features in the combination of a differential equation and some sampling
methods. Finally, in the evaluating phase, we predict unknown labels by
inferencing from the memorized facts plus the learnt differences and
associations in a geometrically meaningful manner. We gently build this theory
in unary situations and apply it on Image Recognition, then extend it into Link
Prediction as a binary situation, in which our method outperforms strong
state-of-the-art baselines on three citation networks and ogbl-ddi dataset.
</p>
<a href="http://arxiv.org/abs/2102.05246" target="_blank">arXiv:2102.05246</a> [<a href="http://arxiv.org/pdf/2102.05246" target="_blank">pdf</a>]

<h2>Policy Augmentation: An Exploration Strategy for Faster Convergence of Deep Reinforcement Learning Algorithms. (arXiv:2102.05249v1 [cs.LG])</h2>
<h3>Arash Mahyari</h3>
<p>Despite advancements in deep reinforcement learning algorithms, developing an
effective exploration strategy is still an open problem. Most existing
exploration strategies either are based on simple heuristics, or require the
model of the environment, or train additional deep neural networks to generate
imagination-augmented paths. In this paper, a revolutionary algorithm, called
Policy Augmentation, is introduced. Policy Augmentation is based on a newly
developed inductive matrix completion method. The proposed algorithm augments
the values of unexplored state-action pairs, helping the agent take actions
that will result in high-value returns while the agent is in the early
episodes. Training deep reinforcement learning algorithms with high-value
rollouts leads to the faster convergence of deep reinforcement learning
algorithms. Our experiments show the superior performance of Policy
Augmentation. The code can be found at:
https://github.com/arashmahyari/PolicyAugmentation.
</p>
<a href="http://arxiv.org/abs/2102.05249" target="_blank">arXiv:2102.05249</a> [<a href="http://arxiv.org/pdf/2102.05249" target="_blank">pdf</a>]

<h2>Robust Federated Learning with Attack-Adaptive Aggregation. (arXiv:2102.05257v1 [cs.LG])</h2>
<h3>Ching Pui Wan, Qifeng Chen</h3>
<p>Federated learning is vulnerable to various attacks, such as model poisoning
and backdoor attacks, even if some existing defense strategies are used. To
address this challenge, we propose an attack-adaptive aggregation strategy to
defend against various attacks for robust federated learning. The proposed
approach is based on training a neural network with an attention mechanism that
learns the vulnerability of federated learning models from a set of plausible
attacks. To the best of our knowledge, our aggregation strategy is the first
one that can be adapted to defend against various attacks in a data-driven
fashion. Our approach has achieved competitive performance in defending model
poisoning and backdoor attacks in federated learning tasks on image and text
datasets.
</p>
<a href="http://arxiv.org/abs/2102.05257" target="_blank">arXiv:2102.05257</a> [<a href="http://arxiv.org/pdf/2102.05257" target="_blank">pdf</a>]

<h2>Locally Free Weight Sharing for Network Width Search. (arXiv:2102.05258v1 [cs.CV])</h2>
<h3>Xiu Su, Shan You, Tao Huang, Fei Wang, Chen Qian, Changshui Zhang, Chang Xu</h3>
<p>Searching for network width is an effective way to slim deep neural networks
with hardware budgets. With this aim, a one-shot supernet is usually leveraged
as a performance evaluator to rank the performance \wrt~different width.
Nevertheless, current methods mainly follow a manually fixed weight sharing
pattern, which is limited to distinguish the performance gap of different
width. In this paper, to better evaluate each width, we propose a locally free
weight sharing strategy (CafeNet) accordingly. In CafeNet, weights are more
freely shared, and each width is jointly indicated by its base channels and
free channels, where free channels are supposed to locate freely in a local
zone to better represent each width. Besides, we propose to further reduce the
search space by leveraging our introduced FLOPs-sensitive bins. As a result,
our CafeNet can be trained stochastically and get optimized within a min-min
strategy. Extensive experiments on ImageNet, CIFAR-10, CelebA and MS COCO
dataset have verified our superiority comparing to other state-of-the-art
baselines. For example, our method can further boost the benchmark NAS network
EfficientNet-B0 by 0.41\% via searching its width more delicately.
</p>
<a href="http://arxiv.org/abs/2102.05258" target="_blank">arXiv:2102.05258</a> [<a href="http://arxiv.org/pdf/2102.05258" target="_blank">pdf</a>]

<h2>Simple Agent, Complex Environment: Efficient Reinforcement Learning with Agent State. (arXiv:2102.05261v1 [cs.LG])</h2>
<h3>Shi Dong, Benjamin Van Roy, Zhengyuan Zhou</h3>
<p>We design a simple reinforcement learning agent that, with a specification
only of agent state dynamics and a reward function, can operate with some
degree of competence in any environment. The agent maintains only visitation
counts and value estimates for each agent-state-action pair. The value function
is updated incrementally in response to temporal differences and optimistic
boosts that encourage exploration. The agent executes actions that are greedy
with respect to this value function. We establish a regret bound demonstrating
convergence to near-optimal per-period performance, where the time taken to
achieve near-optimality is polynomial in the number of agent states and
actions, as well as the reward mixing time of the best policy within the
reference policy class, which is comprised of those that depend on history only
through agent state. Notably, there is no further dependence on the number of
environment states or mixing times associated with other policies or statistics
of history. Our result sheds light on the potential benefits of (deep)
representation learning, which has demonstrated the capability to extract
compact and relevant features from high-dimensional interaction histories.
</p>
<a href="http://arxiv.org/abs/2102.05261" target="_blank">arXiv:2102.05261</a> [<a href="http://arxiv.org/pdf/2102.05261" target="_blank">pdf</a>]

<h2>Input Similarity from the Neural Network Perspective. (arXiv:2102.05262v1 [cs.LG])</h2>
<h3>Guillaume Charpiat, Nicolas Girard, Loris Felardos, Yuliya Tarabalka</h3>
<p>We first exhibit a multimodal image registration task, for which a neural
network trained on a dataset with noisy labels reaches almost perfect accuracy,
far beyond noise variance. This surprising auto-denoising phenomenon can be
explained as a noise averaging effect over the labels of similar input
examples. This effect theoretically grows with the number of similar examples;
the question is then to define and estimate the similarity of examples.

We express a proper definition of similarity, from the neural network
perspective, i.e. we quantify how undissociable two inputs $A$ and $B$ are,
taking a machine learning viewpoint: how much a parameter variation designed to
change the output for $A$ would impact the output for $B$ as well?

We study the mathematical properties of this similarity measure, and show how
to use it on a trained network to estimate sample density, in low complexity,
enabling new types of statistical analysis for neural networks. We analyze data
by retrieving samples perceived as similar by the network, and are able to
quantify the denoising effect without requiring true labels. We also propose,
during training, to enforce that examples known to be similar should also be
seen as similar by the network, and notice speed-up training effects for
certain datasets.
</p>
<a href="http://arxiv.org/abs/2102.05262" target="_blank">arXiv:2102.05262</a> [<a href="http://arxiv.org/pdf/2102.05262" target="_blank">pdf</a>]

<h2>Regression Oracles and Exploration Strategies for Short-Horizon Multi-Armed Bandits. (arXiv:2102.05263v1 [cs.LG])</h2>
<h3>Robert C. Gray, Jichen Zhu, Santiago Onta&#xf1;&#xf3;n</h3>
<p>This paper explores multi-armed bandit (MAB) strategies in very short horizon
scenarios, i.e., when the bandit strategy is only allowed very few interactions
with the environment. This is an understudied setting in the MAB literature
with many applications in the context of games, such as player modeling.
Specifically, we pursue three different ideas. First, we explore the use of
regression oracles, which replace the simple average used in strategies such as
epsilon-greedy with linear regression models. Second, we examine different
exploration patterns such as forced exploration phases. Finally, we introduce a
new variant of the UCB1 strategy called UCBT that has interesting properties
and no tunable parameters. We present experimental results in a domain
motivated by exergames, where the goal is to maximize a player's daily steps.
Our results show that the combination of epsilon-greedy or epsilon-decreasing
with regression oracles outperforms all other tested strategies in the short
horizon setting.
</p>
<a href="http://arxiv.org/abs/2102.05263" target="_blank">arXiv:2102.05263</a> [<a href="http://arxiv.org/pdf/2102.05263" target="_blank">pdf</a>]

<h2>Player Modeling via Multi-Armed Bandits. (arXiv:2102.05264v1 [cs.AI])</h2>
<h3>Robert C. Gray, Jichen Zhu, Dannielle Arigo, Evan Forman, Santiago Onta&#xf1;&#xf3;n</h3>
<p>This paper focuses on building personalized player models solely from player
behavior in the context of adaptive games. We present two main contributions:
The first is a novel approach to player modeling based on multi-armed bandits
(MABs). This approach addresses, at the same time and in a principled way, both
the problem of collecting data to model the characteristics of interest for the
current player and the problem of adapting the interactive experience based on
this model. Second, we present an approach to evaluating and fine-tuning these
algorithms prior to generating data in a user study. This is an important
problem, because conducting user studies is an expensive and labor-intensive
process; therefore, an ability to evaluate the algorithms beforehand can save a
significant amount of resources. We evaluate our approach in the context of
modeling players' social comparison orientation (SCO) and present empirical
results from both simulations and real players.
</p>
<a href="http://arxiv.org/abs/2102.05264" target="_blank">arXiv:2102.05264</a> [<a href="http://arxiv.org/pdf/2102.05264" target="_blank">pdf</a>]

<h2>Stability of SGD: Tightness Analysis and Improved Bounds. (arXiv:2102.05274v1 [cs.LG])</h2>
<h3>Yikai Zhang, Wenjia Zhang, Sammy Bald, Vamsi Pingali, Chao Chen, Mayank Goswami</h3>
<p>Stochastic Gradient Descent (SGD) based methods have been widely used for
training large-scale machine learning models that also generalize well in
practice. Several explanations have been offered for this generalization
performance, a prominent one being algorithmic stability [18]. However, there
are no known examples of smooth loss functions for which the analysis can be
shown to be tight. Furthermore, apart from the properties of the loss function,
data distribution has also been shown to be an important factor in
generalization performance. This raises the question: is the stability analysis
of [18] tight for smooth functions, and if not, for what kind of loss functions
and data distributions can the stability analysis be improved? In this paper we
first settle open questions regarding tightness of bounds in the
data-independent setting: we show that for general datasets, the existing
analysis for convex and strongly-convex loss functions is tight, but it can be
improved for non-convex loss functions. Next, we give a novel and improved
data-dependent bounds: we show stability upper bounds for a large class of
convex regularized loss functions, with negligible regularization parameters,
and improve existing data-dependent bounds in the non-convex setting. We hope
that our results will initiate further efforts to better understand the
data-dependent setting under non-convex loss functions, leading to an improved
understanding of the generalization abilities of deep networks.
</p>
<a href="http://arxiv.org/abs/2102.05274" target="_blank">arXiv:2102.05274</a> [<a href="http://arxiv.org/pdf/2102.05274" target="_blank">pdf</a>]

<h2>A Generic Object Re-identification System for Short Videos. (arXiv:2102.05275v1 [cs.CV])</h2>
<h3>Tairu Qiu, Guanxian Chen, Zhongang Qi, Bin Li, Ying Shan, Xiangyang Xue</h3>
<p>Short video applications like TikTok and Kwai have been a great hit recently.
In order to meet the increasing demands and take full advantage of visual
information in short videos, objects in each short video need to be located and
analyzed as an upstream task. A question is thus raised -- how to improve the
accuracy and robustness of object detection, tracking, and re-identification
across tons of short videos with hundreds of categories and complicated visual
effects (VFX). To this end, a system composed of a detection module, a tracking
module and a generic object re-identification module, is proposed in this
paper, which captures features of major objects from short videos. In
particular, towards the high efficiency demands in practical short video
application, a Temporal Information Fusion Network (TIFN) is proposed in the
object detection module, which shows comparable accuracy and improved time
efficiency to the state-of-the-art video object detector. Furthermore, in order
to mitigate the fragmented issue of tracklets in short videos, a Cross-Layer
Pointwise Siamese Network (CPSN) is proposed in the tracking module to enhance
the robustness of the appearance model. Moreover, in order to evaluate the
proposed system, two challenge datasets containing real-world short videos are
built for video object trajectory extraction and generic object
re-identification respectively. Overall, extensive experiments for each module
and the whole system demonstrate the effectiveness and efficiency of our
system.
</p>
<a href="http://arxiv.org/abs/2102.05275" target="_blank">arXiv:2102.05275</a> [<a href="http://arxiv.org/pdf/2102.05275" target="_blank">pdf</a>]

<h2>Finding the Stochastic Shortest Path with Low Regret: The Adversarial Cost and Unknown Transition Case. (arXiv:2102.05284v1 [cs.LG])</h2>
<h3>Liyu Chen, Haipeng Luo</h3>
<p>We make significant progress toward the stochastic shortest path problem with
adversarial costs and unknown transition. Specifically, we develop algorithms
that achieve $\widetilde{O}(\sqrt{S^2ADT_\star K})$ regret for the
full-information setting and $\widetilde{O}(\sqrt{S^3A^2DT_\star K})$ regret
for the bandit feedback setting, where $D$ is the diameter, $T_\star$ is the
expected hitting time of the optimal policy, $S$ is the number of states, $A$
is the number of actions, and $K$ is the number of episodes. Our work strictly
improves (Rosenberg and Mansour, 2020) in the full information setting, extends
(Chen et al., 2020) from known transition to unknown transition, and is also
the first to consider the most challenging combination: bandit feedback with
adversarial costs and unknown transition. To remedy the gap between our upper
bounds and the current best lower bounds constructed via a stochastically
oblivious adversary, we also propose algorithms with near-optimal regret for
this special case.
</p>
<a href="http://arxiv.org/abs/2102.05284" target="_blank">arXiv:2102.05284</a> [<a href="http://arxiv.org/pdf/2102.05284" target="_blank">pdf</a>]

<h2>Bayesian Inference with Certifiable Adversarial Robustness. (arXiv:2102.05289v1 [cs.LG])</h2>
<h3>Matthew Wicker, Luca Laurenti, Andrea Patane, Zhoutong Chen, Zheng Zhang, Marta Kwiatkowska</h3>
<p>We consider adversarial training of deep neural networks through the lens of
Bayesian learning, and present a principled framework for adversarial training
of Bayesian Neural Networks (BNNs) with certifiable guarantees. We rely on
techniques from constraint relaxation of non-convex optimisation problems and
modify the standard cross-entropy error model to enforce posterior robustness
to worst-case perturbations in $\epsilon$-balls around input points. We
illustrate how the resulting framework can be combined with methods commonly
employed for approximate inference of BNNs. In an empirical investigation, we
demonstrate that the presented approach enables training of certifiably robust
models on MNIST, FashionMNIST and CIFAR-10 and can also be beneficial for
uncertainty calibration. Our method is the first to directly train certifiable
BNNs, thus facilitating their deployment in safety-critical applications.
</p>
<a href="http://arxiv.org/abs/2102.05289" target="_blank">arXiv:2102.05289</a> [<a href="http://arxiv.org/pdf/2102.05289" target="_blank">pdf</a>]

<h2>Clusterability as an Alternative to Anchor Points When Learning with Noisy Labels. (arXiv:2102.05291v1 [cs.LG])</h2>
<h3>Zhaowei Zhu, Yiwen Song, Yang Liu</h3>
<p>The knowledge of the label noise transition matrix, characterizing the
probabilities of a training instance being wrongly annotated, is crucial to
designing popular solutions to learning with noisy labels, including loss
correction and loss reweighting approaches. Existing works heavily rely on the
existence of "anchor points" or their approximates, defined as instances that
belong to a particular class almost surely. Nonetheless, finding anchor points
remains a non-trivial task, and the estimation accuracy is also often throttled
by the number of available anchor points. In this paper, we propose an
alternative option to the above task. Our main contribution is the discovery of
an efficient estimation procedure based on a clusterability condition. We prove
that with clusterable representations of features, using up to third-order
consensuses of noisy labels among neighbor representations is sufficient to
estimate a unique transition matrix. Compared with methods using anchor points,
our approach uses substantially more instances and benefits from a much better
sample complexity. We demonstrate the estimation accuracy and advantages of our
estimates using both synthetic noisy labels (on CIFAR-10/100) and real
human-level noisy labels (on Clothing1M and our self-collected human-annotated
CIFAR-10).
</p>
<a href="http://arxiv.org/abs/2102.05291" target="_blank">arXiv:2102.05291</a> [<a href="http://arxiv.org/pdf/2102.05291" target="_blank">pdf</a>]

<h2>An Efficient Pessimistic-Optimistic Algorithm for Constrained Linear Bandits. (arXiv:2102.05295v1 [cs.LG])</h2>
<h3>Xin Liu, Bin Li, Pengyi Shi, Lei Ying</h3>
<p>This paper considers stochastic linear bandits with general constraints. The
objective is to maximize the expected cumulative reward over horizon $T$
subject to a set of constraints in each round $\tau\leq T$. We propose a
pessimistic-optimistic algorithm for this problem, which is efficient in two
aspects. First, the algorithm yields $\tilde{\cal
O}\left(\left(\frac{K^{1.5}}{\delta^2}+d\right)\sqrt{\tau}\right)$ (pseudo)
regret in round $\tau\leq T,$ where $K$ is the number of constraints, $d$ is
the dimension of the reward feature space, and $\delta$ is a Slater's constant;
and zero constraint violation in any round $\tau&gt;\tau',$ where $\tau'$ is
independent of horizon $T.$ Second, the algorithm is computationally efficient.
Our algorithm is based on the primal-dual approach in optimization, and
includes two components. The primal component is similar to unconstrained
stochastic linear bandits (our algorithm uses the linear upper confidence bound
algorithm (LinUCB)). The computational complexity of the dual component depends
on the number of constraints, and is independent of sizes of the contextual
space, the action space, and even the feature space. So the overall
computational complexity of our algorithm is similar to the linear UCB for
unconstrained stochastic linear bandits.
</p>
<a href="http://arxiv.org/abs/2102.05295" target="_blank">arXiv:2102.05295</a> [<a href="http://arxiv.org/pdf/2102.05295" target="_blank">pdf</a>]

<h2>Inductive Granger Causal Modeling for Multivariate Time Series. (arXiv:2102.05298v1 [cs.LG])</h2>
<h3>Yunfei Chu, Xiaowei Wang, Jianxin Ma, Kunyang Jia, Jingren Zhou, Hongxia Yang</h3>
<p>Granger causal modeling is an emerging topic that can uncover Granger causal
relationship behind multivariate time series data. In many real-world systems,
it is common to encounter a large amount of multivariate time series data
collected from different individuals with sharing commonalities. However, there
are ongoing concerns regarding Granger causality's applicability in such large
scale complex scenarios, presenting both challenges and opportunities for
Granger causal structure reconstruction. Existing methods usually train a
distinct model for each individual, suffering from inefficiency and
over-fitting issues. To bridge this gap, we propose an Inductive GRanger cAusal
modeling (InGRA) framework for inductive Granger causality learning and common
causal structure detection on multivariate time series, which exploits the
shared commonalities underlying the different individuals. In particular, we
train one global model for individuals with different Granger causal structures
through a novel attention mechanism, called prototypical Granger causal
attention. The model can detect common causal structures for different
individuals and infer Granger causal structures for newly arrived individuals.
Extensive experiments, as well as an online A/B test on an E-commercial
advertising platform, demonstrate the superior performances of InGRA.
</p>
<a href="http://arxiv.org/abs/2102.05298" target="_blank">arXiv:2102.05298</a> [<a href="http://arxiv.org/pdf/2102.05298" target="_blank">pdf</a>]

<h2>CIFS: Improving Adversarial Robustness of CNNs via Channel-wise Importance-based Feature Selection. (arXiv:2102.05311v1 [cs.LG])</h2>
<h3>Hanshu Yan, Jingfeng Zhang, Gang Niu, Jiashi Feng, Vincent Y. F. Tan, Masashi Sugiyama</h3>
<p>We investigate the adversarial robustness of CNNs from the perspective of
channel-wise activations. By comparing \textit{non-robust} (normally trained)
and \textit{robustified} (adversarially trained) models, we observe that
adversarial training (AT) robustifies CNNs by aligning the channel-wise
activations of adversarial data with those of their natural counterparts.
However, the channels that are \textit{negatively-relevant} (NR) to predictions
are still over-activated when processing adversarial data. Besides, we also
observe that AT does not result in similar robustness for all classes. For the
robust classes, channels with larger activation magnitudes are usually more
\textit{positively-relevant} (PR) to predictions, but this alignment does not
hold for the non-robust classes. Given these observations, we hypothesize that
suppressing NR channels and aligning PR ones with their relevances further
enhances the robustness of CNNs under AT. To examine this hypothesis, we
introduce a novel mechanism, i.e., \underline{C}hannel-wise
\underline{I}mportance-based \underline{F}eature \underline{S}election (CIFS).
The CIFS manipulates channels' activations of certain layers by generating
non-negative multipliers to these channels based on their relevances to
predictions. Extensive experiments on benchmark datasets including CIFAR10 and
SVHN clearly verify the hypothesis and CIFS's effectiveness of robustifying
CNNs.
</p>
<a href="http://arxiv.org/abs/2102.05311" target="_blank">arXiv:2102.05311</a> [<a href="http://arxiv.org/pdf/2102.05311" target="_blank">pdf</a>]

<h2>Improved Algorithms for Efficient Active Learning Halfspaces with Massart and Tsybakov noise. (arXiv:2102.05312v1 [cs.LG])</h2>
<h3>Chicheng Zhang, Yinan Li</h3>
<p>We develop a computationally-efficient PAC active learning algorithm for
$d$-dimensional homogeneous halfspaces that can tolerate Massart
noise~\citep{massart2006risk} and Tsybakov noise~\citep{tsybakov2004optimal}.
Specialized to the $\eta$-Massart noise setting, our algorithm achieves an
information-theoretic optimal label complexity of $\tilde{O}\left(
\frac{d}{(1-2\eta)^2} \mathrm{polylog}(\frac1\epsilon) \right)$ under a wide
range of unlabeled data distributions (specifically, the family of "structured
distributions" defined in~\citet{diakonikolas2020polynomial}). Under the more
challenging Tsybakov noise condition, we identify two subfamilies of noise
conditions, under which our algorithm achieves computational efficiency and
provide label complexity guarantees strictly lower than passive learning
algorithms.
</p>
<a href="http://arxiv.org/abs/2102.05312" target="_blank">arXiv:2102.05312</a> [<a href="http://arxiv.org/pdf/2102.05312" target="_blank">pdf</a>]

<h2>Conditional Versus Adversarial Euler-based Generators For Time Series. (arXiv:2102.05313v1 [stat.ML])</h2>
<h3>Carl Remlinger, Joseph Mikael, Romuald Elie</h3>
<p>We introduce new generative models for time series based on Euler
discretization that do not require any pre-stationarization procedure.
Specifically, we develop two GAN based methods, relying on the adaptation of
Wasserstein GANs (Arjovsky et al., 2017) and DVD GANs (Clark et al., 2019b) to
time series. Alternatively, we consider a conditional Euler Generator (CEGEN)
minimizing a distance between the induced conditional densities. In the context
of It\^o processes, we theoretically validate this approach and demonstrate
using the Bures metric that reaching a low loss level provides accurate
estimations for both the drift and the volatility terms of the underlying
process. Tests on simple models show how the Euler discretization and the use
of Wasserstein distance allow the proposed GANs and (more considerably) CEGEN
to outperform state-of-the-art Time Series GAN generation( Yoon et al., 2019b)
on time structure metrics. In higher dimensions we observe that CEGEN manages
to get the correct covariance structures. Finally we illustrate how our model
can be combined to a Monte Carlo simulator in a low data context by using a
transfer learning technique
</p>
<a href="http://arxiv.org/abs/2102.05313" target="_blank">arXiv:2102.05313</a> [<a href="http://arxiv.org/pdf/2102.05313" target="_blank">pdf</a>]

<h2>Forecasting Nonnegative Time Series via Sliding Mask Method (SMM) and Latent Clustered Forecast (LCF). (arXiv:2102.05314v1 [cs.LG])</h2>
<h3>Yohann de Castro (ICJ, CERMICS), Luca Mencarelli (CERMICS)</h3>
<p>We consider nonnegative time series forecasting framework. Based on recent
advances in Nonnegative Matrix Factorization (NMF) and Archetypal Analysis, we
introduce two procedures referred to as Sliding Mask Method (SMM) and Latent
Clustered Forecast (LCF). SMM is a simple and powerful method based on time
window prediction using Completion of Nonnegative Matrices. This new procedure
combines low nonnegative rank decomposition and matrix completion where the
hidden values are to be forecasted. LCF is two stage: it leverages archetypal
analysis for dimension reduction and clustering of time series, then it uses
any black-box supervised forecast solver on the clustered latent
representation. Theoretical guarantees on uniqueness and robustness of the
solution of NMF Completion-type problems are also provided for the first time.
Finally, numerical experiments on real-world and synthetic data-set confirms
forecasting accuracy for both the methodologies.
</p>
<a href="http://arxiv.org/abs/2102.05314" target="_blank">arXiv:2102.05314</a> [<a href="http://arxiv.org/pdf/2102.05314" target="_blank">pdf</a>]

<h2>Enhancing Real-World Adversarial Patches with 3D Modeling Techniques. (arXiv:2102.05334v1 [cs.CV])</h2>
<h3>Yael Mathov, Lior Rokach, Yuval Elovici</h3>
<p>Although many studies have examined adversarial examples in the real world,
most of them relied on 2D photos of the attack scene; thus, the attacks
proposed cannot address realistic environments with 3D objects or varied
conditions. Studies that use 3D objects are limited, and in many cases, the
real-world evaluation process is not replicable by other researchers,
preventing others from reproducing the results. In this study, we present a
framework that crafts an adversarial patch for an existing real-world scene.
Our approach uses a 3D digital approximation of the scene as a simulation of
the real world. With the ability to add and manipulate any element in the
digital scene, our framework enables the attacker to improve the patch's
robustness in real-world settings. We use the framework to create a patch for
an everyday scene and evaluate its performance using a novel evaluation process
that ensures that our results are reproducible in both the digital space and
the real world. Our evaluation results show that the framework can generate
adversarial patches that are robust to different settings in the real world.
</p>
<a href="http://arxiv.org/abs/2102.05334" target="_blank">arXiv:2102.05334</a> [<a href="http://arxiv.org/pdf/2102.05334" target="_blank">pdf</a>]

<h2>The importance of understanding instance-level noisy labels. (arXiv:2102.05336v1 [cs.LG])</h2>
<h3>Yang Liu</h3>
<p>This paper aims to provide understandings for the effect of an
over-parameterized model, e.g. a deep neural network, memorizing
instance-dependent noisy labels. We first quantify the harms caused by
memorizing noisy instances from different spectra of the sample distribution.
We then analyze how several popular solutions for learning with noisy labels
mitigate this harm at the instance-level. Our analysis reveals new
understandings for when these approaches work, and provides theoretical
justifications for previously reported empirical observations. A key aspect of
the analysis is its focus on each training instance.
</p>
<a href="http://arxiv.org/abs/2102.05336" target="_blank">arXiv:2102.05336</a> [<a href="http://arxiv.org/pdf/2102.05336" target="_blank">pdf</a>]

<h2>On PyTorch Implementation of Density Estimators for von Mises-Fisher and Its Mixture. (arXiv:2102.05340v1 [cs.LG])</h2>
<h3>Minyoung Kim</h3>
<p>The von Mises-Fisher (vMF) is a well-known density model for directional
random variables. The recent surge of the deep embedding methodologies for
high-dimensional structured data such as images or texts, aimed at extracting
salient directional information, can make the vMF model even more popular. In
this article, we will review the vMF model and its mixture, provide detailed
recipes of how to train the models, focusing on the maximum likelihood
estimators, in Python/PyTorch. In particular, implementation of vMF typically
suffers from the notorious numerical issue of the Bessel function evaluation in
the density normalizer, especially when the dimensionality is high, and we
address the issue using the MPMath library that supports arbitrary precision.
For the mixture learning, we provide both minibatch-based large-scale SGD
learning, as well as the EM algorithm which is a full batch estimator. For each
estimator/methodology, we test our implementation on some synthetic data, while
we also demonstrate the use case in a more realistic scenario of image
clustering. Our code is publicly available in
https://github.com/minyoungkim21/vmf-lib.
</p>
<a href="http://arxiv.org/abs/2102.05340" target="_blank">arXiv:2102.05340</a> [<a href="http://arxiv.org/pdf/2102.05340" target="_blank">pdf</a>]

<h2>H3D: Benchmark on Semantic Segmentation of High-Resolution 3D Point Clouds and textured Meshes from UAV LiDAR and Multi-View-Stereo. (arXiv:2102.05346v1 [cs.CV])</h2>
<h3>Michael K&#xf6;lle, Dominik Laupheimer, Stefan Schmohl, Norbert Haala, Franz Rottensteiner, Jan Dirk Wegner, Hugo Ledoux</h3>
<p>Automated semantic segmentation and object detection are of great importance
in the domain of geospatial data analysis. However, supervised Machine Learning
systems such as Convolutional Neural Networks require large corpora of
annotated training data. Especially in the geospatial domain, such datasets are
quite scarce. Within this paper, we aim to alleviate this issue by introducing
a new annotated 3D dataset which is unique in three ways: i) The dataset
consists of both an UAV Laserscanning point cloud and a derived 3D textured
mesh. ii) The point cloud incorporates a mean point density of about 800
pts/sqm and the oblique imagery used for texturing the 3D mesh realizes a
Ground Sampling Distance of about 2-3 cm. This enables detection of
fine-grained structures and represents the state of the art in UAV-based
mapping. iii) Both data modalities will be published for a total of three
epochs allowing applications such as change detection. The dataset depicts the
village of Hessigheim (Germany), henceforth referred to as H3D. It is designed
for promoting research in the field of 3D data analysis on one hand and to
evaluate and rank existing and emerging approaches for semantic segmentation of
both data modalities on the other hand. Ultimatively, H3D is supposed to become
a new benchmark dataset in company with the well-established ISPRS Vaihingen 3D
Semantic Labeling Challenge benchmark (V3D). The dataset can be retrieved from
https://ifpwww.ifp.uni-stuttgart.de/benchmark/hessigheim/default.aspx.
</p>
<a href="http://arxiv.org/abs/2102.05346" target="_blank">arXiv:2102.05346</a> [<a href="http://arxiv.org/pdf/2102.05346" target="_blank">pdf</a>]

<h2>Simple and Near-Optimal MAP Inference for Nonsymmetric DPPs. (arXiv:2102.05347v1 [cs.LG])</h2>
<h3>Nima Anari, Thuy-Duong Vuong</h3>
<p>Determinantal point processes (DPPs) are widely popular probabilistic models
used in machine learning to capture diversity in random subsets of items. While
traditional DPPs are defined by a symmetric kernel matrix, recent work has
shown a significant increase in the modeling power and applicability of models
defined by nonsymmetric kernels, where the model can capture interactions that
go beyond diversity. We study the problem of maximum a posteriori (MAP)
inference for determinantal point processes defined by a nonsymmetric positive
semidefinite matrix (NDPPs), where the goal is to find the maximum $k\times k$
principal minor of the kernel matrix $L$. We obtain the first multiplicative
approximation guarantee for this problem using local search, a method that has
been previously applied to symmetric DPPs. Our approximation factor of
$k^{O(k)}$ is nearly tight, and we show theoretically and experimentally that
it compares favorably to the state-of-the-art methods for this problem that are
based on greedy maximization. The main new insight enabling our improved
approximation factor is that we allow local search to update up to two elements
of the solution in each iteration, and we show this is necessary to have any
multiplicative approximation guarantee.
</p>
<a href="http://arxiv.org/abs/2102.05347" target="_blank">arXiv:2102.05347</a> [<a href="http://arxiv.org/pdf/2102.05347" target="_blank">pdf</a>]

<h2>Regional Attention with Architecture-Rebuilt 3D Network for RGB-D Gesture Recognition. (arXiv:2102.05348v1 [cs.CV])</h2>
<h3>Benjia Zhou, Yunan Li, Jun Wan</h3>
<p>Human gesture recognition has drawn much attention in the area of computer
vision. However, the performance of gesture recognition is always influenced by
some gesture-irrelevant factors like the background and the clothes of
performers. Therefore, focusing on the regions of hand/arm is important to the
gesture recognition. Meanwhile, a more adaptive architecture-searched network
structure can also perform better than the block-fixed ones like Resnet since
it increases the diversity of features in different stages of the network
better. In this paper, we propose a regional attention with
architecture-rebuilt 3D network (RAAR3DNet) for gesture recognition. We replace
the fixed Inception modules with the automatically rebuilt structure through
the network via Neural Architecture Search (NAS), owing to the different shape
and representation ability of features in the early, middle, and late stage of
the network. It enables the network to capture different levels of feature
representations at different layers more adaptively. Meanwhile, we also design
a stackable regional attention module called dynamic-static Attention (DSA),
which derives a Gaussian guidance heatmap and dynamic motion map to highlight
the hand/arm regions and the motion information in the spatial and temporal
domains, respectively. Extensive experiments on two recent large-scale RGB-D
gesture datasets validate the effectiveness of the proposed method and show it
outperforms state-of-the-art methods. The codes of our method are available at:
https://github.com/zhoubenjia/RAAR3DNet.
</p>
<a href="http://arxiv.org/abs/2102.05348" target="_blank">arXiv:2102.05348</a> [<a href="http://arxiv.org/pdf/2102.05348" target="_blank">pdf</a>]

<h2>Towards Certifying $\ell_\infty$ Robustness using Neural Networks with $\ell_\infty$-dist Neurons. (arXiv:2102.05363v1 [cs.LG])</h2>
<h3>Bohang Zhang, Tianle Cai, Zhou Lu, Di He, Liwei Wang</h3>
<p>It is well-known that standard neural networks, even with a high
classification accuracy, are vulnerable to small $\ell_\infty$-norm bounded
adversarial perturbations. Although many attempts have been made, most previous
works either can only provide empirical verification of the defense to a
particular attack method, or can only develop a certified guarantee of the
model robustness in limited scenarios. In this paper, we seek for a new
approach to develop a theoretically principled neural network that inherently
resists $\ell_\infty$ perturbations. In particular, we design a novel neuron
that uses $\ell_\infty$-distance as its basic operation (which we call
$\ell_\infty$-dist neuron), and show that any neural network constructed with
$\ell_\infty$-dist neurons (called $\ell_{\infty}$-dist net) is naturally a
1-Lipschitz function with respect to $\ell_\infty$-norm. This directly provides
a rigorous guarantee of the certified robustness based on the margin of
prediction outputs. We also prove that such networks have enough expressive
power to approximate any 1-Lipschitz function with robust generalization
guarantee. Our experimental results show that the proposed network is
promising. Using $\ell_{\infty}$-dist nets as the basic building blocks, we
consistently achieve state-of-the-art performance on commonly used datasets:
93.09% certified accuracy on MNIST ($\epsilon=0.3$), 79.23% on Fashion MNIST
($\epsilon=0.1$) and 35.10% on CIFAR-10 ($\epsilon=8/255$).
</p>
<a href="http://arxiv.org/abs/2102.05363" target="_blank">arXiv:2102.05363</a> [<a href="http://arxiv.org/pdf/2102.05363" target="_blank">pdf</a>]

<h2>RoBIC: A benchmark suite for assessing classifiers robustness. (arXiv:2102.05368v1 [cs.CV])</h2>
<h3>Thibault Maho, Beno&#xee;t Bonnet, Teddy Furon, Erwan Le Merrer</h3>
<p>Many defenses have emerged with the development of adversarial attacks.
Models must be objectively evaluated accordingly. This paper systematically
tackles this concern by proposing a new parameter-free benchmark we coin RoBIC.
RoBIC fairly evaluates the robustness of image classifiers using a new
half-distortion measure. It gauges the robustness of the network against white
and black box attacks, independently of its accuracy. RoBIC is faster than the
other available benchmarks. We present the significant differences in the
robustness of 16 recent models as assessed by RoBIC.
</p>
<a href="http://arxiv.org/abs/2102.05368" target="_blank">arXiv:2102.05368</a> [<a href="http://arxiv.org/pdf/2102.05368" target="_blank">pdf</a>]

<h2>Risk-Averse Offline Reinforcement Learning. (arXiv:2102.05371v1 [cs.LG])</h2>
<h3>N&#xfa;ria Armengol Urp&#xed;, Sebastian Curi, Andreas Krause</h3>
<p>Training Reinforcement Learning (RL) agents in high-stakes applications might
be too prohibitive due to the risk associated to exploration. Thus, the agent
can only use data previously collected by safe policies. While previous work
considers optimizing the average performance using offline data, we focus on
optimizing a risk-averse criteria, namely the CVaR. In particular, we present
the Offline Risk-Averse Actor-Critic (O-RAAC), a model-free RL algorithm that
is able to learn risk-averse policies in a fully offline setting. We show that
O-RAAC learns policies with higher CVaR than risk-neutral approaches in
different robot control tasks. Furthermore, considering risk-averse criteria
guarantees distributional robustness of the average performance with respect to
particular distribution shifts. We demonstrate empirically that in the presence
of natural distribution-shifts, O-RAAC learns policies with good average
performance.
</p>
<a href="http://arxiv.org/abs/2102.05371" target="_blank">arXiv:2102.05371</a> [<a href="http://arxiv.org/pdf/2102.05371" target="_blank">pdf</a>]

<h2>GuiltyWalker: Distance to illicit nodes in the Bitcoin network. (arXiv:2102.05373v1 [cs.LG])</h2>
<h3>Catarina Oliveira, Jo&#xe3;o Torres, Maria In&#xea;s Silva, David Apar&#xed;cio, Jo&#xe3;o Tiago Ascens&#xe3;o, Pedro Bizarro</h3>
<p>Money laundering is a global phenomenon with wide-reaching social and
economic consequences. Cryptocurrencies are particularly susceptible due to the
lack of control by authorities and their anonymity. Thus, it is important to
develop new techniques to detect and prevent illicit cryptocurrency
transactions. In our work, we propose new features based on the structure of
the graph and past labels to boost the performance of machine learning methods
to detect money laundering. Our method, GuiltyWalker, performs random walks on
the bitcoin transaction graph and computes features based on the distance to
illicit transactions. We combine these new features with features proposed by
Weber et al. and observe an improvement of about 5pp regarding illicit
classification. Namely, we observe that our proposed features are particularly
helpful during a black market shutdown, where the algorithm by Weber et al. was
low performing.
</p>
<a href="http://arxiv.org/abs/2102.05373" target="_blank">arXiv:2102.05373</a> [<a href="http://arxiv.org/pdf/2102.05373" target="_blank">pdf</a>]

<h2>On Minibatch Noise: Discrete-Time SGD, Overparametrization, and Bayes. (arXiv:2102.05375v1 [cs.LG])</h2>
<h3>Liu Ziyin, Kangqiao Liu, Takashi Mori, Masahito Ueda</h3>
<p>The noise in stochastic gradient descent (SGD), caused by minibatch sampling,
remains poorly understood despite its enormous practical importance in offering
good training efficiency and generalization ability. In this work, we study the
minibatch noise in SGD. Motivated by the observation that minibatch sampling
does not always cause a fluctuation, we set out to find the conditions that
cause minibatch noise to emerge. We first derive the analytically solvable
results for linear regression under various settings, which are compared to the
commonly used approximations that are used to understand SGD noise. We show
that some degree of mismatch between model and data complexity is needed in
order for SGD to "cause" a noise, and that such mismatch may be due to the
existence of static noise in the labels, in the input, the use of
regularization, or underparametrization. Our results motivate a more accurate
general formulation to describe minibatch noise.
</p>
<a href="http://arxiv.org/abs/2102.05375" target="_blank">arXiv:2102.05375</a> [<a href="http://arxiv.org/pdf/2102.05375" target="_blank">pdf</a>]

<h2>Origami spring-inspired shape morphing for flexible robotics. (arXiv:2102.05378v1 [cs.RO])</h2>
<h3>Qianying Chen, Fan Feng, Pengyu Lv, Huiling Duan</h3>
<p>Flexible robotics are capable of achieving various functionalities by shape
morphing, benefiting from their compliant bodies and reconfigurable structures.
Here we construct and study a class of origami springs generalized from the
known interleaved origami spring, as promising candidates for shape morphing in
flexible robotics. These springs are found to exhibit nonlinear stretch-twist
coupling and linear/nonlinear mechanical response in the compression/tension
region, analyzed by the demonstrated continuum mechanics models, experiments,
and finite element simulations. To improve the mechanical performance such as
the damage resistance, we establish an origami rigidization method by adding
additional creases to the spring system. Guided by the theoretical framework,
we experimentally realize three types of flexible robotics -- origami spring
ejectors, crawlers, and a transformer, which show the desired functionality and
outstanding mechanical performance. The proposed concept of origami-aided
design is expected to pave the way to facilitate diverse shape morphing of
flexible robotics.
</p>
<a href="http://arxiv.org/abs/2102.05378" target="_blank">arXiv:2102.05378</a> [<a href="http://arxiv.org/pdf/2102.05378" target="_blank">pdf</a>]

<h2>Argmax Flows and Multinomial Diffusion: Towards Non-Autoregressive Language Models. (arXiv:2102.05379v1 [stat.ML])</h2>
<h3>Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forr&#xe9;, Max Welling</h3>
<p>The field of language modelling has been largely dominated by autoregressive
models, for which sampling is inherently difficult to parallelize. This paper
introduces two new classes of generative models for categorical data such as
language or image segmentation: Argmax Flows and Multinomial Diffusion. Argmax
Flows are defined by a composition of a continuous distribution (such as a
normalizing flow), and an argmax function. To optimize this model, we learn a
probabilistic inverse for the argmax that lifts the categorical data to a
continuous space. Multinomial Diffusion gradually adds categorical noise in a
diffusion process, for which the generative denoising process is learned. We
demonstrate that our models perform competitively on language modelling and
modelling of image segmentation maps.
</p>
<a href="http://arxiv.org/abs/2102.05379" target="_blank">arXiv:2102.05379</a> [<a href="http://arxiv.org/pdf/2102.05379" target="_blank">pdf</a>]

<h2>Learning Interaction-Aware Trajectory Predictions for Decentralized Multi-Robot Motion Planning in Dynamic Environments. (arXiv:2102.05382v1 [cs.RO])</h2>
<h3>Hai Zhu, Francisco Martinez Claramunt, Bruno Brito, Javier Alonso-Mora</h3>
<p>This paper presents a data-driven decentralized trajectory optimization
approach for multi-robot motion planning in dynamic environments. When
navigating in a shared space, each robot needs accurate motion predictions of
neighboring robots to achieve predictive collision avoidance. These motion
predictions can be obtained among robots by sharing their future planned
trajectories with each other via communication. However, such communication may
not be available nor reliable in practice. In this paper, we introduce a novel
trajectory prediction model based on recurrent neural networks (RNN) that can
learn multi-robot motion behaviors from demonstrated trajectories generated
using a centralized sequential planner. The learned model can run efficiently
online for each robot and provide interaction-aware trajectory predictions of
its neighbors based on observations of their history states. We then
incorporate the trajectory prediction model into a decentralized model
predictive control (MPC) framework for multi-robot collision avoidance.
Simulation results show that our decentralized approach can achieve a
comparable level of performance to a centralized planner while being
communication-free and scalable to a large number of robots. We also validate
our approach with a team of quadrotors in real-world experiments.
</p>
<a href="http://arxiv.org/abs/2102.05382" target="_blank">arXiv:2102.05382</a> [<a href="http://arxiv.org/pdf/2102.05382" target="_blank">pdf</a>]

<h2>Improving Aerial Instance Segmentation in the Dark with Self-Supervised Low Light Enhancement. (arXiv:2102.05399v1 [cs.CV])</h2>
<h3>Prateek Garg, Murari Mandal, Pratik Narang</h3>
<p>Low light conditions in aerial images adversely affect the performance of
several vision based applications. There is a need for methods that can
efficiently remove the low light attributes and assist in the performance of
key vision tasks. In this work, we propose a new method that is capable of
enhancing the low light image in a self-supervised fashion, and sequentially
apply detection and segmentation tasks in an end-to-end manner. The proposed
method occupies a very small overhead in terms of memory and computational
power over the original algorithm and delivers superior results. Additionally,
we propose the generation of a new low light aerial dataset using GANs, which
can be used to evaluate vision based networks for similar adverse conditions.
</p>
<a href="http://arxiv.org/abs/2102.05399" target="_blank">arXiv:2102.05399</a> [<a href="http://arxiv.org/pdf/2102.05399" target="_blank">pdf</a>]

<h2>Enhancing efficiency of object recognition in different categorization levels by reinforcement learning in modular spiking neural networks. (arXiv:2102.05401v1 [cs.CV])</h2>
<h3>Fatemeh Sharifizadeh, Mohammad Ganjtabesh, Abbas Nowzari-Dalini</h3>
<p>The human visual system contains a hierarchical sequence of modules that take
part in visual perception at superordinate, basic, and subordinate
categorization levels. During the last decades, various computational models
have been proposed to mimic the hierarchical feed-forward processing of visual
cortex, but many critical characteristics of the visual system, such actual
neural processing and learning mechanisms, are ignored. Pursuing the line of
biological inspiration, we propose a computational model for object recognition
in different categorization levels, in which a spiking neural network equipped
with the reinforcement learning rule is used as a module at each categorization
level. Each module solves the object recognition problem at each categorization
level, solely based on the earliest spike of class-specific neurons at its last
layer, without using any external classifier. According to the required
information at each categorization level, the relevant band-pass filtered
images are utilized. The performance of our proposed model is evaluated by
various appraisal criteria with three benchmark datasets and significant
improvement in recognition accuracy of our proposed model is achieved in all
experiments.
</p>
<a href="http://arxiv.org/abs/2102.05401" target="_blank">arXiv:2102.05401</a> [<a href="http://arxiv.org/pdf/2102.05401" target="_blank">pdf</a>]

<h2>Application of Yolo on Mask Detection Task. (arXiv:2102.05402v1 [cs.CV])</h2>
<h3>Ren Liu, Ziang Ren</h3>
<p>2020 has been a year marked by the COVID-19 pandemic. This event has caused
disruptions to many aspects of normal life. An important aspect in reducing the
impact of the pandemic is to control its spread. Studies have shown that one
effective method in reducing the transmission of COVID-19 is to wear masks.
Strict mask-wearing policies have been met with not only public sensation but
also practical difficulty. We cannot hope to manually check if everyone on a
street is wearing a mask properly. Existing technology to help automate mask
checking uses deep learning models on real-time surveillance camera footages.
The current dominant method to perform real-time mask detection uses Mask-RCNN
with ResNet as the backbone. While giving good detection results, this method
is computationally intensive and its efficiency in real-time face mask
detection is not ideal. Our research proposes a new approach to mask detection
by replacing Mask-R-CNN with a more efficient model "YOLO" to increase the
processing speed of real-time mask detection and not compromise on accuracy.
Besides, given the small volume as well as extreme imbalance of the mask
detection datasets, we adopt a latest progress made in few-shot visual
classification, simple CNAPs, to improve the classification performance.
</p>
<a href="http://arxiv.org/abs/2102.05402" target="_blank">arXiv:2102.05402</a> [<a href="http://arxiv.org/pdf/2102.05402" target="_blank">pdf</a>]

<h2>Non-stationary Reinforcement Learning without Prior Knowledge: An Optimal Black-box Approach. (arXiv:2102.05406v1 [cs.LG])</h2>
<h3>Chen-Yu Wei, Haipeng Luo</h3>
<p>We propose a black-box reduction that turns a certain reinforcement learning
algorithm with optimal regret in a (near-)stationary environment into another
algorithm with optimal dynamic regret in a non-stationary environment,
importantly without any prior knowledge on the degree of non-stationarity. By
plugging different algorithms into our black-box, we provide a list of examples
showing that our approach not only recovers recent results for (contextual)
multi-armed bandits achieved by very specialized algorithms, but also
significantly improves the state of the art for linear bandits, episodic MDPs,
and infinite-horizon MDPs in various ways. Specifically, in most cases our
algorithm achieves the optimal dynamic regret
$\widetilde{\mathcal{O}}(\min\{\sqrt{LT}, \Delta^{1/3}T^{2/3}\})$ where $T$ is
the number of rounds and $L$ and $\Delta$ are the number and amount of changes
of the world respectively, while previous works only obtain suboptimal bounds
and/or require the knowledge of $L$ and $\Delta$.
</p>
<a href="http://arxiv.org/abs/2102.05406" target="_blank">arXiv:2102.05406</a> [<a href="http://arxiv.org/pdf/2102.05406" target="_blank">pdf</a>]

<h2>Manipulability optimization for multi-arm teleoperation. (arXiv:2102.05414v1 [cs.RO])</h2>
<h3>Florian Kennel-Maushart, Roi Poranne, Stelian Coros</h3>
<p>Teleoperation provides a way for human operators to guide robots in
situations where full autonomy is challenging or where direct human
intervention is required. It can also be an important tool to teach robots in
order to achieve autonomous behaviour later on. The increased availability of
collaborative robot arms and Virtual Reality (VR) devices provides ample
opportunity for development of novel teleoperation methods. Since robot arms
are often kinematically different from human arms, mapping human motions to a
robot in real-time is not trivial. Additionally, a human operator might steer
the robot arm toward singularities or its workspace limits, which can lead to
undesirable behaviour. This is further accentuated for the orchestration of
multiple robots. In this paper, we present a VR interface targeted to multi-arm
payload manipulation, which can closely match real-time input motion. Allowing
the user to manipulate the payload rather than mapping their motions to
individual arms we are able to simultaneously guide multiple collaborative
arms. By releasing a single rotational degree of freedom, and by using a local
optimization method, we can improve each arm's manipulability index, which in
turn lets us avoid kinematic singularities and workspace limitations. We apply
our approach to predefined trajectories as well as real-time teleoperation on
different robot arms and compare performance in terms of end effector position
error and relevant joint motion metrics.
</p>
<a href="http://arxiv.org/abs/2102.05414" target="_blank">arXiv:2102.05414</a> [<a href="http://arxiv.org/pdf/2102.05414" target="_blank">pdf</a>]

<h2>Doctor Imitator: A Graph-based Bone Age Assessment Framework Using Hand Radiographs. (arXiv:2102.05424v1 [cs.CV])</h2>
<h3>Jintai Chen, Bohan Yu, Biwen Lei, Ruiwei Feng, Danny Z. Chen, Jian Wu</h3>
<p>Bone age assessment is challenging in clinical practice due to the
complicated bone age assessment process. Current automatic bone age assessment
methods were designed with rare consideration of the diagnostic logistics and
thus may yield certain uninterpretable hidden states and outputs. Consequently,
doctors can find it hard to cooperate with such models harmoniously because it
is difficult to check the correctness of the model predictions. In this work,
we propose a new graph-based deep learning framework for bone age assessment
with hand radiographs, called Doctor Imitator (DI). The architecture of DI is
designed to learn the diagnostic logistics of doctors using the scoring methods
(e.g., the Tanner-Whitehouse method) for bone age assessment. Specifically, the
convolutions of DI capture the local features of the anatomical regions of
interest (ROIs) on hand radiographs and predict the ROI scores by our proposed
Anatomy-based Group Convolution, summing up for bone age prediction. Besides,
we develop a novel Dual Graph-based Attention module to compute
patient-specific attention for ROI features and context attention for ROI
scores. As far as we know, DI is the first automatic bone age assessment
framework following the scoring methods without fully supervised hand
radiographs. Experiments on hand radiographs with only bone age supervision
verify that DI can achieve excellent performance with sparse parameters and
provide more interpretability.
</p>
<a href="http://arxiv.org/abs/2102.05424" target="_blank">arXiv:2102.05424</a> [<a href="http://arxiv.org/pdf/2102.05424" target="_blank">pdf</a>]

<h2>BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction. (arXiv:2102.05426v1 [cs.LG])</h2>
<h3>Yuhang Li, Ruihao Gong, Xu Tan, Yang Yang, Peng Hu, Qi Zhang, Fengwei Yu, Wei Wang, Shi Gu</h3>
<p>We study the challenging task of neural network quantization without
end-to-end retraining, called Post-training Quantization (PTQ). PTQ usually
requires a small subset of training data but produces less powerful quantized
models than Quantization-Aware Training (QAT). In this work, we propose a novel
PTQ framework, dubbed BRECQ, which pushes the limits of bitwidth in PTQ down to
INT2 for the first time. BRECQ leverages the basic building blocks in neural
networks and reconstructs them one-by-one. In a comprehensive theoretical study
of the second-order error, we show that BRECQ achieves a good balance between
cross-layer dependency and generalization error. To further employ the power of
quantization, the mixed precision technique is incorporated in our framework by
approximating the inter-layer and intra-layer sensitivity. Extensive
experiments on various handcrafted and searched neural architectures are
conducted for both image classification and object detection tasks. And for the
first time we prove that, without bells and whistles, PTQ can attain 4-bit
ResNet and MobileNetV2 comparable with QAT and enjoy 240 times faster
production of quantized models. Codes are available at
https://github.com/yhhhli/BRECQ.
</p>
<a href="http://arxiv.org/abs/2102.05426" target="_blank">arXiv:2102.05426</a> [<a href="http://arxiv.org/pdf/2102.05426" target="_blank">pdf</a>]

<h2>MAIN: Multihead-Attention Imputation Networks. (arXiv:2102.05428v1 [cs.LG])</h2>
<h3>Spyridon Mouselinos, Kyriakos Polymenakos, Antonis Nikitakis, Konstantinos Kyriakopoulos</h3>
<p>The problem of missing data, usually absent incurated and
competition-standard datasets, is an unfortunate reality for most machine
learning models used in industry applications. Recent work has focused on
understanding the nature and the negative effects of such phenomena, while
devising solutions for optimal imputation of the missing data, using both
discriminative and generative approaches. We propose a novel mechanism based on
multi-head attention which can be applied effortlessly in any model and
achieves better downstream performance without the introduction of the full
dataset in any part of the modeling pipeline. Our method inductively models
patterns of missingness in the input data in order to increase the performance
of the downstream task. Finally, after evaluating our method against baselines
for a number of datasets, we found performance gains that tend to be larger in
scenarios of high missingness.
</p>
<a href="http://arxiv.org/abs/2102.05428" target="_blank">arXiv:2102.05428</a> [<a href="http://arxiv.org/pdf/2102.05428" target="_blank">pdf</a>]

<h2>Searching for Alignment in Face Recognition. (arXiv:2102.05447v1 [cs.CV])</h2>
<h3>Xiaqing Xu, Qiang Meng, Yunxiao Qin, Jianzhu Guo, Chenxu Zhao, Feng Zhou, Zhen Lei</h3>
<p>A standard pipeline of current face recognition frameworks consists of four
individual steps: locating a face with a rough bounding box and several
fiducial landmarks, aligning the face image using a pre-defined template,
extracting representations and comparing. Among them, face detection, landmark
detection and representation learning have long been studied and a lot of works
have been proposed. As an essential step with a significant impact on
recognition performance, the alignment step has attracted little attention. In
this paper, we first explore and highlight the effects of different alignment
templates on face recognition. Then, for the first time, we try to search for
the optimal template automatically. We construct a well-defined searching space
by decomposing the template searching into the crop size and vertical shift,
and propose an efficient method Face Alignment Policy Search (FAPS). Besides, a
well-designed benchmark is proposed to evaluate the searched policy.
Experiments on our proposed benchmark validate the effectiveness of our method
to improve face recognition performance.
</p>
<a href="http://arxiv.org/abs/2102.05447" target="_blank">arXiv:2102.05447</a> [<a href="http://arxiv.org/pdf/2102.05447" target="_blank">pdf</a>]

<h2>Two Novel Performance Improvements for Evolving CNN Topologies. (arXiv:2102.05451v1 [cs.CV])</h2>
<h3>Yaron Strauch (University of Southampton), Jo Grundy (University of Southampton)</h3>
<p>Convolutional Neural Networks (CNNs) are the state-of-the-art algorithms for
the processing of images. However the configuration and training of these
networks is a complex task requiring deep domain knowledge, experience and much
trial and error. Using genetic algorithms, competitive CNN topologies for image
recognition can be produced for any specific purpose, however in previous work
this has come at high computational cost. In this work two novel approaches are
presented to the utilisation of these algorithms, effective in reducing
complexity and training time by nearly 20%. This is accomplished via
regularisation directly on training time, and the use of partial training to
enable early ranking of individual architectures. Both approaches are validated
on the benchmark CIFAR10 data set, and maintain accuracy.
</p>
<a href="http://arxiv.org/abs/2102.05451" target="_blank">arXiv:2102.05451</a> [<a href="http://arxiv.org/pdf/2102.05451" target="_blank">pdf</a>]

<h2>On the Robustness of Multi-View Rotation Averaging. (arXiv:2102.05454v1 [cs.CV])</h2>
<h3>Xinyi Li, Haibin Ling</h3>
<p>Rotation averaging is a synchronization process on single or multiple
rotation groups, and is a fundamental problem in many computer vision tasks
such as multi-view structure from motion (SfM). Specifically, rotation
averaging involves the recovery of an underlying pose-graph consistency from
pairwise relative camera poses. Specifically, given pairwise motion in rotation
groups, especially 3-dimensional rotation groups (\eg, $\mathbb{SO}(3)$), one
is interested in recovering the original signal of multiple rotations with
respect to a fixed frame. In this paper, we propose a robust framework to solve
multiple rotation averaging problem, especially in the cases that a significant
amount of noisy measurements are present. By introducing the $\epsilon$-cycle
consistency term into the solver, we enable the robust initialization scheme to
be implemented into the IRLS solver. Instead of conducting the costly edge
removal, we implicitly constrain the negative effect of erroneous measurements
by weight reducing, such that IRLS failures caused by poor initialization can
be effectively avoided. Experiment results demonstrate that our proposed
approach outperforms state of the arts on various benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.05454" target="_blank">arXiv:2102.05454</a> [<a href="http://arxiv.org/pdf/2102.05454" target="_blank">pdf</a>]

<h2>Belief Space Planning for Mobile Robots with Range Sensors using iLQG. (arXiv:2102.05466v1 [cs.RO])</h2>
<h3>Ke Sun, Vijay Kumar</h3>
<p>In this work, we use iterative Linear Quadratic Gaussian (iLQG) to plan
motions for a mobile robot with range sensors in belief space. We address two
limitations that prevent applications of iLQG to the considered robotic system.
First, iLQG assumes a differentiable measurement model, which is not true for
range sensors. We show that iLQG only requires the differentiability of the
belief dynamics. We propose to use a derivative-free filter to approximate the
belief dynamics, which does not require explicit differentiability of the
measurement model. Second, informative measurements from a range sensor are
sparse. Uninformative measurements produce trivial gradient information, which
prevent iLQG optimization from converging to a local minimum. We densify the
informative measurements by introducing additional parameters in the
measurement model. The parameters are iteratively updated in the optimization
to ensure convergence to the true measurement model of a range sensor. We show
the effectiveness of the proposed modifications through an ablation study. We
also apply the proposed method in simulations of large scale real world
environments, which show superior performance comparing to the state-of-the-art
methods that either assume the separation principle or maximum likelihood
measurements.
</p>
<a href="http://arxiv.org/abs/2102.05466" target="_blank">arXiv:2102.05466</a> [<a href="http://arxiv.org/pdf/2102.05466" target="_blank">pdf</a>]

<h2>Robust estimation of tree structured models. (arXiv:2102.05472v1 [stat.ML])</h2>
<h3>Marta Casanellas, Marina Garrote-L&#xf3;pez, Piotr Zwiernik</h3>
<p>Consider the problem of learning undirected graphical models on trees from
corrupted data. Recently Katiyar et al. showed that it is possible to recover
trees from noisy binary data up to a small equivalence class of possible trees.
Their other paper on the Gaussian case follows a similar pattern. By framing
this as a special phylogenetic recovery problem we largely generalize these two
settings. Using the framework of linear latent tree models we discuss tree
identifiability for binary data under a continuous corruption model. For the
Ising and the Gaussian tree model we also provide a characterisation of when
the Chow-Liu algorithm consistently learns the underlying tree from the noisy
data.
</p>
<a href="http://arxiv.org/abs/2102.05472" target="_blank">arXiv:2102.05472</a> [<a href="http://arxiv.org/pdf/2102.05472" target="_blank">pdf</a>]

<h2>Adversarial Robustness: What fools you makes you stronger. (arXiv:2102.05475v1 [cs.LG])</h2>
<h3>Grzegorz G&#x142;uch, R&#xfc;diger Urbanke</h3>
<p>We prove an exponential separation for the sample complexity between the
standard PAC-learning model and a version of the Equivalence-Query-learning
model. We then show that this separation has interesting implications for
adversarial robustness. We explore a vision of designing an adaptive defense
that in the presence of an attacker computes a model that is provably robust.
In particular, we show how to realize this vision in a simplified setting.

In order to do so, we introduce a notion of a strong adversary: he is not
limited by the type of perturbations he can apply but when presented with a
classifier can repetitively generate different adversarial examples. We explain
why this notion is interesting to study and use it to prove the following.
There exists an efficient adversarial-learning-like scheme such that for every
strong adversary $\mathbf{A}$ it outputs a classifier that (a) cannot be
strongly attacked by $\mathbf{A}$, or (b) has error at most $\epsilon$. In both
cases our scheme uses exponentially (in $\epsilon$) fewer samples than what the
PAC bound requires.
</p>
<a href="http://arxiv.org/abs/2102.05475" target="_blank">arXiv:2102.05475</a> [<a href="http://arxiv.org/pdf/2102.05475" target="_blank">pdf</a>]

<h2>On the Suboptimality of Thompson Sampling in High Dimensions. (arXiv:2102.05502v1 [stat.ML])</h2>
<h3>Raymond Zhang, Richard Combes</h3>
<p>In this paper we consider Thompson Sampling for combinatorial semi-bandits.
We demonstrate that, perhaps surprisingly, Thompson Sampling is sub-optimal for
this problem in the sense that its regret scales exponentially in the ambient
dimension, and its minimax regret scales almost linearly. This phenomenon
occurs under a wide variety of assumptions including both non-linear and linear
reward functions. We also show that including a fixed amount of forced
exploration to Thompson Sampling does not alleviate the problem. We complement
our theoretical results with numerical results and show that in practice
Thompson Sampling indeed can perform very poorly in high dimensions.
</p>
<a href="http://arxiv.org/abs/2102.05502" target="_blank">arXiv:2102.05502</a> [<a href="http://arxiv.org/pdf/2102.05502" target="_blank">pdf</a>]

<h2>On Disentanglement in Gaussian Process Variational Autoencoders. (arXiv:2102.05507v1 [stat.ML])</h2>
<h3>Simon Bing, Vincent Fortuin, Gunnar R&#xe4;tsch</h3>
<p>Complex multivariate time series arise in many fields, ranging from computer
vision to robotics or medicine. Often we are interested in the independent
underlying factors that give rise to the high-dimensional data we are
observing. While many models have been introduced to learn such disentangled
representations, only few attempt to explicitly exploit the structure of
sequential data. We investigate the disentanglement properties of Gaussian
process variational autoencoders, a class of models recently introduced that
have been successful in different tasks on time series data. Our model exploits
the temporal structure of the data by modeling each latent channel with a GP
prior and employing a structured variational distribution that can capture
dependencies in time. We demonstrate the competitiveness of our approach
against state-of-the-art unsupervised and weakly-supervised disentanglement
methods on a benchmark task. Moreover, we provide evidence that we can learn
meaningful disentangled representations on real-world medical time series data.
</p>
<a href="http://arxiv.org/abs/2102.05507" target="_blank">arXiv:2102.05507</a> [<a href="http://arxiv.org/pdf/2102.05507" target="_blank">pdf</a>]

<h2>Robustness in Compressed Neural Networks for Object Detection. (arXiv:2102.05509v1 [cs.LG])</h2>
<h3>Sebastian Cygert, Andrzej Czyzewski</h3>
<p>Model compression techniques allow to significantly reduce the computational
cost associated with data processing by deep neural networks with only a minor
decrease in average accuracy. Simultaneously, reducing the model size may have
a large effect on noisy cases or objects belonging to less frequent classes. It
is a crucial problem from the perspective of the models' safety, especially for
object detection in the autonomous driving setting, which is considered in this
work. It was shown in the paper that the sensitivity of compressed models to
different distortion types is nuanced, and some of the corruptions are heavily
impacted by the compression methods (i.e., additive noise), while others (blur
effect) are only slightly affected. A common way to improve the robustness of
models is to use data augmentation, which was confirmed to positively affect
models' robustness, also for highly compressed models. It was further shown
that while data imbalance methods brought only a slight increase in accuracy
for the baseline model (without compression), the impact was more striking at
higher compression rates for the structured pruning. Finally, methods for
handling data imbalance brought a significant improvement of the pruned models'
worst-detected class accuracy.
</p>
<a href="http://arxiv.org/abs/2102.05509" target="_blank">arXiv:2102.05509</a> [<a href="http://arxiv.org/pdf/2102.05509" target="_blank">pdf</a>]

<h2>Detecting corruption in single-bidder auctions via positive-unlabelled learning. (arXiv:2102.05523v1 [cs.LG])</h2>
<h3>Natalya Goryunova, Artem Baklanov, Egor Ianovski</h3>
<p>In research and policy-making guidelines, the single-bidder rate is a
commonly used proxy of corruption in public procurement used but ipso facto
this is not evidence of a corrupt auction, but an uncompetitive auction. And
while an uncompetitive auction could arise due to a corrupt procurer attempting
to conceal the transaction, but it could also be a result of geographic
isolation, monopolist presence, or other structural factors. In this paper we
use positive-unlabelled classification to attempt to separate public
procurement auctions in the Russian Federation into auctions that are probably
fair, and those that are suspicious.
</p>
<a href="http://arxiv.org/abs/2102.05523" target="_blank">arXiv:2102.05523</a> [<a href="http://arxiv.org/pdf/2102.05523" target="_blank">pdf</a>]

<h2>Dynamic $\beta$-VAEs for quantifying biodiversity by clustering optically recorded insect signals. (arXiv:2102.05526v1 [cs.LG])</h2>
<h3>Klas Rydhmer, Raghavendra Selvan</h3>
<p>While insects are the largest and most diverse group of animals, constituting
ca. 80% of all known species, they are difficult to study due to their small
size and similarity between species. Conventional monitoring techniques depend
on time consuming trapping methods and tedious microscope-based work by skilled
experts in order to identify the caught insect specimen at species, or even
family, level. Researchers and policy makers are in urgent need of a scalable
monitoring tool in order to conserve biodiversity and secure human food
production due to the rapid decline in insect numbers. Recent work has aimed
for a broader analysis using unsupervised clustering as a proxy for
conventional biodiversity measures, such as species richness and species
evenness, without actually identifying the species of the detected target.

In order to improve upon existing insect clustering methods, we propose an
adaptive variant of the variational autoencoder (VAE) which is capable of
clustering data by phylogenetic groups. The proposed Dynamic $\beta$-VAE
dynamically adapts the scaling of the reconstruction and regularization loss
terms ($\beta$ value) yielding useful latent representations of the input data.
We demonstrate the usefulness of the dynamic $\beta$-VAE on optically recorded
insect signals from regions of southern Scandinavia to cluster unlabelled
targets into possible species. We also demonstrate improved clustering
performance in a semi-supervised setting using a small subset of labelled data.
These experimental results, in both unsupervised- and semi-supervised settings,
with the dynamic $\beta$-VAE are promising and, in the near future, can be
deployed to monitor insects and conserve the rapidly declining insect
biodiversity.
</p>
<a href="http://arxiv.org/abs/2102.05526" target="_blank">arXiv:2102.05526</a> [<a href="http://arxiv.org/pdf/2102.05526" target="_blank">pdf</a>]

<h2>On the Existence of Optimal Transport Gradient for Learning Generative Models. (arXiv:2102.05542v1 [stat.ML])</h2>
<h3>Antoine Houdard, Arthur Leclaire, Nicolas Papadakis, Julien Rabin</h3>
<p>The use of optimal transport cost for learning generative models has become
popular with Wasserstein Generative Adversarial Networks (WGAN). Training of
WGAN relies on a theoretical background: the calculation of the gradient of the
optimal transport cost with respect to the generative model parameters. We
first demonstrate that such gradient may not be defined, which can result in
numerical instabilities during gradient-based optimization. We address this
issue by stating a valid differentiation theorem in the case of entropic
regularized transport and specify conditions under which existence is ensured.
By exploiting the discrete nature of empirical data, we formulate the gradient
in a semi-discrete setting and propose an algorithm for the optimization of the
generative model parameters. Finally, we illustrate numerically the advantage
of the proposed framework.
</p>
<a href="http://arxiv.org/abs/2102.05542" target="_blank">arXiv:2102.05542</a> [<a href="http://arxiv.org/pdf/2102.05542" target="_blank">pdf</a>]

<h2>Partial transfusion: on the expressive influence of trainable batch norm parameters for transfer learning. (arXiv:2102.05543v1 [cs.CV])</h2>
<h3>Fahdi Kanavati, Masayuki Tsuneki</h3>
<p>Transfer learning from ImageNet is the go-to approach when applying deep
learning to medical images. The approach is either to fine-tune a pre-trained
model or use it as a feature extractor. Most modern architecture contain batch
normalisation layers, and fine-tuning a model with such layers requires taking
a few precautions as they consist of trainable and non-trainable weights and
have two operating modes: training and inference. Attention is primarily given
to the non-trainable weights used during inference, as they are the primary
source of unexpected behaviour or degradation in performance during transfer
learning. It is typically recommended to fine-tune the model with the batch
normalisation layers kept in inference mode during both training and inference.
In this paper, we pay closer attention instead to the trainable weights of the
batch normalisation layers, and we explore their expressive influence in the
context of transfer learning. We find that only fine-tuning the trainable
weights (scale and centre) of the batch normalisation layers leads to similar
performance as to fine-tuning all of the weights, with the added benefit of
faster convergence. We demonstrate this on a variety of seven publicly
available medical imaging datasets, using four different model architectures.
</p>
<a href="http://arxiv.org/abs/2102.05543" target="_blank">arXiv:2102.05543</a> [<a href="http://arxiv.org/pdf/2102.05543" target="_blank">pdf</a>]

<h2>Learning Equational Theorem Proving. (arXiv:2102.05547v1 [cs.LG])</h2>
<h3>Jelle Piepenbrock, Tom Heskes, Mikol&#xe1;&#x161; Janota, Josef Urban</h3>
<p>We develop Stratified Shortest Solution Imitation Learning (3SIL) to learn
equational theorem proving in a deep reinforcement learning (RL) setting. The
self-trained models achieve state-of-the-art performance in proving problems
generated by one of the top open conjectures in quasigroup theory, the Abelian
Inner Mapping (AIM) Conjecture. To develop the methods, we first use two
simpler arithmetic rewriting tasks that share tree-structured proof states and
sparse rewards with the AIM problems. On these tasks, 3SIL is shown to
significantly outperform several established RL and imitation learning methods.
The final system is then evaluated in a standalone and cooperative mode on the
AIM problems. The standalone 3SIL-trained system proves in 60 seconds more
theorems (70.2%) than the complex, hand-engineered Waldmeister system (65.5%).
In the cooperative mode, the final system is combined with the Prover9 system,
proving in 2 seconds what standalone Prover9 proves in 60 seconds.
</p>
<a href="http://arxiv.org/abs/2102.05547" target="_blank">arXiv:2102.05547</a> [<a href="http://arxiv.org/pdf/2102.05547" target="_blank">pdf</a>]

<h2>Meta Federated Learning. (arXiv:2102.05561v1 [cs.LG])</h2>
<h3>Omid Aramoon, Pin-Yu Chen, Gang Qu, Yuan Tian</h3>
<p>Due to its distributed methodology alongside its privacy-preserving features,
Federated Learning (FL) is vulnerable to training time adversarial attacks. In
this study, our focus is on backdoor attacks in which the adversary's goal is
to cause targeted misclassifications for inputs embedded with an adversarial
trigger while maintaining an acceptable performance on the main learning task
at hand. Contemporary defenses against backdoor attacks in federated learning
require direct access to each individual client's update which is not feasible
in recent FL settings where Secure Aggregation is deployed. In this study, we
seek to answer the following question, Is it possible to defend against
backdoor attacks when secure aggregation is in place?, a question that has not
been addressed by prior arts. To this end, we propose Meta Federated Learning
(Meta-FL), a novel variant of federated learning which not only is compatible
with secure aggregation protocol but also facilitates defense against backdoor
attacks. We perform a systematic evaluation of Meta-FL on two classification
datasets: SVHN and GTSRB. The results show that Meta-FL not only achieves
better utility than classic FL, but also enhances the performance of
contemporary defenses in terms of robustness against adversarial attacks.
</p>
<a href="http://arxiv.org/abs/2102.05561" target="_blank">arXiv:2102.05561</a> [<a href="http://arxiv.org/pdf/2102.05561" target="_blank">pdf</a>]

<h2>Hyperbolic Generative Adversarial Network. (arXiv:2102.05567v1 [cs.LG])</h2>
<h3>Diego Lazcano, Nicol&#xe1;s Fredes, Werner Creixell</h3>
<p>Recently, Hyperbolic Spaces in the context of Non-Euclidean Deep Learning
have gained popularity because of their ability to represent hierarchical data.
We propose that it is possible to take advantage of the hierarchical
characteristic present in the images by using hyperbolic neural networks in a
GAN architecture. In this study, different configurations using fully connected
hyperbolic layers in the GAN, CGAN, and WGAN are tested, in what we call the
HGAN, HCGAN, and HWGAN, respectively. The results are measured using the
Inception Score (IS) and the Fr\'echet Inception Distance (FID) on the MNIST
dataset. Depending on the configuration and space curvature, better results are
achieved for each proposed hyperbolic versions than their euclidean
counterpart.
</p>
<a href="http://arxiv.org/abs/2102.05567" target="_blank">arXiv:2102.05567</a> [<a href="http://arxiv.org/pdf/2102.05567" target="_blank">pdf</a>]

<h2>An Optimal Witness Function for Two-Sample Testing. (arXiv:2102.05573v1 [cs.LG])</h2>
<h3>Jonas M. K&#xfc;bler, Wittawat Jitkrittum, Bernhard Sch&#xf6;lkopf, Krikamol Muandet</h3>
<p>We propose data-dependent test statistics based on a one-dimensional witness
function, which we call witness two-sample tests (WiTS tests). We first
optimize the witness function by maximizing an asymptotic test-power objective
and then use as the test statistic the difference in means of the witness
evaluated on two held-out test samples. When the witness function belongs to a
reproducing kernel Hilbert space, we show that the optimal witness is given via
kernel Fisher discriminant analysis, whose solution we compute in closed form.
We show that the WiTS test based on a characteristic kernel is consistent
against any fixed alternative. Our experiments demonstrate that the WiTS test
can achieve higher test power than existing two-sample tests with optimized
kernels, suggesting that learning a high- or infinite-dimensional
representation of the data may not be necessary for two-sample testing. The
proposed procedure works beyond kernel methods, allowing practitioners to apply
it within their preferred machine learning framework.
</p>
<a href="http://arxiv.org/abs/2102.05573" target="_blank">arXiv:2102.05573</a> [<a href="http://arxiv.org/pdf/2102.05573" target="_blank">pdf</a>]

<h2>Classification of Long Noncoding RNA Elements Using Deep Convolutional Neural Networks and Siamese Networks. (arXiv:2102.05582v1 [cs.CV])</h2>
<h3>Brian McClannahan, Cucong Zhong, Guanghui Wang</h3>
<p>In the last decade, the discovery of noncoding RNA(ncRNA) has exploded.
Classifying these ncRNA is critical todetermining their function. This thesis
proposes a new methodemploying deep convolutional neural networks (CNNs) to
classifyncRNA sequences. To this end, this paper first proposes anefficient
approach to convert the RNA sequences into imagescharacterizing their
base-pairing probability. As a result, clas-sifying RNA sequences is converted
to an image classificationproblem that can be efficiently solved by available
CNN-basedclassification models. This research also considers the
foldingpotential of the ncRNAs in addition to their primary sequence.Based on
the proposed approach, a benchmark image classifi-cation dataset is generated
from the RFAM database of ncRNAsequences. In addition, three classical CNN
models and threeSiamese network models have been implemented and comparedto
demonstrate the superior performance and efficiency of theproposed approach.
Extensive experimental results show thegreat potential of using deep learning
approaches for RNAclassification.
</p>
<a href="http://arxiv.org/abs/2102.05582" target="_blank">arXiv:2102.05582</a> [<a href="http://arxiv.org/pdf/2102.05582" target="_blank">pdf</a>]

<h2>Fast Classification Learning with Neural Networks and Conceptors for Speech Recognition and Car Driving Maneuvers. (arXiv:2102.05588v1 [cs.LG])</h2>
<h3>Stefanie Krause, Oliver Otto, Frieder Stolzenburg</h3>
<p>Recurrent neural networks are a powerful means in diverse applications. We
show that, together with so-called conceptors, they also allow fast learning,
in contrast to other deep learning methods. In addition, a relatively small
number of examples suffices to train neural networks with high accuracy. We
demonstrate this with two applications, namely speech recognition and detecting
car driving maneuvers. We improve the state-of-the art by application-specific
preparation techniques: For speech recognition, we use mel frequency cepstral
coefficients leading to a compact representation of the frequency spectra, and
detecting car driving maneuvers can be done without the commonly used
polynomial interpolation, as our evaluation suggests.
</p>
<a href="http://arxiv.org/abs/2102.05588" target="_blank">arXiv:2102.05588</a> [<a href="http://arxiv.org/pdf/2102.05588" target="_blank">pdf</a>]

<h2>Improving Model-Based Reinforcement Learning with Internal State Representations through Self-Supervision. (arXiv:2102.05599v1 [cs.LG])</h2>
<h3>Julien Scholz, Cornelius Weber, Muhammad Burhan Hafez, Stefan Wermter</h3>
<p>Using a model of the environment, reinforcement learning agents can plan
their future moves and achieve superhuman performance in board games like
Chess, Shogi, and Go, while remaining relatively sample-efficient. As
demonstrated by the MuZero Algorithm, the environment model can even be learned
dynamically, generalizing the agent to many more tasks while at the same time
achieving state-of-the-art performance. Notably, MuZero uses internal state
representations derived from real environment states for its predictions. In
this paper, we bind the model's predicted internal state representation to the
environment state via two additional terms: a reconstruction model loss and a
simpler consistency loss, both of which work independently and unsupervised,
acting as constraints to stabilize the learning process. Our experiments show
that this new integration of reconstruction model loss and simpler consistency
loss provide a significant performance increase in OpenAI Gym environments. Our
modifications also enable self-supervised pretraining for MuZero, so the
algorithm can learn about environment dynamics before a goal is made available.
</p>
<a href="http://arxiv.org/abs/2102.05599" target="_blank">arXiv:2102.05599</a> [<a href="http://arxiv.org/pdf/2102.05599" target="_blank">pdf</a>]

<h2>Systematic Generalization for Predictive Control in Multivariate Time Series. (arXiv:2102.05602v1 [cs.LG])</h2>
<h3>Hritik Bansal, Gantavya Bhatt, Pankaj Malhotra, Prathosh A.P</h3>
<p>Prior work has focused on evaluating the ability of neural networks to reason
about novel combinations from known components, an intrinsic property of human
cognition. In this work, we aim to study systematic generalization in
predicting future state trajectories of a dynamical system, conditioned on past
states' trajectory (dependent variables), past and future actions (control
variables). In our context, systematic generalization implies that a good model
should perform well on all new combinations of future actions after being
trained on all of them, but only on a limited set of their combinations. For
models to generalize out-of-distribution to unseen action combinations, they
should reason about the states and their dependency relation with the applied
actions. We conduct a rigorous study of useful inductive biases that learn to
predict the trajectories up to large horizons well, and capture true dependency
relations between the states and the controls through our synthetic setup, and
simulated data from electric motors.
</p>
<a href="http://arxiv.org/abs/2102.05602" target="_blank">arXiv:2102.05602</a> [<a href="http://arxiv.org/pdf/2102.05602" target="_blank">pdf</a>]

<h2>Exploiting Depth Information for Wildlife Monitoring. (arXiv:2102.05607v1 [cs.CV])</h2>
<h3>Timm Haucke, Volker Steinhage</h3>
<p>Camera traps are a proven tool in biology and specifically biodiversity
research. However, camera traps including depth estimation are not widely
deployed, despite providing valuable context about the scene and facilitating
the automation of previously laborious manual ecological methods. In this
study, we propose an automated camera trap-based approach to detect and
identify animals using depth estimation. To detect and identify individual
animals, we propose a novel method D-Mask R-CNN for the so-called instance
segmentation which is a deep learning-based technique to detect and delineate
each distinct object of interest appearing in an image or a video clip. An
experimental evaluation shows the benefit of the additional depth estimation in
terms of improved average precision scores of the animal detection compared to
the standard approach that relies just on the image information. This novel
approach was also evaluated in terms of a proof-of-concept in a zoo scenario
using an RGB-D camera trap.
</p>
<a href="http://arxiv.org/abs/2102.05607" target="_blank">arXiv:2102.05607</a> [<a href="http://arxiv.org/pdf/2102.05607" target="_blank">pdf</a>]

<h2>Searching for Fast Model Families on Datacenter Accelerators. (arXiv:2102.05610v1 [cs.CV])</h2>
<h3>Sheng Li, Mingxing Tan, Ruoming Pang, Andrew Li, Liqun Cheng, Quoc Le, Norman P. Jouppi</h3>
<p>Neural Architecture Search (NAS), together with model scaling, has shown
remarkable progress in designing high accuracy and fast convolutional
architecture families. However, as neither NAS nor model scaling considers
sufficient hardware architecture details, they do not take full advantage of
the emerging datacenter (DC) accelerators. In this paper, we search for fast
and accurate CNN model families for efficient inference on DC accelerators. We
first analyze DC accelerators and find that existing CNNs suffer from
insufficient operational intensity, parallelism, and execution efficiency.
These insights let us create a DC-accelerator-optimized search space, with
space-to-depth, space-to-batch, hybrid fused convolution structures with
vanilla and depthwise convolutions, and block-wise activation functions. On top
of our DC accelerator optimized neural architecture search space, we further
propose a latency-aware compound scaling (LACS), the first multi-objective
compound scaling method optimizing both accuracy and latency. Our LACS
discovers that network depth should grow much faster than image size and
network width, which is quite different from previous compound scaling results.
With the new search space and LACS, our search and scaling on datacenter
accelerators results in a new model series named EfficientNet-X. EfficientNet-X
is up to more than 2X faster than EfficientNet (a model series with
state-of-the-art trade-off on FLOPs and accuracy) on TPUv3 and GPUv100, with
comparable accuracy. EfficientNet-X is also up to 7X faster than recent RegNet
and ResNeSt on TPUv3 and GPUv100.
</p>
<a href="http://arxiv.org/abs/2102.05610" target="_blank">arXiv:2102.05610</a> [<a href="http://arxiv.org/pdf/2102.05610" target="_blank">pdf</a>]

<h2>Personalization for Web-based Services using Offline Reinforcement Learning. (arXiv:2102.05612v1 [cs.LG])</h2>
<h3>Pavlos Athanasios Apostolopoulos, Zehui Wang, Hanson Wang, Chad Zhou, Kittipat Virochsiri, Norm Zhou, Igor L. Markov</h3>
<p>Large-scale Web-based services present opportunities for improving UI
policies based on observed user interactions. We address challenges of learning
such policies through model-free offline Reinforcement Learning (RL) with
off-policy training. Deployed in a production system for user authentication in
a major social network, it significantly improves long-term objectives. We
articulate practical challenges, compare several ML techniques, provide
insights on training and evaluation of RL models, and discuss generalizations.
</p>
<a href="http://arxiv.org/abs/2102.05612" target="_blank">arXiv:2102.05612</a> [<a href="http://arxiv.org/pdf/2102.05612" target="_blank">pdf</a>]

<h2>Addressing the Topological Defects of Disentanglement via Distributed Operators. (arXiv:2102.05623v1 [cs.LG])</h2>
<h3>Diane Bouchacourt, Mark Ibrahim, St&#xe9;phane Deny</h3>
<p>A core challenge in Machine Learning is to learn to disentangle natural
factors of variation in data (e.g. object shape vs. pose). A popular approach
to disentanglement consists in learning to map each of these factors to
distinct subspaces of a model's latent representation. However, this approach
has shown limited empirical success to date. Here, we show that, for a broad
family of transformations acting on images--encompassing simple affine
transformations such as rotations and translations--this approach to
disentanglement introduces topological defects (i.e. discontinuities in the
encoder). Motivated by classical results from group representation theory, we
study an alternative, more flexible approach to disentanglement which relies on
distributed latent operators, potentially acting on the entire latent space. We
theoretically and empirically demonstrate the effectiveness of this approach to
disentangle affine transformations. Our work lays a theoretical foundation for
the recent success of a new generation of models using distributed operators
for disentanglement.
</p>
<a href="http://arxiv.org/abs/2102.05623" target="_blank">arXiv:2102.05623</a> [<a href="http://arxiv.org/pdf/2102.05623" target="_blank">pdf</a>]

<h2>NAST: Non-Autoregressive Spatial-Temporal Transformer for Time Series Forecasting. (arXiv:2102.05624v1 [cs.LG])</h2>
<h3>Kai Chen, Guang Chen, Dan Xu, Lijun Zhang, Yuyao Huang, Alois Knoll</h3>
<p>Although Transformer has made breakthrough success in widespread domains
especially in Natural Language Processing (NLP), applying it to time series
forecasting is still a great challenge. In time series forecasting, the
autoregressive decoding of canonical Transformer models could introduce huge
accumulative errors inevitably. Besides, utilizing Transformer to deal with
spatial-temporal dependencies in the problem still faces tough difficulties.~To
tackle these limitations, this work is the first attempt to propose a
Non-Autoregressive Transformer architecture for time series forecasting, aiming
at overcoming the time delay and accumulative error issues in the canonical
Transformer. Moreover, we present a novel spatial-temporal attention mechanism,
building a bridge by a learned temporal influence map to fill the gaps between
the spatial and temporal attention, so that spatial and temporal dependencies
can be processed integrally. Empirically, we evaluate our model on diversified
ego-centric future localization datasets and demonstrate state-of-the-art
performance on both real-time and accuracy.
</p>
<a href="http://arxiv.org/abs/2102.05624" target="_blank">arXiv:2102.05624</a> [<a href="http://arxiv.org/pdf/2102.05624" target="_blank">pdf</a>]

<h2>On the Regularity of Attention. (arXiv:2102.05628v1 [stat.ML])</h2>
<h3>James Vuckovic, Aristide Baratin, Remi Tachet des Combes</h3>
<p>Attention is a powerful component of modern neural networks across a wide
variety of domains. In this paper, we seek to quantify the regularity (i.e. the
amount of smoothness) of the attention operation. To accomplish this goal, we
propose a new mathematical framework that uses measure theory and integral
operators to model attention. We show that this framework is consistent with
the usual definition, and that it captures the essential properties of
attention. Then we use this framework to prove that, on compact domains, the
attention operation is Lipschitz continuous and provide an estimate of its
Lipschitz constant. Additionally, by focusing on a specific type of attention,
we extend these Lipschitz continuity results to non-compact domains. We also
discuss the effects regularity can have on NLP models, and applications to
invertible and infinitely-deep networks.
</p>
<a href="http://arxiv.org/abs/2102.05628" target="_blank">arXiv:2102.05628</a> [<a href="http://arxiv.org/pdf/2102.05628" target="_blank">pdf</a>]

<h2>Agnostic Proper Learning of Halfspaces under Gaussian Marginals. (arXiv:2102.05629v1 [cs.LG])</h2>
<h3>Ilias Diakonikolas, Daniel M. Kane, Vasilis Kontonis, Christos Tzamos, Nikos Zarifis</h3>
<p>We study the problem of agnostically learning halfspaces under the Gaussian
distribution. Our main result is the {\em first proper} learning algorithm for
this problem whose sample complexity and computational complexity qualitatively
match those of the best known improper agnostic learner. Building on this
result, we also obtain the first proper polynomial-time approximation scheme
(PTAS) for agnostically learning homogeneous halfspaces. Our techniques
naturally extend to agnostically learning linear models with respect to other
non-linear activations, yielding in particular the first proper agnostic
algorithm for ReLU regression.
</p>
<a href="http://arxiv.org/abs/2102.05629" target="_blank">arXiv:2102.05629</a> [<a href="http://arxiv.org/pdf/2102.05629" target="_blank">pdf</a>]

<h2>PLGRIM: Hierarchical Value Learning for Large-scale Exploration in Unknown Environments. (arXiv:2102.05633v1 [cs.RO])</h2>
<h3>Sung-Kyun Kim, Amanda Bouman, Gautam Salhotra, David D. Fan, Kyohei Otsu, Joel Burdick, Ali-akbar Agha-mohammadi</h3>
<p>In order for a robot to explore an unknown environment autonomously, it must
account for uncertainty in sensor measurements, hazard assessment,
localization, and motion execution. Making decisions for maximal reward in a
stochastic setting requires learning values and constructing policies over a
belief space, i.e., probability distribution of the robot-world state. Value
learning over belief spaces suffer from computational challenges in
high-dimensional spaces, such as large spatial environments and long temporal
horizons for exploration. At the same time, it should be adaptive and resilient
to disturbances at run time in order to ensure the robot's safety, as required
in many real-world applications. This work proposes a scalable value learning
framework, PLGRIM (Probabilistic Local and Global Reasoning on Information
roadMaps), that bridges the gap between (i) local, risk-aware resiliency and
(ii) global, reward-seeking mission objectives. By leveraging hierarchical
belief space planners with information-rich graph structures, PLGRIM can
address large-scale exploration problems while providing locally near-optimal
coverage plans. PLGRIM is a step toward enabling belief space planners on
physical robots operating in unknown and complex environments. We validate our
proposed framework with a high-fidelity dynamic simulation in diverse
environments and with physical hardware, Boston Dynamics' Spot robot, in a lava
tube.
</p>
<a href="http://arxiv.org/abs/2102.05633" target="_blank">arXiv:2102.05633</a> [<a href="http://arxiv.org/pdf/2102.05633" target="_blank">pdf</a>]

<h2>Energy-Harvesting Distributed Machine Learning. (arXiv:2102.05639v1 [cs.LG])</h2>
<h3>Basak Guler, Aylin Yener</h3>
<p>This paper provides a first study of utilizing energy harvesting for
sustainable machine learning in distributed networks. We consider a distributed
learning setup in which a machine learning model is trained over a large number
of devices that can harvest energy from the ambient environment, and develop a
practical learning framework with theoretical convergence guarantees. We
demonstrate through numerical experiments that the proposed framework can
significantly outperform energy-agnostic benchmarks. Our framework is scalable,
requires only local estimation of the energy statistics, and can be applied to
a wide range of distributed training settings, including machine learning in
wireless networks, edge computing, and mobile internet of things.
</p>
<a href="http://arxiv.org/abs/2102.05639" target="_blank">arXiv:2102.05639</a> [<a href="http://arxiv.org/pdf/2102.05639" target="_blank">pdf</a>]

<h2>An exact solver for the Weston-Watkins SVM subproblem. (arXiv:2102.05640v1 [stat.ML])</h2>
<h3>Yutong Wang, Clayton D. Scott</h3>
<p>Recent empirical evidence suggests that the Weston-Watkins support vector
machine is among the best performing multiclass extensions of the binary SVM.
Current state-of-the-art solvers repeatedly solve a particular subproblem
approximately using an iterative strategy. In this work, we propose an
algorithm that solves the subproblem exactly using a novel reparametrization of
the Weston-Watkins dual problem. For linear WW-SVMs, our solver shows
significant speed-up over the state-of-the-art solver when the number of
classes is large. Our exact subproblem solver also allows us to prove linear
convergence of the overall solver.
</p>
<a href="http://arxiv.org/abs/2102.05640" target="_blank">arXiv:2102.05640</a> [<a href="http://arxiv.org/pdf/2102.05640" target="_blank">pdf</a>]

<h2>Training Vision Transformers for Image Retrieval. (arXiv:2102.05644v1 [cs.CV])</h2>
<h3>Alaaeldin El-Nouby, Natalia Neverova, Ivan Laptev, Herv&#xe9; J&#xe9;gou</h3>
<p>Transformers have shown outstanding results for natural language
understanding and, more recently, for image classification. We here extend this
work and propose a transformer-based approach for image retrieval: we adopt
vision transformers for generating image descriptors and train the resulting
model with a metric learning objective, which combines a contrastive loss with
a differential entropy regularizer. Our results show consistent and significant
improvements of transformers over convolution-based approaches. In particular,
our method outperforms the state of the art on several public benchmarks for
category-level retrieval, namely Stanford Online Product, In-Shop and CUB-200.
Furthermore, our experiments on ROxford and RParis also show that, in
comparable settings, transformers are competitive for particular object
retrieval, especially in the regime of short vector representations and
low-resolution images.
</p>
<a href="http://arxiv.org/abs/2102.05644" target="_blank">arXiv:2102.05644</a> [<a href="http://arxiv.org/pdf/2102.05644" target="_blank">pdf</a>]

<h2>Automated Video Labelling: Identifying Faces by Corroborative Evidence. (arXiv:2102.05645v1 [cs.CV])</h2>
<h3>Andrew Brown, Ernesto Coto, Andrew Zisserman</h3>
<p>We present a method for automatically labelling all faces in video archives,
such as TV broadcasts, by combining multiple evidence sources and multiple
modalities (visual and audio). We target the problem of ever-growing online
video archives, where an effective, scalable indexing solution cannot require a
user to provide manual annotation or supervision. To this end, we make three
key contributions: (1) We provide a novel, simple, method for determining if a
person is famous or not using image-search engines. In turn this enables a
face-identity model to be built reliably and robustly, and used for high
precision automatic labelling; (2) We show that even for less-famous people,
image-search engines can then be used for corroborative evidence to accurately
label faces that are named in the scene or the speech; (3) Finally, we
quantitatively demonstrate the benefits of our approach on different video
domains and test settings, such as TV shows and news broadcasts. Our method
works across three disparate datasets without any explicit domain adaptation,
and sets new state-of-the-art results on all the public benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.05645" target="_blank">arXiv:2102.05645</a> [<a href="http://arxiv.org/pdf/2102.05645" target="_blank">pdf</a>]

<h2>Scale Normalized Image Pyramids with AutoFocus for Object Detection. (arXiv:2102.05646v1 [cs.CV])</h2>
<h3>Bharat Singh, Mahyar Najibi, Abhishek Sharma, Larry S. Davis</h3>
<p>We present an efficient foveal framework to perform object detection. A scale
normalized image pyramid (SNIP) is generated that, like human vision, only
attends to objects within a fixed size range at different scales. Such a
restriction of objects' size during training affords better learning of
object-sensitive filters, and therefore, results in better accuracy. However,
the use of an image pyramid increases the computational cost. Hence, we propose
an efficient spatial sub-sampling scheme which only operates on fixed-size
sub-regions likely to contain objects (as object locations are known during
training). The resulting approach, referred to as Scale Normalized Image
Pyramid with Efficient Resampling or SNIPER, yields up to 3 times speed-up
during training. Unfortunately, as object locations are unknown during
inference, the entire image pyramid still needs processing. To this end, we
adopt a coarse-to-fine approach, and predict the locations and extent of
object-like regions which will be processed in successive scales of the image
pyramid. Intuitively, it's akin to our active human-vision that first skims
over the field-of-view to spot interesting regions for further processing and
only recognizes objects at the right resolution. The resulting algorithm is
referred to as AutoFocus and results in a 2.5-5 times speed-up during inference
when used with SNIP.
</p>
<a href="http://arxiv.org/abs/2102.05646" target="_blank">arXiv:2102.05646</a> [<a href="http://arxiv.org/pdf/2102.05646" target="_blank">pdf</a>]

<h2>Face Synthesis for Eyeglass-Robust Face Recognition. (arXiv:1806.01196v2 [cs.CV] UPDATED)</h2>
<h3>Jianzhu Guo, Xiangyu Zhu, Zhen Lei, Stan Z. Li</h3>
<p>In the application of face recognition, eyeglasses could significantly
degrade the recognition accuracy. A feasible method is to collect large-scale
face images with eyeglasses for training deep learning methods. However, it is
difficult to collect the images with and without glasses of the same identity,
so that it is difficult to optimize the intra-variations caused by eyeglasses.
In this paper, we propose to address this problem in a virtual synthesis
manner. The high-fidelity face images with eyeglasses are synthesized based on
3D face model and 3D eyeglasses. Models based on deep learning methods are then
trained on the synthesized eyeglass face dataset, achieving better performance
than previous ones. Experiments on the real face database validate the
effectiveness of our synthesized data for improving eyeglass face recognition
performance.
</p>
<a href="http://arxiv.org/abs/1806.01196" target="_blank">arXiv:1806.01196</a> [<a href="http://arxiv.org/pdf/1806.01196" target="_blank">pdf</a>]

<h2>Improving Face Anti-Spoofing by 3D Virtual Synthesis. (arXiv:1901.00488v3 [cs.CV] UPDATED)</h2>
<h3>Jianzhu Guo, Xiangyu Zhu, Jinchuan Xiao, Zhen Lei, Genxun Wan, Stan Z. Li</h3>
<p>Face anti-spoofing is crucial for the security of face recognition systems.
Learning based methods especially deep learning based methods need large-scale
training samples to reduce overfitting. However, acquiring spoof data is very
expensive since the live faces should be re-printed and re-captured in many
views. In this paper, we present a method to synthesize virtual spoof data in
3D space to alleviate this problem. Specifically, we consider a printed photo
as a flat surface and mesh it into a 3D object, which is then randomly bent and
rotated in 3D space. Afterward, the transformed 3D photo is rendered through
perspective projection as a virtual sample. The synthetic virtual samples can
significantly boost the anti-spoofing performance when combined with a proposed
data balancing strategy. Our promising results open up new possibilities for
advancing face anti-spoofing using cheap and large-scale synthetic data.
</p>
<a href="http://arxiv.org/abs/1901.00488" target="_blank">arXiv:1901.00488</a> [<a href="http://arxiv.org/pdf/1901.00488" target="_blank">pdf</a>]

<h2>Machine learning with neural networks. (arXiv:1901.05639v3 [cs.LG] UPDATED)</h2>
<h3>B. Mehlig</h3>
<p>Lecture notes for my course on machine learning with neural networks that I
have given at Gothenburg University and Chalmers Technical University in
Gothenburg, Sweden.
</p>
<a href="http://arxiv.org/abs/1901.05639" target="_blank">arXiv:1901.05639</a> [<a href="http://arxiv.org/pdf/1901.05639" target="_blank">pdf</a>]

<h2>Net2Vis -- A Visual Grammar for Automatically Generating Publication-Tailored CNN Architecture Visualizations. (arXiv:1902.04394v6 [cs.LG] UPDATED)</h2>
<h3>Alex B&#xe4;uerle, Christian van Onzenoodt, Timo Ropinski</h3>
<p>To convey neural network architectures in publications, appropriate
visualizations are of great importance. While most current deep learning papers
contain such visualizations, these are usually handcrafted just before
publication, which results in a lack of a common visual grammar, significant
time investment, errors, and ambiguities. Current automatic network
visualization tools focus on debugging the network itself and are not ideal for
generating publication visualizations. Therefore, we present an approach to
automate this process by translating network architectures specified in Keras
into visualizations that can directly be embedded into any publication. To do
so, we propose a visual grammar for convolutional neural networks (CNNs), which
has been derived from an analysis of such figures extracted from all ICCV and
CVPR papers published between 2013 and 2019. The proposed grammar incorporates
visual encoding, network layout, layer aggregation, and legend generation. We
have further realized our approach in an online system available to the
community, which we have evaluated through expert feedback, and a quantitative
study. It not only reduces the time needed to generate network visualizations
for publications, but also enables a unified and unambiguous visualization
design.
</p>
<a href="http://arxiv.org/abs/1902.04394" target="_blank">arXiv:1902.04394</a> [<a href="http://arxiv.org/pdf/1902.04394" target="_blank">pdf</a>]

<h2>Interference Prediction in Wireless Networks: Stochastic Geometry meets Recursive Filtering. (arXiv:1903.10899v3 [cs.LG] UPDATED)</h2>
<h3>Jorge F. Schmidt, Udo Schilcher, Mahin K. Atiq, Christian Bettstetter</h3>
<p>This article proposes and evaluates a technique to predict the level of
interference in wireless networks. We design a recursive predictor that
estimates future interference values by filtering measured interference at a
given location. The predictor's parameterization is done offline by translating
the autocorrelation of interference into an autoregressive moving average
(ARMA) representation. This ARMA model is inserted into a steady-state Kalman
filter enabling nodes to predict with low computational effort. Results show a
good accuracy of predicted values versus true values for relevant time
horizons. Although the predictor is parameterized for Poisson-distributed
nodes, Rayleigh fading, and fixed message lengths, a sensitivity analysis shows
that it also tends to work well in more general network scenarios. Numerical
examples for underlay device-to-device communications, a common wireless sensor
technology, and coexistence scenarios of Wi-Fi and LTE illustrate its broad
applicability. The predictor can be applied as part of interference management
to improve medium access, scheduling, and radio resource allocation.
</p>
<a href="http://arxiv.org/abs/1903.10899" target="_blank">arXiv:1903.10899</a> [<a href="http://arxiv.org/pdf/1903.10899" target="_blank">pdf</a>]

<h2>Saliency is a Possible Red Herring When Diagnosing Poor Generalization. (arXiv:1910.00199v3 [cs.CV] UPDATED)</h2>
<h3>Joseph D. Viviano, Becks Simpson, Francis Dutil, Yoshua Bengio, Joseph Paul Cohen</h3>
<p>Poor generalization is one symptom of models that learn to predict target
variables using spuriously-correlated image features present only in the
training distribution instead of the true image features that denote a class.
It is often thought that this can be diagnosed visually using attribution (aka
saliency) maps. We study if this assumption is correct. In some prediction
tasks, such as for medical images, one may have some images with masks drawn by
a human expert, indicating a region of the image containing relevant
information to make the prediction. We study multiple methods that take
advantage of such auxiliary labels, by training networks to ignore distracting
features which may be found outside of the region of interest. This mask
information is only used during training and has an impact on generalization
accuracy depending on the severity of the shift between the training and test
distributions. Surprisingly, while these methods improve generalization
performance in the presence of a covariate shift, there is no strong
correspondence between the correction of attribution towards the features a
human expert has labelled as important and generalization performance. These
results suggest that the root cause of poor generalization may not always be
spatially defined, and raise questions about the utility of masks as
"attribution priors" as well as saliency maps for explainable predictions.
</p>
<a href="http://arxiv.org/abs/1910.00199" target="_blank">arXiv:1910.00199</a> [<a href="http://arxiv.org/pdf/1910.00199" target="_blank">pdf</a>]

<h2>Improving the convergence of SGD through adaptive batch sizes. (arXiv:1910.08222v3 [cs.LG] UPDATED)</h2>
<h3>Scott Sievert</h3>
<p>Mini-batch stochastic gradient descent (SGD) and variants thereof approximate
the objective function's gradient with a small number of training examples, aka
the batch size. Small batch sizes require little computation for each model
update but can yield high-variance gradient estimates, which poses some
challenges for optimization. Conversely, large batches require more computation
but can yield higher precision gradient estimates. This work presents a method
to adapt the batch size to the model's training loss. For various function
classes, we show that our method requires the same order of model updates as
gradient descent while requiring the same order of gradient computations as
SGD. This method requires evaluating the model's loss on the entire dataset
every model update. However, the required computation is greatly reduced with a
passive approximation of the adaptive method. We provide extensive experiments
illustrating that our methods require fewer model updates without increasing
the total amount of computation.
</p>
<a href="http://arxiv.org/abs/1910.08222" target="_blank">arXiv:1910.08222</a> [<a href="http://arxiv.org/pdf/1910.08222" target="_blank">pdf</a>]

<h2>Distributed Networked Learning with Correlated Data. (arXiv:1910.12783v2 [cs.LG] UPDATED)</h2>
<h3>Lingzhou Hong, Alfredo Garcia, Ceyhun Eksin</h3>
<p>We consider a distributed estimation method in a setting with heterogeneous
streams of correlated data distributed across nodes in a network. In the
considered approach, linear models are estimated locally (i.e., with only local
data) subject to a network regularization term that penalizes a local model
that differs from neighboring models. We analyze computation dynamics
(associated with stochastic gradient updates) and information exchange
(associated with exchanging current models with neighboring nodes). We provide
a finite-time characterization of convergence of the weighted ensemble average
estimate and compare this result to federated learning, an alternative approach
to estimation wherein a single model is updated by locally generated gradient
updates. This comparison highlights the trade-off between speed vs precision:
while model updates take place at a faster rate in federated learning, the
proposed networked approach to estimation enables the identification of models
with higher precision. We illustrate the method's general applicability in two
examples: estimating a Markov random field using wireless sensor networks and
modeling prey escape behavior of flocking birds based on a publicly available
dataset.
</p>
<a href="http://arxiv.org/abs/1910.12783" target="_blank">arXiv:1910.12783</a> [<a href="http://arxiv.org/pdf/1910.12783" target="_blank">pdf</a>]

<h2>Sequential Classification with Empirically Observed Statistics. (arXiv:1912.01170v3 [stat.ML] UPDATED)</h2>
<h3>Mahdi Haghifam, Vincent Y. F. Tan, Ashish Khisti</h3>
<p>Motivated by real-world machine learning applications, we consider a
statistical classification task in a sequential setting where test samples
arrive sequentially. In addition, the generating distributions are unknown and
only a set of empirically sampled sequences are available to a decision maker.
The decision maker is tasked to classify a test sequence which is known to be
generated according to either one of the distributions. In particular, for the
binary case, the decision maker wishes to perform the classification task with
minimum number of the test samples, so, at each step, she declares that either
hypothesis 1 is true, hypothesis 2 is true, or she requests for an additional
test sample. We propose a classifier and analyze the type-I and type-II error
probabilities. We demonstrate the significant advantage of our sequential
scheme compared to an existing non-sequential classifier proposed by Gutman.
Finally, we extend our setup and results to the multi-class classification
scenario and again demonstrate that the variable-length nature of the problem
affords significant advantages as one can achieve the same set of exponents as
Gutman's fixed-length setting but without having the rejection option.
</p>
<a href="http://arxiv.org/abs/1912.01170" target="_blank">arXiv:1912.01170</a> [<a href="http://arxiv.org/pdf/1912.01170" target="_blank">pdf</a>]

<h2>Automatic structured variational inference. (arXiv:2002.00643v3 [stat.ML] UPDATED)</h2>
<h3>Luca Ambrogioni, Kate Lin, Emily Fertig, Sharad Vikram, Max Hinne, Dave Moore, Marcel van Gerven</h3>
<p>Stochastic variational inference offers an attractive option as a default
method for differentiable probabilistic programming. However, the performance
of the variational approach depends on the choice of an appropriate variational
family. Here, we introduce automatic structured variational inference (ASVI), a
fully automated method for constructing structured variational families,
inspired by the closed-form update in conjugate Bayesian models. These
convex-update families incorporate the forward pass of the input probabilistic
program and can therefore capture complex statistical dependencies.
Convex-update families have the same space and time complexity as the input
probabilistic program and are therefore tractable for a very large family of
models including both continuous and discrete variables. We validate our
automatic variational method on a wide range of low- and high-dimensional
inference problems. We find that ASVI provides a clear improvement in
performance when compared with other popular approaches such as the mean-field
approach and inverse autoregressive flows. We provide an open source
implementation of ASVI in TensorFlow Probability.
</p>
<a href="http://arxiv.org/abs/2002.00643" target="_blank">arXiv:2002.00643</a> [<a href="http://arxiv.org/pdf/2002.00643" target="_blank">pdf</a>]

<h2>Fast and Robust Comparison of Probability Measures in Heterogeneous Spaces. (arXiv:2002.01615v3 [stat.ML] UPDATED)</h2>
<h3>Ryoma Sato, Marco Cuturi, Makoto Yamada, Hisashi Kashima</h3>
<p>Comparing two probability measures supported on heterogeneous spaces is an
increasingly important problem in machine learning. Such problems arise when
comparing for instance two populations of biological cells, each described with
its own set of features, or when looking at families of word embeddings trained
across different corpora/languages. For such settings, the Gromov Wasserstein
(GW) distance is often presented as the gold standard. GW is intuitive, as it
quantifies whether one measure can be isomorphically mapped to the other.
However, its exact computation is intractable, and most algorithms that claim
to approximate it remain expensive. Building on \cite{memoli-2011}, who
proposed to represent each point in each distribution as the 1D distribution of
its distances to all other points, we introduce in this paper the Anchor Energy
(AE) and Anchor Wasserstein (AW) distances, which are respectively the energy
and Wasserstein distances instantiated on such representations. Our main
contribution is to propose a sweep line algorithm to compute AE \emph{exactly}
in log-quadratic time, where a naive implementation would be cubic. This is
quasi-linear w.r.t. the description of the problem itself. Our second
contribution is the proposal of robust variants of AE and AW that uses rank
statistics rather than the original distances. We show that AE and AW perform
well in various experimental settings at a fraction of the computational cost
of popular GW approximations. Code is available at
\url{https://github.com/joisino/anchor-energy}.
</p>
<a href="http://arxiv.org/abs/2002.01615" target="_blank">arXiv:2002.01615</a> [<a href="http://arxiv.org/pdf/2002.01615" target="_blank">pdf</a>]

<h2>Improving Neural Network Learning Through Dual Variable Learning Rates. (arXiv:2002.03428v3 [cs.LG] UPDATED)</h2>
<h3>Elizabeth Liner, Risto Miikkulainen</h3>
<p>This paper introduces and evaluates a novel training method for neural
networks: Dual Variable Learning Rates (DVLR). Building on insights from
behavioral psychology, the dual learning rates are used to emphasize correct
and incorrect responses differently, thereby making the feedback to the network
more specific. Further, the learning rates are varied as a function of the
network's performance, thereby making it more efficient. DVLR was implemented
on three types of networks: feedforward, convolutional, and residual, and two
domains: MNIST and CIFAR-10. The results suggest a consistently improved
accuracy, demonstrating that DVLR is a promising, psychologically motivated
technique for training neural network models.
</p>
<a href="http://arxiv.org/abs/2002.03428" target="_blank">arXiv:2002.03428</a> [<a href="http://arxiv.org/pdf/2002.03428" target="_blank">pdf</a>]

<h2>Autonomous Planning Based on Spatial Concepts to Tidy Up Home Environments with Service Robots. (arXiv:2002.03671v2 [cs.RO] UPDATED)</h2>
<h3>Akira Taniguchi, Shota Isobe, Lotfi El Hafi, Yoshinobu Hagiwara, Tadahiro Taniguchi</h3>
<p>Tidy-up tasks by service robots in home environments are challenging in
robotics applications because they involve various interactions with the
environment. In particular, robots are required not only to grasp, move, and
release various home objects but also to plan the order and positions for
placing the objects. In this paper, we propose a novel planning method that can
efficiently estimate the order and positions of the objects to be tidied up by
learning the parameters of a probabilistic generative model. The model allows a
robot to learn the distributions of the co-occurrence probability of the
objects and places to tidy up using the multimodal sensor information collected
in a tidied environment. Additionally, we develop an autonomous robotic system
to perform the tidy-up operation. We evaluate the effectiveness of the proposed
method by an experimental simulation that reproduces the conditions of the Tidy
Up Here task of the World Robot Summit 2018 international robotics competition.
The simulation results show that the proposed method enables the robot to
successively tidy up several objects and achieves the best task score among the
considered baseline tidy-up methods.
</p>
<a href="http://arxiv.org/abs/2002.03671" target="_blank">arXiv:2002.03671</a> [<a href="http://arxiv.org/pdf/2002.03671" target="_blank">pdf</a>]

<h2>Multi-Agent Meta-Reinforcement Learning for Self-Powered and Sustainable Edge Computing Systems. (arXiv:2002.08567v3 [cs.LG] UPDATED)</h2>
<h3>Md. Shirajum Munir, Nguyen H. Tran, Walid Saad, Choong Seon Hong</h3>
<p>The stringent requirements of mobile edge computing (MEC) applications and
functions fathom the high capacity and dense deployment of MEC hosts to the
upcoming wireless networks. However, operating such high capacity MEC hosts can
significantly increase energy consumption. Thus, a base station (BS) unit can
act as a self-powered BS. In this paper, an effective energy dispatch mechanism
for self-powered wireless networks with edge computing capabilities is studied.
First, a two-stage linear stochastic programming problem is formulated with the
goal of minimizing the total energy consumption cost of the system while
fulfilling the energy demand. Second, a semi-distributed data-driven solution
is proposed by developing a novel multi-agent meta-reinforcement learning
(MAMRL) framework to solve the formulated problem. In particular, each BS plays
the role of a local agent that explores a Markovian behavior for both energy
consumption and generation while each BS transfers time-varying features to a
meta-agent. Sequentially, the meta-agent optimizes (i.e., exploits) the energy
dispatch decision by accepting only the observations from each local agent with
its own state information. Meanwhile, each BS agent estimates its own energy
dispatch policy by applying the learned parameters from meta-agent. Finally,
the proposed MAMRL framework is benchmarked by analyzing deterministic,
asymmetric, and stochastic environments in terms of non-renewable energy
usages, energy cost, and accuracy. Experimental results show that the proposed
MAMRL model can reduce up to 11% non-renewable energy usage and by 22.4% the
energy cost (with 95.8% prediction accuracy), compared to other baseline
methods.
</p>
<a href="http://arxiv.org/abs/2002.08567" target="_blank">arXiv:2002.08567</a> [<a href="http://arxiv.org/pdf/2002.08567" target="_blank">pdf</a>]

<h2>On the Decision Boundaries of Neural Networks: A Tropical Geometry Perspective. (arXiv:2002.08838v2 [cs.LG] UPDATED)</h2>
<h3>Motasem Alfarra, Adel Bibi, Hasan Hammoud, Mohamed Gaafar, Bernard Ghanem</h3>
<p>This work tackles the problem of characterizing and understanding the
decision boundaries of neural networks with piecewise linear non-linearity
activations. We use tropical geometry, a new development in the area of
algebraic geometry, to characterize the decision boundaries of a simple network
of the form (Affine, ReLU, Affine). Our main finding is that the decision
boundaries are a subset of a tropical hypersurface, which is intimately related
to a polytope formed by the convex hull of two zonotopes. The generators of
these zonotopes are functions of the network parameters. This geometric
characterization provides new perspectives to three tasks. (i) We propose a new
tropical perspective to the lottery ticket hypothesis, where we view the effect
of different initializations on the tropical geometric representation of a
network's decision boundaries. (ii) Moreover, we propose new tropical based
optimization reformulations that directly influence the decision boundaries of
the network for the task of network pruning. (iii) At last, we discuss the
reformulation of the generation of adversarial attacks in a tropical sense. We
demonstrate that one can construct adversaries in a new tropical setting by
perturbing a specific set of decision boundaries by perturbing a set of
parameters in the network.
</p>
<a href="http://arxiv.org/abs/2002.08838" target="_blank">arXiv:2002.08838</a> [<a href="http://arxiv.org/pdf/2002.08838" target="_blank">pdf</a>]

<h2>Unification-based Reconstruction of Multi-hop Explanations for Science Questions. (arXiv:2004.00061v2 [cs.AI] UPDATED)</h2>
<h3>Marco Valentino, Mokanarangan Thayaparan, Andr&#xe9; Freitas</h3>
<p>This paper presents a novel framework for reconstructing multi-hop
explanations in science Question Answering (QA). While existing approaches for
multi-hop reasoning build explanations considering each question in isolation,
we propose a method to leverage explanatory patterns emerging in a corpus of
scientific explanations. Specifically, the framework ranks a set of atomic
facts by integrating lexical relevance with the notion of unification power,
estimated analysing explanations for similar questions in the corpus.

An extensive evaluation is performed on the Worldtree corpus, integrating
k-NN clustering and Information Retrieval (IR) techniques. We present the
following conclusions: (1) The proposed method achieves results competitive
with Transformers, yet being orders of magnitude faster, a feature that makes
it scalable to large explanatory corpora (2) The unification-based mechanism
has a key role in reducing semantic drift, contributing to the reconstruction
of many hops explanations (6 or more facts) and the ranking of complex
inference facts (+12.0 Mean Average Precision) (3) Crucially, the constructed
explanations can support downstream QA models, improving the accuracy of BERT
by up to 10% overall.
</p>
<a href="http://arxiv.org/abs/2004.00061" target="_blank">arXiv:2004.00061</a> [<a href="http://arxiv.org/pdf/2004.00061" target="_blank">pdf</a>]

<h2>A new hashing based nearest neighbors selection technique for big datasets. (arXiv:2004.02290v2 [cs.LG] UPDATED)</h2>
<h3>Jude Tchaye-Kondi, Yanlong Zhai, Liehuang Zhu</h3>
<p>KNN has the reputation to be the word simplest but efficient supervised
learning algorithm used for either classification or regression. KNN prediction
efficiency highly depends on the size of its training data but when this
training data grows KNN suffers from slowness in making decisions since it
needs to search nearest neighbors within the entire dataset at each decision
making. This paper proposes a new technique that enables the selection of
nearest neighbors directly in the neighborhood of a given observation. The
proposed approach consists of dividing the data space into subcells of a
virtual grid built on top of data space. The mapping between the data points
and subcells is performed using hashing. When it comes to select the nearest
neighbors of a given observation, we firstly identify the cell the observation
belongs by using hashing, and then we look for nearest neighbors from that
central cell and cells around it layer by layer. From our experiment
performance analysis on publicly available datasets, our algorithm outperforms
the original KNN in time efficiency with a prediction quality as good as that
of KNN it also offers competitive performance with solutions like KDtree
</p>
<a href="http://arxiv.org/abs/2004.02290" target="_blank">arXiv:2004.02290</a> [<a href="http://arxiv.org/pdf/2004.02290" target="_blank">pdf</a>]

<h2>Fully Convolutional Online Tracking. (arXiv:2004.07109v3 [cs.CV] UPDATED)</h2>
<h3>Yutao Cui, Cheng Jiang, Limin Wang, Gangshan Wu</h3>
<p>Online learning has turned out to be effective for improving tracking
performance. However, it could be simply applied for classification branch, but
still remains challenging for adapting to regression branch due to the complex
design. To tackle this issue, we present the first fully convolutional online
tracking framework (FCOT), with a focus on enabling online learning for both
classification and regression branches. Our key contribution is to introduce an
online regression model generator (RMG) based on the carefully designed
anchor-free box regression branch, which enables our FCOT to be more effective
in handling target deformation during tracking procedure. In addition, to deal
with the confusion of similar objects, we devise a simple yet effective
multi-scale classification branch to improve both accuracy and robustness of
FCOT. Due to its simplicity in design, our FCOT could be trained and deployed
in a fully convolutional manner with a running speed of 45FPS. The proposed
FCOT sets a new state-of-the-art results on six benchmarks including VOT2018,
LaSOT, TrackingNet, GOT-10k, UAV123, and NFS. Particularly, among real-time
trackers, our FCOT achieves EAO of 0.456 on VOT2018, NP of 0.678 on LaSOT, NP
of 0.828 on TrackingNet, and AO of 0.640 on GOT-10k. The code and models will
be made available at https://github.com/MCG-NJU/FCOT.
</p>
<a href="http://arxiv.org/abs/2004.07109" target="_blank">arXiv:2004.07109</a> [<a href="http://arxiv.org/pdf/2004.07109" target="_blank">pdf</a>]

<h2>DMT: Dynamic Mutual Training for Semi-Supervised Learning. (arXiv:2004.08514v3 [cs.CV] UPDATED)</h2>
<h3>Zhengyang Feng, Qianyu Zhou, Qiqi Gu, Xin Tan, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma</h3>
<p>Recent semi-supervised learning methods use pseudo supervision as core idea,
especially self-training methods that generate pseudo labels. However, pseudo
labels are unreliable. Self-training methods usually rely on single model
prediction confidence to filter low-confidence pseudo labels, thus remaining
high-confidence errors and wasting many low-confidence correct labels. In this
paper, we point out it is difficult for a model to counter its own errors.
Instead, leveraging inter-model disagreement between different models is a key
to locate pseudo label errors. With this new viewpoint, we propose mutual
training between two different models by a dynamically re-weighted loss
function, called Dynamic Mutual Training (DMT). We quantify inter-model
disagreement by comparing predictions from two different models to dynamically
re-weight loss in training, where a larger disagreement indicates a possible
error and corresponds to a lower loss value. Extensive experiments show that
DMT achieves state-of-the-art performance in both image classification and
semantic segmentation. Our codes are released at
https://github.com/voldemortX/DST-CBC .
</p>
<a href="http://arxiv.org/abs/2004.08514" target="_blank">arXiv:2004.08514</a> [<a href="http://arxiv.org/pdf/2004.08514" target="_blank">pdf</a>]

<h2>Interpretable Random Forests via Rule Extraction. (arXiv:2004.14841v4 [stat.ML] UPDATED)</h2>
<h3>Cl&#xe9;ment B&#xe9;nard (LPSM (UMR\_8001)), G&#xe9;rard Biau (LSTA), S&#xe9;bastien da Veiga, Erwan Scornet (CMAP)</h3>
<p>We introduce SIRUS (Stable and Interpretable RUle Set) for regression, a
stable rule learning algorithm which takes the form of a short and simple list
of rules. State-of-the-art learning algorithms are often referred to as "black
boxes" because of the high number of operations involved in their prediction
process. Despite their powerful predictivity, this lack of interpretability may
be highly restrictive for applications with critical decisions at stake. On the
other hand, algorithms with a simple structure-typically decision trees, rule
algorithms, or sparse linear models-are well known for their instability. This
undesirable feature makes the conclusions of the data analysis unreliable and
turns out to be a strong operational limitation. This motivates the design of
SIRUS, which combines a simple structure with a remarkable stable behavior when
data is perturbed. The algorithm is based on random forests, the predictive
accuracy of which is preserved. We demonstrate the efficiency of the method
both empirically (through experiments) and theoretically (with the proof of its
asymptotic stability). Our R/C++ software implementation sirus is available
from CRAN.
</p>
<a href="http://arxiv.org/abs/2004.14841" target="_blank">arXiv:2004.14841</a> [<a href="http://arxiv.org/pdf/2004.14841" target="_blank">pdf</a>]

<h2>A Causal View on Robustness of Neural Networks. (arXiv:2005.01095v3 [cs.LG] UPDATED)</h2>
<h3>Cheng Zhang, Kun Zhang, Yingzhen Li</h3>
<p>We present a causal view on the robustness of neural networks against input
manipulations, which applies not only to traditional classification tasks but
also to general measurement data. Based on this view, we design a deep causal
manipulation augmented model (deep CAMA) which explicitly models possible
manipulations on certain causes leading to changes in the observed effect. We
further develop data augmentation and test-time fine-tuning methods to improve
deep CAMA's robustness. When compared with discriminative deep neural networks,
our proposed model shows superior robustness against unseen manipulations. As a
by-product, our model achieves disentangled representation which separates the
representation of manipulations from those of other latent causes.
</p>
<a href="http://arxiv.org/abs/2005.01095" target="_blank">arXiv:2005.01095</a> [<a href="http://arxiv.org/pdf/2005.01095" target="_blank">pdf</a>]

<h2>Self-Training with Improved Regularization for Sample-Efficient Chest X-Ray Classification. (arXiv:2005.02231v2 [cs.CV] UPDATED)</h2>
<h3>Deepta Rajan, Jayaraman J. Thiagarajan, Alexandros Karargyris, Satyananda Kashyap</h3>
<p>Automated diagnostic assistants in healthcare necessitate accurate AI models
that can be trained with limited labeled data, can cope with severe class
imbalances and can support simultaneous prediction of multiple disease
conditions. To this end, we present a deep learning framework that utilizes a
number of key components to enable robust modeling in such challenging
scenarios. Using an important use-case in chest X-ray classification, we
provide several key insights on the effective use of data augmentation,
self-training via distillation and confidence tempering for small data learning
in medical imaging. Our results show that using 85% lesser labeled data, we can
build predictive models that match the performance of classifiers trained in a
large-scale data setting.
</p>
<a href="http://arxiv.org/abs/2005.02231" target="_blank">arXiv:2005.02231</a> [<a href="http://arxiv.org/pdf/2005.02231" target="_blank">pdf</a>]

<h2>Image-on-Scalar Regression via Deep Neural Networks. (arXiv:2006.09911v2 [stat.ML] UPDATED)</h2>
<h3>Daiwei Zhang, Lexin Li, Chandra Sripada, Jian Kang</h3>
<p>In medical imaging studies, a topic of central interest is the association
analysis of massive imaging data with covariates of interest. The difficulty
arises from the ultrahigh imaging dimensions, heterogeneous noises, and limited
number of training images. To address these challenges, we propose a novel and
conceptually straightforward neural network-based image-on-scalar regression
model, in which the spatially varying functions of the main effects, individual
deviations, and noise variances are all constructed through neural networks.
Compared with existing methods, our method can identify a wider variety of
spatial patterns, better captures the individual-wise heterogeneity, and is
less affected by a small number of individuals. We provide estimation and
selection algorithms with theoretically guaranteed asymptotic properties when
the number of voxels grows faster than the number of individuals. We
demonstrate the efficacy of our method through extensive simulation studies and
the analysis of the fMRI data in the Autism Brain Imaging Data Exchange study
and the Adolescent Brain Cognitive Development study.
</p>
<a href="http://arxiv.org/abs/2006.09911" target="_blank">arXiv:2006.09911</a> [<a href="http://arxiv.org/pdf/2006.09911" target="_blank">pdf</a>]

<h2>A Trainable Optimal Transport Embedding for Feature Aggregation and its Relationship to Attention. (arXiv:2006.12065v4 [cs.LG] UPDATED)</h2>
<h3>Gr&#xe9;goire Mialon, Dexiong Chen, Alexandre d&#x27;Aspremont, Julien Mairal</h3>
<p>We address the problem of learning on sets of features, motivated by the need
of performing pooling operations in long biological sequences of varying sizes,
with long-range dependencies, and possibly few labeled data. To address this
challenging task, we introduce a parametrized representation of fixed size,
which embeds and then aggregates elements from a given input set according to
the optimal transport plan between the set and a trainable reference. Our
approach scales to large datasets and allows end-to-end training of the
reference, while also providing a simple unsupervised learning mechanism with
small computational cost. Our aggregation technique admits two useful
interpretations: it may be seen as a mechanism related to attention layers in
neural networks, or it may be seen as a scalable surrogate of a classical
optimal transport-based kernel. We experimentally demonstrate the effectiveness
of our approach on biological sequences, achieving state-of-the-art results for
protein fold recognition and detection of chromatin profiles tasks, and, as a
proof of concept, we show promising results for processing natural language
sequences. We provide an open-source implementation of our embedding that can
be used alone or as a module in larger learning models at
https://github.com/claying/OTK.
</p>
<a href="http://arxiv.org/abs/2006.12065" target="_blank">arXiv:2006.12065</a> [<a href="http://arxiv.org/pdf/2006.12065" target="_blank">pdf</a>]

<h2>Offline Contextual Bandits with Overparameterized Models. (arXiv:2006.15368v3 [cs.LG] UPDATED)</h2>
<h3>David Brandfonbrener, William F. Whitney, Rajesh Ranganath, Joan Bruna</h3>
<p>Recent results in supervised learning suggest that while overparameterized
models have the capacity to overfit, they in fact generalize quite well. We ask
whether the same phenomenon occurs for offline contextual bandits. Our results
are mixed. Value-based algorithms benefit from the same generalization behavior
as overparameterized supervised learning, but policy-based algorithms do not.
We show that this discrepancy is due to the \emph{action-stability} of their
objectives. An objective is action-stable if there exists a prediction
(action-value vector or action distribution) which is optimal no matter which
action is observed. While value-based objectives are action-stable,
policy-based objectives are unstable. We formally prove upper bounds on the
regret of overparameterized value-based learning and lower bounds on the regret
for policy-based algorithms. In our experiments with large neural networks,
this gap between action-stable value-based objectives and unstable policy-based
objectives leads to significant performance differences.
</p>
<a href="http://arxiv.org/abs/2006.15368" target="_blank">arXiv:2006.15368</a> [<a href="http://arxiv.org/pdf/2006.15368" target="_blank">pdf</a>]

<h2>AEGCN: An Autoencoder-Constrained Graph Convolutional Network. (arXiv:2007.03424v3 [cs.LG] UPDATED)</h2>
<h3>Mingyuan Ma, Sen Na, Hongyu Wang</h3>
<p>We propose a novel neural network architecture, called
autoencoder-constrained graph convolutional network, to solve node
classification task on graph domains. As suggested by its name, the core of
this model is a convolutional network operating directly on graphs, whose
hidden layers are constrained by an autoencoder. Comparing with vanilla graph
convolutional networks, the autoencoder step is added to reduce the information
loss brought by Laplacian smoothing. We consider applying our model on both
homogeneous graphs and heterogeneous graphs. For homogeneous graphs, the
autoencoder approximates to the adjacency matrix of the input graph by taking
hidden layer representations as encoder and another one-layer graph
convolutional network as decoder. For heterogeneous graphs, since there are
multiple adjacency matrices corresponding to different types of edges, the
autoencoder approximates to the feature matrix of the input graph instead, and
changes the encoder to a particularly designed multi-channel pre-processing
network with two layers. In both cases, the error occurred in the autoencoder
approximation goes to the penalty term in the loss function. In extensive
experiments on citation networks and other heterogeneous graphs, we demonstrate
that adding autoencoder constraints significantly improves the performance of
graph convolutional networks. Further, we notice that our technique can be
applied on graph attention network to improve the performance as well. This
reveals the wide applicability of the proposed autoencoder technique.
</p>
<a href="http://arxiv.org/abs/2007.03424" target="_blank">arXiv:2007.03424</a> [<a href="http://arxiv.org/pdf/2007.03424" target="_blank">pdf</a>]

<h2>CD-split and HPD-split: efficient conformal regions in high dimensions. (arXiv:2007.12778v2 [stat.ML] UPDATED)</h2>
<h3>Rafael Izbicki, Gilson Shimizu, Rafael B. Stern</h3>
<p>Conformal methods create prediction bands that control average coverage
assuming solely i.i.d. data. Although the literature has mostly focused on
prediction intervals, more general regions can often better represent
uncertainty. For instance, a bimodal target is better represented by the union
of two intervals. Such prediction regions are obtained by CD-split , which
combines the split method and a data-driven partition of the feature space
which scales to high dimensions. CD-split however contains many tuning
parameters, and their role is not clear. In this paper, we provide new insights
on CD-split by exploring its theoretical properties. In particular, we show
that CD-split converges asymptotically to the oracle highest predictive density
set and satisfies local and asymptotic conditional validity. We also present
simulations which show how to tune CD-split. Finally, we introduce HPD-split, a
variation of CD-split that requires less tuning, and show that it shares the
same theoretical guarantees as CD-split. In a wide variety of our simulations,
CD-split and HPD-split have a better conditional coverage and yield smaller
prediction regions than other methods.
</p>
<a href="http://arxiv.org/abs/2007.12778" target="_blank">arXiv:2007.12778</a> [<a href="http://arxiv.org/pdf/2007.12778" target="_blank">pdf</a>]

<h2>Change Point Detection in Time Series Data using Autoencoders with a Time-Invariant Representation. (arXiv:2008.09524v2 [cs.LG] UPDATED)</h2>
<h3>Tim De Ryck, Maarten De Vos, Alexander Bertrand</h3>
<p>Change point detection (CPD) aims to locate abrupt property changes in time
series data. Recent CPD methods demonstrated the potential of using deep
learning techniques, but often lack the ability to identify more subtle changes
in the autocorrelation statistics of the signal and suffer from a high false
alarm rate. To address these issues, we employ an autoencoder-based methodology
with a novel loss function, through which the used autoencoders learn a
partially time-invariant representation that is tailored for CPD. The result is
a flexible method that allows the user to indicate whether change points should
be sought in the time domain, frequency domain or both. Detectable change
points include abrupt changes in the slope, mean, variance, autocorrelation
function and frequency spectrum. We demonstrate that our proposed method is
consistently highly competitive or superior to baseline methods on diverse
simulated and real-life benchmark data sets. Finally, we mitigate the issue of
false detection alarms through the use of a postprocessing procedure that
combines a matched filter and a newly proposed change point score. We show that
this combination drastically improves the performance of our method as well as
all baseline methods.
</p>
<a href="http://arxiv.org/abs/2008.09524" target="_blank">arXiv:2008.09524</a> [<a href="http://arxiv.org/pdf/2008.09524" target="_blank">pdf</a>]

<h2>Constrained Labeling for Weakly Supervised Learning. (arXiv:2009.07360v4 [cs.LG] UPDATED)</h2>
<h3>Chidubem Arachie, Bert Huang</h3>
<p>Curation of large fully supervised datasets has become one of the major
roadblocks for machine learning. Weak supervision provides an alternative to
supervised learning by training with cheap, noisy, and possibly correlated
labeling functions from varying sources. The key challenge in weakly supervised
learning is combining the different weak supervision signals while navigating
misleading correlations in their errors. In this paper, we propose a simple
data-free approach for combining weak supervision signals by defining a
constrained space for the possible labels of the weak signals and training with
a random labeling within this constrained space. Our method is efficient and
stable, converging after a few iterations of gradient descent. We prove
theoretical conditions under which the worst-case error of the randomized label
decreases with the rank of the linear constraints. We show experimentally that
our method outperforms other weak supervision methods on various text- and
image-classification tasks.
</p>
<a href="http://arxiv.org/abs/2009.07360" target="_blank">arXiv:2009.07360</a> [<a href="http://arxiv.org/pdf/2009.07360" target="_blank">pdf</a>]

<h2>Neural Rough Differential Equations for Long Time Series. (arXiv:2009.08295v2 [cs.LG] UPDATED)</h2>
<h3>James Morrill, Cristopher Salvi, Patrick Kidger, James Foster, Terry Lyons</h3>
<p>Neural controlled differential equations (CDEs) are the continuous-time
analogue of recurrent neural networks, as Neural ODEs are to residual networks,
and offer a memory-efficient continuous-time way to model functions of
potentially irregular time series. Existing methods for computing the forward
pass of a Neural CDE involve embedding the incoming time series into path
space, often via interpolation, and using evaluations of this path to drive the
hidden state. Here, we use rough path theory to extend this formulation.
Instead of directly embedding into path space, we instead represent the input
signal over small time intervals through its \textit{log-signature}, which are
statistics describing how the signal drives a CDE. This is the approach for
solving \textit{rough differential equations} (RDEs), and correspondingly we
describe our main contribution as the introduction of Neural RDEs. This
extension has a purpose: by generalising the Neural CDE approach to a broader
class of driving signals, we demonstrate particular advantages for tackling
long time series. In this regime, we demonstrate efficacy on problems of length
up to 17k observations and observe significant training speed-ups, improvements
in model performance, and reduced memory requirements compared to existing
approaches.
</p>
<a href="http://arxiv.org/abs/2009.08295" target="_blank">arXiv:2009.08295</a> [<a href="http://arxiv.org/pdf/2009.08295" target="_blank">pdf</a>]

<h2>Tailoring: encoding inductive biases by optimizing unsupervised objectives at prediction time. (arXiv:2009.10623v3 [cs.LG] UPDATED)</h2>
<h3>Ferran Alet, Maria Bauza, Kenji Kawaguchi, Nurullah Giray Kuru, Tomas Lozano-Perez, Leslie Pack Kaelbling</h3>
<p>From CNNs to attention mechanisms, encoding inductive biases into neural
networks has been a fruitful source of improvement in machine learning. Adding
auxiliary losses to the main objective function is a general way of encoding
biases that can help networks learn better representations. However, since
auxiliary losses are minimized only on training data, they suffer from the same
generalization gap as regular task losses. Moreover, by adding a term to the
loss function, the model optimizes a different objective than the one we care
about. In this work we address both problems: first, we take inspiration from
transductive learning and note that, after receiving an input but before making
a prediction, we can fine-tune our networks on any unsupervised loss. We call
this process tailoring, because we customize the model to each input to ensure
our prediction satisfies the inductive bias. Second, we formulate
meta-tailoring, a nested optimization similar to that in meta-learning, and
train our models to perform well on the task objective after adapting them
using an unsupervised loss.
</p>
<a href="http://arxiv.org/abs/2009.10623" target="_blank">arXiv:2009.10623</a> [<a href="http://arxiv.org/pdf/2009.10623" target="_blank">pdf</a>]

<h2>Deep multi-stations weather forecasting: explainable recurrent convolutional neural networks. (arXiv:2009.11239v6 [cs.LG] UPDATED)</h2>
<h3>Ismail Alaoui Abdellaoui, Siamak Mehrkanoon</h3>
<p>Deep learning applied to weather forecasting has started gaining popularity
because of the progress achieved by data-driven models. The present paper
compares two different deep learning architectures to perform weather
prediction on daily data gathered from 18 cities across Europe and spanned over
a period of 15 years. We propose the Deep Attention Unistream Multistream
(DAUM) networks that investigate different types of input representations (i.e.
tensorial unistream vs. multistream ) as well as the incorporation of the
attention mechanism. In particular, we show that adding a self-attention block
within the models increases the overall forecasting performance. Furthermore,
visualization techniques such as occlusion analysis and score maximization are
used to give an additional insight on the most important features and cities
for predicting a particular target feature of target cities.
</p>
<a href="http://arxiv.org/abs/2009.11239" target="_blank">arXiv:2009.11239</a> [<a href="http://arxiv.org/pdf/2009.11239" target="_blank">pdf</a>]

<h2>Towards General Purpose Geometry-Preserving Single-View Depth Estimation. (arXiv:2009.12419v2 [cs.CV] UPDATED)</h2>
<h3>Mikhail Romanov, Nikolay Patatkin, Anna Vorontsova, Sergey Nikolenko, Anton Konushin, Dmitry Senyushkin</h3>
<p>Single-view depth estimation (SVDE) plays a crucial role in scene
understanding for AR applications, 3D modeling, and robotics, providing the
geometry of a scene based on a single image. Recent works have shown that a
successful solution strongly relies on the diversity and volume of training
data. This data can be sourced from stereo movies and photos. However, they do
not provide geometrically complete depth maps (as disparities contain unknown
shift value). Therefore, existing models trained on this data are not able to
recover correct 3D representations. Our work shows that a model trained on this
data along with conventional datasets can gain accuracy while predicting
correct scene geometry. Surprisingly, only a small portion of geometrically
correct depth maps are required to train a model that performs equally to a
model trained on the full geometrically correct dataset. After that, we train
computationally efficient models on a mixture of datasets using the proposed
method. Through quantitative comparison on completely unseen datasets and
qualitative comparison of 3D point clouds, we show that our model defines the
new state of the art in general-purpose SVDE.
</p>
<a href="http://arxiv.org/abs/2009.12419" target="_blank">arXiv:2009.12419</a> [<a href="http://arxiv.org/pdf/2009.12419" target="_blank">pdf</a>]

<h2>Query complexity of adversarial attacks. (arXiv:2010.01039v2 [cs.LG] UPDATED)</h2>
<h3>Grzegorz G&#x142;uch, R&#xfc;diger Urbanke</h3>
<p>There are two main attack models considered in the adversarial robustness
literature: black-box and white-box. We consider these threat models as two
ends of a fine-grained spectrum, indexed by the number of queries the adversary
can ask. Using this point of view we investigate how many queries the adversary
needs to make to design an attack that is comparable to the best possible
attack in the white-box model. We give a lower bound on that number of queries
in terms of entropy of decision boundaries of the classifier. Using this result
we analyze two classical learning algorithms on two synthetic tasks for which
we prove meaningful security guarantees. The obtained bounds suggest that some
learning algorithms are inherently more robust against query-bounded
adversaries than others.
</p>
<a href="http://arxiv.org/abs/2010.01039" target="_blank">arXiv:2010.01039</a> [<a href="http://arxiv.org/pdf/2010.01039" target="_blank">pdf</a>]

<h2>Learning the Step-size Policy for the Limited-Memory Broyden-Fletcher-Goldfarb-Shanno Algorithm. (arXiv:2010.01311v2 [cs.LG] UPDATED)</h2>
<h3>Lucas N. Egidio, Anders Hansson, Bo Wahlberg</h3>
<p>We consider the problem of how to learn a step-size policy for the
Limited-Memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm. This is a
limited computational memory quasi-Newton method widely used for deterministic
unconstrained optimization but currently avoided in large-scale problems for
requiring step sizes to be provided at each iteration. Existing methodologies
for the step size selection for L-BFGS use heuristic tuning of design
parameters and massive re-evaluations of the objective function and gradient to
find appropriate step-lengths. We propose a neural network architecture with
local information of the current iterate as the input. The step-length policy
is learned from data of similar optimization problems, avoids additional
evaluations of the objective function, and guarantees that the output step
remains inside a pre-defined interval. The corresponding training procedure is
formulated as a stochastic optimization problem using the backpropagation
through time algorithm. The performance of the proposed method is evaluated on
the training of classifiers for the MNIST database for handwritten digits and
for CIFAR-10. The results show that the proposed algorithm outperforms
heuristically tuned optimizers such as ADAM, RMSprop, L-BFGS with a
backtracking line search, and L-BFGS with a constant step size. The numerical
results also show that a learned policy can be used as a warm-start to train
new policies for different problems after a few additional training steps,
highlighting its potential use in multiple large-scale optimization problems.
</p>
<a href="http://arxiv.org/abs/2010.01311" target="_blank">arXiv:2010.01311</a> [<a href="http://arxiv.org/pdf/2010.01311" target="_blank">pdf</a>]

<h2>Detecting Misclassification Errors in Neural Networks with a Gaussian Process Model. (arXiv:2010.02065v2 [cs.LG] UPDATED)</h2>
<h3>Xin Qiu, Risto Miikkulainen</h3>
<p>As neural network classifiers are deployed in real-world applications, it is
crucial that their failures can be detected reliably. One practical solution is
to assign confidence scores to each prediction, then use these scores to filter
out possible misclassifications. However, existing confidence metrics are not
yet sufficiently reliable for this role. This paper presents a new framework
that produces a more reliable quantitative metric for detecting
misclassification errors. This framework, RED, builds an error detector on top
of the base classifier and estimates uncertainty of the detection scores using
Gaussian Processes. Empirical comparisons with other error detection methods on
125 UCI datasets demonstrate that this approach is effective. Additional
implementations on two probabilistic base classifiers and a large deep learning
architecture solving a vision task further confirm the robustness of the
method. A case study involving out-of-distribution and adversarial samples
shows potential of the proposed method to improve trustworthiness of neural
network classifiers more broadly in the future.
</p>
<a href="http://arxiv.org/abs/2010.02065" target="_blank">arXiv:2010.02065</a> [<a href="http://arxiv.org/pdf/2010.02065" target="_blank">pdf</a>]

<h2>Learning Value Functions in Deep Policy Gradients using Residual Variance. (arXiv:2010.04440v2 [cs.LG] UPDATED)</h2>
<h3>Yannis Flet-Berliac, Reda Ouhamma, Odalric-Ambrym Maillard, Philippe Preux</h3>
<p>Policy gradient algorithms have proven to be successful in diverse decision
making and control tasks. However, these methods suffer from high sample
complexity and instability issues. In this paper, we address these challenges
by providing a different approach for training the critic in the actor-critic
framework. Our work builds on recent studies indicating that traditional
actor-critic algorithms do not succeed in fitting the true value function,
calling for the need to identify a better objective for the critic. In our
method, the critic uses a new state-value (resp. state-action-value) function
approximation that learns the value of the states (resp. state-action pairs)
relative to their mean value rather than the absolute value as in conventional
actor-critic. We prove the theoretical consistency of the new gradient
estimator and observe dramatic empirical improvement across a variety of
continuous control tasks and algorithms. Furthermore, we validate our method in
tasks with sparse rewards, where we provide experimental evidence and
theoretical insights.
</p>
<a href="http://arxiv.org/abs/2010.04440" target="_blank">arXiv:2010.04440</a> [<a href="http://arxiv.org/pdf/2010.04440" target="_blank">pdf</a>]

<h2>Augmenting Physical Models with Deep Networks for Complex Dynamics Forecasting. (arXiv:2010.04456v2 [stat.ML] UPDATED)</h2>
<h3>Vincent Le Guen, Yuan Yin, J&#xe9;r&#xe9;mie Dona, Ibrahim Ayed, Emmanuel de B&#xe9;zenac, Nicolas Thome, Patrick Gallinari</h3>
<p>Forecasting complex dynamical phenomena in settings where only partial
knowledge of their dynamics is available is a prevalent problem across various
scientific fields. While purely data-driven approaches are arguably
insufficient in this context, standard physical modeling based approaches tend
to be over-simplistic, inducing non-negligible errors. In this work, we
introduce the APHYNITY framework, a principled approach for augmenting
incomplete physical dynamics described by differential equations with deep
data-driven models. It consists in decomposing the dynamics into two
components: a physical component accounting for the dynamics for which we have
some prior knowledge, and a data-driven component accounting for errors of the
physical model. The learning problem is carefully formulated such that the
physical model explains as much of the data as possible, while the data-driven
component only describes information that cannot be captured by the physical
model, no more, no less. This not only provides the existence and uniqueness
for this decomposition, but also ensures interpretability and benefits
generalization. Experiments made on three important use cases, each
representative of a different family of phenomena, i.e. reaction-diffusion
equations, wave equations and the non-linear damped pendulum, show that
APHYNITY can efficiently leverage approximate physical models to accurately
forecast the evolution of the system and correctly identify relevant physical
parameters.
</p>
<a href="http://arxiv.org/abs/2010.04456" target="_blank">arXiv:2010.04456</a> [<a href="http://arxiv.org/pdf/2010.04456" target="_blank">pdf</a>]

<h2>Graph Convolutional Value Decomposition in Multi-Agent Reinforcement Learning. (arXiv:2010.04740v2 [cs.LG] UPDATED)</h2>
<h3>Navid Naderializadeh, Fan H. Hung, Sean Soleyman, Deepak Khosla</h3>
<p>We propose a novel framework for value function factorization in multi-agent
deep reinforcement learning (MARL) using graph neural networks (GNNs). In
particular, we consider the team of agents as the set of nodes of a complete
directed graph, whose edge weights are governed by an attention mechanism.
Building upon this underlying graph, we introduce a mixing GNN module, which is
responsible for i) factorizing the team state-action value function into
individual per-agent observation-action value functions, and ii) explicit
credit assignment to each agent in terms of fractions of the global team
reward. Our approach, which we call GraphMIX, follows the centralized training
and decentralized execution paradigm, enabling the agents to make their
decisions independently once training is completed. We show the superiority of
GraphMIX as compared to the state-of-the-art on several scenarios in the
StarCraft II multi-agent challenge (SMAC) benchmark. We further demonstrate how
GraphMIX can be used in conjunction with a recent hierarchical MARL
architecture to both improve the agents' performance and enable fine-tuning
them on mismatched test scenarios with higher numbers of agents and/or actions.
</p>
<a href="http://arxiv.org/abs/2010.04740" target="_blank">arXiv:2010.04740</a> [<a href="http://arxiv.org/pdf/2010.04740" target="_blank">pdf</a>]

<h2>How Important is the Train-Validation Split in Meta-Learning?. (arXiv:2010.05843v2 [cs.LG] UPDATED)</h2>
<h3>Yu Bai, Minshuo Chen, Pan Zhou, Tuo Zhao, Jason D. Lee, Sham Kakade, Huan Wang, Caiming Xiong</h3>
<p>Meta-learning aims to perform fast adaptation on a new task through learning
a "prior" from multiple existing tasks. A common practice in meta-learning is
to perform a train-validation split (\emph{train-val method}) where the prior
adapts to the task on one split of the data, and the resulting predictor is
evaluated on another split. Despite its prevalence, the importance of the
train-validation split is not well understood either in theory or in practice,
particularly in comparison to the more direct \emph{train-train method}, which
uses all the per-task data for both training and evaluation.

We provide a detailed theoretical study on whether and when the
train-validation split is helpful in the linear centroid meta-learning problem.
In the agnostic case, we show that the expected loss of the train-val method is
minimized at the optimal prior for meta testing, and this is not the case for
the train-train method in general without structural assumptions on the data.
In contrast, in the realizable case where the data are generated from linear
models, we show that both the train-val and train-train losses are minimized at
the optimal prior in expectation. Further, perhaps surprisingly, our main
result shows that the train-train method achieves a \emph{strictly better}
excess loss in this realizable case, even when the regularization parameter and
split ratio are optimally tuned for both methods. Our results highlight that
sample splitting may not always be preferable, especially when the data is
realizable by the model. We validate our theories by experimentally showing
that the train-train method can indeed outperform the train-val method, on both
simulations and real meta-learning tasks.
</p>
<a href="http://arxiv.org/abs/2010.05843" target="_blank">arXiv:2010.05843</a> [<a href="http://arxiv.org/pdf/2010.05843" target="_blank">pdf</a>]

<h2>Deep Learning Models for Predicting Wildfires from Historical Remote-Sensing Data. (arXiv:2010.07445v3 [cs.CV] UPDATED)</h2>
<h3>Fantine Huot, R. Lily Hu, Matthias Ihme, Qing Wang, John Burge, Tianjian Lu, Jason Hickey, Yi-Fan Chen, John Anderson</h3>
<p>Identifying regions that have high likelihood for wildfires is a key
component of land and forestry management and disaster preparedness. We create
a data set by aggregating nearly a decade of remote-sensing data and historical
fire records to predict wildfires. This prediction problem is framed as three
machine learning tasks. Results are compared and analyzed for four different
deep learning models to estimate wildfire likelihood. The results demonstrate
that deep learning models can successfully identify areas of high fire
likelihood using aggregated data about vegetation, weather, and topography with
an AUC of 83%.
</p>
<a href="http://arxiv.org/abs/2010.07445" target="_blank">arXiv:2010.07445</a> [<a href="http://arxiv.org/pdf/2010.07445" target="_blank">pdf</a>]

<h2>Maximum Moment Restriction for Instrumental Variable Regression. (arXiv:2010.07684v2 [cs.LG] UPDATED)</h2>
<h3>Rui Zhang, Masaaki Imaizumi, Bernhard Sch&#xf6;lkopf, Krikamol Muandet</h3>
<p>We propose a simple framework for nonlinear instrumental variable (IV)
regression based on a kernelized conditional moment restriction (CMR) known as
a maximum moment restriction (MMR). The MMR is formulated by maximizing the
interaction between the residual and the instruments belonging to a unit ball
in a reproducing kernel Hilbert space (RKHS). The MMR allows us to reformulate
the IV regression as a single-step empirical risk minimization problem, where
the risk depends on the reproducing kernel on the instrument and can be
estimated by a U-statistic or V-statistic. This simplification not only eases
the proofs of consistency and asymptotic normality in both parametric and
non-parametric settings, but also results in easy-to-use algorithms with an
efficient hyper-parameter selection procedure. We demonstrate the advantages of
our framework over existing ones using experiments on both synthetic and
real-world data.
</p>
<a href="http://arxiv.org/abs/2010.07684" target="_blank">arXiv:2010.07684</a> [<a href="http://arxiv.org/pdf/2010.07684" target="_blank">pdf</a>]

<h2>An Identifiable Double VAE For Disentangled Representations. (arXiv:2010.09360v2 [cs.LG] UPDATED)</h2>
<h3>Graziano Mita, Maurizio Filippone, Pietro Michiardi</h3>
<p>A large part of the literature on learning disentangled representations
focuses on variational autoencoders (VAE). Recent developments demonstrate that
disentanglement cannot be obtained in a fully unsupervised setting without
inductive biases on models and data. However, Khemakhem et al., AISTATS, 2020
suggest that employing a particular form of factorized prior, conditionally
dependent on auxiliary variables complementing input observations, can be one
such bias, resulting in an identifiable model with guarantees on
disentanglement. Working along this line, we propose a novel VAE-based
generative model with theoretical guarantees on identifiability. We obtain our
conditional prior over the latents by learning an optimal representation, which
imposes an additional strength on their regularization. We also extend our
method to semi-supervised settings. Experimental results indicate superior
performance with respect to state-of-the-art approaches, according to several
established metrics proposed in the literature on disentanglement.
</p>
<a href="http://arxiv.org/abs/2010.09360" target="_blank">arXiv:2010.09360</a> [<a href="http://arxiv.org/pdf/2010.09360" target="_blank">pdf</a>]

<h2>Autoencoder Watchdog Outlier Detection for Classifiers. (arXiv:2010.12754v2 [cs.LG] UPDATED)</h2>
<h3>Justin Bui, Robert J Marks II</h3>
<p>Neural networks have often been described as black boxes. A generic neural
network trained to differentiate between kittens and puppies will classify a
picture of a kumquat as a kitten or a puppy. An autoencoder watch dog screens
trained classifier/regression machine input candidates before processing, e.g.
to first test whether the neural network input is a puppy or a kitten.
Preliminary results are presented using convolutional neural networks and
convolutional autoencoder watchdogs using MNIST images.
</p>
<a href="http://arxiv.org/abs/2010.12754" target="_blank">arXiv:2010.12754</a> [<a href="http://arxiv.org/pdf/2010.12754" target="_blank">pdf</a>]

<h2>Transporter Networks: Rearranging the Visual World for Robotic Manipulation. (arXiv:2010.14406v2 [cs.RO] UPDATED)</h2>
<h3>Andy Zeng, Pete Florence, Jonathan Tompson, Stefan Welker, Jonathan Chien, Maria Attarian, Travis Armstrong, Ivan Krasin, Dan Duong, Vikas Sindhwani, Johnny Lee</h3>
<p>Robotic manipulation can be formulated as inducing a sequence of spatial
displacements: where the space being moved can encompass an object, part of an
object, or end effector. In this work, we propose the Transporter Network, a
simple model architecture that rearranges deep features to infer spatial
displacements from visual input - which can parameterize robot actions. It
makes no assumptions of objectness (e.g. canonical poses, models, or
keypoints), it exploits spatial symmetries, and is orders of magnitude more
sample efficient than our benchmarked alternatives in learning vision-based
manipulation tasks: from stacking a pyramid of blocks, to assembling kits with
unseen objects; from manipulating deformable ropes, to pushing piles of small
objects with closed-loop feedback. Our method can represent complex multi-modal
policy distributions and generalizes to multi-step sequential tasks, as well as
6DoF pick-and-place. Experiments on 10 simulated tasks show that it learns
faster and generalizes better than a variety of end-to-end baselines, including
policies that use ground-truth object poses. We validate our methods with
hardware in the real world. Experiment videos and code are available at
https://transporternets.github.io
</p>
<a href="http://arxiv.org/abs/2010.14406" target="_blank">arXiv:2010.14406</a> [<a href="http://arxiv.org/pdf/2010.14406" target="_blank">pdf</a>]

<h2>Section Patterns: Efficiently Solving Narrow Passage Problems in Multilevel Motion Planning. (arXiv:2010.14524v2 [cs.RO] UPDATED)</h2>
<h3>Andreas Orthey, Marc Toussaint</h3>
<p>Sampling-based planning methods often become inefficient due to narrow
passages. Narrow passages induce a higher runtime, because the chance to sample
them becomes vanishingly small. In recent work, we showed that narrow passages
can be approached by relaxing the problem using admissible lower-dimensional
projections of the state space. Those relaxations often increase the volume of
narrow passages under projection. Solving the relaxed problem is often
efficient and produces an admissible heuristic we can exploit. However, given a
base path, i.e. a solution to a relaxed problem, there are currently no
tailored methods to efficiently exploit the base path. To efficiently exploit
the base path and thereby its admissible heuristic, we develop section
patterns, which are solution strategies to efficiently exploit base paths in
particular around narrow passages. To coordinate section patterns, we develop
the pattern dance algorithm, which efficiently coordinates section patterns to
reactively traverse narrow passages. We combine the pattern dance algorithm
with previously developed multilevel planning algorithms and benchmark them on
challenging planning problems like the Bugtrap, the double L-shape, an egress
problem and on four pregrasp scenarios for a 37 degrees of freedom shadow hand
mounted on a KUKA LWR robot. Our results confirm that section patterns are
useful to efficiently solve high-dimensional narrow passage motion planning
problems.
</p>
<a href="http://arxiv.org/abs/2010.14524" target="_blank">arXiv:2010.14524</a> [<a href="http://arxiv.org/pdf/2010.14524" target="_blank">pdf</a>]

<h2>Multiview Variational Graph Autoencoders for Canonical Correlation Analysis. (arXiv:2010.16132v2 [cs.LG] UPDATED)</h2>
<h3>Yacouba Kaloga, Pierre Borgnat, Sundeep Prabhakar Chepuri, Patrice Abry, Amaury Habrard</h3>
<p>We present a novel multiview canonical correlation analysis model based on a
variational approach. This is the first nonlinear model that takes into account
the available graph-based geometric constraints while being scalable for
processing large scale datasets with multiple views. It is based on an
autoencoder architecture with graph convolutional neural network layers. We
experiment with our approach on classification, clustering, and recommendation
tasks on real datasets. The algorithm is competitive with state-of-the-art
multiview representation learning techniques.
</p>
<a href="http://arxiv.org/abs/2010.16132" target="_blank">arXiv:2010.16132</a> [<a href="http://arxiv.org/pdf/2010.16132" target="_blank">pdf</a>]

<h2>Self-paced and self-consistent co-training for semi-supervised image segmentation. (arXiv:2011.00325v4 [cs.CV] UPDATED)</h2>
<h3>Ping Wang, Jizong Peng, Marco Pedersoli, Yuanfeng Zhou, Caiming Zhang, Christian Desrosiers</h3>
<p>Deep co-training has recently been proposed as an effective approach for
image segmentation when annotated data is scarce. In this paper, we improve
existing approaches for semi-supervised segmentation with a self-paced and
self-consistent co-training method. To help distillate information from
unlabeled images, we first design a self-paced learning strategy for
co-training that lets jointly-trained neural networks focus on
easier-to-segment regions first, and then gradually consider harder ones.This
is achieved via an end-to-end differentiable loss inthe form of a generalized
Jensen Shannon Divergence(JSD). Moreover, to encourage predictions from
different networks to be both consistent and confident, we enhance this
generalized JSD loss with an uncertainty regularizer based on entropy. The
robustness of individual models is further improved using a self-ensembling
loss that enforces their prediction to be consistent across different training
iterations. We demonstrate the potential of our method on three challenging
image segmentation problems with different image modalities, using small
fraction of labeled data. Results show clear advantages in terms of performance
compared to the standard co-training baselines and recently proposed
state-of-the-art approaches for semi-supervised segmentation
</p>
<a href="http://arxiv.org/abs/2011.00325" target="_blank">arXiv:2011.00325</a> [<a href="http://arxiv.org/pdf/2011.00325" target="_blank">pdf</a>]

<h2>Dynamically Sampled Nonlocal Gradients for Stronger Adversarial Attacks. (arXiv:2011.02707v2 [cs.LG] UPDATED)</h2>
<h3>Leo Schwinn, An Nguyen, Ren&#xe9; Raab, Dario Zanca, Bjoern Eskofier, Daniel Tenbrinck, Martin Burger</h3>
<p>The vulnerability of deep neural networks to small and even imperceptible
perturbations has become a central topic in deep learning research. Although
several sophisticated defense mechanisms have been introduced, most were later
shown to be ineffective. However, a reliable evaluation of model robustness is
mandatory for deployment in safety-critical scenarios. To overcome this problem
we propose a simple yet effective modification to the gradient calculation of
state-of-the-art first-order adversarial attacks. Normally, the gradient update
of an attack is directly calculated for the given data point. This approach is
sensitive to noise and small local optima of the loss function. Inspired by
gradient sampling techniques from non-convex optimization, we propose
Dynamically Sampled Nonlocal Gradient Descent (DSNGD). DSNGD calculates the
gradient direction of the adversarial attack as the weighted average over past
gradients of the optimization history. Moreover, distribution hyperparameters
that define the sampling operation are automatically learned during the
optimization scheme. We empirically show that by incorporating this nonlocal
gradient information, we are able to give a more accurate estimation of the
global descent direction on noisy and non-convex loss surfaces. In addition, we
show that DSNGD-based attacks are on average 35% faster while achieving 0.9% to
27.1% higher success rates compared to their gradient descent-based
counterparts.
</p>
<a href="http://arxiv.org/abs/2011.02707" target="_blank">arXiv:2011.02707</a> [<a href="http://arxiv.org/pdf/2011.02707" target="_blank">pdf</a>]

<h2>Robustness and Diversity Seeking Data-Free Knowledge Distillation. (arXiv:2011.03749v3 [cs.LG] UPDATED)</h2>
<h3>Pengchao Han, Jihong Park, Shiqiang Wang, Yejun Liu</h3>
<p>Knowledge distillation (KD) has enabled remarkable progress in model
compression and knowledge transfer. However, KD requires a large volume of
original data or their representation statistics that are not usually available
in practice. Data-free KD has recently been proposed to resolve this problem,
wherein teacher and student models are fed by a synthetic sample generator
trained from the teacher. Nonetheless, existing data-free KD methods rely on
fine-tuning of weights to balance multiple losses, and ignore the diversity of
generated samples, resulting in limited accuracy and robustness. To overcome
this challenge, we propose robustness and diversity seeking data-free KD
(RDSKD) in this paper. The generator loss function is crafted to produce
samples with high authenticity, class diversity, and inter-sample diversity.
Without real data, the objectives of seeking high sample authenticity and class
diversity often conflict with each other, causing frequent loss fluctuations.
We mitigate this by exponentially penalizing loss increments. With MNIST,
CIFAR-10, and SVHN datasets, our experiments show that RDSKD achieves higher
accuracy with more robustness over different hyperparameter settings, compared
to other data-free KD methods such as DAFL, MSKD, ZSKD, and DeepInversion.
</p>
<a href="http://arxiv.org/abs/2011.03749" target="_blank">arXiv:2011.03749</a> [<a href="http://arxiv.org/pdf/2011.03749" target="_blank">pdf</a>]

<h2>Online Sparse Reinforcement Learning. (arXiv:2011.04018v4 [cs.LG] UPDATED)</h2>
<h3>Botao Hao, Tor Lattimore, Csaba Szepesv&#xe1;ri, Mengdi Wang</h3>
<p>We investigate the hardness of online reinforcement learning in fixed
horizon, sparse linear Markov decision process (MDP), with a special focus on
the high-dimensional regime where the ambient dimension is larger than the
number of episodes. Our contribution is two-fold. First, we provide a lower
bound showing that linear regret is generally unavoidable in this case, even if
there exists a policy that collects well-conditioned data. The lower bound
construction uses an MDP with a fixed number of states while the number of
actions scales with the ambient dimension. Note that when the horizon is fixed
to one, the case of linear stochastic bandits, the linear regret can be
avoided. Second, we show that if the learner has oracle access to a policy that
collects well-conditioned data then a variant of Lasso fitted Q-iteration
enjoys a nearly dimension-free regret of $\tilde{O}( s^{2/3} N^{2/3})$ where
$N$ is the number of episodes and $s$ is the sparsity level. This shows that in
the large-action setting, the difficulty of learning can be attributed to the
difficulty of finding a good exploratory policy.
</p>
<a href="http://arxiv.org/abs/2011.04018" target="_blank">arXiv:2011.04018</a> [<a href="http://arxiv.org/pdf/2011.04018" target="_blank">pdf</a>]

<h2>An HVS-Oriented Saliency Map Prediction Model. (arXiv:2011.04076v5 [cs.CV] UPDATED)</h2>
<h3>Qiang Li</h3>
<p>Visual attention is one of the most significant characteristics for selecting
and understanding the outside redundancy world. The nature complex scenes,
including larger redundancy and human vision, cannot be processing all
information simultaneously because of the information bottleneck. The human
visual system mainly focuses on dominant parts of the scenes to reduce the
input visual redundancy information. It is commonly known as visual attention
prediction or visual saliency map. This paper proposes a new saliency
prediction architecture WECSF which inspired by human low-level visual cortex
function. The model consists of opponent color channels, wavelet transform,
wavelet energy map, and contrast sensitivity function for extracting low-level
image features and maximum approximation to the human visual system. The
proposed model is evaluated several datasets, including MIT1003, MIT300,
TORONTO, SID4VAM and UCF Sports dataset to explain its efficiency. The proposed
model results are quantitatively and qualitatively compared to other
state-of-the-art salience prediction models. Compared with the baseline model,
our model achieved very good performance. Secondly, we also confirmed
Fourier/Spectral inspired saliency prediction models has the best prediction
scores compared to other start-of-the-art non-neural network and even deep
neural network models on the simple image features saliency prediction.
Finally, the model also can be applied to spatial-temporal saliency prediction
and got better performance.
</p>
<a href="http://arxiv.org/abs/2011.04076" target="_blank">arXiv:2011.04076</a> [<a href="http://arxiv.org/pdf/2011.04076" target="_blank">pdf</a>]

<h2>Time Synchronized State Estimation for Incompletely Observed Distribution Systems Using Deep Learning Considering Realistic Measurement Noise. (arXiv:2011.04272v2 [cs.LG] UPDATED)</h2>
<h3>Behrouz Azimian, Reetam Sen Biswas, Anamitra Pal, Lang Tong</h3>
<p>Time-synchronized state estimation is a challenge for distribution systems
because of limited real-time observability. This paper addresses this challenge
by formulating a deep learning (DL)-based approach to perform unbalanced
three-phase distribution system state estimation (DSSE). Initially, a
data-driven approach for judicious measurement selection to facilitate reliable
state estimation is provided. Then, a deep neural network (DNN) is trained to
perform DSSE for systems that are incompletely observed by synchrophasor
measurement devices (SMDs). Robustness of the proposed methodology is
demonstrated by considering realistic measurement error models for SMDs. A
comparative study of the DNN-based DSSE with classical linear state estimation
indicates that the DL-based approach gives better accuracy with a significantly
smaller number of SMDs.
</p>
<a href="http://arxiv.org/abs/2011.04272" target="_blank">arXiv:2011.04272</a> [<a href="http://arxiv.org/pdf/2011.04272" target="_blank">pdf</a>]

<h2>Active Inference and Behavior Trees for Reactive Action Planning and Execution in Robotics. (arXiv:2011.09756v2 [cs.RO] UPDATED)</h2>
<h3>Corrado Pezzato, Carlos Hernandez, Martijn Wisse</h3>
<p>We propose a hybrid combination of active inference and behavior trees (BTs)
for reactive action planning and execution in dynamic environments. We show how
robotic tasks can be formulated as a free-energy minimization problem, bringing
the neuroscientific theory of active inference on a mobile manipulator. In this
framework, the general nominal behavior is specified offline through BTs. A new
type of leaf node, the \textit{prior} node, is introduced to specify the
desired state to be achieved rather than an action to be executed as in
classical BTs. The decision of which action to execute to reach the desired
state is performed online through active inference. The resulting hybrid
combination improves the robustness of plans against unexpected contingencies
while considerably reducing the number of nodes in a BT. The properties of our
algorithm, such as the convergence and robustness, are thoroughly analyzed and
outperform classical BT solutions. The theoretical results are validated using
a mobile manipulator in a retail environment.
</p>
<a href="http://arxiv.org/abs/2011.09756" target="_blank">arXiv:2011.09756</a> [<a href="http://arxiv.org/pdf/2011.09756" target="_blank">pdf</a>]

<h2>Online Orthogonal Matching Pursuit. (arXiv:2011.11117v2 [stat.ML] UPDATED)</h2>
<h3>El Mehdi Saad, Gilles Blanchard, Sylvain Arlot</h3>
<p>Greedy algorithms for feature selection are widely used for recovering sparse
high-dimensional vectors in linear models. In classical procedures, the main
emphasis was put on the sample complexity, with little or no consideration of
the computation resources required. We present a novel online algorithm: Online
Orthogonal Matching Pursuit (OOMP) for online support recovery in the random
design setting of sparse linear regression. Our procedure selects features
sequentially, alternating between allocation of samples only as needed to
candidate features, and optimization over the selected set of variables to
estimate the regression coefficients. Theoretical guarantees about the output
of this algorithm are proven and its computational complexity is analysed.
</p>
<a href="http://arxiv.org/abs/2011.11117" target="_blank">arXiv:2011.11117</a> [<a href="http://arxiv.org/pdf/2011.11117" target="_blank">pdf</a>]

<h2>Structure-Aware Completion of Photogrammetric Meshes in Urban Road Environment. (arXiv:2011.11210v3 [cs.CV] UPDATED)</h2>
<h3>Qing Zhu, Qisen Shang, Han Hu, Haojia Yu, Ruofei Zhong</h3>
<p>Photogrammetric mesh models obtained from aerial oblique images have been
widely used for urban reconstruction. However, the photogrammetric meshes also
suffer from severe texture problems, especially on the road areas due to
occlusion. This paper proposes a structure-aware completion approach to improve
the quality of meshes by removing undesired vehicles on the road seamlessly.
Specifically, the discontinuous texture atlas is first integrated to a
continuous screen space through rendering by the graphics pipeline; the
rendering also records necessary mapping for deintegration to the original
texture atlas after editing. Vehicle regions are masked by a standard object
detection approach, e.g. Faster RCNN. Then, the masked regions are completed
guided by the linear structures and regularities in the road region, which is
implemented based on Patch Match. Finally, the completed rendered image is
deintegrated to the original texture atlas and the triangles for the vehicles
are also flattened for improved meshes. Experimental evaluations and analyses
are conducted against three datasets, which are captured with different sensors
and ground sample distances. The results reveal that the proposed method can
quite realistic meshes after removing the vehicles. The structure-aware
completion approach for road regions outperforms popular image completion
methods and ablation study further confirms the effectiveness of the linear
guidance. It should be noted that the proposed method is also capable to handle
tiled mesh models for large-scale scenes. Dataset and code are available at
vrlab.org.cn/~hanhu/projects/mesh.
</p>
<a href="http://arxiv.org/abs/2011.11210" target="_blank">arXiv:2011.11210</a> [<a href="http://arxiv.org/pdf/2011.11210" target="_blank">pdf</a>]

<h2>Score-Based Generative Modeling through Stochastic Differential Equations. (arXiv:2011.13456v2 [cs.LG] UPDATED)</h2>
<h3>Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole</h3>
<p>Creating noise from data is easy; creating data from noise is generative
modeling. We present a stochastic differential equation (SDE) that smoothly
transforms a complex data distribution to a known prior distribution by slowly
injecting noise, and a corresponding reverse-time SDE that transforms the prior
distribution back into the data distribution by slowly removing the noise.
Crucially, the reverse-time SDE depends only on the time-dependent gradient
field (\aka, score) of the perturbed data distribution. By leveraging advances
in score-based generative modeling, we can accurately estimate these scores
with neural networks, and use numerical SDE solvers to generate samples. We
show that this framework encapsulates previous approaches in score-based
generative modeling and diffusion probabilistic modeling, allowing for new
sampling procedures and new modeling capabilities. In particular, we introduce
a predictor-corrector framework to correct errors in the evolution of the
discretized reverse-time SDE. We also derive an equivalent neural ODE that
samples from the same distribution as the SDE, but additionally enables exact
likelihood computation, and improved sampling efficiency. In addition, we
provide a new way to solve inverse problems with score-based models, as
demonstrated with experiments on class-conditional generation, image
inpainting, and colorization. Combined with multiple architectural
improvements, we achieve record-breaking performance for unconditional image
generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a
competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity
generation of 1024 x 1024 images for the first time from a score-based
generative model.
</p>
<a href="http://arxiv.org/abs/2011.13456" target="_blank">arXiv:2011.13456</a> [<a href="http://arxiv.org/pdf/2011.13456" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning for Wireless Scheduling with Multiclass Services. (arXiv:2011.13634v2 [cs.LG] UPDATED)</h2>
<h3>Apostolos Avranas (EURECOM), Marios Kountouris (EURECOM), Philippe Ciblat (T&#xe9;l&#xe9;com Paris)</h3>
<p>In this paper, we investigate the problem of scheduling and resource
allocation over a time varying set of clients with heterogeneous demands.In
this context, a service provider has to schedule traffic destined to users with
different classes of requirements and to allocate bandwidth resources over time
as a means to efficiently satisfy service demands within a limited time
horizon. This is a highly intricate problem, in particular in wireless
communication systems, and solutions may involve tools stemming from diverse
fields, including combinatorics and constrained optimization. Although recent
work has successfully proposed solutions based on Deep Reinforcement Learning
(DRL), the challenging setting of heterogeneous user traffic and demands has
not been addressed. We propose a deep deterministic policy gradient algorithm
that combines state-of-the-art techniques, namely Distributional RL and Deep
Sets, to train a model for heterogeneous traffic scheduling. We test on diverse
scenarios with different time dependence dynamics, users' requirements, and
resources available, demonstrating consistent results using both synthetic and
real data. We evaluate the algorithm on a wireless communication setting using
both synthetic and real data and show significant gains in terms of Quality of
Service (QoS) defined by the classes, against state-of-the-art conventional
algorithms from combinatorics, optimization and scheduling metric(e.g.
Knapsack, Integer Linear Programming, Frank-Wolfe, Exponential Rule).
</p>
<a href="http://arxiv.org/abs/2011.13634" target="_blank">arXiv:2011.13634</a> [<a href="http://arxiv.org/pdf/2011.13634" target="_blank">pdf</a>]

<h2>Minimax Regret for Stochastic Shortest Path with Adversarial Costs and Known Transition. (arXiv:2012.04053v2 [cs.LG] UPDATED)</h2>
<h3>Liyu Chen, Haipeng Luo, Chen-Yu Wei</h3>
<p>We study the stochastic shortest path problem with adversarial costs and
known transition, and show that the minimax regret is
$\widetilde{O}(\sqrt{DT^\star K})$ and $\widetilde{O}(\sqrt{DT^\star SA K})$
for the full-information setting and the bandit feedback setting respectively,
where $D$ is the diameter, $T^\star$ is the expected hitting time of the
optimal policy, $S$ is the number of states, $A$ is the number of actions, and
$K$ is the number of episodes. Our results significantly improve upon the
existing work of (Rosenberg and Mansour, 2020) which only considers the
full-information setting and achieves suboptimal regret. Our work is also the
first to consider bandit feedback with adversarial costs.

Our algorithms are built on top of the Online Mirror Descent framework with a
variety of new techniques that might be of independent interest, including an
improved multi-scale expert algorithm, a reduction from general stochastic
shortest path to a special loop-free case, a skewed occupancy measure space,
%the usage of log-barrier with an increasing learning rate schedule, and a
novel correction term added to the cost estimators. Interestingly, the last two
elements reduce the variance of the learner via positive bias and the variance
of the optimal policy via negative bias respectively, and having them
simultaneously is critical for obtaining the optimal high-probability bound in
the bandit feedback setting.
</p>
<a href="http://arxiv.org/abs/2012.04053" target="_blank">arXiv:2012.04053</a> [<a href="http://arxiv.org/pdf/2012.04053" target="_blank">pdf</a>]

<h2>Automatic Registration and Clustering of Time Series. (arXiv:2012.04756v2 [stat.ML] UPDATED)</h2>
<h3>Michael Weylandt, George Michailidis</h3>
<p>Clustering of time series data exhibits a number of challenges not present in
other settings, notably the problem of registration (alignment) of observed
signals. Typical approaches include pre-registration to a user-specified
template or time warping approaches which attempt to optimally align series
with a minimum of distortion. For many signals obtained from recording or
sensing devices, these methods may be unsuitable as a template signal is not
available for pre-registration, while the distortion of warping approaches may
obscure meaningful temporal information. We propose a new method for automatic
time series alignment within a clustering problem. Our approach, Temporal
Registration using Optimal Unitary Transformations (TROUT), is based on a novel
dissimilarity measure between time series that is easy to compute and
automatically identifies optimal alignment between pairs of time series. By
embedding our new measure in a optimization formulation, we retain well-known
advantages of computational and statistical performance. We provide an
efficient algorithm for TROUT-based clustering and demonstrate its superior
performance over a range of competitors.
</p>
<a href="http://arxiv.org/abs/2012.04756" target="_blank">arXiv:2012.04756</a> [<a href="http://arxiv.org/pdf/2012.04756" target="_blank">pdf</a>]

<h2>Evaluating Agents without Rewards. (arXiv:2012.11538v2 [cs.LG] UPDATED)</h2>
<h3>Brendon Matusch, Jimmy Ba, Danijar Hafner</h3>
<p>Reinforcement learning has enabled agents to solve challenging tasks in
unknown environments. However, manually crafting reward functions can be time
consuming, expensive, and error prone to human error. Competing objectives have
been proposed for agents to learn without external supervision, but it has been
unclear how well they reflect task rewards or human behavior. To accelerate the
development of intrinsic objectives, we retrospectively compute potential
objectives on pre-collected datasets of agent behavior, rather than optimizing
them online, and compare them by analyzing their correlations. We study input
entropy, information gain, and empowerment across seven agents, three Atari
games, and the 3D game Minecraft. We find that all three intrinsic objectives
correlate more strongly with a human behavior similarity metric than with task
reward. Moreover, input entropy and information gain correlate more strongly
with human similarity than task reward does, suggesting the use of intrinsic
objectives for designing agents that behave similarly to human players.
</p>
<a href="http://arxiv.org/abs/2012.11538" target="_blank">arXiv:2012.11538</a> [<a href="http://arxiv.org/pdf/2012.11538" target="_blank">pdf</a>]

<h2>A Person Re-identification Data Augmentation Method with Adversarial Defense Effect. (arXiv:2101.08783v2 [cs.CV] UPDATED)</h2>
<h3>Yunpeng Gong, Zhiyong Zeng, Liwen Chen, Yifan Luo, Bin Weng, Feng Ye</h3>
<p>The security of the Person Re-identification(ReID) model plays a decisive
role in the application of ReID. However, deep neural networks have been shown
to be vulnerable, and adding undetectable adversarial perturbations to clean
images can trick deep neural networks that perform well in clean images. We
propose a ReID multi-modal data augmentation method with adversarial defense
effect: 1) Grayscale Patch Replacement, it consists of Local Grayscale Patch
Replacement(LGPR) and Global Grayscale Patch Replacement(GGPR). This method can
not only improve the accuracy of the model, but also help the model defend
against adversarial examples; 2) Multi-Modal Defense, it integrates three
homogeneous modal images of visible, grayscale and sketch, and further
strengthens the defense ability of the model. These methods fuse different
modalities of homogeneous images to enrich the input sample variety, the
variaty of samples will reduce the over-fitting of the ReID model to color
variations and make the adversarial space of the dataset that the attack method
can find difficult to align, thus the accuracy of model is improved, and the
attack effect is greatly reduced. The more modal homogeneous images are fused,
the stronger the defense capabilities is . The proposed method performs well on
multiple datasets, and successfully defends the attack of MS-SSIM proposed by
CVPR2020 against ReID [10], and increases the accuracy by 467 times(0.2% to
93.3%).The code is available at
https://github.com/finger-monkey/ReID_Adversarial_Defense.
</p>
<a href="http://arxiv.org/abs/2101.08783" target="_blank">arXiv:2101.08783</a> [<a href="http://arxiv.org/pdf/2101.08783" target="_blank">pdf</a>]

<h2>A reproducibility study of "Augmenting Genetic Algorithms with Deep Neural Networks for Exploring the Chemical Space". (arXiv:2102.00700v3 [cs.LG] UPDATED)</h2>
<h3>Kevin Maik Jablonka, Fergus Mcilwaine, Susana Garcia, Berend Smit, Brian Yoo</h3>
<p>Nigam et al. reported a genetic algorithm (GA) utilizing the SELFIES
representation and also propose an adaptive, neural network-based penalty that
is supposed to improve the diversity of the generated molecules. The main
claims of the paper are that this GA outperforms other generative techniques
(as measured by the penalized logP) and that a neural network-based adaptive
penalty increases the diversity of the generated molecules. In this work, we
investigated the reproducibility of their claims. Overall, we were able to
reproduce comparable results using the SELFIES-based GA, but mostly by
exploiting deficiencies of the (easily optimizable) fitness function (i.e.,
generating long, sulfur containing chains). In addition, we reproduce results
showing that the discriminator can be used to bias the generation of molecules
to ones that are similar to the reference set. Lastly, we attempted to quantify
the evolution of the diversity, understand the influence of some
hyperparameters, and propose improvements to the adaptive penalty.
</p>
<a href="http://arxiv.org/abs/2102.00700" target="_blank">arXiv:2102.00700</a> [<a href="http://arxiv.org/pdf/2102.00700" target="_blank">pdf</a>]

<h2>Undecidability of Underfitting in Learning Algorithms. (arXiv:2102.02850v3 [cs.LG] UPDATED)</h2>
<h3>Sonia Sehra, David Flores, George D. Montanez</h3>
<p>Using recent machine learning results that present an information-theoretic
perspective on underfitting and overfitting, we prove that deciding whether an
encodable learning algorithm will always underfit a dataset, even if given
unlimited training time, is undecidable. We discuss the importance of this
result and potential topics for further research, including
information-theoretic and probabilistic strategies for bounding learning
algorithm fit.
</p>
<a href="http://arxiv.org/abs/2102.02850" target="_blank">arXiv:2102.02850</a> [<a href="http://arxiv.org/pdf/2102.02850" target="_blank">pdf</a>]

<h2>A Variational Information Bottleneck Approach to Multi-Omics Data Integration. (arXiv:2102.03014v2 [cs.LG] UPDATED)</h2>
<h3>Changhee Lee, Mihaela van der Schaar</h3>
<p>Integration of data from multiple omics techniques is becoming increasingly
important in biomedical research. Due to non-uniformity and technical
limitations in omics platforms, such integrative analyses on multiple omics,
which we refer to as views, involve learning from incomplete observations with
various view-missing patterns. This is challenging because i) complex
interactions within and across observed views need to be properly addressed for
optimal predictive power and ii) observations with various view-missing
patterns need to be flexibly integrated. To address such challenges, we propose
a deep variational information bottleneck (IB) approach for incomplete
multi-view observations. Our method applies the IB framework on marginal and
joint representations of the observed views to focus on intra-view and
inter-view interactions that are relevant for the target. Most importantly, by
modeling the joint representations as a product of marginal representations, we
can efficiently learn from observed views with various view-missing patterns.
Experiments on real-world datasets show that our method consistently achieves
gain from data integration and outperforms state-of-the-art benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.03014" target="_blank">arXiv:2102.03014</a> [<a href="http://arxiv.org/pdf/2102.03014" target="_blank">pdf</a>]

<h2>Self-supervised driven consistency training for annotation efficient histopathology image analysis. (arXiv:2102.03897v2 [cs.CV] UPDATED)</h2>
<h3>Chetan L. Srinidhi, Seung Wook Kim, Fu-Der Chen, Anne L. Martel</h3>
<p>Training a neural network with a large labeled dataset is still a dominant
paradigm in computational histopathology. However, obtaining such exhaustive
manual annotations is often expensive, laborious, and prone to inter and
Intra-observer variability. While recent self-supervised and semi-supervised
methods can alleviate this need by learn-ing unsupervised feature
representations, they still struggle to generalize well to downstream tasks
when the number of labeled instances is small. In this work, we overcome this
challenge by leveraging both task-agnostic and task-specific unlabeled data
based on two novel strategies: i) a self-supervised pretext task that harnesses
the underlying multi-resolution contextual cues in histology whole-slide images
to learn a powerful supervisory signal for unsupervised representation
learning; ii) a new teacher-student semi-supervised consistency paradigm that
learns to effectively transfer the pretrained representations to downstream
tasks based on prediction consistency with the task-specific un-labeled data.
We carry out extensive validation experiments on three histopathology benchmark
datasets across two classification and one regression-based tasks, i.e., tumor
metastasis detection, tissue type classification, and tumor cellularity
quantification. Under limited-label data, the proposed method yields tangible
improvements, which is close or even outperforming other state-of-the-art
self-supervised and supervised baselines. Furthermore, we empirically show that
the idea of bootstrapping the self-supervised pretrained features is an
effective way to improve the task-specific semi-supervised learning on standard
benchmarks. Code and pretrained models will be made available at:
https://github.com/srinidhiPY/SSL_CR_Histo
</p>
<a href="http://arxiv.org/abs/2102.03897" target="_blank">arXiv:2102.03897</a> [<a href="http://arxiv.org/pdf/2102.03897" target="_blank">pdf</a>]

<h2>Machine Learning-based Classification of Active Walking Tasks in Older Adults using fNIRS. (arXiv:2102.03987v2 [cs.LG] UPDATED)</h2>
<h3>Dongning Ma, Meltem Izzetoglu, Roee Holtzer, Xun Jiao</h3>
<p>Decline in gait features is common in older adults and an indicator of
disability and mortality. Cortical control of gait, specifically in the
pre-frontal cortex as measured by functional near infrared spectroscopy
(fNIRS), during dual task walking has shown to be moderated by age, gender,
cognitive status, and various age-related disease conditions. In this study, we
develop classification models using machine learning methods to classify active
walking tasks in older adults based on fNIRS signals into either
Single-Task-Walk (STW) or Dual-Task-Walk (DTW) conditions. In this study, we
develop classification models using machine learning methods to classify active
walking tasks in older adults based on fNIRS signals into either single-task
walking (STW) or dual-task walking (DTW). The fNIRS measurements included
oxyhemoglobin (HbO2) and deoxyhemoglobin (Hb) signals obtained from prefrontal
cortex (PFC) of the subject performing on the ground active walking tasks with
or without a secondary cognitive task. We extract the fNIRS-related features by
calculating the minimum, maximum, mean, skewness and kurtosis values of Hb and
Hbo2 signals. We then use feature encoding to map the values into binary space.
Using these features, we apply and evaluate various machine learning methods
including logistic regression (LR), decision tree (DT), support vector machine
(SVM), k-nearest neighbors (kNN), multilayer perceptron (MLP), and Random
Forest (RF). Results showed that the machine learning models can achieve around
97\% classification accuracy.
</p>
<a href="http://arxiv.org/abs/2102.03987" target="_blank">arXiv:2102.03987</a> [<a href="http://arxiv.org/pdf/2102.03987" target="_blank">pdf</a>]

<h2>Continuous-Time Model-Based Reinforcement Learning. (arXiv:2102.04764v2 [cs.LG] UPDATED)</h2>
<h3>&#xc7;a&#x11f;atay Y&#x131;ld&#x131;z, Markus Heinonen, Harri L&#xe4;hdesm&#xe4;ki</h3>
<p>Model-based reinforcement learning (MBRL) approaches rely on discrete-time
state transition models whereas physical systems and the vast majority of
control tasks operate in continuous-time. To avoid time-discretization
approximation of the underlying process, we propose a continuous-time MBRL
framework based on a novel actor-critic method. Our approach also infers the
unknown state evolution differentials with Bayesian neural ordinary
differential equations (ODE) to account for epistemic uncertainty. We implement
and test our method on a new ODE-RL suite that explicitly solves
continuous-time control systems. Our experiments illustrate that the model is
robust against irregular and noisy data, is sample-efficient, and can solve
control problems which pose challenges to discrete-time MBRL methods.
</p>
<a href="http://arxiv.org/abs/2102.04764" target="_blank">arXiv:2102.04764</a> [<a href="http://arxiv.org/pdf/2102.04764" target="_blank">pdf</a>]

<h2>On Theory-training Neural Networks to Infer the Solution of Highly Coupled Differential Equations. (arXiv:2102.04890v2 [cs.LG] UPDATED)</h2>
<h3>M. Torabi Rad, A. Viardin, M. Apel</h3>
<p>Deep neural networks are transforming fields ranging from computer vision to
computational medicine, and we recently extended their application to the field
of phase-change heat transfer by introducing theory-trained neural networks
(TTNs) for a solidification problem \cite{TTN}. Here, we present general,
in-depth, and empirical insights into theory-training networks for learning the
solution of highly coupled differential equations. We analyze the deteriorating
effects of the oscillating loss on the ability of a network to satisfy the
equations at the training data points, measured by the final training loss, and
on the accuracy of the inferred solution. We introduce a theory-training
technique that, by leveraging regularization, eliminates those oscillations,
decreases the final training loss, and improves the accuracy of the inferred
solution, with no additional computational cost. Then, we present guidelines
that allow a systematic search for the network that has the optimal training
time and inference accuracy for a given set of equations; following these
guidelines can reduce the number of tedious training iterations in that search.
Finally, a comparison between theory-training and the rival, conventional
method of solving differential equations using discretization attests to the
advantages of theory-training not being necessarily limited to high-dimensional
sets of equations. The comparison also reveals a limitation of the current
theory-training framework that may limit its application in domains where
extreme accuracies are necessary.
</p>
<a href="http://arxiv.org/abs/2102.04890" target="_blank">arXiv:2102.04890</a> [<a href="http://arxiv.org/pdf/2102.04890" target="_blank">pdf</a>]

<h2>Dynamic Neural Networks: A Survey. (arXiv:2102.04906v2 [cs.CV] UPDATED)</h2>
<h3>Yizeng Han, Gao Huang, Shiji Song, Le Yang, Honghui Wang, Yulin Wang</h3>
<p>Dynamic neural network is an emerging research topic in deep learning.
Compared to static models which have fixed computational graphs and parameters
at the inference stage, dynamic networks can adapt their structures or
parameters to different inputs, leading to notable advantages in terms of
accuracy, computational efficiency, adaptiveness, etc. In this survey, we
comprehensively review this rapidly developing area by dividing dynamic
networks into three main categories: 1) instance-wise dynamic models that
process each instance with data-dependent architectures or parameters; 2)
spatial-wise dynamic networks that conduct adaptive computation with respect to
different spatial locations of image data and 3) temporal-wise dynamic models
that perform adaptive inference along the temporal dimension for sequential
data such as videos and texts. The important research problems of dynamic
networks, e.g., architecture design, decision making scheme, optimization
technique and applications, are reviewed systematically. Finally, we discuss
the open problems in this field together with interesting future research
directions.
</p>
<a href="http://arxiv.org/abs/2102.04906" target="_blank">arXiv:2102.04906</a> [<a href="http://arxiv.org/pdf/2102.04906" target="_blank">pdf</a>]

<h2>PyTorchRL: Modular and Distributed Reinforcement Learning in PyTorch. (arXiv:2007.02622v2 [cs.CV] CROSS LISTED)</h2>
<h3>Albert Bou, Gianni De Fabritiis</h3>
<p>Deep reinforcement learning (RL) has proved successful at solving challenging
environments but often requires scaling to large sampling and computing
resources. Furthermore, advancing RL requires tools that are flexible enough to
easily prototype new methods, yet avoiding impractically slow experimental
turnaround times. To this end, we present PyTorchRL, a PyTorch-based library
for RL with a modular design that allows composing agents from a set of
reusable and easily extendable modules. Additionally, PyTorchRL permits the
definition of distributed training architectures with flexibility and
independence of the Agent components. In combination, these two features can
accelerate the pace at which ideas are implemented and tested, simplifying
research and enabling to tackle more challenging RL problems. We present
several interesting use-cases of PyTorchRL and showcase the library by
obtaining the highest to-date test performance on the Obstacle Tower Unity3D
challenge environment.
</p>
<a href="http://arxiv.org/abs/2007.02622" target="_blank">arXiv:2007.02622</a> [<a href="http://arxiv.org/pdf/2007.02622" target="_blank">pdf</a>]

<h2>VS-Quant: Per-vector Scaled Quantization for Accurate Low-Precision Neural Network Inference. (arXiv:2102.04503v1 [cs.LG] CROSS LISTED)</h2>
<h3>Steve Dai, Rangharajan Venkatesan, Haoxing Ren, Brian Zimmer, William J. Dally, Brucek Khailany</h3>
<p>Quantization enables efficient acceleration of deep neural networks by
reducing model memory footprint and exploiting low-cost integer math hardware
units. Quantization maps floating-point weights and activations in a trained
model to low-bitwidth integer values using scale factors. Excessive
quantization, reducing precision too aggressively, results in accuracy
degradation. When scale factors are shared at a coarse granularity across many
dimensions of each tensor, effective precision of individual elements within
the tensor are limited. To reduce quantization-related accuracy loss, we
propose using a separate scale factor for each small vector of ($\approx$16-64)
elements within a single dimension of a tensor. To achieve an efficient
hardware implementation, the per-vector scale factors can be implemented with
low-bitwidth integers when calibrated using a two-level quantization scheme. We
find that per-vector scaling consistently achieves better inference accuracy at
low precision compared to conventional scaling techniques for popular neural
networks without requiring retraining. We also modify a deep learning
accelerator hardware design to study the area and energy overheads of
per-vector scaling support. Our evaluation demonstrates that per-vector scaled
quantization with 4-bit weights and activations achieves 37% area saving and
24% energy saving while maintaining over 75% accuracy for ResNet50 on ImageNet.
4-bit weights and 8-bit activations achieve near-full-precision accuracy for
both BERT-base and BERT-large on SQuAD while reducing area by 26% compared to
an 8-bit baseline.
</p>
<a href="http://arxiv.org/abs/2102.04503" target="_blank">arXiv:2102.04503</a> [<a href="http://arxiv.org/pdf/2102.04503" target="_blank">pdf</a>]

<h2>A Ranking Approach to Fair Classification. (arXiv:2102.04565v1 [cs.LG] CROSS LISTED)</h2>
<h3>Jakob Schoeffer, Niklas Kuehl, Isabel Valera</h3>
<p>Algorithmic decision systems are increasingly used in areas such as hiring,
school admission, or loan approval. Typically, these systems rely on labeled
data for training a classification model. However, in many scenarios,
ground-truth labels are unavailable, and instead we have only access to
imperfect labels as the result of (potentially biased) human-made decisions.
Despite being imperfect, historical decisions often contain some useful
information on the unobserved true labels. In this paper, we focus on scenarios
where only imperfect labels are available and propose a new fair ranking-based
decision system, as an alternative to traditional classification algorithms.
Our approach is both intuitive and easy to implement, and thus particularly
suitable for adoption in real-world settings. More in detail, we introduce a
distance-based decision criterion, which incorporates useful information from
historical decisions and accounts for unwanted correlation between protected
and legitimate features. Through extensive experiments on synthetic and
real-world data, we show that our method is fair, as it a) assigns the
desirable outcome to the most qualified individuals, and b) removes the effect
of stereotypes in decision-making, thereby outperforming traditional
classification algorithms. Additionally, we are able to show theoretically that
our method is consistent with a prominent concept of individual fairness which
states that "similar individuals should be treated similarly."
</p>
<a href="http://arxiv.org/abs/2102.04565" target="_blank">arXiv:2102.04565</a> [<a href="http://arxiv.org/pdf/2102.04565" target="_blank">pdf</a>]

