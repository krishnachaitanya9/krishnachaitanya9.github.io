---
title: Latest Deep Learning Papers
date: 2021-01-25 21:00:02 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (236 Articles)</h1>
<h2>A Novel Genetic Algorithm with Hierarchical Evaluation Strategy for Hyperparameter Optimisation of Graph Neural Networks. (arXiv:2101.09300v1 [cs.LG])</h2>
<h3>Yingfang Yuan, Wenjun Wang, George M. Coghill, Wei Pang</h3>
<p>Graph representation of structured data can facilitate the extraction of
stereoscopic features, and it has demonstrated excellent ability when working
with deep learning systems, the so-called Graph Neural Networks (GNNs).
Choosing a promising architecture for constructing GNNs can be transferred to a
hyperparameter optimisation problem, a very challenging task due to the size of
the underlying search space and high computational cost for evaluating
candidate GNNs. To address this issue, this research presents a novel genetic
algorithm with a hierarchical evaluation strategy (HESGA), which combines the
full evaluation of GNNs with a fast evaluation approach. By using full
evaluation, a GNN is represented by a set of hyperparameter values and trained
on a specified dataset, and root mean square error (RMSE) will be used to
measure the quality of the GNN represented by the set of hyperparameter values
(for regression problems). While in the proposed fast evaluation process, the
training will be interrupted at an early stage, the difference of RMSE values
between the starting and interrupted epochs will be used as a fast score, which
implies the potential of the GNN being considered. To coordinate both types of
evaluations, the proposed hierarchical strategy uses the fast evaluation in a
lower level for recommending candidates to a higher level, where the full
evaluation will act as a final assessor to maintain a group of elite
individuals. To validate the effectiveness of HESGA, we apply it to optimise
two types of deep graph neural networks. The experimental results on three
benchmark datasets demonstrate its advantages compared to Bayesian
hyperparameter optimization.
</p>
<a href="http://arxiv.org/abs/2101.09300" target="_blank">arXiv:2101.09300</a> [<a href="http://arxiv.org/pdf/2101.09300" target="_blank">pdf</a>]

<h2>i-Algebra: Towards Interactive Interpretability of Deep Neural Networks. (arXiv:2101.09301v1 [cs.LG])</h2>
<h3>Xinyang Zhang, Ren Pang, Shouling Ji, Fenglong Ma, Ting Wang</h3>
<p>Providing explanations for deep neural networks (DNNs) is essential for their
use in domains wherein the interpretability of decisions is a critical
prerequisite. Despite the plethora of work on interpreting DNNs, most existing
solutions offer interpretability in an ad hoc, one-shot, and static manner,
without accounting for the perception, understanding, or response of end-users,
resulting in their poor usability in practice. In this paper, we argue that DNN
interpretability should be implemented as the interactions between users and
models. We present i-Algebra, a first-of-its-kind interactive framework for
interpreting DNNs. At its core is a library of atomic, composable operators,
which explain model behaviors at varying input granularity, during different
inference stages, and from distinct interpretation perspectives. Leveraging a
declarative query language, users are enabled to build various analysis tools
(e.g., "drill-down", "comparative", "what-if" analysis) via flexibly composing
such operators. We prototype i-Algebra and conduct user studies in a set of
representative analysis tasks, including inspecting adversarial inputs,
resolving model inconsistency, and cleansing contaminated data, all
demonstrating its promising usability.
</p>
<a href="http://arxiv.org/abs/2101.09301" target="_blank">arXiv:2101.09301</a> [<a href="http://arxiv.org/pdf/2101.09301" target="_blank">pdf</a>]

<h2>Partition-Based Convex Relaxations for Certifying the Robustness of ReLU Neural Networks. (arXiv:2101.09306v1 [cs.LG])</h2>
<h3>Brendon G. Anderson, Ziye Ma, Jingqi Li, Somayeh Sojoudi</h3>
<p>In this paper, we study certifying the robustness of ReLU neural networks
against adversarial input perturbations. To diminish the relaxation error
suffered by the popular linear programming (LP) and semidefinite programming
(SDP) certification methods, we propose partitioning the input uncertainty set
and solving the relaxations on each part separately. We show that this approach
reduces relaxation error, and that the error is eliminated entirely upon
performing an LP relaxation with an intelligently designed partition. To scale
this approach to large networks, we consider courser partitions that take the
same form as this motivating partition. We prove that computing such a
partition that directly minimizes the LP relaxation error is NP-hard. By
instead minimizing the worst-case LP relaxation error, we develop a
computationally tractable scheme with a closed-form optimal two-part partition.
We extend the analysis to the SDP, where the feasible set geometry is exploited
to design a two-part partition that minimizes the worst-case SDP relaxation
error. Experiments on IRIS classifiers demonstrate significant reduction in
relaxation error, offering certificates that are otherwise void without
partitioning. By independently increasing the input size and the number of
layers, we empirically illustrate under which regimes the partitioned LP and
SDP are best applied.
</p>
<a href="http://arxiv.org/abs/2101.09306" target="_blank">arXiv:2101.09306</a> [<a href="http://arxiv.org/pdf/2101.09306" target="_blank">pdf</a>]

<h2>Tighter expected generalization error bounds via Wasserstein distance. (arXiv:2101.09315v1 [stat.ML])</h2>
<h3>Borja Rodr&#xed;guez-G&#xe1;lvez, Germ&#xe1;n Bassi, Ragnar Thobaben, Mikael Skoglund</h3>
<p>In this work, we introduce several expected generalization error bounds based
on the Wasserstein distance. More precisely, we present full-dataset,
single-letter, and random-subset bounds on both the standard setting and the
randomized-subsample setting from Steinke and Zakynthinou [2020]. Moreover, we
show that, when the loss function is bounded, these bounds recover from below
(and thus are tighter than) current bounds based on the relative entropy and,
for the standard setting, generate new, non-vacuous bounds also based on the
relative entropy. Then, we show how similar bounds featuring the backward
channel can be derived with the proposed proof techniques. Finally, we show how
various new bounds based on different information measures (e.g., the lautum
information or several $f$-divergences) can be derived from the presented
bounds.
</p>
<a href="http://arxiv.org/abs/2101.09315" target="_blank">arXiv:2101.09315</a> [<a href="http://arxiv.org/pdf/2101.09315" target="_blank">pdf</a>]

<h2>Machine Learning in LiDAR 3D point clouds. (arXiv:2101.09318v1 [cs.CV])</h2>
<h3>F. Patricia Medina, Randy Paffenroth</h3>
<p>LiDAR point clouds contain measurements of complicated natural scenes and can
be used to update digital elevation models, glacial monitoring, detecting
faults and measuring uplift detecting, forest inventory, detect shoreline and
beach volume changes, landslide risk analysis, habitat mapping, and urban
development, among others. A very important application is the classification
of the 3D cloud into elementary classes. For example, it can be used to
differentiate between vegetation, man-made structures, and water. Our goal is
to present a preliminary comparison study for the classification of 3D point
cloud LiDAR data that includes several types of feature engineering. In
particular, we demonstrate that providing context by augmenting each point in
the LiDAR point cloud with information about its neighboring points can improve
the performance of downstream learning algorithms. We also experiment with
several dimension reduction strategies, ranging from Principal Component
Analysis (PCA) to neural network-based auto-encoders, and demonstrate how they
affect classification performance in LiDAR point clouds. For instance, we
observe that combining feature engineering with a dimension reduction a method
such as PCA, there is an improvement in the accuracy of the classification with
respect to doing a straightforward classification with the raw data.
</p>
<a href="http://arxiv.org/abs/2101.09318" target="_blank">arXiv:2101.09318</a> [<a href="http://arxiv.org/pdf/2101.09318" target="_blank">pdf</a>]

<h2>A systematic literature review on state-of-the-art deep learning methods for process prediction. (arXiv:2101.09320v1 [cs.LG])</h2>
<h3>Dominic A. Neu, Johannes Lahann, Peter Fettke</h3>
<p>Process mining enables the reconstruction and evaluation of business
processes based on digital traces in IT systems. An increasingly important
technique in this context is process prediction. Given a sequence of events of
an ongoing trace, process prediction allows forecasting upcoming events or
performance measurements. In recent years, multiple process prediction
approaches have been proposed, applying different data processing schemes and
prediction algorithms. This study focuses on deep learning algorithms since
they seem to outperform their machine learning alternatives consistently.
Whilst having a common learning algorithm, they use different data
preprocessing techniques, implement a variety of network topologies and focus
on various goals such as outcome prediction, time prediction or control-flow
prediction. Additionally, the set of log-data, evaluation metrics and baselines
used by the authors diverge, making the results hard to compare. This paper
attempts to synthesise the advantages and disadvantages of the procedural
decisions in these approaches by conducting a systematic literature review.
</p>
<a href="http://arxiv.org/abs/2101.09320" target="_blank">arXiv:2101.09320</a> [<a href="http://arxiv.org/pdf/2101.09320" target="_blank">pdf</a>]

<h2>Vessel-CAPTCHA: an efficient learning framework for vessel annotation and segmentation. (arXiv:2101.09321v1 [cs.CV])</h2>
<h3>Vien Ngoc Dang, Giuseppe Di Giacomo, Viola Marconeto, Pratek Mathur, Rosa Cortese, Marco Lorenzi, Ferran Prados, Maria A. Zuluaga</h3>
<p>The use of deep learning techniques for 3D brain vessel image segmentation
has not been as widespread as for the segmentation of other organs and tissues.
This can be explained by two factors. First, deep learning techniques tend to
show poor performances at the segmentation of relatively small objects compared
to the size of the full image. Second, due to the complexity of vascular trees
and the small size of vessels, it is challenging to obtain the amount of
annotated training data typically needed by deep learning methods. To address
these problems, we propose a novel annotation-efficient deep learning vessel
segmentation framework. The framework avoids pixel-wise annotations, only
requiring patch-level labels to discriminate between vessel and non-vessel 2D
patches in the training set, in a setup similar to the CAPTCHAs used to
differentiate humans from bots in web applications. The user-provided
annotations are used for two tasks: 1) to automatically generate pixel-wise
labels for vessels and background in each patch, which are used to train a
segmentation network, and 2) to train a classifier network. The classifier
network allows to generate additional weak patch labels, further reducing the
annotation burden, and it acts as a noise filter for poor quality images. We
use this framework for the segmentation of the cerebrovascular tree in
Time-of-Flight angiography (TOF) and Susceptibility-Weighted Images (SWI). The
results show that the framework achieves state-of-the-art accuracy, while
reducing the annotation time by up to 80% with respect to learning-based
segmentation methods using pixel-wise labels for training
</p>
<a href="http://arxiv.org/abs/2101.09321" target="_blank">arXiv:2101.09321</a> [<a href="http://arxiv.org/pdf/2101.09321" target="_blank">pdf</a>]

<h2>Generating Black-Box Adversarial Examples in Sparse Domain. (arXiv:2101.09324v1 [cs.LG])</h2>
<h3>Hadi Zanddizari, J. Morris Chang</h3>
<p>Applications of machine learning (ML) models and convolutional neural
networks (CNNs) have been rapidly increased. Although ML models provide high
accuracy in many applications, recent investigations show that such networks
are highly vulnerable to adversarial attacks. The black-box adversarial attack
is one type of attack that the attacker does not have any knowledge about the
model or the training dataset. In this paper, we propose a novel approach to
generate a black-box attack in sparse domain whereas the most important
information of an image can be observed. Our investigation shows that large
sparse components play a critical role in the performance of the image
classifiers. Under this presumption, to generate adversarial example, we
transfer an image into a sparse domain and put a threshold to choose only k
largest components. In contrast to the very recent works that randomly perturb
k low frequency (LoF) components, we perturb k largest sparse (LaS)components
either randomly (query-based) or in the direction of the most correlated sparse
signal from a different class. We show that LaS components contain some middle
or higher frequency components information which can help us fool the
classifiers with a fewer number of queries. We also demonstrate the
effectiveness of this approach by fooling the TensorFlow Lite (TFLite) model of
Google Cloud Vision platform. Mean squared error (MSE) and peak signal to noise
ratio (PSNR) are used as quality metrics. We present a theoretical proof to
connect these metrics to the level of perturbation in the sparse domain. We
tested our adversarial examples to the state-of-the-art CNNs and support vector
machine (SVM) classifiers on color and grayscale image datasets. The results
show the proposed method can highly increase the misclassification rate of the
classifiers.
</p>
<a href="http://arxiv.org/abs/2101.09324" target="_blank">arXiv:2101.09324</a> [<a href="http://arxiv.org/pdf/2101.09324" target="_blank">pdf</a>]

<h2>Theory of Mind for Deep Reinforcement Learning in Hanabi. (arXiv:2101.09328v1 [cs.AI])</h2>
<h3>Andrew Fuchs, Michael Walton, Theresa Chadwick, Doug Lange</h3>
<p>The partially observable card game Hanabi has recently been proposed as a new
AI challenge problem due to its dependence on implicit communication
conventions and apparent necessity of theory of mind reasoning for efficient
play. In this work, we propose a mechanism for imbuing Reinforcement Learning
agents with a theory of mind to discover efficient cooperative strategies in
Hanabi. The primary contributions of this work are threefold: First, a formal
definition of a computationally tractable mechanism for computing hand
probabilities in Hanabi. Second, an extension to conventional Deep
Reinforcement Learning that introduces reasoning over finitely nested theory of
mind belief hierarchies. Finally, an intrinsic reward mechanism enabled by
theory of mind that incentivizes agents to share strategically relevant private
knowledge with their teammates. We demonstrate the utility of our algorithm
against Rainbow, a state-of-the-art Reinforcement Learning agent.
</p>
<a href="http://arxiv.org/abs/2101.09328" target="_blank">arXiv:2101.09328</a> [<a href="http://arxiv.org/pdf/2101.09328" target="_blank">pdf</a>]

<h2>Robotic Knee Tracking Control to Mimic the Intact Human Knee Profile Based on Actor-critic Reinforcement Learning. (arXiv:2101.09334v1 [cs.RO])</h2>
<h3>Ruofan Wu, Zhikai Yao, Jennie Si, He (Helen) Huang</h3>
<p>We address a state-of-the-art reinforcement learning (RL) control approach to
automatically configure robotic prosthesis impedance parameters to enable
end-to-end, continuous locomotion intended for transfemoral amputee subjects.
Specifically, our actor-critic based RL provides tracking control of a robotic
knee prosthesis to mimic the intact knee profile. This is a significant advance
from our previous RL based automatic tuning of prosthesis control parameters
which have centered on regulation control with a designer prescribed robotic
knee profile as the target. In addition to presenting the complete tracking
control algorithm based on direct heuristic dynamic programming (dHDP), we
provide an analytical framework for the tracking controller with constrained
inputs. We show that our proposed tracking control possesses several important
properties, such as weight convergence of the learning networks, Bellman
(sub)optimality of the cost-to-go value function and control input, and
practical stability of the human-robot system under input constraint. We
further provide a systematic simulation of the proposed tracking control using
a realistic human-robot system simulator, the OpenSim, to emulate how the dHDP
enables level ground walking, walking on different terrains and at different
paces. These results show that our proposed dHDP based tracking control is not
only theoretically suitable, but also practically useful.
</p>
<a href="http://arxiv.org/abs/2101.09334" target="_blank">arXiv:2101.09334</a> [<a href="http://arxiv.org/pdf/2101.09334" target="_blank">pdf</a>]

<h2>A Comprehensive Survey on Hardware-Aware Neural Architecture Search. (arXiv:2101.09336v1 [cs.LG])</h2>
<h3>Hadjer Benmeziane, Kaoutar El Maghraoui, Hamza Ouarnoughi, Smail Niar, Martin Wistuba, Naigang Wang</h3>
<p>Neural Architecture Search (NAS) methods have been growing in popularity.
These techniques have been fundamental to automate and speed up the time
consuming and error-prone process of synthesizing novel Deep Learning (DL)
architectures. NAS has been extensively studied in the past few years. Arguably
their most significant impact has been in image classification and object
detection tasks where the state of the art results have been obtained. Despite
the significant success achieved to date, applying NAS to real-world problems
still poses significant challenges and is not widely practical. In general, the
synthesized Convolution Neural Network (CNN) architectures are too complex to
be deployed in resource-limited platforms, such as IoT, mobile, and embedded
systems. One solution growing in popularity is to use multi-objective
optimization algorithms in the NAS search strategy by taking into account
execution latency, energy consumption, memory footprint, etc. This kind of NAS,
called hardware-aware NAS (HW-NAS), makes searching the most efficient
architecture more complicated and opens several questions.

In this survey, we provide a detailed review of existing HW-NAS research and
categorize them according to four key dimensions: the search space, the search
strategy, the acceleration technique, and the hardware cost estimation
strategies. We further discuss the challenges and limitations of existing
approaches and potential future directions. This is the first survey paper
focusing on hardware-aware NAS. We hope it serves as a valuable reference for
the various techniques and algorithms discussed and paves the road for future
research towards hardware-aware NAS.
</p>
<a href="http://arxiv.org/abs/2101.09336" target="_blank">arXiv:2101.09336</a> [<a href="http://arxiv.org/pdf/2101.09336" target="_blank">pdf</a>]

<h2>Machine Learning Based Early Fire Detection System using a Low-Cost Drone. (arXiv:2101.09362v1 [cs.RO])</h2>
<h3>Ay&#x15f;eg&#xfc;l Yan&#x131;k, Mehmet Serdar G&#xfc;zel, Mertkan Yan&#x131;k, Erkan Bostanc&#x131;</h3>
<p>This paper proposes a new machine learning based system for forest fire
earlier detection in a low-cost and accurate manner. Accordingly, it is aimed
to bring a new and definite perspective to visual detection in forest fires. A
drone is constructed for this purpose. The microcontroller in the system has
been programmed by training with deep learning methods, and the unmanned aerial
vehicle has been given the ability to recognize the smoke, the earliest sign of
fire detection. The common problem in the prevalent algorithms used in fire
detection is the high false alarm and overlook rates. Confirming the result
obtained from the visualization with an additional supervision stage will
increase the reliability of the system as well as guarantee the accuracy of the
result. Due to the mobile vision ability of the unmanned aerial vehicle, the
data can be controlled from any point of view clearly and continuously. System
performance are validated by conducting experiments in both simulation and
physical environments.
</p>
<a href="http://arxiv.org/abs/2101.09362" target="_blank">arXiv:2101.09362</a> [<a href="http://arxiv.org/pdf/2101.09362" target="_blank">pdf</a>]

<h2>Gaussian Process-Based Model Predictive Control for Overtaking. (arXiv:2101.09375v1 [cs.RO])</h2>
<h3>Wenjun Liu, Chang Liu, Guang Chen, Peng Hang, Alois Knoll</h3>
<p>This paper proposes a novel framework for addressing the challenge of
autonomous overtaking and obstacle avoidance, which incorporates the overtaking
path planning into Gaussian Process-based model predictive control (GPMPC).
Compared with the conventional control strategies, this approach has two main
advantages. Firstly, combining Gaussian Process (GP) regression with a nominal
model allows for learning from model mismatch and unmodeled dynamics, which
enhances a simple model and delivers significantly better results. Due to the
approximation for propagating uncertainties, we can furthermore satisfy the
constraints and thereby safety of the vehicle is ensured. Secondly, we convert
the geometric relationship between the ego vehicle and other obstacle vehicles
into the constraints. Without relying on a higherlevel path planner, this
approach substantially reduces the computational burden. In addition, we
transform the state constraints under the model predictive control (MPC)
framework into a soft constraint and incorporate it as relaxed barrier function
into the cost function, which makes the optimizer more efficient. Simulation
results reveal the usefulness of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2101.09375" target="_blank">arXiv:2101.09375</a> [<a href="http://arxiv.org/pdf/2101.09375" target="_blank">pdf</a>]

<h2>The Role of Edges in Line Drawing Perception. (arXiv:2101.09376v1 [cs.CV])</h2>
<h3>Aaron Hertzmann</h3>
<p>It has often been conjectured that the effectiveness of line drawings can be
explained by the similarity of edge images to line drawings. This paper
presents several problems with explaining line drawing perception in terms of
edges, and how the recently-proposed Realism Hypothesis of Hertzmann (2020)
resolves these problems. There is nonetheless existing evidence that edges are
often the best features for predicting where people draw lines; this paper
describes how the Realism Hypothesis can explain this evidence.
</p>
<a href="http://arxiv.org/abs/2101.09376" target="_blank">arXiv:2101.09376</a> [<a href="http://arxiv.org/pdf/2101.09376" target="_blank">pdf</a>]

<h2>Online Adversarial Purification based on Self-Supervision. (arXiv:2101.09387v1 [cs.LG])</h2>
<h3>Changhao Shi, Chester Holtz, Gal Mishne</h3>
<p>Deep neural networks are known to be vulnerable to adversarial examples,
where a perturbation in the input space leads to an amplified shift in the
latent network representation. In this paper, we combine canonical supervised
learning with self-supervised representation learning, and present
Self-supervised Online Adversarial Purification (SOAP), a novel defense
strategy that uses a self-supervised loss to purify adversarial examples at
test-time. Our approach leverages the label-independent nature of
self-supervised signals and counters the adversarial perturbation with respect
to the self-supervised tasks. SOAP yields competitive robust accuracy against
state-of-the-art adversarial training and purification methods, with
considerably less training complexity. In addition, our approach is robust even
when adversaries are given knowledge of the purification defense strategy. To
the best of our knowledge, our paper is the first that generalizes the idea of
using self-supervised signals to perform online test-time purification.
</p>
<a href="http://arxiv.org/abs/2101.09387" target="_blank">arXiv:2101.09387</a> [<a href="http://arxiv.org/pdf/2101.09387" target="_blank">pdf</a>]

<h2>Learning Setup Policies: Reliable Transition Between Locomotion Behaviours. (arXiv:2101.09391v1 [cs.RO])</h2>
<h3>Brendan Tidd, Nicolas Hudson, Akansel Cosgun, Jurgen Leitner</h3>
<p>Dynamic platforms that operate over manyunique terrain conditions typically
require multiple controllers.To transition safely between controllers, there
must be anoverlap of states between adjacent controllers. We developa novel
method for training Setup Policies that bridge thetrajectories between
pre-trained Deep Reinforcement Learning(DRL) policies. We demonstrate our
method with a simulatedbiped traversing a difficult jump terrain, where a
single policyfails to learn the task, and switching between pre-trainedpolicies
without Setup Policies also fails. We perform anablation of key components of
our system, and show thatour method outperforms others that learn transition
policies.We demonstrate our method with several difficult and diverseterrain
types, and show that we can use Setup Policies as partof a modular control
suite to successfully traverse a sequence ofcomplex terrains. We show that
using Setup Policies improvesthe success rate for traversing a single difficult
jump terrain(from 1.5%success rate without Setup Policies to 82%), and
asequence of various terrains (from 6.5%without Setup Policiesto 29.1%).
</p>
<a href="http://arxiv.org/abs/2101.09391" target="_blank">arXiv:2101.09391</a> [<a href="http://arxiv.org/pdf/2101.09391" target="_blank">pdf</a>]

<h2>Fixed Viewpoint Mirror Surface Reconstruction under an Uncalibrated Camera. (arXiv:2101.09392v1 [cs.CV])</h2>
<h3>Kai Han, Miaomiao Liu, Dirk Schnieders, Kwan-Yee K. Wong</h3>
<p>This paper addresses the problem of mirror surface reconstruction, and
proposes a solution based on observing the reflections of a moving reference
plane on the mirror surface. Unlike previous approaches which require tedious
calibration, our method can recover the camera intrinsics, the poses of the
reference plane, as well as the mirror surface from the observed reflections of
the reference plane under at least three unknown distinct poses. We first show
that the 3D poses of the reference plane can be estimated from the reflection
correspondences established between the images and the reference plane. We then
form a bunch of 3D lines from the reflection correspondences, and derive an
analytical solution to recover the line projection matrix. We transform the
line projection matrix to its equivalent camera projection matrix, and propose
a cross-ratio based formulation to optimize the camera projection matrix by
minimizing reprojection errors. The mirror surface is then reconstructed based
on the optimized cross-ratio constraint. Experimental results on both synthetic
and real data are presented, which demonstrate the feasibility and accuracy of
our method.
</p>
<a href="http://arxiv.org/abs/2101.09392" target="_blank">arXiv:2101.09392</a> [<a href="http://arxiv.org/pdf/2101.09392" target="_blank">pdf</a>]

<h2>Next-best-view Regression using a 3D Convolutional Neural Network. (arXiv:2101.09397v1 [cs.CV])</h2>
<h3>J. Irving Vasquez-Gomez, David Troncoso, Israel Becerra, Enrique Sucar, Rafael Murrieta-Cid</h3>
<p>Automated three-dimensional (3D) object reconstruction is the task of
building a geometric representation of a physical object by means of sensing
its surface. Even though new single view reconstruction techniques can predict
the surface, they lead to incomplete models, specially, for non commons objects
such as antique objects or art sculptures. Therefore, to achieve the task's
goals, it is essential to automatically determine the locations where the
sensor will be placed so that the surface will be completely observed. This
problem is known as the next-best-view problem. In this paper, we propose a
data-driven approach to address the problem. The proposed approach trains a 3D
convolutional neural network (3D CNN) with previous reconstructions in order to
regress the \btxt{position of the} next-best-view. To the best of our
knowledge, this is one of the first works that directly infers the
next-best-view in a continuous space using a data-driven approach for the 3D
object reconstruction task. We have validated the proposed approach making use
of two groups of experiments. In the first group, several variants of the
proposed architecture are analyzed. Predicted next-best-views were observed to
be closely positioned to the ground truth. In the second group of experiments,
the proposed approach is requested to reconstruct several unseen objects,
namely, objects not considered by the 3D CNN during training nor validation.
Coverage percentages of up to 90 \% were observed. With respect to current
state-of-the-art methods, the proposed approach improves the performance of
previous next-best-view classification approaches and it is quite fast in
running time (3 frames per second), given that it does not compute the
expensive ray tracing required by previous information metrics.
</p>
<a href="http://arxiv.org/abs/2101.09397" target="_blank">arXiv:2101.09397</a> [<a href="http://arxiv.org/pdf/2101.09397" target="_blank">pdf</a>]

<h2>4D Atlas: Statistical Analysis of the Spatiotemporal Variability in Longitudinal 3D Shape Data. (arXiv:2101.09403v1 [cs.CV])</h2>
<h3>Hamid Laga, Marcel Padilla, Ian H. Jermyn, Sebastian Kurtek, Mohammed Bennamoun, Anuj Srivastava</h3>
<p>We propose a novel framework to learn the spatiotemporal variability in
longitudinal 3D shape data sets, which contain observations of subjects that
evolve and deform over time. This problem is challenging since surfaces come
with arbitrary spatial and temporal parameterizations. Thus, they need to be
spatially registered and temporally aligned onto each other. We solve this
spatiotemporal registration problem using a Riemannian approach. We treat a 3D
surface as a point in a shape space equipped with an elastic metric that
measures the amount of bending and stretching that the surfaces undergo. A 4D
surface can then be seen as a trajectory in this space. With this formulation,
the statistical analysis of 4D surfaces becomes the problem of analyzing
trajectories embedded in a nonlinear Riemannian manifold. However, computing
spatiotemporal registration and statistics on nonlinear spaces relies on
complex nonlinear optimizations. Our core contribution is the mapping of the
surfaces to the space of Square-Root Normal Fields (SRNF) where the L2 metric
is equivalent to the partial elastic metric in the space of surfaces. By
solving the spatial registration in the SRNF space, analyzing 4D surfaces
becomes the problem of analyzing trajectories embedded in the SRNF space, which
is Euclidean. Here, we develop the building blocks that enable such analysis.
These include the spatiotemporal registration of arbitrarily parameterized 4D
surfaces even in the presence of large elastic deformations and large
variations in their execution rates, the computation of geodesics between 4D
surfaces, the computation of statistical summaries, such as means and modes of
variation, and the synthesis of random 4D surfaces. We demonstrate the
performance of the proposed framework using 4D facial surfaces and 4D human
body shapes.
</p>
<a href="http://arxiv.org/abs/2101.09403" target="_blank">arXiv:2101.09403</a> [<a href="http://arxiv.org/pdf/2101.09403" target="_blank">pdf</a>]

<h2>Exploiting Web Images for Fine-Grained Visual Recognition by Eliminating Noisy Samples and Utilizing Hard Ones. (arXiv:2101.09412v1 [cs.CV])</h2>
<h3>Huafeng Liu, Chuanyi Zhang, Yazhou Yao, Xiushen Wei, Fumin Shen, Jian Zhang, Zhenmin Tang</h3>
<p>Labeling objects at a subordinate level typically requires expert knowledge,
which is not always available when using random annotators. As such, learning
directly from web images for fine-grained recognition has attracted broad
attention. However, the presence of label noise and hard examples in web images
are two obstacles for training robust fine-grained recognition models.
Therefore, in this paper, we propose a novel approach for removing irrelevant
samples from real-world web images during training, while employing useful hard
examples to update the network. Thus, our approach can alleviate the harmful
effects of irrelevant noisy web images and hard examples to achieve better
performance. Extensive experiments on three commonly used fine-grained datasets
demonstrate that our approach is far superior to current state-of-the-art
web-supervised methods.
</p>
<a href="http://arxiv.org/abs/2101.09412" target="_blank">arXiv:2101.09412</a> [<a href="http://arxiv.org/pdf/2101.09412" target="_blank">pdf</a>]

<h2>Deep Anti-aliasing of Whole Focal Stack Using Its Slice Spectrum. (arXiv:2101.09420v1 [cs.CV])</h2>
<h3>Yaning Li, Xue Wang, Guoqing Zhou, Qing Wang</h3>
<p>The paper aims at removing the aliasing effects for the whole focal stack
generated from a sparse 3D light field, while keeping the consistency across
all the focal layers.We first explore the structural characteristics embedded
in the focal stack slice and its corresponding frequency-domain representation,
i.e., the focal stack spectrum (FSS). We also observe that the energy
distribution of FSS always locates within the same triangular area under
different angular sampling rates, additionally the continuity of point spread
function (PSF) is intrinsically maintained in the FSS. Based on these two
findings, we propose a learning-based FSS reconstruction approach for one-time
aliasing removing over the whole focal stack. What's more, a novel
conjugate-symmetric loss function is proposed for the optimization. Compared to
previous works, our method avoids an explicit depth estimation, and can handle
challenging large-disparity scenarios. Experimental results on both synthetic
and real light field datasets show the superiority of the proposed approach for
different scenes and various angular sampling rates.
</p>
<a href="http://arxiv.org/abs/2101.09420" target="_blank">arXiv:2101.09420</a> [<a href="http://arxiv.org/pdf/2101.09420" target="_blank">pdf</a>]

<h2>Vertical federated learning based on DFP and BFGS. (arXiv:2101.09428v1 [cs.LG])</h2>
<h3>Song WenJie, Shen Xuan</h3>
<p>As data privacy is gradually valued by people, federated learning(FL) has
emerged because of its potential to protect data. FL uses homomorphic
encryption and differential privacy encryption on the promise of ensuring data
security to realize distributed machine learning by exchanging encrypted
information between different data providers. However, there are still many
problems in FL, such as the communication efficiency between the client and the
server and the data is non-iid. In order to solve the two problems mentioned
above, we propose a novel vertical federated learning framework based on the
DFP and the BFGS(denoted as BDFL), then apply it to logistic regression.
Finally, we perform experiments using real datasets to test efficiency of BDFL
framework.
</p>
<a href="http://arxiv.org/abs/2101.09428" target="_blank">arXiv:2101.09428</a> [<a href="http://arxiv.org/pdf/2101.09428" target="_blank">pdf</a>]

<h2>Explainable Artificial Intelligence Approaches: A Survey. (arXiv:2101.09429v1 [cs.AI])</h2>
<h3>Sheikh Rabiul Islam, William Eberle, Sheikh Khaled Ghafoor, Mohiuddin Ahmed</h3>
<p>The lack of explainability of a decision from an Artificial Intelligence (AI)
based "black box" system/model, despite its superiority in many real-world
applications, is a key stumbling block for adopting AI in many high stakes
applications of different domain or industry. While many popular Explainable
Artificial Intelligence (XAI) methods or approaches are available to facilitate
a human-friendly explanation of the decision, each has its own merits and
demerits, with a plethora of open challenges. We demonstrate popular XAI
methods with a mutual case study/task (i.e., credit default prediction),
analyze for competitive advantages from multiple perspectives (e.g., local,
global), provide meaningful insight on quantifying explainability, and
recommend paths towards responsible or human-centered AI using XAI as a medium.
Practitioners can use this work as a catalog to understand, compare, and
correlate competitive advantages of popular XAI methods. In addition, this
survey elicits future research directions towards responsible or human-centric
AI systems, which is crucial to adopt AI in high stakes applications.
</p>
<a href="http://arxiv.org/abs/2101.09429" target="_blank">arXiv:2101.09429</a> [<a href="http://arxiv.org/pdf/2101.09429" target="_blank">pdf</a>]

<h2>A Pressure Ulcer Care System For Remote Medical Assistance: Residual U-Net with an Attention Model Based for Wound Area Segmentation. (arXiv:2101.09433v1 [cs.CV])</h2>
<h3>Jinyeong Chae, Ki Yong Hong, Jihie Kim</h3>
<p>Increasing numbers of patients with disabilities or elderly people with
mobility issues often suffer from a pressure ulcer. The affected areas need
regular checks, but they have a difficulty in accessing a hospital. Some remote
diagnosis systems are being used for them, but there are limitations in
checking a patient's status regularly. In this paper, we present a remote
medical assistant that can help pressure ulcer management with image processing
techniques. The proposed system includes a mobile application with a deep
learning model for wound segmentation and analysis. As there are not enough
data to train the deep learning model, we make use of a pretrained model from a
relevant domain and data augmentation that is appropriate for this task. First
of all, an image preprocessing method using bilinear interpolation is used to
resize images and normalize the images. Second, for data augmentation, we use
rotation, reflection, and a watershed algorithm. Third, we use a pretrained
deep learning model generated from skin wound images similar to pressure ulcer
images. Finally, we added an attention module that can provide hints on the
pressure ulcer image features. The resulting model provides an accuracy of
99.0%, an intersection over union (IoU) of 99.99%, and a dice similarity
coefficient (DSC) of 93.4% for pressure ulcer segmentation, which is better
than existing results.
</p>
<a href="http://arxiv.org/abs/2101.09433" target="_blank">arXiv:2101.09433</a> [<a href="http://arxiv.org/pdf/2101.09433" target="_blank">pdf</a>]

<h2>Hierarchical Domain Invariant Variational Auto-Encoding with weak domain supervision. (arXiv:2101.09436v1 [cs.LG])</h2>
<h3>Xudong Sun, Florian Buettner</h3>
<p>We address the task of domain generalization, where the goal is to train a
predictive model based on a number of domains such that it is able to
generalize to a new, previously unseen domain. We choose a generative approach
within the framework of variational autoencoders and propose a weakly
supervised algorithm that is able to account for incomplete and hierarchical
domain information. We show that our method is able to learn representations
that disentangle domain-specific information from class-label specific
information even in complex settings where an unobserved substructure is
present in domains. Our interpretable method outperforms previously proposed
generative algorithms for domain generalization and achieves competitive
performance compared to state-of-the-art approaches, which are based on complex
image-processing steps, on the standard domain generalization benchmark dataset
PACS.
</p>
<a href="http://arxiv.org/abs/2101.09436" target="_blank">arXiv:2101.09436</a> [<a href="http://arxiv.org/pdf/2101.09436" target="_blank">pdf</a>]

<h2>An Optimal Reduction of TV-Denoising to Adaptive Online Learning. (arXiv:2101.09438v1 [cs.LG])</h2>
<h3>Dheeraj Baby, Xuandong Zhao, Yu-Xiang Wang</h3>
<p>We consider the problem of estimating a function from $n$ noisy samples whose
discrete Total Variation (TV) is bounded by $C_n$. We reveal a deep connection
to the seemingly disparate problem of Strongly Adaptive online learning
(Daniely et.al, 2015) and provide an $O(n \log n)$ time algorithm that attains
the near minimax optimal rate of $\tilde O (n^{1/3}C_n^{2/3})$ under squared
error loss. The resulting algorithm runs online and optimally adapts to the
unknown smoothness parameter $C_n$. This leads to a new and more versatile
alternative to wavelets-based methods for (1) adaptively estimating TV bounded
functions; (2) online forecasting of TV bounded trends in time series.
</p>
<a href="http://arxiv.org/abs/2101.09438" target="_blank">arXiv:2101.09438</a> [<a href="http://arxiv.org/pdf/2101.09438" target="_blank">pdf</a>]

<h2>Unlabeled Principal Component Analysis. (arXiv:2101.09446v1 [cs.LG])</h2>
<h3>Yunzhen Yao, Liangzu Peng, Manolis C. Tsakiris</h3>
<p>We consider the problem of principal component analysis from a data matrix
where the entries of each column have undergone some unknown permutation,
termed Unlabeled Principal Component Analysis (UPCA). Using algebraic geometry,
we establish that for generic enough data, and up to a permutation of the
coordinates of the ambient space, there is a unique subspace of minimal
dimension that explains the data. We show that a permutation-invariant system
of polynomial equations has finitely many solutions, with each solution
corresponding to a row permutation of the ground-truth data matrix. Allowing
for missing entries on top of permutations leads to the problem of unlabeled
matrix completion, for which we give theoretical results of similar flavor. We
also propose a two-stage algorithmic pipeline for UPCA suitable for the
practically relevant case where only a fraction of the data has been permuted.
Stage-I of this pipeline employs robust-PCA methods to estimate the
ground-truth column-space. Equipped with the column-space, stage-II applies
methods for linear regression without correspondences to restore the permuted
data. A computational study reveals encouraging findings, including the ability
of UPCA to handle face images from the Extended Yale-B database with
arbitrarily permuted patches of arbitrary size in $0.3$ seconds on a standard
desktop computer.
</p>
<a href="http://arxiv.org/abs/2101.09446" target="_blank">arXiv:2101.09446</a> [<a href="http://arxiv.org/pdf/2101.09446" target="_blank">pdf</a>]

<h2>Error Diffusion Halftoning Against Adversarial Examples. (arXiv:2101.09451v1 [cs.CV])</h2>
<h3>Shao-Yuan Lo, Vishal M. Patel</h3>
<p>Adversarial examples contain carefully crafted perturbations that can fool
deep neural networks (DNNs) into making wrong predictions. Enhancing the
adversarial robustness of DNNs has gained considerable interest in recent
years. Although image transformation-based defenses were widely considered at
an earlier time, most of them have been defeated by adaptive attacks. In this
paper, we propose a new image transformation defense based on error diffusion
halftoning, and combine it with adversarial training to defend against
adversarial examples. Error diffusion halftoning projects an image into a 1-bit
space and diffuses quantization error to neighboring pixels. This process can
remove adversarial perturbations from a given image while maintaining
acceptable image quality in the meantime in favor of recognition. Experimental
results demonstrate that the proposed method is able to improve adversarial
robustness even under advanced adaptive attacks, while most of the other image
transformation-based defenses do not. We show that a proper image
transformation can still be an effective defense approach.
</p>
<a href="http://arxiv.org/abs/2101.09451" target="_blank">arXiv:2101.09451</a> [<a href="http://arxiv.org/pdf/2101.09451" target="_blank">pdf</a>]

<h2>Improved Training of Sparse Coding Variational Autoencoder via Weight Normalization. (arXiv:2101.09453v1 [cs.LG])</h2>
<h3>Linxing Preston Jiang, Luciano de la Iglesia</h3>
<p>Learning a generative model of visual information with sparse and
compositional features has been a challenge for both theoretical neuroscience
and machine learning communities. Sparse coding models have achieved great
success in explaining the receptive fields of mammalian primary visual cortex
with sparsely activated latent representation. In this paper, we focus on a
recently proposed model, sparse coding variational autoencoder (SVAE) (Barello
et al., 2018), and show that the end-to-end training scheme of SVAE leads to a
large group of decoding filters not fully optimized with noise-like receptive
fields. We propose a few heuristics to improve the training of SVAE and show
that a unit $L_2$ norm constraint on the decoder is critical to produce sparse
coding filters. Such normalization can be considered as local lateral
inhibition in the cortex. We verify this claim empirically on both natural
image patches and MNIST dataset and show that projection of the filters onto
unit norm drastically increases the number of active filters. Our results
highlight the importance of weight normalization for learning sparse
representation from data and suggest a new way of reducing the number of
inactive latent components in VAE learning.
</p>
<a href="http://arxiv.org/abs/2101.09453" target="_blank">arXiv:2101.09453</a> [<a href="http://arxiv.org/pdf/2101.09453" target="_blank">pdf</a>]

<h2>Rethinking Exploration for Sample-Efficient Policy Learning. (arXiv:2101.09458v1 [cs.LG])</h2>
<h3>William F. Whitney, Michael Bloesch, Jost Tobias Springenberg, Abbas Abdolmaleki, Martin Riedmiller</h3>
<p>Off-policy reinforcement learning for control has made great strides in terms
of performance and sample efficiency. We suggest that for many tasks the sample
efficiency of modern methods is now limited by the richness of the data
collected rather than the difficulty of policy fitting. We examine the reasons
that directed exploration methods in the bonus-based exploration (BBE) family
have not been more influential in the sample efficient control problem. Three
issues have limited the applicability of BBE: bias with finite samples, slow
adaptation to decaying bonuses, and lack of optimism on unseen transitions. We
propose modifications to the bonus-based exploration recipe to address each of
these limitations. The resulting algorithm, which we call UFO, produces
policies that are Unbiased with finite samples, Fast-adapting as the
exploration bonus changes, and Optimistic with respect to new transitions. We
include experiments showing that rapid directed exploration is a promising
direction to improve sample efficiency for control.
</p>
<a href="http://arxiv.org/abs/2101.09458" target="_blank">arXiv:2101.09458</a> [<a href="http://arxiv.org/pdf/2101.09458" target="_blank">pdf</a>]

<h2>Feature Selection Using Reinforcement Learning. (arXiv:2101.09460v1 [cs.LG])</h2>
<h3>Sali Rasoul, Sodiq Adewole, Alphonse Akakpo</h3>
<p>With the decreasing cost of data collection, the space of variables or
features that can be used to characterize a particular predictor of interest
continues to grow exponentially. Therefore, identifying the most characterizing
features that minimizes the variance without jeopardizing the bias of our
models is critical to successfully training a machine learning model. In
addition, identifying such features is critical for interpretability,
prediction accuracy and optimal computation cost. While statistical methods
such as subset selection, shrinkage, dimensionality reduction have been applied
in selecting the best set of features, some other approaches in literature have
approached feature selection task as a search problem where each state in the
search space is a possible feature subset. In this paper, we solved the feature
selection problem using Reinforcement Learning. Formulating the state space as
a Markov Decision Process (MDP), we used Temporal Difference (TD) algorithm to
select the best subset of features. Each state was evaluated using a robust and
low cost classifier algorithm which could handle any non-linearities in the
dataset.
</p>
<a href="http://arxiv.org/abs/2101.09460" target="_blank">arXiv:2101.09460</a> [<a href="http://arxiv.org/pdf/2101.09460" target="_blank">pdf</a>]

<h2>Sequence-based Dynamic Handwriting Analysis for Parkinson's Disease Detection with One-dimensional Convolutions and BiGRUs. (arXiv:2101.09461v1 [cs.CV])</h2>
<h3>Moises Diaz, Momina Moetesum, Imran Siddiqi, Gennaro Vessio</h3>
<p>Parkinson's disease (PD) is commonly characterized by several motor symptoms,
such as bradykinesia, akinesia, rigidity, and tremor. The analysis of patients'
fine motor control, particularly handwriting, is a powerful tool to support PD
assessment. Over the years, various dynamic attributes of handwriting, such as
pen pressure, stroke speed, in-air time, etc., which can be captured with the
help of online handwriting acquisition tools, have been evaluated for the
identification of PD. Motion events, and their associated spatio-temporal
properties captured in online handwriting, enable effective classification of
PD patients through the identification of unique sequential patterns. This
paper proposes a novel classification model based on one-dimensional
convolutions and Bidirectional Gated Recurrent Units (BiGRUs) to assess the
potential of sequential information of handwriting in identifying Parkinsonian
symptoms. One-dimensional convolutions are applied to raw sequences as well as
derived features; the resulting sequences are then fed to BiGRU layers to
achieve the final classification. The proposed method outperformed
state-of-the-art approaches on the PaHaW dataset and achieved competitive
results on the NewHandPD dataset.
</p>
<a href="http://arxiv.org/abs/2101.09461" target="_blank">arXiv:2101.09461</a> [<a href="http://arxiv.org/pdf/2101.09461" target="_blank">pdf</a>]

<h2>Neural Relational Inference with Efficient Message Passing Mechanisms. (arXiv:2101.09486v1 [cs.LG])</h2>
<h3>Siyuan Chen, Jiahai Wang, Guoqing Li</h3>
<p>Many complex processes can be viewed as dynamical systems of interacting
agents. In many cases, only the state sequences of individual agents are
observed, while the interacting relations and the dynamical rules are unknown.
The neural relational inference (NRI) model adopts graph neural networks that
pass messages over a latent graph to jointly learn the relations and the
dynamics based on the observed data. However, NRI infers the relations
independently and suffers from error accumulation in multi-step prediction at
dynamics learning procedure. Besides, relation reconstruction without prior
knowledge becomes more difficult in more complex systems. This paper introduces
efficient message passing mechanisms to the graph neural networks with
structural prior knowledge to address these problems. A relation interaction
mechanism is proposed to capture the coexistence of all relations, and a
spatio-temporal message passing mechanism is proposed to use historical
information to alleviate error accumulation. Additionally, the structural prior
knowledge, symmetry as a special case, is introduced for better relation
prediction in more complex systems. The experimental results on simulated
physics systems show that the proposed method outperforms existing
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2101.09486" target="_blank">arXiv:2101.09486</a> [<a href="http://arxiv.org/pdf/2101.09486" target="_blank">pdf</a>]

<h2>Symbiotic System Design for Safe and Resilient Autonomous Robotics in Offshore Wind Farms. (arXiv:2101.09491v1 [cs.RO])</h2>
<h3>Daniel Mitchell, Osama Zaki, Jamie Blanche, Joshua Roe, Leo Kong, Samuel Harper, Valentin Robu, Theodore Lim, David Flynn</h3>
<p>To reduce Operation and Maintenance (O&amp;M) costs on offshore wind farms,
wherein 80% of the O&amp;M cost relates to deploying personnel, the offshore wind
sector looks to robotics and Artificial Intelligence (AI) for solutions.
Barriers to Beyond Visual Line of Sight (BVLOS) robotics include operational
safety compliance and resilience, inhibiting the commercialization of
autonomous services offshore. To address safety and resilience challenges we
propose a symbiotic system; reflecting the lifecycle learning and co-evolution
with knowledge sharing for mutual gain of robotic platforms and remote human
operators. Our methodology enables the run-time verification of safety,
reliability and resilience during autonomous missions. We synchronize digital
models of the robot, environment and infrastructure and integrate front-end
analytics and bidirectional communication for autonomous adaptive mission
planning and situation reporting to a remote operator. A reliability ontology
for the deployed robot, based on our holistic hierarchical-relational model,
supports computationally efficient platform data analysis. We analyze the
mission status and diagnostics of critical sub-systems within the robot to
provide automatic updates to our run-time reliability ontology, enabling faults
to be translated into failure modes for decision making during the mission. We
demonstrate an asset inspection mission within a confined space and employ
millimeter-wave sensing to enhance situational awareness to detect the presence
of obscured personnel to mitigate risk. Our results demonstrate a symbiotic
system provides an enhanced resilience capability to BVLOS missions. A
symbiotic system addresses the operational challenges and reprioritization of
autonomous mission objectives. This advances the technology required to achieve
fully trustworthy autonomous systems.
</p>
<a href="http://arxiv.org/abs/2101.09491" target="_blank">arXiv:2101.09491</a> [<a href="http://arxiv.org/pdf/2101.09491" target="_blank">pdf</a>]

<h2>MinConvNets: A new class of multiplication-less Neural Networks. (arXiv:2101.09492v1 [cs.LG])</h2>
<h3>Xuecan Yang, Sumanta Chaudhuri, Laurence Likforman, Lirida Naviner</h3>
<p>Convolutional Neural Networks have achieved unprecedented success in image
classification, recognition, or detection applications. However, their
large-scale deployment in embedded devices is still limited by the huge
computational requirements, i.e., millions of MAC operations per layer. In this
article, MinConvNets where the multiplications in the forward propagation are
approximated by minimum comparator operations are introduced. Hardware
implementation of minimum operation is much simpler than multipliers. Firstly,
a methodology to find approximate operations based on statistical correlation
is presented. We show that it is possible to replace multipliers by minimum
operations in the forward propagation under certain constraints, i.e. given
similar mean and variances of the feature and the weight vectors. A modified
training method which guarantees the above constraints is proposed. And it is
shown that equivalent precision can be achieved during inference with
MinConvNets by using transfer learning from well trained exact CNNs.
</p>
<a href="http://arxiv.org/abs/2101.09492" target="_blank">arXiv:2101.09492</a> [<a href="http://arxiv.org/pdf/2101.09492" target="_blank">pdf</a>]

<h2>Granular conditional entropy-based attribute reduction for partially labeled data with proxy labels. (arXiv:2101.09495v1 [cs.AI])</h2>
<h3>Can Gao, Jie Zhoua, Duoqian Miao, Xiaodong Yue, Jun Wan</h3>
<p>Attribute reduction is one of the most important research topics in the
theory of rough sets, and many rough sets-based attribute reduction methods
have thus been presented. However, most of them are specifically designed for
dealing with either labeled data or unlabeled data, while many real-world
applications come in the form of partial supervision. In this paper, we propose
a rough sets-based semi-supervised attribute reduction method for partially
labeled data. Particularly, with the aid of prior class distribution
information about data, we first develop a simple yet effective strategy to
produce the proxy labels for unlabeled data. Then the concept of information
granularity is integrated into the information-theoretic measure, based on
which, a novel granular conditional entropy measure is proposed, and its
monotonicity is proved in theory. Furthermore, a fast heuristic algorithm is
provided to generate the optimal reduct of partially labeled data, which could
accelerate the process of attribute reduction by removing irrelevant examples
and excluding redundant attributes simultaneously. Extensive experiments
conducted on UCI data sets demonstrate that the proposed semi-supervised
attribute reduction method is promising and even compares favourably with the
supervised methods on labeled data and unlabeled data with true labels in terms
of classification performance.
</p>
<a href="http://arxiv.org/abs/2101.09495" target="_blank">arXiv:2101.09495</a> [<a href="http://arxiv.org/pdf/2101.09495" target="_blank">pdf</a>]

<h2>Show or Suppress? Managing Input Uncertainty in Machine Learning Model Explanations. (arXiv:2101.09498v1 [cs.LG])</h2>
<h3>Danding Wang, Wencan Zhang, Brian Y. Lim</h3>
<p>Feature attribution is widely used in interpretable machine learning to
explain how influential each measured input feature value is for an output
inference. However, measurements can be uncertain, and it is unclear how the
awareness of input uncertainty can affect the trust in explanations. We propose
and study two approaches to help users to manage their perception of
uncertainty in a model explanation: 1) transparently show uncertainty in
feature attributions to allow users to reflect on, and 2) suppress attribution
to features with uncertain measurements and shift attribution to other features
by regularizing with an uncertainty penalty. Through simulation experiments,
qualitative interviews, and quantitative user evaluations, we identified the
benefits of moderately suppressing attribution uncertainty, and concerns
regarding showing attribution uncertainty. This work adds to the understanding
of handling and communicating uncertainty for model interpretability.
</p>
<a href="http://arxiv.org/abs/2101.09498" target="_blank">arXiv:2101.09498</a> [<a href="http://arxiv.org/pdf/2101.09498" target="_blank">pdf</a>]

<h2>Contrastive Prototype Learning with Augmented Embeddings for Few-Shot Learning. (arXiv:2101.09499v1 [cs.CV])</h2>
<h3>Yizhao Gao, Nanyi Fei, Guangzhen Liu, Zhiwu Lu, Tao Xiang, Songfang Huang</h3>
<p>Most recent few-shot learning (FSL) methods are based on meta-learning with
episodic training. In each meta-training episode, a discriminative feature
embedding and/or classifier are first constructed from a support set in an
inner loop, and then evaluated in an outer loop using a query set for model
updating. This query set sample centered learning objective is however
intrinsically limited in addressing the lack of training data problem in the
support set. In this paper, a novel contrastive prototype learning with
augmented embeddings (CPLAE) model is proposed to overcome this limitation.
First, data augmentations are introduced to both the support and query sets
with each sample now being represented as an augmented embedding (AE) composed
of concatenated embeddings of both the original and augmented versions. Second,
a novel support set class prototype centered contrastive loss is proposed for
contrastive prototype learning (CPL). With a class prototype as an anchor, CPL
aims to pull the query samples of the same class closer and those of different
classes further away. This support set sample centered loss is highly
complementary to the existing query centered loss, fully exploiting the limited
training data in each episode. Extensive experiments on several benchmarks
demonstrate that our proposed CPLAE achieves new state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2101.09499" target="_blank">arXiv:2101.09499</a> [<a href="http://arxiv.org/pdf/2101.09499" target="_blank">pdf</a>]

<h2>Disentangled Sequence Clustering for Human Intention Inference. (arXiv:2101.09500v1 [cs.RO])</h2>
<h3>Mark Zolotas, Yiannis Demiris</h3>
<p>Equipping robots with the ability to infer human intent is a vital
precondition for effective collaboration. Most computational approaches towards
this objective employ probabilistic reasoning to recover a distribution of
"intent" conditioned on the robot's perceived sensory state. However, these
approaches typically assume task-specific notions of human intent (e.g.
labelled goals) are known a priori. To overcome this constraint, we propose the
Disentangled Sequence Clustering Variational Autoencoder (DiSCVAE), a
clustering framework that can be used to learn such a distribution of intent in
an unsupervised manner. The DiSCVAE leverages recent advances in unsupervised
learning to derive a disentangled latent representation of sequential data,
separating time-varying local features from time-invariant global aspects.
Though unlike previous frameworks for disentanglement, the proposed variant
also infers a discrete variable to form a latent mixture model and enable
clustering of global sequence concepts, e.g. intentions from observed human
behaviour. To evaluate the DiSCVAE, we first validate its capacity to discover
classes from unlabelled sequences using video datasets of bouncing digits and
2D animations. We then report results from a real-world human-robot interaction
experiment conducted on a robotic wheelchair. Our findings glean insights into
how the inferred discrete variable coincides with human intent and thus serves
to improve assistance in collaborative settings, such as shared control.
</p>
<a href="http://arxiv.org/abs/2101.09500" target="_blank">arXiv:2101.09500</a> [<a href="http://arxiv.org/pdf/2101.09500" target="_blank">pdf</a>]

<h2>Safe Learning and Optimization Techniques: Towards a Survey of the State of the Art. (arXiv:2101.09505v1 [cs.LG])</h2>
<h3>Youngmin Kim, Richard Allmendinger, Manuel L&#xf3;pez-Ib&#xe1;&#xf1;ez</h3>
<p>Safe learning and optimization deals with learning and optimization problems
that avoid, as much as possible, the evaluation of non-safe input points, which
are solutions, policies, or strategies that cause an irrecoverable loss (e.g.,
breakage of a machine or equipment, or life threat). Although a comprehensive
survey of safe reinforcement learning algorithms was published in 2015, a
number of new algorithms have been proposed thereafter, and related works in
active learning and in optimization were not considered. This paper reviews
those algorithms from a number of domains including reinforcement learning,
Gaussian process regression and classification, evolutionary algorithms, and
active learning. We provide the fundamental concepts on which the reviewed
algorithms are based and a characterization of the individual algorithms. We
conclude by explaining how the algorithms are connected and suggestions for
future research.
</p>
<a href="http://arxiv.org/abs/2101.09505" target="_blank">arXiv:2101.09505</a> [<a href="http://arxiv.org/pdf/2101.09505" target="_blank">pdf</a>]

<h2>Short-term daily precipitation forecasting with seasonally-integrated autoencoder. (arXiv:2101.09509v1 [cs.LG])</h2>
<h3>Donlapark Ponnoprat</h3>
<p>Short-term precipitation forecasting is essential for planning of human
activities in multiple scales, ranging from individuals' planning, urban
management to flood prevention. Yet the short-term atmospheric dynamics are
highly nonlinear that it cannot be easily captured with classical time series
models. On the other hand, deep learning models are good at learning nonlinear
interactions, but they are not designed to deal with the seasonality in time
series. In this study, we aim to develop a forecasting model that can both
handle the nonlinearities and detect the seasonality hidden within the daily
precipitation data. To this end, we propose a seasonally-integrated autoencoder
(SSAE) consisting of two long short-term memory (LSTM) autoencoders: one for
learning short-term dynamics, and the other for learning the seasonality in the
time series. Our experimental results show that not only does the SSAE
outperform various time series models regardless of the climate type, but it
also has low output variance compared to other deep learning models. The
results also show that the seasonal component of the SSAE helped improve the
correlation between the forecast and the actual values from 4% at horizon 1 to
37% at horizon 3.
</p>
<a href="http://arxiv.org/abs/2101.09509" target="_blank">arXiv:2101.09509</a> [<a href="http://arxiv.org/pdf/2101.09509" target="_blank">pdf</a>]

<h2>Unsupervised clustering of series using dynamic programming. (arXiv:2101.09512v1 [cs.LG])</h2>
<h3>Karthigan Sinnathamby, Chang-Yu Hou, Lalitha Venkataramanan, Vasileios-Marios Gkortsas, Fran&#xe7;ois Fleuret</h3>
<p>We are interested in clustering parts of a given single multi-variate series
in an unsupervised manner. We would like to segment and cluster the series such
that the resulting blocks present in each cluster are coherent with respect to
a known model (e.g. physics model). Data points are said to be coherent if they
can be described using this model with the same parameters. We have designed an
algorithm based on dynamic programming with constraints on the number of
clusters, the number of transitions as well as the minimal size of a block such
that the clusters are coherent with this process. We present an use-case:
clustering of petrophysical series using the Waxman-Smits equation.
</p>
<a href="http://arxiv.org/abs/2101.09512" target="_blank">arXiv:2101.09512</a> [<a href="http://arxiv.org/pdf/2101.09512" target="_blank">pdf</a>]

<h2>A Dual-arm Robot that Autonomously Lifts Up and Tumbles Heavy Plates Using Crane Pulley Blocks. (arXiv:2101.09526v1 [cs.RO])</h2>
<h3>Shogo Hayakawa, Weiwei Wan, Keisuke Koyama, Kensuke Harada</h3>
<p>This paper develops a planner that plans the action sequences and motion for
a dual-arm robot to lift up and flip heavy plates using crane pulley blocks.
The problem is motivated by the low payload of modern collaborative robots.
Instead of directly manipulating heavy plates that collaborative robots cannot
afford, the paper develops a planner for collaborative robots to operate crane
pulley blocks. The planner assumes a target plate is pre-attached to the crane
hook. It optimizes dual-arm action sequences and plans the robot's dual-arm
motion that pulls the rope of the crane pulley blocks to lift up the plate. The
crane pulley blocks reduce the payload that each robotic arm needs to bear.
When the plate is lifted up to a satisfying pose, the planner plans a pushing
motion for one of the robot arms to tumble over the plate while considering
force and moment constraints. The article presents the technical details of the
planner and several experiments and analysis carried out using a dual-arm robot
made by two Universal Robots UR3 arms. The influence of various parameters and
optimization goals are investigated and compared in depth. The results show
that the proposed planner is flexible and efficient.
</p>
<a href="http://arxiv.org/abs/2101.09526" target="_blank">arXiv:2101.09526</a> [<a href="http://arxiv.org/pdf/2101.09526" target="_blank">pdf</a>]

<h2>Memory-Efficient Semi-Supervised Continual Learning: The World is its Own Replay Buffer. (arXiv:2101.09536v1 [cs.CV])</h2>
<h3>James Smith, Jonathan Balloch, Yen-Chang Hsu, Zsolt Kira</h3>
<p>Rehearsal is a critical component for class-incremental continual learning,
yet it requires a substantial memory budget. Our work investigates whether we
can significantly reduce this memory budget by leveraging unlabeled data from
an agent's environment in a realistic and challenging continual learning
paradigm. Specifically, we explore and formalize a novel semi-supervised
continual learning (SSCL) setting, where labeled data is scarce yet non-i.i.d.
unlabeled data from the agent's environment is plentiful. Importantly, data
distributions in the SSCL setting are realistic and therefore reflect object
class correlations between, and among, the labeled and unlabeled data
distributions. We show that a strategy built on pseudo-labeling, consistency
regularization, Out-of-Distribution (OoD) detection, and knowledge distillation
reduces forgetting in this setting. Our approach, DistillMatch, increases
performance over the state-of-the-art by no less than 8.7% average task
accuracy and up to a 54.5% increase in average task accuracy in SSCL CIFAR-100
experiments. Moreover, we demonstrate that DistillMatch can save up to 0.23
stored images per processed unlabeled image compared to the next best method
which only saves 0.08. Our results suggest that focusing on realistic
correlated distributions is a significantly new perspective, which accentuates
the importance of leveraging the world's structure as a continual learning
strategy.
</p>
<a href="http://arxiv.org/abs/2101.09536" target="_blank">arXiv:2101.09536</a> [<a href="http://arxiv.org/pdf/2101.09536" target="_blank">pdf</a>]

<h2>Real-Time, Flight-Ready, Non-Cooperative Spacecraft Pose Estimation Using Monocular Imagery. (arXiv:2101.09553v1 [cs.CV])</h2>
<h3>Kevin Black, Shrivu Shankar, Daniel Fonseka, Jacob Deutsch, Abhimanyu Dhir, Maruthi R. Akella</h3>
<p>A key requirement for autonomous on-orbit proximity operations is the
estimation of a target spacecraft's relative pose (position and orientation).
It is desirable to employ monocular cameras for this problem due to their low
cost, weight, and power requirements. This work presents a novel convolutional
neural network (CNN)-based monocular pose estimation system that achieves
state-of-the-art accuracy with low computational demand. In combination with a
Blender-based synthetic data generation scheme, the system demonstrates the
ability to generalize from purely synthetic training data to real in-space
imagery of the Northrop Grumman Enhanced Cygnus spacecraft. Additionally, the
system achieves real-time performance on low-power flight-like hardware.
</p>
<a href="http://arxiv.org/abs/2101.09553" target="_blank">arXiv:2101.09553</a> [<a href="http://arxiv.org/pdf/2101.09553" target="_blank">pdf</a>]

<h2>Network-Agnostic Knowledge Transfer for Medical Image Segmentation. (arXiv:2101.09560v1 [cs.CV])</h2>
<h3>Shuhang Wang, Vivek Kumar Singh, Alex Benjamin, Mercy Asiedu, Elham Yousef Kalafi, Eugene Cheah, Viksit Kumar, Anthony Samir</h3>
<p>Conventional transfer learning leverages weights of pre-trained networks, but
mandates the need for similar neural architectures. Alternatively, knowledge
distillation can transfer knowledge between heterogeneous networks but often
requires access to the original training data or additional generative
networks. Knowledge transfer between networks can be improved by being agnostic
to the choice of network architecture and reducing the dependence on original
training data. We propose a knowledge transfer approach from a teacher to a
student network wherein we train the student on an independent transferal
dataset, whose annotations are generated by the teacher. Experiments were
conducted on five state-of-the-art networks for semantic segmentation and seven
datasets across three imaging modalities. We studied knowledge transfer from a
single teacher, combination of knowledge transfer and fine-tuning, and
knowledge transfer from multiple teachers. The student model with a single
teacher achieved similar performance as the teacher; and the student model with
multiple teachers achieved better performance than the teachers. The salient
features of our algorithm include: 1)no need for original training data or
generative networks, 2) knowledge transfer between different architectures, 3)
ease of implementation for downstream tasks by using the downstream task
dataset as the transferal dataset, 4) knowledge transfer of an ensemble of
models, trained independently, into one student model. Extensive experiments
demonstrate that the proposed algorithm is effective for knowledge transfer and
easily tunable.
</p>
<a href="http://arxiv.org/abs/2101.09560" target="_blank">arXiv:2101.09560</a> [<a href="http://arxiv.org/pdf/2101.09560" target="_blank">pdf</a>]

<h2>Deep Learning for General Game Playing with Ludii and Polygames. (arXiv:2101.09562v1 [cs.AI])</h2>
<h3>Dennis J. N. J. Soemers, Vegard Mella, Cameron Browne, Olivier Teytaud</h3>
<p>Combinations of Monte-Carlo tree search and Deep Neural Networks, trained
through self-play, have produced state-of-the-art results for automated
game-playing in many board games. The training and search algorithms are not
game-specific, but every individual game that these approaches are applied to
still requires domain knowledge for the implementation of the game's rules, and
constructing the neural network's architecture -- in particular the shapes of
its input and output tensors. Ludii is a general game system that already
contains over 500 different games, which can rapidly grow thanks to its
powerful and user-friendly game description language. Polygames is a framework
with training and search algorithms, which has already produced superhuman
players for several board games. This paper describes the implementation of a
bridge between Ludii and Polygames, which enables Polygames to train and
evaluate models for games that are implemented and run through Ludii. We do not
require any game-specific domain knowledge anymore, and instead leverage our
domain knowledge of the Ludii system and its abstract state and move
representations to write functions that can automatically determine the
appropriate shapes for input and output tensors for any game implemented in
Ludii. We describe experimental results for short training runs in a wide
variety of different board games, and discuss several open problems and avenues
for future research.
</p>
<a href="http://arxiv.org/abs/2101.09562" target="_blank">arXiv:2101.09562</a> [<a href="http://arxiv.org/pdf/2101.09562" target="_blank">pdf</a>]

<h2>A Transferable Anti-Forensic Attack on Forensic CNNs Using A Generative Adversarial Network. (arXiv:2101.09568v1 [cs.CV])</h2>
<h3>Xinwei Zhao, Chen Chen, Matthew C. Stamm</h3>
<p>With the development of deep learning, convolutional neural networks (CNNs)
have become widely used in multimedia forensics for tasks such as detecting and
identifying image forgeries. Meanwhile, anti-forensic attacks have been
developed to fool these CNN-based forensic algorithms. Previous anti-forensic
attacks often were designed to remove forgery traces left by a single
manipulation operation as opposed to a set of manipulations. Additionally,
recent research has shown that existing anti-forensic attacks against forensic
CNNs have poor transferability, i.e. they are unable to fool other forensic
CNNs that were not explicitly used during training. In this paper, we propose a
new anti-forensic attack framework designed to remove forensic traces left by a
variety of manipulation operations. This attack is transferable, i.e. it can be
used to attack forensic CNNs are unknown to the attacker, and it introduces
only minimal distortions that are imperceptible to human eyes. Our proposed
attack utilizes a generative adversarial network (GAN) to build a generator
that can attack color images of any size. We achieve attack transferability
through the use of a new training strategy and loss function. We conduct
extensive experiment to demonstrate that our attack can fool many state-of-art
forensic CNNs with varying levels of knowledge available to the attacker.
</p>
<a href="http://arxiv.org/abs/2101.09568" target="_blank">arXiv:2101.09568</a> [<a href="http://arxiv.org/pdf/2101.09568" target="_blank">pdf</a>]

<h2>S-BEV: Semantic Birds-Eye View Representation for Weather and Lighting Invariant 3-DoF Localization. (arXiv:2101.09569v1 [cs.CV])</h2>
<h3>Mokshith Voodarla, Shubham Shrivastava, Sagar Manglani, Ankit Vora, Siddharth Agarwal, Punarjay Chakravarty</h3>
<p>We describe a light-weight, weather and lighting invariant, Semantic Bird's
Eye View (S-BEV) signature for vision-based vehicle re-localization. A
topological map of S-BEV signatures is created during the first traversal of
the route, which are used for coarse localization in subsequent route
traversal. A fine-grained localizer is then trained to output the global 3-DoF
pose of the vehicle using its S-BEV and its coarse localization. We conduct
experiments on vKITTI2 virtual dataset and show the potential of the S-BEV to
be robust to weather and lighting. We also demonstrate results with 2 vehicles
on a 22 km long highway route in the Ford AV dataset.
</p>
<a href="http://arxiv.org/abs/2101.09569" target="_blank">arXiv:2101.09569</a> [<a href="http://arxiv.org/pdf/2101.09569" target="_blank">pdf</a>]

<h2>BF++:a language for general-purpose neural program synthesis. (arXiv:2101.09571v1 [cs.AI])</h2>
<h3>Vadim Liventsev, Aki H&#xe4;rm&#xe4;, Milan Petkovi&#x107;</h3>
<p>Most state of the art decision systems based on Reinforcement Learning (RL)
are data-driven black-box neuralmodels, where it is often difficult to
incorporate expert knowledge into the models or let experts review andvalidate
the learned decision mechanisms. Knowledge-insertion and model review are
important requirements inmany applications involving human health and safety.
One way to bridge the gap between data and knowledgedriven systems is program
synthesis: replacing a neural network that outputs decisions with one that
generatesdecision-making code in some programming language. We propose a new
programming language, BF++,designed specifically for neural program synthesis
in a Partially Observable Markov Decision Process (POMDP)setting and generate
programs for a number of standard OpenAI Gym benchmarks.
</p>
<a href="http://arxiv.org/abs/2101.09571" target="_blank">arXiv:2101.09571</a> [<a href="http://arxiv.org/pdf/2101.09571" target="_blank">pdf</a>]

<h2>ReliefE: Feature Ranking in High-dimensional Spaces via Manifold Embeddings. (arXiv:2101.09577v1 [cs.LG])</h2>
<h3>Bla&#x17e; &#x160;krlj, Sa&#x161;o D&#x17e;eroski, Nada Lavra&#x10d;, Matej Petkovi&#x107;</h3>
<p>Feature ranking has been widely adopted in machine learning applications such
as high-throughput biology and social sciences. The approaches of the popular
Relief family of algorithms assign importances to features by iteratively
accounting for nearest relevant and irrelevant instances. Despite their high
utility, these algorithms can be computationally expensive and not-well suited
for high-dimensional sparse input spaces. In contrast, recent embedding-based
methods learn compact, low-dimensional representations, potentially
facilitating down-stream learning capabilities of conventional learners. This
paper explores how the Relief branch of algorithms can be adapted to benefit
from (Riemannian) manifold-based embeddings of instance and target spaces,
where a given embedding's dimensionality is intrinsic to the dimensionality of
the considered data set. The developed ReliefE algorithm is faster and can
result in better feature rankings, as shown by our evaluation on 20 real-life
data sets for multi-class and multi-label classification tasks. The utility of
ReliefE for high-dimensional data sets is ensured by its implementation that
utilizes sparse matrix algebraic operations. Finally, the relation of ReliefE
to other ranking algorithms is studied via the Fuzzy Jaccard Index.
</p>
<a href="http://arxiv.org/abs/2101.09577" target="_blank">arXiv:2101.09577</a> [<a href="http://arxiv.org/pdf/2101.09577" target="_blank">pdf</a>]

<h2>BSUV-Net 2.0: Spatio-Temporal Data Augmentations for Video-AgnosticSupervised Background Subtraction. (arXiv:2101.09585v1 [cs.CV])</h2>
<h3>M. Ozan Tezcan, Prakash Ishwar, Janusz Konrad</h3>
<p>Background subtraction (BGS) is a fundamental video processing task which is
a key component of many applications. Deep learning-based supervised algorithms
achieve very promising results in BGS, however, most of these algorithms are
optimized for either a specific video or a group of videos, and their
performance decreases significantly when applied to unseen videos. Recently,
several papers addressed this problem and proposed video-agnostic supervised
BGS algorithms. However, nearly all of the data augmentations used in these
works are limited to spatial domain and do not account for temporal variations
naturally occurring in video data. In this work, we introduce spatio-temporal
data augmentations and apply it to one of the leading video-agnostic BGS
algorithms, BSUV-Net. Our new model trained using the proposed data
augmentations, named BSUV-Net 2.0, significantly outperforms the
state-of-the-art algorithms evaluated on unseen videos. We also develop a
real-time variant of our model named Fast BSUV-Net 2.0 with performance close
to the state-of-the-art. Furthermore, we introduce a new cross-validation
training and evaluation strategy for the CDNet-2014 dataset that makes it
possible to fairly and easily compare the performance of various video-agnostic
supervised BGS algorithms. The source code of BSUV-Net 2.0 will be published.
</p>
<a href="http://arxiv.org/abs/2101.09585" target="_blank">arXiv:2101.09585</a> [<a href="http://arxiv.org/pdf/2101.09585" target="_blank">pdf</a>]

<h2>3D Underactuated Bipedal Walking via H-LIP based Gait Synthesis and Stepping Stabilization. (arXiv:2101.09588v1 [cs.RO])</h2>
<h3>Xiaobin Xiong, Aaron Ames</h3>
<p>In this paper, we present a Hybrid-Linear Inverted Pendulum (H-LIP) based
approach for synthesizing and stabilizing 3D underactuated bipedal walking. The
H-LIP model is proposed to capture the essential components of the
underactuated part and actuated part of the robotic walking. The walking gait
of the robot is then synthesized based on the H-LIP. We comprehensively
characterize the periodic orbits of the H-LIP and provably derive their
stepping stabilization. The step-to-step (S2S) dynamics of the H-LIP is then
utilized to approximate the S2S dynamics of the horizontal state of the center
of mass (COM) of the robotic walking, which results in a H-LIP based stepping
controller to provide desired step sizes to stabilize the robotic walking. By
realizing the desired step sizes, the robot achieves dynamic and stable
walking. The approach is evaluated in both simulation and experiment on the 3D
underactuated bipedal robot Cassie, which demonstrate dynamic walking behaviors
with both versatility and robustness.
</p>
<a href="http://arxiv.org/abs/2101.09588" target="_blank">arXiv:2101.09588</a> [<a href="http://arxiv.org/pdf/2101.09588" target="_blank">pdf</a>]

<h2>Generating a Doppelganger Graph: Resembling but Distinct. (arXiv:2101.09593v1 [cs.LG])</h2>
<h3>Yuliang Ji, Ru Huang, Jie Chen, Yuanzhe Xi</h3>
<p>Deep generative models, since their inception, have become increasingly more
capable of generating novel and perceptually realistic signals (e.g., images
and sound waves). With the emergence of deep models for graph structured data,
natural interests seek extensions of these generative models for graphs.
Successful extensions were seen recently in the case of learning from a
collection of graphs (e.g., protein data banks), but the learning from a single
graph has been largely under explored. The latter case, however, is important
in practice. For example, graphs in financial and healthcare systems contain so
much confidential information that their public accessibility is nearly
impossible, but open science in these fields can only advance when similar data
are available for benchmarking.

In this work, we propose an approach to generating a doppelganger graph that
resembles a given one in many graph properties but nonetheless can hardly be
used to reverse engineer the original one, in the sense of a near zero edge
overlap. The approach is an orchestration of graph representation learning,
generative adversarial networks, and graph realization algorithms. Through
comparison with several graph generative models (either parameterized by neural
networks or not), we demonstrate that our result barely reproduces the given
graph but closely matches its properties. We further show that downstream
tasks, such as node classification, on the generated graphs reach similar
performance to the use of the original ones.
</p>
<a href="http://arxiv.org/abs/2101.09593" target="_blank">arXiv:2101.09593</a> [<a href="http://arxiv.org/pdf/2101.09593" target="_blank">pdf</a>]

<h2>Optimistic and Adaptive Lagrangian Hedging. (arXiv:2101.09603v1 [cs.LG])</h2>
<h3>Ryan D&#x27;Orazio, Ruitong Huang</h3>
<p>In online learning an algorithm plays against an environment with losses
possibly picked by an adversary at each round. The generality of this framework
includes problems that are not adversarial, for example offline optimization,
or saddle point problems (i.e. min max optimization). However, online
algorithms are typically not designed to leverage additional structure present
in non-adversarial problems. Recently, slight modifications to well-known
online algorithms such as optimism and adaptive step sizes have been used in
several domains to accelerate online learning -- recovering optimal rates in
offline smooth optimization, and accelerating convergence to saddle points or
social welfare in smooth games. In this work we introduce optimism and adaptive
stepsizes to Lagrangian hedging, a class of online algorithms that includes
regret-matching, and hedge (i.e. multiplicative weights). Our results include:
a general general regret bound; a path length regret bound for a fixed smooth
loss, applicable to an optimistic variant of regret-matching and
regret-matching+; optimistic regret bounds for $\Phi$ regret, a framework that
includes external, internal, and swap regret; and optimistic bounds for a
family of algorithms that includes regret-matching+ as a special case.
</p>
<a href="http://arxiv.org/abs/2101.09603" target="_blank">arXiv:2101.09603</a> [<a href="http://arxiv.org/pdf/2101.09603" target="_blank">pdf</a>]

<h2>Learning degraded image classification with restoration data fidelity. (arXiv:2101.09606v1 [cs.CV])</h2>
<h3>Xiaoyu Lin</h3>
<p>Learning-based methods especially with convolutional neural networks (CNN)
are continuously showing superior performance in computer vision applications,
ranging from image classification to restoration. For image classification,
most existing works focus on very clean images such as images in Caltech-256
and ImageNet datasets. However, in most realistic scenarios, the acquired
images may suffer from degradation. One important and interesting problem is to
combine image classification and restoration tasks to improve the performance
of CNN-based classification networks on degraded images. In this report, we
explore the influence of degradation types and levels on four widely-used
classification networks, and the use of a restoration network to eliminate the
degradation's influence. We also propose a novel method leveraging a fidelity
map to calibrate the image features obtained by pre-trained classification
networks. We empirically demonstrate that our proposed method consistently
outperforms the pre-trained networks under all degradation levels and types
with additive white Gaussian noise (AWGN), and it even outperforms the
re-trained networks for degraded images under low degradation levels. We also
show that the proposed method is a model-agnostic approach that benefits
different classification networks. Our results reveal that the proposed method
is a promising solution to mitigate the effect caused by image degradation.
</p>
<a href="http://arxiv.org/abs/2101.09606" target="_blank">arXiv:2101.09606</a> [<a href="http://arxiv.org/pdf/2101.09606" target="_blank">pdf</a>]

<h2>On the Proof of Global Convergence of Gradient Descent for Deep ReLU Networks with Linear Widths. (arXiv:2101.09612v1 [cs.LG])</h2>
<h3>Quynh Nguyen</h3>
<p>This paper studies the global convergence of gradient descent for deep ReLU
networks under the square loss. For this setting, the current state-of-the-art
results show that gradient descent converges to a global optimum if the widths
of all the hidden layers scale at least as $\Omega(N^8)$ ($N$ being the number
of training samples). In this paper, we discuss a simple proof framework which
allows us to improve the existing over-parameterization condition to linear,
quadratic and cubic widths (depending on the type of initialization scheme
and/or the depth of the network).
</p>
<a href="http://arxiv.org/abs/2101.09612" target="_blank">arXiv:2101.09612</a> [<a href="http://arxiv.org/pdf/2101.09612" target="_blank">pdf</a>]

<h2>A Comprehensive Evaluation Framework for Deep Model Robustness. (arXiv:2101.09617v1 [cs.CV])</h2>
<h3>Aishan Liu, Xianglong Liu, Jun Guo, Jiakai Wang, Yuqing Ma, Ze Zhao, Xinghai Gao, Gang Xiao</h3>
<p>Deep neural networks (DNNs) have achieved remarkable performance across a
wide area of applications. However, they are vulnerable to adversarial
examples, which motivates the adversarial defense. By adopting simple
evaluation metrics, most of the current defenses only conduct incomplete
evaluations, which are far from providing comprehensive understandings of the
limitations of these defenses. Thus, most proposed defenses are quickly shown
to be attacked successfully, which result in the "arm race" phenomenon between
attack and defense. To mitigate this problem, we establish a model robustness
evaluation framework containing a comprehensive, rigorous, and coherent set of
evaluation metrics, which could fully evaluate model robustness and provide
deep insights into building robust models. With 23 evaluation metrics in total,
our framework primarily focuses on the two key factors of adversarial learning
(\ie, data and model). Through neuron coverage and data imperceptibility, we
use data-oriented metrics to measure the integrity of test examples; by delving
into model structure and behavior, we exploit model-oriented metrics to further
evaluate robustness in the adversarial setting. To fully demonstrate the
effectiveness of our framework, we conduct large-scale experiments on multiple
datasets including CIFAR-10 and SVHN using different models and defenses with
our open-source platform AISafety. Overall, our paper aims to provide a
comprehensive evaluation framework which could demonstrate detailed inspections
of the model robustness, and we hope that our paper can inspire further
improvement to the model robustness.
</p>
<a href="http://arxiv.org/abs/2101.09617" target="_blank">arXiv:2101.09617</a> [<a href="http://arxiv.org/pdf/2101.09617" target="_blank">pdf</a>]

<h2>DenseNet for Breast Tumor Classification in Mammographic Images. (arXiv:2101.09637v1 [cs.CV])</h2>
<h3>Yuliana Jim&#xe9;nez Gaona, Mar&#xed;a Jos&#xe9; Rodriguez-Alvarez, Hector Espin&#xf3; Morat&#xf3;, Darwin Castillo Malla, Vasudevan Lakshminarayanan</h3>
<p>Breast cancer is the most common invasive cancer in women, and the second
main cause of death. Breast cancer screening is an efficient method to detect
indeterminate breast lesions early. The common approaches of screening for
women are tomosynthesis and mammography images. However, the traditional manual
diagnosis requires an intense workload by pathologists, who are prone to
diagnostic errors. Thus, the aim of this study is to build a deep convolutional
neural network method for automatic detection, segmentation, and classification
of breast lesions in mammography images. Based on deep learning the Mask-CNN
(RoIAlign) method was developed to features selection and extraction; and the
classification was carried out by DenseNet architecture. Finally, the precision
and accuracy of the model is evaluated by cross validation matrix and AUC
curve. To summarize, the findings of this study may provide a helpful to
improve the diagnosis and efficiency in the automatic tumor localization
through the medical image classification.
</p>
<a href="http://arxiv.org/abs/2101.09637" target="_blank">arXiv:2101.09637</a> [<a href="http://arxiv.org/pdf/2101.09637" target="_blank">pdf</a>]

<h2>FlowReg: Fast Deformable Unsupervised Medical Image Registration using Optical Flow. (arXiv:2101.09639v1 [cs.CV])</h2>
<h3>Sergiu Mocanu, Alan R. Moody, April Khademi</h3>
<p>We propose FlowReg, a deep learning-based framework for unsupervised image
registration for neuroimaging applications. The system is composed of two
architectures that are trained sequentially: FlowReg-A which affinely corrects
for gross differences between moving and fixed volumes in 3D followed by
FlowReg-O which performs pixel-wise deformations on a slice-by-slice basis for
fine tuning in 2D. The affine network regresses the 3D affine matrix based on a
correlation loss function that enforces global similarity. The deformable
network operates on 2D image slices based on the optical flow network
FlowNet-Simple but with three loss components. The photometric loss minimizes
pixel intensity differences differences, the smoothness loss encourages similar
magnitudes between neighbouring vectors, and a correlation loss that is used to
maintain the intensity similarity between fixed and moving image slices. The
proposed method is compared to four open source registration techniques ANTs,
Demons, SE, and Voxelmorph. In total, 4643 FLAIR MR imaging volumes are used
from dementia and vascular disease cohorts, acquired from over 60 international
centres with varying acquisition parameters. A battery of quantitative novel
registration validation metrics are proposed that focus on the structural
integrity of tissues, spatial alignment, and intensity similarity. Experimental
results show FlowReg (FlowReg-A+O) performs better than iterative-based
registration algorithms for intensity and spatial alignment metrics with a
Pixelwise Agreement of 0.65, correlation coefficient of 0.80, and Mutual
Information of 0.29. Among the deep learning frameworks, FlowReg-A or
FlowReg-A+O provided the highest performance over all but one of the metrics.
Results show that FlowReg is able to obtain high intensity and spatial
similarity while maintaining the shape and structure of anatomy and pathology.
</p>
<a href="http://arxiv.org/abs/2101.09639" target="_blank">arXiv:2101.09639</a> [<a href="http://arxiv.org/pdf/2101.09639" target="_blank">pdf</a>]

<h2>OpenGF: An Ultra-Large-Scale Ground Filtering Dataset Built Upon Open ALS Point Clouds Around the World. (arXiv:2101.09641v1 [cs.CV])</h2>
<h3>Nannan Qin, Weikai Tan, Lingfei Ma, Dedong Zhang, Jonathan Li</h3>
<p>Ground filtering has remained a widely studied but incompletely resolved
bottleneck for decades in the automatic generation of high-precision digital
elevation model, due to the dramatic changes of topography and the complex
structures of objects. The recent breakthrough of supervised deep learning
algorithms in 3D scene understanding brings new solutions for better solving
such problems. However, there are few large-scale and scene-rich public
datasets dedicated to ground extraction, which considerably limits the
development of effective deep-learning-based ground filtering methods. To this
end, we present OpenGF, first Ultra-Large-Scale Ground Filtering dataset
covering over 47 $km^2$ of 9 different typical terrain scenes built upon open
ALS point clouds of 4 different countries around the world. OpenGF contains
more than half a billion finely labeled ground and non-ground points, thousands
of times the number of labeled points than the de facto standard ISPRS
filtertest dataset. We extensively evaluate the performance of state-of-the-art
rule-based algorithms and 3D semantic segmentation networks on our dataset and
provide a comprehensive analysis. The results have confirmed the capability of
OpenGF to train deep learning models effectively. This dataset will be released
at https://github.com/Nathan-UW/OpenGF to promote more advancing research for
ground filtering and large-scale 3D geographic environment understanding.
</p>
<a href="http://arxiv.org/abs/2101.09641" target="_blank">arXiv:2101.09641</a> [<a href="http://arxiv.org/pdf/2101.09641" target="_blank">pdf</a>]

<h2>Image Compression with Encoder-Decoder Matched Semantic Segmentation. (arXiv:2101.09642v1 [cs.CV])</h2>
<h3>Trinh Man Hoang, Jinjia Zhou, Yibo Fan</h3>
<p>In recent years, layered image compression is demonstrated to be a promising
direction, which encodes a compact representation of the input image and apply
an up-sampling network to reconstruct the image. To further improve the quality
of the reconstructed image, some works transmit the semantic segment together
with the compressed image data. Consequently, the compression ratio is also
decreased because extra bits are required for transmitting the semantic
segment. To solve this problem, we propose a new layered image compression
framework with encoder-decoder matched semantic segmentation (EDMS). And then,
followed by the semantic segmentation, a special convolution neural network is
used to enhance the inaccurate semantic segment. As a result, the accurate
semantic segment can be obtained in the decoder without requiring extra bits.
The experimental results show that the proposed EDMS framework can get up to
35.31% BD-rate reduction over the HEVC-based (BPG) codec, 5% bitrate, and 24%
encoding time saving compare to the state-of-the-art semantic-based image
codec.
</p>
<a href="http://arxiv.org/abs/2101.09642" target="_blank">arXiv:2101.09642</a> [<a href="http://arxiv.org/pdf/2101.09642" target="_blank">pdf</a>]

<h2>A Dual-branch Network for Infrared and Visible Image Fusion. (arXiv:2101.09643v1 [cs.CV])</h2>
<h3>Yu Fu, Xiao-Jun Wu</h3>
<p>Deep learning is a rapidly developing approach in the field of infrared and
visible image fusion. In this context, the use of dense blocks in deep networks
significantly improves the utilization of shallow information, and the
combination of the Generative Adversarial Network (GAN) also improves the
fusion performance of two source images. We propose a new method based on dense
blocks and GANs , and we directly insert the input image-visible light image in
each layer of the entire network. We use SSIM and gradient loss functions that
are more consistent with perception instead of mean square error loss. After
the adversarial training between the generator and the discriminator, we show
that a trained end-to-end fusion network -- the generator network -- is finally
obtained. Our experiments show that the fused images obtained by our approach
achieve good score based on multiple evaluation indicators. Further, our fused
images have better visual effects in multiple sets of contrasts, which are more
satisfying to human visual perception.
</p>
<a href="http://arxiv.org/abs/2101.09643" target="_blank">arXiv:2101.09643</a> [<a href="http://arxiv.org/pdf/2101.09643" target="_blank">pdf</a>]

<h2>Multi-Task Time Series Forecasting With Shared Attention. (arXiv:2101.09645v1 [cs.LG])</h2>
<h3>Zekai Chen, Jiaze E, Xiao Zhang, Hao Sheng, Xiuzheng Cheng</h3>
<p>Time series forecasting is a key component in many industrial and business
decision processes and recurrent neural network (RNN) based models have
achieved impressive progress on various time series forecasting tasks. However,
most of the existing methods focus on single-task forecasting problems by
learning separately based on limited supervised objectives, which often suffer
from insufficient training instances. As the Transformer architecture and other
attention-based models have demonstrated its great capability of capturing long
term dependency, we propose two self-attention based sharing schemes for
multi-task time series forecasting which can train jointly across multiple
tasks. We augment a sequence of paralleled Transformer encoders with an
external public multi-head attention function, which is updated by all data of
all tasks. Experiments on a number of real-world multi-task time series
forecasting tasks show that our proposed architectures can not only outperform
the state-of-the-art single-task forecasting baselines but also outperform the
RNN-based multi-task forecasting method.
</p>
<a href="http://arxiv.org/abs/2101.09645" target="_blank">arXiv:2101.09645</a> [<a href="http://arxiv.org/pdf/2101.09645" target="_blank">pdf</a>]

<h2>Leveraging Expert Consistency to Improve Algorithmic Decision Support. (arXiv:2101.09648v1 [cs.LG])</h2>
<h3>Maria De-Arteaga, Artur Dubrawski, Alexandra Chouldechova</h3>
<p>Due to their promise of superior predictive power relative to human
assessment, machine learning models are increasingly being used to support
high-stakes decisions. However, the nature of the labels available for training
these models often hampers the usefulness of predictive models for decision
support. In this paper, we explore the use of historical expert decisions as a
rich--yet imperfect--source of information, and we show that it can be
leveraged to mitigate some of the limitations of learning from observed labels
alone. We consider the problem of estimating expert consistency indirectly when
each case in the data is assessed by a single expert, and propose influence
functions based methodology as a solution to this problem. We then incorporate
the estimated expert consistency into the predictive model meant for decision
support through an approach we term label amalgamation. This allows the machine
learning models to learn from experts in instances where there is expert
consistency, and learn from the observed labels elsewhere. We show how the
proposed approach can help mitigate common challenges of learning from observed
labels alone, reducing the gap between the construct that the algorithm
optimizes for and the construct of interest to experts. After providing
intuition and theoretical results, we present empirical results in the context
of child maltreatment hotline screenings. Here, we find that (1) there are
high-risk cases whose risk is considered by the experts but not wholly captured
in the target labels used to train a deployed model, and (2) the proposed
approach improves recall for these cases.
</p>
<a href="http://arxiv.org/abs/2101.09648" target="_blank">arXiv:2101.09648</a> [<a href="http://arxiv.org/pdf/2101.09648" target="_blank">pdf</a>]

<h2>GST: Group-Sparse Training for Accelerating Deep Reinforcement Learning. (arXiv:2101.09650v1 [cs.LG])</h2>
<h3>Juhyoung Lee, Sangyeob Kim, Sangjin Kim, Wooyoung Jo, Hoi-Jun Yoo</h3>
<p>Deep reinforcement learning (DRL) has shown remarkable success in sequential
decision-making problems but suffers from a long training time to obtain such
good performance. Many parallel and distributed DRL training approaches have
been proposed to solve this problem, but it is difficult to utilize them on
resource-limited devices. In order to accelerate DRL in real-world edge
devices, memory bandwidth bottlenecks due to large weight transactions have to
be resolved. However, previous iterative pruning not only shows a low
compression ratio at the beginning of training but also makes DRL training
unstable. To overcome these shortcomings, we propose a novel weight compression
method for DRL training acceleration, named group-sparse training (GST). GST
selectively utilizes block-circulant compression to maintain a high weight
compression ratio during all iterations of DRL training and dynamically adapt
target sparsity through reward-aware pruning for stable training. Thanks to the
features, GST achieves a 25 \%p $\sim$ 41.5 \%p higher average compression
ratio than the iterative pruning method without reward drop in Mujoco
Halfcheetah-v2 and Mujoco humanoid-v2 environment with TD3 training.
</p>
<a href="http://arxiv.org/abs/2101.09650" target="_blank">arXiv:2101.09650</a> [<a href="http://arxiv.org/pdf/2101.09650" target="_blank">pdf</a>]

<h2>VIO-Aided Structure from Motion Under Challenging Environments. (arXiv:2101.09657v1 [cs.CV])</h2>
<h3>Zijie Jiang, Hajime Taira, Naoyuki Miyashita, Masatoshi Okutomi</h3>
<p>In this paper, we present a robust and efficient Structure from Motion
pipeline for accurate 3D reconstruction under challenging environments by
leveraging the camera pose information from a visual-inertial odometry.
Specifically, we propose a geometric verification method to filter out
mismatches by considering the prior geometric configuration of candidate image
pairs. Furthermore, we introduce an efficient and scalable reconstruction
approach that relies on batched image registration and robust bundle
adjustment, both leveraging the reliable local odometry estimation. Extensive
experimental results show that our pipeline performs better than the
state-of-the-art SfM approaches in terms of reconstruction accuracy and
robustness for challenging sequential image collections.
</p>
<a href="http://arxiv.org/abs/2101.09657" target="_blank">arXiv:2101.09657</a> [<a href="http://arxiv.org/pdf/2101.09657" target="_blank">pdf</a>]

<h2>Computational Intelligence Approach to Improve the Classification Accuracy of Brain Neoplasm in MRI Data. (arXiv:2101.09658v1 [cs.CV])</h2>
<h3>Nilanjan Sinhababu, Monalisa Sarma, Debasis Samanta</h3>
<p>Automatic detection of brain neoplasm in Magnetic Resonance Imaging (MRI) is
gaining importance in many medical diagnostic applications. This report
presents two improvements for brain neoplasm detection in MRI data: an advanced
preprocessing technique is proposed to improve the area of interest in MRI data
and a hybrid technique using Convolutional Neural Network (CNN) for feature
extraction followed by Support Vector Machine (SVM) for classification. The
learning algorithm for SVM is modified with the addition of cost function to
minimize false positive prediction addressing the errors in MRI data diagnosis.
The proposed approach can effectively detect the presence of neoplasm and also
predict whether it is cancerous (malignant) or non-cancerous (benign). To check
the effectiveness of the proposed preprocessing technique, it is inspected
visually and evaluated using training performance metrics. A comparison study
between the proposed classification technique and the existing techniques was
performed. The result showed that the proposed approach outperformed in terms
of accuracy and can handle errors in classification better than the existing
approaches.
</p>
<a href="http://arxiv.org/abs/2101.09658" target="_blank">arXiv:2101.09658</a> [<a href="http://arxiv.org/pdf/2101.09658" target="_blank">pdf</a>]

<h2>Grad-CAM guided channel-spatial attention module for fine-grained visual classification. (arXiv:2101.09666v1 [cs.CV])</h2>
<h3>Shuai Xu, Dongliang Chang, Jiyang Xie, Zhanyu Ma</h3>
<p>Fine-grained visual classification (FGVC) is becoming an important research
field, due to its wide applications and the rapid development of computer
vision technologies. The current state-of-the-art (SOTA) methods in the FGVC
usually employ attention mechanisms to first capture the semantic parts and
then discover their subtle differences between distinct classes. The
channel-spatial attention mechanisms, which focus on the discriminative
channels and regions simultaneously, have significantly improved the
classification performance. However, the existing attention modules are poorly
guided since part-based detectors in the FGVC depend on the network learning
ability without the supervision of part annotations. As obtaining such part
annotations is labor-intensive, some visual localization and explanation
methods, such as gradient-weighted class activation mapping (Grad-CAM), can be
utilized for supervising the attention mechanism. We propose a Grad-CAM guided
channel-spatial attention module for the FGVC, which employs the Grad-CAM to
supervise and constrain the attention weights by generating the coarse
localization maps. To demonstrate the effectiveness of the proposed method, we
conduct comprehensive experiments on three popular FGVC datasets, including
CUB-$200$-$2011$, Stanford Cars, and FGVC-Aircraft datasets. The proposed
method outperforms the SOTA attention modules in the FGVC task. In addition,
visualizations of feature maps also demonstrate the superiority of the proposed
method against the SOTA approaches.
</p>
<a href="http://arxiv.org/abs/2101.09666" target="_blank">arXiv:2101.09666</a> [<a href="http://arxiv.org/pdf/2101.09666" target="_blank">pdf</a>]

<h2>Pruning and Quantization for Deep Neural Network Acceleration: A Survey. (arXiv:2101.09671v1 [cs.CV])</h2>
<h3>Tailin Liang, John Glossner, Lei Wang, Shaobo Shi</h3>
<p>Deep neural networks have been applied in many applications exhibiting
extraordinary abilities in the field of computer vision. However, complex
network architectures challenge efficient real-time deployment and require
significant computation resources and energy costs. These challenges can be
overcome through optimizations such as network compression. This paper provides
a survey on two types of network compression: pruning and quantization. We
compare current techniques, analyze their strengths and weaknesses, provide
guidance for compressing networks, and discuss possible future compression
techniques.
</p>
<a href="http://arxiv.org/abs/2101.09671" target="_blank">arXiv:2101.09671</a> [<a href="http://arxiv.org/pdf/2101.09671" target="_blank">pdf</a>]

<h2>Exploitation of Image Statistics with Sparse Coding in the Case of Stereo Vision. (arXiv:2101.09710v1 [cs.CV])</h2>
<h3>Gerrit A. Ecke, Harald M. Papp, Hanspeter A. Mallot</h3>
<p>The sparse coding algorithm has served as a model for early processing in
mammalian vision. It has been assumed that the brain uses sparse coding to
exploit statistical properties of the sensory stream. We hypothesize that
sparse coding discovers patterns from the data set, which can be used to
estimate a set of stimulus parameters by simple readout. In this study, we
chose a model of stereo vision to test our hypothesis. We used the Locally
Competitive Algorithm (LCA), followed by a na\"ive Bayes classifier, to infer
stereo disparity. From the results we report three observations. First,
disparity inference was successful with this naturalistic processing pipeline.
Second, an expanded, highly redundant representation is required to robustly
identify the input patterns. Third, the inference error can be predicted from
the number of active coefficients in the LCA representation. We conclude that
sparse coding can generate a suitable general representation for subsequent
inference tasks. Keywords: Sparse coding; Locally Competitive Algorithm (LCA);
Efficient coding; Compact code; Probabilistic inference; Stereo vision
</p>
<a href="http://arxiv.org/abs/2101.09710" target="_blank">arXiv:2101.09710</a> [<a href="http://arxiv.org/pdf/2101.09710" target="_blank">pdf</a>]

<h2>Learning Synthetic Environments for Reinforcement Learning with Evolution Strategies. (arXiv:2101.09721v1 [cs.LG])</h2>
<h3>Fabio Ferreira, Thomas Nierhoff, Frank Hutter</h3>
<p>This work explores learning agent-agnostic synthetic environments (SEs) for
Reinforcement Learning. SEs act as a proxy for target environments and allow
agents to be trained more efficiently than when directly trained on the target
environment. We formulate this as a bi-level optimization problem and represent
an SE as a neural network. By using Natural Evolution Strategies and a
population of SE parameter vectors, we train agents in the inner loop on
evolving SEs while in the outer loop we use the performance on the target task
as a score for meta-updating the SE population. We show empirically that our
method is capable of learning SEs for two discrete-action-space tasks
(CartPole-v0 and Acrobot-v1) that allow us to train agents more robustly and
with up to 60% fewer steps. Not only do we show in experiments with 4000
evaluations that the SEs are robust against hyperparameter changes such as the
learning rate, batch sizes and network sizes, we also show that SEs trained
with DDQN agents transfer in limited ways to a discrete-action-space version of
TD3 and very well to Dueling DDQN.
</p>
<a href="http://arxiv.org/abs/2101.09721" target="_blank">arXiv:2101.09721</a> [<a href="http://arxiv.org/pdf/2101.09721" target="_blank">pdf</a>]

<h2>Improving Continuous-time Conflict Based Search. (arXiv:2101.09723v1 [cs.AI])</h2>
<h3>Anton Andreychuk, Konstantin Yakovlev, Eli Boyarski, Roni Stern</h3>
<p>Conflict-Based Search (CBS) is a powerful algorithmic framework for optimally
solving classical multi-agent path finding (MAPF) problems, where time is
discretized into the time steps. Continuous-time CBS (CCBS) is a recently
proposed version of CBS that guarantees optimal solutions without the need to
discretize time. However, the scalability of CCBS is limited because it does
not include any known improvements of CBS. In this paper, we begin to close
this gap and explore how to adapt successful CBS improvements, namely,
prioritizing conflicts (PC), disjoint splitting (DS), and high-level
heuristics, to the continuous time setting of CCBS. These adaptions are not
trivial, and require careful handling of different types of constraints,
applying a generalized version of the Safe interval path planning (SIPP)
algorithm, and extending the notion of cardinal conflicts. We evaluate the
effect of the suggested enhancements by running experiments both on general
graphs and $2^k$-neighborhood grids. CCBS with these improvements significantly
outperforms vanilla CCBS, solving problems with almost twice as many agents in
some cases and pushing the limits of multiagent path finding in continuous-time
domains.
</p>
<a href="http://arxiv.org/abs/2101.09723" target="_blank">arXiv:2101.09723</a> [<a href="http://arxiv.org/pdf/2101.09723" target="_blank">pdf</a>]

<h2>Classic versus deep approaches to address computer vision challenges. (arXiv:2101.09744v1 [cs.CV])</h2>
<h3>Nati Ofir, Jean-Christophe Nebel</h3>
<p>Computer vision and image processing address many challenging applications.
While the last decade has seen deep neural network architectures
revolutionizing those fields, early methods relied on 'classic', i.e.,
non-learned approaches. In this study, we explore the differences between
classic and deep learning (DL) algorithms to gain new insight regarding which
is more suitable for a given application. The focus is on two challenging
ill-posed problems, namely faint edge detection and multispectral image
registration, studying recent state-of-the-art DL and classic solutions. While
those DL algorithms outperform classic methods in terms of accuracy and
development time, they tend to have higher resource requirements and are unable
to perform outside their training space. Moreover, classic algorithms are more
transparent, which facilitates their adoption for real-life applications. As
both classes of approaches have unique strengths and limitations, the choice of
a solution is clearly application dependent.
</p>
<a href="http://arxiv.org/abs/2101.09744" target="_blank">arXiv:2101.09744</a> [<a href="http://arxiv.org/pdf/2101.09744" target="_blank">pdf</a>]

<h2>Iterative Greedy Matching for 3D Human Pose Tracking from Multiple Views. (arXiv:2101.09745v1 [cs.CV])</h2>
<h3>Julian Tanke, Juergen Gall</h3>
<p>In this work we propose an approach for estimating 3D human poses of multiple
people from a set of calibrated cameras. Estimating 3D human poses from
multiple views has several compelling properties: human poses are estimated
within a global coordinate space and multiple cameras provide an extended field
of view which helps in resolving ambiguities, occlusions and motion blur. Our
approach builds upon a real-time 2D multi-person pose estimation system and
greedily solves the association problem between multiple views. We utilize
bipartite matching to track multiple people over multiple frames. This proofs
to be especially efficient as problems associated with greedy matching such as
occlusion can be easily resolved in 3D. Our approach achieves state-of-the-art
results on popular benchmarks and may serve as a baseline for future work.
</p>
<a href="http://arxiv.org/abs/2101.09745" target="_blank">arXiv:2101.09745</a> [<a href="http://arxiv.org/pdf/2101.09745" target="_blank">pdf</a>]

<h2>Numerical issues in maximum likelihood parameter estimation for Gaussian process regression. (arXiv:2101.09747v1 [stat.ML])</h2>
<h3>Subhasish Basak, S&#xe9;bastien Petit, Julien Bect, Emmanuel Vazquez</h3>
<p>This article focuses on numerical issues in maximum likelihood parameter
estimation for Gaussian process regression (GPR). This article investigates the
origin of the numerical issues and provides simple but effective improvement
strategies. This work targets a basic problem but a host of studies,
particularly in the literature of Bayesian optimization, rely on off-the-shelf
GPR implementations. For the conclusions of these studies to be reliable and
reproducible, robust GPR implementations are critical.
</p>
<a href="http://arxiv.org/abs/2101.09747" target="_blank">arXiv:2101.09747</a> [<a href="http://arxiv.org/pdf/2101.09747" target="_blank">pdf</a>]

<h2>Deployable, Data-Driven Unmanned Vehicle Navigation System in GPS-Denied, Feature-Deficient Environments. (arXiv:2101.09750v1 [cs.RO])</h2>
<h3>Sohum Misra, Kaarthik Sundar, Rajnikant Sharma, Kevin Brink</h3>
<p>This paper presents a novel data-driven navigation system to navigate an
Unmanned Vehicle (UV) in GPS-denied, feature-deficient environments such as
tunnels, or mines. The method utilizes Radio Frequency Identification (RFID)
tags, also referred to as landmarks, as range sensors that are carried by the
vehicle and are deployed in the environment to enable localization as the
vehicle traverses its pre-defined path through the tunnel. A key question that
arises in such scenario is to estimate and reduce the number of landmarks
required for localization before the start of the mission, given some
information about the environment. The main constraint of the problem is to
keep the maximum uncertainty in the position estimate near a desired value. In
this article, we combine techniques from estimation, machine learning, and
mixed-integer convex optimization to develop a systematic method to perform
localization and navigate the UV through the environment while ensuring minimum
number of landmarks are used and all the mission constraints are satisfied.
</p>
<a href="http://arxiv.org/abs/2101.09750" target="_blank">arXiv:2101.09750</a> [<a href="http://arxiv.org/pdf/2101.09750" target="_blank">pdf</a>]

<h2>Entropy Partial Transport with Tree Metrics: Theory and Practice. (arXiv:2101.09756v1 [stat.ML])</h2>
<h3>Tam Le, Truyen Nguyen</h3>
<p>Optimal transport (OT) theory provides powerful tools to compare probability
measures. However, OT is limited to nonnegative measures having the same mass,
and suffers serious drawbacks about its computation and statistics. This leads
to several proposals of regularized variants of OT in the recent literature. In
this work, we consider an \textit{entropy partial transport} (EPT) problem for
nonnegative measures on a tree having different masses. The EPT is shown to be
equivalent to a standard complete OT problem on a one-node extended tree. We
derive its dual formulation, then leverage this to propose a novel
regularization for EPT which admits fast computation and negative definiteness.
To our knowledge, the proposed regularized EPT is the first approach that
yields a \textit{closed-form} solution among available variants of unbalanced
OT. For practical applications without priori knowledge about the tree
structure for measures, we propose tree-sliced variants of the regularized EPT,
computed by averaging the regularized EPT between these measures using random
tree metrics, built adaptively from support data points. Exploiting the
negative definiteness of our regularized EPT, we introduce a positive definite
kernel, and evaluate it against other baselines on benchmark tasks such as
document classification with word embedding and topological data analysis. In
addition, we empirically demonstrate that our regularization also provides
effective approximations.
</p>
<a href="http://arxiv.org/abs/2101.09756" target="_blank">arXiv:2101.09756</a> [<a href="http://arxiv.org/pdf/2101.09756" target="_blank">pdf</a>]

<h2>Analysing the Noise Model Error for Realistic Noisy Label Data. (arXiv:2101.09763v1 [cs.LG])</h2>
<h3>Michael A. Hedderich, Dawei Zhu, Dietrich Klakow</h3>
<p>Distant and weak supervision allow to obtain large amounts of labeled
training data quickly and cheaply, but these automatic annotations tend to
contain a high amount of errors. A popular technique to overcome the negative
effects of these noisy labels is noise modelling where the underlying noise
process is modelled. In this work, we study the quality of these estimated
noise models from the theoretical side by deriving the expected error of the
noise model. Apart from evaluating the theoretical results on commonly used
synthetic noise, we also publish NoisyNER, a new noisy label dataset from the
NLP domain that was obtained through a realistic distant supervision technique.
It provides seven sets of labels with differing noise patterns to evaluate
different noise levels on the same instances. Parallel, clean labels are
available making it possible to study scenarios where a small amount of
gold-standard data can be leveraged. Our theoretical results and the
corresponding experiments give insights into the factors that influence the
noise model estimation like the noise distribution and the sampling technique.
</p>
<a href="http://arxiv.org/abs/2101.09763" target="_blank">arXiv:2101.09763</a> [<a href="http://arxiv.org/pdf/2101.09763" target="_blank">pdf</a>]

<h2>Fighting deepfakes by detecting GAN DCT anomalies. (arXiv:2101.09781v1 [cs.CV])</h2>
<h3>Oliver Giudice (1), Luca Guarnera (1 and 2), Sebastiano Battiato (1 and 2) ((1) University of Catania, (2) iCTLab s.r.l. - Spin-off of University of Catania)</h3>
<p>Synthetic multimedia content created through AI technologies, such as
Generative Adversarial Networks (GAN), applied to human faces can brings
serious social and political consequences in the private life of every person.
State-of-the-art algorithms use deep neural networks to detect a fake content
but unfortunately almost all approaches appear to be neither generalizable nor
explainable. A new fast detection method able to discriminate Deepfake images
with blazing speed and high precision is exposed. By employing Discrete Cosine
Transform (DCT) transform, anomalous frequencies in real and Deepfake datasets
were analyzed. The \beta statistics inferred by the AC coefficients
distribution have been the key to recognize GAN-engine generated data. The
technique has been validated on pristine high quality faces synthesized by
different GANs architectures. Experiments carried out show that the method is
innovative, exceeds the state-of-the-art and also gives many insights in terms
of explainability
</p>
<a href="http://arxiv.org/abs/2101.09781" target="_blank">arXiv:2101.09781</a> [<a href="http://arxiv.org/pdf/2101.09781" target="_blank">pdf</a>]

<h2>A Joint Representation Learning and Feature Modeling Approach for One-class Recognition. (arXiv:2101.09782v1 [cs.CV])</h2>
<h3>Pramuditha Perera, Vishal Patel</h3>
<p>One-class recognition is traditionally approached either as a representation
learning problem or a feature modeling problem. In this work, we argue that
both of these approaches have their own limitations; and a more effective
solution can be obtained by combining the two. The proposed approach is based
on the combination of a generative framework and a one-class classification
method. First, we learn generative features using the one-class data with a
generative framework. We augment the learned features with the corresponding
reconstruction errors to obtain augmented features. Then, we qualitatively
identify a suitable feature distribution that reduces the redundancy in the
chosen classifier space. Finally, we force the augmented features to take the
form of this distribution using an adversarial framework. We test the
effectiveness of the proposed method on three one-class classification tasks
and obtain state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/2101.09782" target="_blank">arXiv:2101.09782</a> [<a href="http://arxiv.org/pdf/2101.09782" target="_blank">pdf</a>]

<h2>Context-Specific Likelihood Weighting. (arXiv:2101.09791v1 [cs.AI])</h2>
<h3>Nitesh Kumar, Ond&#x159;ej Ku&#x17e;elka</h3>
<p>Sampling is a popular method for approximate inference when exact inference
is impractical. Generally, sampling algorithms do not exploit context-specific
independence (CSI) properties of probability distributions. We introduce
context-specific likelihood weighting (CS-LW), a new sampling methodology,
which besides exploiting the classical conditional independence properties,
also exploits context-specific independence (CSI) properties. Unlike the
standard likelihood weighting, CS-LW is based on partial assignments of random
variables and requires fewer samples for convergence due to the sampling
variance reduction. Furthermore, the speed of generating samples increases. Our
novel notion of contextual assignments theoretically justifies CS-LW. We
empirically show that CS-LW is competitive with state-of-the-art algorithms for
approximate inference in the presence of a significant amount of CSIs.
</p>
<a href="http://arxiv.org/abs/2101.09791" target="_blank">arXiv:2101.09791</a> [<a href="http://arxiv.org/pdf/2101.09791" target="_blank">pdf</a>]

<h2>cGANs for Cartoon to Real-life Images. (arXiv:2101.09793v1 [cs.CV])</h2>
<h3>Pranjal Singh Rajput, Kanya Satis, Sonnya Dellarosa, Wenxuan Huang, Obinna Agba</h3>
<p>The image-to-image translation is a learning task to establish a visual
mapping between an input and output image. The task has several variations
differentiated based on the purpose of the translation, such as synthetic to
real translation, photo to caricature translation, and many others. The problem
has been tackled using different approaches, either through traditional
computer vision methods, as well as deep learning approaches in recent trends.
One approach currently deemed popular and effective is using the conditional
generative adversarial network, also known shortly as cGAN. It is adapted to
perform image-to-image translation tasks with typically two networks: a
generator and a discriminator. This project aims to evaluate the robustness of
the Pix2Pix model by applying the Pix2Pix model to datasets consisting of
cartoonized images. Using the Pix2Pix model, it should be possible to train the
network to generate real-life images from the cartoonized images.
</p>
<a href="http://arxiv.org/abs/2101.09793" target="_blank">arXiv:2101.09793</a> [<a href="http://arxiv.org/pdf/2101.09793" target="_blank">pdf</a>]

<h2>Exploring ensembles and uncertainty minimization in denoising networks. (arXiv:2101.09798v1 [cs.CV])</h2>
<h3>Xiaoqi Ma</h3>
<p>The development of neural networks has greatly improved the performance in
various computer vision tasks. In the filed of image denoising, convolutional
neural network based methods such as DnCNN break through the limits of
classical methods, achieving better quantitative results. However, the
epistemic uncertainty existing in neural networks limits further improvements
in their performance over denoising tasks. Therefore, we develop and study
different solutions to minimize uncertainty and further improve the removal of
noise. From the perspective of ensemble learning, we implement manipulations to
noisy images from the point of view of spatial and frequency domains and then
denoise them using pre-trained denoising networks. We propose a fusion model
consisting of two attention modules, which focus on assigning the proper
weights to pixels and channels. The experimental results show that our model
achieves better performance on top of the baseline of regular pre-trained
denoising networks.
</p>
<a href="http://arxiv.org/abs/2101.09798" target="_blank">arXiv:2101.09798</a> [<a href="http://arxiv.org/pdf/2101.09798" target="_blank">pdf</a>]

<h2>Analytical Characterization and Design Space Exploration for Optimization of CNNs. (arXiv:2101.09808v1 [cs.LG])</h2>
<h3>Rui Li, Yufan Xu, Aravind Sukumaran-Rajam, Atanas Rountev, P. Sadayappan</h3>
<p>Moving data through the memory hierarchy is a fundamental bottleneck that can
limit the performance of core algorithms of machine learning, such as
convolutional neural networks (CNNs). Loop-level optimization, including loop
tiling and loop permutation, are fundamental transformations to reduce data
movement. However, the search space for finding the best loop-level
optimization configuration is explosively large. This paper develops an
analytical modeling approach for finding the best loop-level optimization
configuration for CNNs on multi-core CPUs. Experimental evaluation shows that
this approach achieves comparable or better performance than state-of-the-art
libraries and auto-tuning based optimizers for CNNs.
</p>
<a href="http://arxiv.org/abs/2101.09808" target="_blank">arXiv:2101.09808</a> [<a href="http://arxiv.org/pdf/2101.09808" target="_blank">pdf</a>]

<h2>NeurT-FDR: Controlling FDR by Incorporating Feature Hierarchy. (arXiv:2101.09809v1 [stat.ML])</h2>
<h3>Lin Qiu, Nils Murrugarra-Llerena, V&#xed;tor Silva, Lin Lin, Vernon M. Chinchilli</h3>
<p>Controlling false discovery rate (FDR) while leveraging the side information
of multiple hypothesis testing is an emerging research topic in modern data
science. Existing methods rely on the test-level covariates while ignoring
possible hierarchy among the covariates. This strategy may not be optimal for
complex large-scale problems, where hierarchical information often exists among
those test-level covariates. We propose NeurT-FDR which boosts statistical
power and controls FDR for multiple hypothesis testing while leveraging the
hierarchy among test-level covariates. Our method parametrizes the test-level
covariates as a neural network and adjusts the feature hierarchy through a
regression framework, which enables flexible handling of high-dimensional
features as well as efficient end-to-end optimization. We show that NeurT-FDR
has strong FDR guarantees and makes substantially more discoveries in synthetic
and real datasets compared to competitive baselines.
</p>
<a href="http://arxiv.org/abs/2101.09809" target="_blank">arXiv:2101.09809</a> [<a href="http://arxiv.org/pdf/2101.09809" target="_blank">pdf</a>]

<h2>Annealed Stein Variational Gradient Descent. (arXiv:2101.09815v1 [cs.LG])</h2>
<h3>Francesco D&#x27;Angelo, Vincent Fortuin</h3>
<p>Particle based optimization algorithms have recently been developed as
sampling methods that iteratively update a set of particles to approximate a
target distribution. In particular Stein variational gradient descent has
gained attention in the approximate inference literature for its flexibility
and accuracy. We empirically explore the ability of this method to sample from
multi-modal distributions and focus on two important issues: (i) the inability
of the particles to escape from local modes and (ii) the inefficacy in
reproducing the density of the different regions. We propose an annealing
schedule to solve these issues and show, through various experiments, how this
simple solution leads to significant improvements in mode coverage, without
invalidating any theoretical properties of the original algorithm.
</p>
<a href="http://arxiv.org/abs/2101.09815" target="_blank">arXiv:2101.09815</a> [<a href="http://arxiv.org/pdf/2101.09815" target="_blank">pdf</a>]

<h2>Encrypted Internet traffic classification using a supervised Spiking Neural Network. (arXiv:2101.09818v1 [cs.LG])</h2>
<h3>Ali Rasteh, Florian Delpech, Carlos Aguilar-Melchor, Romain Zimmer, Saeed Bagheri Shouraki, Timoth&#xe9;e Masquelier</h3>
<p>Internet traffic recognition is an essential tool for access providers since
recognizing traffic categories related to different data packets transmitted on
a network help them define adapted priorities. That means, for instance, high
priority requirements for an audio conference and low ones for a file transfer,
to enhance user experience. As internet traffic becomes increasingly encrypted,
the mainstream classic traffic recognition technique, payload inspection, is
rendered ineffective. This paper uses machine learning techniques for encrypted
traffic classification, looking only at packet size and time of arrival.
Spiking neural networks (SNN), largely inspired by how biological neurons
operate, were used for two reasons. Firstly, they are able to recognize
time-related data packet features. Secondly, they can be implemented
efficiently on neuromorphic hardware with a low energy footprint. Here we used
a very simple feedforward SNN, with only one fully-connected hidden layer, and
trained in a supervised manner using the newly introduced method known as
Surrogate Gradient Learning. Surprisingly, such a simple SNN reached an
accuracy of 95.9% on ISCX datasets, outperforming previous approaches. Besides
better accuracy, there is also a very significant improvement on simplicity:
input size, number of neurons, trainable parameters are all reduced by one to
four orders of magnitude. Next, we analyzed the reasons for this good accuracy.
It turns out that, beyond spatial (i.e. packet size) features, the SNN also
exploits temporal ones, mostly the nearly synchronous (within a 200ms range)
arrival times of packets with certain sizes. Taken together, these results show
that SNNs are an excellent fit for encrypted internet traffic classification:
they can be more accurate than conventional artificial neural networks (ANN),
and they could be implemented efficiently on low power embedded systems.
</p>
<a href="http://arxiv.org/abs/2101.09818" target="_blank">arXiv:2101.09818</a> [<a href="http://arxiv.org/pdf/2101.09818" target="_blank">pdf</a>]

<h2>Meta-Regularization by Enforcing Mutual-Exclusiveness. (arXiv:2101.09819v1 [cs.LG])</h2>
<h3>Edwin Pan, Pankaj Rajak, Shubham Shrivastava</h3>
<p>Meta-learning models have two objectives. First, they need to be able to make
predictions over a range of task distributions while utilizing only a small
amount of training data. Second, they also need to adapt to new novel unseen
tasks at meta-test time again by using only a small amount of training data
from that task. It is the second objective where meta-learning models fail for
non-mutually exclusive tasks due to task overfitting. Given that guaranteeing
mutually exclusive tasks is often difficult, there is a significant need for
regularization methods that can help reduce the impact of task-memorization in
meta-learning. For example, in the case of N-way, K-shot classification
problems, tasks becomes non-mutually exclusive when the labels associated with
each task is fixed. Under this design, the model will simply memorize the class
labels of all the training tasks, and thus will fail to recognize a new task
(class) at meta-test time. A direct observable consequence of this memorization
is that the meta-learning model simply ignores the task-specific training data
in favor of directly classifying based on the test-data input. In our work, we
propose a regularization technique for meta-learning models that gives the
model designer more control over the information flow during meta-training. Our
method consists of a regularization function that is constructed by maximizing
the distance between task-summary statistics, in the case of black-box models
and task specific network parameters in the case of optimization based models
during meta-training. Our proposed regularization function shows an accuracy
boost of $\sim$ $36\%$ on the Omniglot dataset for 5-way, 1-shot classification
using black-box method and for 20-way, 1-shot classification problem using
optimization-based method.
</p>
<a href="http://arxiv.org/abs/2101.09819" target="_blank">arXiv:2101.09819</a> [<a href="http://arxiv.org/pdf/2101.09819" target="_blank">pdf</a>]

<h2>Improving Few-Shot Learning with Auxiliary Self-Supervised Pretext Tasks. (arXiv:2101.09825v1 [cs.LG])</h2>
<h3>Nathaniel Simard, Guillaume Lagrange</h3>
<p>Recent work on few-shot learning \cite{tian2020rethinking} showed that
quality of learned representations plays an important role in few-shot
classification performance. On the other hand, the goal of self-supervised
learning is to recover useful semantic information of the data without the use
of class labels. In this work, we exploit the complementarity of both paradigms
via a multi-task framework where we leverage recent self-supervised methods as
auxiliary tasks. We found that combining multiple tasks is often beneficial,
and that solving them simultaneously can be done efficiently. Our results
suggest that self-supervised auxiliary tasks are effective data-dependent
regularizers for representation learning. Our code is available at:
\url{https://github.com/nathanielsimard/improving-fs-ssl}.
</p>
<a href="http://arxiv.org/abs/2101.09825" target="_blank">arXiv:2101.09825</a> [<a href="http://arxiv.org/pdf/2101.09825" target="_blank">pdf</a>]

<h2>ATRM: Attention-based Task-level Relation Module for GNN-based Few-shot Learning. (arXiv:2101.09840v1 [cs.CV])</h2>
<h3>Yurong Guo, Zhanyu Ma, Xiaoxu Li, Yuan Dong</h3>
<p>Recently, graph neural networks (GNNs) have shown powerful ability to handle
few-shot classification problem, which aims at classifying unseen samples when
trained with limited labeled samples per class. GNN-based few-shot learning
architectures mostly replace traditional metric with a learnable GNN. In the
GNN, the nodes are set as the samples embedding, and the relationship between
two connected nodes can be obtained by a network, the input of which is the
difference of their embedding features. We consider this method of measuring
relation of samples only models the sample-to-sample relation, while neglects
the specificity of different tasks. That is, this method of measuring relation
does not take the task-level information into account. To this end, we propose
a new relation measure method, namely the attention-based task-level relation
module (ATRM), to explicitly model the task-level relation of one sample to all
the others. The proposed module captures the relation representations between
nodes by considering the sample-to-task instead of sample-to-sample embedding
features. We conducted extensive experiments on four benchmark datasets:
mini-ImageNet, tiered-ImageNet, CUB-200-2011, and CIFAR-FS. Experimental
results demonstrate that the proposed module is effective for GNN-based
few-shot learning.
</p>
<a href="http://arxiv.org/abs/2101.09840" target="_blank">arXiv:2101.09840</a> [<a href="http://arxiv.org/pdf/2101.09840" target="_blank">pdf</a>]

<h2>High-Confidence Off-Policy (or Counterfactual) Variance Estimation. (arXiv:2101.09847v1 [cs.LG])</h2>
<h3>Yash Chandak, Shiv Shankar, Philip S. Thomas</h3>
<p>Many sequential decision-making systems leverage data collected using prior
policies to propose a new policy. For critical applications, it is important
that high-confidence guarantees on the new policy's behavior are provided
before deployment, to ensure that the policy will behave as desired. Prior
works have studied high-confidence off-policy estimation of the expected
return, however, high-confidence off-policy estimation of the variance of
returns can be equally critical for high-risk applications. In this paper, we
tackle the previously open problem of estimating and bounding, with high
confidence, the variance of returns from off-policy data
</p>
<a href="http://arxiv.org/abs/2101.09847" target="_blank">arXiv:2101.09847</a> [<a href="http://arxiv.org/pdf/2101.09847" target="_blank">pdf</a>]

<h2>Deep Learning Generalization and the Convex Hull of Training Sets. (arXiv:2101.09849v1 [cs.LG])</h2>
<h3>Roozbeh Yousefzadeh</h3>
<p>We study the generalization of deep learning models in relation to the convex
hull of their training sets. A trained image classifier basically partitions
its domain via decision boundaries and assigns a class to each of those
partitions. The location of decision boundaries inside the convex hull of
training set can be investigated in relation to the training samples. However,
our analysis shows that in standard image classification datasets, all testing
images are considerably outside that convex hull, in the pixel space, in the
wavelet space, and in the internal representations learned by deep networks.
Therefore, the performance of a trained model partially depends on how its
decision boundaries are extended outside the convex hull of its training data.
From this perspective which is not studied before, over-parameterization of
deep learning models may be considered a necessity for shaping the extension of
decision boundaries. At the same time, over-parameterization should be
accompanied by a specific training regime, in order to yield a model that not
only fits the training set, but also its decision boundaries extend desirably
outside the convex hull. To illustrate this, we investigate the decision
boundaries of a neural network, with various degrees of parameters, inside and
outside the convex hull of its training set. Moreover, we use a polynomial
decision boundary to study the necessity of over-parameterization and the
influence of training regime in shaping its extensions outside the convex hull
of training set.
</p>
<a href="http://arxiv.org/abs/2101.09849" target="_blank">arXiv:2101.09849</a> [<a href="http://arxiv.org/pdf/2101.09849" target="_blank">pdf</a>]

<h2>Weakly Supervised Learning for Facial Behavior Analysis : A Review. (arXiv:2101.09858v1 [cs.CV])</h2>
<h3>Gnana Praveen R, Eric Granger, Patrick Cardinal</h3>
<p>In the recent years, there has been a shift in facial behavior analysis from
the laboratory-controlled conditions to the challenging in-the-wild conditions
due to the superior performance of deep learning based approaches for many real
world applications.However, the performance of deep learning approaches relies
on the amount of training data. One of the major problems with data acquisition
is the requirement of annotations for large amount of training data. Labeling
process of huge training data demands lot of human support with strong domain
expertise for facial expressions or action units, which is difficult to obtain
in real-time environments.Moreover, labeling process is highly vulnerable to
ambiguity of expressions or action units, especially for intensities due to the
bias induced by the domain experts. Therefore, there is an imperative need to
address the problem of facial behavior analysis with weak annotations. In this
paper, we provide a comprehensive review of weakly supervised learning (WSL)
approaches for facial behavior analysis with both categorical as well as
dimensional labels along with the challenges and potential research directions
associated with it. First, we introduce various types of weak annotations in
the context of facial behavior analysis and the corresponding challenges
associated with it. We then systematically review the existing state-of-the-art
approaches and provide a taxonomy of these approaches along with their insights
and limitations. In addition, widely used data-sets in the reviewed literature
and the performance of these approaches along with evaluation principles are
summarized. Finally, we discuss the remaining challenges and opportunities
along with the potential research directions in order to apply facial behavior
analysis with weak labels in real life situations.
</p>
<a href="http://arxiv.org/abs/2101.09858" target="_blank">arXiv:2101.09858</a> [<a href="http://arxiv.org/pdf/2101.09858" target="_blank">pdf</a>]

<h2>Applications of Deep Learning in Fundus Images: A Review. (arXiv:2101.09864v1 [cs.CV])</h2>
<h3>Tao Li, Wang Bo, Chunyu Hu, Hong Kang, Hanruo Liu, Kai Wang, Huazhu Fu</h3>
<p>The use of fundus images for the early screening of eye diseases is of great
clinical importance. Due to its powerful performance, deep learning is becoming
more and more popular in related applications, such as lesion segmentation,
biomarkers segmentation, disease diagnosis and image synthesis. Therefore, it
is very necessary to summarize the recent developments in deep learning for
fundus images with a review paper. In this review, we introduce 143 application
papers with a carefully designed hierarchy. Moreover, 33 publicly available
datasets are presented. Summaries and analyses are provided for each task.
Finally, limitations common to all tasks are revealed and possible solutions
are given. We will also release and regularly update the state-of-the-art
results and newly-released datasets at https://github.com/nkicsl/Fundus Review
to adapt to the rapid development of this field.
</p>
<a href="http://arxiv.org/abs/2101.09864" target="_blank">arXiv:2101.09864</a> [<a href="http://arxiv.org/pdf/2101.09864" target="_blank">pdf</a>]

<h2>ECOL-R: Encouraging Copying in Novel Object Captioning with Reinforcement Learning. (arXiv:2101.09865v1 [cs.CV])</h2>
<h3>Yufei Wang, Ian D. Wood, Stephen Wan, Mark Johnson</h3>
<p>Novel Object Captioning is a zero-shot Image Captioning task requiring
describing objects not seen in the training captions, but for which information
is available from external object detectors. The key challenge is to select and
describe all salient detected novel objects in the input images. In this paper,
we focus on this challenge and propose the ECOL-R model (Encouraging Copying of
Object Labels with Reinforced Learning), a copy-augmented transformer model
that is encouraged to accurately describe the novel object labels. This is
achieved via a specialised reward function in the SCST reinforcement learning
framework (Rennie et al., 2017) that encourages novel object mentions while
maintaining the caption quality. We further restrict the SCST training to the
images where detected objects are mentioned in reference captions to train the
ECOL-R model. We additionally improve our copy mechanism via Abstract Labels,
which transfer knowledge from known to novel object types, and a Morphological
Selector, which determines the appropriate inflected forms of novel object
labels. The resulting model sets new state-of-the-art on the nocaps (Agrawal et
al., 2019) and held-out COCO (Hendricks et al., 2016) benchmarks.
</p>
<a href="http://arxiv.org/abs/2101.09865" target="_blank">arXiv:2101.09865</a> [<a href="http://arxiv.org/pdf/2101.09865" target="_blank">pdf</a>]

<h2>Supervision by Registration and Triangulation for Landmark Detection. (arXiv:2101.09866v1 [cs.CV])</h2>
<h3>Xuanyi Dong, Yi Yang, Shih-En Wei, Xinshuo Weng, Yaser Sheikh, Shoou-I Yu</h3>
<p>We present Supervision by Registration and Triangulation (SRT), an
unsupervised approach that utilizes unlabeled multi-view video to improve the
accuracy and precision of landmark detectors. Being able to utilize unlabeled
data enables our detectors to learn from massive amounts of unlabeled data
freely available and not be limited by the quality and quantity of manual human
annotations. To utilize unlabeled data, there are two key observations: (1) the
detections of the same landmark in adjacent frames should be coherent with
registration, i.e., optical flow. (2) the detections of the same landmark in
multiple synchronized and geometrically calibrated views should correspond to a
single 3D point, i.e., multi-view consistency. Registration and multi-view
consistency are sources of supervision that do not require manual labeling,
thus it can be leveraged to augment existing training data during detector
training. End-to-end training is made possible by differentiable registration
and 3D triangulation modules. Experiments with 11 datasets and a newly proposed
metric to measure precision demonstrate accuracy and precision improvements in
landmark detection on both images and video. Code is available at
https://github.com/D-X-Y/landmark-detection.
</p>
<a href="http://arxiv.org/abs/2101.09866" target="_blank">arXiv:2101.09866</a> [<a href="http://arxiv.org/pdf/2101.09866" target="_blank">pdf</a>]

<h2>CPT: Efficient Deep Neural Network Training via Cyclic Precision. (arXiv:2101.09868v1 [cs.LG])</h2>
<h3>Yonggan Fu, Han Guo, Meng Li, Xin Yang, Yining Ding, Vikas Chandra, Yingyan Lin</h3>
<p>Low-precision deep neural network (DNN) training has gained tremendous
attention as reducing precision is one of the most effective knobs for boosting
DNNs' training time/energy efficiency. In this paper, we attempt to explore
low-precision training from a new perspective as inspired by recent findings in
understanding DNN training: we conjecture that DNNs' precision might have a
similar effect as the learning rate during DNN training, and advocate dynamic
precision along the training trajectory for further boosting the time/energy
efficiency of DNN training. Specifically, we propose Cyclic Precision Training
(CPT) to cyclically vary the precision between two boundary values which can be
identified using a simple precision range test within the first few training
epochs. Extensive simulations and ablation studies on five datasets and ten
models demonstrate that CPT's effectiveness is consistent across various
models/tasks (including classification and language modeling). Furthermore,
through experiments and visualization we show that CPT helps to (1) converge to
a wider minima with a lower generalization error and (2) reduce training
variance which we believe opens up a new design knob for simultaneously
improving the optimization and efficiency of DNN training. Our codes are
available at: https://github.com/RICE-EIC/CPT.
</p>
<a href="http://arxiv.org/abs/2101.09868" target="_blank">arXiv:2101.09868</a> [<a href="http://arxiv.org/pdf/2101.09868" target="_blank">pdf</a>]

<h2>Joint Denoising and Demosaicking with Green Channel Prior for Real-world Burst Images. (arXiv:2101.09870v1 [cs.CV])</h2>
<h3>Shi Guo, Zhetong Liang, Lei Zhang</h3>
<p>Denoising and demosaicking are essential yet correlated steps to reconstruct
a full color image from the raw color filter array (CFA) data. By learning a
deep convolutional neural network (CNN), significant progress has been achieved
to perform denoising and demosaicking jointly. However, most existing CNN-based
joint denoising and demosaicking (JDD) methods work on a single image while
assuming additive white Gaussian noise, which limits their performance on
real-world applications. In this work, we study the JDD problem for real-world
burst images, namely JDD-B. Considering the fact that the green channel has
twice the sampling rate and better quality than the red and blue channels in
CFA raw data, we propose to use this green channel prior (GCP) to build a
GCP-Net for the JDD-B task. In GCP-Net, the GCP features extracted from green
channels are utilized to guide the feature extraction and feature upsampling of
the whole image. To compensate for the shift between frames, the offset is also
estimated from GCP features to reduce the impact of noise. Our GCP-Net can
preserve more image structures and details than other JDD methods while
removing noise. Experiments on synthetic and real-world noisy images
demonstrate the effectiveness of GCP-Net quantitatively and qualitatively.
</p>
<a href="http://arxiv.org/abs/2101.09870" target="_blank">arXiv:2101.09870</a> [<a href="http://arxiv.org/pdf/2101.09870" target="_blank">pdf</a>]

<h2>Federated Intrusion Detection for IoT with Heterogeneous Cohort Privacy. (arXiv:2101.09878v1 [cs.LG])</h2>
<h3>Ajesh Koyatan Chathoth (1), Abhyuday Jagannatha (2), Stephen Lee (1) ((1) University of Pittsburgh, (2) University of Massachusetts Amherst)</h3>
<p>Internet of Things (IoT) devices are becoming increasingly popular and are
influencing many application domains such as healthcare and transportation.
These devices are used for real-world applications such as sensor monitoring,
real-time control. In this work, we look at differentially private (DP) neural
network (NN) based network intrusion detection systems (NIDS) to detect
intrusion attacks on networks of such IoT devices. Existing NN training
solutions in this domain either ignore privacy considerations or assume that
the privacy requirements are homogeneous across all users. We show that the
performance of existing differentially private stochastic methods degrade for
clients with non-identical data distributions when clients' privacy
requirements are heterogeneous. We define a cohort-based $(\epsilon,\delta)$-DP
framework that models the more practical setting of IoT device cohorts with
non-identical clients and heterogeneous privacy requirements. We propose two
novel continual-learning based DP training methods that are designed to improve
model performance in the aforementioned setting. To the best of our knowledge,
ours is the first system that employs a continual learning-based approach to
handle heterogeneity in client privacy requirements. We evaluate our approach
on real datasets and show that our techniques outperform the baselines. We also
show that our methods are robust to hyperparameter changes. Lastly, we show
that one of our proposed methods can easily adapt to post-hoc relaxations of
client privacy requirements.
</p>
<a href="http://arxiv.org/abs/2101.09878" target="_blank">arXiv:2101.09878</a> [<a href="http://arxiv.org/pdf/2101.09878" target="_blank">pdf</a>]

<h2>Cross Knowledge-based Generative Zero-Shot Learning Approach with Taxonomy Regularization. (arXiv:2101.09892v1 [cs.CV])</h2>
<h3>Cheng Xie, Hongxin Xiang, Ting Zeng, Yun Yang, Beibei Yu, Qing Liu</h3>
<p>Although zero-shot learning (ZSL) has an inferential capability of
recognizing new classes that have never been seen before, it always faces two
fundamental challenges of the cross modality and crossdomain challenges. In
order to alleviate these problems, we develop a generative network-based ZSL
approach equipped with the proposed Cross Knowledge Learning (CKL) scheme and
Taxonomy Regularization (TR). In our approach, the semantic features are taken
as inputs, and the output is the synthesized visual features generated from the
corresponding semantic features. CKL enables more relevant semantic features to
be trained for semantic-to-visual feature embedding in ZSL, while Taxonomy
Regularization (TR) significantly improves the intersections with unseen images
with more generalized visual features generated from generative network.
Extensive experiments on several benchmark datasets (i.e., AwA1, AwA2, CUB, NAB
and aPY) show that our approach is superior to these state-of-the-art methods
in terms of ZSL image classification and retrieval.
</p>
<a href="http://arxiv.org/abs/2101.09892" target="_blank">arXiv:2101.09892</a> [<a href="http://arxiv.org/pdf/2101.09892" target="_blank">pdf</a>]

<h2>Spatio-temporal Data Augmentation for Visual Surveillance. (arXiv:2101.09895v1 [cs.CV])</h2>
<h3>Jae-Yeul Kim, Jong-Eun Ha</h3>
<p>Visual surveillance aims to stably detect a foreground object using a
continuous image acquired from a fixed camera. Recent deep learning methods
based on supervised learning show superior performance compared to classical
background subtraction algorithms. However, there is still a room for
improvement in static foreground, dynamic background, hard shadow, illumination
changes, camouflage, etc. In addition, most of the deep learning-based methods
operates well on environments similar to training. If the testing environments
are different from training ones, their performance degrades. As a result,
additional training on those operating environments is required to ensure a
good performance. Our previous work which uses spatio-temporal input data
consisted of a number of past images, background images and current image
showed promising results in different environments from training, although it
uses a simple U-NET structure. In this paper, we propose a data augmentation
technique suitable for visual surveillance for additional performance
improvement using the same network used in our previous work. In deep learning,
most data augmentation techniques deal with spatial-level data augmentation
techniques for use in image classification and object detection. In this paper,
we propose a new method of data augmentation in the spatio-temporal dimension
suitable for our previous work. Two data augmentation methods of adjusting
background model images and past images are proposed. Through this, it is shown
that performance can be improved in difficult areas such as static foreground
and ghost objects, compared to previous studies. Through quantitative and
qualitative evaluation using SBI, LASIESTA, and our own dataset, we show that
it gives superior performance compared to deep learning-based algorithms and
background subtraction algorithms.
</p>
<a href="http://arxiv.org/abs/2101.09895" target="_blank">arXiv:2101.09895</a> [<a href="http://arxiv.org/pdf/2101.09895" target="_blank">pdf</a>]

<h2>MultiFace: A Generic Training Mechanism for Boosting Face Recognition Performance. (arXiv:2101.09899v1 [cs.CV])</h2>
<h3>Jing Xu, Tszhang Guo, Fan Ye, Zenglin Xu, Kun Bai</h3>
<p>Deep Convolutional Neural Networks (DCNNs) and their variants have been
widely used in large scale face recognition(FR) recently. Existing methods have
achieved good performance on many FR benchmarks. However, most of them suffer
from two major problems. First, these methods converge quite slowly since they
optimize the loss functions in a high-dimensional and sparse Gaussian Sphere.
Second, the high dimensionality of features, despite the powerful descriptive
ability, brings difficulty to the optimization, which may lead to a sub-optimal
local optimum. To address these problems, we propose a simple yet efficient
training mechanism called MultiFace, where we approximate the original
high-dimensional features by the ensemble of low-dimensional features. The
proposed mechanism is also generic and can be easily applied to many advanced
FR models. Moreover, it brings the benefits of good interpretability to FR
models via the clustering effect. In detail, the ensemble of these
low-dimensional features can capture complementary yet discriminative
information, which can increase the intra-class compactness and inter-class
separability. Experimental results show that the proposed mechanism can
accelerate 2-3 times with the softmax loss and 1.2-1.5 times with Arcface or
Cosface, while achieving state-of-the-art performances in several benchmark
datasets. Especially, the significant improvements on large-scale
datasets(e.g., IJB and MageFace) demonstrate the flexibility of our new
training mechanism.
</p>
<a href="http://arxiv.org/abs/2101.09899" target="_blank">arXiv:2101.09899</a> [<a href="http://arxiv.org/pdf/2101.09899" target="_blank">pdf</a>]

<h2>A Two-stage Framework for Compound Figure Separation. (arXiv:2101.09903v1 [cs.CV])</h2>
<h3>Weixin Jiang, Eric Schwenker, Trevor Spreadbury, Nicola Ferrier, Maria K.Y. Chan, Oliver Cossairt</h3>
<p>Scientific literature contains large volumes of complex, unstructured figures
that are compound in nature (i.e. composed of multiple images, graphs, and
drawings). Separation of these compound figures is critical for information
retrieval from these figures. In this paper, we propose a new strategy for
compound figure separation, which decomposes the compound figures into
constituent subfigures while preserving the association between the subfigures
and their respective caption components. We propose a two-stage framework to
address the proposed compound figure separation problem. In particular, the
subfigure label detection module detects all subfigure labels in the first
stage. Then, in the subfigure detection module, the detected subfigure labels
help to detect the subfigures by optimizing the feature selection process and
providing the global layout information as extra features. Extensive
experiments are conducted to validate the effectiveness and superiority of the
proposed framework, which improves the detection precision by 9%.
</p>
<a href="http://arxiv.org/abs/2101.09903" target="_blank">arXiv:2101.09903</a> [<a href="http://arxiv.org/pdf/2101.09903" target="_blank">pdf</a>]

<h2>Weakly Supervised Thoracic Disease Localization via Disease Masks. (arXiv:2101.09915v1 [cs.CV])</h2>
<h3>Hyun-Woo Kim, Hong-Gyu Jung, Seong-Whan Lee</h3>
<p>To enable a deep learning-based system to be used in the medical domain as a
computer-aided diagnosis system, it is essential to not only classify diseases
but also present the locations of the diseases. However, collecting
instance-level annotations for various thoracic diseases is expensive.
Therefore, weakly supervised localization methods have been proposed that use
only image-level annotation. While the previous methods presented the disease
location as the most discriminative part for classification, this causes a deep
network to localize wrong areas for indistinguishable X-ray images. To solve
this issue, we propose a spatial attention method using disease masks that
describe the areas where diseases mainly occur. We then apply the spatial
attention to find the precise disease area by highlighting the highest
probability of disease occurrence. Meanwhile, the various sizes, rotations and
noise in chest X-ray images make generating the disease masks challenging. To
reduce the variation among images, we employ an alignment module to transform
an input X-ray image into a generalized image. Through extensive experiments on
the NIH-Chest X-ray dataset with eight kinds of diseases, we show that the
proposed method results in superior localization performances compared to
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2101.09915" target="_blank">arXiv:2101.09915</a> [<a href="http://arxiv.org/pdf/2101.09915" target="_blank">pdf</a>]

<h2>Generalizing Adversarial Examples by AdaBelief Optimizer. (arXiv:2101.09930v1 [cs.LG])</h2>
<h3>Yixiang Wang, Jiqiang Liu, Xiaolin Chang</h3>
<p>Recent research has proved that deep neural networks (DNNs) are vulnerable to
adversarial examples, the legitimate input added with imperceptible and
well-designed perturbations can fool DNNs easily in the testing stage. However,
most of the existing adversarial attacks are difficult to fool adversarially
trained models. To solve this issue, we propose an AdaBelief iterative Fast
Gradient Sign Method (AB-FGSM) to generalize adversarial examples. By
integrating AdaBelief optimization algorithm to I-FGSM, we believe that the
generalization of adversarial examples will be improved, relying on the strong
generalization of AdaBelief optimizer. To validate the effectiveness and
transferability of adversarial examples generated by our proposed AB-FGSM, we
conduct the white-box and black-box attacks on various single models and
ensemble models. Compared with state-of-the-art attack methods, our proposed
method can generate adversarial examples effectively in the white-box setting,
and the transfer rate is 7%-21% higher than latest attack methods.
</p>
<a href="http://arxiv.org/abs/2101.09930" target="_blank">arXiv:2101.09930</a> [<a href="http://arxiv.org/pdf/2101.09930" target="_blank">pdf</a>]

<h2>From Model-driven to Data-driven: A Survey on Active Deep Learning. (arXiv:2101.09933v1 [cs.LG])</h2>
<h3>Peng Liu, Guojin He, Lei Zhao</h3>
<p>Which samples should be labelled in a large data set is one of the most
important problems for trainingof deep learning. So far, a variety of active
sample selection strategies related to deep learning havebeen proposed in many
literatures. We defined them as Active Deep Learning (ADL) only if
theirpredictor is deep model, where the basic learner is called as predictor
and the labeling schemes iscalled selector. In this survey, three fundamental
factors in selector designation were summarized. Wecategory ADL into
model-driven ADL and data-driven ADL, by whether its selector is model-drivenor
data-driven. The different characteristics of the two major type of ADL were
addressed in indetail respectively. Furthermore, different sub-classes of
data-driven and model-driven ADL are alsosummarized and discussed emphatically.
The advantages and disadvantages between data-driven ADLand model-driven ADL
are thoroughly analyzed. We pointed out that, with the development of
deeplearning, the selector in ADL also is experiencing the stage from
model-driven to data-driven. Finally,we make discussion on ADL about its
uncertainty, explanatory, foundations of cognitive science etc.and survey on
the trend of ADL from model-driven to data-driven.
</p>
<a href="http://arxiv.org/abs/2101.09933" target="_blank">arXiv:2101.09933</a> [<a href="http://arxiv.org/pdf/2101.09933" target="_blank">pdf</a>]

<h2>Robust Flight Control of a Small Unmanned Helicopter. (arXiv:2101.09937v1 [cs.RO])</h2>
<h3>Miaolei He, Jilin He, Xuan-yi Zhou</h3>
<p>This paper addresses the design and application controller for a small-size
unmanned aerial vehicle (UAV). In this work, the main objective is to study the
modeling and attitude controller design for a small size helicopter. Based on a
non-simplified helicopter model, a new robust attitude control law, which is
combined with a nonlinear control method and a model-free method, is proposed
in this paper. Both wind gust and ground effect phenomena conditions are
involved in this experiment and the result on a real helicopter platform
demonstrates the effectiveness of the proposed control algorithm and robustness
of its resultant controller.
</p>
<a href="http://arxiv.org/abs/2101.09937" target="_blank">arXiv:2101.09937</a> [<a href="http://arxiv.org/pdf/2101.09937" target="_blank">pdf</a>]

<h2>Activation Functions in Artificial Neural Networks: A Systematic Overview. (arXiv:2101.09957v1 [cs.LG])</h2>
<h3>Johannes Lederer</h3>
<p>Activation functions shape the outputs of artificial neurons and, therefore,
are integral parts of neural networks in general and deep learning in
particular. Some activation functions, such as logistic and relu, have been
used for many decades. But with deep learning becoming a mainstream research
topic, new activation functions have mushroomed, leading to confusion in both
theory and practice. This paper provides an analytic yet up-to-date overview of
popular activation functions and their properties, which makes it a timely
resource for anyone who studies or applies neural networks.
</p>
<a href="http://arxiv.org/abs/2101.09957" target="_blank">arXiv:2101.09957</a> [<a href="http://arxiv.org/pdf/2101.09957" target="_blank">pdf</a>]

<h2>Scaffolded Gait Learning of a Quadruped Robot with Bayesian Optimization. (arXiv:2101.09961v1 [cs.RO])</h2>
<h3>Keyan Zhai, Chu&#x27;an Li, Andre Rosendo</h3>
<p>During learning trials, systems are exposed to different failure conditions
which may break robotic parts before a safe behavior is discovered. Humans
contour this problem by grounding their learning to a safer structure/control
first and gradually increasing its difficulty. This paper presents the impact
of a similar supports in the learning of a stable gait on a quadruped robot.
Based on the psychological theory of instructional scaffolding, we provide
different support settings to our robot, evaluated with strain gauges, and use
Bayesian Optimization to conduct a parametric search towards a stable Raibert
controller. We perform several experiments to measure the relation between
constant supports and gradually reduced supports during gait learning, and our
results show that a gradually reduced support is capable of creating a more
stable gait than a support at a fixed height. Although gaps between simulation
and reality can lead robots to catastrophic failures, our proposed method
combines speed and safety when learning a new behavior.
</p>
<a href="http://arxiv.org/abs/2101.09961" target="_blank">arXiv:2101.09961</a> [<a href="http://arxiv.org/pdf/2101.09961" target="_blank">pdf</a>]

<h2>Approximating Probability Distributions by ReLU Networks. (arXiv:2101.09973v1 [cs.LG])</h2>
<h3>Manuj Mukherjee, Aslan Tchamkerten, Mansoor Yousefi</h3>
<p>How many neurons are needed to approximate a target probability distribution
using a neural network with a given input distribution and approximation error?
This paper examines this question for the case when the input distribution is
uniform, and the target distribution belongs to the class of histogram
distributions. We obtain a new upper bound on the number of required neurons,
which is strictly better than previously existing upper bounds. The key
ingredient in this improvement is an efficient construction of the neural nets
representing piecewise linear functions. We also obtain a lower bound on the
minimum number of neurons needed to approximate the histogram distributions.
</p>
<a href="http://arxiv.org/abs/2101.09973" target="_blank">arXiv:2101.09973</a> [<a href="http://arxiv.org/pdf/2101.09973" target="_blank">pdf</a>]

<h2>A Unified Joint Maximum Mean Discrepancy for Domain Adaptation. (arXiv:2101.09979v1 [cs.LG])</h2>
<h3>Wei Wang, Baopu Li, Shuhui Yang, Jing Sun, Zhengming Ding, Junyang Chen, Xiao Dong, Zhihui Wang, Haojie Li</h3>
<p>Domain adaptation has received a lot of attention in recent years, and many
algorithms have been proposed with impressive progress. However, it is still
not fully explored concerning the joint probability distribution (P(X, Y))
distance for this problem, since its empirical estimation derived from the
maximum mean discrepancy (joint maximum mean discrepancy, JMMD) will involve
complex tensor-product operator that is hard to manipulate. To solve this
issue, this paper theoretically derives a unified form of JMMD that is easy to
optimize, and proves that the marginal, class conditional and weighted class
conditional probability distribution distances are our special cases with
different label kernels, among which the weighted class conditional one not
only can realize feature alignment across domains in the category level, but
also deal with imbalance dataset using the class prior probabilities. From the
revealed unified JMMD, we illustrate that JMMD degrades the feature-label
dependence (discriminability) that benefits to classification, and it is
sensitive to the label distribution shift when the label kernel is the weighted
class conditional one. Therefore, we leverage Hilbert Schmidt independence
criterion and propose a novel MMD matrix to promote the dependence, and devise
a novel label kernel that is robust to label distribution shift. Finally, we
conduct extensive experiments on several cross-domain datasets to demonstrate
the validity and effectiveness of the revealed theoretical results.
</p>
<a href="http://arxiv.org/abs/2101.09979" target="_blank">arXiv:2101.09979</a> [<a href="http://arxiv.org/pdf/2101.09979" target="_blank">pdf</a>]

<h2>Adversarial Text-to-Image Synthesis: A Review. (arXiv:2101.09983v1 [cs.CV])</h2>
<h3>Stanislav Frolov, Tobias Hinz, Federico Raue, J&#xf6;rn Hees, Andreas Dengel</h3>
<p>With the advent of generative adversarial networks, synthesizing images from
textual descriptions has recently become an active research area. It is a
flexible and intuitive way for conditional image generation with significant
progress in the last years regarding visual realism, diversity, and semantic
alignment. However, the field still faces several challenges that require
further research efforts such as enabling the generation of high-resolution
images with multiple objects, and developing suitable and reliable evaluation
metrics that correlate with human judgement. In this review, we contextualize
the state of the art of adversarial text-to-image synthesis models, their
development since their inception five years ago, and propose a taxonomy based
on the level of supervision. We critically examine current strategies to
evaluate text-to-image synthesis models, highlight shortcomings, and identify
new areas of research, ranging from the development of better datasets and
evaluation metrics to possible improvements in architectural design and model
training. This review complements previous surveys on generative adversarial
networks with a focus on text-to-image synthesis which we believe will help
researchers to further advance the field.
</p>
<a href="http://arxiv.org/abs/2101.09983" target="_blank">arXiv:2101.09983</a> [<a href="http://arxiv.org/pdf/2101.09983" target="_blank">pdf</a>]

<h2>Multi-view Integration Learning for Irregularly-sampled Clinical Time Series. (arXiv:2101.09986v1 [cs.LG])</h2>
<h3>Yurim Lee, Eunji Jun, Heung-Il Suk</h3>
<p>Electronic health record (EHR) data is sparse and irregular as it is recorded
at irregular time intervals, and different clinical variables are measured at
each observation point. In this work, we propose a multi-view features
integration learning from irregular multivariate time series data by
self-attention mechanism in an imputation-free manner. Specifically, we devise
a novel multi-integration attention module (MIAM) to extract complex
information inherent in irregular time series data. In particular, we
explicitly learn the relationships among the observed values, missing
indicators, and time interval between the consecutive observations,
simultaneously. The rationale behind our approach is the use of human knowledge
such as what to measure and when to measure in different situations, which are
indirectly represented in the data. In addition, we build an attention-based
decoder as a missing value imputer that helps empower the representation
learning of the inter-relations among multi-view observations for the
prediction task, which operates at the training phase only. We validated the
effectiveness of our method over the public MIMIC-III and PhysioNet challenge
2012 datasets by comparing with and outperforming the state-of-the-art methods
for in-hospital mortality prediction.
</p>
<a href="http://arxiv.org/abs/2101.09986" target="_blank">arXiv:2101.09986</a> [<a href="http://arxiv.org/pdf/2101.09986" target="_blank">pdf</a>]

<h2>UniToPatho, a labeled histopathological dataset for colorectal polyps classification and adenoma dysplasia grading. (arXiv:2101.09991v1 [cs.CV])</h2>
<h3>Carlo Alberto Barbano, Daniele Perlo, Enzo Tartaglione, Attilio Fiandrotti, Luca Bertero, Paola Cassoni, Marco Grangetto</h3>
<p>Histopathological characterization of colorectal polyps allows to tailor
patients' management and follow up with the ultimate aim of avoiding or
promptly detecting an invasive carcinoma. Colorectal polyps characterization
relies on the histological analysis of tissue samples to determine the polyps
malignancy and dysplasia grade. Deep neural networks achieve outstanding
accuracy in medical patterns recognition, however they require large sets of
annotated training images. We introduce UniToPatho, an annotated dataset of
9536 hematoxylin and eosin (H&amp;E) stained patches extracted from 292 whole-slide
images, meant for training deep neural networks for colorectal polyps
classification and adenomas grading. We present our dataset and provide
insights on how to tackle the problem of automatic colorectal polyps
characterization.
</p>
<a href="http://arxiv.org/abs/2101.09991" target="_blank">arXiv:2101.09991</a> [<a href="http://arxiv.org/pdf/2101.09991" target="_blank">pdf</a>]

<h2>Fruit recognition from images using deep learning. (arXiv:1712.00580v10 [cs.CV] UPDATED)</h2>
<h3>Horea Mure&#x15f;an, Mihai Oltean</h3>
<p>In this paper we introduce a new, high-quality, dataset of images containing
fruits. We also present the results of some numerical experiment for training a
neural network to detect fruits. We discuss the reason why we chose to use
fruits in this project by proposing a few applications that could use this kind
of neural network.
</p>
<a href="http://arxiv.org/abs/1712.00580" target="_blank">arXiv:1712.00580</a> [<a href="http://arxiv.org/pdf/1712.00580" target="_blank">pdf</a>]

<h2>Fast and Robust Matching for Multimodal Remote Sensing Image Registration. (arXiv:1808.06194v7 [cs.CV] UPDATED)</h2>
<h3>Yuanxin Ye, Lorenzo Bruzzone, Jie Shan, Francesca Bovolo, Qing Zhu</h3>
<p>While image registration has been studied in remote sensing community for
decades, registering multimodal data [e.g., optical, light detection and
ranging (LiDAR), synthetic aperture radar (SAR), and map] remains a challenging
problem because of significant nonlinear intensity differences between such
data. To address this problem, this paper presents a fast and robust matching
framework integrating local descriptors for multimodal registration. In the
proposed framework, a local descriptor, such as Histogram of Oriented Gradient
(HOG), Local Self Similarity (LSS), or Speeded-Up Robust Feature (SURF), is
first extracted at each pixel to form a pixel-wise feature representation of an
image. Then we define a similarity measure based on the feature representation
in frequency domain using the 3 Dimensional Fast Fourier Transform (3DFFT)
technique, followed by a template matching scheme to detect control points
between images. In this procedure, we also propose a novel pixel-wise feature
representation using orientated gradients of images, which is named channel
features of orientated gradients (CFOG). This novel feature is an extension of
the pixel-wise HOG descriptors, and outperforms that both in matching
performance and computational efficiency. The major advantage of the proposed
framework includes: (1) structural similarity representation using the
pixel-wise feature description and (2) high computational efficiency due to the
use of 3DFFT. Experimental results on different types of multimodal images show
the superior matching performance of the proposed framework than the
state-of-the-art methods. Moreover, we design an automatic registration system
for very large-size multimodal images (more than 20000*20000 pixels) based on
the proposed framework. Experimental results show the effectiveness of the
designed registration system.The matlab code is available in this manuscript.
</p>
<a href="http://arxiv.org/abs/1808.06194" target="_blank">arXiv:1808.06194</a> [<a href="http://arxiv.org/pdf/1808.06194" target="_blank">pdf</a>]

<h2>Group-based Learning of Disentangled Representations with Generalizability for Novel Contents. (arXiv:1809.02383v2 [cs.LG] UPDATED)</h2>
<h3>Haruo Hosoya</h3>
<p>Sensory data are often comprised of independent content and transformation
factors. For example, face images may have shapes as content and poses as
transformation. To infer separately these factors from given data, various
``disentangling'' models have been proposed. However, many of these are
supervised or semi-supervised, either requiring attribute labels that are often
unavailable or disallowing for generalization over new contents. In this study,
we introduce a novel deep generative model, called group-based variational
autoencoders. In this, we assume no explicit labels, but a weaker form of
structure that groups together data instances having the same content but
transformed differently; we thereby separately estimate a group-common factor
as content and an instance-specific factor as transformation. This approach
allows for learning to represent a general continuous space of contents, which
can accommodate unseen contents. Despite the simplicity, our model succeeded in
learning, from five datasets, content representations that are highly separate
from the transformation representation and generalizable to data with novel
contents. We further provide detailed analysis of the latent content code and
show insight into how our model obtains the notable transformation invariance
and content generalizability.
</p>
<a href="http://arxiv.org/abs/1809.02383" target="_blank">arXiv:1809.02383</a> [<a href="http://arxiv.org/pdf/1809.02383" target="_blank">pdf</a>]

<h2>Solving for multi-class: a survey and synthesis. (arXiv:1809.05929v7 [stat.ML] UPDATED)</h2>
<h3>Peter Mills</h3>
<p>Many of the best statistical classification algorithms are binary classifiers
that can only distinguish between one of two classes. The number of possible
ways of generalizing binary classification to multi-class increases
exponentially with the number of classes. There is some indication that the
best method will depend on the dataset. Hence, we are particularly interested
in data-driven solution design, whether based on prior considerations or on
empirical examination of the data. Here we demonstrate how a recursive control
language can be used to describe a multitude of different partitioning
strategies in multi-class classification, including those in most common use.
We use it both to manually construct new partitioning configurations as well as
to examine those that have been automatically designed.

Eight different strategies were tested on eight different datasets using a
support vector machine (SVM) as the base binary classifier. Numerical results
suggest that a one-size-fits-all solution consisting of one-versus-one is
appropriate for most datasets. Three datasets showed better accuracy using
different methods. The best solution for the most improved dataset exploited a
property of the data to produce an uncertainty coefficient 36\% higher (0.016
absolute gain) than one-vs.-one. For the same dataset, an adaptive solution
that empirically examined the data was also more accurate than one-vs.-one
while being faster.
</p>
<a href="http://arxiv.org/abs/1809.05929" target="_blank">arXiv:1809.05929</a> [<a href="http://arxiv.org/pdf/1809.05929" target="_blank">pdf</a>]

<h2>Graph Neural Networks with convolutional ARMA filters. (arXiv:1901.01343v7 [cs.LG] UPDATED)</h2>
<h3>Filippo Maria Bianchi, Daniele Grattarola, Lorenzo Livi, Cesare Alippi</h3>
<p>Popular graph neural networks implement convolution operations on graphs
based on polynomial spectral filters. In this paper, we propose a novel graph
convolutional layer inspired by the auto-regressive moving average (ARMA)
filter that, compared to polynomial ones, provides a more flexible frequency
response, is more robust to noise, and better captures the global graph
structure. We propose a graph neural network implementation of the ARMA filter
with a recursive and distributed formulation, obtaining a convolutional layer
that is efficient to train, localized in the node space, and can be transferred
to new graphs at test time. We perform a spectral analysis to study the
filtering effect of the proposed ARMA layer and report experiments on four
downstream tasks: semi-supervised node classification, graph signal
classification, graph classification, and graph regression. Results show that
the proposed ARMA layer brings significant improvements over graph neural
networks based on polynomial filters.
</p>
<a href="http://arxiv.org/abs/1901.01343" target="_blank">arXiv:1901.01343</a> [<a href="http://arxiv.org/pdf/1901.01343" target="_blank">pdf</a>]

<h2>Ensembling methods for countrywide short term forecasting of gas demand. (arXiv:1902.00097v4 [cs.LG] UPDATED)</h2>
<h3>Emanuele Fabbiani, Andrea Marziali, Giuseppe De Nicolao</h3>
<p>Gas demand is made of three components: Residential, Industrial, and
Thermoelectric Gas Demand. Herein, the one-day-ahead prediction of each
component is studied, using Italian data as a case study. Statistical
properties and relationships with temperature are discussed, as a preliminary
step for an effective feature selection. Nine "base forecasters" are
implemented and compared: Ridge Regression, Gaussian Processes, Nearest
Neighbours, Artificial Neural Networks, Torus Model, LASSO, Elastic Net, Random
Forest, and Support Vector Regression (SVR). Based on them, four ensemble
predictors are crafted: simple average, weighted average, subset average, and
SVR aggregation. We found that ensemble predictors perform consistently better
than base ones. Moreover, our models outperformed Transmission System Operator
(TSO) predictions in a two-year out-of-sample validation. Such results suggest
that combining predictors may lead to significant performance improvements in
gas demand forecasting.
</p>
<a href="http://arxiv.org/abs/1902.00097" target="_blank">arXiv:1902.00097</a> [<a href="http://arxiv.org/pdf/1902.00097" target="_blank">pdf</a>]

<h2>Nonlinear Model Predictive Control for Robust Bipedal Locomotion: Exploring Angular Momentum and CoM Height Changes. (arXiv:1902.06770v2 [cs.RO] UPDATED)</h2>
<h3>Jiatao Ding, Chengxu Zhou, Songyan Xin, Xiaohui Xiao, Nikos Tsagarakis</h3>
<p>Human beings can utilize multiple balance strategies, e.g. step location
adjustment and angular momentum adaptation, to maintain balance when walking
under dynamic disturbances. In this work, we propose a novel Nonlinear Model
Predictive Control (NMPC) framework for robust locomotion, with the
capabilities of step location adjustment, Center of Mass (CoM) height
variation, and angular momentum adaptation. These features are realized by
constraining the Zero Moment Point within the support polygon. By using the
nonlinear inverted pendulum plus flywheel model, the effects of upper-body
rotation and vertical height motion are considered. As a result, the NMPC is
formulated as a quadratically constrained quadratic program problem, which is
solved fast by sequential quadratic programming. Using this unified framework,
robust walking patterns that exploit reactive stepping, body inclination, and
CoM height variation are generated based on the state estimation. The
adaptability for bipedal walking in multiple scenarios has been demonstrated
through simulation studies.
</p>
<a href="http://arxiv.org/abs/1902.06770" target="_blank">arXiv:1902.06770</a> [<a href="http://arxiv.org/pdf/1902.06770" target="_blank">pdf</a>]

<h2>Interaction-aware Kalman Neural Networks for Trajectory Prediction. (arXiv:1902.10928v4 [cs.RO] UPDATED)</h2>
<h3>Ce Ju, Zheng Wang, Cheng Long, Xiaoyu Zhang, Dong Eui Chang</h3>
<p>Forecasting the motion of surrounding obstacles (vehicles, bicycles,
pedestrians and etc.) benefits the on-road motion planning for intelligent and
autonomous vehicles. Complex scenes always yield great challenges in modeling
the patterns of surrounding traffic. For example, one main challenge comes from
the intractable interaction effects in a complex traffic system. In this paper,
we propose a multi-layer architecture Interaction-aware Kalman Neural Networks
(IaKNN) which involves an interaction layer for resolving high-dimensional
traffic environmental observations as interaction-aware accelerations, a motion
layer for transforming the accelerations to interaction aware trajectories, and
a filter layer for estimating future trajectories with a Kalman filter network.
Attributed to the multiple traffic data sources, our end-to-end trainable
approach technically fuses dynamic and interaction-aware trajectories boosting
the prediction performance. Experiments on the NGSIM dataset demonstrate that
IaKNN outperforms the state-of-the-art methods in terms of effectiveness for
traffic trajectory prediction.
</p>
<a href="http://arxiv.org/abs/1902.10928" target="_blank">arXiv:1902.10928</a> [<a href="http://arxiv.org/pdf/1902.10928" target="_blank">pdf</a>]

<h2>Tight Regret Bounds for Infinite-armed Linear Contextual Bandits. (arXiv:1905.01435v2 [stat.ML] UPDATED)</h2>
<h3>Yingkai Li, Yining Wang, Xi Chen, Yuan Zhou</h3>
<p>Linear contextual bandit is an important class of sequential decision making
problems with a wide range of applications to recommender systems, online
advertising, healthcare, and many other machine learning related tasks. While
there is a lot of prior research, tight regret bounds of linear contextual
bandit with infinite action sets remain open. In this paper, we address this
open problem by considering the linear contextual bandit with (changing)
infinite action sets. We prove a regret upper bound on the order of
$O(\sqrt{d^2T\log T})\times \text{poly}(\log\log T)$ where $d$ is the domain
dimension and $T$ is the time horizon. Our upper bound matches the previous
lower bound of $\Omega(\sqrt{d^2 T\log T})$ in [Li et al., 2019] up to iterated
logarithmic terms.
</p>
<a href="http://arxiv.org/abs/1905.01435" target="_blank">arXiv:1905.01435</a> [<a href="http://arxiv.org/pdf/1905.01435" target="_blank">pdf</a>]

<h2>Bayesian Optimization with Approximate Set Kernels. (arXiv:1905.09780v3 [stat.ML] UPDATED)</h2>
<h3>Jungtaek Kim, Michael McCourt, Tackgeun You, Saehoon Kim, Seungjin Choi</h3>
<p>We propose a practical Bayesian optimization method over sets, to minimize a
black-box function that takes a set as a single input. Because set inputs are
permutation-invariant, traditional Gaussian process-based Bayesian optimization
strategies which assume vector inputs can fall short. To address this, we
develop a Bayesian optimization method with \emph{set kernel} that is used to
build surrogate functions. This kernel accumulates similarity over set elements
to enforce permutation-invariance, but this comes at a greater computational
cost. To reduce this burden, we propose two key components: (i) a more
efficient approximate set kernel which is still positive-definite and is an
unbiased estimator of the true set kernel with upper-bounded variance in terms
of the number of subsamples, (ii) a constrained acquisition function
optimization over sets, which uses symmetry of the feasible region that defines
a set input. Finally, we present several numerical experiments which
demonstrate that our method outperforms other methods.
</p>
<a href="http://arxiv.org/abs/1905.09780" target="_blank">arXiv:1905.09780</a> [<a href="http://arxiv.org/pdf/1905.09780" target="_blank">pdf</a>]

<h2>Learning Temporal Causal Sequence Relationships from Real-Time Time-Series. (arXiv:1905.12262v6 [cs.LG] UPDATED)</h2>
<h3>Antonio Anastasio Bruto da Costa, Pallab Dasgupta</h3>
<p>We aim to mine temporal causal sequences that explain observed events
(consequents) in time-series traces. Causal explanations of key events in a
time-series has applications in design debugging, anomaly detection, planning,
root-cause analysis and many more. We make use of decision trees and interval
arithmetic to mine sequences that explain defining events in the time-series.
We propose modified decision tree construction metrics to handle the
non-determinism introduced by the temporal dimension. The mined sequences are
expressed in a readable temporal logic language that is easy to interpret. The
application of the proposed methodology is illustrated through various
examples.
</p>
<a href="http://arxiv.org/abs/1905.12262" target="_blank">arXiv:1905.12262</a> [<a href="http://arxiv.org/pdf/1905.12262" target="_blank">pdf</a>]

<h2>A Tunable Loss Function for Robust Classification: Calibration, Landscape, and Generalization. (arXiv:1906.02314v5 [cs.LG] UPDATED)</h2>
<h3>Tyler Sypherd, Mario Diaz, John Kevin Cava, Gautam Dasarathy, Peter Kairouz, Lalitha Sankar</h3>
<p>We introduce a tunable loss function called $\alpha$-loss, parameterized by
$\alpha \in (0,\infty]$, which interpolates between the exponential loss
($\alpha = 1/2$), the log-loss ($\alpha = 1$), and the 0-1 loss ($\alpha =
\infty$), for the machine learning setting of classification. Theoretically, we
illustrate a fundamental connection between $\alpha$-loss and Arimoto
conditional entropy, verify the classification-calibration of $\alpha$-loss in
order to demonstrate asymptotic optimality via Rademacher complexity
generalization techniques, and build-upon a notion called strictly local
quasi-convexity in order to quantitatively characterize the optimization
landscape of $\alpha$-loss. Practically, we perform class imbalance,
robustness, and classification experiments on benchmark image datasets using
convolutional-neural-networks. Our main practical conclusion is that certain
tasks may benefit from tuning $\alpha$-loss away from log-loss ($\alpha = 1$),
and to this end we provide simple heuristics for the practitioner. In
particular, navigating the $\alpha$ hyperparameter can readily provide superior
model robustness to label flips ($\alpha &gt; 1$) and sensitivity to imbalanced
classes ($\alpha &lt; 1$).
</p>
<a href="http://arxiv.org/abs/1906.02314" target="_blank">arXiv:1906.02314</a> [<a href="http://arxiv.org/pdf/1906.02314" target="_blank">pdf</a>]

<h2>Multitasking collision-free motion planning algorithms in Euclidean spaces. (arXiv:1906.03239v2 [cs.RO] UPDATED)</h2>
<h3>Cesar A. Ipanaque Zapata, Jesus Gonzalez</h3>
<p>We present optimal motion planning algorithms which can be used in designing
practical systems controlling objects moving in Euclidean space without
collisions. Our algorithms are optimal in a very concrete sense, namely, they
have the minimal possible number of local planners. Our algorithms are
motivated by those presented by Mas-Ku and Torres-Giese (as streamlined by
Farber), and are developed within the more general context of the multitasking
(a.k.a.~higher) motion planning problem. In addition, an eventual
implementation of our algorithms is expected to work more efficiently than
previous ones when applied to systems with a large number of moving objects.
</p>
<a href="http://arxiv.org/abs/1906.03239" target="_blank">arXiv:1906.03239</a> [<a href="http://arxiv.org/pdf/1906.03239" target="_blank">pdf</a>]

<h2>EnlightenGAN: Deep Light Enhancement without Paired Supervision. (arXiv:1906.06972v2 [cs.CV] UPDATED)</h2>
<h3>Yifan Jiang, Xinyu Gong, Ding Liu, Yu Cheng, Chen Fang, Xiaohui Shen, Jianchao Yang, Pan Zhou, Zhangyang Wang</h3>
<p>Deep learning-based methods have achieved remarkable success in image
restoration and enhancement, but are they still competitive when there is a
lack of paired training data? As one such example, this paper explores the
low-light image enhancement problem, where in practice it is extremely
challenging to simultaneously take a low-light and a normal-light photo of the
same visual scene. We propose a highly effective unsupervised generative
adversarial network, dubbed EnlightenGAN, that can be trained without
low/normal-light image pairs, yet proves to generalize very well on various
real-world test images. Instead of supervising the learning using ground truth
data, we propose to regularize the unpaired training using the information
extracted from the input itself, and benchmark a series of innovations for the
low-light image enhancement problem, including a global-local discriminator
structure, a self-regularized perceptual loss fusion, and attention mechanism.
Through extensive experiments, our proposed approach outperforms recent methods
under a variety of metrics in terms of visual quality and subjective user
study. Thanks to the great flexibility brought by unpaired training,
EnlightenGAN is demonstrated to be easily adaptable to enhancing real-world
images from various domains. The code is available at
\url{https://github.com/yueruchen/EnlightenGAN}
</p>
<a href="http://arxiv.org/abs/1906.06972" target="_blank">arXiv:1906.06972</a> [<a href="http://arxiv.org/pdf/1906.06972" target="_blank">pdf</a>]

<h2>An Unsupervised Bayesian Neural Network for Truth Discovery in Social Networks. (arXiv:1906.10470v2 [cs.LG] UPDATED)</h2>
<h3>Jielong Yang, Wee Peng Tay</h3>
<p>The problem of estimating event truths from conflicting agent opinions in a
social network is investigated. An autoencoder learns the complex relationships
between event truths, agent reliabilities and agent observations. A Bayesian
network model is proposed to guide the learning process by modeling the
relationship of the autoencoder's outputs with different variables. At the same
time, it also models the social relationships between agents in the network.
The proposed approach is unsupervised and is applicable when ground truth
labels of events are unavailable. A variational inference method is used to
jointly estimate the hidden variables in the Bayesian network and the
parameters in the autoencoder. Experiments on three real datasets demonstrate
that our proposed approach is competitive with, and in most cases better than,
several state-of-the-art benchmark methods.
</p>
<a href="http://arxiv.org/abs/1906.10470" target="_blank">arXiv:1906.10470</a> [<a href="http://arxiv.org/pdf/1906.10470" target="_blank">pdf</a>]

<h2>Vector Quantized Bayesian Neural Network Inference for Data Streams. (arXiv:1907.05911v3 [cs.LG] UPDATED)</h2>
<h3>Namuk Park, Taekyu Lee, Songkuk Kim</h3>
<p>Bayesian neural networks (BNN) can estimate the uncertainty in predictions,
as opposed to non-Bayesian neural networks (NNs). However, BNNs have been far
less widely used than non-Bayesian NNs in practice since they need iterative NN
executions to predict a result for one data, and it gives rise to prohibitive
computational cost. This computational burden is a critical problem when
processing data streams with low-latency. To address this problem, we propose a
novel model VQ-BNN, which approximates BNN inference for data streams. In order
to reduce the computational burden, VQ-BNN inference predicts NN only once and
compensates the result with previously memorized predictions. To be specific,
VQ-BNN inference for data streams is given by temporal exponential smoothing of
recent predictions. The computational cost of this model is almost the same as
that of non-Bayesian NNs. Experiments including semantic segmentation on
real-world data show that this model performs significantly faster than BNNs
while estimating predictive results comparable to or superior to the results of
BNNs.
</p>
<a href="http://arxiv.org/abs/1907.05911" target="_blank">arXiv:1907.05911</a> [<a href="http://arxiv.org/pdf/1907.05911" target="_blank">pdf</a>]

<h2>End-to-End Learning from Complex Multigraphs with Latent-Graph Convolutional Networks. (arXiv:1908.05365v2 [stat.ML] UPDATED)</h2>
<h3>Floris Hermsen, Peter Bloem, Fabian Jansen, Wolf Vos</h3>
<p>We study the problem of end-to-end learning from complex multigraphs with
potentially very large numbers of edges between two vertices, each edge labeled
with rich information. Examples range from communication networks to flights
between airports or financial transaction graphs. We propose Latent-Graph
Convolutional Networks (L-GCNs), which propagate information from these complex
edges to a latent adjacency tensor, after which further downstream tasks can be
performed, such as node classification. We evaluate the performance of several
variations of the model on two synthetic datasets simulating fraud in financial
transaction networks, ensuring the model must make use of edge labels in order
to achieve good classification performance. We find that allowing for nonlinear
interactions on a per-neighbor basis boosts performance significantly, while
showing promising results in an inductive setting. Finally, we demonstrate the
use of L-GCNs on real-world data in the form of an urban transportation
network.
</p>
<a href="http://arxiv.org/abs/1908.05365" target="_blank">arXiv:1908.05365</a> [<a href="http://arxiv.org/pdf/1908.05365" target="_blank">pdf</a>]

<h2>Matching Embeddings for Domain Adaptation. (arXiv:1909.11651v4 [cs.LG] UPDATED)</h2>
<h3>Manuel P&#xe9;rez-Carrasco, Guillermo Cabrera-Vives, Pavlos Protopapas, Nicol&#xe1;s Astorga, Marouan Belhaj</h3>
<p>In this work we address the problem of transferring knowledge obtained from a
vast annotated source domain to a low labeled target domain. We propose
Adversarial Variational Domain Adaptation (AVDA), a semi-supervised domain
adaptation method based on deep variational embedded representations. We use
approximate inference and domain adversarial methods to map samples from source
and target domains into an aligned class-dependent embedding defined as a
Gaussian Mixture Model. AVDA works as a classifier and considers a generative
model that helps this classification. We used digits dataset for
experimentation. Our results show that on a semi-supervised few-shot scenario
our model outperforms previous methods in most of the adaptation tasks, even
using a fewer number of labeled samples per class on target domain.
</p>
<a href="http://arxiv.org/abs/1909.11651" target="_blank">arXiv:1909.11651</a> [<a href="http://arxiv.org/pdf/1909.11651" target="_blank">pdf</a>]

<h2>Hierarchical Neural Architecture Search via Operator Clustering. (arXiv:1909.11926v5 [cs.LG] UPDATED)</h2>
<h3>Guilin Li, Xing Zhang, Zitong Wang, Matthias Tan, Jiashi Feng, Zhenguo Li, Tong Zhang</h3>
<p>Recently, the efficiency of automatic neural architecture design has been
significantly improved by gradient-based search methods such as DARTS. However,
recent literature has brought doubt to the generalization ability of DARTS,
arguing that DARTS performs poorly when the search space is changed, i.e, when
different set of candidate operators are used. Regularization techniques such
as early stopping have been proposed to partially solve this problem. In this
paper, we tackle this problem from a different perspective by identifying two
contributing factors to the collapse of DARTS when the search space changes:
(1) the correlation of similar operators incurs unfavorable competition among
them and makes their relative importance score unreliable and (2) the
optimization complexity gap between the proxy search stage and the final
training. Based on these findings, we propose a new hierarchical search
algorithm. With its operator clustering and optimization complexity match, the
algorithm can consistently find high-performance architecture across various
search spaces. For all the five variants of the popular cell-based search
spaces, the proposed algorithm always obtains state-of-the-art architecture
with best accuracy on the CIFAR-10, CIFAR-100 and ImageNet over other
well-established DARTS-alike algorithms. Code is available at
https://github.com/susan0199/StacNAS.
</p>
<a href="http://arxiv.org/abs/1909.11926" target="_blank">arXiv:1909.11926</a> [<a href="http://arxiv.org/pdf/1909.11926" target="_blank">pdf</a>]

<h2>One-Shot Neural Architecture Search via Self-Evaluated Template Network. (arXiv:1910.05733v4 [cs.CV] UPDATED)</h2>
<h3>Xuanyi Dong, Yi Yang</h3>
<p>Neural architecture search (NAS) aims to automate the search procedure of
architecture instead of manual design. Even if recent NAS approaches finish the
search within days, lengthy training is still required for a specific
architecture candidate to get the parameters for its accurate evaluation.
Recently one-shot NAS methods are proposed to largely squeeze the tedious
training process by sharing parameters across candidates. In this way, the
parameters for each candidate can be directly extracted from the shared
parameters instead of training them from scratch. However, they have no sense
of which candidate will perform better until evaluation so that the candidates
to evaluate are randomly sampled and the top-1 candidate is considered the
best. In this paper, we propose a Self-Evaluated Template Network (SETN) to
improve the quality of the architecture candidates for evaluation so that it is
more likely to cover competitive candidates. SETN consists of two components:
(1) an evaluator, which learns to indicate the probability of each individual
architecture being likely to have a lower validation loss. The candidates for
evaluation can thus be selectively sampled according to this evaluator. (2) a
template network, which shares parameters among all candidates to amortize the
training cost of generated candidates. In experiments, the architecture found
by SETN achieves state-of-the-art performance on CIFAR and ImageNet benchmarks
within comparable computation costs. Code is publicly available on GitHub:
https://github.com/D-X-Y/AutoDL-Projects.
</p>
<a href="http://arxiv.org/abs/1910.05733" target="_blank">arXiv:1910.05733</a> [<a href="http://arxiv.org/pdf/1910.05733" target="_blank">pdf</a>]

<h2>Dynamic Graph Convolutional Networks Using the Tensor M-Product. (arXiv:1910.07643v3 [cs.LG] UPDATED)</h2>
<h3>Osman Asif Malik, Shashanka Ubaru, Lior Horesh, Misha E. Kilmer, Haim Avron</h3>
<p>Many irregular domains such as social networks, financial transactions,
neuron connections, and natural language constructs are represented using graph
structures. In recent years, a variety of graph neural networks (GNNs) have
been successfully applied for representation learning and prediction on such
graphs. In many of the real-world applications, the underlying graph changes
over time, however, most of the existing GNNs are inadequate for handling such
dynamic graphs. In this paper we propose a novel technique for learning
embeddings of dynamic graphs using a tensor algebra framework. Our method
extends the popular graph convolutional network (GCN) for learning
representations of dynamic graphs using the recently proposed tensor M-product
technique. Theoretical results presented establish a connection between the
proposed tensor approach and spectral convolution of tensors. The proposed
method TM-GCN is consistent with the Message Passing Neural Network (MPNN)
framework, accounting for both spatial and temporal message passing. Numerical
experiments on real-world datasets demonstrate the performance of the proposed
method for edge classification and link prediction tasks on dynamic graphs. We
also consider an application related to the COVID-19 pandemic, and show how our
method can be used for early detection of infected individuals from contact
tracing data.
</p>
<a href="http://arxiv.org/abs/1910.07643" target="_blank">arXiv:1910.07643</a> [<a href="http://arxiv.org/pdf/1910.07643" target="_blank">pdf</a>]

<h2>Collision Avoidance in Pedestrian-Rich Environments with Deep Reinforcement Learning. (arXiv:1910.11689v4 [cs.RO] UPDATED)</h2>
<h3>Michael Everett, Yu Fan Chen, Jonathan P. How</h3>
<p>Collision avoidance algorithms are essential for safe and efficient robot
operation among pedestrians. This work proposes using deep reinforcement (RL)
learning as a framework to model the complex interactions and cooperation with
nearby, decision-making agents, such as pedestrians and other robots. Existing
RL-based works assume homogeneity of agent properties, use specific motion
models over short timescales, or lack a principled method to handle a large,
possibly varying number of agents. Therefore, this work develops an algorithm
that learns collision avoidance among a variety of heterogeneous,
non-communicating, dynamic agents without assuming they follow any particular
behavior rules. It extends our previous work by introducing a strategy using
Long Short-Term Memory (LSTM) that enables the algorithm to use observations of
an arbitrary number of other agents, instead of a small, fixed number of
neighbors. The proposed algorithm is shown to outperform a classical collision
avoidance algorithm, another deep RL-based algorithm, and scales with the
number of agents better (fewer collisions, shorter time to goal) than our
previously published learning-based approach. Analysis of the LSTM provides
insights into how observations of nearby agents affect the hidden state and
quantifies the performance impact of various agent ordering heuristics. The
learned policy generalizes to several applications beyond the training
scenarios: formation control (arrangement into letters), demonstrations on a
fleet of four multirotors and on a fully autonomous robotic vehicle capable of
traveling at human walking speed among pedestrians.
</p>
<a href="http://arxiv.org/abs/1910.11689" target="_blank">arXiv:1910.11689</a> [<a href="http://arxiv.org/pdf/1910.11689" target="_blank">pdf</a>]

<h2>When MAML Can Adapt Fast and How to Assist When It Cannot. (arXiv:1910.13603v3 [cs.LG] UPDATED)</h2>
<h3>S&#xe9;bastien M.R. Arnold, Shariq Iqbal, Fei Sha</h3>
<p>Model-Agnostic Meta-Learning (MAML) and its variants have achieved success in
meta-learning tasks on many datasets and settings. On the other hand, we have
just started to understand and analyze how they are able to adapt fast to new
tasks. For example, one popular hypothesis is that the algorithms learn good
representations for transfer, as in multi-task learning. In this work, we
contribute by providing a series of empirical and theoretical studies, and
discover several interesting yet previously unknown properties of the
algorithm. We find MAML adapts better with a deep architecture even if the
tasks need only a shallow one (and thus, no representation learning is needed).
While echoing previous findings by others that the bottom layers in deep
architectures enable representation learning, we also find that upper layers
enable fast adaptation by being meta-learned to perform adaptive gradient
update when generalizing to new tasks. Motivated by these findings, we study
several meta-optimization approaches and propose a new one for learning to
optimize adaptively. Those approaches attain stronger performance in
meta-learning both shallower and deeper architectures than MAML.
</p>
<a href="http://arxiv.org/abs/1910.13603" target="_blank">arXiv:1910.13603</a> [<a href="http://arxiv.org/pdf/1910.13603" target="_blank">pdf</a>]

<h2>Fairness Violations and Mitigation under Covariate Shift. (arXiv:1911.00677v2 [cs.LG] UPDATED)</h2>
<h3>Harvineet Singh, Rina Singh, Vishwali Mhasawade, Rumi Chunara</h3>
<p>We study the problem of learning fair prediction models for unseen test sets
distributed differently from the train set. Stability against changes in data
distribution is an important mandate for responsible deployment of models. The
domain adaptation literature addresses this concern, albeit with the notion of
stability limited to that of prediction accuracy. We identify sufficient
conditions under which stable models, both in terms of prediction accuracy and
fairness, can be learned. Using the causal graph describing the data and the
anticipated shifts, we specify an approach based on feature selection that
exploits conditional independencies in the data to estimate accuracy and
fairness metrics for the test set. We show that for specific fairness
definitions, the resulting model satisfies a form of worst-case optimality. In
context of a healthcare task, we illustrate the advantages of the approach in
making more equitable decisions.
</p>
<a href="http://arxiv.org/abs/1911.00677" target="_blank">arXiv:1911.00677</a> [<a href="http://arxiv.org/pdf/1911.00677" target="_blank">pdf</a>]

<h2>DocParser: Hierarchical Structure Parsing of Document Renderings. (arXiv:1911.01702v2 [cs.LG] UPDATED)</h2>
<h3>Johannes Rausch, Octavio Martinez, Fabian Bissig, Ce Zhang, Stefan Feuerriegel</h3>
<p>Translating renderings (e. g. PDFs, scans) into hierarchical document
structures is extensively demanded in the daily routines of many real-world
applications. However, a holistic, principled approach to inferring the
complete hierarchical structure of documents is missing. As a remedy, we
developed "DocParser": an end-to-end system for parsing the complete document
structure - including all text elements, nested figures, tables, and table cell
structures. Our second contribution is to provide a dataset for evaluating
hierarchical document structure parsing. Our third contribution is to propose a
scalable learning framework for settings where domain-specific data are scarce,
which we address by a novel approach to weak supervision that significantly
improves the document structure parsing performance. Our experiments confirm
the effectiveness of our proposed weak supervision: Compared to the baseline
without weak supervision, it improves the mean average precision for detecting
document entities by 39.1 % and improves the F1 score of classifying
hierarchical relations by 35.8 %.
</p>
<a href="http://arxiv.org/abs/1911.01702" target="_blank">arXiv:1911.01702</a> [<a href="http://arxiv.org/pdf/1911.01702" target="_blank">pdf</a>]

<h2>GeoTrackNet-A Maritime Anomaly Detector using Probabilistic Neural Network Representation of AIS Tracks and A Contrario Detection. (arXiv:1912.00682v3 [cs.LG] UPDATED)</h2>
<h3>Duong Nguyen, Rodolphe Vadaine, Guillaume Hajduch, Ren&#xe9; Garello, Ronan Fablet</h3>
<p>Representing maritime traffic patterns and detecting anomalies from them are
key to vessel monitoring and maritime situational awareness. We propose a novel
approach -- referred to as GeoTrackNet -- for maritime anomaly detection from
AIS data streams. Our model exploits state-of-the-art neural network schemes to
learn a probabilistic representation of AIS tracks and a contrario detection to
detect abnormal events. The neural network provides a new means to capture
complex and heterogeneous patterns in vessels' behaviours, while the \textit{a
contrario} detector takes into account the fact that the learnt distribution
may be location-dependent. Experiments on a real AIS dataset comprising more
than 4.2 million AIS messages demonstrate the relevance of the proposed method
compared with state-of-the-art schemes.
</p>
<a href="http://arxiv.org/abs/1912.00682" target="_blank">arXiv:1912.00682</a> [<a href="http://arxiv.org/pdf/1912.00682" target="_blank">pdf</a>]

<h2>On Interpretability of Artificial Neural Networks: A Survey. (arXiv:2001.02522v3 [cs.LG] UPDATED)</h2>
<h3>Fenglei Fan, Jinjun Xiong, Mengzhou Li, Ge Wang</h3>
<p>Deep learning as represented by the artificial deep neural networks (DNNs)
has achieved great success in many important areas that deal with text, images,
videos, graphs, and so on. However, the black-box nature of DNNs has become one
of the primary obstacles for their wide acceptance in mission-critical
applications such as medical diagnosis and therapy. Due to the huge potential
of deep learning, interpreting neural networks has recently attracted much
research attention. In this paper, based on our comprehensive taxonomy, we
systematically review recent studies in understanding the mechanism of neural
networks, describe applications of interpretability especially in medicine, and
discuss future directions of interpretability research, such as in relation to
fuzzy logic and brain science.
</p>
<a href="http://arxiv.org/abs/2001.02522" target="_blank">arXiv:2001.02522</a> [<a href="http://arxiv.org/pdf/2001.02522" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning for Autonomous Driving: A Survey. (arXiv:2002.00444v2 [cs.LG] UPDATED)</h2>
<h3>B Ravi Kiran, Ibrahim Sobh, Victor Talpaert, Patrick Mannion, Ahmad A. Al Sallab, Senthil Yogamani, Patrick P&#xe9;rez</h3>
<p>With the development of deep representation learning, the domain of
reinforcement learning (RL) has become a powerful learning framework now
capable of learning complex policies in high dimensional environments. This
review summarises deep reinforcement learning (DRL) algorithms and provides a
taxonomy of automated driving tasks where (D)RL methods have been employed,
while addressing key computational challenges in real world deployment of
autonomous driving agents. It also delineates adjacent domains such as behavior
cloning, imitation learning, inverse reinforcement learning that are related
but are not classical RL algorithms. The role of simulators in training agents,
methods to validate, test and robustify existing solutions in RL are discussed.
</p>
<a href="http://arxiv.org/abs/2002.00444" target="_blank">arXiv:2002.00444</a> [<a href="http://arxiv.org/pdf/2002.00444" target="_blank">pdf</a>]

<h2>Metric-Free Individual Fairness in Online Learning. (arXiv:2002.05474v3 [cs.LG] UPDATED)</h2>
<h3>Yahav Bechavod, Christopher Jung, Zhiwei Steven Wu</h3>
<p>We study an online learning problem subject to the constraint of individual
fairness, which requires that similar individuals are treated similarly. Unlike
prior work on individual fairness, we do not assume the similarity measure
among individuals is known, nor do we assume that such measure takes a certain
parametric form. Instead, we leverage the existence of an auditor who detects
fairness violations without enunciating the quantitative measure. In each
round, the auditor examines the learner's decisions and attempts to identify a
pair of individuals that are treated unfairly by the learner. We provide a
general reduction framework that reduces online classification in our model to
standard online classification, which allows us to leverage existing online
learning algorithms to achieve sub-linear regret and number of fairness
violations. Surprisingly, in the stochastic setting where the data are drawn
independently from a distribution, we are also able to establish PAC-style
fairness and accuracy generalization guarantees (Yona and Rothblum [2018]),
despite only having access to a very restricted form of fairness feedback. Our
fairness generalization bound qualitatively matches the uniform convergence
bound of Yona and Rothblum [2018], while also providing a meaningful accuracy
generalization guarantee. Our results resolve an open question by Gillen et al.
[2018] by showing that online learning under an unknown individual fairness
constraint is possible even without assuming a strong parametric form of the
underlying similarity measure.
</p>
<a href="http://arxiv.org/abs/2002.05474" target="_blank">arXiv:2002.05474</a> [<a href="http://arxiv.org/pdf/2002.05474" target="_blank">pdf</a>]

<h2>Robust Policies For Proactive ICU Transfers. (arXiv:2002.06247v2 [cs.LG] UPDATED)</h2>
<h3>Julien Grand-Clement, Carri W. Chan, Vineet Goyal, Gabriel Escobar</h3>
<p>Patients whose transfer to the Intensive Care Unit (ICU) is unplanned are
prone to higher mortality rates than those who were admitted directly to the
ICU. Recent advances in machine learning to predict patient deterioration have
introduced the possibility of \emph{proactive transfer} from the ward to the
ICU. In this work, we study the problem of finding \emph{robust} patient
transfer policies which account for uncertainty in statistical estimates due to
data limitations when optimizing to improve overall patient care. We propose a
Markov Decision Process model to capture the evolution of patient health, where
the states represent a measure of patient severity. Under fairly general
assumptions, we show that an optimal transfer policy has a threshold structure,
i.e., that it transfers all patients above a certain severity level to the ICU
(subject to available capacity). As model parameters are typically determined
based on statistical estimations from real-world data, they are inherently
subject to misspecification and estimation errors. We account for this
parameter uncertainty by deriving a robust policy that optimizes the worst-case
reward across all plausible values of the model parameters. We show that the
robust policy also has a threshold structure under fairly general assumptions.
Moreover, it is more aggressive in transferring patients than the optimal
nominal policy, which does not take into account parameter uncertainty. We
present computational experiments using a dataset of hospitalizations at 21
KNPC hospitals, and present empirical evidence of the sensitivity of various
hospital metrics (mortality, length-of-stay, average ICU occupancy) to small
changes in the parameters. Our work provides useful insights into the impact of
parameter uncertainty on deriving simple policies for proactive ICU transfer
that have strong empirical performance and theoretical guarantees.
</p>
<a href="http://arxiv.org/abs/2002.06247" target="_blank">arXiv:2002.06247</a> [<a href="http://arxiv.org/pdf/2002.06247" target="_blank">pdf</a>]

<h2>Addressing Some Limitations of Transformers with Feedback Memory. (arXiv:2002.09402v3 [cs.LG] UPDATED)</h2>
<h3>Angela Fan, Thibaut Lavril, Edouard Grave, Armand Joulin, Sainbayar Sukhbaatar</h3>
<p>Transformers have been successfully applied to sequential, auto-regressive
tasks despite being feedforward networks. Unlike recurrent neural networks,
Transformers use attention to capture temporal relations while processing input
tokens in parallel. While this parallelization makes them computationally
efficient, it restricts the model from fully exploiting the sequential nature
of the input. The representation at a given layer can only access
representations from lower layers, rather than the higher level representations
already available. In this work, we propose the Feedback Transformer
architecture that exposes all previous representations to all future
representations, meaning the lowest representation of the current timestep is
formed from the highest-level abstract representation of the past. We
demonstrate on a variety of benchmarks in language modeling, machine
translation, and reinforcement learning that the increased representation
capacity can create small, shallow models with much stronger performance than
comparable Transformers.
</p>
<a href="http://arxiv.org/abs/2002.09402" target="_blank">arXiv:2002.09402</a> [<a href="http://arxiv.org/pdf/2002.09402" target="_blank">pdf</a>]

<h2>Computation-efficient Deep Model Training for Ciphertext-based Cross-silo Federated Learning. (arXiv:2002.09843v4 [cs.LG] UPDATED)</h2>
<h3>Xue Yang, Yan Feng, Weijun Fang, Jun Shao, Xiaohu Tang, Shu-Tao Xia, Rongxing Lu</h3>
<p>Although cross-silo federated learning improves privacy of training data by
exchanging model updates rather than raw data, sharing updates (e.g., local
gradients or parameters) may still involve risks. To ensure no updates are
revealed to the server, industrial FL schemes allow clients (e.g., financial or
medical) to mask local gradients by homomorphic encryption (HE). In this case,
the server cannot obtain the updates, but the curious clients can obtain this
information to infer other clients' private data. To alleviate this situation,
the most direct idea is to let clients train deep models on encrypted domain.
Unfortunately, the resulting solution is of poor accuracy and high cost, since
the existing advanced HE is incompatible with non-linear activation functions
and inefficient in terms of computational cost. In this paper, we propose a
\emph{computational-efficient deep model training scheme for ciphertext-based
cross-silo federated learning} to comprehensively guarantee privacy. First, we
customize \emph{a novel one-time-pad-style model encryption method} to directly
supports non-linear activation functions and decimal arithmetic operations on
the encrypted domain. Then, we design a hybrid privacy-preserving scheme by
combining our model encryption method with secret sharing techniques to keep
updates secret from the clients and prevent the server from obtaining local
gradients of each client. Extensive experiments demonstrate that for both
regression and classification tasks, our scheme achieves the same accuracy as
non-private approaches and outperforms the state-of-the-art HE-based scheme.
Besides, training time of our scheme is almost the same as non-private
approaches and much more efficient than HE-based schemes. Our scheme trains a
$9$-layer neural network on the MNIST dataset in less than one hour.
</p>
<a href="http://arxiv.org/abs/2002.09843" target="_blank">arXiv:2002.09843</a> [<a href="http://arxiv.org/pdf/2002.09843" target="_blank">pdf</a>]

<h2>Anatomy-aware 3D Human Pose Estimation in Videos. (arXiv:2002.10322v4 [cs.CV] UPDATED)</h2>
<h3>Tianlang Chen, Chen Fang, Xiaohui Shen, Yiheng Zhu, Zhili Chen, Jiebo Luo</h3>
<p>In this work, we propose a new solution for 3D human pose estimation in
videos. Instead of directly regressing the 3D joint locations, we draw
inspiration from the human skeleton anatomy and decompose the task into bone
direction prediction and bone length prediction, from which the 3D joint
locations can be completely derived. Our motivation is the fact that the bone
lengths of a human skeleton remain consistent across time. This promotes us to
develop effective techniques to utilize global information across {\it all} the
frames in a video for high-accuracy bone length prediction. Moreover, for the
bone direction prediction network, we propose a fully-convolutional propagating
architecture with long skip connections. Essentially, it predicts the
directions of different bones hierarchically without using any time-consuming
memory units (e.g. LSTM). A novel joint shift loss is further introduced to
bridge the training of the bone length and bone direction prediction networks.
Finally, we employ an implicit attention mechanism to feed the 2D keypoint
visibility scores into the model as extra guidance, which significantly
mitigates the depth ambiguity in many challenging poses. Our full model
outperforms the previous best results on Human3.6M and MPI-INF-3DHP datasets,
where comprehensive evaluation validates the effectiveness of our model.
</p>
<a href="http://arxiv.org/abs/2002.10322" target="_blank">arXiv:2002.10322</a> [<a href="http://arxiv.org/pdf/2002.10322" target="_blank">pdf</a>]

<h2>Knowledge Graphs. (arXiv:2003.02320v5 [cs.AI] UPDATED)</h2>
<h3>Aidan Hogan, Eva Blomqvist, Michael Cochez, Claudia d&#x27;Amato, Gerard de Melo, Claudio Gutierrez, Jos&#xe9; Emilio Labra Gayo, Sabrina Kirrane, Sebastian Neumaier, Axel Polleres, Roberto Navigli, Axel-Cyrille Ngonga Ngomo, Sabbir M. Rashid, Anisa Rula, Lukas Schmelzeisen, Juan Sequeda, Steffen Staab, Antoine Zimmermann</h3>
<p>In this paper we provide a comprehensive introduction to knowledge graphs,
which have recently garnered significant attention from both industry and
academia in scenarios that require exploiting diverse, dynamic, large-scale
collections of data. After some opening remarks, we motivate and contrast
various graph-based data models and query languages that are used for knowledge
graphs. We discuss the roles of schema, identity, and context in knowledge
graphs. We explain how knowledge can be represented and extracted using a
combination of deductive and inductive techniques. We summarise methods for the
creation, enrichment, quality assessment, refinement, and publication of
knowledge graphs. We provide an overview of prominent open knowledge graphs and
enterprise knowledge graphs, their applications, and how they use the
aforementioned techniques. We conclude with high-level future research
directions for knowledge graphs.
</p>
<a href="http://arxiv.org/abs/2003.02320" target="_blank">arXiv:2003.02320</a> [<a href="http://arxiv.org/pdf/2003.02320" target="_blank">pdf</a>]

<h2>DeProCams: Simultaneous Relighting, Compensation and Shape Reconstruction for Projector-Camera Systems. (arXiv:2003.03040v2 [cs.CV] UPDATED)</h2>
<h3>Bingyao Huang, Haibin Ling</h3>
<p>Image-based relighting, projector compensation and depth/normal
reconstruction are three important tasks of projector-camera systems (ProCams)
and spatial augmented reality (SAR). Although they share a similar pipeline of
finding projector-camera image mappings, in tradition, they are addressed
independently, sometimes with different prerequisites, devices and sampling
images. In practice, this may be cumbersome for SAR applications to address
them one-by-one. In this paper, we propose a novel end-to-end trainable model
named DeProCams to explicitly learn the photometric and geometric mappings of
ProCams, and once trained, DeProCams can be applied simultaneously to the three
tasks. DeProCams explicitly decomposes the projector-camera image mappings into
three subprocesses: shading attributes estimation, rough direct light
estimation and photorealistic neural rendering. A particular challenge
addressed by DeProCams is occlusion, for which we exploit epipolar constraint
and propose a novel differentiable projector direct light mask. Thus, it can be
learned end-to-end along with the other modules. Afterwards, to improve
convergence, we apply photometric and geometric constraints such that the
intermediate results are plausible. In our experiments, DeProCams shows clear
advantages over previous arts with promising quality and meanwhile being fully
differentiable. Moreover, by solving the three tasks in a unified model,
DeProCams waives the need for additional optical devices, radiometric
calibrations and structured light.
</p>
<a href="http://arxiv.org/abs/2003.03040" target="_blank">arXiv:2003.03040</a> [<a href="http://arxiv.org/pdf/2003.03040" target="_blank">pdf</a>]

<h2>Evaluation of Rounding Functions in Nearest-Neighbor Interpolation. (arXiv:2003.06885v2 [cs.CV] UPDATED)</h2>
<h3>Olivier Rukundo</h3>
<p>A novel evaluation study of the most appropriate round function for
nearest-neighbor (NN) image interpolation is presented. Evaluated rounding
functions are selected among the five rounding rules defined by the Institute
of Electrical and Electronics Engineers (IEEE) 754-2008 standard. Both full-
and no-reference image quality assessment (IQA) metrics are used to study and
evaluate the influence of rounding functions on NN interpolation image quality.
The concept of achieved occurrences over targeted occurrences is used to
determine the percentage of achieved occurrences based on the number of test
images used. Inferential statistical analysis is applied to deduce from a small
number of images and draw a conclusion of the behavior of each rounding
function on a bigger number of images. Under the normal distribution and at the
level of confidence equals to 95%, the maximum and minimum achievable
occurrences by each evaluated rounding function are both provided based on the
inferential analysis-based experiments.
</p>
<a href="http://arxiv.org/abs/2003.06885" target="_blank">arXiv:2003.06885</a> [<a href="http://arxiv.org/pdf/2003.06885" target="_blank">pdf</a>]

<h2>Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks. (arXiv:2004.05937v6 [cs.CV] UPDATED)</h2>
<h3>Lin Wang, Kuk-Jin Yoon</h3>
<p>Deep neural models in recent years have been successful in almost every
field, including extremely complex problem statements. However, these models
are huge in size, with millions (and even billions) of parameters, thus
demanding more heavy computation power and failing to be deployed on edge
devices. Besides, the performance boost is highly dependent on redundant
labeled data. To achieve faster speeds and to handle the problems caused by the
lack of data, knowledge distillation (KD) has been proposed to transfer
information learned from one model to another. KD is often characterized by the
so-called `Student-Teacher' (S-T) learning framework and has been broadly
applied in model compression and knowledge transfer. This paper is about KD and
S-T learning, which are being actively studied in recent years. First, we aim
to provide explanations of what KD is and how/why it works. Then, we provide a
comprehensive survey on the recent progress of KD methods together with S-T
frameworks typically for vision tasks. In general, we consider some fundamental
questions that have been driving this research area and thoroughly generalize
the research progress and technical details. Additionally, we systematically
analyze the research status of KD in vision applications. Finally, we discuss
the potentials and open challenges of existing methods and prospect the future
directions of KD and S-T learning.
</p>
<a href="http://arxiv.org/abs/2004.05937" target="_blank">arXiv:2004.05937</a> [<a href="http://arxiv.org/pdf/2004.05937" target="_blank">pdf</a>]

<h2>Certifiable Robustness to Adversarial State Uncertainty in Deep Reinforcement Learning. (arXiv:2004.06496v4 [cs.LG] UPDATED)</h2>
<h3>Michael Everett, Bjorn Lutjens, Jonathan P. How</h3>
<p>Deep Neural Network-based systems are now the state-of-the-art in many
robotics tasks, but their application in safety-critical domains remains
dangerous without formal guarantees on network robustness. Small perturbations
to sensor inputs (from noise or adversarial examples) are often enough to
change network-based decisions, which was recently shown to cause an autonomous
vehicle to swerve into another lane. In light of these dangers, numerous
algorithms have been developed as defensive mechanisms from these adversarial
inputs, some of which provide formal robustness guarantees or certificates.
This work leverages research on certified adversarial robustness to develop an
online certifiably robust for deep reinforcement learning algorithms. The
proposed defense computes guaranteed lower bounds on state-action values during
execution to identify and choose a robust action under a worst-case deviation
in input space due to possible adversaries or noise. Moreover, the resulting
policy comes with a certificate of solution quality, even though the true state
and optimal action are unknown to the certifier due to the perturbations. The
approach is demonstrated on a Deep Q-Network policy and is shown to increase
robustness to noise and adversaries in pedestrian collision avoidance scenarios
and a classic control task. This work extends one of our prior works with new
performance guarantees, extensions to other RL algorithms, expanded results
aggregated across more scenarios, an extension into scenarios with adversarial
behavior, comparisons with a more computationally expensive method, and
visualizations that provide intuition about the robustness algorithm.
</p>
<a href="http://arxiv.org/abs/2004.06496" target="_blank">arXiv:2004.06496</a> [<a href="http://arxiv.org/pdf/2004.06496" target="_blank">pdf</a>]

<h2>Causal Modeling with Stochastic Confounders. (arXiv:2004.11497v4 [stat.ML] UPDATED)</h2>
<h3>Thanh Vinh Vo, Pengfei Wei, Wicher Bergsma, Tze-Yun Leong</h3>
<p>This work extends causal inference with stochastic confounders. We propose a
new approach to variational estimation for causal inference based on a
representer theorem with a random input space. We estimate causal effects
involving latent confounders that may be interdependent and time-varying from
sequential, repeated measurements in an observational study. Our approach
extends current work that assumes independent, non-temporal latent confounders,
with potentially biased estimators. We introduce a simple yet elegant algorithm
without parametric specification on model components. Our method avoids the
need for expensive and careful parameterization in deploying complex models,
such as deep neural networks, for causal inference in existing approaches. We
demonstrate the effectiveness of our approach on various benchmark temporal
datasets.
</p>
<a href="http://arxiv.org/abs/2004.11497" target="_blank">arXiv:2004.11497</a> [<a href="http://arxiv.org/pdf/2004.11497" target="_blank">pdf</a>]

<h2>Federated Transfer Learning for EEG Signal Classification. (arXiv:2004.12321v5 [cs.LG] UPDATED)</h2>
<h3>Ce Ju, Dashan Gao, Ravikiran Mane, Ben Tan, Yang Liu, Cuntai Guan</h3>
<p>The success of deep learning (DL) methods in the Brain-Computer Interfaces
(BCI) field for classification of electroencephalographic (EEG) recordings has
been restricted by the lack of large datasets. Privacy concerns associated with
EEG signals limit the possibility of constructing a large EEG-BCI dataset by
the conglomeration of multiple small ones for jointly training machine learning
models. Hence, in this paper, we propose a novel privacy-preserving DL
architecture named federated transfer learning (FTL) for EEG classification
that is based on the federated learning framework. Working with the
single-trial covariance matrix, the proposed architecture extracts common
discriminative information from multi-subject EEG data with the help of domain
adaptation techniques. We evaluate the performance of the proposed architecture
on the PhysioNet dataset for 2-class motor imagery classification. While
avoiding the actual data sharing, our FTL approach achieves 2% higher
classification accuracy in a subject-adaptive analysis. Also, in the absence of
multi-subject data, our architecture provides 6% better accuracy compared to
other state-of-the-art DL architectures.
</p>
<a href="http://arxiv.org/abs/2004.12321" target="_blank">arXiv:2004.12321</a> [<a href="http://arxiv.org/pdf/2004.12321" target="_blank">pdf</a>]

<h2>Multi-Task Learning for Dense Prediction Tasks: A Survey. (arXiv:2004.13379v3 [cs.CV] UPDATED)</h2>
<h3>Simon Vandenhende, Stamatios Georgoulis, Wouter Van Gansbeke, Marc Proesmans, Dengxin Dai, Luc Van Gool</h3>
<p>With the advent of deep learning, many dense prediction tasks, i.e. tasks
that produce pixel-level predictions, have seen significant performance
improvements. The typical approach is to learn these tasks in isolation, that
is, a separate neural network is trained for each individual task. Yet, recent
multi-task learning (MTL) techniques have shown promising results w.r.t.
performance, computations and/or memory footprint, by jointly tackling multiple
tasks through a learned shared representation. In this survey, we provide a
well-rounded view on state-of-the-art deep learning approaches for MTL in
computer vision, explicitly emphasizing on dense prediction tasks. Our
contributions concern the following. First, we consider MTL from a network
architecture point-of-view. We include an extensive overview and discuss the
advantages/disadvantages of recent popular MTL models. Second, we examine
various optimization methods to tackle the joint learning of multiple tasks. We
summarize the qualitative elements of these works and explore their
commonalities and differences. Finally, we provide an extensive experimental
evaluation across a variety of dense prediction benchmarks to examine the pros
and cons of the different methods, including both architectural and
optimization based strategies.
</p>
<a href="http://arxiv.org/abs/2004.13379" target="_blank">arXiv:2004.13379</a> [<a href="http://arxiv.org/pdf/2004.13379" target="_blank">pdf</a>]

<h2>Open Graph Benchmark: Datasets for Machine Learning on Graphs. (arXiv:2005.00687v6 [cs.LG] UPDATED)</h2>
<h3>Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, Jure Leskovec</h3>
<p>We present the Open Graph Benchmark (OGB), a diverse set of challenging and
realistic benchmark datasets to facilitate scalable, robust, and reproducible
graph machine learning (ML) research. OGB datasets are large-scale, encompass
multiple important graph ML tasks, and cover a diverse range of domains,
ranging from social and information networks to biological networks, molecular
graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a
unified evaluation protocol using meaningful application-specific data splits
and evaluation metrics. In addition to building the datasets, we also perform
extensive benchmark experiments for each dataset. Our experiments suggest that
OGB datasets present significant challenges of scalability to large-scale
graphs and out-of-distribution generalization under realistic data splits,
indicating fruitful opportunities for future research. Finally, OGB provides an
automated end-to-end graph ML pipeline that simplifies and standardizes the
process of graph data loading, experimental setup, and model evaluation. OGB
will be regularly updated and welcomes inputs from the community. OGB datasets
as well as data loaders, evaluation scripts, baseline code, and leaderboards
are publicly available at https://ogb.stanford.edu .
</p>
<a href="http://arxiv.org/abs/2005.00687" target="_blank">arXiv:2005.00687</a> [<a href="http://arxiv.org/pdf/2005.00687" target="_blank">pdf</a>]

<h2>Initializing Perturbations in Multiple Directions for Fast Adversarial Training. (arXiv:2005.07606v2 [cs.LG] UPDATED)</h2>
<h3>Xunguang Wang, Ship Peng Xu, Eric Ke Wang</h3>
<p>Recent developments in the filed of Deep Learning have demonstrated that Deep
Neural Networks(DNNs) are vulnerable to adversarial examples. Specifically, in
image classification, an adversarial example can fool the well trained deep
neural networks by adding barely imperceptible perturbations to clean images.
Adversarial Training, one of the most direct and effective methods, minimizes
the losses of perturbed-data to learn robust deep networks against adversarial
attacks. It has been proven that using the fast gradient sign method (FGSM) can
achieve Fast Adversarial Training. However, FGSM-based adversarial training may
finally obtain a failed model because of overfitting to FGSM samples. In this
paper, we proposed the Diversified Initialized Perturbations Adversarial
Training (DIP-FAT) which involves seeking the initialization of the
perturbation via enlarging the output distances of the target model in a random
directions. Due to the diversity of random directions, the embedded fast
adversarial training using FGSM increases the information from the adversary
and reduces the possibility of overfitting. In addition to preventing
overfitting, the extensive results show that our proposed DIP-FAT technique can
also improve the accuracy of the clean data. The biggest advantage of DIP-FAT
method: achieving the best banlance among clean-data, perturbed-data and
efficiency.
</p>
<a href="http://arxiv.org/abs/2005.07606" target="_blank">arXiv:2005.07606</a> [<a href="http://arxiv.org/pdf/2005.07606" target="_blank">pdf</a>]

<h2>Consistent Estimators for Learning to Defer to an Expert. (arXiv:2006.01862v3 [cs.LG] UPDATED)</h2>
<h3>Hussein Mozannar, David Sontag</h3>
<p>Learning algorithms are often used in conjunction with expert decision makers
in practical scenarios, however this fact is largely ignored when designing
these algorithms. In this paper we explore how to learn predictors that can
either predict or choose to defer the decision to a downstream expert. Given
only samples of the expert's decisions, we give a procedure based on learning a
classifier and a rejector and analyze it theoretically. Our approach is based
on a novel reduction to cost sensitive learning where we give a consistent
surrogate loss for cost sensitive learning that generalizes the cross entropy
loss. We show the effectiveness of our approach on a variety of experimental
tasks.
</p>
<a href="http://arxiv.org/abs/2006.01862" target="_blank">arXiv:2006.01862</a> [<a href="http://arxiv.org/pdf/2006.01862" target="_blank">pdf</a>]

<h2>Grounding Language to Autonomously-Acquired Skills via Goal Generation. (arXiv:2006.07185v3 [cs.AI] UPDATED)</h2>
<h3>Ahmed Akakzia, C&#xe9;dric Colas, Pierre-Yves Oudeyer, Mohamed Chetouani, Olivier Sigaud</h3>
<p>We are interested in the autonomous acquisition of repertoires of skills.
Language-conditioned reinforcement learning (LC-RL) approaches are great tools
in this quest, as they allow to express abstract goals as sets of constraints
on the states. However, most LC-RL agents are not autonomous and cannot learn
without external instructions and feedback. Besides, their direct language
condition cannot account for the goal-directed behavior of pre-verbal infants
and strongly limits the expression of behavioral diversity for a given language
input. To resolve these issues, we propose a new conceptual approach to
language-conditioned RL: the Language-Goal-Behavior architecture (LGB). LGB
decouples skill learning and language grounding via an intermediate semantic
representation of the world. To showcase the properties of LGB, we present a
specific implementation called DECSTR. DECSTR is an intrinsically motivated
learning agent endowed with an innate semantic representation describing
spatial relations between physical objects. In a first stage (G -&gt; B), it
freely explores its environment and targets self-generated semantic
configurations. In a second stage (L -&gt; G), it trains a language-conditioned
goal generator to generate semantic goals that match the constraints expressed
in language-based inputs. We showcase the additional properties of LGB w.r.t.
both an end-to-end LC-RL approach and a similar approach leveraging
non-semantic, continuous intermediate representations. Intermediate semantic
representations help satisfy language commands in a diversity of ways, enable
strategy switching after a failure and facilitate language grounding.
</p>
<a href="http://arxiv.org/abs/2006.07185" target="_blank">arXiv:2006.07185</a> [<a href="http://arxiv.org/pdf/2006.07185" target="_blank">pdf</a>]

<h2>Multiple Video Frame Interpolation via Enhanced Deformable Separable Convolution. (arXiv:2006.08070v2 [cs.CV] UPDATED)</h2>
<h3>Xianhang Cheng, Zhenzhong Chen</h3>
<p>Generating non-existing frames from a consecutive video sequence has been an
interesting and challenging problem in the video processing field. Typical
kernel-based interpolation methods predict pixels with a single convolution
process that convolves source frames with spatially adaptive local kernels,
which circumvents the time-consuming, explicit motion estimation in the form of
optical flow. However, when scene motion is larger than the pre-defined kernel
size, these methods are prone to yield less plausible results. In addition,
they cannot directly generate a frame at an arbitrary temporal position because
the learned kernels are tied to the midpoint in time between the input frames.
In this paper, we try to solve these problems and propose a novel non-flow
kernel-based approach that we refer to as enhanced deformable separable
convolution (EDSC) to estimate not only adaptive kernels, but also offsets,
masks and biases to make the network obtain information from non-local
neighborhood. During the learning process, different intermediate time step can
be involved as a control variable by means of an extension of coord-conv trick,
allowing the estimated components to vary with different input temporal
information. This makes our method capable to produce multiple in-between
frames. Furthermore, we investigate the relationships between our method and
other typical kernel- and flow-based methods. Experimental results show that
our method performs favorably against the state-of-the-art methods across a
broad range of datasets. Code will be publicly available on URL:
\url{https://github.com/Xianhang/EDSC-pytorch}.
</p>
<a href="http://arxiv.org/abs/2006.08070" target="_blank">arXiv:2006.08070</a> [<a href="http://arxiv.org/pdf/2006.08070" target="_blank">pdf</a>]

<h2>Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. (arXiv:2006.12655v3 [cs.LG] UPDATED)</h2>
<h3>Cassidy Laidlaw, Sahil Singla, Soheil Feizi</h3>
<p>A key challenge in adversarial robustness is the lack of a precise
mathematical characterization of human perception, used in the very definition
of adversarial attacks that are imperceptible to human eyes. Most current
attacks and defenses try to avoid this issue by considering restrictive
adversarial threat models such as those bounded by $L_2$ or $L_\infty$
distance, spatial perturbations, etc. However, models that are robust against
any of these restrictive threat models are still fragile against other threat
models. To resolve this issue, we propose adversarial training against the set
of all imperceptible adversarial examples, approximated using deep neural
networks. We call this threat model the neural perceptual threat model (NPTM);
it includes adversarial examples with a bounded neural perceptual distance (a
neural network-based approximation of the true perceptual distance) to natural
images. Through an extensive perceptual study, we show that the neural
perceptual distance correlates well with human judgements of perceptibility of
adversarial examples, validating our threat model.

Under the NPTM, we develop novel perceptual adversarial attacks and defenses.
Because the NPTM is very broad, we find that Perceptual Adversarial Training
(PAT) against a perceptual attack gives robustness against many other types of
adversarial attacks. We test PAT on CIFAR-10 and ImageNet-100 against five
diverse adversarial attacks. We find that PAT achieves state-of-the-art
robustness against the union of these five attacks, more than doubling the
accuracy over the next best model, without training against any of them. That
is, PAT generalizes well to unforeseen perturbation types. This is vital in
sensitive applications where a particular threat model cannot be assumed, and
to the best of our knowledge, PAT is the first adversarial defense with this
property.
</p>
<a href="http://arxiv.org/abs/2006.12655" target="_blank">arXiv:2006.12655</a> [<a href="http://arxiv.org/pdf/2006.12655" target="_blank">pdf</a>]

<h2>Learning Task-General Representations with Generative Neuro-Symbolic Modeling. (arXiv:2006.14448v2 [cs.AI] UPDATED)</h2>
<h3>Reuben Feinman, Brenden M. Lake</h3>
<p>People can learn rich, general-purpose conceptual representations from only
raw perceptual inputs. Current machine learning approaches fall well short of
these human standards, although different modeling traditions often have
complementary strengths. Symbolic models can capture the compositional and
causal knowledge that enables flexible generalization, but they struggle to
learn from raw inputs, relying on strong abstractions and simplifying
assumptions. Neural network models can learn directly from raw data, but they
struggle to capture compositional and causal structure and typically must
retrain to tackle new tasks. We bring together these two traditions to learn
generative models of concepts that capture rich compositional and causal
structure, while learning from raw data. We develop a generative neuro-symbolic
(GNS) model of handwritten character concepts that uses the control flow of a
probabilistic program, coupled with symbolic stroke primitives and a symbolic
image renderer, to represent the causal and compositional processes by which
characters are formed. The distributions of parts (strokes), and correlations
between parts, are modeled with neural network subroutines, allowing the model
to learn directly from raw data and express nonparametric statistical
relationships. We apply our model to the Omniglot challenge of human-level
concept learning, using a background set of alphabets to learn an expressive
prior distribution over character drawings. In a subsequent evaluation, our GNS
model uses probabilistic inference to learn rich conceptual representations
from a single training image that generalize to 4 unique tasks, succeeding
where previous work has fallen short.
</p>
<a href="http://arxiv.org/abs/2006.14448" target="_blank">arXiv:2006.14448</a> [<a href="http://arxiv.org/pdf/2006.14448" target="_blank">pdf</a>]

<h2>Level Set Stereo for Cooperative Grouping with Occlusion. (arXiv:2006.16094v2 [cs.CV] UPDATED)</h2>
<h3>Jialiang Wang, Todd Zickler</h3>
<p>Localizing stereo boundaries is difficult because matching cues are absent in
the adjacent occluded regions. We introduce an energy and level-set optimizer
that improves boundaries by encoding the geometry of occlusions in stereo
images that are rectified: the spatial extent of an occlusion must equal the
amplitude of the disparity jump that causes it. Focusing on two-layer,
figure-ground scenes, we implement the optimizer cooperatively, using messages
that pass predominantly between parents and children in an undecimated
hierarchy of multi-scale image patches. In a collection of figure-ground scenes
from Middlebury and Falling Things stereo datasets, the model provides more
accurate boundaries than previous occlusion-handling stereo techniques.
</p>
<a href="http://arxiv.org/abs/2006.16094" target="_blank">arXiv:2006.16094</a> [<a href="http://arxiv.org/pdf/2006.16094" target="_blank">pdf</a>]

<h2>Diagnostic Uncertainty Calibration: Towards Reliable Machine Predictions in Medical Domain. (arXiv:2007.01659v3 [stat.ML] UPDATED)</h2>
<h3>Takahiro Mimori, Keiko Sasada, Hirotaka Matsui, Issei Sato</h3>
<p>We propose an evaluation framework for class probability estimates (CPEs) in
the presence of label uncertainty, which is commonly observed as diagnosis
disagreement between experts in the medical domain. We also formalize
evaluation metrics for higher-order statistics, including inter-rater
disagreement, to assess predictions on label uncertainty. Moreover, we propose
a novel post-hoc method called $alpha$-calibration, that equips neural network
classifiers with calibrated distributions over CPEs. Using synthetic
experiments and a large-scale medical imaging application, we show that our
approach significantly enhances the reliability of uncertainty estimates:
disagreement probabilities and posterior CPEs.
</p>
<a href="http://arxiv.org/abs/2007.01659" target="_blank">arXiv:2007.01659</a> [<a href="http://arxiv.org/pdf/2007.01659" target="_blank">pdf</a>]

<h2>SmaAt-UNet: Precipitation Nowcasting using a Small Attention-UNet Architecture. (arXiv:2007.04417v2 [cs.LG] UPDATED)</h2>
<h3>Kevin Trebing, Tomasz Stanczyk, Siamak Mehrkanoon</h3>
<p>Weather forecasting is dominated by numerical weather prediction that tries
to model accurately the physical properties of the atmosphere. A downside of
numerical weather prediction is that it is lacking the ability for short-term
forecasts using the latest available information. By using a data-driven neural
network approach we show that it is possible to produce an accurate
precipitation nowcast. To this end, we propose SmaAt-UNet, an efficient
convolutional neural networks-based on the well known UNet architecture
equipped with attention modules and depthwise-separable convolutions. We
evaluate our approaches on a real-life datasets using precipitation maps from
the region of the Netherlands and binary images of cloud coverage of France.
The experimental results show that in terms of prediction performance, the
proposed model is comparable to other examined models while only using a
quarter of the trainable parameters.
</p>
<a href="http://arxiv.org/abs/2007.04417" target="_blank">arXiv:2007.04417</a> [<a href="http://arxiv.org/pdf/2007.04417" target="_blank">pdf</a>]

<h2>Multimodal price prediction. (arXiv:2007.05056v3 [cs.CV] UPDATED)</h2>
<h3>Aidin Zehtab-Salmasi, Ali-Reza Feizi-Derakhshi, Narjes Nikzad-Khasmakhi, Meysam Asgari-Chenaghlu, Saeideh Nabipour</h3>
<p>Valorization is one of the most heated discussions in the business community,
and commodities valorization is one subset in this task. Features of a product
is an essential characteristic in valorization and features are categorized
into two classes: graphical and non-graphical. Nowadays, the value of products
is measured by price. The goal of this research is to achieve an arrangement to
predict the price of a product based on specifications of that. We propose five
deep learning models to predict the price range of a product, one unimodal and
four multimodal systems. The multimodal methods predict based on the image and
non-graphical specification of product. As a platform to evaluate the methods,
a cellphones dataset has been gathered from GSMArena. In proposed methods,
convolutional neural network is an infrastructure. The experimental results
show 88.3% F1-score in the best method.
</p>
<a href="http://arxiv.org/abs/2007.05056" target="_blank">arXiv:2007.05056</a> [<a href="http://arxiv.org/pdf/2007.05056" target="_blank">pdf</a>]

<h2>SpaceNet: Make Free Space For Continual Learning. (arXiv:2007.07617v2 [cs.LG] UPDATED)</h2>
<h3>Ghada Sokar, Decebal Constantin Mocanu, Mykola Pechenizkiy</h3>
<p>The continual learning (CL) paradigm aims to enable neural networks to learn
tasks continually in a sequential fashion. The fundamental challenge in this
learning paradigm is catastrophic forgetting previously learned tasks when the
model is optimized for a new task, especially when their data is not
accessible. Current architectural-based methods aim at alleviating the
catastrophic forgetting problem but at the expense of expanding the capacity of
the model. Regularization-based methods maintain a fixed model capacity;
however, previous studies showed the huge performance degradation of these
methods when the task identity is not available during inference (e.g. class
incremental learning scenario). In this work, we propose a novel
architectural-based method referred as SpaceNet for class incremental learning
scenario where we utilize the available fixed capacity of the model
intelligently. SpaceNet trains sparse deep neural networks from scratch in an
adaptive way that compresses the sparse connections of each task in a compact
number of neurons. The adaptive training of the sparse connections results in
sparse representations that reduce the interference between the tasks.
Experimental results show the robustness of our proposed method against
catastrophic forgetting old tasks and the efficiency of SpaceNet in utilizing
the available capacity of the model, leaving space for more tasks to be
learned. In particular, when SpaceNet is tested on the well-known benchmarks
for CL: split MNIST, split Fashion-MNIST, and CIFAR-10/100, it outperforms
regularization-based methods by a big performance gap. Moreover, it achieves
better performance than architectural-based methods without model expansion and
achieved comparable results with rehearsal-based methods, while offering a huge
memory reduction.
</p>
<a href="http://arxiv.org/abs/2007.07617" target="_blank">arXiv:2007.07617</a> [<a href="http://arxiv.org/pdf/2007.07617" target="_blank">pdf</a>]

<h2>The multilayer random dot product graph. (arXiv:2007.10455v3 [stat.ML] UPDATED)</h2>
<h3>Andrew Jones, Patrick Rubin-Delanchy</h3>
<p>We present a comprehensive extension of the latent position network model
known as the random dot product graph to accommodate multiple graphs -- both
undirected and directed -- which share a common subset of nodes, and propose a
method for jointly embedding the associated adjacency matrices, or submatrices
thereof, into a suitable latent space. Theoretical results concerning the
asymptotic behaviour of the node representations thus obtained are established,
showing that after the application of a linear transformation these converge
uniformly in the Euclidean norm to the latent positions with Gaussian error.
Within this framework, we present a generalisation of the stochastic block
model to a number of different multiple graph settings, and demonstrate the
effectiveness of our joint embedding method through several statistical
inference tasks in which we achieve comparable or better results than rival
spectral methods. Empirical improvements in link prediction over single graph
embeddings are exhibited in a cyber-security example.
</p>
<a href="http://arxiv.org/abs/2007.10455" target="_blank">arXiv:2007.10455</a> [<a href="http://arxiv.org/pdf/2007.10455" target="_blank">pdf</a>]

<h2>MathNet: Haar-Like Wavelet Multiresolution-Analysis for Graph Representation and Learning. (arXiv:2007.11202v2 [cs.LG] UPDATED)</h2>
<h3>Xuebin Zheng, Bingxin Zhou, Ming Li, Yu Guang Wang, Junbin Gao</h3>
<p>Graph Neural Networks (GNNs) have recently caught great attention and
achieved significant progress in graph-level applications. In this paper, we
propose a framework for graph neural networks with multiresolution Haar-like
wavelets, or MathNet, with interrelated convolution and pooling strategies. The
underlying method takes graphs in different structures as input and assembles
consistent graph representations for readout layers, which then accomplishes
label prediction. To achieve this, the multiresolution graph representations
are first constructed and fed into graph convolutional layers for processing.
The hierarchical graph pooling layers are then involved to downsample graph
resolution while simultaneously remove redundancy within graph signals. The
whole workflow could be formed with a multi-level graph analysis, which not
only helps embed the intrinsic topological information of each graph into the
GNN, but also supports fast computation of forward and adjoint graph
transforms. We show by extensive experiments that the proposed framework
obtains notable accuracy gains on graph classification and regression tasks
with performance stability. The proposed MathNet outperforms various existing
GNN models, especially on big data sets.
</p>
<a href="http://arxiv.org/abs/2007.11202" target="_blank">arXiv:2007.11202</a> [<a href="http://arxiv.org/pdf/2007.11202" target="_blank">pdf</a>]

<h2>A Lifelong Learning Approach to Mobile Robot Navigation. (arXiv:2007.14486v4 [cs.RO] UPDATED)</h2>
<h3>Bo Liu, Xuesu Xiao, Peter Stone</h3>
<p>This paper presents a self-improving lifelong learning framework for a mobile
robot navigating in different environments. Classical static navigation methods
require environment-specific in-situ system adjustment, e.g. from human
experts, or may repeat their mistakes regardless of how many times they have
navigated in the same environment. Having the potential to improve with
experience, learning-based navigation is highly dependent on access to training
resources, e.g. sufficient memory and fast computation, and is prone to
forgetting previously learned capability, especially when facing different
environments. In this work, we propose Lifelong Learning for Navigation (LLfN)
which (1) improves a mobile robot's navigation behavior purely based on its own
experience, and (2) retains the robot's capability to navigate in previous
environments after learning in new ones. LLfN is implemented and tested
entirely onboard a physical robot with a limited memory and computation budget.
</p>
<a href="http://arxiv.org/abs/2007.14486" target="_blank">arXiv:2007.14486</a> [<a href="http://arxiv.org/pdf/2007.14486" target="_blank">pdf</a>]

<h2>The Exact Asymptotic Form of Bayesian Generalization Error in Latent Dirichlet Allocation. (arXiv:2008.01304v2 [stat.ML] UPDATED)</h2>
<h3>Naoki Hayashi</h3>
<p>Latent Dirichlet allocation (LDA) obtains essential information from data by
using Bayesian inference. It is applied to knowledge discovery via dimension
reducing and clustering in many fields. However, its generalization error had
not been yet clarified since it is a singular statistical model where there is
no one-to-one mapping from parameters to probability distributions. In this
paper, we give the exact asymptotic form of its generalization error and
marginal likelihood, by theoretical analysis of its learning coefficient using
algebraic geometry. The theoretical result shows that the Bayesian
generalization error in LDA is expressed in terms of that in matrix
factorization and a penalty from the simplex restriction of LDA's parameter
region. A numerical experiment is consistent to the theoretical result.
</p>
<a href="http://arxiv.org/abs/2008.01304" target="_blank">arXiv:2008.01304</a> [<a href="http://arxiv.org/pdf/2008.01304" target="_blank">pdf</a>]

<h2>Deep neural networks adapt to intrinsic dimensionality beyond the target domain. (arXiv:2008.02545v2 [stat.ML] UPDATED)</h2>
<h3>Alexander Cloninger, Timo Klock</h3>
<p>We study the approximation of two-layer compositions $f(x) = g(\phi(x))$ via
deep networks with ReLU activation, where $\phi$ is a geometrically intuitive,
dimensionality reducing feature map. We focus on two intuitive and practically
relevant choices for $\phi$: the projection onto a low-dimensional embedded
submanifold and a distance to a collection of low-dimensional sets. We achieve
near optimal approximation rates, which depend only on the complexity of the
dimensionality reducing map $\phi$ rather than the ambient dimension. Since
$\phi$ encapsulates all nonlinear features that are material to the function
$f$, this suggests that deep nets are faithful to an intrinsic dimension
governed by $f$ rather than the complexity of the domain of $f$. In particular,
the prevalent assumption of approximating functions on low-dimensional
manifolds can be significantly relaxed using functions of type $f(x) =
g(\phi(x))$ with $\phi$ representing an orthogonal projection onto the same
manifold.
</p>
<a href="http://arxiv.org/abs/2008.02545" target="_blank">arXiv:2008.02545</a> [<a href="http://arxiv.org/pdf/2008.02545" target="_blank">pdf</a>]

<h2>Polyth-Net: Classification of Polythene Bags for Garbage Segregation Using Deep Learning. (arXiv:2008.07592v4 [cs.CV] UPDATED)</h2>
<h3>Divyansh Singh</h3>
<p>Polythene has always been a threat to the environment since its invention. It
is non-biodegradable and very difficult to recycle. Even after many awareness
campaigns and practices, Separation of polythene bags from waste has been a
challenge for human civilization. The primary method of segregation deployed is
manual handpicking, which causes a dangerous health hazards to the workers and
is also highly inefficient due to human errors. In this paper I have designed
and researched on image-based classification of polythene bags using a
deep-learning model and its efficiency. This paper focuses on the architecture
and statistical analysis of its performance on the data set as well as problems
experienced in the classification. It also suggests a modified loss function to
specifically detect polythene irrespective of its individual features. It aims
to help the current environment protection endeavours and save countless lives
lost to the hazards caused by current methods.
</p>
<a href="http://arxiv.org/abs/2008.07592" target="_blank">arXiv:2008.07592</a> [<a href="http://arxiv.org/pdf/2008.07592" target="_blank">pdf</a>]

<h2>NATS-Bench: Benchmarking NAS Algorithms for Architecture Topology and Size. (arXiv:2009.00437v5 [cs.LG] UPDATED)</h2>
<h3>Xuanyi Dong, Lu Liu, Katarzyna Musial, Bogdan Gabrys</h3>
<p>Neural architecture search (NAS) has attracted a lot of attention and has
been illustrated to bring tangible benefits in a large number of applications
in the past few years. Architecture topology and architecture size have been
regarded as two of the most important aspects for the performance of deep
learning models and the community has spawned lots of searching algorithms for
both aspects of the neural architectures. However, the performance gain from
these searching algorithms is achieved under different search spaces and
training setups. This makes the overall performance of the algorithms to some
extent incomparable and the improvement from a sub-module of the searching
model unclear. In this paper, we propose NATS-Bench, a unified benchmark on
searching for both topology and size, for (almost) any up-to-date NAS
algorithm. NATS-Bench includes the search space of 15,625 neural cell
candidates for architecture topology and 32,768 for architecture size on three
datasets. We analyse the validity of our benchmark in terms of various criteria
and performance comparison of all candidates in the search space. We also show
the versatility of NATS-Bench by benchmarking 13 recent state-of-the-art NAS
algorithms on it. All logs and diagnostic information trained using the same
setup for each candidate are provided. This facilitates a much larger community
of researchers to focus on developing better NAS algorithms in a more
comparable and computationally cost friendly environment. All codes are
publicly available at: https://xuanyidong.com/assets/projects/NATS-Bench .
</p>
<a href="http://arxiv.org/abs/2009.00437" target="_blank">arXiv:2009.00437</a> [<a href="http://arxiv.org/pdf/2009.00437" target="_blank">pdf</a>]

<h2>SwarmCCO: Probabilistic Reactive Collision Avoidance for Quadrotor Swarms under Uncertainty. (arXiv:2009.07894v3 [cs.RO] UPDATED)</h2>
<h3>Senthil Hariharan Arul, Dinesh Manocha</h3>
<p>We present decentralized collision avoidance algorithms for quadrotor swarms
operating under uncertain state estimation. Our approach exploits the
differential flatness property and feedforward linearization to approximate the
quadrotor dynamics and performs reciprocal collision avoidance. We account for
the uncertainty in position and velocity by formulating the collision
constraints as chance constraints, which describe a set of velocities that
avoid collisions with a specified confidence level. We present two different
methods for formulating and solving the chance constraints: our first method
assumes a Gaussian noise distribution. Our second method is its extension to
the non-Gaussian case by using a Gaussian Mixture Model (GMM). We reformulate
the linear chance constraints into equivalent deterministic constraints, which
are used with an MPC framework to compute a local collision-free trajectory for
each quadrotor. We evaluate the proposed algorithm in simulations on benchmark
scenarios and highlight its benefits over prior methods. We observe that both
the Gaussian and non-Gaussian methods provide improved collision avoidance
performance over the deterministic method. On average, the Gaussian method
requires ~5ms to compute a local collision-free trajectory, while our
non-Gaussian method is computationally more expensive and requires ~9ms on
average in scenarios with 4 agents.
</p>
<a href="http://arxiv.org/abs/2009.07894" target="_blank">arXiv:2009.07894</a> [<a href="http://arxiv.org/pdf/2009.07894" target="_blank">pdf</a>]

<h2>BNAS-v2: Memory-efficient and Performance-collapse-prevented Broad Neural Architecture Search. (arXiv:2009.08886v4 [cs.CV] UPDATED)</h2>
<h3>Zixiang Ding, Yaran Chen, Nannan Li, Dongbin Zhao</h3>
<p>In this paper, we propose BNAS-v2 to further improve the efficiency of NAS,
embodying both superiorities of BCNN simultaneously. To mitigate the unfair
training issue of BNAS, we employ continuous relaxation strategy to make each
edge of cell in BCNN relevant to all candidate operations for
over-parameterized BCNN construction. Moreover, the continuous relaxation
strategy relaxes the choice of a candidate operation as a softmax over all
predefined operations. Consequently, BNAS-v2 employs the gradient-based
optimization algorithm to simultaneously update every possible path of
over-parameterized BCNN, rather than the single sampled one as BNAS. However,
continuous relaxation leads to another issue named performance collapse, in
which those weight-free operations are prone to be selected by the search
strategy. For this consequent issue, two solutions are given: 1) we propose
Confident Learning Rate (CLR) that considers the confidence of gradient for
architecture weights update, increasing with the training time of
over-parameterized BCNN; 2) we introduce the combination of partial channel
connections and edge normalization that also can improve the memory efficiency
further. Moreover, we denote differentiable BNAS (i.e. BNAS with continuous
relaxation) as BNAS-D, BNAS-D with CLR as BNAS-v2-CLR, and partial-connected
BNAS-D as BNAS-v2-PC. Experimental results on CIFAR-10 and ImageNet show that
1) BNAS-v2 delivers state-of-the-art search efficiency on both CIFAR-10 (0.05
GPU days that is 4x faster than BNAS) and ImageNet (0.19 GPU days); and 2) the
proposed CLR is effective to alleviate the performance collapse issue in both
BNAS-D and vanilla differentiable NAS framework.
</p>
<a href="http://arxiv.org/abs/2009.08886" target="_blank">arXiv:2009.08886</a> [<a href="http://arxiv.org/pdf/2009.08886" target="_blank">pdf</a>]

<h2>OWL2Vec*: Embedding of OWL Ontologies. (arXiv:2009.14654v2 [cs.AI] UPDATED)</h2>
<h3>Jiaoyan Chen, Pan Hu, Ernesto Jimenez-Ruiz, Ole Magnus Holter, Denvar Antonyrajah, Ian Horrocks</h3>
<p>Semantic embedding of knowledge graphs has been widely studied and used for
prediction and statistical analysis tasks across various domains such as
Natural Language Processing and the Semantic Web. However, less attention has
been paid to developing robust methods for embedding OWL (Web Ontology
Language) ontologies which can express a much wider range of semantics than
knowledge graphs and have been widely adopted in domains such as
bioinformatics. In this paper, we propose a random walk and word embedding
based ontology embedding method named OWL2Vec*, which encodes the semantics of
an OWL ontology by taking into account its graph structure, lexical information
and logical constructors. Our empirical evaluation with three real world
datasets suggests that OWL2Vec* benefits from these three different aspects of
an ontology in class membership prediction and class subsumption prediction
tasks. Furthermore, OWL2Vec* often significantly outperforms the
state-of-the-art methods in our experiments.
</p>
<a href="http://arxiv.org/abs/2009.14654" target="_blank">arXiv:2009.14654</a> [<a href="http://arxiv.org/pdf/2009.14654" target="_blank">pdf</a>]

<h2>Contrastive Learning with Hard Negative Samples. (arXiv:2010.04592v2 [cs.LG] UPDATED)</h2>
<h3>Joshua Robinson, Ching-Yao Chuang, Suvrit Sra, Stefanie Jegelka</h3>
<p>How can you sample good negative examples for contrastive learning? We argue
that, as with metric learning, contrastive learning of representations benefits
from hard negative samples (i.e., points that are difficult to distinguish from
an anchor point). The key challenge toward using hard negatives is that
contrastive methods must remain unsupervised, making it infeasible to adopt
existing negative sampling strategies that use true similarity information. In
response, we develop a new family of unsupervised sampling methods for
selecting hard negative samples where the user can control the hardness. A
limiting case of this sampling results in a representation that tightly
clusters each class, and pushes different classes as far apart as possible. The
proposed method improves downstream performance across multiple modalities,
requires only few additional lines of code to implement, and introduces no
computational overhead.
</p>
<a href="http://arxiv.org/abs/2010.04592" target="_blank">arXiv:2010.04592</a> [<a href="http://arxiv.org/pdf/2010.04592" target="_blank">pdf</a>]

<h2>Light Field Salient Object Detection: A Review and Benchmark. (arXiv:2010.04968v3 [cs.CV] UPDATED)</h2>
<h3>Yao Jiang, Tao Zhou, Ge-Peng Ji, Keren Fu, Qijun Zhao, Deng-Ping Fan</h3>
<p>Salient object detection (SOD) is a long-standing research topic in computer
vision and has drawn an increasing amount of research interest in the past
decade. This paper provides the first comprehensive review and benchmark for
light field SOD, which has long been lacking in the saliency community.
Firstly, we introduce preliminary knowledge on light fields, including theory
and data forms, and then review existing studies on light field SOD, covering
ten traditional models, seven deep learning-based models, one comparative
study, and one brief review. Existing datasets for light field SOD are also
summarized with detailed information and statistical analyses. Secondly, we
benchmark seven representative light field SOD models together with several
cutting-edge RGB-D SOD models on four widely used light field datasets, from
which insightful discussions and analyses, including a comparison between light
field SOD and RGB-D SOD models, are achieved. Besides, due to the inconsistency
of datasets in their current forms, we further generate complete data and
supplement focal stacks, depth maps and multi-view images for the inconsistent
datasets, making them consistent and unified. Our supplemental data makes a
universal benchmark possible. Lastly, because light field SOD is quite a
special problem attributed to its diverse data representations and high
dependency on acquisition hardware, making it differ greatly from other
saliency detection tasks, we provide nine hints into the challenges and future
directions, and outline several open issues. We hope our review and
benchmarking could serve as a catalyst to advance research in this field. All
the materials including collected models, datasets, benchmarking results, and
supplemented light field datasets will be publicly available on our project
site https://github.com/kerenfu/LFSOD-Survey.
</p>
<a href="http://arxiv.org/abs/2010.04968" target="_blank">arXiv:2010.04968</a> [<a href="http://arxiv.org/pdf/2010.04968" target="_blank">pdf</a>]

<h2>Partial FC: Training 10 Million Identities on a Single Machine. (arXiv:2010.05222v2 [cs.CV] UPDATED)</h2>
<h3>Xiang An, Xuhan Zhu, Yang Xiao, Lan Wu, Ming Zhang, Yuan Gao, Bin Qin, Debing Zhang, Ying Fu</h3>
<p>Face recognition has been an active and vital topic among computer vision
community for a long time. Previous researches mainly focus on loss functions
used for facial feature extraction network, among which the improvements of
softmax-based loss functions greatly promote the performance of face
recognition. However, the contradiction between the drastically increasing
number of face identities and the shortage of GPU memories is gradually
becoming irreconcilable. In this paper, we thoroughly analyze the optimization
goal of softmax-based loss functions and the difficulty of training massive
identities. We find that the importance of negative classes in softmax function
in face representation learning is not as high as we previously thought. The
experiment demonstrates no loss of accuracy when training with only 10\%
randomly sampled classes for the softmax-based loss functions, compared with
training with full classes using state-of-the-art models on mainstream
benchmarks. We also implement a very efficient distributed sampling algorithm,
taking into account model accuracy and training efficiency, which uses only
eight NVIDIA RTX2080Ti to complete classification tasks with tens of millions
of identities. The code of this paper has been made available
https://github.com/deepinsight/insightface/tree/master/recognition/partial_fc.
</p>
<a href="http://arxiv.org/abs/2010.05222" target="_blank">arXiv:2010.05222</a> [<a href="http://arxiv.org/pdf/2010.05222" target="_blank">pdf</a>]

<h2>Federated Learning via Posterior Averaging: A New Perspective and Practical Algorithms. (arXiv:2010.05273v3 [cs.LG] UPDATED)</h2>
<h3>Maruan Al-Shedivat, Jennifer Gillenwater, Eric Xing, Afshin Rostamizadeh</h3>
<p>Federated learning is typically approached as an optimization problem, where
the goal is to minimize a global loss function by distributing computation
across client devices that possess local data and specify different parts of
the global objective. We present an alternative perspective and formulate
federated learning as a posterior inference problem, where the goal is to infer
a global posterior distribution by having client devices each infer the
posterior of their local data. While exact inference is often intractable, this
perspective provides a principled way to search for global optima in federated
settings. Further, starting with the analysis of federated quadratic
objectives, we develop a computation- and communication-efficient approximate
posterior inference algorithm -- federated posterior averaging (FedPA). Our
algorithm uses MCMC for approximate inference of local posteriors on the
clients and efficiently communicates their statistics to the server, where the
latter uses them to refine a global estimate of the posterior mode. Finally, we
show that FedPA generalizes federated averaging (FedAvg), can similarly benefit
from adaptive optimizers, and yields state-of-the-art results on four realistic
and challenging benchmarks, converging faster, to better optima.
</p>
<a href="http://arxiv.org/abs/2010.05273" target="_blank">arXiv:2010.05273</a> [<a href="http://arxiv.org/pdf/2010.05273" target="_blank">pdf</a>]

<h2>BiPointNet: Binary Neural Network for Point Clouds. (arXiv:2010.05501v2 [cs.CV] UPDATED)</h2>
<h3>Haotong Qin, Zhongang Cai, Mingyuan Zhang, Yifu Ding, Haiyu Zhao, Shuai Yi, Xianglong Liu, Hao Su</h3>
<p>To alleviate the resource constraint for real-time point cloud applications
that run on edge devices, in this paper we present BiPointNet, the first model
binarization approach for efficient deep learning on point clouds. We first
discover that the immense performance drop of binarized models for point clouds
mainly stems from two challenges: aggregation-induced feature homogenization
that leads to a degradation of information entropy, and scale distortion that
hinders optimization and invalidates scale-sensitive structures. With
theoretical justifications and in-depth analysis, our BiPointNet introduces
Entropy-Maximizing Aggregation (EMA) to modulate the distribution before
aggregation for the maximum information entropy, and Layer-wise Scale Recovery
(LSR) to efficiently restore feature representation capacity. Extensive
experiments show that BiPointNet outperforms existing binarization methods by
convincing margins, at the level even comparable with the full precision
counterpart. We highlight that our techniques are generic, guaranteeing
significant improvements on various fundamental tasks and mainstream backbones,
e.g., BiPointNet gives an impressive 14.7x speedup and 18.9x storage saving on
real-world resource-constrained devices.
</p>
<a href="http://arxiv.org/abs/2010.05501" target="_blank">arXiv:2010.05501</a> [<a href="http://arxiv.org/pdf/2010.05501" target="_blank">pdf</a>]

<h2>Information-Theoretic Bounds on Transfer Generalization Gap Based on Jensen-Shannon Divergence. (arXiv:2010.09484v4 [cs.LG] UPDATED)</h2>
<h3>Sharu Theresa Jose, Osvaldo Simeone</h3>
<p>In transfer learning, training and testing data sets are drawn from different
data distributions. The transfer generalization gap is the difference between
the population loss on the target data distribution and the training loss. The
training data set generally includes data drawn from both source and target
distributions. This work presents novel information-theoretic upper bounds on
the average transfer generalization gap that capture $(i)$ the domain shift
between the target data distribution $P'_Z$ and the source distribution $P_Z$
through a two-parameter family of generalized
$(\alpha_1,\alpha_2)$-Jensen-Shannon (JS) divergences; and $(ii)$ the
sensitivity of the transfer learner output $W$ to each individual sample of the
data set $Z_i$ via the mutual information $I(W;Z_i)$. For $\alpha_1 \in (0,1)$,
the $(\alpha_1,\alpha_2)$-JS divergence can be bounded even when the support of
$P_Z$ is not included in that of $P'_Z$. This contrasts the Kullback-Leibler
(KL) divergence $D_{KL}(P_Z||P'_Z)$-based bounds of Wu et al. [1], which are
vacuous under this assumption. Moreover, the obtained bounds hold for unbounded
loss functions with bounded cumulant generating functions, unlike the
$\phi$-divergence based bound of Wu et al. [1]. We also obtain new upper bounds
on the average transfer excess risk in terms of the $(\alpha_1,\alpha_2)$-JS
divergence for empirical weighted risk minimization (EWRM), which minimizes the
weighted average training losses over source and target data sets. Finally, we
provide a numerical example to illustrate the merits of the introduced bounds.
</p>
<a href="http://arxiv.org/abs/2010.09484" target="_blank">arXiv:2010.09484</a> [<a href="http://arxiv.org/pdf/2010.09484" target="_blank">pdf</a>]

<h2>Feature Inference Attack on Model Predictions in Vertical Federated Learning. (arXiv:2010.10152v2 [cs.LG] UPDATED)</h2>
<h3>Xinjian Luo, Yuncheng Wu, Xiaokui Xiao, Beng Chin Ooi</h3>
<p>Federated learning (FL) is an emerging paradigm for facilitating multiple
organizations' data collaboration without revealing their private data to each
other. Recently, vertical FL, where the participating organizations hold the
same set of samples but with disjoint features and only one organization owns
the labels, has received increased attention. This paper presents several
feature inference attack methods to investigate the potential privacy leakages
in the model prediction stage of vertical FL. The attack methods consider the
most stringent setting that the adversary controls only the trained vertical FL
model and the model predictions, relying on no background information. We first
propose two specific attacks on the logistic regression (LR) and decision tree
(DT) models, according to individual prediction output. We further design a
general attack method based on multiple prediction outputs accumulated by the
adversary to handle complex models, such as neural networks (NN) and random
forest (RF) models. Experimental evaluations demonstrate the effectiveness of
the proposed attacks and highlight the need for designing private mechanisms to
protect the prediction outputs in vertical FL.
</p>
<a href="http://arxiv.org/abs/2010.10152" target="_blank">arXiv:2010.10152</a> [<a href="http://arxiv.org/pdf/2010.10152" target="_blank">pdf</a>]

<h2>On Information Asymmetry in Competitive Multi-Agent Reinforcement Learning: Convergence and Optimality. (arXiv:2010.10901v2 [cs.LG] UPDATED)</h2>
<h3>Ezra Tampubolon, Haris Ceribasic, Holger Boche</h3>
<p>In this work, we study the system of interacting non-cooperative two
Q-learning agents, where one agent has the privilege of observing the other's
actions. We show that this information asymmetry can lead to a stable outcome
of population learning, which generally does not occur in an environment of
general independent learners. The resulting post-learning policies are almost
optimal in the underlying game sense, i.e., they form a Nash equilibrium.
Furthermore, we propose in this work a Q-learning algorithm, requiring
predictive observation of two subsequent opponent's actions, yielding an
optimal strategy given that the latter applies a stationary strategy, and
discuss the existence of the Nash equilibrium in the underlying information
asymmetrical game.
</p>
<a href="http://arxiv.org/abs/2010.10901" target="_blank">arXiv:2010.10901</a> [<a href="http://arxiv.org/pdf/2010.10901" target="_blank">pdf</a>]

<h2>Federated Transfer Learning: concept and applications. (arXiv:2010.15561v2 [cs.LG] UPDATED)</h2>
<h3>Sudipan Saha, Tahir Ahmad</h3>
<p>Development of Artificial Intelligence (AI) is inherently tied to the
development of data. However, in most industries data exists in form of
isolated islands, with limited scope of sharing between different
organizations. This is an hindrance to the further development of AI. Federated
learning has emerged as a possible solution to this problem in the last few
years without compromising user privacy. Among different variants of the
federated learning, noteworthy is federated transfer learning (FTL) that allows
knowledge to be transferred across domains that do not have many overlapping
features and users. In this work we provide a comprehensive survey of the
existing works on this topic. In more details, we study the background of FTL
and its different existing applications. We further analyze FTL from privacy
and machine learning perspective.
</p>
<a href="http://arxiv.org/abs/2010.15561" target="_blank">arXiv:2010.15561</a> [<a href="http://arxiv.org/pdf/2010.15561" target="_blank">pdf</a>]

<h2>Language for Description of Worlds. (arXiv:2010.16243v2 [cs.AI] UPDATED)</h2>
<h3>Dimiter Dobrev</h3>
<p>We will reduce the task of creating AI to the task of finding an appropriate
language for description of the world. This will not be a programing language
because programing languages describe only computable functions, while our
language will describe a somewhat broader class of functions. Another
specificity of this language will be that the description will consist of
separate modules. This will enable us look for the description of the world
automatically such that we discover it module after module. Our approach to the
creation of this new language will be to start with a particular world and
write the description of that particular world. The point is that the language
which can describe this particular world will be appropriate for describing any
world.
</p>
<a href="http://arxiv.org/abs/2010.16243" target="_blank">arXiv:2010.16243</a> [<a href="http://arxiv.org/pdf/2010.16243" target="_blank">pdf</a>]

<h2>General Data Analytics with Applications to Visual Information Analysis: A Provable Backward-Compatible Semisimple Paradigm over T-Algebra. (arXiv:2011.00307v6 [cs.CV] UPDATED)</h2>
<h3>Liang Liao, Stephen John Maybank</h3>
<p>We consider a novel backward-compatible paradigm of general data analytics
over a recently-reported semisimple algebra (called t-algebra). We study the
abstract algebraic framework over the t-algebra by representing the elements of
t-algebra by fix-sized multi-way arrays of complex numbers and the algebraic
structure over the t-algebra by a collection of direct-product constituents.
Over the t-algebra, many algorithms are generalized in a straightforward manner
using this new semisimple paradigm. To demonstrate the new paradigm's
performance and its backward-compatibility, we generalize some canonical
algorithms for visual pattern analysis. Experiments on public datasets show
that the generalized algorithms compare favorably with their canonical
counterparts.
</p>
<a href="http://arxiv.org/abs/2011.00307" target="_blank">arXiv:2011.00307</a> [<a href="http://arxiv.org/pdf/2011.00307" target="_blank">pdf</a>]

<h2>DebiNet: Debiasing Linear Models with Nonlinear Overparameterized Neural Networks. (arXiv:2011.00417v2 [stat.ML] UPDATED)</h2>
<h3>Shiyun Xu, Zhiqi Bu</h3>
<p>Recent years have witnessed strong empirical performance of
over-parameterized neural networks on various tasks and many advances in the
theory, e.g. the universal approximation and provable convergence to global
minimum. In this paper, we incorporate over-parameterized neural networks into
semi-parametric models to bridge the gap between inference and prediction,
especially in the high dimensional linear problem. By doing so, we can exploit
a wide class of networks to approximate the nuisance functions and to estimate
the parameters of interest consistently. Therefore, we may offer the best of
two worlds: the universal approximation ability from neural networks and the
interpretability from classic ordinary linear model, leading to both valid
inference and accurate prediction. We show the theoretical foundations that
make this possible and demonstrate with numerical experiments. Furthermore, we
propose a framework, DebiNet, in which we plug-in arbitrary feature selection
methods to our semi-parametric neural network. DebiNet can debias the
regularized estimators (e.g. Lasso) and perform well, in terms of the
post-selection inference and the generalization error.
</p>
<a href="http://arxiv.org/abs/2011.00417" target="_blank">arXiv:2011.00417</a> [<a href="http://arxiv.org/pdf/2011.00417" target="_blank">pdf</a>]

<h2>A Dilated Residual Hierarchically Fashioned Segmentation Framework for Extracting Gleason Tissues and Grading Prostate Cancer from Whole Slide Images. (arXiv:2011.00527v3 [cs.CV] UPDATED)</h2>
<h3>Taimur Hassan, Ayman El-Baz, Naoufel Werghi</h3>
<p>Prostate cancer (PCa) is the second deadliest form of cancer in males. PCa
severity can be clinically graded by examining the structural representations
of Gleason tissues. The paper proposes a framework for segmenting Gleason
tissues and grading PCa using Whole Slide Images (WSI). Our approach
encompasses two main contributions: 1) An asymmetric dilated residual
segmentation model integrating a novel hierarchical decomposition scheme to
extract textured Gleason tissues. 2) A three-tiered loss function to ensure
accurate recognition of the cluttered regions in the cancerous tissues. The
proposed framework has been extensively evaluated on a large-scale PCa dataset
containing 10,516 whole slide scans (with around 71.7M patches), where it
outperforms state-of-the-art schemes in several metrics for extracting the
Gleason tissues and grading the progression of PCa.
</p>
<a href="http://arxiv.org/abs/2011.00527" target="_blank">arXiv:2011.00527</a> [<a href="http://arxiv.org/pdf/2011.00527" target="_blank">pdf</a>]

<h2>Prediction against a limited adversary. (arXiv:2011.01217v2 [cs.LG] UPDATED)</h2>
<h3>Erhan Bayraktar, Ibrahim Ekren, Xin Zhang</h3>
<p>We study the problem of prediction with expert advice with adversarial
corruption where the adversary can at most corrupt one expert. Using tools from
viscosity theory, we characterize the long-time behavior of the value function
of the game between the forecaster and the adversary. We provide lower and
upper bounds for the growth rate of regret without relying on a comparison
result. We show that depending on the description of regret, the limiting
behavior of the game can significantly differ.
</p>
<a href="http://arxiv.org/abs/2011.01217" target="_blank">arXiv:2011.01217</a> [<a href="http://arxiv.org/pdf/2011.01217" target="_blank">pdf</a>]

<h2>Complex Query Answering with Neural Link Predictors. (arXiv:2011.03459v2 [cs.LG] UPDATED)</h2>
<h3>Erik Arakelyan, Daniel Daza, Pasquale Minervini, Michael Cochez</h3>
<p>Neural link predictors are immensely useful for identifying missing edges in
large scale Knowledge Graphs. However, it is still not clear how to use these
models for answering more complex queries that arise in a number of domains,
such as queries using logical conjunctions ($\land$), disjunctions ($\lor$) and
existential quantifiers ($\exists$), while accounting for missing edges. In
this work, we propose a framework for efficiently answering complex queries on
incomplete Knowledge Graphs. We translate each query into an end-to-end
differentiable objective, where the truth value of each atom is computed by a
pre-trained neural link predictor. We then analyse two solutions to the
optimisation problem, including gradient-based and combinatorial search. In our
experiments, the proposed approach produces more accurate results than
state-of-the-art methods -- black-box neural models trained on millions of
generated queries -- without the need of training on a large and diverse set of
complex queries. Using orders of magnitude less training data, we obtain
relative improvements ranging from 8% up to 40% in Hits@3 across different
knowledge graphs containing factual information. Finally, we demonstrate that
it is possible to explain the outcome of our model in terms of the intermediate
solutions identified for each of the complex query atoms.
</p>
<a href="http://arxiv.org/abs/2011.03459" target="_blank">arXiv:2011.03459</a> [<a href="http://arxiv.org/pdf/2011.03459" target="_blank">pdf</a>]

<h2>Impedance Optimization for Uncertain Contact Interactions Through Risk Sensitive Optimal Control. (arXiv:2011.04684v2 [cs.RO] UPDATED)</h2>
<h3>Bilal Hammoud, Majid Khadiv, Ludovic Righetti</h3>
<p>This paper addresses the problem of computing optimal impedance schedules for
legged locomotion tasks involving complex contact interactions. We formulate
the problem of impedance regulation as a trade-off between disturbance
rejection and measurement uncertainty. We extend a stochastic optimal control
algorithm known as Risk Sensitive Control to take into account measurement
uncertainty and propose a formal way to include such uncertainty for unknown
contact locations. The approach can efficiently generate optimal state and
control trajectories along with local feedback control gains, i.e. impedance
schedules. Extensive simulations demonstrate the capabilities of the approach
in generating meaningful stiffness and damping modulation patterns before and
after contact interaction. For example, contact forces are reduced during early
contacts, damping increases to anticipate a high impact event and tracking is
automatically traded-off for increased stability. In particular, we show a
significant improvement in performance during jumping and trotting tasks with a
simulated quadruped robot.
</p>
<a href="http://arxiv.org/abs/2011.04684" target="_blank">arXiv:2011.04684</a> [<a href="http://arxiv.org/pdf/2011.04684" target="_blank">pdf</a>]

<h2>Texture image classification based on a pseudo-parabolic diffusion model. (arXiv:2011.07173v2 [cs.CV] UPDATED)</h2>
<h3>Jardel Vieira, Eduardo Abreu, Joao B. Florindo</h3>
<p>This work proposes a novel method based on a pseudo-parabolic diffusion
process to be employed for texture recognition. The proposed operator is
applied over a range of time scales giving rise to a family of images
transformed by nonlinear filters. Therefore each of those images are encoded by
a local descriptor (we use local binary patterns for that purpose) and they are
summarized by a simple histogram, yielding in this way the image feature
vector. The proposed approach is tested on the classification of well
established benchmark texture databases and on a practical task of plant
species recognition. In both cases, it is compared with several
state-of-the-art methodologies employed for texture recognition. Our proposal
outperforms those methods in terms of classification accuracy, confirming its
competitiveness. The good performance can be justified to a large extent by the
ability of the pseudo-parabolic operator to smooth possibly noisy details
inside homogeneous regions of the image at the same time that it preserves
discontinuities that convey critical information for the object description.
Such results also confirm that model-based approaches like the proposed one can
still be competitive with the omnipresent learning-based approaches, especially
when the user does not have access to a powerful computational structure and a
large amount of labeled data for training.
</p>
<a href="http://arxiv.org/abs/2011.07173" target="_blank">arXiv:2011.07173</a> [<a href="http://arxiv.org/pdf/2011.07173" target="_blank">pdf</a>]

<h2>CcGAN: Continuous Conditional Generative Adversarial Networks for Image Generation. (arXiv:2011.07466v3 [cs.CV] UPDATED)</h2>
<h3>Xin Ding, Yongwei Wang, Zuheng Xu, William J. Welch, Z. Jane Wang</h3>
<p>This work proposes the continuous conditional generative adversarial network
(CcGAN), the first generative model for image generation conditional on
continuous, scalar conditions (termed regression labels). Existing conditional
GANs (cGANs) are mainly designed for categorical conditions (e.g., class
labels); conditioning on regression labels is mathematically distinct and
raises two fundamental problems: (P1) Since there may be very few (even zero)
real images for some regression labels, minimizing existing empirical versions
of cGAN losses (a.k.a. empirical cGAN losses) often fails in practice; (P2)
Since regression labels are scalar and infinitely many, conventional label
input methods (e.g., combining a hidden map of the generator/discriminator with
a one-hot encoded label) are not applicable. The proposed CcGAN solves the
above problems, respectively, by (S1) reformulating existing empirical cGAN
losses to be appropriate for the continuous scenario; and (S2) proposing a
novel method to incorporate regression labels into the generator and the
discriminator. The reformulation in (S1) leads to two novel empirical
discriminator losses, termed the hard vicinal discriminator loss (HVDL) and the
soft vicinal discriminator loss (SVDL) respectively, and a novel empirical
generator loss. The error bounds of a discriminator trained with HVDL and SVDL
are derived under mild assumptions in this work. A new benchmark dataset,
RC-49, is also proposed for generative image modeling conditional on regression
labels. Our experiments on the Circular 2-D Gaussians, RC-49, and UTKFace
datasets show that CcGAN is able to generate diverse, high-quality samples from
the image distribution conditional on a given regression label. Moreover, in
these experiments, CcGAN substantially outperforms cGAN both visually and
quantitatively.
</p>
<a href="http://arxiv.org/abs/2011.07466" target="_blank">arXiv:2011.07466</a> [<a href="http://arxiv.org/pdf/2011.07466" target="_blank">pdf</a>]

<h2>Depth-Enhanced Feature Pyramid Network for Occlusion-Aware Verification of Buildings from Oblique Images. (arXiv:2011.13226v2 [cs.CV] UPDATED)</h2>
<h3>Qing Zhu, Shengzhi Huang, Han Hu, Haifeng Li, Min Chen, Ruofei Zhong</h3>
<p>Detecting the changes of buildings in urban environments is essential.
Existing methods that use only nadir images suffer from severe problems of
ambiguous features and occlusions between buildings and other regions.
Furthermore, buildings in urban environments vary significantly in scale, which
leads to performance issues when using single-scale features. To solve these
issues, this paper proposes a fused feature pyramid network, which utilizes
both color and depth data for the 3D verification of existing buildings 2D
footprints from oblique images. First, the color data of oblique images are
enriched with the depth information rendered from 3D mesh models. Second,
multiscale features are fused in the feature pyramid network to convolve both
the color and depth data. Finally, multi-view information from both the nadir
and oblique images is used in a robust voting procedure to label changes in
existing buildings. Experimental evaluations using both the ISPRS benchmark
datasets and Shenzhen datasets reveal that the proposed method outperforms the
ResNet and EfficientNet networks by 5\% and 2\%, respectively, in terms of
recall rate and precision. We demonstrate that the proposed method can
successfully detect all changed buildings; therefore, only those marked as
changed need to be manually checked during the pipeline updating procedure;
this significantly reduces the manual quality control requirements. Moreover,
ablation studies indicate that using depth data, feature pyramid modules, and
multi-view voting strategies can lead to clear and progressive improvements.
</p>
<a href="http://arxiv.org/abs/2011.13226" target="_blank">arXiv:2011.13226</a> [<a href="http://arxiv.org/pdf/2011.13226" target="_blank">pdf</a>]

<h2>Polarization-driven Semantic Segmentation via Efficient Attention-bridged Fusion. (arXiv:2011.13313v2 [cs.CV] UPDATED)</h2>
<h3>Kaite Xiang, Kailun Yang, Kaiwei Wang</h3>
<p>Semantic Segmentation (SS) is promising for outdoor scene perception in
safety-critical applications like autonomous vehicles, assisted navigation and
so on. However, traditional SS is primarily based on RGB images, which limits
the reliability of SS in complex outdoor scenes, where RGB images lack
necessary information dimensions to fully perceive unconstrained environments.
As preliminary investigation, we examine SS in an unexpected obstacle detection
scenario, which demonstrates the necessity of multimodal fusion. Thereby, in
this work, we present EAFNet, an Efficient Attention-bridged Fusion Network to
exploit complementary information coming from different optical sensors.
Specifically, we incorporate polarization sensing to obtain supplementary
information, considering its optical characteristics for robust representation
of diverse materials. By using a single-shot polarization sensor, we build the
first RGB-P dataset which consists of 394 annotated pixel-aligned
RGB-Polarization images. A comprehensive variety of experiments shows the
effectiveness of EAFNet to fuse polarization and RGB information, as well as
the flexibility to be adapted to other sensor combination scenarios.
</p>
<a href="http://arxiv.org/abs/2011.13313" target="_blank">arXiv:2011.13313</a> [<a href="http://arxiv.org/pdf/2011.13313" target="_blank">pdf</a>]

<h2>FROCC: Fast Random projection-based One-Class Classification. (arXiv:2011.14317v2 [cs.LG] UPDATED)</h2>
<h3>Arindam Bhattacharya, Sumanth Varambally, Amitabha Bagchi, Srikanta Bedathur</h3>
<p>We present Fast Random projection-based One-Class Classification (FROCC), an
extremely efficient method for one-class classification. Our method is based on
a simple idea of transforming the training data by projecting it onto a set of
random unit vectors that are chosen uniformly and independently from the unit
sphere, and bounding the regions based on separation of the data. FROCC can be
naturally extended with kernels. We theoretically prove that FROCC generalizes
well in the sense that it is stable and has low bias. FROCC achieves up to 3.1
percent points better ROC, with 1.2--67.8x speedup in training and test times
over a range of state-of-the-art benchmarks including the SVM and the deep
learning based models for the OCC task.
</p>
<a href="http://arxiv.org/abs/2011.14317" target="_blank">arXiv:2011.14317</a> [<a href="http://arxiv.org/pdf/2011.14317" target="_blank">pdf</a>]

<h2>The Geometry and Kinematics of the Matrix Lie Group $SE_K(3)$. (arXiv:2012.00950v2 [cs.RO] UPDATED)</h2>
<h3>Yarong Luo, Mengyuan Wang, Chi Guo</h3>
<p>Currently state estimation is very important for the robotics, and the
uncertainty representation based Lie group is natural for the state estimation
problem. It is necessary to exploit the geometry and kinematic of matrix Lie
group sufficiently. Therefore, this note gives a detailed derivation of the
recently proposed matrix Lie group $SE_K(3)$ for the first time, our results
extend the results in Barfoot \cite{barfoot2017state}. Then we describe the
situations where this group is suitable for state representation. We also have
developed code based on Matlab framework for quickly implementing and testing.
</p>
<a href="http://arxiv.org/abs/2012.00950" target="_blank">arXiv:2012.00950</a> [<a href="http://arxiv.org/pdf/2012.00950" target="_blank">pdf</a>]

<h2>Self-supervised asymmetric deep hashing with margin-scalable constraint for image retrieval. (arXiv:2012.03820v2 [cs.CV] UPDATED)</h2>
<h3>Zhengyang Yu, Zhihao Dou, Erwin M.Bakker, Song Wu</h3>
<p>Due to its effectivity and efficiency, image retrieval based on deep hashing
approaches is widely used especially for large-scale visual search. However,
many existing deep hashing methods inadequately utilize label information as
guidance for feature learning networks without more advanced exploration of the
semantic space. Besides the similarity correlations in the Hamming space are
not fully discovered and embedded into hash codes, by which the retrieval
quality is diminished with inefficient preservation of pairwise correlations
and multi-label semantics. To cope with these problems, we propose a novel
self-supervised asymmetric deep hashing method with a margin-scalable
constraint(SADH) approach for image retrieval. SADH implements a
self-supervised network to preserve semantic information in a semantic feature
map and a semantic code map for the semantics of the given dataset, which
efficiently and precisely guides a feature learning network to preserve
multi-label semantic information using an asymmetric learning strategy.
Moreover, for the feature learning part, by further exploiting semantic maps, a
new margin-scalable constraint is employed for both highly-accurate
construction of pairwise correlations in the hamming space and a more
discriminative hash code representation. Extensive empirical research on three
benchmark datasets validates the proposed method and shows it outperforms
several state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2012.03820" target="_blank">arXiv:2012.03820</a> [<a href="http://arxiv.org/pdf/2012.03820" target="_blank">pdf</a>]

<h2>GAN "Steerability" without optimization. (arXiv:2012.05328v2 [cs.CV] UPDATED)</h2>
<h3>Nurit Spingarn-Eliezer, Ron Banner, Tomer Michaeli</h3>
<p>Recent research has shown remarkable success in revealing "steering"
directions in the latent spaces of pre-trained GANs. These directions
correspond to semantically meaningful image transformations e.g., shift, zoom,
color manipulations), and have similar interpretable effects across all
categories that the GAN can generate. Some methods focus on user-specified
transformations, while others discover transformations in an unsupervised
manner. However, all existing techniques rely on an optimization procedure to
expose those directions, and offer no control over the degree of allowed
interaction between different transformations. In this paper, we show that
"steering" trajectories can be computed in closed form directly from the
generator's weights without any form of training or optimization. This applies
to user-prescribed geometric transformations, as well as to unsupervised
discovery of more complex effects. Our approach allows determining both linear
and nonlinear trajectories, and has many advantages over previous methods. In
particular, we can control whether one transformation is allowed to come on the
expense of another (e.g. zoom-in with or without allowing translation to keep
the object centered). Moreover, we can determine the natural end-point of the
trajectory, which corresponds to the largest extent to which a transformation
can be applied without incurring degradation. Finally, we show how transferring
attributes between images can be achieved without optimization, even across
different categories.
</p>
<a href="http://arxiv.org/abs/2012.05328" target="_blank">arXiv:2012.05328</a> [<a href="http://arxiv.org/pdf/2012.05328" target="_blank">pdf</a>]

<h2>Theory-guided hard constraint projection (HCP): a knowledge-based data-driven scientific machine learning method. (arXiv:2012.06148v2 [cs.LG] UPDATED)</h2>
<h3>Yuntian Chen, Dou Huang, Dongxiao Zhang, Junsheng Zeng, Nanzhe Wang, Haoran Zhang, Jinyue Yan</h3>
<p>Machine learning models have been successfully used in many scientific and
engineering fields. However, it remains difficult for a model to simultaneously
utilize domain knowledge and experimental observation data. The application of
knowledge-based symbolic AI represented by an expert system is limited by the
expressive ability of the model, and data-driven connectionism AI represented
by neural networks is prone to produce predictions that violate physical
mechanisms. In order to fully integrate domain knowledge with observations, and
make full use of the prior information and the strong fitting ability of neural
networks, this study proposes theory-guided hard constraint projection (HCP).
This model converts physical constraints, such as governing equations, into a
form that is easy to handle through discretization, and then implements hard
constraint optimization through projection. Based on rigorous mathematical
proofs, theory-guided HCP can ensure that model predictions strictly conform to
physical mechanisms in the constraint patch. The performance of the
theory-guided HCP is verified by experiments based on the heterogeneous
subsurface flow problem. Due to the application of hard constraints, compared
with fully connected neural networks and soft constraint models, such as
theory-guided neural networks and physics-informed neural networks,
theory-guided HCP requires fewer data, and achieves higher prediction accuracy
and stronger robustness to noisy observations.
</p>
<a href="http://arxiv.org/abs/2012.06148" target="_blank">arXiv:2012.06148</a> [<a href="http://arxiv.org/pdf/2012.06148" target="_blank">pdf</a>]

<h2>Fork or Fail: Cycle-Consistent Training with Many-to-One Mappings. (arXiv:2012.07412v3 [cs.LG] UPDATED)</h2>
<h3>Qipeng Guo, Zhijing Jin, Ziyu Wang, Xipeng Qiu, Weinan Zhang, Jun Zhu, Zheng Zhang, David Wipf</h3>
<p>Cycle-consistent training is widely used for jointly learning a forward and
inverse mapping between two domains of interest without the cumbersome
requirement of collecting matched pairs within each domain. In this regard, the
implicit assumption is that there exists (at least approximately) a
ground-truth bijection such that a given input from either domain can be
accurately reconstructed from successive application of the respective
mappings. But in many applications no such bijection can be expected to exist
and large reconstruction errors can compromise the success of cycle-consistent
training. As one important instance of this limitation, we consider
practically-relevant situations where there exists a many-to-one or surjective
mapping between domains. To address this regime, we develop a conditional
variational autoencoder (CVAE) approach that can be viewed as converting
surjective mappings to implicit bijections whereby reconstruction errors in
both directions can be minimized, and as a natural byproduct, realistic output
diversity can be obtained in the one-to-many direction. As theoretical
motivation, we analyze a simplified scenario whereby minima of the proposed
CVAE-based energy function align with the recovery of ground-truth surjective
mappings. On the empirical side, we consider a synthetic image dataset with
known ground-truth, as well as a real-world application involving natural
language generation from knowledge graphs and vice versa, a prototypical
surjective case. For the latter, our CVAE pipeline can capture such many-to-one
mappings during cycle training while promoting textural diversity for
graph-to-text tasks. Our code is available at github.com/QipengGuo/CycleGT

*A condensed version of this paper has been accepted to AISTATS 2021. This
version contains additional content and updates.
</p>
<a href="http://arxiv.org/abs/2012.07412" target="_blank">arXiv:2012.07412</a> [<a href="http://arxiv.org/pdf/2012.07412" target="_blank">pdf</a>]

<h2>Deep Neural Networks for COVID-19 Detection and Diagnosis using Images and Acoustic-based Techniques: A Recent Review. (arXiv:2012.07655v2 [cs.CV] UPDATED)</h2>
<h3>Walid Hariri, Ali Narin</h3>
<p>The new coronavirus disease (COVID-19) has been declared a pandemic since
March 2020 by the World Health Organization. It consists of an emerging viral
infection with respiratory tropism that could develop atypical pneumonia.
Experts emphasize the importance of early detection of those who have the
COVID-19 virus. In this way, patients will be isolated from other people and
the spread of the virus can be prevented. For this reason, it has become an
area of interest to develop early diagnosis and detection methods to ensure a
rapid treatment process and prevent the virus from spreading. Since the
standard testing system is time-consuming and not available for everyone,
alternative early-screening techniques have become an urgent need. In this
study, the approaches used in the detection of COVID-19 based on deep learning
(DL) algorithms, which have been popular in recent years, have been
comprehensively discussed. The advantages and disadvantages of different
approaches used in literature are examined in detail. The Computed Tomography
of the chest and X-ray images give a rich representation of the patient's lung
that is less time-consuming and allows an efficient viral pneumonia detection
using the DL algorithms. The first step is the pre-processing of these images
to remove noise. Next, deep features are extracted using multiple types of deep
models (pre-trained models, generative models, generic neural networks, etc.).
Finally, the classification is performed using the obtained features to decide
whether the patient is infected by coronavirus or it is another lung disease.
In this study, we also give a brief review of the latest applications of cough
analysis to early screen the COVID-19, and human mobility estimation to limit
its spread.
</p>
<a href="http://arxiv.org/abs/2012.07655" target="_blank">arXiv:2012.07655</a> [<a href="http://arxiv.org/pdf/2012.07655" target="_blank">pdf</a>]

<h2>A Generalization of Transformer Networks to Graphs. (arXiv:2012.09699v2 [cs.LG] UPDATED)</h2>
<h3>Vijay Prakash Dwivedi, Xavier Bresson</h3>
<p>We propose a generalization of transformer neural network architecture for
arbitrary graphs. The original transformer was designed for Natural Language
Processing (NLP), which operates on fully connected graphs representing all
connections between the words in a sequence. Such architecture does not
leverage the graph connectivity inductive bias, and can perform poorly when the
graph topology is important and has not been encoded into the node features. We
introduce a graph transformer with four new properties compared to the standard
model. First, the attention mechanism is a function of the neighborhood
connectivity for each node in the graph. Second, the positional encoding is
represented by the Laplacian eigenvectors, which naturally generalize the
sinusoidal positional encodings often used in NLP. Third, the layer
normalization is replaced by a batch normalization layer, which provides faster
training and better generalization performance. Finally, the architecture is
extended to edge feature representation, which can be critical to tasks s.a.
chemistry (bond type) or link prediction (entity relationship in knowledge
graphs). Numerical experiments on a graph benchmark demonstrate the performance
of the proposed graph transformer architecture. This work closes the gap
between the original transformer, which was designed for the limited case of
line graphs, and graph neural networks, that can work with arbitrary graphs. As
our architecture is simple and generic, we believe it can be used as a black
box for future applications that wish to consider transformer and graphs.
</p>
<a href="http://arxiv.org/abs/2012.09699" target="_blank">arXiv:2012.09699</a> [<a href="http://arxiv.org/pdf/2012.09699" target="_blank">pdf</a>]

<h2>Deep Learning-based Prediction of Key Performance Indicators for Electrical Machine. (arXiv:2012.11299v2 [cs.LG] UPDATED)</h2>
<h3>Vivek Parekh, Dominik Flore, Sebastian Sch&#xf6;ps</h3>
<p>The design of an electrical machine can be quantified and evaluated by Key
Performance Indicators (KPIs) such as maximum torque, critical field strength,
costs of active parts, sound power, etc. Generally, cross-domain tool-chains
are used to optimize all the KPIs from different domains (multi-objective
optimization) by varying the given input parameters in the largest possible
design space. This optimization process involves magneto-static finite element
simulation to obtain these decisive KPIs. It makes the whole process a
vehemently time-consuming computational task that counts on the availability of
resources with the involvement of high computational cost. In this paper, a
data-aided, deep learning-based meta-model is employed to predict the KPIs of
an electrical machine quickly and with high accuracy to accelerate the full
optimization process and reduce its computational costs. The focus is on
analyzing various forms of input data that serve as a geometry representation
of the machine. Namely, these are the cross-section image of the electrical
machine that allows a very general description of the geometry relating to
different topologies and the classical way with scalar parametrization of
geometry. The impact of the resolution of the image is studied in detail. The
results show a high prediction accuracy and proof that the validity of a deep
learning-based meta-model to minimize the optimization time. The results also
indicate that the prediction quality of an image-based approach can be made
comparable to the classical way based on scalar parameters.
</p>
<a href="http://arxiv.org/abs/2012.11299" target="_blank">arXiv:2012.11299</a> [<a href="http://arxiv.org/pdf/2012.11299" target="_blank">pdf</a>]

<h2>A Tight Lower Bound for Uniformly Stable Algorithms. (arXiv:2012.13326v2 [cs.LG] UPDATED)</h2>
<h3>Qinghua Liu, Zhou Lu</h3>
<p>Leveraging algorithmic stability to derive sharp generalization bounds is a
classic and powerful approach in learning theory. Since Vapnik and Chervonenkis
[1974] first formalized the idea for analyzing SVMs, it has been utilized to
study many fundamental learning algorithms (e.g., $k$-nearest neighbors [Rogers
and Wagner, 1978], stochastic gradient method [Hardt et al., 2016], linear
regression [Maurer, 2017], etc). In a recent line of great works by Feldman and
Vondrak [2018, 2019] as well as Bousquet et al. [2020b], they prove a high
probability generalization upper bound of order $\tilde{\mathcal{O}}(\gamma
+\frac{L}{\sqrt{n}})$ for any uniformly $\gamma$-stable algorithm and
$L$-bounded loss function. Although much progress was achieved in proving
generalization upper bounds for stable algorithms, our knowledge of lower
bounds is rather limited. In fact, there is no nontrivial lower bound known
ever since the study of uniform stability [Bousquet and Elisseeff, 2002], to
the best of our knowledge. In this paper we fill the gap by proving a tight
generalization lower bound of order $\Omega(\gamma+\frac{L}{\sqrt{n}})$, which
matches the best known upper bound up to logarithmic factors
</p>
<a href="http://arxiv.org/abs/2012.13326" target="_blank">arXiv:2012.13326</a> [<a href="http://arxiv.org/pdf/2012.13326" target="_blank">pdf</a>]

<h2>Weighted defeasible knowledge bases and a multipreference semantics for a deep neural network model. (arXiv:2012.13421v2 [cs.AI] UPDATED)</h2>
<h3>Laura Giordano, Daniele Theseider Dupr&#xe9;</h3>
<p>In this paper we investigate the relationships between a multipreferential
semantics for defeasible reasoning in knowledge representation and a deep
neural network model. Weighted knowledge bases for description logics are
considered under a "concept-wise" multipreference semantics. The semantics is
further extended to fuzzy interpretations and exploited to provide a
preferential interpretation of Multilayer Perceptrons.
</p>
<a href="http://arxiv.org/abs/2012.13421" target="_blank">arXiv:2012.13421</a> [<a href="http://arxiv.org/pdf/2012.13421" target="_blank">pdf</a>]

<h2>Improving Adversarial Robustness in Weight-quantized Neural Networks. (arXiv:2012.14965v2 [cs.LG] UPDATED)</h2>
<h3>Chang Song, Elias Fallon, Hai Li</h3>
<p>Neural networks are getting deeper and more computation-intensive nowadays.
Quantization is a useful technique in deploying neural networks on hardware
platforms and saving computation costs with negligible performance loss.
However, recent research reveals that neural network models, no matter
full-precision or quantized, are vulnerable to adversarial attacks. In this
work, we analyze both adversarial and quantization losses and then introduce
criteria to evaluate them. We propose a boundary-based retraining method to
mitigate adversarial and quantization losses together and adopt a nonlinear
mapping method to defend against white-box gradient-based adversarial attacks.
The evaluations demonstrate that our method can better restore accuracy after
quantization than other baseline methods on both black-box and white-box
adversarial attacks. The results also show that adversarial training suffers
quantization loss and does not cooperate well with other training methods.
</p>
<a href="http://arxiv.org/abs/2012.14965" target="_blank">arXiv:2012.14965</a> [<a href="http://arxiv.org/pdf/2012.14965" target="_blank">pdf</a>]

<h2>Provident Vehicle Detection at Night: The PVDN Dataset. (arXiv:2012.15376v2 [cs.CV] UPDATED)</h2>
<h3>Lars Ohnemus, Lukas Ewecker, Ebubekir Asan, Stefan Roos, Simon Isele, Jakob Ketterer, Leopold M&#xfc;ller, Sascha Saralajew</h3>
<p>For advanced driver assistance systems, it is crucial to have information
about oncoming vehicles as early as possible. At night, this task is especially
difficult due to poor lighting conditions. For that, during nighttime, every
vehicle uses headlamps to improve sight and therefore ensure safe driving. As
humans, we intuitively assume oncoming vehicles before the vehicles are
actually physically visible by detecting light reflections caused by their
headlamps. In this paper, we present a novel dataset containing 59746 annotated
grayscale images out of 346 different scenes in a rural environment at night.
In these images, all oncoming vehicles, their corresponding light objects
(e.g., headlamps), and their respective light reflections (e.g., light
reflections on guardrails) are labeled. This is accompanied by an in-depth
analysis of the dataset characteristics. With that, we are providing the first
open-source dataset with comprehensive ground truth data to enable research
into new methods of detecting oncoming vehicles based on the light reflections
they cause, long before they are directly visible. We consider this as an
essential step to further close the performance gap between current advanced
driver assistance systems and human behavior.
</p>
<a href="http://arxiv.org/abs/2012.15376" target="_blank">arXiv:2012.15376</a> [<a href="http://arxiv.org/pdf/2012.15376" target="_blank">pdf</a>]

<h2>Super-k: A Piecewise Linear Classifier Based on Voronoi Tessellations. (arXiv:2012.15492v2 [cs.LG] UPDATED)</h2>
<h3>Rahman Salim Zengin (1), Volkan Sezer (1) ((1) Istanbul Technical University)</h3>
<p>Voronoi tessellations are used to partition the Euclidean space into
polyhedral regions, which are called Voronoi cells. Labeling the Voronoi cells
with the class information, we can map any classification problem into a
Voronoi tessellation. In this way, the classification problem changes into a
query of just finding the enclosing Voronoi cell. In order to accomplish this
task, we have developed a new algorithm which generates a labeled Voronoi
tessellation that partitions the training data into polyhedral regions and
obtains interclass boundaries as an indirect result. It is called Supervised
k-Voxels or in short Super-k. We are introducing Super-k as a foundational new
algorithm and opening the possibility of a new family of algorithms. In this
paper, it is shown via comparisons on certain datasets that the Super-k
algorithm has the potential of providing similar accuracy and training
performance of the well-known SVM family of algorithms with less complexity.
Furthermore, the Super-k algorithm has an exceptional inference performance.
According to the experimental results, the Super-k algorithm is at least a
hundred-fold faster than its competitors.
</p>
<a href="http://arxiv.org/abs/2012.15492" target="_blank">arXiv:2012.15492</a> [<a href="http://arxiv.org/pdf/2012.15492" target="_blank">pdf</a>]

<h2>Stereo Correspondence and Reconstruction of Endoscopic Data Challenge. (arXiv:2101.01133v3 [cs.CV] UPDATED)</h2>
<h3>Max Allan, Jonathan Mcleod, Cong Cong Wang, Jean Claude Rosenthal, Zhenglei Hu, Niklas Gard, Peter Eisert, Ke Xue Fu, Trevor Zeffiro, Wenyao Xia, Zhanshi Zhu, Huoling Luo, Fucang Jia, Xiran Zhang, Xiaohong Li, Lalith Sharan, Tom Kurmann, Sebastian Schmid, Dimitris Psychogyios, Mahdi Azizian, Danail Stoyanov, Lena Maier-Hein, Stefanie Speidel</h3>
<p>The stereo correspondence and reconstruction of endoscopic data sub-challenge
was organized during the Endovis challenge at MICCAI 2019 in Shenzhen, China.
The task was to perform dense depth estimation using 7 training datasets and 2
test sets of structured light data captured using porcine cadavers. These were
provided by a team at Intuitive Surgical. 10 teams participated in the
challenge day. This paper contains 3 additional methods which were submitted
after the challenge finished as well as a supplemental section from these teams
on issues they found with the dataset.
</p>
<a href="http://arxiv.org/abs/2101.01133" target="_blank">arXiv:2101.01133</a> [<a href="http://arxiv.org/pdf/2101.01133" target="_blank">pdf</a>]

<h2>Spherical Transformer: Adapting Spherical Signal to CNNs. (arXiv:2101.03848v2 [cs.CV] UPDATED)</h2>
<h3>Haikuan Du, Hui Cao, Shen Cai, Junchi Yan, Siyu Zhang</h3>
<p>Convolutional neural networks (CNNs) have been widely used in various vision
tasks, e.g. image classification, semantic segmentation, etc. Unfortunately,
standard 2D CNNs are not well suited for spherical signals such as panorama
images or spherical projections, as the sphere is an unstructured grid. In this
paper, we present Spherical Transformer which can transform spherical signals
into vectors that can be directly processed by standard CNNs such that many
well-designed CNNs architectures can be reused across tasks and datasets by
pretraining. To this end, the proposed method first uses locally structured
sampling methods such as HEALPix to construct a transformer grid by using the
information of spherical points and its adjacent points, and then transforms
the spherical signals to the vectors through the grid. By building the
Spherical Transformer module, we can use multiple CNN architectures directly.
We evaluate our approach on the tasks of spherical MNIST recognition, 3D object
classification and omnidirectional image semantic segmentation. For 3D object
classification, we further propose a rendering-based projection method to
improve the performance and a rotational-equivariant model to improve the
anti-rotation ability. Experimental results on three tasks show that our
approach achieves superior performance over state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2101.03848" target="_blank">arXiv:2101.03848</a> [<a href="http://arxiv.org/pdf/2101.03848" target="_blank">pdf</a>]

<h2>Improving Classification Accuracy with Graph Filtering. (arXiv:2101.04789v2 [stat.ML] UPDATED)</h2>
<h3>Mounia Hamidouche, Carlos Lassance, Yuqing Hu, Lucas Drumetz, Bastien Pasdeloup, Vincent Gripon</h3>
<p>In machine learning, classifiers are typically susceptible to noise in the
training data. In this work, we aim at reducing intra-class noise with the help
of graph filtering to improve the classification performance. Considered graphs
are obtained by connecting samples of the training set that belong to a same
class depending on the similarity of their representation in a latent space. We
show that the proposed graph filtering methodology has the effect of
asymptotically reducing intra-class variance, while maintaining the mean. While
our approach applies to all classification problems in general, it is
particularly useful in few-shot settings, where intra-class noise can have a
huge impact due to the small sample selection. Using standardized benchmarks in
the field of vision, we empirically demonstrate the ability of the proposed
method to slightly improve state-of-the-art results in both cases of few-shot
and standard classification.
</p>
<a href="http://arxiv.org/abs/2101.04789" target="_blank">arXiv:2101.04789</a> [<a href="http://arxiv.org/pdf/2101.04789" target="_blank">pdf</a>]

<h2>COVID-19 Prognosis via Self-Supervised Representation Learning and Multi-Image Prediction. (arXiv:2101.04909v2 [cs.CV] UPDATED)</h2>
<h3>Anuroop Sriram, Matthew Muckley, Koustuv Sinha, Farah Shamout, Joelle Pineau, Krzysztof J. Geras, Lea Azour, Yindalon Aphinyanaphongs, Nafissa Yakubova, William Moore</h3>
<p>The rapid spread of COVID-19 cases in recent months has strained hospital
resources, making rapid and accurate triage of patients presenting to emergency
departments a necessity. Machine learning techniques using clinical data such
as chest X-rays have been used to predict which patients are most at risk of
deterioration. We consider the task of predicting two types of patient
deterioration based on chest X-rays: adverse event deterioration (i.e.,
transfer to the intensive care unit, intubation, or mortality) and increased
oxygen requirements beyond 6 L per day. Due to the relative scarcity of
COVID-19 patient data, existing solutions leverage supervised pretraining on
related non-COVID images, but this is limited by the differences between the
pretraining data and the target COVID-19 patient data. In this paper, we use
self-supervised learning based on the momentum contrast (MoCo) method in the
pretraining phase to learn more general image representations to use for
downstream tasks. We present three results. The first is deterioration
prediction from a single image, where our model achieves an area under receiver
operating characteristic curve (AUC) of 0.742 for predicting an adverse event
within 96 hours (compared to 0.703 with supervised pretraining) and an AUC of
0.765 for predicting oxygen requirements greater than 6 L a day at 24 hours
(compared to 0.749 with supervised pretraining). We then propose a new
transformer-based architecture that can process sequences of multiple images
for prediction and show that this model can achieve an improved AUC of 0.786
for predicting an adverse event at 96 hours and an AUC of 0.848 for predicting
mortalities at 96 hours. A small pilot clinical study suggested that the
prediction accuracy of our model is comparable to that of experienced
radiologists analyzing the same information.
</p>
<a href="http://arxiv.org/abs/2101.04909" target="_blank">arXiv:2101.04909</a> [<a href="http://arxiv.org/pdf/2101.04909" target="_blank">pdf</a>]

<h2>Road Surface Translation Under Snow-covered and Semantic Segmentation for Snow Hazard Index. (arXiv:2101.05616v3 [cs.CV] UPDATED)</h2>
<h3>Yasuno Takato, Fujii Junichiro, Sugawara Hiroaki, Amakata Masazumi</h3>
<p>In 2020, there was a record heavy snowfall owing to climate change. In
reality, 2,000 vehicles were stuck on the highway for three days. Because of
the freezing of the road surface, 10 vehicles had a billiard accident. Road
managers are required to provide indicators to alert drivers regarding snow
cover at hazardous locations. This study proposes a deep learning application
with live image post-processing to automatically calculate a snow hazard ratio
indicator. First, the road surface hidden under snow is translated using a
generative adversarial network, pix2pix. Second, snow-covered and road surface
classes are detected by semantic segmentation using DeepLabv3+ with MobileNet
as a backbone. Based on these trained networks, we automatically compute the
road to snow rate hazard index, indicating the amount of snow covered on the
road surface. We demonstrate the applied results to 1,155 live snow images of
the cold region in Japan. We mention the usefulness and the practical
robustness of our study.
</p>
<a href="http://arxiv.org/abs/2101.05616" target="_blank">arXiv:2101.05616</a> [<a href="http://arxiv.org/pdf/2101.05616" target="_blank">pdf</a>]

<h2>Spillover Algorithm: A Decentralized Coordination Approach for Multi-Robot Production Planning in Open Shared Factories. (arXiv:2101.05700v2 [cs.RO] UPDATED)</h2>
<h3>Marin Lujak, Alberto Fern&#xe1;ndez, Eva Onaindia</h3>
<p>Open and shared manufacturing factories typically dispose of a limited number
of robots that should be properly allocated to tasks in time and space for an
effective and efficient system performance. In particular, we deal with the
dynamic capacitated production planning problem with sequence independent setup
costs where quantities of products to manufacture and location of robots need
to be determined at consecutive periods within a given time horizon and
products can be anticipated or backordered related to the demand period. We
consider a decentralized multi-agent variant of this problem in an open factory
setting with multiple owners of robots as well as different owners of the items
to be produced, both considered self-interested and individually rational.
Existing solution approaches to the classic constrained lot-sizing problem are
centralized exact methods that require sharing of global knowledge of all the
participants' private and sensitive information and are not applicable in the
described multi-agent context. Therefore, we propose a computationally
efficient decentralized approach based on the spillover effect that solves this
NP-hard problem by distributing decisions in an intrinsically decentralized
multi-agent system environment while protecting private and sensitive
information. To the best of our knowledge, this is the first decentralized
algorithm for the solution of the studied problem in intrinsically
decentralized environments where production resources and/or products are owned
by multiple stakeholders with possibly conflicting objectives. To show its
efficiency, the performance of the Spillover Algorithm is benchmarked against
state-of-the-art commercial solver CPLEX 12.8.
</p>
<a href="http://arxiv.org/abs/2101.05700" target="_blank">arXiv:2101.05700</a> [<a href="http://arxiv.org/pdf/2101.05700" target="_blank">pdf</a>]

<h2>APEX-Net: Automatic Plot Extractor Network. (arXiv:2101.06217v2 [cs.CV] UPDATED)</h2>
<h3>Aalok Gangopadhyay, Prajwal Singh, Shanmuganathan Raman</h3>
<p>Automatic extraction of raw data from 2D line plot images is a problem of
great importance having many real-world applications. Several algorithms have
been proposed for solving this problem. However, these algorithms involve a
significant amount of human intervention. To minimize this intervention, we
propose APEX-Net, a deep learning based framework with novel loss functions for
solving the plot extraction problem. We introduce APEX-1M, a new large scale
dataset which contains both the plot images and the raw data. We demonstrate
the performance of APEX-Net on the APEX-1M test set and show that it obtains
impressive accuracy. We also show visual results of our network on unseen plot
images and demonstrate that it extracts the shape of the plots to a great
extent. Finally, we develop a GUI based software for plot extraction that can
benefit the community at large. For dataset and more information visit
https://sites.google.com/view/apexnetpaper/.
</p>
<a href="http://arxiv.org/abs/2101.06217" target="_blank">arXiv:2101.06217</a> [<a href="http://arxiv.org/pdf/2101.06217" target="_blank">pdf</a>]

<h2>Kimera: from SLAM to Spatial Perception with 3D Dynamic Scene Graphs. (arXiv:2101.06894v2 [cs.RO] UPDATED)</h2>
<h3>Antoni Rosinol, Andrew Violette, Marcus Abate, Nathan Hughes, Yun Chang, Jingnan Shi, Arjun Gupta, Luca Carlone</h3>
<p>Humans are able to form a complex mental model of the environment they move
in. This mental model captures geometric and semantic aspects of the scene,
describes the environment at multiple levels of abstractions (e.g., objects,
rooms, buildings), includes static and dynamic entities and their relations
(e.g., a person is in a room at a given time). In contrast, current robots'
internal representations still provide a partial and fragmented understanding
of the environment, either in the form of a sparse or dense set of geometric
primitives (e.g., points, lines, planes, voxels) or as a collection of objects.
This paper attempts to reduce the gap between robot and human perception by
introducing a novel representation, a 3D Dynamic Scene Graph(DSG), that
seamlessly captures metric and semantic aspects of a dynamic environment. A DSG
is a layered graph where nodes represent spatial concepts at different levels
of abstraction, and edges represent spatio-temporal relations among nodes. Our
second contribution is Kimera, the first fully automatic method to build a DSG
from visual-inertial data. Kimera includes state-of-the-art techniques for
visual-inertial SLAM, metric-semantic 3D reconstruction, object localization,
human pose and shape estimation, and scene parsing. Our third contribution is a
comprehensive evaluation of Kimera in real-life datasets and photo-realistic
simulations, including a newly released dataset, uHumans2, which simulates a
collection of crowded indoor and outdoor scenes. Our evaluation shows that
Kimera achieves state-of-the-art performance in visual-inertial SLAM, estimates
an accurate 3D metric-semantic mesh model in real-time, and builds a DSG of a
complex indoor environment with tens of objects and humans in minutes. Our
final contribution shows how to use a DSG for real-time hierarchical semantic
path-planning. The core modules in Kimera are open-source.
</p>
<a href="http://arxiv.org/abs/2101.06894" target="_blank">arXiv:2101.06894</a> [<a href="http://arxiv.org/pdf/2101.06894" target="_blank">pdf</a>]

<h2>Semi-Automatic Video Annotation For Object Detection. (arXiv:2101.06977v2 [cs.CV] UPDATED)</h2>
<h3>Kutalmis Gokalp Ince, Aybora Koksal, Arda Fazla, A. Aydin Alatan</h3>
<p>In this study, a semi-automatic video annotation method is proposed which
utilizes temporal information to eliminate false-positives with a
tracking-by-detection approach by employing multiple hypothesis tracking (MHT).
MHT method automatically forms tracklets which are confirmed by human operators
to enlarge the training set. A novel incremental learning approach helps to
annotate videos in an iterative way. The experiments performed on AUTH
Multidrone Dataset reveals that the annotation workload can be reduced up to
96% by the proposed approach.
</p>
<a href="http://arxiv.org/abs/2101.06977" target="_blank">arXiv:2101.06977</a> [<a href="http://arxiv.org/pdf/2101.06977" target="_blank">pdf</a>]

<h2>Hybrid Trilinear and Bilinear Programming for Aligning Partially Overlapping Point Sets. (arXiv:2101.07458v2 [cs.CV] UPDATED)</h2>
<h3>Wei Lian, Wangmeng Zuo, Lei Zhang</h3>
<p>Alignment methods which can handle partially overlapping point sets and are
invariant to the corresponding transformations are desirable in computer
vision, with applications such as providing initial transformation
configuration for local search based methods like ICP. To this end, we first
show that the objective of the robust point matching (RPM) algorithm is a cubic
polynomial. We then utilize the convex envelopes of trilinear and bilinear
monomials to develop its lower bounding function. The resulting lower bounding
problem can be efficiently solved via linear assignment and low dimensional
convex quadratic programming. We next develop a branch-and-bound (BnB)
algorithm which only branches over the transformation parameters and converges
quickly. Experimental results demonstrated favorable performance of the
proposed method over the state-of-the-art methods in terms of robustness and
speed.
</p>
<a href="http://arxiv.org/abs/2101.07458" target="_blank">arXiv:2101.07458</a> [<a href="http://arxiv.org/pdf/2101.07458" target="_blank">pdf</a>]

<h2>LowKey: Leveraging Adversarial Attacks to Protect Social Media Users from Facial Recognition. (arXiv:2101.07922v2 [cs.CV] UPDATED)</h2>
<h3>Valeriia Cherepanova, Micah Goldblum, Harrison Foley, Shiyuan Duan, John Dickerson, Gavin Taylor, Tom Goldstein</h3>
<p>Facial recognition systems are increasingly deployed by private corporations,
government agencies, and contractors for consumer services and mass
surveillance programs alike. These systems are typically built by scraping
social media profiles for user images. Adversarial perturbations have been
proposed for bypassing facial recognition systems. However, existing methods
fail on full-scale systems and commercial APIs. We develop our own adversarial
filter that accounts for the entire image processing pipeline and is
demonstrably effective against industrial-grade pipelines that include face
detection and large scale databases. Additionally, we release an easy-to-use
webtool that significantly degrades the accuracy of Amazon Rekognition and the
Microsoft Azure Face Recognition API, reducing the accuracy of each to below
1%.
</p>
<a href="http://arxiv.org/abs/2101.07922" target="_blank">arXiv:2101.07922</a> [<a href="http://arxiv.org/pdf/2101.07922" target="_blank">pdf</a>]

<h2>Non-Parametric Adaptive Network Pruning. (arXiv:2101.07985v2 [cs.CV] UPDATED)</h2>
<h3>Mingbao Lin, Rongrong Ji, Shaojie Li, Yan Wang, Yongjian Wu, Feiyue Huang, Qixiang Ye</h3>
<p>Popular network pruning algorithms reduce redundant information by optimizing
hand-crafted parametric models, and may cause suboptimal performance and long
time in selecting filters. We innovatively introduce non-parametric modeling to
simplify the algorithm design, resulting in an automatic and efficient pruning
approach called EPruner. Inspired by the face recognition community, we use a
message passing algorithm Affinity Propagation on the weight matrices to obtain
an adaptive number of exemplars, which then act as the preserved filters.
EPruner breaks the dependency on the training data in determining the
"important" filters and allows the CPU implementation in seconds, an order of
magnitude faster than GPU based SOTAs. Moreover, we show that the weights of
exemplars provide a better initialization for the fine-tuning. On VGGNet-16,
EPruner achieves a 76.34%-FLOPs reduction by removing 88.80% parameters, with
0.06% accuracy improvement on CIFAR-10. In ResNet-152, EPruner achieves a
65.12%-FLOPs reduction by removing 64.18% parameters, with only 0.71% top-5
accuracy loss on ILSVRC-2012. Code can be available at
https://github.com/lmbxmu/EPruner.
</p>
<a href="http://arxiv.org/abs/2101.07985" target="_blank">arXiv:2101.07985</a> [<a href="http://arxiv.org/pdf/2101.07985" target="_blank">pdf</a>]

<h2>An Information-Theoretic Analysis of the Impact of Task Similarity on Meta-Learning. (arXiv:2101.08390v2 [cs.LG] UPDATED)</h2>
<h3>Sharu Theresa Jose, Osvaldo Simeone</h3>
<p>Meta-learning aims at optimizing the hyperparameters of a model class or
training algorithm from the observation of data from a number of related tasks.
Following the setting of Baxter [1], the tasks are assumed to belong to the
same task environment, which is defined by a distribution over the space of
tasks and by per-task data distributions. The statistical properties of the
task environment thus dictate the similarity of the tasks. The goal of the
meta-learner is to ensure that the hyperparameters obtain a small loss when
applied for training of a new task sampled from the task environment. The
difference between the resulting average loss, known as meta-population loss,
and the corresponding empirical loss measured on the available data from
related tasks, known as meta-generalization gap, is a measure of the
generalization capability of the meta-learner. In this paper, we present novel
information-theoretic bounds on the average absolute value of the
meta-generalization gap. Unlike prior work [2], our bounds explicitly capture
the impact of task relatedness, the number of tasks, and the number of data
samples per task on the meta-generalization gap. Task similarity is gauged via
the Kullback-Leibler (KL) and Jensen-Shannon (JS) divergences. We illustrate
the proposed bounds on the example of ridge regression with meta-learned bias.
</p>
<a href="http://arxiv.org/abs/2101.08390" target="_blank">arXiv:2101.08390</a> [<a href="http://arxiv.org/pdf/2101.08390" target="_blank">pdf</a>]

<h2>All-Day Object Tracking for Unmanned Aerial Vehicle. (arXiv:2101.08446v2 [cs.CV] UPDATED)</h2>
<h3>Bowen Li, Changhong Fu, Fangqiang Ding, Junjie Ye, Fuling Lin</h3>
<p>Visual object tracking, which is representing a major interest in image
processing field, has facilitated numerous real world applications. Among them,
equipping unmanned aerial vehicle (UAV) with real time robust visual trackers
for all day aerial maneuver, is currently attracting incremental attention and
has remarkably broadened the scope of applications of object tracking. However,
prior tracking methods have merely focused on robust tracking in the
well-illuminated scenes, while ignoring trackers' capabilities to be deployed
in the dark. In darkness, the conditions can be more complex and harsh, easily
posing inferior robust tracking or even tracking failure. To this end, this
work proposed a novel discriminative correlation filter based tracker with
illumination adaptive and anti dark capability, namely ADTrack. ADTrack firstly
exploits image illuminance information to enable adaptability of the model to
the given light condition. Then, by virtue of an efficient and effective image
enhancer, ADTrack carries out image pretreatment, where a target aware mask is
generated. Benefiting from the mask, ADTrack aims to solve a dual regression
problem where dual filters, i.e., the context filter and target focused filter,
are trained with mutual constraint. Thus ADTrack is able to maintain
continuously favorable performance in all-day conditions. Besides, this work
also constructed one UAV nighttime tracking benchmark UAVDark135, comprising of
more than 125k manually annotated frames, which is also very first UAV
nighttime tracking benchmark. Exhaustive experiments are extended on
authoritative daytime benchmarks, i.e., UAV123 10fps, DTB70, and the newly
built dark benchmark UAVDark135, which have validated the superiority of
ADTrack in both bright and dark conditions on a single CPU.
</p>
<a href="http://arxiv.org/abs/2101.08446" target="_blank">arXiv:2101.08446</a> [<a href="http://arxiv.org/pdf/2101.08446" target="_blank">pdf</a>]

<h2>Trans2Seg: Transparent Object Segmentation with Transformer. (arXiv:2101.08461v2 [cs.CV] UPDATED)</h2>
<h3>Enze Xie, Wenjia Wang, Wenhai Wang, Peize Sun, Hang Xu, Ding Liang, Ping Luo</h3>
<p>This work presents a new fine-grained transparent object segmentation
dataset, termed Trans10K-v2, extending Trans10K-v1, the first large-scale
transparent object segmentation dataset. Unlike Trans10K-v1 that only has two
limited categories, our new dataset has several appealing benefits. (1) It has
11 fine-grained categories of transparent objects, commonly occurring in the
human domestic environment, making it more practical for real-world
application. (2) Trans10K-v2 brings more challenges for the current advanced
segmentation methods than its former version. Furthermore, a novel
transformer-based segmentation pipeline termed Trans2Seg is proposed. Firstly,
the transformer encoder of Trans2Seg provides the global receptive field in
contrast to CNN's local receptive field, which shows excellent advantages over
pure CNN architectures. Secondly, by formulating semantic segmentation as a
problem of dictionary look-up, we design a set of learnable prototypes as the
query of Trans2Seg's transformer decoder, where each prototype learns the
statistics of one category in the whole dataset. We benchmark more than 20
recent semantic segmentation methods, demonstrating that Trans2Seg
significantly outperforms all the CNN-based methods, showing the proposed
algorithm's potential ability to solve transparent object segmentation.
</p>
<a href="http://arxiv.org/abs/2101.08461" target="_blank">arXiv:2101.08461</a> [<a href="http://arxiv.org/pdf/2101.08461" target="_blank">pdf</a>]

<h2>An empirical evaluation of active inference in multi-armed bandits. (arXiv:2101.08699v2 [cs.LG] UPDATED)</h2>
<h3>Dimitrije Markovic, Hrvoje Stojic, Sarah Schwoebel, Stefan J. Kiebel</h3>
<p>A key feature of sequential decision making under uncertainty is a need to
balance between exploiting--choosing the best action according to the current
knowledge, and exploring--obtaining information about values of other actions.
The multi-armed bandit problem, a classical task that captures this trade-off,
served as a vehicle in machine learning for developing bandit algorithms that
proved to be useful in numerous industrial applications. The active inference
framework, an approach to sequential decision making recently developed in
neuroscience for understanding human and animal behaviour, is distinguished by
its sophisticated strategy for resolving the exploration-exploitation
trade-off. This makes active inference an exciting alternative to already
established bandit algorithms. Here we derive an efficient and scalable
approximate active inference algorithm and compare it to two state-of-the-art
bandit algorithms: Bayesian upper confidence bound and optimistic Thompson
sampling. This comparison is done on two types of bandit problems: a stationary
and a dynamic switching bandit. Our empirical evaluation shows that the active
inference algorithm does not produce efficient long-term behaviour in
stationary bandits. However, in the more challenging switching bandit problem
active inference performs substantially better than the two state-of-the-art
bandit algorithms. The results open exciting venues for further research in
theoretical and applied machine learning, as well as lend additional
credibility to active inference as a general framework for studying human and
animal behaviour.
</p>
<a href="http://arxiv.org/abs/2101.08699" target="_blank">arXiv:2101.08699</a> [<a href="http://arxiv.org/pdf/2101.08699" target="_blank">pdf</a>]

<h2>Optimizing Convergence for Iterative Learning of ARIMA for Stationary Time Series. (arXiv:2101.10037v1 [cs.LG])</h2>
<h3>Kevin Styp-Rekowski, Florian Schmidt, Odej Kao</h3>
<p>Forecasting of time series in continuous systems becomes an increasingly
relevant task due to recent developments in IoT and 5G. The popular forecasting
model ARIMA is applied to a large variety of applications for decades. An
online variant of ARIMA applies the Online Newton Step in order to learn the
underlying process of the time series. This optimization method has pitfalls
concerning the computational complexity and convergence. Thus, this work
focuses on the computational less expensive Online Gradient Descent
optimization method, which became popular for learning of neural networks in
recent years. For the iterative training of such models, we propose a new
approach combining different Online Gradient Descent learners (such as Adam,
AMSGrad, Adagrad, Nesterov) to achieve fast convergence. The evaluation on
synthetic data and experimental datasets show that the proposed approach
outperforms the existing methods resulting in an overall lower prediction
error.
</p>
<a href="http://arxiv.org/abs/2101.10037" target="_blank">arXiv:2101.10037</a> [<a href="http://arxiv.org/pdf/2101.10037" target="_blank">pdf</a>]

<h2>Probabilistic Robustness Analysis for DNNs based on PAC Learning. (arXiv:2101.10102v1 [cs.LG])</h2>
<h3>Renjue Li, Pengfei Yang, Cheng-Chao Huang, Bai Xue, Lijun Zhang</h3>
<p>This paper proposes a black box based approach for analysing deep neural
networks (DNNs). We view a DNN as a function $\boldsymbol{f}$ from inputs to
outputs, and consider the local robustness property for a given input. Based on
scenario optimization technique in robust control design, we learn the score
difference function $f_i-f_\ell$ with respect to the target label $\ell$ and
attacking label $i$. We use a linear template over the input pixels, and learn
the corresponding coefficients of the score difference function, based on a
reduction to a linear programming (LP) problems. To make it scalable, we
propose optimizations including components based learning and focused learning.
The learned function offers a probably approximately correct (PAC) guarantee
for the robustness property. Since the score difference function is an
approximation of the local behaviour of the DNN, it can be used to generate
potential adversarial examples, and the original network can be used to check
whether they are spurious or not. Finally, we focus on the input pixels with
large absolute coefficients, and use them to explain the attacking scenario. We
have implemented our approach in a prototypical tool DeepPAC. Our experimental
results show that our framework can handle very large neural networks like
ResNet152 with $6.5$M neurons, and often generates adversarial examples which
are very close to the decision boundary.
</p>
<a href="http://arxiv.org/abs/2101.10102" target="_blank">arXiv:2101.10102</a> [<a href="http://arxiv.org/pdf/2101.10102" target="_blank">pdf</a>]

<h2>Conditional Generative Models for Counterfactual Explanations. (arXiv:2101.10123v1 [cs.LG])</h2>
<h3>Arnaud Van Looveren, Janis Klaise, Giovanni Vacanti, Oliver Cobb</h3>
<p>Counterfactual instances offer human-interpretable insight into the local
behaviour of machine learning models. We propose a general framework to
generate sparse, in-distribution counterfactual model explanations which match
a desired target prediction with a conditional generative model, allowing
batches of counterfactual instances to be generated with a single forward pass.
The method is flexible with respect to the type of generative model used as
well as the task of the underlying predictive model. This allows
straightforward application of the framework to different modalities such as
images, time series or tabular data as well as generative model paradigms such
as GANs or autoencoders and predictive tasks like classification or regression.
We illustrate the effectiveness of our method on image (CelebA), time series
(ECG) and mixed-type tabular (Adult Census) data.
</p>
<a href="http://arxiv.org/abs/2101.10123" target="_blank">arXiv:2101.10123</a> [<a href="http://arxiv.org/pdf/2101.10123" target="_blank">pdf</a>]

<h2>Measuring Dependence with Matrix-based Entropy Functional. (arXiv:2101.10160v1 [cs.LG])</h2>
<h3>Shujian Yu, Francesco Alesiani, Xi Yu, Robert Jenssen, Jose C. Principe</h3>
<p>Measuring the dependence of data plays a central role in statistics and
machine learning. In this work, we summarize and generalize the main idea of
existing information-theoretic dependence measures into a higher-level
perspective by the Shearer's inequality. Based on our generalization, we then
propose two measures, namely the matrix-based normalized total correlation
($T_\alpha^*$) and the matrix-based normalized dual total correlation
($D_\alpha^*$), to quantify the dependence of multiple variables in arbitrary
dimensional space, without explicit estimation of the underlying data
distributions. We show that our measures are differentiable and statistically
more powerful than prevalent ones. We also show the impact of our measures in
four different machine learning problems, namely the gene regulatory network
inference, the robust machine learning under covariate shift and non-Gaussian
noises, the subspace outlier detection, and the understanding of the learning
dynamics of convolutional neural networks (CNNs), to demonstrate their
utilities, advantages, as well as implications to those problems. Code of our
dependence measure is available at: https://bit.ly/AAAI-dependence
</p>
<a href="http://arxiv.org/abs/2101.10160" target="_blank">arXiv:2101.10160</a> [<a href="http://arxiv.org/pdf/2101.10160" target="_blank">pdf</a>]

<h2>Universal Approximation Properties for ODENet and ResNet. (arXiv:2101.10229v1 [cs.LG])</h2>
<h3>Yuto Aizawa, Masato Kimura</h3>
<p>We prove a universal approximation property (UAP) for a class of ODENet and a
class of ResNet, which are used in many deep learning algorithms. The UAP can
be stated as follows. Let $n$ and $m$ be the dimension of input and output
data, and assume $m\leq n$. Then we show that ODENet width $n+m$ with any
non-polynomial continuous activation function can approximate any continuous
function on a compact subset on $\mathbb{R}^n$. We also show that ResNet has
the same property as the depth tends to infinity. Furthermore, we derive
explicitly the gradient of a loss function with respect to a certain tuning
variable. We use this to construct a learning algorithm for ODENet. To
demonstrate the usefulness of this algorithm, we apply it to a regression
problem, a binary classification, and a multinomial classification in MNIST.
</p>
<a href="http://arxiv.org/abs/2101.10229" target="_blank">arXiv:2101.10229</a> [<a href="http://arxiv.org/pdf/2101.10229" target="_blank">pdf</a>]

<h2>Discrete Choice Analysis with Machine Learning Capabilities. (arXiv:2101.10261v1 [cs.LG])</h2>
<h3>Youssef M. Aboutaleb, Mazen Danaf, Yifei Xie, Moshe Ben-Akiva</h3>
<p>This paper discusses capabilities that are essential to models applied in
policy analysis settings and the limitations of direct applications of
off-the-shelf machine learning methodologies to such settings. Traditional
econometric methodologies for building discrete choice models for policy
analysis involve combining data with modeling assumptions guided by
subject-matter considerations. Such considerations are typically most useful in
specifying the systematic component of random utility discrete choice models
but are typically of limited aid in determining the form of the random
component. We identify an area where machine learning paradigms can be
leveraged, namely in specifying and systematically selecting the best
specification of the random component of the utility equations. We review two
recent novel applications where mixed-integer optimization and cross-validation
are used to algorithmically select optimal specifications for the random
utility components of nested logit and logit mixture models subject to
interpretability constraints.
</p>
<a href="http://arxiv.org/abs/2101.10261" target="_blank">arXiv:2101.10261</a> [<a href="http://arxiv.org/pdf/2101.10261" target="_blank">pdf</a>]

<h2>COVID-19 Outbreak Prediction and Analysis using Self Reported Symptoms. (arXiv:2101.10266v1 [cs.LG])</h2>
<h3>Rohan Sukumaran, Parth Patwa, T V Sethuraman, Sheshank Shankar, Rishank Kanaparti, Joseph Bae, Yash Mathur, Abhishek Singh, Ayush Chopra, Myungsun Kang, Priya Ramaswamy, Ramesh Raskar</h3>
<p>The COVID-19 pandemic has challenged scientists and policy-makers
internationally to develop novel approaches to public health policy.
Furthermore, it has also been observed that the prevalence and spread of
COVID-19 vary across different spatial, temporal, and demographics. Despite
ramping up testing, we still are not at the required level in most parts of the
globe. Therefore, we utilize self-reported symptoms survey data to understand
trends in the spread of COVID-19. The aim of this study is to segment
populations that are highly susceptible. In order to understand such
populations, we perform exploratory data analysis, outbreak prediction, and
time-series forecasting using public health and policy datasets. From our
studies, we try to predict the likely % of the population that tested positive
for COVID-19 based on self-reported symptoms. Our findings reaffirm the
predictive value of symptoms, such as anosmia and ageusia. And we forecast that
% of the population having COVID-19-like illness (CLI) and those tested
positive as 0.15% and 1.14% absolute error respectively. These findings could
help aid faster development of the public health policy, particularly in areas
with low levels of testing and having a greater reliance on self-reported
symptoms. Our analysis sheds light on identifying clinical attributes of
interest across different demographics. We also provide insights into the
effects of various policy enactments on COVID-19 prevalence.
</p>
<a href="http://arxiv.org/abs/2101.10266" target="_blank">arXiv:2101.10266</a> [<a href="http://arxiv.org/pdf/2101.10266" target="_blank">pdf</a>]

<h2>Supervised Dimensionality Reduction for Big Data. (arXiv:1709.01233v9 [stat.ML] UPDATED)</h2>
<h3>Joshua T. Vogelstein, Eric Bridgeford, Minh Tang, Da Zheng, Christopher Douville, Randal Burns, Mauro Maggioni</h3>
<p>To solve key biomedical problems, experimentalists now routinely measure
millions or billions of features (dimensions) per sample, with the hope that
data science techniques will be able to build accurate data-driven inferences.
Because sample sizes are typically orders of magnitude smaller than the
dimensionality of these data, valid inferences require finding a
low-dimensional representation that preserves the discriminating information
(e.g., whether the individual suffers from a particular disease). There is a
lack of interpretable supervised dimensionality reduction methods that scale to
millions of dimensions with strong statistical theoretical guarantees.We
introduce an approach, XOX, to extending principal components analysis by
incorporating class-conditional moment estimates into the low-dimensional
projection. The simplest ver-sion, "Linear Optimal Low-rank" projection (LOL),
incorporates the class-conditional means. We prove, and substantiate with both
synthetic and real data benchmarks, that LOL and its generalizations in the XOX
framework lead to improved data representations for subsequent classification,
while maintaining computational efficiency and scalability. Using multiple
brain imaging datasets consisting of &gt;150 million features, and several
genomics datasets with&gt;500,000 features, LOL outperforms other scalable linear
dimensionality reduction techniques in terms of accuracy, while only requiring
a few minutes on a standard desktop computer.
</p>
<a href="http://arxiv.org/abs/1709.01233" target="_blank">arXiv:1709.01233</a> [<a href="http://arxiv.org/pdf/1709.01233" target="_blank">pdf</a>]

