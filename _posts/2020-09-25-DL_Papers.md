---
title: Latest Deep Learning Papers
date: 2021-02-24 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (163 Articles)</h1>
<h2>Good Actors can come in Smaller Sizes: A Case Study on the Value of Actor-Critic Asymmetry. (arXiv:2102.11893v1 [cs.LG])</h2>
<h3>Siddharth Mysore, Bassel Mabsout, Renato Mancuso, Kate Saenko</h3>
<p>Actors and critics in actor-critic reinforcement learning algorithms are
functionally separate, yet they often use the same network architectures. This
case study explores the performance impact of network sizes when considering
actor and critic architectures independently. By relaxing the assumption of
architectural symmetry, it is often possible for smaller actors to achieve
comparable policy performance to their symmetric counterparts. Our experiments
show up to 97% reduction in the number of network weights with an average
reduction of 64% over multiple algorithms on multiple tasks. Given the
practical benefits of reducing actor complexity, we believe configurations of
actors and critics are aspects of actor-critic design that deserve to be
considered independently.
</p>
<a href="http://arxiv.org/abs/2102.11893" target="_blank">arXiv:2102.11893</a> [<a href="http://arxiv.org/pdf/2102.11893" target="_blank">pdf</a>]

<h2>Grounded Relational Inference: Domain Knowledge Driven Explainable Autonomous Driving. (arXiv:2102.11905v1 [cs.AI])</h2>
<h3>Chen Tang, Nishan Srishankar, Sujitha Martin, Masayoshi Tomizuka</h3>
<p>Explainability is essential for autonomous vehicles and other robotics
systems interacting with humans and other objects during operation. Humans need
to understand and anticipate the actions taken by the machines for trustful and
safe cooperation. In this work, we aim to enable the explainability of an
autonomous driving system at the design stage by incorporating expert domain
knowledge into the model. We propose Grounded Relational Inference (GRI). It
models an interactive system's underlying dynamics by inferring an interaction
graph representing the agents' relations. We ensure an interpretable
interaction graph by grounding the relational latent space into semantic
behaviors defined with expert domain knowledge. We demonstrate that it can
model interactive traffic scenarios under both simulation and real-world
settings, and generate interpretable graphs explaining the vehicle's behavior
by their interactions.
</p>
<a href="http://arxiv.org/abs/2102.11905" target="_blank">arXiv:2102.11905</a> [<a href="http://arxiv.org/pdf/2102.11905" target="_blank">pdf</a>]

<h2>Instance Specific Approximations for Submodular Maximization. (arXiv:2102.11911v1 [cs.LG])</h2>
<h3>Eric Balkanski, Sharon Qian, Yaron Singer</h3>
<p>For many optimization problems in machine learning, finding an optimal
solution is computationally intractable and we seek algorithms that perform
well in practice. Since computational intractability often results from
pathological instances, we look for methods to benchmark the performance of
algorithms against optimal solutions on real-world instances. The main
challenge is that an optimal solution cannot be efficiently computed for
intractable problems, and we therefore often do not know how far a solution is
from being optimal. A major question is therefore how to measure the
performance of an algorithm in comparison to an optimal solution on instances
we encounter in practice.

In this paper, we address this question in the context of submodular
optimization problems. For the canonical problem of submodular maximization
under a cardinality constraint, it is intractable to compute a solution that is
better than a $1-1/e \approx 0.63$ fraction of the optimum. Algorithms like the
celebrated greedy algorithm are guaranteed to achieve this $1-1/e$ bound on any
instance and are used in practice.

Our main contribution is not a new algorithm for submodular maximization but
an analytical method that measures how close an algorithm for submodular
maximization is to optimal on a given problem instance. We use this method to
show that on a wide variety of real-world datasets and objectives, the
approximation of the solution found by greedy goes well beyond $1-1/e$ and is
often at least 0.95. We develop this method using a novel technique that lower
bounds the objective of a dual minimization problem to obtain an upper bound on
the value of an optimal solution to the primal maximization problem.
</p>
<a href="http://arxiv.org/abs/2102.11911" target="_blank">arXiv:2102.11911</a> [<a href="http://arxiv.org/pdf/2102.11911" target="_blank">pdf</a>]

<h2>Event Camera Based Real-Time Detection and Tracking of Indoor Ground Robots. (arXiv:2102.11916v1 [cs.CV])</h2>
<h3>Himanshu Patel, Craig Iaboni, Deepan Lobo, Ji-won Choi, Pramod Abichandani</h3>
<p>This paper presents a real-time method to detect and track multiple mobile
ground robots using event cameras. The method uses density-based spatial
clustering of applications with noise (DBSCAN) to detect the robots and a
single k-dimensional (k-d) tree to accurately keep track of them as they move
in an indoor arena. Robust detections and tracks are maintained in the face of
event camera noise and lack of events (due to robots moving slowly or
stopping). An off-the-shelf RGB camera-based tracking system was used to
provide ground truth. Experiments including up to 4 robots are performed to
study the effect of i) varying DBSCAN parameters, ii) the event accumulation
time, iii) the number of robots in the arena, and iv) the speed of the robots
on the detection and tracking performance. The experimental results showed 100%
detection and tracking fidelity in the face of event camera noise and robots
stopping for tests involving up to 3 robots (and upwards of 93% for 4 robots).
</p>
<a href="http://arxiv.org/abs/2102.11916" target="_blank">arXiv:2102.11916</a> [<a href="http://arxiv.org/pdf/2102.11916" target="_blank">pdf</a>]

<h2>Fair Set Selection: Meritocracy and Social Welfare. (arXiv:2102.11932v1 [cs.AI])</h2>
<h3>Thomas Kleine Buening, Meirav Segal, Debabrota Basu, Christos Dimitrakakis</h3>
<p>In this paper, we formulate the problem of selecting a set of individuals
from a candidate population as a utility maximisation problem. From the
decision maker's perspective, it is equivalent to finding a selection policy
that maximises expected utility. Our framework leads to the notion of expected
marginal contribution (EMC) of an individual with respect to a selection policy
as a measure of deviation from meritocracy. In order to solve the maximisation
problem, we propose to use a policy gradient algorithm. For certain policy
structures, the policy gradients are proportional to EMCs of individuals.
Consequently, the policy gradient algorithm leads to a locally optimal solution
that has zero EMC, and satisfies meritocracy. For uniform policies, EMC reduces
to the Shapley value. EMC also generalises the fair selection properties of
Shapley value for general selection policies. We experimentally analyse the
effect of different policy structures in a simulated college admission setting
and compare with ranking and greedy algorithms. Our results verify that
separable linear policies achieve high utility while minimising EMCs. We also
show that we can design utility functions that successfully promote notions of
group fairness, such as diversity.
</p>
<a href="http://arxiv.org/abs/2102.11932" target="_blank">arXiv:2102.11932</a> [<a href="http://arxiv.org/pdf/2102.11932" target="_blank">pdf</a>]

<h2>Feature Importance Explanations for Temporal Black-Box Models. (arXiv:2102.11934v1 [cs.LG])</h2>
<h3>Akshay Sood, Mark Craven</h3>
<p>Models in the supervised learning framework may capture rich and complex
representations over the features that are hard for humans to interpret.
Existing methods to explain such models are often specific to architectures and
data where the features do not have a time-varying component. In this work, we
propose TIME, a method to explain models that are inherently temporal in
nature. Our approach (i) uses a model-agnostic permutation-based approach to
analyze global feature importance, (ii) identifies the importance of salient
features with respect to their temporal ordering as well as localized windows
of influence, and (iii) uses hypothesis testing to provide statistical rigor.
</p>
<a href="http://arxiv.org/abs/2102.11934" target="_blank">arXiv:2102.11934</a> [<a href="http://arxiv.org/pdf/2102.11934" target="_blank">pdf</a>]

<h2>Non-Singular Adversarial Robustness of Neural Networks. (arXiv:2102.11935v1 [cs.LG])</h2>
<h3>Yu-Lin Tsai, Chia-Yi Hsu, Chia-Mu Yu, Pin-Yu Chen</h3>
<p>Adversarial robustness has become an emerging challenge for neural network
owing to its over-sensitivity to small input perturbations. While being
critical, we argue that solving this singular issue alone fails to provide a
comprehensive robustness assessment. Even worse, the conclusions drawn from
singular robustness may give a false sense of overall model robustness.
Specifically, our findings show that adversarially trained models that are
robust to input perturbations are still (or even more) vulnerable to weight
perturbations when compared to standard models. In this paper, we formalize the
notion of non-singular adversarial robustness for neural networks through the
lens of joint perturbations to data inputs as well as model weights. To our
best knowledge, this study is the first work considering simultaneous
input-weight adversarial perturbations. Based on a multi-layer feed-forward
neural network model with ReLU activation functions and standard classification
loss, we establish error analysis for quantifying the loss sensitivity subject
to $\ell_\infty$-norm bounded perturbations on data inputs and model weights.
Based on the error analysis, we propose novel regularization functions for
robust training and demonstrate improved non-singular robustness against joint
input-weight adversarial perturbations.
</p>
<a href="http://arxiv.org/abs/2102.11935" target="_blank">arXiv:2102.11935</a> [<a href="http://arxiv.org/pdf/2102.11935" target="_blank">pdf</a>]

<h2>Baby Intuitions Benchmark (BIB): Discerning the goals, preferences, and actions of others. (arXiv:2102.11938v1 [cs.AI])</h2>
<h3>Kanishk Gandhi, Gala Stojnic, Brenden M. Lake, Moira R. Dillon</h3>
<p>To achieve human-like common sense about everyday life, machine learning
systems must understand and reason about the goals, preferences, and actions of
others. Human infants intuitively achieve such common sense by making
inferences about the underlying causes of other agents' actions. Directly
informed by research on infant cognition, our benchmark BIB challenges machines
to achieve generalizable, common-sense reasoning about other agents like human
infants do. As in studies on infant cognition, moreover, we use a violation of
expectation paradigm in which machines must predict the plausibility of an
agent's behavior given a video sequence, making this benchmark appropriate for
direct validation with human infants in future studies. We show that recently
proposed, deep-learning-based agency reasoning models fail to show infant-like
reasoning, leaving BIB an open challenge.
</p>
<a href="http://arxiv.org/abs/2102.11938" target="_blank">arXiv:2102.11938</a> [<a href="http://arxiv.org/pdf/2102.11938" target="_blank">pdf</a>]

<h2>State Augmented Constrained Reinforcement Learning: Overcoming the Limitations of Learning with Rewards. (arXiv:2102.11941v1 [cs.LG])</h2>
<h3>Miguel Calvo-Fullana, Santiago Paternain, Luiz F. O. Chamon, Alejandro Ribeiro</h3>
<p>Constrained reinforcement learning involves multiple rewards that must
individually accumulate to given thresholds. In this class of problems, we show
a simple example in which the desired optimal policy cannot be induced by any
linear combination of rewards. Hence, there exist constrained reinforcement
learning problems for which neither regularized nor classical primal-dual
methods yield optimal policies. This work addresses this shortcoming by
augmenting the state with Lagrange multipliers and reinterpreting primal-dual
methods as the portion of the dynamics that drives the multipliers evolution.
This approach provides a systematic state augmentation procedure that is
guaranteed to solve reinforcement learning problems with constraints. Thus,
while primal-dual methods can fail at finding optimal policies, running the
dual dynamics while executing the augmented policy yields an algorithm that
provably samples actions from the optimal policy.
</p>
<a href="http://arxiv.org/abs/2102.11941" target="_blank">arXiv:2102.11941</a> [<a href="http://arxiv.org/pdf/2102.11941" target="_blank">pdf</a>]

<h2>Arguments for the Unsuitability of Convolutional Neural Networks for Non--Local Tasks. (arXiv:2102.11944v1 [cs.CV])</h2>
<h3>Sebastian Stabinger, David Peer, Antonio Rodr&#xed;guez-S&#xe1;nchez</h3>
<p>Convolutional neural networks have established themselves over the past years
as the state of the art method for image classification, and for many datasets,
they even surpass humans in categorizing images. Unfortunately, the same
architectures perform much worse when they have to compare parts of an image to
each other to correctly classify this image.

Until now, no well-formed theoretical argument has been presented to explain
this deficiency. In this paper, we will argue that convolutional layers are of
little use for such problems, since comparison tasks are global by nature, but
convolutional layers are local by design. We will use this insight to
reformulate a comparison task into a sorting task and use findings on sorting
networks to propose a lower bound for the number of parameters a neural network
needs to solve comparison tasks in a generalizable way. We will use this lower
bound to argue that attention, as well as iterative/recurrent processing, is
needed to prevent a combinatorial explosion.
</p>
<a href="http://arxiv.org/abs/2102.11944" target="_blank">arXiv:2102.11944</a> [<a href="http://arxiv.org/pdf/2102.11944" target="_blank">pdf</a>]

<h2>Learning to Drop Points for LiDAR Scan Synthesis. (arXiv:2102.11952v1 [cs.CV])</h2>
<h3>Kazuto Nakashima, Ryo Kurazume</h3>
<p>Generative modeling of 3D scenes is a crucial topic for aiding mobile robots
to improve unreliable observations. However, despite the rapid progress in the
natural image domain, building generative models is still challenging for 3D
data, such as point clouds. Most existing studies on point clouds have focused
on small and uniform-density data. In contrast, 3D LiDAR point clouds widely
used in mobile robots are non-trivial to be handled because of the large number
of points and varying-density. To circumvent this issue, 3D-to-2D projected
representation such as a cylindrical depth map has been studied in existing
LiDAR processing tasks but susceptible to discrete lossy pixels caused by
failures of laser reflection. This paper proposes a novel framework based on
generative adversarial networks to synthesize realistic LiDAR data as an
improved 2D representation. Our generative architectures are designed to learn
a distribution of inverse depth maps and simultaneously simulate the lossy
pixels, which enables us to decompose an underlying smooth geometry and the
corresponding uncertainty of laser reflection. To simulate the lossy pixels, we
propose a differentiable framework to learn to produce sample-dependent binary
masks using the Gumbel-Sigmoid reparametrization trick. We demonstrate the
effectiveness of our approach in synthesis and reconstruction tasks on two
LiDAR datasets. We further showcase potential applications by recovering
various corruptions in LiDAR data.
</p>
<a href="http://arxiv.org/abs/2102.11952" target="_blank">arXiv:2102.11952</a> [<a href="http://arxiv.org/pdf/2102.11952" target="_blank">pdf</a>]

<h2>Location Trace Privacy Under Conditional Priors. (arXiv:2102.11955v1 [cs.AI])</h2>
<h3>Casey Meehan, Kamalika Chaudhuri</h3>
<p>Providing meaningful privacy to users of location based services is
particularly challenging when multiple locations are revealed in a short period
of time. This is primarily due to the tremendous degree of dependence that can
be anticipated between points. We propose a R\'enyi divergence based privacy
framework for bounding expected privacy loss for conditionally dependent data.
Additionally, we demonstrate an algorithm for achieving this privacy under
Gaussian process conditional priors. This framework both exemplifies why
conditionally dependent data is so challenging to protect and offers a strategy
for preserving privacy to within a fixed radius for sensitive locations in a
user's trace.
</p>
<a href="http://arxiv.org/abs/2102.11955" target="_blank">arXiv:2102.11955</a> [<a href="http://arxiv.org/pdf/2102.11955" target="_blank">pdf</a>]

<h2>The SpaceNet Multi-Temporal Urban Development Challenge. (arXiv:2102.11958v1 [cs.CV])</h2>
<h3>Adam Van Etten, Daniel Hogan</h3>
<p>Building footprints provide a useful proxy for a great many humanitarian
applications. For example, building footprints are useful for high fidelity
population estimates, and quantifying population statistics is fundamental to
~1/4 of the United Nations Sustainable Development Goals Indicators. In this
paper we (the SpaceNet Partners) discuss efforts to develop techniques for
precise building footprint localization, tracking, and change detection via the
SpaceNet Multi-Temporal Urban Development Challenge (also known as SpaceNet 7).
In this NeurIPS 2020 competition, participants were asked identify and track
buildings in satellite imagery time series collected over rapidly urbanizing
areas. The competition centered around a brand new open source dataset of
Planet Labs satellite imagery mosaics at 4m resolution, which includes 24
images (one per month) covering ~100 unique geographies. Tracking individual
buildings at this resolution is quite challenging, yet the winning participants
demonstrated impressive performance with the newly developed SpaceNet Change
and Object Tracking (SCOT) metric. This paper details the top-5 winning
approaches, as well as analysis of results that yielded a handful of
interesting anecdotes such as decreasing performance with latitude.
</p>
<a href="http://arxiv.org/abs/2102.11958" target="_blank">arXiv:2102.11958</a> [<a href="http://arxiv.org/pdf/2102.11958" target="_blank">pdf</a>]

<h2>Modular Design Patterns for Hybrid Learning and Reasoning Systems: a taxonomy, patterns and use cases. (arXiv:2102.11965v1 [cs.AI])</h2>
<h3>Michael van Bekkum, Maaike de Boer, Frank van Harmelen, Andr&#xe9; Meyer-Vitali, Annette ten Teije</h3>
<p>The unification of statistical (data-driven) and symbolic (knowledge-driven)
methods is widely recognised as one of the key challenges of modern AI. Recent
years have seen large number of publications on such hybrid neuro-symbolic AI
systems. That rapidly growing literature is highly diverse and mostly
empirical, and is lacking a unifying view of the large variety of these hybrid
systems. In this paper we analyse a large body of recent literature and we
propose a set of modular design patterns for such hybrid, neuro-symbolic
systems. We are able to describe the architecture of a very large number of
hybrid systems by composing only a small set of elementary patterns as building
blocks.

The main contributions of this paper are: 1) a taxonomically organised
vocabulary to describe both processes and data structures used in hybrid
systems; 2) a set of 15+ design patterns for hybrid AI systems, organised in a
set of elementary patterns and a set of compositional patterns; 3) an
application of these design patterns in two realistic use-cases for hybrid AI
systems. Our patterns reveal similarities between systems that were not
recognised until now. Finally, our design patterns extend and refine Kautz'
earlier attempt at categorising neuro-symbolic architectures.
</p>
<a href="http://arxiv.org/abs/2102.11965" target="_blank">arXiv:2102.11965</a> [<a href="http://arxiv.org/pdf/2102.11965" target="_blank">pdf</a>]

<h2>Do Transformer Modifications Transfer Across Implementations and Applications?. (arXiv:2102.11972v1 [cs.LG])</h2>
<h3>Sharan Narang, Hyung Won Chung, Yi Tay, William Fedus, Thibault Fevry, Michael Matena, Karishma Malkan, Noah Fiedel, Noam Shazeer, Zhenzhong Lan, Yanqi Zhou, Wei Li, Nan Ding, Jake Marcus, Adam Roberts, Colin Raffel</h3>
<p>The research community has proposed copious modifications to the Transformer
architecture since it was introduced over three years ago, relatively few of
which have seen widespread adoption. In this paper, we comprehensively evaluate
many of these modifications in a shared experimental setting that covers most
of the common uses of the Transformer in natural language processing.
Surprisingly, we find that most modifications do not meaningfully improve
performance. Furthermore, most of the Transformer variants we found beneficial
were either developed in the same codebase that we used or are relatively minor
changes. We conjecture that performance improvements may strongly depend on
implementation details and correspondingly make some recommendations for
improving the generality of experimental results.
</p>
<a href="http://arxiv.org/abs/2102.11972" target="_blank">arXiv:2102.11972</a> [<a href="http://arxiv.org/pdf/2102.11972" target="_blank">pdf</a>]

<h2>Learner-Private Online Convex Optimization. (arXiv:2102.11976v1 [stat.ML])</h2>
<h3>Jiaming Xu, Kuang Xu, Dana Yang</h3>
<p>Online convex optimization is a framework where a learner sequentially
queries an external data source in order to arrive at the optimal solution of a
convex function. The paradigm has gained significant popularity recently thanks
to its scalability in large-scale optimization and machine learning. The
repeated interactions, however, expose the learner to privacy risks from
eavesdropping adversary that observe the submitted queries. In this paper, we
study how to optimally obfuscate the learner's queries in first-order online
convex optimization, so that their learned optimal value is provably difficult
to estimate for the eavesdropping adversary. We consider two formulations of
learner privacy: a Bayesian formulation in which the convex function is drawn
randomly, and a minimax formulation in which the function is fixed and the
adversary's probability of error is measured with respect to a minimax
criterion. We show that, if the learner wants to ensure the probability of
accurate prediction by the adversary be kept below $1/L$, then the overhead in
query complexity is additive in $L$ in the minimax formulation, but
multiplicative in $L$ in the Bayesian formulation. Compared to existing
learner-private sequential learning models with binary feedback, our results
apply to the significantly richer family of general convex functions with
full-gradient feedback. Our proofs are largely enabled by tools from the theory
of Dirichlet processes, as well as more sophisticated lines of analysis aimed
at measuring the amount of information leakage under a full-gradient oracle.
</p>
<a href="http://arxiv.org/abs/2102.11976" target="_blank">arXiv:2102.11976</a> [<a href="http://arxiv.org/pdf/2102.11976" target="_blank">pdf</a>]

<h2>Characterization and recognition of handwritten digits using Julia. (arXiv:2102.11994v1 [cs.CV])</h2>
<h3>M. A. Jishan, M. S. Alam, Afrida Islam, I. R. Mazumder, K. R. Mahmud, A. K. Al Azad</h3>
<p>Automatic image and digit recognition is a computationally challenging task
for image processing and pattern recognition, requiring an adequate
appreciation of the syntactic and semantic importance of the image for the
identification ofthe handwritten digits. Image and Pattern Recognition has been
identified as one of the driving forces in the research areas because of its
shifting of different types of applications, such as safety frameworks,
clinical frameworks, diversion, and so on.In this study, for recognition, we
implemented a hybrid neural network model that is capable of recognizing the
digit of MNISTdataset and achieved a remarkable result. The proposed neural
model network can extract features from the image and recognize the features in
the layer by layer. To expand, it is so important for the neural network to
recognize how the proposed modelcan work in each layer, how it can generate
output, and so on. Besides, it also can recognize the auto-encoding system and
the variational auto-encoding system of the MNIST dataset. This study will
explore those issues that are discussed above, and the explanation for them,
and how this phenomenon can be overcome.
</p>
<a href="http://arxiv.org/abs/2102.11994" target="_blank">arXiv:2102.11994</a> [<a href="http://arxiv.org/pdf/2102.11994" target="_blank">pdf</a>]

<h2>A Genetic Algorithm with Tree-structured Mutation for Hyperparameter Optimisation of Graph Neural Networks. (arXiv:2102.11995v1 [cs.LG])</h2>
<h3>Yingfang Yuan, Wenjun Wang, Wei Pang</h3>
<p>In recent years, graph neural networks (GNNs) have gained increasing
attention, as they possess excellent capability of processing graph-related
problems. In practice, hyperparameter optimisation (HPO) is critical for GNNs
to achieve satisfactory results, but this process is costly because the
evaluations of different hyperparameter settings require excessively training
many GNNs. Many approaches have been proposed for HPO which aims to identify
promising hyperparameters efficiently. In particular, genetic algorithm (GA)
for HPO has been explored, which treats GNNs as a black-box model, of which
only the outputs can be observed given a set of hyperparameters. However,
because GNN models are extremely sophisticated and the evaluations of
hyperparameters on GNNs are expensive, GA requires advanced techniques to
balance the exploration and exploitation of the search and make the
optimisation more effective given limited computational resources. Therefore,
we proposed a tree-structured mutation strategy for GA to alleviate this issue.
Meanwhile, we reviewed the recent HPO works which gives the room to the idea of
tree-structure to develop, and we hope our approach can further improve these
HPO methods in the future.
</p>
<a href="http://arxiv.org/abs/2102.11995" target="_blank">arXiv:2102.11995</a> [<a href="http://arxiv.org/pdf/2102.11995" target="_blank">pdf</a>]

<h2>On Relative Pose Recovery for Multi-Camera Systems. (arXiv:2102.11996v1 [cs.CV])</h2>
<h3>Ji Zhao, Banglei Guan</h3>
<p>The point correspondence (PC) and affine correspondence (AC) are widely used
for relative pose estimation. An AC consists of a PC across two views and an
affine transformation between the small patches around this PC. Previous work
demonstrates that one AC generally provides three independent constraints for
relative pose estimation. For multi-camera systems, there is still not any
AC-based minimal solver for general relative pose estimation. To deal with this
problem, we propose a complete solution to relative pose estimation from two
ACs for multi-camera systems, consisting of a series of minimal solvers. The
solver generation in our solution is based on Cayley or quaternion
parameterization for rotation and hidden variable technique to eliminate
translation. This solver generation method is also naturally applied to
relative pose estimation from PCs, resulting in a new six-point method for
multi-camera systems. A few extensions are made, including relative pose
estimation with known rotation angle and/or with unknown focal lengths.
Extensive experiments demonstrate that the proposed AC-based solvers and
PC-based solvers are effective and efficient on synthetic and real-world
datasets.
</p>
<a href="http://arxiv.org/abs/2102.11996" target="_blank">arXiv:2102.11996</a> [<a href="http://arxiv.org/pdf/2102.11996" target="_blank">pdf</a>]

<h2>Adversarial Robustness with Non-uniform Perturbations. (arXiv:2102.12002v1 [cs.LG])</h2>
<h3>Ecenaz Erdemir, Jeffrey Bickford, Luca Melis, Sergul Aydore</h3>
<p>Robustness of machine learning models is critical for security related
applications, where real-world adversaries are uniquely focused on evading
neural network based detectors. Prior work mainly focus on crafting adversarial
examples with small uniform norm-bounded perturbations across features to
maintain the requirement of imperceptibility. Although such approaches are
valid for images, uniform perturbations do not result in realistic adversarial
examples in domains such as malware, finance, and social networks. For these
types of applications, features typically have some semantically meaningful
dependencies. The key idea of our proposed approach is to enable non-uniform
perturbations that can adequately represent these feature dependencies during
adversarial training. We propose using characteristics of the empirical data
distribution, both on correlations between the features and the importance of
the features themselves. Using experimental datasets for malware
classification, credit risk prediction, and spam detection, we show that our
approach is more robust to real-world attacks. Our approach can be adapted to
other domains where non-uniform perturbations more accurately represent
realistic adversarial examples.
</p>
<a href="http://arxiv.org/abs/2102.12002" target="_blank">arXiv:2102.12002</a> [<a href="http://arxiv.org/pdf/2102.12002" target="_blank">pdf</a>]

<h2>PixSet : An Opportunity for 3D Computer Vision to Go Beyond Point Clouds With a Full-Waveform LiDAR Dataset. (arXiv:2102.12010v1 [cs.RO])</h2>
<h3>Jean-Luc D&#xe9;ziel, Pierre Merriaux, Francis Tremblay, Dave Lessard, Dominique Plourde, Julien Stanguennec, Pierre Goulet, Pierre Olivier</h3>
<p>Leddar PixSet is a new publicly available dataset (dataset.leddartech.com)
for autonomous driving research and development. One key novelty of this
dataset is the presence of full-waveform data from the Leddar Pixell sensor, a
solid-state flash LiDAR. Full-waveform data has been shown to improve the
performance of perception algorithms in airborne applications but is yet to be
demonstrated for terrestrial applications such as autonomous driving. The
PixSet dataset contains approximately 29k frames from 97 sequences recorded in
high-density urban areas, using a set of various sensors (cameras, LiDARs,
radar, IMU, etc.) Each frame has been manually annotated with 3D bounding
boxes.
</p>
<a href="http://arxiv.org/abs/2102.12010" target="_blank">arXiv:2102.12010</a> [<a href="http://arxiv.org/pdf/2102.12010" target="_blank">pdf</a>]

<h2>Understanding and Mitigating Accuracy Disparity in Regression. (arXiv:2102.12013v1 [cs.LG])</h2>
<h3>Jianfeng Chi, Yuan Tian, Geoffrey J. Gordon, Han Zhao</h3>
<p>With the widespread deployment of large-scale prediction systems in
high-stakes domains, e.g., face recognition, criminal justice, etc., disparity
on prediction accuracy between different demographic subgroups has called for
fundamental understanding on the source of such disparity and algorithmic
intervention to mitigate it. In this paper, we study the accuracy disparity
problem in regression. To begin with, we first propose an error decomposition
theorem, which decomposes the accuracy disparity into the distance between
marginal label distributions and the distance between conditional
representations, to help explain why such accuracy disparity appears in
practice. Motivated by this error decomposition and the general idea of
distribution alignment with statistical distances, we then propose an algorithm
to reduce this disparity, and analyze its game-theoretic optima of the proposed
objective functions. To corroborate our theoretical findings, we also conduct
experiments on five benchmark datasets. The experimental results suggest that
our proposed algorithms can effectively mitigate accuracy disparity while
maintaining the predictive power of the regression models.
</p>
<a href="http://arxiv.org/abs/2102.12013" target="_blank">arXiv:2102.12013</a> [<a href="http://arxiv.org/pdf/2102.12013" target="_blank">pdf</a>]

<h2>Annotating Motion Primitives for Simplifying Action Search in Reinforcement Learning. (arXiv:2102.12017v1 [cs.LG])</h2>
<h3>Isaac J. Sledge, Darshan W. Bryner, Jose C. Principe</h3>
<p>Reinforcement learning in large-scale environments is challenging due to the
many possible actions that can be taken in specific situations. We have
previously developed a means of constraining, and hence speeding up, the search
process through the use of motion primitives; motion primitives are sequences
of pre-specified actions taken across a state series. As a byproduct of this
work, we have found that if the motion primitives' motions and actions are
labeled, then the search can be sped up further. Since motion primitives may
initially lack such details, we propose a theoretically viewpoint-insensitive
and speed-insensitive means of automatically annotating the underlying motions
and actions. We do this through a differential-geometric, spatio-temporal
kinematics descriptor, which analyzes how the poses of entities in two motion
sequences change over time. We use this descriptor in conjunction with a
weighted-nearest-neighbor classifier to label the primitives using a limited
set of training examples. In our experiments, we achieve high motion and action
annotation rates for human-action-derived primitives with as few as one
training sample. We also demonstrate that reinforcement learning using
accurately labeled trajectories leads to high-performing policies more quickly
than standard reinforcement learning techniques. This is partly because motion
primitives encode prior domain knowledge and preempt the need to re-discover
that knowledge during training. It is also because agents can leverage the
labels to systematically ignore action classes that do not facilitate task
objectives, thereby reducing the action space.
</p>
<a href="http://arxiv.org/abs/2102.12017" target="_blank">arXiv:2102.12017</a> [<a href="http://arxiv.org/pdf/2102.12017" target="_blank">pdf</a>]

<h2>Towards Optimized Distributed Multi-Robot Printing: An Algorithmic Approach. (arXiv:2102.12026v1 [cs.RO])</h2>
<h3>Kedar Karpe, Avinash Sinha, Shreyas Raorane, Ayon Chatterjee, Pranav Srinivas, Lorenzo Sabattini</h3>
<p>This paper presents a distributed multi-robot printing method which utilizes
an optimization approach to decompose and allocate a printing task to a group
of mobile robots. The motivation for this problem is to minimize the printing
time of the robots by using an appropriate task decomposition algorithm. We
present one such algorithm which decomposes an image into rasterized geodesic
cells before allocating them to the robots for printing. In addition to this,
we also present the design of a numerically controlled holonomic robot capable
of spraying ink on smooth surfaces. Further, we use this robot to
experimentally verify the results of this paper.
</p>
<a href="http://arxiv.org/abs/2102.12026" target="_blank">arXiv:2102.12026</a> [<a href="http://arxiv.org/pdf/2102.12026" target="_blank">pdf</a>]

<h2>Theoretical Understandings of Product Embedding for E-commerce Machine Learning. (arXiv:2102.12029v1 [cs.LG])</h2>
<h3>Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan</h3>
<p>Product embeddings have been heavily investigated in the past few years,
serving as the cornerstone for a broad range of machine learning applications
in e-commerce. Despite the empirical success of product embeddings, little is
known on how and why they work from the theoretical standpoint. Analogous
results from the natural language processing (NLP) often rely on
domain-specific properties that are not transferable to the e-commerce setting,
and the downstream tasks often focus on different aspects of the embeddings. We
take an e-commerce-oriented view of the product embeddings and reveal a
complete theoretical view from both the representation learning and the
learning theory perspective. We prove that product embeddings trained by the
widely-adopted skip-gram negative sampling algorithm and its variants are
sufficient dimension reduction regarding a critical product relatedness
measure. The generalization performance in the downstream machine learning task
is controlled by the alignment between the embeddings and the product
relatedness measure. Following the theoretical discoveries, we conduct
exploratory experiments that supports our theoretical insights for the product
embeddings.
</p>
<a href="http://arxiv.org/abs/2102.12029" target="_blank">arXiv:2102.12029</a> [<a href="http://arxiv.org/pdf/2102.12029" target="_blank">pdf</a>]

<h2>Self-Diagnosing GAN: Diagnosing Underrepresented Samples in Generative Adversarial Networks. (arXiv:2102.12033v1 [cs.LG])</h2>
<h3>Jinhee Lee, Haeri Kim, Youngkyu Hong, Hye Won Chung</h3>
<p>Despite remarkable performance in producing realistic samples, Generative
Adversarial Networks (GANs) often produce low-quality samples near low-density
regions of the data manifold. Recently, many techniques have been developed to
improve the quality of generated samples, either by rejecting low-quality
samples after training or by pre-processing the empirical data distribution
before training, but at the cost of reduced diversity. To guarantee both the
quality and the diversity, we propose a simple yet effective method to diagnose
and emphasize underrepresented samples during training of a GAN. The main idea
is to use the statistics of the discrepancy between the data distribution and
the model distribution at each data instance. Based on the observation that the
underrepresented samples have a high average discrepancy or high variability in
discrepancy, we propose a method to emphasize those samples during training of
a GAN. Our experimental results demonstrate that the proposed method improves
GAN performance on various datasets, and it is especially effective in
improving the quality of generated samples with minor features.
</p>
<a href="http://arxiv.org/abs/2102.12033" target="_blank">arXiv:2102.12033</a> [<a href="http://arxiv.org/pdf/2102.12033" target="_blank">pdf</a>]

<h2>DNN2LR: Automatic Feature Crossing for Credit Scoring. (arXiv:2102.12036v1 [cs.LG])</h2>
<h3>Qiang Liu, Zhaocheng Liu, Haoli Zhang, Yuntian Chen, Jun Zhu</h3>
<p>Credit scoring is a major application of machine learning for financial
institutions to decide whether to approve or reject a credit loan. For sake of
reliability, it is necessary for credit scoring models to be both accurate and
globally interpretable. Simple classifiers, e.g., Logistic Regression (LR), are
white-box models, but not powerful enough to model complex nonlinear
interactions among features. Fortunately, automatic feature crossing is a
promising way to find cross features to make simple classifiers to be more
accurate without heavy handcrafted feature engineering. However, credit scoring
is usually based on different aspects of users, and the data usually contains
hundreds of feature fields. This makes existing automatic feature crossing
methods not efficient for credit scoring. In this work, we find local
piece-wise interpretations in Deep Neural Networks (DNNs) of a specific feature
are usually inconsistent in different samples, which is caused by feature
interactions in the hidden layers. Accordingly, we can design an automatic
feature crossing method to find feature interactions in DNN, and use them as
cross features in LR. We give definition of the interpretation inconsistency in
DNN, based on which a novel feature crossing method for credit scoring
prediction called DNN2LR is proposed. Apparently, the final model, i.e., a LR
model empowered with cross features, generated by DNN2LR is a white-box model.
Extensive experiments have been conducted on both public and business datasets
from real-world credit scoring applications. Experimental shows that, DNN2LR
can outperform the DNN model, as well as several feature crossing methods.
Moreover, comparing with the state-of-the-art feature crossing methods, i.e.,
AutoCross, DNN2LR can accelerate the speed for feature crossing by about 10 to
40 times on datasets with large numbers of feature fields.
</p>
<a href="http://arxiv.org/abs/2102.12036" target="_blank">arXiv:2102.12036</a> [<a href="http://arxiv.org/pdf/2102.12036" target="_blank">pdf</a>]

<h2>Image Completion via Inference in Deep Generative Models. (arXiv:2102.12037v1 [cs.CV])</h2>
<h3>William Harvey, Saeid Naderiparizi, Frank Wood</h3>
<p>We consider image completion from the perspective of amortized inference in
an image generative model. We leverage recent state of the art variational
auto-encoder architectures that have been shown to produce photo-realistic
natural images at non-trivial resolutions. Through amortized inference in such
a model we can train neural artifacts that produce diverse, realistic image
completions even when the vast majority of an image is missing. We demonstrate
superior sample quality and diversity compared to prior art on the CIFAR-10 and
FFHQ-256 datasets. We conclude by describing and demonstrating an application
that requires an in-painting model with the capabilities ours exhibits: the use
of Bayesian optimal experimental design to select the most informative sequence
of small field of view x-rays for chest pathology detection.
</p>
<a href="http://arxiv.org/abs/2102.12037" target="_blank">arXiv:2102.12037</a> [<a href="http://arxiv.org/pdf/2102.12037" target="_blank">pdf</a>]

<h2>Deep Video Prediction for Time Series Forecasting. (arXiv:2102.12061v1 [cs.CV])</h2>
<h3>Zhen Zeng, Tucker Balch, Manuela Veloso</h3>
<p>Time series forecasting is essential for decision making in many domains. In
this work, we address the challenge of predicting prices evolution among
multiple potentially interacting financial assets. A solution to this problem
has obvious importance for governments, banks, and investors. Statistical
methods such as Auto Regressive Integrated Moving Average (ARIMA) are widely
applied to these problems. In this paper, we propose to approach economic time
series forecasting of multiple financial assets in a novel way via video
prediction. Given past prices of multiple potentially interacting financial
assets, we aim to predict the prices evolution in the future. Instead of
treating the snapshot of prices at each time point as a vector, we spatially
layout these prices in 2D as an image, such that we can harness the power of
CNNs in learning a latent representation for these financial assets. Thus, the
history of these prices becomes a sequence of images, and our goal becomes
predicting future images. We build on a state-of-the-art video prediction
method for forecasting future images. Our experiments involve the prediction
task of the price evolution of nine financial assets traded in U.S. stock
markets. The proposed method outperforms baselines including ARIMA, Prophet,
and variations of the proposed method, demonstrating the benefits of harnessing
the power of CNNs in the problem of economic time series forecasting.
</p>
<a href="http://arxiv.org/abs/2102.12061" target="_blank">arXiv:2102.12061</a> [<a href="http://arxiv.org/pdf/2102.12061" target="_blank">pdf</a>]

<h2>Spatio-Temporal Look-Ahead Trajectory Prediction using Memory Neural Network. (arXiv:2102.12070v1 [cs.RO])</h2>
<h3>Nishanth Rao, Suresh Sundaram</h3>
<p>Prognostication of vehicle trajectories in unknown environments is
intrinsically a challenging and difficult problem to solve. The behavior of
such vehicles is highly influenced by surrounding traffic, road conditions, and
rogue participants present in the environment. Moreover, the presence of
pedestrians, traffic lights, stop signs, etc., makes it much harder to infer
the behavior of various traffic agents. This paper attempts to solve the
problem of Spatio-temporal look-ahead trajectory prediction using a novel
recurrent neural network called the Memory Neuron Network. The Memory Neuron
Network (MNN) attempts to capture the input-output relationship between the
past positions and the future positions of the traffic agents. The proposed
model is computationally less intensive and has a simple architecture as
compared to other deep learning models that utilize LSTMs and GRUs. It is then
evaluated on the publicly available NGSIM dataset and its performance is
compared with several state-of-art algorithms. Additionally, the performance is
also evaluated on a custom synthetic dataset generated from the CARLA
simulator. It is seen that the proposed model outperforms the existing
state-of-art algorithms. Finally, the model is integrated with the CARLA
simulator to test its robustness in real-time traffic scenarios.
</p>
<a href="http://arxiv.org/abs/2102.12070" target="_blank">arXiv:2102.12070</a> [<a href="http://arxiv.org/pdf/2102.12070" target="_blank">pdf</a>]

<h2>Perspective: Purposeful Failure in Artificial Life and Artificial Intelligence. (arXiv:2102.12076v1 [cs.AI])</h2>
<h3>Lana Sinapayen</h3>
<p>Complex systems fail. I argue that failures can be a blueprint characterizing
living organisms and biological intelligence, a control mechanism to increase
complexity in evolutionary simulations, and an alternative to classical fitness
optimization. Imitating biological successes in Artificial Life and Artificial
Intelligence can be misleading; imitating failures offers a path towards
understanding and emulating life it in artificial systems.
</p>
<a href="http://arxiv.org/abs/2102.12076" target="_blank">arXiv:2102.12076</a> [<a href="http://arxiv.org/pdf/2102.12076" target="_blank">pdf</a>]

<h2>Fast Approximate Solutions using Reinforcement Learning for Dynamic Capacitated Vehicle Routing with Time Windows. (arXiv:2102.12088v1 [cs.AI])</h2>
<h3>Nazneen N Sultana, Vinita Baniwal, Ansuma Basumatary, Piyush Mittal, Supratim Ghosh, Harshad Khadilkar</h3>
<p>This paper develops an inherently parallelised, fast, approximate
learning-based solution to the generic class of Capacitated Vehicle Routing
with Time Windows and Dynamic Routing (CVRP-TWDR). Considering vehicles in a
fleet as decentralised agents, we postulate that using reinforcement learning
(RL) based adaptation is a key enabler for real-time route formation in a
dynamic environment. The methodology allows each agent (vehicle) to
independently evaluate the value of serving each customer, and uses a
centralised allocation heuristic to finalise the allocations based on the
generated values. We show that the solutions produced by this method on
standard datasets are significantly faster than exact formulations and
state-of-the-art meta-heuristics, while being reasonably close to optimal in
terms of solution quality. We describe experiments in both the static case
(when all customer demands and time windows are known in advance) as well as
the dynamic case (where customers can `pop up' at any time during execution).
The results with a single trained model on large, out-of-distribution test data
demonstrate the scalability and flexibility of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2102.12088" target="_blank">arXiv:2102.12088</a> [<a href="http://arxiv.org/pdf/2102.12088" target="_blank">pdf</a>]

<h2>Continuous Mean-Covariance Bandits. (arXiv:2102.12090v1 [cs.LG])</h2>
<h3>Yihan Du, Siwei Wang, Zhixuan Fang, Longbo Huang</h3>
<p>Existing risk-aware multi-armed bandit models typically focus on risk
measures of individual options such as variance. As a result, they cannot be
directly applied to important real-world online decision making problems with
correlated options. In this paper, we propose a novel Continuous
Mean-Covariance Bandit (CMCB) model to explicitly take into account option
correlation. Specifically, in CMCB, there is a learner who sequentially chooses
weight vectors on given options and observes random feedback according to the
decisions. The agent's objective is to achieve the best trade-off between
reward and risk, measured with option covariance. To capture important reward
observation scenarios in practice, we consider three feedback settings, i.e.,
full-information, semi-bandit and full-bandit feedback. We propose novel
algorithms with the optimal regrets (within logarithmic factors), and provide
matching lower bounds to validate their optimalities. Our experimental results
also demonstrate the superiority of the proposed algorithms. To the best of our
knowledge, this is the first work that considers option correlation in
risk-aware bandits and explicitly quantifies how arbitrary covariance
structures impact the learning performance.
</p>
<a href="http://arxiv.org/abs/2102.12090" target="_blank">arXiv:2102.12090</a> [<a href="http://arxiv.org/pdf/2102.12090" target="_blank">pdf</a>]

<h2>Zero-Shot Text-to-Image Generation. (arXiv:2102.12092v1 [cs.CV])</h2>
<h3>Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, Ilya Sutskever</h3>
<p>Text-to-image generation has traditionally focused on finding better modeling
assumptions for training on a fixed dataset. These assumptions might involve
complex architectures, auxiliary losses, or side information such as object
part labels or segmentation masks supplied during training. We describe a
simple approach for this task based on a transformer that autoregressively
models the text and image tokens as a single stream of data. With sufficient
data and scale, our approach is competitive with previous domain-specific
models when evaluated in a zero-shot fashion.
</p>
<a href="http://arxiv.org/abs/2102.12092" target="_blank">arXiv:2102.12092</a> [<a href="http://arxiv.org/pdf/2102.12092" target="_blank">pdf</a>]

<h2>PRIN/SPRIN: On Extracting Point-wise Rotation Invariant Features. (arXiv:2102.12093v1 [cs.CV])</h2>
<h3>Yang You, Yujing Lou, Ruoxi Shi, Qi Liu, Yu-Wing Tai, Lizhuang Ma, Weiming Wang, Cewu Lu</h3>
<p>Point cloud analysis without pose priors is very challenging in real
applications, as the orientations of point clouds are often unknown. In this
paper, we propose a brand new point-set learning framework PRIN, namely,
Point-wise Rotation Invariant Network, focusing on rotation invariant feature
extraction in point clouds analysis. We construct spherical signals by Density
Aware Adaptive Sampling to deal with distorted point distributions in spherical
space. Spherical Voxel Convolution and Point Re-sampling are proposed to
extract rotation invariant features for each point. In addition, we extend PRIN
to a sparse version called SPRIN, which directly operates on sparse point
clouds. Both PRIN and SPRIN can be applied to tasks ranging from object
classification, part segmentation, to 3D feature matching and label alignment.
Results show that, on the dataset with randomly rotated point clouds, SPRIN
demonstrates better performance than state-of-the-art methods without any data
augmentation. We also provide thorough theoretical proof and analysis for
point-wise rotation invariance achieved by our methods. Our code is available
on https://github.com/qq456cvb/SPRIN.
</p>
<a href="http://arxiv.org/abs/2102.12093" target="_blank">arXiv:2102.12093</a> [<a href="http://arxiv.org/pdf/2102.12093" target="_blank">pdf</a>]

<h2>Combinatorial Pure Exploration with Bottleneck Reward Function and its Extension to General Reward Functions. (arXiv:2102.12094v1 [cs.LG])</h2>
<h3>Yihan Du, Yuko Kuroki, Wei Chen</h3>
<p>In this paper, we study the Combinatorial Pure Exploration problem with the
bottleneck reward function (CPE-B) under the fixed-confidence and fixed-budget
settings. In CPE-B, given a set of base arms and a collection of subsets of
base arms (super arms) following certain combinatorial constraint, a learner
sequentially plays (samples) a base arm and observes its random outcome, with
the objective of finding the optimal super arm that maximizes its bottleneck
value, defined as the minimum expected value among the base arms contained in
the super arm. CPE-B captures a variety of practical scenarios such as network
routing in communication networks, but it cannot be solved by the existing CPE
algorithms since most of them assumed linear reward functions. For CPE-B, we
present both fixed-confidence and fixed-budget algorithms, and provide the
sample complexity lower bound for the fixed-confidence setting, which implies
that our algorithms match the lower bound (within a logarithmic factor) for a
broad family of instances. In addition, we extend CPE-B to general reward
functions (CPE-G) and propose the first fixed-confidence algorithm for general
non-linear reward functions with non-trivial sample complexity. Our
experimental results on the top-$k$, path and matching instances demonstrate
the empirical superiority of our proposed algorithms over the baselines.
</p>
<a href="http://arxiv.org/abs/2102.12094" target="_blank">arXiv:2102.12094</a> [<a href="http://arxiv.org/pdf/2102.12094" target="_blank">pdf</a>]

<h2>Synergy Between Semantic Segmentation and Image Denoising via Alternate Boosting. (arXiv:2102.12095v1 [cs.CV])</h2>
<h3>Shunxin Xu, Ke Sun, Dong Liu, Zhiwei Xiong, Zheng-Jun Zha</h3>
<p>The capability of image semantic segmentation may be deteriorated due to
noisy input image, where image denoising prior to segmentation helps. Both
image denoising and semantic segmentation have been developed significantly
with the advance of deep learning. Thus, we are interested in the synergy
between them by using a holistic deep model. We observe that not only denoising
helps combat the drop of segmentation accuracy due to noise, but also
pixel-wise semantic information boosts the capability of denoising. We then
propose a boosting network to perform denoising and segmentation alternately.
The proposed network is composed of multiple segmentation and denoising blocks
(SDBs), each of which estimates semantic map then uses the map to regularize
denoising. Experimental results show that the denoised image quality is
improved substantially and the segmentation accuracy is improved to close to
that of clean images. Our code and models will be made publicly available.
</p>
<a href="http://arxiv.org/abs/2102.12095" target="_blank">arXiv:2102.12095</a> [<a href="http://arxiv.org/pdf/2102.12095" target="_blank">pdf</a>]

<h2>PFRL: Pose-Free Reinforcement Learning for 6D Pose Estimation. (arXiv:2102.12096v1 [cs.CV])</h2>
<h3>Jianzhun Shao, Yuhang Jiang, Gu Wang, Zhigang Li, Xiangyang Ji</h3>
<p>6D pose estimation from a single RGB image is a challenging and vital task in
computer vision. The current mainstream deep model methods resort to 2D images
annotated with real-world ground-truth 6D object poses, whose collection is
fairly cumbersome and expensive, even unavailable in many cases. In this work,
to get rid of the burden of 6D annotations, we formulate the 6D pose refinement
as a Markov Decision Process and impose on the reinforcement learning approach
with only 2D image annotations as weakly-supervised 6D pose information, via a
delicate reward definition and a composite reinforced optimization method for
efficient and effective policy training. Experiments on LINEMOD and T-LESS
datasets demonstrate that our Pose-Free approach is able to achieve
state-of-the-art performance compared with the methods without using real-world
ground-truth 6D pose labels.
</p>
<a href="http://arxiv.org/abs/2102.12096" target="_blank">arXiv:2102.12096</a> [<a href="http://arxiv.org/pdf/2102.12096" target="_blank">pdf</a>]

<h2>The Promises and Pitfalls of Deep Kernel Learning. (arXiv:2102.12108v1 [stat.ML])</h2>
<h3>Sebastian W. Ober, Carl E. Rasmussen, Mark van der Wilk</h3>
<p>Deep kernel learning and related techniques promise to combine the
representational power of neural networks with the reliable uncertainty
estimates of Gaussian processes. One crucial aspect of these models is an
expectation that, because they are treated as Gaussian process models optimized
using the marginal likelihood, they are protected from overfitting. However, we
identify pathological behavior, including overfitting, on a simple toy example.
We explore this pathology, explaining its origins and considering how it
applies to real datasets. Through careful experimentation on UCI datasets,
CIFAR-10, and the UTKFace dataset, we find that the overfitting from
overparameterized deep kernel learning, in which the model is "somewhat
Bayesian", can in certain scenarios be worse than that from not being Bayesian
at all. However, we find that a fully Bayesian treatment of deep kernel
learning can rectify this overfitting and obtain the desired performance
improvements over standard neural networks and Gaussian processes.
</p>
<a href="http://arxiv.org/abs/2102.12108" target="_blank">arXiv:2102.12108</a> [<a href="http://arxiv.org/pdf/2102.12108" target="_blank">pdf</a>]

<h2>Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions. (arXiv:2102.12122v1 [cs.CV])</h2>
<h3>Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao</h3>
<p>Although using convolutional neural networks (CNNs) as backbones achieves
great successes in computer vision, this work investigates a simple backbone
network useful for many dense prediction tasks without convolutions. Unlike the
recently-proposed Transformer model (e.g., ViT) that is specially designed for
image classification, we propose Pyramid Vision Transformer~(PVT), which
overcomes the difficulties of porting Transformer to various dense prediction
tasks. PVT has several merits compared to prior arts. (1) Different from ViT
that typically has low-resolution outputs and high computational and memory
cost, PVT can be not only trained on dense partitions of the image to achieve
high output resolution, which is important for dense predictions but also using
a progressive shrinking pyramid to reduce computations of large feature maps.
(2) PVT inherits the advantages from both CNN and Transformer, making it a
unified backbone in various vision tasks without convolutions by simply
replacing CNN backbones. (3) We validate PVT by conducting extensive
experiments, showing that it boosts the performance of many downstream tasks,
e.g., object detection, semantic, and instance segmentation. For example, with
a comparable number of parameters, RetinaNet+PVT achieves 40.4 AP on the COCO
dataset, surpassing RetinNet+ResNet50 (36.3 AP) by 4.1 absolute AP. We hope PVT
could serve as an alternative and useful backbone for pixel-level predictions
and facilitate future researches. Code is available at
https://github.com/whai362/PVT.
</p>
<a href="http://arxiv.org/abs/2102.12122" target="_blank">arXiv:2102.12122</a> [<a href="http://arxiv.org/pdf/2102.12122" target="_blank">pdf</a>]

<h2>Safe Learning-based Gradient-free Model Predictive Control Based on Cross-entropy Method. (arXiv:2102.12124v1 [cs.RO])</h2>
<h3>Lei Zheng, Rui Yang, Zhixuan Wu, Jiesen Panb, Hui Cheng</h3>
<p>In this paper, a safe and learning-based control framework for model
predictive control (MPC) is proposed to optimize nonlinear systems with a
gradient-free objective function under uncertain environmental disturbances.
The control framework integrates a learning-based MPC with an auxiliary
controller in a way of minimal intervention. The learning-based MPC augments
the prior nominal model with incremental Gaussian Processes to learn the
uncertain disturbances. The cross-entropy method (CEM) is utilized as the
sampling-based optimizer for the MPC with a gradient-free objective function. A
minimal intervention controller is devised with a control Lyapunov function and
a control barrier function to guide the sampling process and endow the system
with high probabilistic safety. The proposed algorithm shows a safe and
adaptive control performance on a simulated quadrotor in the tasks of
trajectory tracking and obstacle avoidance under uncertain wind disturbances.
</p>
<a href="http://arxiv.org/abs/2102.12124" target="_blank">arXiv:2102.12124</a> [<a href="http://arxiv.org/pdf/2102.12124" target="_blank">pdf</a>]

<h2>Efficient Palm-Line Segmentation with U-Net Context Fusion Module. (arXiv:2102.12127v1 [cs.CV])</h2>
<h3>Toan Pham Van, Son Trung Nguyen, Linh Bao Doan, Ngoc N. Tran, Ta Minh Thanh</h3>
<p>Many cultures around the world believe that palm reading can be used to
predict the future life of a person. Palmistry uses features of the hand such
as palm lines, hand shape, or fingertip position. However, the research on
palm-line detection is still scarce, many of them applied traditional image
processing techniques. In most real-world scenarios, images usually are not in
well-conditioned, causing these methods to severely under-perform. In this
paper, we propose an algorithm to extract principle palm lines from an image of
a person's hand. Our method applies deep learning networks (DNNs) to improve
performance. Another challenge of this problem is the lack of training data. To
deal with this issue, we handcrafted a dataset from scratch. From this dataset,
we compare the performance of readily available methods with ours. Furthermore,
based on the UNet segmentation neural network architecture and the knowledge of
attention mechanism, we propose a highly efficient architecture to detect
palm-lines. We proposed the Context Fusion Module to capture the most important
context feature, which aims to improve segmentation accuracy. The experimental
results show that it outperforms the other methods with the highest F1 Score
about 99.42% and mIoU is 0.584 for the same dataset.
</p>
<a href="http://arxiv.org/abs/2102.12127" target="_blank">arXiv:2102.12127</a> [<a href="http://arxiv.org/pdf/2102.12127" target="_blank">pdf</a>]

<h2>Self-Domain Adaptation for Face Anti-Spoofing. (arXiv:2102.12129v1 [cs.CV])</h2>
<h3>Jingjing Wang, Jingyi Zhang, Ying Bian, Youyi Cai, Chunmao Wang, Shiliang Pu</h3>
<p>Although current face anti-spoofing methods achieve promising results under
intra-dataset testing, they suffer from poor generalization to unseen attacks.
Most existing works adopt domain adaptation (DA) or domain generalization (DG)
techniques to address this problem. However, the target domain is often unknown
during training which limits the utilization of DA methods. DG methods can
conquer this by learning domain invariant features without seeing any target
data. However, they fail in utilizing the information of target data. In this
paper, we propose a self-domain adaptation framework to leverage the unlabeled
test domain data at inference. Specifically, a domain adaptor is designed to
adapt the model for test domain. In order to learn a better adaptor, a
meta-learning based adaptor learning algorithm is proposed using the data of
multiple source domains at the training step. At test time, the adaptor is
updated using only the test domain data according to the proposed unsupervised
adaptor loss to further improve the performance. Extensive experiments on four
public datasets validate the effectiveness of the proposed method.
</p>
<a href="http://arxiv.org/abs/2102.12129" target="_blank">arXiv:2102.12129</a> [<a href="http://arxiv.org/pdf/2102.12129" target="_blank">pdf</a>]

<h2>Efficient and Accurate Multi-scale Topological Network for Single Image Dehazing. (arXiv:2102.12135v1 [cs.CV])</h2>
<h3>Qiaosi Yi, Juncheng Li, Faming Fang, Aiwen Jiang, Guixu Zhang</h3>
<p>Single image dehazing is a challenging ill-posed problem that has drawn
significant attention in the last few years. Recently, convolutional neural
networks have achieved great success in image dehazing. However, it is still
difficult for these increasingly complex models to recover accurate details
from the hazy image. In this paper, we pay attention to the feature extraction
and utilization of the input image itself. To achieve this, we propose a
Multi-scale Topological Network (MSTN) to fully explore the features at
different scales. Meanwhile, we design a Multi-scale Feature Fusion Module
(MFFM) and an Adaptive Feature Selection Module (AFSM) to achieve the selection
and fusion of features at different scales, so as to achieve progressive image
dehazing. This topological network provides a large number of search paths that
enable the network to extract abundant image features as well as strong fault
tolerance and robustness. In addition, ASFM and MFFM can adaptively select
important features and ignore interference information when fusing different
scale representations. Extensive experiments are conducted to demonstrate the
superiority of our method compared with state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.12135" target="_blank">arXiv:2102.12135</a> [<a href="http://arxiv.org/pdf/2102.12135" target="_blank">pdf</a>]

<h2>SFANet: A Spectrum-aware Feature Augmentation Network for Visible-Infrared Person Re-Identification. (arXiv:2102.12137v1 [cs.CV])</h2>
<h3>Haojie Liu, Shun Ma, Daoxun Xia, Shaozi Li</h3>
<p>Visible-Infrared person re-identification (VI-ReID) is a challenging matching
problem due to large modality varitions between visible and infrared images.
Existing approaches usually bridge the modality gap with only feature-level
constraints, ignoring pixel-level variations. Some methods employ GAN to
generate style-consistent images, but it destroys the structure information and
incurs a considerable level of noise. In this paper, we explicitly consider
these challenges and formulate a novel spectrum-aware feature augementation
network named SFANet for cross-modality matching problem. Specifically, we put
forward to employ grayscale-spectrum images to fully replace RGB images for
feature learning. Learning with the grayscale-spectrum images, our model can
apparently reduce modality discrepancy and detect inner structure relations
across the different modalities, making it robust to color variations. In
feature-level, we improve the conventional two-stream network through balancing
the number of specific and sharable convolutional blocks, which preserve the
spatial structure information of features. Additionally, a bi-directional
tri-constrained top-push ranking loss (BTTR) is embedded in the proposed
network to improve the discriminability, which efficiently further boosts the
matching accuracy. Meanwhile, we further introduce an effective dual-linear
with batch normalization ID embedding method to model the identity-specific
information and assits BTTR loss in magnitude stabilizing. On SYSU-MM01 and
RegDB datasets, we conducted extensively experiments to demonstrate that our
proposed framework contributes indispensably and achieves a very competitive
VI-ReID performance.
</p>
<a href="http://arxiv.org/abs/2102.12137" target="_blank">arXiv:2102.12137</a> [<a href="http://arxiv.org/pdf/2102.12137" target="_blank">pdf</a>]

<h2>Interpreting the Latent Space of Generative Adversarial Networks using Supervised Learning. (arXiv:2102.12139v1 [cs.LG])</h2>
<h3>Toan Pham Van, Tam Minh Nguyen, Ngoc N. Tran, Hoai Viet Nguyen, Linh Bao Doan, Huy Quang Dao, Thanh Ta Minh</h3>
<p>With great progress in the development of Generative Adversarial Networks
(GANs), in recent years, the quest for insights in understanding and
manipulating the latent space of GAN has gained more and more attention due to
its wide range of applications. While most of the researches on this task have
focused on unsupervised learning method, which induces difficulties in training
and limitation in results, our work approaches another direction, encoding
human's prior knowledge to discover more about the hidden space of GAN. With
this supervised manner, we produce promising results, demonstrated by accurate
manipulation of generated images. Even though our model is more suitable for
task-specific problems, we hope that its ease in implementation, preciseness,
robustness, and the allowance of richer set of properties (compared to other
approaches) for image manipulation can enhance the result of many current
applications.
</p>
<a href="http://arxiv.org/abs/2102.12139" target="_blank">arXiv:2102.12139</a> [<a href="http://arxiv.org/pdf/2102.12139" target="_blank">pdf</a>]

<h2>Learning to Shift Attention for Motion Generation. (arXiv:2102.12141v1 [cs.RO])</h2>
<h3>You Zhou, Jianfeng Gao, Tamim Asfour</h3>
<p>One challenge of motion generation using robot learning from demonstration
techniques is that human demonstrations follow a distribution with multiple
modes for one task query. Previous approaches fail to capture all modes or tend
to average modes of the demonstrations and thus generate invalid trajectories.
The other difficulty is the small number of demonstrations that cannot cover
the entire working space. To overcome this problem, a motion generation model
with extrapolation ability is needed. Previous works restrict task queries as
local frames and learn representations in local frames. We propose a model to
solve both problems. For multiple modes, we suggest to learn local latent
representations of motion trajectories with a density estimation method based
on real-valued non-volume preserving (RealNVP) transformations that provides a
set of powerful, stably invertible, and learnable transformations. To improve
the extrapolation ability, we propose to shift the attention of the robot from
one local frame to another during the task execution. In experiments, we
consider the docking problem used also in previous works where a trajectory has
to be generated to connect two dockers without collision. We increase
complexity of the task and show that the proposed method outperforms other
approaches. In addition, we evaluate the approach in real robot experiments.
</p>
<a href="http://arxiv.org/abs/2102.12141" target="_blank">arXiv:2102.12141</a> [<a href="http://arxiv.org/pdf/2102.12141" target="_blank">pdf</a>]

<h2>GDR-Net: Geometry-Guided Direct Regression Network for Monocular 6D Object Pose Estimation. (arXiv:2102.12145v1 [cs.CV])</h2>
<h3>Gu Wang, Fabian Manhardt, Federico Tombari, Xiangyang Ji</h3>
<p>6D pose estimation from a single RGB image is a fundamental task in computer
vision. The current top-performing deep learning-based methods rely on an
indirect strategy, i.e., first establishing 2D-3D correspondences between the
coordinates in the image plane and object coordinate system, and then applying
a variant of the P$n$P/RANSAC algorithm. However, this two-stage pipeline is
not end-to-end trainable, thus is hard to be employed for many tasks requiring
differentiable poses. On the other hand, methods based on direct regression are
currently inferior to geometry-based methods. In this work, we perform an
in-depth investigation on both direct and indirect methods, and propose a
simple yet effective Geometry-guided Direct Regression Network (GDR-Net) to
learn the 6D pose in an end-to-end manner from dense correspondence-based
intermediate geometric representations. Extensive experiments show that our
approach remarkably outperforms state-of-the-art methods on LM, LM-O and YCB-V
datasets. The code will be available at https://git.io/GDR-Net.
</p>
<a href="http://arxiv.org/abs/2102.12145" target="_blank">arXiv:2102.12145</a> [<a href="http://arxiv.org/pdf/2102.12145" target="_blank">pdf</a>]

<h2>A New Pairwise Deep Learning Feature For Environmental Microorganism Image Analysis. (arXiv:2102.12147v1 [cs.CV])</h2>
<h3>Frank Kulwa, Chen Li, Jinghua Zhang, Kimiaki Shirahama, Sergey Kosov, Xin Zhao, Hongzan Sun, Tao Jiang, Marcin Grzegorzek</h3>
<p>Environmental microorganism (EM) offers a high-efficient, harmless, and
low-cost solution to environmental pollution. They are used in sanitation,
monitoring, and decomposition of environmental pollutants. However, this
depends on the proper identification of suitable microorganisms. In order to
fasten, low the cost, increase consistency and accuracy of identification, we
propose the novel pairwise deep learning features to analyze microorganisms.
The pairwise deep learning features technique combines the capability of
handcrafted and deep learning features. In this technique we, leverage the Shi
and Tomasi interest points by extracting deep learning features from patches
which are centered at interest points locations. Then, to increase the number
of potential features that have intermediate spatial characteristics between
nearby interest points, we use Delaunay triangulation theorem and straight-line
geometric theorem to pair the nearby deep learning features. The potential of
pairwise features is justified on the classification of EMs using SVMs, k-NN,
and Random Forest classifier. The pairwise features obtain outstanding results
of 99.17%, 91.34%, 91.32%, 91.48%, and 99.56%, which are the increase of about
5.95%, 62.40%, 62.37%, 61.84%, and 3.23% in accuracy, F1-score, recall,
precision, and specificity respectively, compared to non-paired deep learning
features.
</p>
<a href="http://arxiv.org/abs/2102.12147" target="_blank">arXiv:2102.12147</a> [<a href="http://arxiv.org/pdf/2102.12147" target="_blank">pdf</a>]

<h2>CoreDiag: Eliminating Redundancy in Constraint Sets. (arXiv:2102.12151v1 [cs.AI])</h2>
<h3>Alexander Felfernig, Christoph Zehentner, Paul Blazek</h3>
<p>Constraint-based environments such as configuration systems, recommender
systems, and scheduling systems support users in different decision making
scenarios. These environments exploit a knowledge base for determining
solutions of interest for the user. The development and maintenance of such
knowledge bases is an extremely time-consuming and error-prone task. Users
often specify constraints which do not reflect the real-world. For example,
redundant constraints are specified which often increase both, the effort for
calculating a solution and efforts related to knowledge base development and
maintenance. In this paper we present a new algorithm (CoreDiag) which can be
exploited for the determination of minimal cores (minimal non-redundant
constraint sets). The algorithm is especially useful for distributed knowledge
engineering scenarios where the degree of redundancy can become high. In order
to show the applicability of our approach, we present an empirical study
conducted with commercial configuration knowledge bases.
</p>
<a href="http://arxiv.org/abs/2102.12151" target="_blank">arXiv:2102.12151</a> [<a href="http://arxiv.org/pdf/2102.12151" target="_blank">pdf</a>]

<h2>Should I Look at the Head or the Tail? Dual-awareness Attention for Few-Shot Object Detection. (arXiv:2102.12152v1 [cs.CV])</h2>
<h3>Tung-I Chen, Yueh-Cheng Liu, Hung-Ting Su, Yu-Cheng Chang, Yu-Hsiang Lin, Jia-Fong Yeh, Winston H. Hsu</h3>
<p>While recent progress has significantly boosted few-shot classification (FSC)
performance, few-shot object detection (FSOD) remains challenging for modern
learning systems. Existing FSOD systems follow FSC approaches, neglect the
problem of spatial misalignment and the risk of information entanglement, and
result in low performance. Observing this, we propose a novel
Dual-Awareness-Attention (DAnA), which captures the pairwise spatial
relationship cross the support and query images. The generated
query-position-aware support features are robust to spatial misalignment and
used to guide the detection network precisely. Our DAnA component is adaptable
to various existing object detection networks and boosts FSOD performance by
paying attention to specific semantics conditioned on the query. Experimental
results demonstrate that DAnA significantly boosts (48% and 125% relatively)
object detection performance on the COCO benchmark. By equipping DAnA,
conventional object detection models, Faster-RCNN and RetinaNet, which are not
designed explicitly for few-shot learning, reach state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2102.12152" target="_blank">arXiv:2102.12152</a> [<a href="http://arxiv.org/pdf/2102.12152" target="_blank">pdf</a>]

<h2>Multi-Level Adaptive Region of Interest and Graph Learning for Facial Action Unit Recognition. (arXiv:2102.12154v1 [cs.CV])</h2>
<h3>Jingwei Yan, Boyuan Jiang, Jingjing Wang, Qiang Li, Chunmao Wang, Shiliang Pu</h3>
<p>In facial action unit (AU) recognition tasks, regional feature learning and
AU relation modeling are two effective aspects which are worth exploring.
However, the limited representation capacity of regional features makes it
difficult for relation models to embed AU relationship knowledge. In this
paper, we propose a novel multi-level adaptive ROI and graph learning (MARGL)
framework to tackle this problem. Specifically, an adaptive ROI learning module
is designed to automatically adjust the location and size of the predefined AU
regions. Meanwhile, besides relationship between AUs, there exists strong
relevance between regional features across multiple levels of the backbone
network as level-wise features focus on different aspects of representation. In
order to incorporate the intra-level AU relation and inter-level AU regional
relevance simultaneously, a multi-level AU relation graph is constructed and
graph convolution is performed to further enhance AU regional features of each
level. Experiments on BP4D and DISFA demonstrate the proposed MARGL
significantly outperforms the previous state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.12154" target="_blank">arXiv:2102.12154</a> [<a href="http://arxiv.org/pdf/2102.12154" target="_blank">pdf</a>]

<h2>Efficient Low-Latency Dynamic Licensing for Deep Neural Network Deployment on Edge Devices. (arXiv:2102.12165v1 [cs.LG])</h2>
<h3>Toan Pham Van, Ngoc N. Tran, Hoang Pham Minh, Tam Nguyen Minh anh Thanh Ta Minh</h3>
<p>Along with the rapid development in the field of artificial intelligence,
especially deep learning, deep neural network applications are becoming more
and more popular in reality. To be able to withstand the heavy load from
mainstream users, deployment techniques are essential in bringing neural
network models from research to production. Among the two popular computing
topologies for deploying neural network models in production are
cloud-computing and edge-computing. Recent advances in communication
technologies, along with the great increase in the number of mobile devices,
has made edge-computing gradually become an inevitable trend. In this paper, we
propose an architecture to solve deploying and processing deep neural networks
on edge-devices by leveraging their synergy with the cloud and the
access-control mechanisms of the database. Adopting this architecture allows
low-latency DNN model updates on devices. At the same time, with only one model
deployed, we can easily make different versions of it by setting access
permissions on the model weights. This method allows for dynamic model
licensing, which benefits commercial applications.
</p>
<a href="http://arxiv.org/abs/2102.12165" target="_blank">arXiv:2102.12165</a> [<a href="http://arxiv.org/pdf/2102.12165" target="_blank">pdf</a>]

<h2>Learning to Generate Wasserstein Barycenters. (arXiv:2102.12178v1 [cs.LG])</h2>
<h3>Julien Lacombe, Julie Digne, Nicolas Courty, Nicolas Bonneel</h3>
<p>Optimal transport is a notoriously difficult problem to solve numerically,
with current approaches often remaining intractable for very large scale
applications such as those encountered in machine learning. Wasserstein
barycenters -- the problem of finding measures in-between given input measures
in the optimal transport sense -- is even more computationally demanding as it
requires to solve an optimization problem involving optimal transport
distances. By training a deep convolutional neural network, we improve by a
factor of 60 the computational speed of Wasserstein barycenters over the
fastest state-of-the-art approach on the GPU, resulting in milliseconds
computational times on $512\times512$ regular grids. We show that our network,
trained on Wasserstein barycenters of pairs of measures, generalizes well to
the problem of finding Wasserstein barycenters of more than two measures. We
demonstrate the efficiency of our approach for computing barycenters of
sketches and transferring colors between multiple images.
</p>
<a href="http://arxiv.org/abs/2102.12178" target="_blank">arXiv:2102.12178</a> [<a href="http://arxiv.org/pdf/2102.12178" target="_blank">pdf</a>]

<h2>Parameterized Temperature Scaling for Boosting the Expressive Power in Post-Hoc Uncertainty Calibration. (arXiv:2102.12182v1 [cs.LG])</h2>
<h3>Christian Tomani, Daniel Cremers, Florian Buettner</h3>
<p>We address the problem of uncertainty calibration and introduce a novel
calibration method, Parametrized Temperature Scaling (PTS). Standard deep
neural networks typically yield uncalibrated predictions, which can be
transformed into calibrated confidence scores using post-hoc calibration
methods. In this contribution, we demonstrate that the performance of
accuracy-preserving state-of-the-art post-hoc calibrators is limited by their
intrinsic expressive power. We generalize temperature scaling by computing
prediction-specific temperatures, parameterized by a neural network. We show
with extensive experiments that our novel accuracy-preserving approach
consistently outperforms existing algorithms across a large number of model
architectures, datasets and metrics.
</p>
<a href="http://arxiv.org/abs/2102.12182" target="_blank">arXiv:2102.12182</a> [<a href="http://arxiv.org/pdf/2102.12182" target="_blank">pdf</a>]

<h2>Multiplicative Reweighting for Robust Neural Network Optimization. (arXiv:2102.12192v1 [cs.LG])</h2>
<h3>Noga Bar, Tomer Koren, Raja Giryes</h3>
<p>Deep neural networks are widespread due to their powerful performance. Yet,
they suffer from degraded performance in the presence of noisy labels at train
time or adversarial examples during inference. Inspired by the setting of
learning with expert advice, where multiplicative weights (MW) updates were
recently shown to be robust to moderate adversarial corruptions, we propose to
use MW for reweighting examples during neural networks optimization. We
establish the convergence of our method when used with gradient descent and
demonstrate its advantage in two simple examples. We then validate empirically
our findings by showing that MW improves network's accuracy in the presence of
label noise on CIFAR-10, CIFAR-100 and Clothing1M, and that it leads to better
robustness to adversarial attacks.
</p>
<a href="http://arxiv.org/abs/2102.12192" target="_blank">arXiv:2102.12192</a> [<a href="http://arxiv.org/pdf/2102.12192" target="_blank">pdf</a>]

<h2>Combining Off and On-Policy Training in Model-Based Reinforcement Learning. (arXiv:2102.12194v1 [cs.LG])</h2>
<h3>Alexandre Borges, Arlindo Oliveira</h3>
<p>The combination of deep learning and Monte Carlo Tree Search (MCTS) has shown
to be effective in various domains, such as board and video games. AlphaGo
represented a significant step forward in our ability to learn complex board
games, and it was rapidly followed by significant advances, such as AlphaGo
Zero and AlphaZero. Recently, MuZero demonstrated that it is possible to master
both Atari games and board games by directly learning a model of the
environment, which is then used with MCTS to decide what move to play in each
position. During tree search, the algorithm simulates games by exploring
several possible moves and then picks the action that corresponds to the most
promising trajectory. When training, limited use is made of these simulated
games since none of their trajectories are directly used as training examples.
Even if we consider that not all trajectories from simulated games are useful,
there are thousands of potentially useful trajectories that are discarded.
Using information from these trajectories would provide more training data,
more quickly, leading to faster convergence and higher sample efficiency.
Recent work introduced an off-policy value target for AlphaZero that uses data
from simulated games. In this work, we propose a way to obtain off-policy
targets using data from simulated games in MuZero. We combine these off-policy
targets with the on-policy targets already used in MuZero in several ways, and
study the impact of these targets and their combinations in three environments
with distinct characteristics. When used in the right combinations, our results
show that these targets speed up the training process and lead to faster
convergence and higher rewards than the ones obtained by MuZero.
</p>
<a href="http://arxiv.org/abs/2102.12194" target="_blank">arXiv:2102.12194</a> [<a href="http://arxiv.org/pdf/2102.12194" target="_blank">pdf</a>]

<h2>Identifying Untrustworthy Predictions in Neural Networks by Geometric Gradient Analysis. (arXiv:2102.12196v1 [cs.LG])</h2>
<h3>Leo Schwinn, An Nguyen, Ren&#xe9; Raab, Leon Bungert, Daniel Tenbrinck, Dario Zanca, Martin Burger, Bjoern Eskofier</h3>
<p>The susceptibility of deep neural networks to untrustworthy predictions,
including out-of-distribution (OOD) data and adversarial examples, still
prevent their widespread use in safety-critical applications. Most existing
methods either require a re-training of a given model to achieve robust
identification of adversarial attacks or are limited to out-of-distribution
sample detection only. In this work, we propose a geometric gradient analysis
(GGA) to improve the identification of untrustworthy predictions without
retraining of a given model. GGA analyzes the geometry of the loss landscape of
neural networks based on the saliency maps of their respective input. To
motivate the proposed approach, we provide theoretical connections between
gradients' geometrical properties and local minima of the loss function.
Furthermore, we demonstrate that the proposed method outperforms prior
approaches in detecting OOD data and adversarial attacks, including
state-of-the-art and adaptive attacks.
</p>
<a href="http://arxiv.org/abs/2102.12196" target="_blank">arXiv:2102.12196</a> [<a href="http://arxiv.org/pdf/2102.12196" target="_blank">pdf</a>]

<h2>Enabling the Network to Surf the Internet. (arXiv:2102.12205v1 [cs.CV])</h2>
<h3>Zhuoling Li, Haohan Wang, Tymoteusz Swistek, Weixin Chen, Yuanzheng Li, Haoqian Wang</h3>
<p>Few-shot learning is challenging due to the limited data and labels. Existing
algorithms usually resolve this problem by pre-training the model with a
considerable amount of annotated data which shares knowledge with the target
domain. Nevertheless, large quantities of homogenous data samples are not
always available. To tackle this issue, we develop a framework that enables the
model to surf the Internet, which implies that the model can collect and
annotate data without manual effort. Since the online data is virtually
limitless and continues to be generated, the model can thus be empowered to
constantly obtain up-to-date knowledge from the Internet. Additionally, we
observe that the generalization ability of the learned representation is
crucial for self-supervised learning. To present its importance, a naive yet
efficient normalization strategy is proposed. Consequentially, this strategy
boosts the accuracy of the model significantly (20.46% at most). We demonstrate
the superiority of the proposed framework with experiments on miniImageNet,
tieredImageNet and Omniglot. The results indicate that our method has surpassed
previous unsupervised counterparts by a large margin (more than 10%) and
obtained performance comparable with the supervised ones.
</p>
<a href="http://arxiv.org/abs/2102.12205" target="_blank">arXiv:2102.12205</a> [<a href="http://arxiv.org/pdf/2102.12205" target="_blank">pdf</a>]

<h2>Unsupervised semantic discovery through visual patterns detection. (arXiv:2102.12213v1 [cs.CV])</h2>
<h3>Francesco Pelosin, Andrea Gasparetto, Andrea Albarelli, Andrea Torsello</h3>
<p>We propose a new fast fully unsupervised method to discover semantic
patterns. Our algorithm is able to hierarchically find visual categories and
produce a segmentation mask where previous methods fail. Through the modeling
of what is a visual pattern in an image, we introduce the notion of "semantic
levels" and devise a conceptual framework along with measures and a dedicated
benchmark dataset for future comparisons. Our algorithm is composed by two
phases. A filtering phase, which selects semantical hotsposts by means of an
accumulator space, then a clustering phase which propagates the semantic
properties of the hotspots on a superpixels basis. We provide both qualitative
and quantitative experimental validation, achieving optimal results in terms of
robustness to noise and semantic consistency. We also made code and dataset
publicly available.
</p>
<a href="http://arxiv.org/abs/2102.12213" target="_blank">arXiv:2102.12213</a> [<a href="http://arxiv.org/pdf/2102.12213" target="_blank">pdf</a>]

<h2>A Trident Quaternion Framework for Inertial-based Navigation Part I: Rigid Motion Representation and Computation. (arXiv:2102.12217v1 [cs.RO])</h2>
<h3>Wei Ouyang, Yuanxin Wu</h3>
<p>Strapdown inertial navigation research involves the parameterization and
computation of the attitude, velocity and position of a rigid body in a chosen
reference frame. The community has long devoted to finding the most concise and
efficient representation for the strapdown inertial navigation system (INS).
The current work is motivated by simplifying the existing dual quaternion
representation of the kinematic model. This paper proposes a compact and
elegant representation of the body's attitude, velocity and position, with the
aid of a devised trident quaternion tool in which the position is accounted for
by adding a second imaginary part to the dual quaternion. Eventually, the
kinematics of strapdown INS are cohesively unified in one concise differential
equation, which bears the same form as the classical attitude quaternion
equation. In addition, the computation of this trident quaternion-based
kinematic equation is implemented with the recently proposed functional
iterative integration approach. Numerical results verify the analysis and show
that incorporating the new representation into the functional iterative
integration scheme achieves high inertial navigation computation accuracy as
well.
</p>
<a href="http://arxiv.org/abs/2102.12217" target="_blank">arXiv:2102.12217</a> [<a href="http://arxiv.org/pdf/2102.12217" target="_blank">pdf</a>]

<h2>Multi-Task Temporal Convolutional Networks for Joint Recognition of Surgical Phases and Steps in Gastric Bypass Procedures. (arXiv:2102.12218v1 [cs.CV])</h2>
<h3>Sanat Ramesh, Diego Dall&#x27;Alba, Cristians Gonzalez, Tong Yu, Pietro Mascagni, Didier Mutter, Jacques Marescaux, Paolo Fiorini, Nicolas Padoy</h3>
<p>Purpose: Automatic segmentation and classification of surgical activity is
crucial for providing advanced support in computer-assisted interventions and
autonomous functionalities in robot-assisted surgeries. Prior works have
focused on recognizing either coarse activities, such as phases, or
fine-grained activities, such as gestures. This work aims at jointly
recognizing two complementary levels of granularity directly from videos,
namely phases and steps. Method: We introduce two correlated surgical
activities, phases and steps, for the laparoscopic gastric bypass procedure. We
propose a Multi-task Multi-Stage Temporal Convolutional Network (MTMS-TCN)
along with a multi-task Convolutional Neural Network (CNN) training setup to
jointly predict the phases and steps and benefit from their complementarity to
better evaluate the execution of the procedure. We evaluate the proposed method
on a large video dataset consisting of 40 surgical procedures (Bypass40).
Results: We present experimental results from several baseline models for both
phase and step recognition on the Bypass40 dataset. The proposed MTMS-TCN
method outperforms in both phase and step recognition by 1-2% in accuracy,
precision and recall, compared to single-task methods. Furthermore, for step
recognition, MTMS-TCN achieves a superior performance of 3-6% compared to LSTM
based models in accuracy, precision, and recall. Conclusion: In this work, we
present a multi-task multi-stage temporal convolutional network for surgical
activity recognition, which shows improved results compared to single-task
models on the Bypass40 gastric bypass dataset with multi-level annotations. The
proposed method shows that the joint modeling of phases and steps is beneficial
to improve the overall recognition of each type of activity.
</p>
<a href="http://arxiv.org/abs/2102.12218" target="_blank">arXiv:2102.12218</a> [<a href="http://arxiv.org/pdf/2102.12218" target="_blank">pdf</a>]

<h2>Object Detection in Aerial Images: A Large-Scale Benchmark and Challenges. (arXiv:2102.12219v1 [cs.CV])</h2>
<h3>Jian Ding, Nan Xue, Gui-Song Xia, Xiang Bai, Wen Yang, Micheal Ying Yang, Serge Belongie, Jiebo Luo, Mihai Datcu, Marcello Pelillo, Liangpei Zhang</h3>
<p>In the past decade, object detection has achieved significant progress in
natural images but not in aerial images, due to the massive variations in the
scale and orientation of objects caused by the bird's-eye view of aerial
images. More importantly, the lack of large-scale benchmarks becomes a major
obstacle to the development of object detection in aerial images (ODAI). In
this paper, we present a large-scale Dataset of Object deTection in Aerial
images (DOTA) and comprehensive baselines for ODAI. The proposed DOTA dataset
contains 1,793,658 object instances of 18 categories of oriented-bounding-box
annotations collected from 11,268 aerial images. Based on this large-scale and
well-annotated dataset, we build baselines covering 10 state-of-the-art
algorithms with over 70 configurations, where the speed and accuracy
performances of each model have been evaluated. Furthermore, we provide a
uniform code library for ODAI and build a website for testing and evaluating
different algorithms. Previous challenges run on DOTA have attracted more than
1300 teams worldwide. We believe that the expanded large-scale DOTA dataset,
the extensive baselines, the code library and the challenges can facilitate the
designs of robust algorithms and reproducible research on the problem of object
detection in aerial images.
</p>
<a href="http://arxiv.org/abs/2102.12219" target="_blank">arXiv:2102.12219</a> [<a href="http://arxiv.org/pdf/2102.12219" target="_blank">pdf</a>]

<h2>A Trident Quaternion Framework for Inertial-based Navigation Part II: Error Models and Application to Initial Alignment. (arXiv:2102.12220v1 [cs.RO])</h2>
<h3>Wei Ouyang, Yuanxin Wu</h3>
<p>This work deals with error models for trident quaternion framework proposed
in the companion paper "A Trident Quaternion Framework for Inertial-based
Navigation Part I: Motion Representation and Computation" and further uses them
to investigate the static and in-motion alignment for land vehicles.
Specifically, the zero-velocity and odometer velocity measurements are applied
in the static and in-motion alignment process, respectively. By linearizing the
trident quaternion kinematic equation, the right and left trident quaternion
error models are obtained. The resultant models are found to be equivalent to
those derived from profound group affine. Then the two models are used to
design the corresponding extended Kalman filters (EKF), namely, the
left-quaternion EKF (LQEKF) and the right-quaternion EKF (RQEKF). Simulations
and field tests are conducted to evaluate their actual performances. For the
static alignment, owing to their high consistency, the L/RQEKF converge much
faster than the EKF even without any heading information. For the in-motion
alignment, however, the two filters still need the assistance of the
analytical/optimization-based in-motion alignment methods at the very start to
avoid extremely large attitude errors, although they possess much larger
convergence region than the traditional EKF does.
</p>
<a href="http://arxiv.org/abs/2102.12220" target="_blank">arXiv:2102.12220</a> [<a href="http://arxiv.org/pdf/2102.12220" target="_blank">pdf</a>]

<h2>A CP-Net based Qualitative Composition Approach for an IaaS Provider. (arXiv:2102.12221v1 [cs.AI])</h2>
<h3>Sheik Mohammad Mostakim Fattah, Athman Bouguettaya, Sajib Mistry</h3>
<p>We propose a novel CP-Net based composition approach to qualitatively select
an optimal set of consumers for an IaaS provider. The IaaS provider's and
consumers' qualitative preferences are captured using CP-Nets. We propose a
CP-Net composability model using the semantic congruence property of a
qualitative composition. A greedy-based and a heuristic-based consumer
selection approaches are proposed that effectively reduce the search space of
candidate consumers in the composition. Experimental results prove the
feasibility of the proposed composition approach.
</p>
<a href="http://arxiv.org/abs/2102.12221" target="_blank">arXiv:2102.12221</a> [<a href="http://arxiv.org/pdf/2102.12221" target="_blank">pdf</a>]

<h2>Abelian Neural Networks. (arXiv:2102.12232v1 [cs.LG])</h2>
<h3>Kenshin Abe, Takanori Maehara, Issei Sato</h3>
<p>We study the problem of modeling a binary operation that satisfies some
algebraic requirements. We first construct a neural network architecture for
Abelian group operations and derive a universal approximation property. Then,
we extend it to Abelian semigroup operations using the characterization of
associative symmetric polynomials. Both models take advantage of the analytic
invertibility of invertible neural networks. For each case, by repeating the
binary operations, we can represent a function for multiset input thanks to the
algebraic structure. Naturally, our multiset architecture has
size-generalization ability, which has not been obtained in existing methods.
Further, we present modeling the Abelian group operation itself is useful in a
word analogy task. We train our models over fixed word embeddings and
demonstrate improved performance over the original word2vec and another naive
learning method.
</p>
<a href="http://arxiv.org/abs/2102.12232" target="_blank">arXiv:2102.12232</a> [<a href="http://arxiv.org/pdf/2102.12232" target="_blank">pdf</a>]

<h2>Inductive Bias of Multi-Channel Linear Convolutional Networks with Bounded Weight Norm. (arXiv:2102.12238v1 [cs.LG])</h2>
<h3>Meena Jagadeesan, Ilya Razenshteyn, Suriya Gunasekar</h3>
<p>We study the function space characterization of the inductive bias resulting
from controlling the $\ell_2$ norm of the weights in linear convolutional
networks. We view this in terms of an induced regularizer in the function space
given by the minimum norm of weights required to realize a linear function. For
two layer linear convolutional networks with $C$ output channels and kernel
size $K$, we show the following: (a) If the inputs to the network have a single
channel, the induced regularizer for any $K$ is a norm given by a semidefinite
program (SDP) that is independent of the number of output channels $C$. We
further validate these results through a binary classification task on MNIST.
(b) In contrast, for networks with multi-channel inputs, multiple output
channels can be necessary to merely realize all matrix-valued linear functions
and thus the inductive bias does depend on $C$. Further, for sufficiently large
$C$, the induced regularizer for $K=1$ and $K=D$ are the nuclear norm and the
$\ell_{2,1}$ group-sparse norm, respectively, of the Fourier coefficients --
both of which promote sparse structures.
</p>
<a href="http://arxiv.org/abs/2102.12238" target="_blank">arXiv:2102.12238</a> [<a href="http://arxiv.org/pdf/2102.12238" target="_blank">pdf</a>]

<h2>State-of-the-Art in Human Scanpath Prediction. (arXiv:2102.12239v1 [cs.CV])</h2>
<h3>Matthias K&#xfc;mmerer, Matthias Bethge</h3>
<p>The last years have seen a surge in models predicting the scanpaths of
fixations made by humans when viewing images. However, the field is lacking a
principled comparison of those models with respect to their predictive power.
In the past, models have usually been evaluated based on comparing human
scanpaths to scanpaths generated from the model. Here, instead we evaluate
models based on how well they predict each fixation in a scanpath given the
previous scanpath history. This makes model evaluation closely aligned with the
biological processes thought to underly scanpath generation and allows to apply
established saliency metrics like AUC and NSS in an intuitive and interpretable
way. We evaluate many existing models of scanpath prediction on the datasets
MIT1003, MIT300, CAT2000 train and CAT200 test, for the first time giving a
detailed picture of the current state of the art of human scanpath prediction.
We also show that the discussed method of model benchmarking allows for more
detailed analyses leading to interesting insights about where and when models
fail to predict human behaviour. The MIT/Tuebingen Saliency Benchmark will
implement the evaluation of scanpath models as detailed here, allowing
researchers to score their models on the established benchmark datasets MIT300
and CAT2000.
</p>
<a href="http://arxiv.org/abs/2102.12239" target="_blank">arXiv:2102.12239</a> [<a href="http://arxiv.org/pdf/2102.12239" target="_blank">pdf</a>]

<h2>Estimation of Continuous Blood Pressure from PPG via a Federated Learning Approach. (arXiv:2102.12245v1 [cs.LG])</h2>
<h3>Eoin Brophy, Maarten De Vos, Geraldine Boylan, Tomas Ward</h3>
<p>Ischemic heart disease is the highest cause of mortality globally each year.
This not only puts a massive strain on the lives of those affected but also on
the public healthcare systems. To understand the dynamics of the healthy and
unhealthy heart doctors commonly use electrocardiogram (ECG) and blood pressure
(BP) readings. These methods are often quite invasive, in particular when
continuous arterial blood pressure (ABP) readings are taken and not to mention
very costly. Using machine learning methods we seek to develop a framework that
is capable of inferring ABP from a single optical photoplethysmogram (PPG)
sensor alone. We train our framework across distributed models and data sources
to mimic a large-scale distributed collaborative learning experiment that could
be implemented across low-cost wearables. Our time series-to-time series
generative adversarial network (T2TGAN) is capable of high-quality continuous
ABP generation from a PPG signal with a mean error of 2.54 mmHg and a standard
deviation of 23.7 mmHg when estimating mean arterial pressure on a previously
unseen, noisy, independent dataset. To our knowledge, this framework is the
first example of a GAN capable of continuous ABP generation from an input PPG
signal that also uses a federated learning methodology.
</p>
<a href="http://arxiv.org/abs/2102.12245" target="_blank">arXiv:2102.12245</a> [<a href="http://arxiv.org/pdf/2102.12245" target="_blank">pdf</a>]

<h2>Localization Distillation for Object Detection. (arXiv:2102.12252v1 [cs.CV])</h2>
<h3>Zhaohui Zheng, Rongguang Ye, Ping Wang, Jun Wang, Dongwei Ren, Wangmeng Zuo</h3>
<p>Knowledge distillation (KD) has witnessed its powerful ability in learning
compact models in deep learning field, but it is still limited in distilling
localization information for object detection. Existing KD methods for object
detection mainly focus on mimicking deep features between teacher model and
student model, which not only is restricted by specific model architectures,
but also cannot distill localization ambiguity. In this paper, we first propose
localization distillation (LD) for object detection. In particular, our LD can
be formulated as standard KD by adopting the general localization
representation of bounding box. Our LD is very flexible, and is applicable to
distill localization ambiguity for arbitrary architecture of teacher model and
student model. Moreover, it is interesting to find that Self-LD, i.e.,
distilling teacher model itself, can further boost state-of-the-art
performance. Second, we suggest a teacher assistant (TA) strategy to fill the
possible gap between teacher model and student model, by which the distillation
effectiveness can be guaranteed even the selected teacher model is not optimal.
On benchmark datasets PASCAL VOC and MS COCO, our LD can consistently improve
the performance for student detectors, and also boosts state-of-the-art
detectors notably. Our source code and trained models are publicly available at
https://github.com/HikariTJU/LD
</p>
<a href="http://arxiv.org/abs/2102.12252" target="_blank">arXiv:2102.12252</a> [<a href="http://arxiv.org/pdf/2102.12252" target="_blank">pdf</a>]

<h2>An Enhanced Prohibited Items Recognition Model. (arXiv:2102.12256v1 [cs.CV])</h2>
<h3>Tianze Rong, Hongxiang Cai, Yichao Xiong</h3>
<p>We proposed a new modeling method to promote the performance of prohibited
items recognition via X-ray image. We analyzed the characteristics of
prohibited items and X-ray images. We found the fact that the scales of some
items are too small to be recognized which encumber the model performance. Then
we adopted a set of data augmentation and modified the model to adapt the field
of prohibited items recognition. The Convolutional Block Attention Module(CBAM)
and rescoring mechanism has been assembled into the model. By the modification,
our model achieved a mAP of 89.9% on SIXray10, mAP of 74.8%.
</p>
<a href="http://arxiv.org/abs/2102.12256" target="_blank">arXiv:2102.12256</a> [<a href="http://arxiv.org/pdf/2102.12256" target="_blank">pdf</a>]

<h2>Classification with abstention but without disparities. (arXiv:2102.12258v1 [stat.ML])</h2>
<h3>Nicolas Schreuder, Evgenii Chzhen</h3>
<p>Classification with abstention has gained a lot of attention in recent years
as it allows to incorporate human decision-makers in the process. Yet,
abstention can potentially amplify disparities and lead to discriminatory
predictions. The goal of this work is to build a general purpose classification
algorithm, which is able to abstain from prediction, while avoiding disparate
impact. We formalize this problem as risk minimization under fairness and
abstention constraints for which we derive the form of the optimal classifier.
Building on this result, we propose a post-processing classification algorithm,
which is able to modify any off-the-shelf score-based classifier using only
unlabeled sample. We establish finite sample risk, fairness, and abstention
guarantees for the proposed algorithm. In particular, it is shown that fairness
and abstention constraints can be achieved independently from the initial
classifier as long as sufficiently many unlabeled data is available. The risk
guarantee is established in terms of the quality of the initial classifier. Our
post-processing scheme reduces to a sparse linear program allowing for an
efficient implementation, which we provide. Finally, we validate our method
empirically showing that moderate abstention rates allow to bypass the
risk-fairness trade-off.
</p>
<a href="http://arxiv.org/abs/2102.12258" target="_blank">arXiv:2102.12258</a> [<a href="http://arxiv.org/pdf/2102.12258" target="_blank">pdf</a>]

<h2>Graphfool: Targeted Label Adversarial Attack on Graph Embedding. (arXiv:2102.12284v1 [cs.LG])</h2>
<h3>Jinyin Chen, Xiang Lin, Dunjie Zhang, Wenrong Jiang, Guohan Huang, Hui Xiong, Yun Xiang</h3>
<p>Deep learning is effective in graph analysis. It is widely applied in many
related areas, such as link prediction, node classification, community
detection, and graph classification etc. Graph embedding, which learns
low-dimensional representations for vertices or edges in the graph, usually
employs deep models to derive the embedding vector. However, these models are
vulnerable. We envision that graph embedding methods based on deep models can
be easily attacked using adversarial examples. Thus, in this paper, we propose
Graphfool, a novel targeted label adversarial attack on graph embedding. It can
generate adversarial graph to attack graph embedding methods via classifying
boundary and gradient information in graph convolutional network (GCN).
Specifically, we perform the following steps: 1),We first estimate the
classification boundaries of different classes. 2), We calculate the minimal
perturbation matrix to misclassify the attacked vertex according to the target
classification boundary. 3), We modify the adjacency matrix according to the
maximal absolute value of the disturbance matrix. This process is implemented
iteratively. To the best of our knowledge, this is the first targeted label
attack technique. The experiments on real-world graph networks demonstrate that
Graphfool can derive better performance than state-of-art techniques. Compared
with the second best algorithm, Graphfool can achieve an average improvement of
11.44% in attack success rate.
</p>
<a href="http://arxiv.org/abs/2102.12284" target="_blank">arXiv:2102.12284</a> [<a href="http://arxiv.org/pdf/2102.12284" target="_blank">pdf</a>]

<h2>Two-way kernel matrix puncturing: towards resource-efficient PCA and spectral clustering. (arXiv:2102.12293v1 [cs.LG])</h2>
<h3>Romain Couillet, Florent Chatelain, Nicolas Le Bihan</h3>
<p>The article introduces an elementary cost and storage reduction method for
spectral clustering and principal component analysis. The method consists in
randomly "puncturing" both the data matrix $X\in\mathbb{C}^{p\times n}$ (or
$\mathbb{R}^{p\times n}$) and its corresponding kernel (Gram) matrix $K$
through Bernoulli masks: $S\in\{0,1\}^{p\times n}$ for $X$ and
$B\in\{0,1\}^{n\times n}$ for $K$. The resulting "two-way punctured" kernel is
thus given by $K=\frac{1}{p}[(X \odot S)^{\sf H} (X \odot S)] \odot B$. We
demonstrate that, for $X$ composed of independent columns drawn from a Gaussian
mixture model, as $n,p\to\infty$ with $p/n\to c_0\in(0,\infty)$, the spectral
behavior of $K$ -- its limiting eigenvalue distribution, as well as its
isolated eigenvalues and eigenvectors -- is fully tractable and exhibits a
series of counter-intuitive phenomena. We notably prove, and empirically
confirm on GAN-generated image databases, that it is possible to drastically
puncture the data, thereby providing possibly huge computational and storage
gains, for a virtually constant (clustering of PCA) performance. This
preliminary study opens as such the path towards rethinking, from a large
dimensional standpoint, computational and storage costs in elementary machine
learning models.
</p>
<a href="http://arxiv.org/abs/2102.12293" target="_blank">arXiv:2102.12293</a> [<a href="http://arxiv.org/pdf/2102.12293" target="_blank">pdf</a>]

<h2>Image Augmentation for Multitask Few-Shot Learning: Agricultural Domain Use-Case. (arXiv:2102.12295v1 [cs.CV])</h2>
<h3>Sergey Nesteruk, Dmitrii Shadrin, Mariia Pukalchik</h3>
<p>Large datasets' availability is catalyzing a rapid expansion of deep learning
in general and computer vision in particular. At the same time, in many
domains, a sufficient amount of training data is lacking, which may become an
obstacle to the practical application of computer vision techniques. This paper
challenges small and imbalanced datasets based on the example of a plant
phenomics domain. We introduce an image augmentation framework, which enables
us to extremely enlarge the number of training samples while providing the data
for such tasks as object detection, semantic segmentation, instance
segmentation, object counting, image denoising, and classification. We prove
that our augmentation method increases model performance when only a few
training samples are available. In our experiment, we use the DeepLabV3 model
on semantic segmentation tasks with Arabidopsis and Nicotiana tabacum image
dataset. The obtained result shows a 9% relative increase in model performance
compared to the basic image augmentation techniques.
</p>
<a href="http://arxiv.org/abs/2102.12295" target="_blank">arXiv:2102.12295</a> [<a href="http://arxiv.org/pdf/2102.12295" target="_blank">pdf</a>]

<h2>Mobile Recharger Path Planning and Recharge Scheduling in a Multi-Robot Environment. (arXiv:2102.12296v1 [cs.RO])</h2>
<h3>Tanmoy Kundu, Indranil Saha</h3>
<p>In many multi-robot applications, mobile worker robots are often engaged in
performing some tasks repetitively by following pre-computed trajectories. As
these robots are battery-powered, they need to get recharged at regular
intervals. We envision that in the future, a few mobile recharger robots will
be employed to supply charge to the energy-deficient worker robots recurrently,
to keep the overall efficiency of the system optimized.In this setup, we need
to find the time instants and locations for the meeting of the worker robots
and recharger robots optimally. We present a Satisfiability Modulo Theory
(SMT)-based approach that captures the activities of the robots in the form of
constraints in a sufficiently long finite-length time window (hypercycle) whose
repetitions provide their perpetual behavior. Our SMT encoding ensures that for
a chosen length of the hypercycle, the total waiting time of the worker robots
due to charge constraints is minimized under certain condition, and close to
optimal when the condition does not hold. Moreover, the recharger robots follow
the most energy-efficient trajectories. We show the efficacy of our approach by
comparing it with another variant of the SMT-based method which is not scalable
but provides an optimal solution globally, and with a greedy algorithm.
</p>
<a href="http://arxiv.org/abs/2102.12296" target="_blank">arXiv:2102.12296</a> [<a href="http://arxiv.org/pdf/2102.12296" target="_blank">pdf</a>]

<h2>Balancing Rational and Other-Regarding Preferences in Cooperative-Competitive Environments. (arXiv:2102.12307v1 [cs.LG])</h2>
<h3>Dmitry Ivanov, Vladimir Egorov, Aleksei Shpilman</h3>
<p>Recent reinforcement learning studies extensively explore the interplay
between cooperative and competitive behaviour in mixed environments. Unlike
cooperative environments where agents strive towards a common goal, mixed
environments are notorious for the conflicts of selfish and social interests.
As a consequence, purely rational agents often struggle to achieve and maintain
cooperation. A prevalent approach to induce cooperative behaviour is to assign
additional rewards based on other agents' well-being. However, this approach
suffers from the issue of multi-agent credit assignment, which can hinder
performance. This issue is efficiently alleviated in cooperative setting with
such state-of-the-art algorithms as QMIX and COMA. Still, when applied to mixed
environments, these algorithms may result in unfair allocation of rewards. We
propose BAROCCO, an extension of these algorithms capable to balance individual
and social incentives. The mechanism behind BAROCCO is to train two distinct
but interwoven components that jointly affect each agent's decisions. Our
meta-algorithm is compatible with both Q-learning and Actor-Critic frameworks.
We experimentally confirm the advantages over the existing methods and explore
the behavioural aspects of BAROCCO in two mixed multi-agent setups.
</p>
<a href="http://arxiv.org/abs/2102.12307" target="_blank">arXiv:2102.12307</a> [<a href="http://arxiv.org/pdf/2102.12307" target="_blank">pdf</a>]

<h2>"Train one, Classify one, Teach one" -- Cross-surgery transfer learning for surgical step recognition. (arXiv:2102.12308v1 [cs.CV])</h2>
<h3>Daniel Neimark, Omri Bar, Maya Zohar, Gregory D. Hager, Dotan Asselmann</h3>
<p>Prior work demonstrated the ability of machine learning to automatically
recognize surgical workflow steps from videos. However, these studies focused
on only a single type of procedure. In this work, we analyze, for the first
time, surgical step recognition on four different laparoscopic surgeries:
Cholecystectomy, Right Hemicolectomy, Sleeve Gastrectomy, and Appendectomy.
Inspired by the traditional apprenticeship model, in which surgical training is
based on the Halstedian method, we paraphrase the "see one, do one, teach one"
approach for the surgical intelligence domain as "train one, classify one,
teach one". In machine learning, this approach is often referred to as transfer
learning. To analyze the impact of transfer learning across different
laparoscopic procedures, we explore various time-series architectures and
examine their performance on each target domain. We introduce a new
architecture, the Time-Series Adaptation Network (TSAN), an architecture
optimized for transfer learning of surgical step recognition, and we show how
TSAN can be pre-trained using self-supervised learning on a Sequence Sorting
task. Such pre-training enables TSAN to learn workflow steps of a new
laparoscopic procedure type from only a small number of labeled samples from
the target procedure. Our proposed architecture leads to better performance
compared to other possible architectures, reaching over 90% accuracy when
transferring from laparoscopic Cholecystectomy to the other three procedure
types.
</p>
<a href="http://arxiv.org/abs/2102.12308" target="_blank">arXiv:2102.12308</a> [<a href="http://arxiv.org/pdf/2102.12308" target="_blank">pdf</a>]

<h2>Learning-Augmented Sketches for Hessians. (arXiv:2102.12317v1 [cs.LG])</h2>
<h3>Yi Li, Honghao Lin, David P. Woodruff</h3>
<p>Sketching is a dimensionality reduction technique where one compresses a
matrix by linear combinations that are typically chosen at random. A line of
work has shown how to sketch the Hessian to speed up each iteration in a second
order method, but such sketches usually depend only on the matrix at hand, and
in a number of cases are even oblivious to the input matrix. One could instead
hope to learn a distribution on sketching matrices that is optimized for the
specific distribution of input matrices. We show how to design learned sketches
for the Hessian in the context of second order methods, where we learn
potentially different sketches for the different iterations of an optimization
procedure. We show empirically that learned sketches, compared with their
"non-learned" counterparts, improve the approximation accuracy for important
problems, including LASSO, SVM, and matrix estimation with nuclear norm
constraints. Several of our schemes can be proven to perform no worse than
their unlearned counterparts. Additionally, we show that a smaller sketching
dimension of the column space of a tall matrix is possible, assuming an oracle
for predicting rows which have a large leverage score.
</p>
<a href="http://arxiv.org/abs/2102.12317" target="_blank">arXiv:2102.12317</a> [<a href="http://arxiv.org/pdf/2102.12317" target="_blank">pdf</a>]

<h2>Set-valued classification -- overview via a unified framework. (arXiv:2102.12318v1 [stat.ML])</h2>
<h3>Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Titouan Lorieul</h3>
<p>Multi-class classification problem is among the most popular and well-studied
statistical frameworks. Modern multi-class datasets can be extremely ambiguous
and single-output predictions fail to deliver satisfactory performance. By
allowing predictors to predict a set of label candidates, set-valued
classification offers a natural way to deal with this ambiguity. Several
formulations of set-valued classification are available in the literature and
each of them leads to different prediction strategies. The present survey aims
to review popular formulations using a unified statistical framework. The
proposed framework encompasses previously considered and leads to new
formulations as well as it allows to understand underlying trade-offs of each
formulation. We provide infinite sample optimal set-valued classification
strategies and review a general plug-in principle to construct data-driven
algorithms. The exposition is supported by examples and pointers to both
theoretical and practical contributions. Finally, we provide experiments on
real-world datasets comparing these approaches in practice and providing
general practical guidelines.
</p>
<a href="http://arxiv.org/abs/2102.12318" target="_blank">arXiv:2102.12318</a> [<a href="http://arxiv.org/pdf/2102.12318" target="_blank">pdf</a>]

<h2>GEM: Glare or Gloom, I Can Still See You -- End-to-End Multimodal Object Detector. (arXiv:2102.12319v1 [cs.CV])</h2>
<h3>Osama Mazhar, Jens Kober, Robert Babuska</h3>
<p>Deep neural networks designed for vision tasks are often prone to failure
when they encounter environmental conditions not covered by the training data.
Efficient fusion strategies for multi-sensor configurations can enhance the
robustness of the detection algorithms by exploiting redundancy from different
sensor streams. In this paper, we propose sensor-aware multi-modal fusion
strategies for 2D object detection in harsh-lighting conditions. Our network
learns to estimate the measurement reliability of each sensor modality in the
form of scalar weights and masks, without prior knowledge of the sensor
characteristics. The obtained weights are assigned to the extracted feature
maps which are subsequently fused and passed to the transformer encoder-decoder
network for object detection. This is critical in the case of asymmetric sensor
failures and to prevent any tragic consequences. Through extensive
experimentation, we show that the proposed strategies out-perform the existing
state-of-the-art methods on the FLIR-Thermal dataset, improving the mAP up-to
25.2%. We also propose a new "r-blended" hybrid depth modality for RGB-D
multi-modal detection tasks. Our proposed method also obtained promising
results on the SUNRGB-D dataset.
</p>
<a href="http://arxiv.org/abs/2102.12319" target="_blank">arXiv:2102.12319</a> [<a href="http://arxiv.org/pdf/2102.12319" target="_blank">pdf</a>]

<h2>AGENT: A Benchmark for Core Psychological Reasoning. (arXiv:2102.12321v1 [cs.AI])</h2>
<h3>Tianmin Shu, Abhishek Bhandwaldar, Chuang Gan, Kevin A. Smith, Shari Liu, Dan Gutfreund, Elizabeth Spelke, Joshua B. Tenenbaum, Tomer D. Ullman</h3>
<p>For machine agents to successfully interact with humans in real-world
settings, they will need to develop an understanding of human mental life.
Intuitive psychology, the ability to reason about hidden mental variables that
drive observable actions, comes naturally to people: even pre-verbal infants
can tell agents from objects, expecting agents to act efficiently to achieve
goals given constraints. Despite recent interest in machine agents that reason
about other agents, it is not clear if such agents learn or hold the core
psychology principles that drive human reasoning. Inspired by cognitive
development studies on intuitive psychology, we present a benchmark consisting
of a large dataset of procedurally generated 3D animations, AGENT (Action,
Goal, Efficiency, coNstraint, uTility), structured around four scenarios (goal
preferences, action efficiency, unobserved constraints, and cost-reward
trade-offs) that probe key concepts of core intuitive psychology. We validate
AGENT with human-ratings, propose an evaluation protocol emphasizing
generalization, and compare two strong baselines built on Bayesian inverse
planning and a Theory of Mind neural network. Our results suggest that to pass
the designed tests of core intuitive psychology at human levels, a model must
acquire or have built-in representations of how agents plan, combining utility
computations and core knowledge of objects and physics.
</p>
<a href="http://arxiv.org/abs/2102.12321" target="_blank">arXiv:2102.12321</a> [<a href="http://arxiv.org/pdf/2102.12321" target="_blank">pdf</a>]

<h2>Iterative Refinement for Real-Time Multi-Robot Path Planning. (arXiv:2102.12331v1 [cs.RO])</h2>
<h3>Keisuke Okumura, Yasumasa Tamura, Xavier Defago</h3>
<p>We study the iterative refinement of path planning for multiple robots, known
as multi-agent pathfinding (MAPF). Given a graph, agents, their initial
locations, and destinations, a solution of MAPF is a set of paths without
collisions. Iterative refinement for MAPF is desirable for three reasons: 1)
optimization is intractable, 2) sub-optimal solutions can be obtained
instantly, and 3) it is anytime planning, desired in online scenarios where
time for deliberation is limited. Despite the high demand, this is
under-explored in MAPF because finding good neighborhoods has been unclear so
far. Our proposal uses a sub-optimal MAPF solver to obtain an initial solution
quickly, then iterates the two procedures: 1) select a subset of agents, 2) use
an optimal MAPF solver to refine paths of selected agents while keeping other
paths unchanged. Since the optimal solvers are used on small instances of the
problem, this scheme yields efficient-enough solutions rapidly while providing
high scalability. We also present reasonable candidates on how to select a
subset of agents. Evaluations in various scenarios show that the proposal is
promising; the convergence is fast, scalable, with reasonable quality, and
practical because it can be interrupted whenever the solution is needed.
</p>
<a href="http://arxiv.org/abs/2102.12331" target="_blank">arXiv:2102.12331</a> [<a href="http://arxiv.org/pdf/2102.12331" target="_blank">pdf</a>]

<h2>Similarity measure for sparse time course data based on Gaussian processes. (arXiv:2102.12342v1 [cs.LG])</h2>
<h3>Zijing Liu, Mauricio Barahona</h3>
<p>We propose a similarity measure for sparsely sampled time course data in the
form of a log-likelihood ratio of Gaussian processes (GP). The proposed GP
similarity is similar to a Bayes factor and provides enhanced robustness to
noise in sparse time series, such as those found in various biological
settings, e.g., gene transcriptomics. We show that the GP measure is equivalent
to the Euclidean distance when the noise variance in the GP is negligible
compared to the noise variance of the signal. Our numerical experiments on both
synthetic and real data show improved performance of the GP similarity when
used in conjunction with two distance-based clustering methods.
</p>
<a href="http://arxiv.org/abs/2102.12342" target="_blank">arXiv:2102.12342</a> [<a href="http://arxiv.org/pdf/2102.12342" target="_blank">pdf</a>]

<h2>Memory-based Deep Reinforcement Learning for POMDP. (arXiv:2102.12344v1 [cs.LG])</h2>
<h3>Lingheng Meng, Rob Gorbet, Dana Kuli&#x107;</h3>
<p>A promising characteristic of Deep Reinforcement Learning (DRL) is its
capability to learn optimal policy in an end-to-end manner without relying on
feature engineering. However, most approaches assume a fully observable state
space, i.e. fully observable Markov Decision Process (MDP). In real-world
robotics, this assumption is unpractical, because of the sensor issues such as
sensors' capacity limitation and sensor noise, and the lack of knowledge about
if the observation design is complete or not. These scenarios lead to Partially
Observable MDP (POMDP) and need special treatment. In this paper, we propose
Long-Short-Term-Memory-based Twin Delayed Deep Deterministic Policy Gradient
(LSTM-TD3) by introducing a memory component to TD3, and compare its
performance with other DRL algorithms in both MDPs and POMDPs. Our results
demonstrate the significant advantages of the memory component in addressing
POMDPs, including the ability to handle missing and noisy observation data.
</p>
<a href="http://arxiv.org/abs/2102.12344" target="_blank">arXiv:2102.12344</a> [<a href="http://arxiv.org/pdf/2102.12344" target="_blank">pdf</a>]

<h2>AutoAI-TS: AutoAI for Time Series Forecasting. (arXiv:2102.12347v1 [cs.LG])</h2>
<h3>Syed Yousaf Shah, Dhaval Patel, Long Vu, Xuan-Hong Dang, Bei Chen, Peter Kirchner, Horst Samulowitz, David Wood, Gregory Bramble, Wesley M. Gifford, Giridhar Ganapavarapu, Roman Vaculin, Petros Zerfos</h3>
<p>A large number of time series forecasting models including traditional
statistical models, machine learning models and more recently deep learning
have been proposed in the literature. However, choosing the right model along
with good parameter values that performs well on a given data is still
challenging. Automatically providing a good set of models to users for a given
dataset saves both time and effort from using trial-and-error approaches with a
wide variety of available models along with parameter optimization. We present
AutoAI for Time Series Forecasting (AutoAI-TS) that provides users with a zero
configuration (zero-conf ) system to efficiently train, optimize and choose
best forecasting model among various classes of models for the given dataset.
With its flexible zero-conf design, AutoAI-TS automatically performs all the
data preparation, model creation, parameter optimization, training and model
selection for users and provides a trained model that is ready to use. For
given data, AutoAI-TS utilizes a wide variety of models including classical
statistical models, Machine Learning (ML) models, statistical-ML hybrid models
and deep learning models along with various transformations to create
forecasting pipelines. It then evaluates and ranks pipelines using the proposed
T-Daub mechanism to choose the best pipeline. The paper describe in detail all
the technical aspects of AutoAI-TS along with extensive benchmarking on a
variety of real world data sets for various use-cases. Benchmark results show
that AutoAI-TS, with no manual configuration from the user, automatically
trains and selects pipelines that on average outperform existing
state-of-the-art time series forecasting toolkits.
</p>
<a href="http://arxiv.org/abs/2102.12347" target="_blank">arXiv:2102.12347</a> [<a href="http://arxiv.org/pdf/2102.12347" target="_blank">pdf</a>]

<h2>Nonlinear Invariant Risk Minimization: A Causal Approach. (arXiv:2102.12353v1 [cs.LG])</h2>
<h3>Chaochao Lu, Yuhuai Wu, Jo&#x15b;e Miguel Hern&#xe1;ndez-Lobato, Bernhard Sch&#xf6;lkopf</h3>
<p>Due to spurious correlations, machine learning systems often fail to
generalize to environments whose distributions differ from the ones used at
training time. Prior work addressing this, either explicitly or implicitly,
attempted to find a data representation that has an invariant causal
relationship with the target. This is done by leveraging a diverse set of
training environments to reduce the effect of spurious features and build an
invariant predictor. However, these methods have generalization guarantees only
when both data representation and classifiers come from a linear model class.
We propose Invariant Causal Representation Learning (ICRL), a learning paradigm
that enables out-of-distribution (OOD) generalization in the nonlinear setting
(i.e., nonlinear representations and nonlinear classifiers). It builds upon a
practical and general assumption: the prior over the data representation
factorizes when conditioning on the target and the environment. Based on this,
we show identifiability of the data representation up to very simple
transformations. We also prove that all direct causes of the target can be
fully discovered, which further enables us to obtain generalization guarantees
in the nonlinear setting. Extensive experiments on both synthetic and
real-world datasets show that our approach significantly outperforms a variety
of baseline methods. Finally, in the concluding discussion, we further explore
the aforementioned assumption and propose a general view, called the Agnostic
Hypothesis: there exist a set of hidden causal factors affecting both inputs
and outcomes. The Agnostic Hypothesis can provide a unifying view of machine
learning in terms of representation learning. More importantly, it can inspire
a new direction to explore the general theory for identifying hidden causal
factors, which is key to enabling the OOD generalization guarantees in machine
learning.
</p>
<a href="http://arxiv.org/abs/2102.12353" target="_blank">arXiv:2102.12353</a> [<a href="http://arxiv.org/pdf/2102.12353" target="_blank">pdf</a>]

<h2>On the Impact of Interpretability Methods in Active Image Augmentation Method. (arXiv:2102.12354v1 [cs.CV])</h2>
<h3>Flavio Santos, Cleber Zanchettin, Leonardo Matos, Paulo Novais</h3>
<p>Robustness is a significant constraint in machine learning models. The
performance of the algorithms must not deteriorate when training and testing
with slightly different data. Deep neural network models achieve awe-inspiring
results in a wide range of applications of computer vision. Still, in the
presence of noise or region occlusion, some models exhibit inaccurate
performance even with data handled in training. Besides, some experiments
suggest deep learning models sometimes use incorrect parts of the input
information to perform inference. Activate Image Augmentation (ADA) is an
augmentation method that uses interpretability methods to augment the training
data and improve its robustness to face the described problems. Although ADA
presented interesting results, its original version only used the Vanilla
Backpropagation interpretability to train the U-Net model. In this work, we
propose an extensive experimental analysis of the interpretability method's
impact on ADA. We use five interpretability methods: Vanilla Backpropagation,
Guided Backpropagation, GradCam, Guided GradCam, and InputXGradient. The
results show that all methods achieve similar performance at the ending of
training, but when combining ADA with GradCam, the U-Net model presented an
impressive fast convergence.
</p>
<a href="http://arxiv.org/abs/2102.12354" target="_blank">arXiv:2102.12354</a> [<a href="http://arxiv.org/pdf/2102.12354" target="_blank">pdf</a>]

<h2>HiPaR: Hierarchical Pattern-aided Regression. (arXiv:2102.12370v1 [cs.LG])</h2>
<h3>Luis Gal&#xe1;rraga, Olivier Pelgrin, Alexandre Termier</h3>
<p>We introduce HiPaR, a novel pattern-aided regression method for tabular data
containing both categorical and numerical attributes. HiPaR mines hybrid rules
of the form $p \Rightarrow y = f(X)$ where $p$ is the characterization of a
data region and $f(X)$ is a linear regression model on a variable of interest
$y$. HiPaR relies on pattern mining techniques to identify regions of the data
where the target variable can be accurately explained via local linear models.
The novelty of the method lies in the combination of an enumerative approach to
explore the space of regions and efficient heuristics that guide the search.
Such a strategy provides more flexibility when selecting a small set of jointly
accurate and human-readable hybrid rules that explain the entire dataset. As
our experiments shows, HiPaR mines fewer rules than existing pattern-based
regression methods while still attaining state-of-the-art prediction
performance.
</p>
<a href="http://arxiv.org/abs/2102.12370" target="_blank">arXiv:2102.12370</a> [<a href="http://arxiv.org/pdf/2102.12370" target="_blank">pdf</a>]

<h2>Transfer of Fully Convolutional Policy-Value Networks Between Games and Game Variants. (arXiv:2102.12375v1 [cs.LG])</h2>
<h3>Dennis J.N.J. Soemers, Vegard Mella, Eric Piette, Matthew Stephenson, Cameron Browne, Olivier Teytaud</h3>
<p>In this paper, we use fully convolutional architectures in AlphaZero-like
self-play training setups to facilitate transfer between variants of board
games as well as distinct games. We explore how to transfer trained parameters
of these architectures based on shared semantics of channels in the state and
action representations of the Ludii general game system. We use Ludii's large
library of games and game variants for extensive transfer learning evaluations,
in zero-shot transfer experiments as well as experiments with additional
fine-tuning time.
</p>
<a href="http://arxiv.org/abs/2102.12375" target="_blank">arXiv:2102.12375</a> [<a href="http://arxiv.org/pdf/2102.12375" target="_blank">pdf</a>]

<h2>Pre-Training on Dynamic Graph Neural Networks. (arXiv:2102.12380v1 [cs.LG])</h2>
<h3>Jiajun Zhang, Kejia Chen, Yunyun Wang</h3>
<p>The pre-training on the graph neural network model can learn the general
features of large-scale networks or networks of the same type by
self-supervised methods, which allows the model to work even when node labels
are missing. However, the existing pre-training methods do not take network
evolution into consideration. This paper proposes a pre-training method on
dynamic graph neural networks (PT-DGNN), which uses dynamic attributed graph
generation tasks to simultaneously learn the structure, semantics, and
evolution features of the graph. The method includes two steps: 1) dynamic
sub-graph sampling, and 2) pre-training with dynamic attributed graph
generation task. Comparative experiments on three realistic dynamic network
datasets show that the proposed method achieves the best results on the link
prediction fine-tuning task.
</p>
<a href="http://arxiv.org/abs/2102.12380" target="_blank">arXiv:2102.12380</a> [<a href="http://arxiv.org/pdf/2102.12380" target="_blank">pdf</a>]

<h2>R2LIVE: A Robust, Real-time, LiDAR-Inertial-Visual tightly-coupled state Estimator and mapping. (arXiv:2102.12400v1 [cs.RO])</h2>
<h3>Jiarong Lin, Chunran Zheng, Wei Xu, Fu Zhang</h3>
<p>In this letter, we propose a robust, real-time tightly-coupled multi-sensor
fusion framework, which fuses measurement from LiDAR, inertial sensor, and
visual camera to achieve robust and accurate state estimation. Our proposed
framework is composed of two parts: the filter-based odometry and factor graph
optimization. To guarantee real-time performance, we estimate the state within
the framework of error-state iterated Kalman-filter, and further improve the
overall precision with our factor graph optimization. Taking advantage of
measurement from all individual sensors, our algorithm is robust enough to
various visual failure, LiDAR-degenerated scenarios, and is able to run in
real-time on an on-board computation platform, as shown by extensive
experiments conducted in indoor, outdoor, and mixed environment of different
scale. Moreover, the results show that our proposed framework can improve the
accuracy of state-of-the-art LiDAR-inertial or visual-inertial odometry. To
share our findings and to make contributions to the community, we open source
our codes on our Github.
</p>
<a href="http://arxiv.org/abs/2102.12400" target="_blank">arXiv:2102.12400</a> [<a href="http://arxiv.org/pdf/2102.12400" target="_blank">pdf</a>]

<h2>Synthetic Returns for Long-Term Credit Assignment. (arXiv:2102.12425v1 [cs.LG])</h2>
<h3>David Raposo, Sam Ritter, Adam Santoro, Greg Wayne, Theophane Weber, Matt Botvinick, Hado van Hasselt, Francis Song</h3>
<p>Since the earliest days of reinforcement learning, the workhorse method for
assigning credit to actions over time has been temporal-difference (TD)
learning, which propagates credit backward timestep-by-timestep. This approach
suffers when delays between actions and rewards are long and when intervening
unrelated events contribute variance to long-term returns. We propose
state-associative (SA) learning, where the agent learns associations between
states and arbitrarily distant future rewards, then propagates credit directly
between the two. In this work, we use SA-learning to model the contribution of
past states to the current reward. With this model we can predict each state's
contribution to the far future, a quantity we call "synthetic returns".
TD-learning can then be applied to select actions that maximize these synthetic
returns (SRs). We demonstrate the effectiveness of augmenting agents with SRs
across a range of tasks on which TD-learning alone fails. We show that the
learned SRs are interpretable: they spike for states that occur after critical
actions are taken. Finally, we show that our IMPALA-based SR agent solves Atari
Skiing -- a game with a lengthy reward delay that posed a major hurdle to
deep-RL agents -- 25 times faster than the published state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2102.12425" target="_blank">arXiv:2102.12425</a> [<a href="http://arxiv.org/pdf/2102.12425" target="_blank">pdf</a>]

<h2>Noisy Gradient Descent Converges to Flat Minima for Nonconvex Matrix Factorization. (arXiv:2102.12430v1 [cs.LG])</h2>
<h3>Tianyi Liu, Yan Li, Song Wei, Enlu Zhou, Tuo Zhao</h3>
<p>Numerous empirical evidences have corroborated the importance of noise in
nonconvex optimization problems. The theory behind such empirical observations,
however, is still largely unknown. This paper studies this fundamental problem
through investigating the nonconvex rectangular matrix factorization problem,
which has infinitely many global minima due to rotation and scaling invariance.
Hence, gradient descent (GD) can converge to any optimum, depending on the
initialization. In contrast, we show that a perturbed form of GD with an
arbitrary initialization converges to a global optimum that is uniquely
determined by the injected noise. Our result implies that the noise imposes
implicit bias towards certain optima. Numerical experiments are provided to
support our theory.
</p>
<a href="http://arxiv.org/abs/2102.12430" target="_blank">arXiv:2102.12430</a> [<a href="http://arxiv.org/pdf/2102.12430" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning for Safe Landing Site Selection with Concurrent Consideration of Divert Maneuvers. (arXiv:2102.12432v1 [cs.RO])</h2>
<h3>Keidai Iiyama, Kento Tomita, Bhavi A. Jagatia, Tatsuwaki Nakagawa, Koki Ho</h3>
<p>This research proposes a new integrated framework for identifying safe
landing locations and planning in-flight divert maneuvers. The state-of-the-art
algorithms for landing zone selection utilize local terrain features such as
slopes and roughness to judge the safety and priority of the landing point.
However, when there are additional chances of observation and diverting in the
future, these algorithms are not able to evaluate the safety of the decision
itself to target the selected landing point considering the overall descent
trajectory. In response to this challenge, we propose a reinforcement learning
framework that optimizes a landing site selection strategy concurrently with a
guidance and control strategy to the target landing site. The trained agent
could evaluate and select landing sites with explicit consideration of the
terrain features, quality of future observations, and control to achieve a safe
and efficient landing trajectory at a system-level. The proposed framework was
able to achieve 94.8 $\%$ of successful landing in highly challenging landing
sites where over 80$\%$ of the area around the initial target lading point is
hazardous, by effectively updating the target landing site and feedback control
gain during descent.
</p>
<a href="http://arxiv.org/abs/2102.12432" target="_blank">arXiv:2102.12432</a> [<a href="http://arxiv.org/pdf/2102.12432" target="_blank">pdf</a>]

<h2>A generative, predictive model for menstrual cycle lengths that accounts for potential self-tracking artifacts in mobile health data. (arXiv:2102.12439v1 [cs.LG])</h2>
<h3>Kathy Li, I&#xf1;igo Urteaga, Amanda Shea, Virginia J. Vitzthum, Chris H. Wiggins, No&#xe9;mie Elhadad</h3>
<p>Mobile health (mHealth) apps such as menstrual trackers provide a rich source
of self-tracked health observations that can be leveraged for statistical
modeling. However, such data streams are notoriously unreliable since they
hinge on user adherence to the app. Thus, it is crucial for machine learning
models to account for self-tracking artifacts like skipped self-tracking. In
this abstract, we propose and evaluate a hierarchical, generative model for
predicting next cycle length based on previously tracked cycle lengths that
accounts explicitly for the possibility of users forgetting to track their
period. Our model offers several advantages: 1) accounting explicitly for
self-tracking artifacts yields better prediction accuracy as likelihood of
skipping increases; 2) as a generative model, predictions can be updated online
as a given cycle evolves; and 3) its hierarchical nature enables modeling of an
individual's cycle length history while incorporating population-level
information. Our experiments using real mHealth cycle length data from 5,000
menstruators show that our method yields state-of-the-art performance against
neural network-based and summary statistic-based baselines.
</p>
<a href="http://arxiv.org/abs/2102.12439" target="_blank">arXiv:2102.12439</a> [<a href="http://arxiv.org/pdf/2102.12439" target="_blank">pdf</a>]

<h2>A Straightforward Framework For Video Retrieval Using CLIP. (arXiv:2102.12443v1 [cs.CV])</h2>
<h3>Jes&#xfa;s Andr&#xe9;s Portillo-Quintero, Jos&#xe9; Carlos Ortiz-Bayliss, Hugo Terashima-Mar&#xed;n</h3>
<p>Video Retrieval is a challenging task where a text query is matched to a
video or vice versa. Most of the existing approaches for addressing such a
problem rely on annotations made by the users. Although simple, this approach
is not always feasible in practice. In this work, we explore the application of
the language-image model, CLIP, to obtain video representations without the
need for said annotations. This model was explicitly trained to learn a common
space where images and text can be compared. Using various techniques described
in this document, we extended its application to videos, obtaining
state-of-the-art results on the MSR-VTT and MSVD benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.12443" target="_blank">arXiv:2102.12443</a> [<a href="http://arxiv.org/pdf/2102.12443" target="_blank">pdf</a>]

<h2>Generating and Blending Game Levels via Quality-Diversity in the Latent Space of a Variational Autoencoder. (arXiv:2102.12463v1 [cs.LG])</h2>
<h3>Anurag Sarkar, Seth Cooper</h3>
<p>Several recent works have demonstrated the use of variational autoencoders
(VAEs) for both generating levels in the style of existing games as well as
blending levels across different games. Additionally, quality-diversity (QD)
algorithms have also become popular for generating varied game content by using
evolution to explore a search space while focusing on both variety and quality.
In order to reap the benefits of both these approaches, we present a level
generation and game blending approach that combines the use of VAEs and QD
algorithms. Specifically, we train VAEs on game levels and then run the
MAP-Elites QD algorithm using the learned latent space of the VAE as the search
space. The latent space captures the properties of the games whose levels we
want to generate and blend, while MAP-Elites searches this latent space to find
a diverse set of levels optimizing a given objective such as playability. We
test our method using models for 5 different platformer games as well as a
blended domain spanning 3 of these games. Our results show that using
MAP-Elites in conjunction with VAEs enables the generation of a diverse set of
playable levels not just for each individual game but also for the blended
domain while illuminating game-specific regions of the blended latent space.
</p>
<a href="http://arxiv.org/abs/2102.12463" target="_blank">arXiv:2102.12463</a> [<a href="http://arxiv.org/pdf/2102.12463" target="_blank">pdf</a>]

<h2>Information Directed Reward Learning for Reinforcement Learning. (arXiv:2102.12466v1 [cs.LG])</h2>
<h3>David Lindner, Matteo Turchetta, Sebastian Tschiatschek, Kamil Ciosek, Andreas Krause</h3>
<p>For many reinforcement learning (RL) applications, specifying a reward is
difficult. In this paper, we consider an RL setting where the agent can obtain
information about the reward only by querying an expert that can, for example,
evaluate individual states or provide binary preferences over trajectories.
From such expensive feedback, we aim to learn a model of the reward function
that allows standard RL algorithms to achieve high expected return with as few
expert queries as possible. For this purpose, we propose Information Directed
Reward Learning (IDRL), which uses a Bayesian model of the reward function and
selects queries that maximize the information gain about the difference in
return between potentially optimal policies. In contrast to prior active reward
learning methods designed for specific types of queries, IDRL naturally
accommodates different query types. Moreover, by shifting the focus from
reducing the reward approximation error to improving the policy induced by the
reward model, it achieves similar or better performance with significantly
fewer queries. We support our findings with extensive evaluations in multiple
environments and with different types of queries.
</p>
<a href="http://arxiv.org/abs/2102.12466" target="_blank">arXiv:2102.12466</a> [<a href="http://arxiv.org/pdf/2102.12466" target="_blank">pdf</a>]

<h2>No-Regret Algorithms for Private Gaussian Process Bandit Optimization. (arXiv:2102.12467v1 [stat.ML])</h2>
<h3>Abhimanyu Dubey</h3>
<p>The widespread proliferation of data-driven decision-making has ushered in a
recent interest in the design of privacy-preserving algorithms. In this paper,
we consider the ubiquitous problem of gaussian process (GP) bandit optimization
from the lens of privacy-preserving statistics. We propose a solution for
differentially private GP bandit optimization that combines a uniform kernel
approximator with random perturbations, providing a generic framework to create
differentially-private (DP) Gaussian process bandit algorithms. For two
specific DP settings - joint and local differential privacy, we provide
algorithms based on efficient quadrature Fourier feature approximators, that
are computationally efficient and provably no-regret for popular stationary
kernel functions. Our algorithms maintain differential privacy throughout the
optimization procedure and critically do not rely explicitly on the sample path
for prediction, making the parameters straightforward to release as well.
</p>
<a href="http://arxiv.org/abs/2102.12467" target="_blank">arXiv:2102.12467</a> [<a href="http://arxiv.org/pdf/2102.12467" target="_blank">pdf</a>]

<h2>On the Validity of Modeling SGD with Stochastic Differential Equations (SDEs). (arXiv:2102.12470v1 [cs.LG])</h2>
<h3>Zhiyuan Li, Sadhika Malladi, Sanjeev Arora</h3>
<p>It is generally recognized that finite learning rate (LR), in contrast to
infinitesimal LR, is important for good generalization in real-life deep nets.
Most attempted explanations propose approximating finite-LR SGD with Ito
Stochastic Differential Equations (SDEs). But formal justification for this
approximation (e.g., (Li et al., 2019a)) only applies to SGD with tiny LR.
Experimental verification of the approximation appears computationally
infeasible. The current paper clarifies the picture with the following
contributions: (a) An efficient simulation algorithm SVAG that provably
converges to the conventionally used Ito SDE approximation. (b) Experiments
using this simulation to demonstrate that the previously proposed SDE
approximation can meaningfully capture the training and generalization
properties of common deep nets. (c) A provable and empirically testable
necessary condition for the SDE approximation to hold and also its most famous
implication, the linear scaling rule (Smith et al., 2020; Goyal et al., 2017).
The analysis also gives rigorous insight into why the SDE approximation may
fail.
</p>
<a href="http://arxiv.org/abs/2102.12470" target="_blank">arXiv:2102.12470</a> [<a href="http://arxiv.org/pdf/2102.12470" target="_blank">pdf</a>]

<h2>4D Panoptic LiDAR Segmentation. (arXiv:2102.12472v1 [cs.CV])</h2>
<h3>Mehmet Ayg&#xfc;n, Aljo&#x161;a O&#x161;ep, Mark Weber, Maxim Maximov, Cyrill Stachniss, Jens Behley, Laura Leal-Taix&#xe9;</h3>
<p>Temporal semantic scene understanding is critical for self-driving cars or
robots operating in dynamic environments. In this paper, we propose 4D panoptic
LiDAR segmentation to assign a semantic class and a temporally-consistent
instance ID to a sequence of 3D points. To this end, we present an approach and
a point-centric evaluation metric. Our approach determines a semantic class for
every point while modeling object instances as probability distributions in the
4D spatio-temporal domain. We process multiple point clouds in parallel and
resolve point-to-instance associations, effectively alleviating the need for
explicit temporal data association. Inspired by recent advances in benchmarking
of multi-object tracking, we propose to adopt a new evaluation metric that
separates the semantic and point-to-instance association aspects of the task.
With this work, we aim at paving the road for future developments of temporal
LiDAR panoptic perception.
</p>
<a href="http://arxiv.org/abs/2102.12472" target="_blank">arXiv:2102.12472</a> [<a href="http://arxiv.org/pdf/2102.12472" target="_blank">pdf</a>]

<h2>Character-Based Handwritten Text Transcription with Attention Networks. (arXiv:1712.04046v3 [cs.CV] UPDATED)</h2>
<h3>Jason Poulos, Rafael Valle</h3>
<p>The paper approaches the task of handwritten text recognition (HTR) with
attentional encoder-decoder networks trained on sequences of characters, rather
than words. We experiment on lines of text from popular handwriting datasets
and compare different activation functions for the attention mechanism used for
aligning image pixels and target characters. We find that softmax attention
focuses heavily on individual characters, while sigmoid attention focuses on
multiple characters at each step of the decoding. When the sequence alignment
is one-to-one, softmax attention is able to learn a more precise alignment at
each step of the decoding, whereas the alignment generated by sigmoid attention
is much less precise. When a linear function is used to obtain attention
weights, the model predicts a character by looking at the entire sequence of
characters and performs poorly because it lacks a precise alignment between the
source and target. Future research may explore HTR in natural scene images,
since the model is capable of transcribing handwritten text without the need
for producing segmentations or bounding boxes of text in images.
</p>
<a href="http://arxiv.org/abs/1712.04046" target="_blank">arXiv:1712.04046</a> [<a href="http://arxiv.org/pdf/1712.04046" target="_blank">pdf</a>]

<h2>The decoupled extended Kalman filter for dynamic exponential-family factorization models. (arXiv:1806.09976v2 [stat.ML] UPDATED)</h2>
<h3>Carlos Alberto Gomez-Uribe, Brian Karrer</h3>
<p>Motivated by the needs of online large-scale recommender systems, we
specialize the decoupled extended Kalman filter (DEKF) to factorization models,
including factorization machines, matrix and tensor factorization, and
illustrate the effectiveness of the approach through numerical experiments on
synthetic and on real-world data. Online learning of model parameters through
the DEKF makes factorization models more broadly useful by (i) allowing for
more flexible observations through the entire exponential family, (ii) modeling
parameter drift, and (iii) producing parameter uncertainty estimates that can
enable explore/exploit and other applications. We use a different parameter
dynamics than the standard DEKF, allowing parameter drift while encouraging
reasonable values. We also present an alternate derivation of the extended
Kalman filter and DEKF that highlights the role of the Fisher information
matrix in the EKF.
</p>
<a href="http://arxiv.org/abs/1806.09976" target="_blank">arXiv:1806.09976</a> [<a href="http://arxiv.org/pdf/1806.09976" target="_blank">pdf</a>]

<h2>Learning Multiple Defaults for Machine Learning Algorithms. (arXiv:1811.09409v2 [stat.ML] UPDATED)</h2>
<h3>Florian Pfisterer, Jan N. van Rijn, Philipp Probst, Andreas M&#xfc;ller, Bernd Bischl</h3>
<p>The performance of modern machine learning methods highly depends on their
hyperparameter configurations. One simple way of selecting a configuration is
to use default settings, often proposed along with the publication and
implementation of a new algorithm. Those default values are usually chosen in
an ad-hoc manner to work good enough on a wide variety of datasets. To address
this problem, different automatic hyperparameter configuration algorithms have
been proposed, which select an optimal configuration per dataset. This
principled approach usually improves performance, but adds additional
algorithmic complexity and computational costs to the training procedure. As an
alternative to this, we propose learning a set of complementary default values
from a large database of prior empirical results. Selecting an appropriate
configuration on a new dataset then requires only a simple, efficient and
embarrassingly parallel search over this set. We demonstrate the effectiveness
and efficiency of the approach we propose in comparison to random search and
Bayesian Optimization.
</p>
<a href="http://arxiv.org/abs/1811.09409" target="_blank">arXiv:1811.09409</a> [<a href="http://arxiv.org/pdf/1811.09409" target="_blank">pdf</a>]

<h2>Face morphing detection in the presence of printing/scanning and heterogeneous image sources. (arXiv:1901.08811v4 [cs.CV] UPDATED)</h2>
<h3>Matteo Ferrara, Annalisa Franco, Davide Maltoni</h3>
<p>Face morphing represents nowadays a big security threat in the context of
electronic identity documents as well as an interesting challenge for
researchers in the field of face recognition. Despite of the good performance
obtained by state-of-the-art approaches on digital images, no satisfactory
solutions have been identified so far to deal with cross-database testing and
printed-scanned images (typically used in many countries for document issuing).
In this work, novel approaches are proposed to train Deep Neural Networks for
morphing detection: in particular generation of simulated printed-scanned
images together with other data augmentation strategies and pre-training on
large face recognition datasets, allowed to reach state-of-the-art accuracy on
challenging datasets from heterogeneous image sources.
</p>
<a href="http://arxiv.org/abs/1901.08811" target="_blank">arXiv:1901.08811</a> [<a href="http://arxiv.org/pdf/1901.08811" target="_blank">pdf</a>]

<h2>Labelling Vertebrae with 2D Reformations of Multidetector CT Images: An Adversarial Approach for Incorporating Prior Knowledge of Spine Anatomy. (arXiv:1902.02205v3 [cs.CV] UPDATED)</h2>
<h3>Anjany Sekuboyina, Markus Rempfler, Alexander Valentinitsch, Bjoern H. Menze, Jan S. Kirschke</h3>
<p>Purpose: To use and test a labelling algorithm that operates on
two-dimensional (2D) reformations, rather than three-dimensional (3D) data to
locate and identify vertebrae.

Methods: We improved the Btrfly Net (described by Sekuboyina et al) that
works on sagittal and coronal maximum intensity projections (MIP) and augmented
it with two additional components: spine-localization and adversarial a
priori-learning. Furthermore, we explored two variants of adversarial training
schemes that incorporated the anatomical a priori knowledge into the Btrfly
Net. We investigated the superiority of the proposed approach for labelling
vertebrae on three datasets: a public benchmarking dataset of 302 CT scans and
two in-house datasets with a total of 238 CT scans. We employed Wilcoxon
signed-rank test to compute the statistical significance of the improvement in
performance observed due to various architectural components in our approach.

Results: On the public dataset, our approach using the described
Btrfly(pe-eb) network performed on par with current state-of-the-art methods
achieving a statistically significant (p &lt; .001) vertebrae identification rate
of 88.5+/-0.2 % and localization distances of less than 7-mm. On the in-house
datasets that had a higher inter-scan data variability, we obtained an
identification rate of 85.1+/-1.2%.

Conclusion: An identification performance comparable to existing 3D
approaches was achieved when labelling vertebrae on 2D MIPs. The performance
was further improved using the proposed adversarial training regime that
effectively enforced local spine a priori knowledge during training. Lastly,
spine-localization increased the generalizability of our approach by
homogenizing the content in the MIPs.
</p>
<a href="http://arxiv.org/abs/1902.02205" target="_blank">arXiv:1902.02205</a> [<a href="http://arxiv.org/pdf/1902.02205" target="_blank">pdf</a>]

<h2>A Plug-in Method for Representation Factorization in Connectionist Models. (arXiv:1905.11088v4 [cs.LG] UPDATED)</h2>
<h3>Jee Seok Yoon, Myung-Cheol Roh, Heung-Il Suk</h3>
<p>In this article, we focus on decomposing latent representations in generative
adversarial networks or learned feature representations in deep autoencoders
into semantically controllable factors in a semisupervised manner, without
modifying the original trained models. Particularly, we propose factors'
decomposer-entangler network (FDEN) that learns to decompose a latent
representation into mutually independent factors. Given a latent
representation, the proposed framework draws a set of interpretable factors,
each aligned to independent factors of variations by minimizing their total
correlation in an information-theoretic means. As a plug-in method, we have
applied our proposed FDEN to the existing networks of adversarially learned
inference and pioneer network and performed computer vision tasks of
image-to-image translation in semantic ways, e.g., changing styles, while
keeping the identity of a subject, and object classification in a few-shot
learning scheme. We have also validated the effectiveness of the proposed
method with various ablation studies in the qualitative, quantitative, and
statistical examination.
</p>
<a href="http://arxiv.org/abs/1905.11088" target="_blank">arXiv:1905.11088</a> [<a href="http://arxiv.org/pdf/1905.11088" target="_blank">pdf</a>]

<h2>Noise Contrastive Meta-Learning for Conditional Density Estimation using Kernel Mean Embeddings. (arXiv:1906.02236v2 [stat.ML] UPDATED)</h2>
<h3>Jean-Francois Ton, Lucian Chan, Yee Whye Teh, Dino Sejdinovic</h3>
<p>Current meta-learning approaches focus on learning functional representations
of relationships between variables, i.e. on estimating conditional expectations
in regression. In many applications, however, we are faced with conditional
distributions which cannot be meaningfully summarized using expectation only
(due to e.g. multimodality). Hence, we consider the problem of conditional
density estimation in the meta-learning setting. We introduce a novel technique
for meta-learning which combines neural representation and noise-contrastive
estimation with the established literature of conditional mean embeddings into
reproducing kernel Hilbert spaces. The method is validated on synthetic and
real-world problems, demonstrating the utility of sharing learned
representations across multiple conditional density estimation tasks.
</p>
<a href="http://arxiv.org/abs/1906.02236" target="_blank">arXiv:1906.02236</a> [<a href="http://arxiv.org/pdf/1906.02236" target="_blank">pdf</a>]

<h2>Benchmarking time series classification -- Functional data vs machine learning approaches. (arXiv:1911.07511v2 [stat.ML] UPDATED)</h2>
<h3>Florian Pfisterer, Laura Beggel, Xudong Sun, Fabian Scheipl, Bernd Bischl</h3>
<p>Time series classification problems have drawn increasing attention in the
machine learning and statistical community. Closely related is the field of
functional data analysis (FDA): it refers to the range of problems that deal
with the analysis of data that is continuously indexed over some domain. While
often employing different methods, both fields strive to answer similar
questions, a common example being classification or regression problems with
functional covariates. We study methods from functional data analysis, such as
functional generalized additive models, as well as functionality to concatenate
(functional-) feature extraction or basis representations with traditional
machine learning algorithms like support vector machines or classification
trees. In order to assess the methods and implementations, we run a benchmark
on a wide variety of representative (time series) data sets, with in-depth
analysis of empirical results, and strive to provide a reference ranking for
which method(s) to use for non-expert practitioners. Additionally, we provide a
software framework in R for functional data analysis for supervised learning,
including machine learning and more linear approaches from statistics. This
allows convenient access, and in connection with the machine-learning toolbox
mlr, those methods can now also be tuned and benchmarked.
</p>
<a href="http://arxiv.org/abs/1911.07511" target="_blank">arXiv:1911.07511</a> [<a href="http://arxiv.org/pdf/1911.07511" target="_blank">pdf</a>]

<h2>Pneumothorax Segmentation: Deep Learning Image Segmentation to predict Pneumothorax. (arXiv:1912.07329v3 [cs.CV] UPDATED)</h2>
<h3>Karan Jakhar</h3>
<p>Computer vision has shown promising results in medical image processing.
Pneumothorax is a deadly condition and if not diagnosed and treated at time
then it causes death. It can be diagnosed with chest X-ray images. We need an
expert and experienced radiologist to predict whether a person is suffering
from pneumothorax or not by looking at the chest X-ray images. Everyone does
not have access to such a facility. Moreover, in some cases, we need quick
diagnoses. So we propose an image segmentation model to predict and give the
output a mask that will assist the doctor in taking this crucial decision. Deep
Learning has proved their worth in many areas and outperformed man
state-of-the-art models. We want to use the power of these deep learning model
to solve this problem. We have used U-net [13] architecture with ResNet [17] as
a backbone and achieved promising results. U-net [13] performs very well in
medical image processing and semantic segmentation. Our problem falls in the
semantic segmentation category.
</p>
<a href="http://arxiv.org/abs/1912.07329" target="_blank">arXiv:1912.07329</a> [<a href="http://arxiv.org/pdf/1912.07329" target="_blank">pdf</a>]

<h2>Learning to Group: A Bottom-Up Framework for 3D Part Discovery in Unseen Categories. (arXiv:2002.06478v2 [cs.CV] UPDATED)</h2>
<h3>Tiange Luo, Kaichun Mo, Zhiao Huang, Jiarui Xu, Siyu Hu, Liwei Wang, Hao Su</h3>
<p>We address the problem of discovering 3D parts for objects in unseen
categories. Being able to learn the geometry prior of parts and transfer this
prior to unseen categories pose fundamental challenges on data-driven shape
segmentation approaches. Formulated as a contextual bandit problem, we propose
a learning-based agglomerative clustering framework which learns a grouping
policy to progressively group small part proposals into bigger ones in a
bottom-up fashion. At the core of our approach is to restrict the local context
for extracting part-level features, which encourages the generalizability to
unseen categories. On the large-scale fine-grained 3D part dataset, PartNet, we
demonstrate that our method can transfer knowledge of parts learned from 3
training categories to 21 unseen testing categories without seeing any
annotated samples. Quantitative comparisons against four shape segmentation
baselines shows that our approach achieve the state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2002.06478" target="_blank">arXiv:2002.06478</a> [<a href="http://arxiv.org/pdf/2002.06478" target="_blank">pdf</a>]

<h2>An Optimization and Generalization Analysis for Max-Pooling Networks. (arXiv:2002.09781v3 [cs.LG] UPDATED)</h2>
<h3>Alon Brutzkus, Amir Globerson</h3>
<p>Max-Pooling operations are a core component of deep learning architectures.
In particular, they are part of most convolutional architectures used in
machine vision, since pooling is a natural approach to pattern detection
problems. However, these architectures are not well understood from a
theoretical perspective. For example, we do not understand when they can be
globally optimized, and what is the effect of over-parameterization on
generalization. Here we perform a theoretical analysis of a convolutional
max-pooling architecture, proving that it can be globally optimized, and can
generalize well even for highly over-parameterized models. Our analysis focuses
on a data generating distribution inspired by pattern detection problem, where
a "discriminative" pattern needs to be detected among "spurious" patterns. We
empirically validate that CNNs significantly outperform fully connected
networks in our setting, as predicted by our theoretical results.
</p>
<a href="http://arxiv.org/abs/2002.09781" target="_blank">arXiv:2002.09781</a> [<a href="http://arxiv.org/pdf/2002.09781" target="_blank">pdf</a>]

<h2>Towards CRISP-ML(Q): A Machine Learning Process Model with Quality Assurance Methodology. (arXiv:2003.05155v2 [cs.LG] UPDATED)</h2>
<h3>Stefan Studer, Thanh Binh Bui, Christian Drescher, Alexander Hanuschkin, Ludwig Winkler, Steven Peters, Klaus-Robert Mueller</h3>
<p>Machine learning is an established and frequently used technique in industry
and academia but a standard process model to improve success and efficiency of
machine learning applications is still missing. Project organizations and
machine learning practitioners have a need for guidance throughout the life
cycle of a machine learning application to meet business expectations. We
therefore propose a process model for the development of machine learning
applications, that covers six phases from defining the scope to maintaining the
deployed machine learning application. The first phase combines business and
data understanding as data availability oftentimes affects the feasibility of
the project. The sixth phase covers state-of-the-art approaches for monitoring
and maintenance of a machine learning applications, as the risk of model
degradation in a changing environment is eminent. With each task of the
process, we propose quality assurance methodology that is suitable to adress
challenges in machine learning development that we identify in form of risks.
The methodology is drawn from practical experience and scientific literature
and has proven to be general and stable. The process model expands on CRISP-DM,
a data mining process model that enjoys strong industry support but lacks to
address machine learning specific tasks. Our work proposes an industry and
application neutral process model tailored for machine learning applications
with focus on technical tasks for quality assurance.
</p>
<a href="http://arxiv.org/abs/2003.05155" target="_blank">arXiv:2003.05155</a> [<a href="http://arxiv.org/pdf/2003.05155" target="_blank">pdf</a>]

<h2>Long Tail Visual Relationship Recognition with Hubless Regularized Relmix. (arXiv:2004.00436v5 [cs.CV] UPDATED)</h2>
<h3>Sherif Abdelkarim, Aniket Agarwal, Panos Achlioptas, Jun Chen, Jiaji Huang, Boyang Li, Kenneth Church, Mohamed Elhoseiny</h3>
<p>Several approaches have been proposed in recent literature to alleviate the
long-tail problem, mostly in the object classification task. We propose to
study the task of Long-Tail Visual Relationship Recognition (LTVRR), which aims
at generalizing on the structured long-tail distribution of visual
relationships (e.g., "rabbit grazing on grass"). In this setup, subject,
relation, and object classes individually follow a long-tail distribution. We
first introduce two large-scale long-tail visual relationship recognition
benchmarks to study this task, dubbed as VG8K-LT (5330 objects, 2000
relationships) and GQA-LT (1703 objects, 310 relations). VG8K-LT and GQA-LT are
built upon the widely used Visual Genome and GQA datasets. In contrast to
existing benchmarks, some classes appear at a very low frequency ($1-14$
examples). We use these benchmarks to study the performance of several
state-of-the-art long-tail models on LTVRR setup. We developed a
visiolinguistic hubless (ViLHub) loss that consistently encourages visual
classifiers to be more predictive of tail classes while being accurate on the
head. We also propose relationship Mixup augmentation, dubbed as RelMix, to
improve performance on the tail on VG8K-LT and GQA-LT benchmarks with the best
performance achieved when combined with ViLHub loss. Benchmarks and code will
be made available.
</p>
<a href="http://arxiv.org/abs/2004.00436" target="_blank">arXiv:2004.00436</a> [<a href="http://arxiv.org/pdf/2004.00436" target="_blank">pdf</a>]

<h2>Information-Theoretic Abstractions for Planning in Agents with Computational Constraints. (arXiv:2005.09611v2 [cs.RO] UPDATED)</h2>
<h3>Daniel T. Larsson, Dipankar Maity, Panagiotis Tsiotras</h3>
<p>In this paper, we develop a framework for path-planning on abstractions that
are not provided to the agent a priori but instead emerge as a function of the
available computational resources. We show how a path-planning problem in an
environment can be systematically approximated by solving a sequence of easier
to solve problems on abstractions of the original space. The properties of the
problem are analyzed, and a number of theoretical results are presented and
discussed. A numerical example is presented to show the utility of the approach
and to corroborate the theoretical findings. We conclude by providing a
discussion detailing the connections of the proposed approach to anytime
algorithms and bounded rationality.
</p>
<a href="http://arxiv.org/abs/2005.09611" target="_blank">arXiv:2005.09611</a> [<a href="http://arxiv.org/pdf/2005.09611" target="_blank">pdf</a>]

<h2>Hadamard Wirtinger Flow for Sparse Phase Retrieval. (arXiv:2006.01065v2 [stat.ML] UPDATED)</h2>
<h3>Fan Wu, Patrick Rebeschini</h3>
<p>We consider the problem of reconstructing an $n$-dimensional $k$-sparse
signal from a set of noiseless magnitude-only measurements. Formulating the
problem as an unregularized empirical risk minimization task, we study the
sample complexity performance of gradient descent with Hadamard
parametrization, which we call Hadamard Wirtinger flow (HWF). Provided
knowledge of the signal sparsity $k$, we prove that a single step of HWF is
able to recover the support from $k(x^*_{max})^{-2}$ (modulo logarithmic term)
samples, where $x^*_{max}$ is the largest component of the signal in magnitude.
This support recovery procedure can be used to initialize existing
reconstruction methods and yields algorithms with total runtime proportional to
the cost of reading the data and improved sample complexity, which is linear in
$k$ when the signal contains at least one large component. We numerically
investigate the performance of HWF at convergence and show that, while not
requiring any explicit form of regularization nor knowledge of $k$, HWF adapts
to the signal sparsity and reconstructs sparse signals with fewer measurements
than existing gradient based methods.
</p>
<a href="http://arxiv.org/abs/2006.01065" target="_blank">arXiv:2006.01065</a> [<a href="http://arxiv.org/pdf/2006.01065" target="_blank">pdf</a>]

<h2>Optimal Transport for Conditional Domain Matching and Label Shift. (arXiv:2006.08161v3 [cs.LG] UPDATED)</h2>
<h3>Alain Rakotomamonjy (Criteo AI Lab), R&#xe9;mi Flamary (CMAP), Gilles Gasso (DocApp - LITIS), Mokhtar Z. Alaya (LMAC, Compi&#xe8;gne), Maxime Berar (DocApp - LITIS), Nicolas Courty (OBELIX)</h3>
<p>We address the problem of unsupervised domain adaptation under the setting of
generalized target shift (joint class-conditional and label shifts). For this
framework, we theoretically show that, for good generalization, it is necessary
to learn a latent representation in which both marginals and class-conditional
distributions are aligned across domains. For this sake, we propose a learning
problem that minimizes importance weighted loss in the source domain and a
Wasserstein distance between weighted marginals. For a proper weighting, we
provide an estimator of target label proportion by blending mixture estimation
and optimal matching by optimal transport. This estimation comes with
theoretical guarantees of correctness under mild assumptions. Our experimental
results show that our method performs better on average than competitors across
a range domain adaptation problems including \emph{digits},\emph{VisDA} and
\emph{Office}. Code for this paper is available at
\url{https://github.com/arakotom/mars_domain_adaptation}.
</p>
<a href="http://arxiv.org/abs/2006.08161" target="_blank">arXiv:2006.08161</a> [<a href="http://arxiv.org/pdf/2006.08161" target="_blank">pdf</a>]

<h2>Survey on the Analysis and Modeling of Visual Kinship: A Decade in the Making. (arXiv:2006.16033v4 [cs.CV] UPDATED)</h2>
<h3>Joseph P Robinson, Ming Shao, Yun Fu</h3>
<p>Kinship recognition is a challenging problem with many practical
applications. With much progress and milestones having been reached after ten
years - we are now able to survey the research and create new milestones. We
review the public resources and data challenges that enabled and inspired many
to hone-in on the views of automatic kinship recognition in the visual domain.
The different tasks are described in technical terms and syntax consistent
across the problem domain and the practical value of each discussed and
measured. State-of-the-art methods for visual kinship recognition problems,
whether to discriminate between or generate from, are examined. As part of
such, we review systems proposed as part of a recent data challenge held in
conjunction with the 2020 IEEE Conference on Automatic Face and Gesture
Recognition. We establish a stronghold for the state of progress for the
different problems in a consistent manner. This survey will serve as the
central resource for the work of the next decade to build upon. For the tenth
anniversary, the demo code is provided for the various kin-based tasks.
Detecting relatives with visual recognition and classifying the relationship is
an area with high potential for impact in research and practice.IEEE
Transactions on pattern analysis and machine intelligence
</p>
<a href="http://arxiv.org/abs/2006.16033" target="_blank">arXiv:2006.16033</a> [<a href="http://arxiv.org/pdf/2006.16033" target="_blank">pdf</a>]

<h2>On spectral algorithms for community detection in stochastic blockmodel graphs with vertex covariates. (arXiv:2007.02156v2 [stat.ML] UPDATED)</h2>
<h3>Cong Mu, Angelo Mele, Lingxin Hao, Joshua Cape, Avanti Athreya, Carey E. Priebe</h3>
<p>In network inference applications, it is often desirable to detect community
structure, namely to cluster vertices into groups, or blocks, according to some
measure of similarity. Beyond mere adjacency matrices, many real networks also
involve vertex covariates that carry key information about underlying block
structure in graphs. To assess the effects of such covariates on block
recovery, we present a comparative analysis of two model-based spectral
algorithms for clustering vertices in stochastic blockmodel graphs with vertex
covariates. The first algorithm uses only the adjacency matrix, and directly
estimates the induced block assignments. The second algorithm incorporates both
the adjacency matrix and the vertex covariates into the estimation of block
assignments, and moreover quantifies the explicit impact of the vertex
covariates on the resulting estimate of the block assignments. We employ
Chernoff information to analytically compare the algorithms' performance and
derive the Chernoff ratio for certain models of interest. Analytic results and
simulations suggest that the second algorithm is often preferred: we can often
better estimate the induced block assignments by first estimating the effect of
vertex covariates. In addition, real data examples on diffusion MRI connectome
datasets and social network datasets also indicate that the second algorithm
has the advantages of revealing underlying block structure and taking observed
vertex heterogeneity into account in real applications. Our findings emphasize
the importance of distinguishing between observed and unobserved factors that
can affect block structure in graphs.
</p>
<a href="http://arxiv.org/abs/2007.02156" target="_blank">arXiv:2007.02156</a> [<a href="http://arxiv.org/pdf/2007.02156" target="_blank">pdf</a>]

<h2>CMPCC: Corridor-based Model Predictive Contouring Control for Aggressive Drone Flight. (arXiv:2007.03271v3 [cs.RO] UPDATED)</h2>
<h3>Jialin Ji, Xin Zhou, Chao Xu, Fei Gao</h3>
<p>In this paper, we propose an efficient, receding horizon, local adaptive
low-level planner as the middle layer between our original planner and
controller. Our method is named as corridor-based model predictive contouring
control (CMPCC) since it builds upon on MPCC and utilizes the flight corridor
as hard safety constraints. It optimizes the flight aggressiveness and tracking
accuracy simultaneously, thus improving our system's robustness by overcoming
unmeasured disturbances. Our method features its online flight speed
optimization, strict safety and feasibility, and real-time performance, and
will be released as a low-level plugin for a large variety of quadrotor
systems.
</p>
<a href="http://arxiv.org/abs/2007.03271" target="_blank">arXiv:2007.03271</a> [<a href="http://arxiv.org/pdf/2007.03271" target="_blank">pdf</a>]

<h2>Temporal Pointwise Convolutional Networks for Length of Stay Prediction in the Intensive Care Unit. (arXiv:2007.09483v4 [cs.LG] UPDATED)</h2>
<h3>Emma Rocheteau, Pietro Li&#xf2;, Stephanie Hyland</h3>
<p>The pressure of ever-increasing patient demand and budget restrictions make
hospital bed management a daily challenge for clinical staff. Most critical is
the efficient allocation of resource-heavy Intensive Care Unit (ICU) beds to
the patients who need life support. Central to solving this problem is knowing
for how long the current set of ICU patients are likely to stay in the unit. In
this work, we propose a new deep learning model based on the combination of
temporal convolution and pointwise (1x1) convolution, to solve the length of
stay prediction task on the eICU and MIMIC-IV critical care datasets. The model
- which we refer to as Temporal Pointwise Convolution (TPC) - is specifically
designed to mitigate common challenges with Electronic Health Records, such as
skewness, irregular sampling and missing data. In doing so, we have achieved
significant performance benefits of 18-68% (metric and dataset dependent) over
the commonly used Long-Short Term Memory (LSTM) network, and the multi-head
self-attention network known as the Transformer. By adding mortality prediction
as a side-task, we can improve performance further still, resulting in a mean
absolute deviation of 1.55 days (eICU) and 2.28 days (MIMIC-IV) on predicting
remaining length of stay.
</p>
<a href="http://arxiv.org/abs/2007.09483" target="_blank">arXiv:2007.09483</a> [<a href="http://arxiv.org/pdf/2007.09483" target="_blank">pdf</a>]

<h2>Few-Shot Bearing Anomaly Detection Based on Model-Agnostic Meta-Learning. (arXiv:2007.12851v3 [cs.LG] UPDATED)</h2>
<h3>Shen Zhang, Fei Ye, Bingnan Wang, Thomas G. Habetler</h3>
<p>As an essential component of many mission-critical equipment, mechanical
bearings need to be monitored to identify any traces of abnormal conditions.
Most of the latest data-driven methods applied to bearing anomaly detection are
trained using a large amount of fault data collected a priori. However, in many
practical applications, it may be unsafe and time-consuming to collect enough
data samples for each fault category, which brings challenges to training a
robust classifier. This paper proposes a few-shot learning framework for
bearing anomaly detection based on model-agnostic meta-learning (MAML), which
aims to train an effective fault classifier using very limited data. In
addition, it can use training data and learn to more effectively identify new
fault conditions. A case study on the generalization of new artificial faults
shows that this method can achieve up to 25\% overall accuracy when compared to
a benchmark study based on the Siamese network. Finally, the generalization
ability of MAML is also competitive when compared with some state-of-the-art
few-shot learning methods in terms of identifying realistic bearing damages
using a sufficient amount of training data from artificial damages.
</p>
<a href="http://arxiv.org/abs/2007.12851" target="_blank">arXiv:2007.12851</a> [<a href="http://arxiv.org/pdf/2007.12851" target="_blank">pdf</a>]

<h2>Families In Wild Multimedia (FIW-MM): A Multi-Modal Database for Recognizing Kinship. (arXiv:2007.14509v3 [cs.CV] UPDATED)</h2>
<h3>Joseph P. Robinson, Zaid Khan, Yu Yin, Ming Shao, Yun Fu</h3>
<p>Kinship is a soft biometric detectable in media with an abundance of
practical applications. Despite the difficulty of detecting kinship, annual
data challenges using still images have consistently resulted in improved
performances and attracted new researchers. Now, systems are reaching
performance levels unforeseeable a decade ago, closing in on performances
acceptable for real-world use. Similar to other biometric tasks, we expect that
systems can benefit from additional modalities. We hypothesize that adding
modalities to FIW, which contains only still images, will improve performance.
Thus, to narrow the gap between research-and-reality and enhance the power of
kinship recognition systems, we extend FIW with multimedia (MM) data (i.e.,
video, audio, and text captions). Specifically, we introduce the first publicly
available multi-task MM kinship dataset. To build FIW-MM, machinery was
developed to collect, annotate, and prepare the data automatically, requiring
minimal human input and no financial cost. The proposed MM corpus allows us to
formulate problems following more realistic template-based protocols. We show
significant improvements in all benchmarks with the added modalities. The
results are analyzed by highlighting edge cases to inspire future research with
different areas of improvement. FIW-MM provides the data required to increase
the potential of systems built to automatically detect kinship in MM. It also
allows experts from diverse fields to collaborate in new ways.
</p>
<a href="http://arxiv.org/abs/2007.14509" target="_blank">arXiv:2007.14509</a> [<a href="http://arxiv.org/pdf/2007.14509" target="_blank">pdf</a>]

<h2>Partitioning signal classes using transport transforms for data analysis and machine learning. (arXiv:2008.03452v2 [cs.LG] UPDATED)</h2>
<h3>Akram Aldroubi, Shiying Li, Gustavo K. Rohde</h3>
<p>A relatively new set of transport-based transforms (CDT, R-CDT, LOT) have
shown their strength and great potential in various image and data processing
tasks such as parametric signal estimation, classification, cancer detection
among many others. It is hence worthwhile to elucidate some of the mathematical
properties that explain the successes of these transforms when they are used as
tools in data analysis, signal processing or data classification. In
particular, we give conditions under which classes of signals that are created
by algebraic generative models are transformed into convex sets by the
transport transforms. Such convexification of the classes simplify the
classification and other data analysis and processing problems when viewed in
the transform domain. More specifically, we study the extent and limitation of
the convexification ability of these transforms under an algebraic generative
modeling framework. We hope that this paper will serve as an introduction to
these transforms and will encourage mathematicians and other researchers to
further explore the theoretical underpinnings and algorithmic tools that will
help understand the successes of these transforms and lay the groundwork for
further successful applications.
</p>
<a href="http://arxiv.org/abs/2008.03452" target="_blank">arXiv:2008.03452</a> [<a href="http://arxiv.org/pdf/2008.03452" target="_blank">pdf</a>]

<h2>Understanding the wiring evolution in differentiable neural architecture search. (arXiv:2009.01272v3 [cs.LG] UPDATED)</h2>
<h3>Sirui Xie, Shoukang Hu, Xinjiang Wang, Chunxiao Liu, Jianping Shi, Xunying Liu, Dahua Lin</h3>
<p>Controversy exists on whether differentiable neural architecture search
methods discover wiring topology effectively. To understand how wiring topology
evolves, we study the underlying mechanism of several existing differentiable
NAS frameworks. Our investigation is motivated by three observed searching
patterns of differentiable NAS: 1) they search by growing instead of pruning;
2) wider networks are more preferred than deeper ones; 3) no edges are selected
in bi-level optimization. To anatomize these phenomena, we propose a unified
view on searching algorithms of existing frameworks, transferring the global
optimization to local cost minimization. Based on this reformulation, we
conduct empirical and theoretical analyses, revealing implicit inductive biases
in the cost's assignment mechanism and evolution dynamics that cause the
observed phenomena. These biases indicate strong discrimination towards certain
topologies. To this end, we pose questions that future differentiable methods
for neural wiring discovery need to confront, hoping to evoke a discussion and
rethinking on how much bias has been enforced implicitly in existing NAS
methods.
</p>
<a href="http://arxiv.org/abs/2009.01272" target="_blank">arXiv:2009.01272</a> [<a href="http://arxiv.org/pdf/2009.01272" target="_blank">pdf</a>]

<h2>RENT -- Repeated Elastic Net Technique for Feature Selection. (arXiv:2009.12780v2 [cs.LG] UPDATED)</h2>
<h3>Anna Jenul, Stefan Schrunner, Kristian Hovde Liland, Ulf Geir Indahl, Cecilia Marie Futsaether, Oliver Tomic</h3>
<p>Feature selection is an essential step in data science pipelines to reduce
the complexity of models trained on large datasets. While a major part of
feature selection research focuses on optimizing predictive performance, there
are only few studies that investigate the integration of feature selection
stability into the feature selection process. Taking advantage of feature
selection stability has the potential to enhance interpretability of machine
learning models whilst maintaining predictive performance. In this study we
present the RENT feature selector for binary classification and regression
problems. The proposed methodology is based on an ensemble of elastic net
regularized models, trained on unique subsets of the dataset. RENT selects
features based on three criteria evaluating the weight distributions of
features across all elementary models. Compared to conventional approaches,
RENT simultaneously performs high-quality feature selection while gathering
useful information for model interpretation. In addition, the proposed
ensemble-based selection criteria guarantee robustness of the model by
selecting features with high stability. In an experimental evaluation, we
compare feature selection quality on eight multivariate datasets: six for
binary classification and two for regression. We benchmark RENT against six
established feature selectors. In terms of both, number of features selected
and predictive performance, RENT delivers on-par results with the best
performing competitors. The additional information on stability provided by
RENT can be integrated in an exploratory post-hoc analysis for further insight
as demonstrated in a use-case from the healthcare domain.
</p>
<a href="http://arxiv.org/abs/2009.12780" target="_blank">arXiv:2009.12780</a> [<a href="http://arxiv.org/pdf/2009.12780" target="_blank">pdf</a>]

<h2>Understanding the Role of Momentum in Non-Convex Optimization: Practical Insights from a Lyapunov Analysis. (arXiv:2010.00406v3 [cs.LG] UPDATED)</h2>
<h3>Aaron Defazio</h3>
<p>Momentum methods are now used pervasively within the machine learning
community for training non-convex models such as deep neural networks.
Empirically, they out perform traditional stochastic gradient descent (SGD)
approaches. In this work we develop a Lyapunov analysis of SGD with momentum
(SGD+M), by utilizing a equivalent rewriting of the method known as the
stochastic primal averaging (SPA) form. This analysis is much tighter than
previous theory in the non-convex case, and due to this we are able to give
precise insights into when SGD+M may out-perform SGD, and what hyper-parameter
schedules will work and why.
</p>
<a href="http://arxiv.org/abs/2010.00406" target="_blank">arXiv:2010.00406</a> [<a href="http://arxiv.org/pdf/2010.00406" target="_blank">pdf</a>]

<h2>Kernel regression in high dimensions: Refined analysis beyond double descent. (arXiv:2010.02681v2 [stat.ML] UPDATED)</h2>
<h3>Fanghui Liu, Zhenyu Liao, Johan A.K. Suykens</h3>
<p>In this paper, we provide a precise characterization of generalization
properties of high dimensional kernel ridge regression across the under- and
over-parameterized regimes, depending on whether the number of training data n
exceeds the feature dimension d. By establishing a bias-variance decomposition
of the expected excess risk, we show that, while the bias is (almost)
independent of d and monotonically decreases with n, the variance depends on n,
d and can be unimodal or monotonically decreasing under different
regularization schemes. Our refined analysis goes beyond the double descent
theory by showing that, depending on the data eigen-profile and the level of
regularization, the kernel regression risk curve can be a double-descent-like,
bell-shaped, or monotonic function of n. Experiments on synthetic and real data
are conducted to support our theoretical findings.
</p>
<a href="http://arxiv.org/abs/2010.02681" target="_blank">arXiv:2010.02681</a> [<a href="http://arxiv.org/pdf/2010.02681" target="_blank">pdf</a>]

<h2>Semantic Histogram Based Graph Matching for Real-Time Multi-Robot Global Localization in Large Scale Environment. (arXiv:2010.09297v2 [cs.RO] UPDATED)</h2>
<h3>Xiyue Guo, Junjie Hu, Junfeng Chen, Fuqin Deng, Tin Lun Lam</h3>
<p>The core problem of visual multi-robot simultaneous localization and mapping
(MR-SLAM) is how to efficiently and accurately perform multi-robot global
localization (MR-GL). The difficulties are two-fold. The first is the
difficulty of global localization for significant viewpoint difference.
Appearance-based localization methods tend to fail under large viewpoint
changes. Recently, semantic graphs have been utilized to overcome the viewpoint
variation problem. However, the methods are highly time-consuming, especially
in large-scale environments. This leads to the second difficulty, which is how
to perform real-time global localization. In this paper, we propose a semantic
histogram-based graph matching method that is robust to viewpoint variation and
can achieve real-time global localization. Based on that, we develop a system
that can accurately and efficiently perform MR-GL for both homogeneous and
heterogeneous robots. The experimental results show that our approach is about
30 times faster than Random Walk based semantic descriptors. Moreover, it
achieves an accuracy of 95% for global localization, while the accuracy of the
state-of-the-art method is 85%.
</p>
<a href="http://arxiv.org/abs/2010.09297" target="_blank">arXiv:2010.09297</a> [<a href="http://arxiv.org/pdf/2010.09297" target="_blank">pdf</a>]

<h2>What About Taking Policy as Input of Value Function: Policy-extended Value Function Approximator. (arXiv:2010.09536v2 [cs.LG] UPDATED)</h2>
<h3>Hongyao Tang, Zhaopeng Meng, Jianye Hao, Chen Chen, Daniel Graves, Dong Li, Wulong Liu, Yaodong Yang, Changmin Yu</h3>
<p>We study Policy-extended Value Function Ap-proximator (PeVFA) in
Reinforcement Learning(RL), which extends the conventional value func-tion to
take as input not only the state (and ac-tion) but also an explicit policy
representation.Such an extension enables PeVFA to preserve val-ues of multiple
policies in contrast to the conven-tional VFA for only one policy. This brings
a newcharacteristic ofvalue generalization among poli-cies. From both
theoretical and empirical lens,we focus on value generalization along
policyimprovement path (calledlocal generalization),from which we derive a new
form of GeneralizedPolicy Iteration (GPI) with PeVFA. Besides, weintroduce a
representation learning framework forRL policy, providing several approaches to
learneffective policy embeddings from policy networkparameters or state-action
pairs by contrastivelearning and action prediction. In our experi-ments,
Proximal Policy Optimization (PPO) re-implemented with PeVFA outperforms its
vanillacounterpart in several OpenAI Gym continuouscontrol tasks, which
demonstrates the effective-ness of value generalization offered by PeVFAand
policy representation learning.
</p>
<a href="http://arxiv.org/abs/2010.09536" target="_blank">arXiv:2010.09536</a> [<a href="http://arxiv.org/pdf/2010.09536" target="_blank">pdf</a>]

<h2>Counterfactual Representation Learning with Balancing Weights. (arXiv:2010.12618v2 [stat.ML] UPDATED)</h2>
<h3>Serge Assaad, Shuxi Zeng, Chenyang Tao, Shounak Datta, Nikhil Mehta, Ricardo Henao, Fan Li, Lawrence Carin</h3>
<p>A key to causal inference with observational data is achieving balance in
predictive features associated with each treatment type. Recent literature has
explored representation learning to achieve this goal. In this work, we discuss
the pitfalls of these strategies - such as a steep trade-off between achieving
balance and predictive power - and present a remedy via the integration of
balancing weights in causal learning. Specifically, we theoretically link
balance to the quality of propensity estimation, emphasize the importance of
identifying a proper target population, and elaborate on the complementary
roles of feature balancing and weight adjustments. Using these concepts, we
then develop an algorithm for flexible, scalable and accurate estimation of
causal effects. Finally, we show how the learned weighted representations may
serve to facilitate alternative causal learning procedures with appealing
statistical features. We conduct an extensive set of experiments on both
synthetic examples and standard benchmarks, and report encouraging results
relative to state-of-the-art baselines.
</p>
<a href="http://arxiv.org/abs/2010.12618" target="_blank">arXiv:2010.12618</a> [<a href="http://arxiv.org/pdf/2010.12618" target="_blank">pdf</a>]

<h2>REDE: End-to-end Object 6D Pose Robust Estimation Using Differentiable Outliers Elimination. (arXiv:2010.12807v3 [cs.CV] UPDATED)</h2>
<h3>Weitong Hua, Zhongxiang Zhou, Jun Wu, Huang Huang, Yue Wang, Rong Xiong</h3>
<p>Object 6D pose estimation is a fundamental task in many applications.
Conventional methods solve the task by detecting and matching the keypoints,
then estimating the pose. Recent efforts bringing deep learning into the
problem mainly overcome the vulnerability of conventional methods to
environmental variation due to the hand-crafted feature design. However, these
methods cannot achieve end-to-end learning and good interpretability at the
same time. In this paper, we propose REDE, a novel end-to-end object pose
estimator using RGB-D data, which utilizes network for keypoint regression, and
a differentiable geometric pose estimator for pose error back-propagation.
Besides, to achieve better robustness when outlier keypoint prediction occurs,
we further propose a differentiable outliers elimination method that regresses
the candidate result and the confidence simultaneously. Via confidence weighted
aggregation of multiple candidates, we can reduce the effect from the outliers
in the final estimation. Finally, following the conventional method, we apply a
learnable refinement process to further improve the estimation. The
experimental results on three benchmark datasets show that REDE slightly
outperforms the state-of-the-art approaches and is more robust to object
occlusion.
</p>
<a href="http://arxiv.org/abs/2010.12807" target="_blank">arXiv:2010.12807</a> [<a href="http://arxiv.org/pdf/2010.12807" target="_blank">pdf</a>]

<h2>Scalable Gaussian Process Variational Autoencoders. (arXiv:2010.13472v3 [stat.ML] UPDATED)</h2>
<h3>Metod Jazbec, Matthew Ashman, Vincent Fortuin, Michael Pearce, Stephan Mandt, Gunnar R&#xe4;tsch</h3>
<p>Conventional variational autoencoders fail in modeling correlations between
data points due to their use of factorized priors. Amortized Gaussian process
inference through GP-VAEs has led to significant improvements in this regard,
but is still inhibited by the intrinsic complexity of exact GP inference. We
improve the scalability of these methods through principled sparse inference
approaches. We propose a new scalable GP-VAE model that outperforms existing
approaches in terms of runtime and memory footprint, is easy to implement, and
allows for joint end-to-end optimization of all components.
</p>
<a href="http://arxiv.org/abs/2010.13472" target="_blank">arXiv:2010.13472</a> [<a href="http://arxiv.org/pdf/2010.13472" target="_blank">pdf</a>]

<h2>Learning unbiased group-wise registration (LUGR) and joint segmentation: evaluation on longitudinal diffusion MRI. (arXiv:2011.01869v2 [cs.CV] UPDATED)</h2>
<h3>Bo Li, Wiro J. Niessen, Stefan Klein, M. Arfan Ikram, Meike W. Vernooij, Esther E. Bron</h3>
<p>Analysis of longitudinal changes in imaging studies often involves both
segmentation of structures of interest and registration of multiple timeframes.
The accuracy of such analysis could benefit from a tailored framework that
jointly optimizes both tasks to fully exploit the information available in the
longitudinal data. Most learning-based registration algorithms, including joint
optimization approaches, currently suffer from bias due to selection of a fixed
reference frame and only support pairwise transformations. We here propose an
analytical framework based on an unbiased learning strategy for group-wise
registration that simultaneously registers images to the mean space of a group
to obtain consistent segmentations. We evaluate the proposed method on
longitudinal analysis of a white matter tract in a brain MRI dataset with 2-3
time-points for 3249 individuals, i.e., 8045 images in total. The
reproducibility of the method is evaluated on test-retest data from 97
individuals. The results confirm that the implicit reference image is an
average of the input image. In addition, the proposed framework leads to
consistent segmentations and significantly lower processing bias than that of a
pair-wise fixed-reference approach. This processing bias is even smaller than
those obtained when translating segmentations by only one voxel, which can be
attributed to subtle numerical instabilities and interpolation. Therefore, we
postulate that the proposed mean-space learning strategy could be widely
applied to learning-based registration tasks. In addition, this group-wise
framework introduces a novel way for learning-based longitudinal studies by
direct construction of an unbiased within-subject template and allowing
reliable and efficient analysis of spatio-temporal imaging biomarkers.
</p>
<a href="http://arxiv.org/abs/2011.01869" target="_blank">arXiv:2011.01869</a> [<a href="http://arxiv.org/pdf/2011.01869" target="_blank">pdf</a>]

<h2>Causal Autoregressive Flows. (arXiv:2011.02268v2 [stat.ML] UPDATED)</h2>
<h3>Ilyes Khemakhem, Ricardo Pio Monti, Robert Leech, Aapo Hyv&#xe4;rinen</h3>
<p>Two apparently unrelated fields -- normalizing flows and causality -- have
recently received considerable attention in the machine learning community. In
this work, we highlight an intrinsic correspondence between a simple family of
autoregressive normalizing flows and identifiable causal models. We exploit the
fact that autoregressive flow architectures define an ordering over variables,
analogous to a causal ordering, to show that they are well-suited to performing
a range of causal inference tasks, ranging from causal discovery to making
interventional and counterfactual predictions. First, we show that causal
models derived from both affine and additive autoregressive flows with fixed
orderings over variables are identifiable, i.e. the true direction of causal
influence can be recovered. This provides a generalization of the additive
noise model well-known in causal discovery. Second, we derive a bivariate
measure of causal direction based on likelihood ratios, leveraging the fact
that flow models can estimate normalized log-densities of data. Third, we
demonstrate that flows naturally allow for direct evaluation of both
interventional and counterfactual queries, the latter case being possible due
to the invertible nature of flows. Finally, throughout a series of experiments
on synthetic and real data, the proposed method is shown to outperform current
approaches for causal discovery as well as making accurate interventional and
counterfactual predictions.
</p>
<a href="http://arxiv.org/abs/2011.02268" target="_blank">arXiv:2011.02268</a> [<a href="http://arxiv.org/pdf/2011.02268" target="_blank">pdf</a>]

<h2>A New Inference algorithm of Dynamic Uncertain Causality Graph based on Conditional Sampling Method for Complex Cases. (arXiv:2011.03359v2 [cs.AI] UPDATED)</h2>
<h3>Hao Nie, Qin Zhang</h3>
<p>Dynamic Uncertain Causality Graph(DUCG) is a recently proposed model for
diagnoses of complex systems. It performs well for industry system such as
nuclear power plants, chemical system and spacecrafts. However, the variable
state combination explosion in some cases is still a problem that may result in
inefficiency or even disability in DUCG inference. In the situation of clinical
diagnoses, when a lot of intermediate causes are unknown while the downstream
results are known in a DUCG graph, the combination explosion may appear during
the inference computation. Monte Carlo sampling is a typical algorithm to solve
this problem. However, we are facing the case that the occurrence rate of the
case is very small, e.g. $10^{-20}$, which means a huge number of samplings are
needed. This paper proposes a new scheme based on conditional stochastic
simulation which obtains the final result from the expectation of the
conditional probability in sampling loops instead of counting the sampling
frequency, and thus overcomes the problem. As a result, the proposed algorithm
requires much less time than the DUCG recursive inference algorithm presented
earlier. Moreover, a simple analysis of convergence rate based on a designed
example is given to show the advantage of the proposed method. % In addition,
supports for logic gate, logic cycles, and parallelization, which exist in
DUCG, are also addressed in this paper. The new algorithm reduces the time
consumption a lot and performs 3 times faster than old one with 2.7% error
ratio in a practical graph for Viral Hepatitis B.
</p>
<a href="http://arxiv.org/abs/2011.03359" target="_blank">arXiv:2011.03359</a> [<a href="http://arxiv.org/pdf/2011.03359" target="_blank">pdf</a>]

<h2>Data Preprocessing to Mitigate Bias with Boosted Fair Mollifiers. (arXiv:2012.00188v2 [stat.ML] UPDATED)</h2>
<h3>Alexander Soen, Hisham Husain, Richard Nock</h3>
<p>In a recent paper, Celis et al. (2020) introduced a new approach to fairness
that corrects the data distribution itself. The approach is computationally
appealing, but its approximation guarantees with respect to the target
distribution can be quite loose as they need to rely on a (typically limited)
number of constraints on data-based aggregated statistics; also resulting in a
fairness guarantee which can be data dependent.

Our paper makes use of a mathematical object recently introduced in privacy
-- mollifiers of distributions -- and a popular approach to machine learning --
boosting -- to get an approach in the same lineage as Celis et al. but without
the same impediments, including in particular, better guarantees in terms of
accuracy and finer guarantees in terms of fairness. The approach involves
learning the sufficient statistics of an exponential family. When the training
data is tabular, the sufficient statistics can be defined by decision trees
whose interpretability can provide clues on the source of (un)fairness.
Experiments display the quality of the results for simulated and real-world
data.
</p>
<a href="http://arxiv.org/abs/2012.00188" target="_blank">arXiv:2012.00188</a> [<a href="http://arxiv.org/pdf/2012.00188" target="_blank">pdf</a>]

<h2>Unsupervised Anomaly Detection From Semantic Similarity Scores. (arXiv:2012.00461v2 [cs.LG] UPDATED)</h2>
<h3>Nima Rafiee, Rahil Gholamipoor, Markus Kollmann</h3>
<p>Classifying samples as in-distribution or out-of-distribution (OOD) is a
challenging problem of anomaly detection and a strong test of the
generalisation power for models of the in-distribution. In this paper, we
present a simple and generic framework, {\it SemSAD}, that makes use of a
semantic similarity score to carry out anomaly detection. The idea is to first
find for any test example the semantically closest examples in the training
set, where the semantic relation between examples is quantified by the cosine
similarity between feature vectors that leave semantics unchanged under
transformations, such as geometric transformations (images), time shifts (audio
signals), and synonymous word substitutions (text). A trained discriminator is
then used to classify a test example as OOD if the semantic similarity to its
nearest neighbours is significantly lower than the corresponding similarity for
test examples from the in-distribution. We are able to outperform previous
approaches for anomaly, novelty, or out-of-distribution detection in the visual
domain by a large margin. In particular, we obtain AUROC values close to one
for the challenging task of detecting examples from CIFAR-10 as
out-of-distribution given CIFAR-100 as in-distribution, without making use of
label information.
</p>
<a href="http://arxiv.org/abs/2012.00461" target="_blank">arXiv:2012.00461</a> [<a href="http://arxiv.org/pdf/2012.00461" target="_blank">pdf</a>]

<h2>Message Passing Adaptive Resonance Theory for Online Active Semi-supervised Learning. (arXiv:2012.01227v2 [cs.LG] UPDATED)</h2>
<h3>Taehyeong Kim, Injune Hwang, Hyundo Lee, Hyunseo Kim, Won-Seok Choi, Joseph J. Lim, Byoung-Tak Zhang</h3>
<p>Active learning is widely used to reduce labeling effort and training time by
repeatedly querying only the most beneficial samples from unlabeled data. In
real-world problems where data cannot be stored indefinitely due to limited
storage or privacy issues, the query selection and the model update should be
performed as soon as a new data sample is observed. Various online active
learning methods have been studied to deal with these challenges; however,
there are difficulties in selecting representative query samples and updating
the model efficiently. In this study, we propose Message Passing Adaptive
Resonance Theory (MPART) for online active semi-supervised learning. The
proposed model learns the distribution and topology of the input data online.
It then infers the class of unlabeled data and selects informative and
representative samples through message passing between nodes on the topological
graph. MPART queries the beneficial samples on-the-fly in stream-based
selective sampling scenarios, and continuously improve the classification model
using both labeled and unlabeled data. We evaluate our model with comparable
query selection strategies and frequencies, showing that MPART significantly
outperforms the competitive models in online active learning environments.
</p>
<a href="http://arxiv.org/abs/2012.01227" target="_blank">arXiv:2012.01227</a> [<a href="http://arxiv.org/pdf/2012.01227" target="_blank">pdf</a>]

<h2>Ditto: Fair and Robust Federated Learning Through Personalization. (arXiv:2012.04221v2 [cs.LG] UPDATED)</h2>
<h3>Tian Li, Shengyuan Hu, Ahmad Beirami, Virginia Smith</h3>
<p>Fairness and robustness are two important concerns for federated learning
systems. In this work, we identify that robustness to data and model poisoning
attacks and fairness, measured as the uniformity of performance across devices,
are competing constraints in statistically heterogeneous networks. To address
these constraints, we propose employing a simple, general framework for
personalized federated learning, Ditto, and develop a scalable solver for it.
Theoretically, we analyze the ability of Ditto to achieve fairness and
robustness simultaneously on a class of linear problems. Empirically, across a
suite of federated datasets, we show that Ditto not only achieves competitive
performance relative to recent personalization methods, but also enables more
accurate, robust, and fair models relative to state-of-the-art fair or robust
baselines.
</p>
<a href="http://arxiv.org/abs/2012.04221" target="_blank">arXiv:2012.04221</a> [<a href="http://arxiv.org/pdf/2012.04221" target="_blank">pdf</a>]

<h2>Convex Potential Flows: Universal Probability Distributions with Optimal Transport and Convex Optimization. (arXiv:2012.05942v2 [cs.LG] UPDATED)</h2>
<h3>Chin-Wei Huang, Ricky T. Q. Chen, Christos Tsirigotis, Aaron Courville</h3>
<p>Flow-based models are powerful tools for designing probabilistic models with
tractable density. This paper introduces Convex Potential Flows (CP-Flow), a
natural and efficient parameterization of invertible models inspired by the
optimal transport (OT) theory. CP-Flows are the gradient map of a strongly
convex neural potential function. The convexity implies invertibility and
allows us to resort to convex optimization to solve the convex conjugate for
efficient inversion. To enable maximum likelihood training, we derive a new
gradient estimator of the log-determinant of the Jacobian, which involves
solving an inverse-Hessian vector product using the conjugate gradient method.
The gradient estimator has constant-memory cost, and can be made effectively
unbiased by reducing the error tolerance level of the convex optimization
routine. Theoretically, we prove that CP-Flows are universal density
approximators and are optimal in the OT sense. Our empirical results show that
CP-Flow performs competitively on standard benchmarks of density estimation and
variational inference.
</p>
<a href="http://arxiv.org/abs/2012.05942" target="_blank">arXiv:2012.05942</a> [<a href="http://arxiv.org/pdf/2012.05942" target="_blank">pdf</a>]

<h2>Fair for All: Best-effort Fairness Guarantees for Classification. (arXiv:2012.10216v4 [cs.LG] UPDATED)</h2>
<h3>Anilesh K. Krishnaswamy, Zhihao Jiang, Kangning Wang, Yu Cheng, Kamesh Munagala</h3>
<p>Standard approaches to group-based notions of fairness, such as \emph{parity}
and \emph{equalized odds}, try to equalize absolute measures of performance
across known groups (based on race, gender, etc.). Consequently, a group that
is inherently harder to classify may hold back the performance on other groups;
and no guarantees can be provided for unforeseen groups. Instead, we propose a
fairness notion whose guarantee, on each group $g$ in a class $\mathcal{G}$, is
relative to the performance of the best classifier on $g$. We apply this notion
to broad classes of groups, in particular, where (a) $\mathcal{G}$ consists of
all possible groups (subsets) in the data, and (b) $\mathcal{G}$ is more
streamlined.

For the first setting, which is akin to groups being completely unknown, we
devise the {\sc PF} (Proportional Fairness) classifier, which guarantees, on
any possible group $g$, an accuracy that is proportional to that of the optimal
classifier for $g$, scaled by the relative size of $g$ in the data set. Due to
including all possible groups, some of which could be too complex to be
relevant, the worst-case theoretical guarantees here have to be proportionally
weaker for smaller subsets.

For the second setting, we devise the {\sc BeFair} (Best-effort Fair)
framework which seeks an accuracy, on every $g \in \mathcal{G}$, which
approximates that of the optimal classifier on $g$, independent of the size of
$g$. Aiming for such a guarantee results in a non-convex problem, and we design
novel techniques to get around this difficulty when $\mathcal{G}$ is the set of
linear hypotheses. We test our algorithms on real-world data sets, and present
interesting comparative insights on their performance.
</p>
<a href="http://arxiv.org/abs/2012.10216" target="_blank">arXiv:2012.10216</a> [<a href="http://arxiv.org/pdf/2012.10216" target="_blank">pdf</a>]

<h2>XAI4Wind: A Multimodal Knowledge Graph Database for Explainable Decision Support in Operations & Maintenance of Wind Turbines. (arXiv:2012.10489v2 [cs.AI] UPDATED)</h2>
<h3>Joyjit Chatterjee, Nina Dethlefs</h3>
<p>Condition-based monitoring (CBM) has been widely utilised in the wind
industry for monitoring operational inconsistencies and failures in turbines,
with techniques ranging from signal processing and vibration analysis to
artificial intelligence (AI) models using Supervisory Control &amp; Acquisition
(SCADA) data. However, existing studies do not present a concrete basis to
facilitate explainable decision support in operations and maintenance (O&amp;M),
particularly for automated decision support through recommendation of
appropriate maintenance action reports corresponding to failures predicted by
CBM techniques. Knowledge graph databases (KGs) model a collection of
domain-specific information and have played an intrinsic role for real-world
decision support in domains such as healthcare and finance, but have seen very
limited attention in the wind industry. We propose XAI4Wind, a multimodal
knowledge graph for explainable decision support in real-world operational
turbines and demonstrate through experiments several use-cases of the proposed
KG towards O&amp;M planning through interactive query and reasoning and providing
novel insights using graph data science algorithms. The proposed KG combines
multimodal knowledge like SCADA parameters and alarms with natural language
maintenance actions, images etc. By integrating our KG with an Explainable AI
model for anomaly prediction, we show that it can provide effective
human-intelligible O&amp;M strategies for predicted operational inconsistencies in
various turbine sub-components. This can help instil better trust and
confidence in conventionally black-box AI models. We make our KG publicly
available and envisage that it can serve as the building ground for providing
autonomous decision support in the wind industry.
</p>
<a href="http://arxiv.org/abs/2012.10489" target="_blank">arXiv:2012.10489</a> [<a href="http://arxiv.org/pdf/2012.10489" target="_blank">pdf</a>]

<h2>Generalize a Small Pre-trained Model to Arbitrarily Large TSP Instances. (arXiv:2012.10658v2 [cs.LG] UPDATED)</h2>
<h3>Zhang-Hua Fu, Kai-Bin Qiu, Hongyuan Zha</h3>
<p>For the traveling salesman problem (TSP), the existing supervised learning
based algorithms suffer seriously from the lack of generalization ability. To
overcome this drawback, this paper tries to train (in supervised manner) a
small-scale model, which could be repetitively used to build heat maps for TSP
instances of arbitrarily large size, based on a series of techniques such as
graph sampling, graph converting and heat maps merging. Furthermore, the heat
maps are fed into a reinforcement learning approach (Monte Carlo tree search),
to guide the search of high-quality solutions. Experimental results based on a
large number of instances (with up to 10,000 vertices) show that, this new
approach clearly outperforms the existing machine learning based TSP
algorithms, and significantly improves the generalization ability of the
trained model.
</p>
<a href="http://arxiv.org/abs/2012.10658" target="_blank">arXiv:2012.10658</a> [<a href="http://arxiv.org/pdf/2012.10658" target="_blank">pdf</a>]

<h2>Learning Compositional Sparse Gaussian Processes with a Shrinkage Prior. (arXiv:2012.11339v2 [cs.LG] UPDATED)</h2>
<h3>Anh Tong, Toan Tran, Hung Bui, Jaesik Choi</h3>
<p>Choosing a proper set of kernel functions is an important problem in learning
Gaussian Process (GP) models since each kernel structure has different model
complexity and data fitness. Recently, automatic kernel composition methods
provide not only accurate prediction but also attractive interpretability
through search-based methods. However, existing methods suffer from slow kernel
composition learning. To tackle large-scaled data, we propose a new sparse
approximate posterior for GPs, MultiSVGP, constructed from groups of inducing
points associated with individual additive kernels in compositional kernels. We
demonstrate that this approximation provides a better fit to learn
compositional kernels given empirical observations. We also provide
theoretically justification on error bound when compared to the traditional
sparse GP. In contrast to the search-based approach, we present a novel
probabilistic algorithm to learn a kernel composition by handling the sparsity
in the kernel selection with Horseshoe prior. We demonstrate that our model can
capture characteristics of time series with significant reductions in
computational time and have competitive regression performance on real-world
data sets.
</p>
<a href="http://arxiv.org/abs/2012.11339" target="_blank">arXiv:2012.11339</a> [<a href="http://arxiv.org/pdf/2012.11339" target="_blank">pdf</a>]

<h2>Motif-Driven Contrastive Learning of Graph Representations. (arXiv:2012.12533v2 [cs.LG] UPDATED)</h2>
<h3>Shichang Zhang, Ziniu Hu, Arjun Subramonian, Yizhou Sun</h3>
<p>Pre-training Graph Neural Networks (GNN) via self-supervised contrastive
learning has recently drawn lots of attention. However, most existing works
focus on node-level contrastive learning, which cannot capture global graph
structure. The key challenge to conducting subgraph-level contrastive learning
is to sample informative subgraphs that are semantically meaningful. To solve
it, we propose to learn graph motifs, which are frequently-occurring subgraph
patterns (e.g. functional groups of molecules), for better subgraph sampling.
Our framework MotIf-driven Contrastive leaRning Of Graph representations
(MICRO-Graph) can: 1) use GNNs to extract motifs from large graph datasets; 2)
leverage learned motifs to sample informative subgraphs for contrastive
learning of GNN. We formulate motif learning as a differentiable clustering
problem, and adopt EM-clustering to group similar and significant subgraphs
into several motifs. Guided by these learned motifs, a sampler is trained to
generate more informative subgraphs, and these subgraphs are used to train GNNs
through graph-to-subgraph contrastive learning. By pre-training on the
ogbg-molhiv dataset with MICRO-Graph, the pre-trained GNN achieves 2.04%
ROC-AUC average performance enhancement on various downstream benchmark
datasets, which is significantly higher than other state-of-the-art
self-supervised learning baselines.
</p>
<a href="http://arxiv.org/abs/2012.12533" target="_blank">arXiv:2012.12533</a> [<a href="http://arxiv.org/pdf/2012.12533" target="_blank">pdf</a>]

<h2>Generating Long-term Continuous Multi-type Generation Profiles using Generative Adversarial Network. (arXiv:2012.13344v2 [cs.LG] UPDATED)</h2>
<h3>Ming Dong, Kaigui Xie, Wenyuan Li</h3>
<p>Today, the adoption of new technologies has increased power system dynamics
significantly. Traditional long-term planning studies that most utility
companies perform based on discrete power levels such as peak or average values
cannot reflect system dynamics and often fail to accurately predict system
reliability deficiencies. As a result, long-term future continuous profiles
such as the 8760 hourly profiles are required to enable time-series based
long-term planning studies. However, unlike short-term profiles used for
operation studies, generating long-term continuous profiles that can reflect
both historical time-varying characteristics and future expected power
magnitude is very challenging. Current methods such as average profiling have
major drawbacks. To solve this challenge, this paper proposes a completely
novel approach to generate such profiles for multiple generation types using
Generative Adversarial Networks (GAN). A multi-level profile synthesis process
is proposed to capture time-varying characteristics at different time levels.
Both Single-type GAN and a modified Conditional GAN systems are developed.
Unique profile evaluation metrics are proposed. The proposed approach was
evaluated based on a public dataset and demonstrated great performance and
application value for generating long-term continuous multi-type generation
profiles.
</p>
<a href="http://arxiv.org/abs/2012.13344" target="_blank">arXiv:2012.13344</a> [<a href="http://arxiv.org/pdf/2012.13344" target="_blank">pdf</a>]

<h2>MoDern-Cloud: An Artificial Intelligence Cloud for Accelerated NMR Spectroscopy. (arXiv:2012.14830v3 [cs.LG] UPDATED)</h2>
<h3>Zi Wang, Di Guo, Zhangren Tu, Yihui Huang, Yirong Zhou, Jian Wang, Liubin Feng, Donghai Lin, Yongfu You, Tatiana Agback, Vladislav Orekhov, Xiaobo Qu</h3>
<p>Multi-dimensional NMR spectroscopy is an invaluable biophysical tool.
Non-uniform sampling is a powerful approach for shortening measurement time and
increasing spectra resolution. Deep learning, a representative artificial
intelligence technology, has shown astonishing potential in recovering spectra
from undersampled NMR data. However, many existing problems, such as lack of
robustness and explainability, greatly limit its applications. Here, we first
devise the model-inspired deep learning framework (MoDern), which learns the
optimal mapping from the undersampled data to the complete spectrum under a
relatively comprehensible and low-computation-cost architecture. Second, we
show that MoDern enables robust and high-fidelity spectra reconstruction for
challenging multi-dimensional protein NMR and achieves high reliability on the
relative concentration of the metabolite mixture. Third, we develop an
easy-to-use cloud platform (MoDern-Cloud), to facilitate the widespread usage
of this method, bridging the gap between high-performance and accessible
implementations, and contributing a promising platform for further development
of spectra analysis. These results suggest that MoDern-Cloud is a reliable,
widely-available, understandable, and ultra-fast reconstruction technique for
highly accelerated NMR.
</p>
<a href="http://arxiv.org/abs/2012.14830" target="_blank">arXiv:2012.14830</a> [<a href="http://arxiv.org/pdf/2012.14830" target="_blank">pdf</a>]

<h2>tf.data: A Machine Learning Data Processing Framework. (arXiv:2101.12127v2 [cs.LG] UPDATED)</h2>
<h3>Derek G. Murray, Jiri Simsa, Ana Klimovic, Ihor Indyk</h3>
<p>Training machine learning models requires feeding input data for models to
ingest. Input pipelines for machine learning jobs are often challenging to
implement efficiently as they require reading large volumes of data, applying
complex transformations, and transferring data to hardware accelerators while
overlapping computation and communication to achieve optimal performance. We
present tf.data, a framework for building and executing efficient input
pipelines for machine learning jobs. The tf.data API provides operators which
can be parameterized with user-defined computation, composed, and reused across
different machine learning domains. These abstractions allow users to focus on
the application logic of data processing, while tf.data's runtime ensures that
pipelines run efficiently.

We demonstrate that input pipeline performance is critical to the end-to-end
training time of state-of-the-art machine learning models. tf.data delivers the
high performance required, while avoiding the need for manual tuning of
performance knobs. We show that tf.data features, such as parallelism, caching,
static optimizations, and non-deterministic execution are essential for high
performance. Finally, we characterize machine learning input pipelines for
millions of jobs that ran in Google's fleet, showing that input data processing
is highly diverse and consumes a significant fraction of job resources. Our
analysis motivates future research directions, such as sharing computation
across jobs and pushing data projection to the storage layer.
</p>
<a href="http://arxiv.org/abs/2101.12127" target="_blank">arXiv:2101.12127</a> [<a href="http://arxiv.org/pdf/2101.12127" target="_blank">pdf</a>]

<h2>The Analysis from Nonlinear Distance Metric to Kernel-based Drug Prescription Prediction System. (arXiv:2102.02446v2 [cs.LG] UPDATED)</h2>
<h3>Der-Chen Chang, Ophir Frieder, Chi-Feng Hung, Hao-Ren Yao</h3>
<p>Distance metrics and their nonlinear variant play a crucial role in machine
learning based real-world problem solving. We demonstrated how Euclidean and
cosine distance measures differ not only theoretically but also in real-world
medical application, namely, outcome prediction of drug prescription. Euclidean
distance exhibits favorable properties in the local geometry problem. To this
regard, Euclidean distance can be applied under short-term disease with
low-variation outcome observation. Moreover, when presenting to highly variant
chronic disease, it is preferable to use cosine distance. These different
geometric properties lead to different submanifolds in the original embedded
space, and hence, to different optimizing nonlinear kernel embedding
frameworks. We first established the geometric properties that we needed in
these frameworks. From these properties interpreted their differences in
certain perspectives. Our evaluation on real-world, large-scale electronic
health records and embedding space visualization empirically validated our
approach.
</p>
<a href="http://arxiv.org/abs/2102.02446" target="_blank">arXiv:2102.02446</a> [<a href="http://arxiv.org/pdf/2102.02446" target="_blank">pdf</a>]

<h2>Hybrid Adversarial Inverse Reinforcement Learning. (arXiv:2102.02454v2 [cs.LG] UPDATED)</h2>
<h3>Mingqi Yuan, Man-On Pun, Yi Chen, Qi Cao</h3>
<p>In this paper, we investigate the problem of the inverse reinforcement
learning (IRL), especially the beyond-demonstrator (BD) IRL. The BD-IRL aims to
not only imitate the expert policy but also extrapolate BD policy based on
finite demonstrations of the expert. Currently, most of the BD-IRL algorithms
are two-stage, which first infer a reward function then learn the policy via
reinforcement learning (RL). Because of the two separate procedures, the
two-stage algorithms have high computation complexity and lack robustness. To
overcome these flaw, we propose a BD-IRL framework entitled hybrid adversarial
inverse reinforcement learning (HAIRL), which successfully integrates the
imitation and exploration into one procedure. The simulation results show that
the HAIRL is more efficient and robust when compared with other similar
state-of-the-art (SOTA) algorithms.
</p>
<a href="http://arxiv.org/abs/2102.02454" target="_blank">arXiv:2102.02454</a> [<a href="http://arxiv.org/pdf/2102.02454" target="_blank">pdf</a>]

<h2>Is Space-Time Attention All You Need for Video Understanding?. (arXiv:2102.05095v2 [cs.CV] UPDATED)</h2>
<h3>Gedas Bertasius, Heng Wang, Lorenzo Torresani</h3>
<p>We present a convolution-free approach to video classification built
exclusively on self-attention over space and time. Our method, named
"TimeSformer," adapts the standard Transformer architecture to video by
enabling spatiotemporal feature learning directly from a sequence of
frame-level patches. Our experimental study compares different self-attention
schemes and suggests that "divided attention," where temporal attention and
spatial attention are separately applied within each block, leads to the best
video classification accuracy among the design choices considered. Despite the
radically different design compared to the prominent paradigm of 3D
convolutional architectures for video, TimeSformer achieves state-of-the-art
results on several major action recognition benchmarks, including the best
reported accuracy on Kinetics-400 and Kinetics-600. Furthermore, our model is
faster to train and has higher test-time efficiency compared to competing
architectures. Code and pretrained models will be made publicly available.
</p>
<a href="http://arxiv.org/abs/2102.05095" target="_blank">arXiv:2102.05095</a> [<a href="http://arxiv.org/pdf/2102.05095" target="_blank">pdf</a>]

<h2>Locally Free Weight Sharing for Network Width Search. (arXiv:2102.05258v2 [cs.CV] UPDATED)</h2>
<h3>Xiu Su, Shan You, Tao Huang, Fei Wang, Chen Qian, Changshui Zhang, Chang Xu</h3>
<p>Searching for network width is an effective way to slim deep neural networks
with hardware budgets. With this aim, a one-shot supernet is usually leveraged
as a performance evaluator to rank the performance \wrt~different width.
Nevertheless, current methods mainly follow a manually fixed weight sharing
pattern, which is limited to distinguish the performance gap of different
width. In this paper, to better evaluate each width, we propose a locally free
weight sharing strategy (CafeNet) accordingly. In CafeNet, weights are more
freely shared, and each width is jointly indicated by its base channels and
free channels, where free channels are supposed to loCAte FrEely in a local
zone to better represent each width. Besides, we propose to further reduce the
search space by leveraging our introduced FLOPs-sensitive bins. As a result,
our CafeNet can be trained stochastically and get optimized within a min-min
strategy. Extensive experiments on ImageNet, CIFAR-10, CelebA and MS COCO
dataset have verified our superiority comparing to other state-of-the-art
baselines. For example, our method can further boost the benchmark NAS network
EfficientNet-B0 by 0.41\% via searching its width more delicately.
</p>
<a href="http://arxiv.org/abs/2102.05258" target="_blank">arXiv:2102.05258</a> [<a href="http://arxiv.org/pdf/2102.05258" target="_blank">pdf</a>]

<h2>Learning Interaction-Aware Trajectory Predictions for Decentralized Multi-Robot Motion Planning in Dynamic Environments. (arXiv:2102.05382v2 [cs.RO] UPDATED)</h2>
<h3>Hai Zhu, Francisco Martinez Claramunt, Bruno Brito, Javier Alonso-Mora</h3>
<p>This paper presents a data-driven decentralized trajectory optimization
approach for multi-robot motion planning in dynamic environments. When
navigating in a shared space, each robot needs accurate motion predictions of
neighboring robots to achieve predictive collision avoidance. These motion
predictions can be obtained among robots by sharing their future planned
trajectories with each other via communication. However, such communication may
not be available nor reliable in practice. In this paper, we introduce a novel
trajectory prediction model based on recurrent neural networks (RNN) that can
learn multi-robot motion behaviors from demonstrated trajectories generated
using a centralized sequential planner. The learned model can run efficiently
online for each robot and provide interaction-aware trajectory predictions of
its neighbors based on observations of their history states. We then
incorporate the trajectory prediction model into a decentralized model
predictive control (MPC) framework for multi-robot collision avoidance.
Simulation results show that our decentralized approach can achieve a
comparable level of performance to a centralized planner while being
communication-free and scalable to a large number of robots. We also validate
our approach with a team of quadrotors in real-world experiments.
</p>
<a href="http://arxiv.org/abs/2102.05382" target="_blank">arXiv:2102.05382</a> [<a href="http://arxiv.org/pdf/2102.05382" target="_blank">pdf</a>]

<h2>Interventional Sum-Product Networks: Causal Inference with Tractable Probabilistic Models. (arXiv:2102.10440v2 [cs.LG] UPDATED)</h2>
<h3>Matej Ze&#x10d;evi&#x107;, Devendra Singh Dhami, Athresh Karanam, Sriraam Natarajan, Kristian Kersting</h3>
<p>While probabilistic models are an important tool for studying causality,
doing so suffers from the intractability of inference. As a step towards
tractable causal models, we consider the problem of learning interventional
distributions using sum-product networks (SPNs) that are over-parameterized by
gate functions, e.g., neural networks. Providing an arbitrarily intervened
causal graph as input, effectively subsuming Pearl's do-operator, the gate
function predicts the parameters of the SPN. The resulting interventional SPNs
are motivated and illustrated by a structural causal model themed around
personal health. Our empirical evaluation on three benchmark data sets as well
as a synthetic health data set clearly demonstrates that interventional SPNs
indeed are both expressive in modelling and flexible in adapting to the
interventions.
</p>
<a href="http://arxiv.org/abs/2102.10440" target="_blank">arXiv:2102.10440</a> [<a href="http://arxiv.org/pdf/2102.10440" target="_blank">pdf</a>]

<h2>Generative Archimedean Copulas. (arXiv:2102.11351v2 [cs.LG] UPDATED)</h2>
<h3>Yuting Ng, Ali Hasan, Khalil Elkhalil, Vahid Tarokh</h3>
<p>We propose a new generative modeling technique for learning multidimensional
cumulative distribution functions (CDFs) in the form of copulas. Specifically,
we consider certain classes of copulas known as Archimedean and hierarchical
Archimedean copulas, popular for their parsimonious representation and ability
to model different tail dependencies. We consider their representation as
mixture models with Laplace transforms of latent random variables from
generative neural networks. This alternative representation allows for easy
sampling and computational efficiencies especially in high dimensions. We
additionally describe multiple methods for optimizing the model parameters.
Finally, we present empirical results that demonstrate the efficacy of our
proposed method in learning multidimensional CDFs and its computational
efficiency compared to existing methods.
</p>
<a href="http://arxiv.org/abs/2102.11351" target="_blank">arXiv:2102.11351</a> [<a href="http://arxiv.org/pdf/2102.11351" target="_blank">pdf</a>]

<h2>DeepThermal: Combustion Optimization for Thermal Power Generating Units Using Offline Reinforcement Learning. (arXiv:2102.11492v2 [cs.LG] UPDATED)</h2>
<h3>Xianyuan Zhan, Haoran Xu, Yue Zhang, Yusen Huo, Xiangyu Zhu, Honglei Yin, Yu Zheng</h3>
<p>Thermal power generation plays a dominant role in the world's electricity
supply. It consumes large amounts of coal worldwide, and causes serious air
pollution. Optimizing the combustion efficiency of a thermal power generating
unit (TPGU) is a highly challenging and critical task in the energy industry.
We develop a new data-driven AI system, namely DeepThermal, to optimize the
combustion control strategy for TPGUs. At its core, is a new model-based
offline reinforcement learning (RL) framework, called MORE, which leverages
logged historical operational data of a TPGU to solve a highly complex
constrained Markov decision process problem via purely offline training. MORE
aims at simultaneously improving the long-term reward (increase combustion
efficiency and reduce pollutant emission) and controlling operational risks
(safety constraints satisfaction). In DeepThermal, we first learn a data-driven
combustion process simulator from the offline dataset. The RL agent of MORE is
then trained by combining real historical data as well as carefully filtered
and processed simulation data through a novel restrictive exploration scheme.
DeepThermal has been successfully deployed in four large coal-fired thermal
power plants in China. Real-world experiments show that DeepThermal effectively
improves the combustion efficiency of a TPGU. We also report and demonstrate
the superior performance of MORE by comparing with the state-of-the-art
algorithms on the standard offline RL benchmarks. To the best knowledge of the
authors, DeepThermal is the first AI application that has been used to solve
real-world complex mission-critical control tasks using the offline RL
approach.
</p>
<a href="http://arxiv.org/abs/2102.11492" target="_blank">arXiv:2102.11492</a> [<a href="http://arxiv.org/pdf/2102.11492" target="_blank">pdf</a>]

<h2>Differentiable Logic Machines. (arXiv:2102.11529v2 [cs.AI] UPDATED)</h2>
<h3>Matthieu Zimmer, Xuening Feng, Claire Glanois, Zhaohui Jiang, Jianyi Zhang, Paul Weng, Hao Jianye, Li Dong, Liu Wulong</h3>
<p>The integration of reasoning, learning, and decision-making is key to build
more general AI systems. As a step in this direction, we propose a novel
neural-logic architecture that can solve both inductive logic programming (ILP)
and deep reinforcement learning (RL) problems. Our architecture defines a
restricted but expressive continuous space of first-order logic programs by
assigning weights to predicates instead of rules. Therefore, it is fully
differentiable and can be efficiently trained with gradient descent. Besides,
in the deep RL setting with actor-critic algorithms, we propose a novel
efficient critic architecture. Compared to state-of-the-art methods on both ILP
and RL problems, our proposition achieves excellent performance, while being
able to provide a fully interpretable solution and scaling much better,
especially during the testing phase.
</p>
<a href="http://arxiv.org/abs/2102.11529" target="_blank">arXiv:2102.11529</a> [<a href="http://arxiv.org/pdf/2102.11529" target="_blank">pdf</a>]

<h2>SeqNet: Learning Descriptors for Sequence-based Hierarchical Place Recognition. (arXiv:2102.11603v2 [cs.CV] UPDATED)</h2>
<h3>Sourav Garg, Michael Milford</h3>
<p>Visual Place Recognition (VPR) is the task of matching current visual imagery
from a camera to images stored in a reference map of the environment. While
initial VPR systems used simple direct image methods or hand-crafted visual
features, recent work has focused on learning more powerful visual features and
further improving performance through either some form of sequential matcher /
filter or a hierarchical matching process. In both cases the performance of the
initial single-image based system is still far from perfect, putting
significant pressure on the sequence matching or (in the case of hierarchical
systems) pose refinement stages. In this paper we present a novel hybrid system
that creates a high performance initial match hypothesis generator using short
learnt sequential descriptors, which enable selective control sequential score
aggregation using single image learnt descriptors. Sequential descriptors are
generated using a temporal convolutional network dubbed SeqNet, encoding short
image sequences using 1-D convolutions, which are then matched against the
corresponding temporal descriptors from the reference dataset to provide an
ordered list of place match hypotheses. We then perform selective sequential
score aggregation using shortlisted single image learnt descriptors from a
separate pipeline to produce an overall place match hypothesis. Comprehensive
experiments on challenging benchmark datasets demonstrate the proposed method
outperforming recent state-of-the-art methods using the same amount of
sequential information. Source code and supplementary material can be found at
https://github.com/oravus/seqNet.
</p>
<a href="http://arxiv.org/abs/2102.11603" target="_blank">arXiv:2102.11603</a> [<a href="http://arxiv.org/pdf/2102.11603" target="_blank">pdf</a>]

<h2>Learning to Fairly Classify the Quality of Wireless Links. (arXiv:2102.11655v2 [cs.LG] UPDATED)</h2>
<h3>Gregor Cerar, Halil Yetgin, Mihael Mohor&#x10d;i&#x10d;, Carolina Fortuna</h3>
<p>Machine learning (ML) has been used to develop increasingly accurate link
quality estimators for wireless networks. However, more in-depth questions
regarding the most suitable class of models, most suitable metrics and model
performance on imbalanced datasets remain open. In this paper, we propose a new
tree-based link quality classifier that meets high performance and fairly
classifies the minority class and, at the same time, incurs low training cost.
We compare the tree-based model, to a multilayer perceptron (MLP) non-linear
model and two linear models, namely logistic regression (LR) and SVM, on a
selected imbalanced dataset and evaluate their results using five different
performance metrics. Our study shows that 1) non-linear models perform slightly
better than linear models in general, 2) the proposed non-linear tree-based
model yields the best performance trade-off considering F1, training time and
fairness, 3) single metric aggregated evaluations based only on accuracy can
hide poor, unfair performance especially on minority classes, and 4) it is
possible to improve the performance on minority classes, by over 40% through
feature selection and by over 20% through resampling, therefore leading to
fairer classification results.
</p>
<a href="http://arxiv.org/abs/2102.11655" target="_blank">arXiv:2102.11655</a> [<a href="http://arxiv.org/pdf/2102.11655" target="_blank">pdf</a>]

<h2>School of hard knocks: Curriculum analysis for Pommerman with a fixed computational budget. (arXiv:2102.11762v2 [cs.AI] UPDATED)</h2>
<h3>Omkar Shelke, Hardik Meisheri, Harshad Khadilkar</h3>
<p>Pommerman is a hybrid cooperative/adversarial multi-agent environment, with
challenging characteristics in terms of partial observability, limited or no
communication, sparse and delayed rewards, and restrictive computational time
limits. This makes it a challenging environment for reinforcement learning (RL)
approaches. In this paper, we focus on developing a curriculum for learning a
robust and promising policy in a constrained computational budget of 100,000
games, starting from a fixed base policy (which is itself trained to imitate a
noisy expert policy). All RL algorithms starting from the base policy use
vanilla proximal-policy optimization (PPO) with the same reward function, and
the only difference between their training is the mix and sequence of opponent
policies. One expects that beginning training with simpler opponents and then
gradually increasing the opponent difficulty will facilitate faster learning,
leading to more robust policies compared against a baseline where all available
opponent policies are introduced from the start. We test this hypothesis and
show that within constrained computational budgets, it is in fact better to
"learn in the school of hard knocks", i.e., against all available opponent
policies nearly from the start. We also include ablation studies where we study
the effect of modifying the base environment properties of ammo and bomb blast
strength on the agent performance.
</p>
<a href="http://arxiv.org/abs/2102.11762" target="_blank">arXiv:2102.11762</a> [<a href="http://arxiv.org/pdf/2102.11762" target="_blank">pdf</a>]

<h2>Learning Obstacle Representations for Neural Motion Planning. (arXiv:2008.11174v4 [cs.RO] CROSS LISTED)</h2>
<h3>Robin Strudel, Ricardo Garcia, Justin Carpentier, Jean-Paul Laumond, Ivan Laptev, Cordelia Schmid</h3>
<p>Motion planning and obstacle avoidance is a key challenge in robotics
applications. While previous work succeeds to provide excellent solutions for
known environments, sensor-based motion planning in new and dynamic
environments remains difficult. In this work we address sensor-based motion
planning from a learning perspective. Motivated by recent advances in visual
recognition, we argue the importance of learning appropriate representations
for motion planning. We propose a new obstacle representation based on the
PointNet architecture and train it jointly with policies for obstacle
avoidance. We experimentally evaluate our approach for rigid body motion
planning in challenging environments and demonstrate significant improvements
of the state of the art in terms of accuracy and efficiency.
</p>
<a href="http://arxiv.org/abs/2008.11174" target="_blank">arXiv:2008.11174</a> [<a href="http://arxiv.org/pdf/2008.11174" target="_blank">pdf</a>]

